[
    {
        "query":"什么是 AWS Organizations？",
        "intention":"知识问答",
        "reply":"AWS Organizations 有助于您在 AWS 上扩展工作负载时对您的环境进行集中管理。无论您是一个成长型初创公司还是一个大型企业，Organizations 都能帮助您以编程方式创建新账户和分配资源，通过为所有账户设置单个付款方式简化计费，创建账户组以组织您的工作流，并将策略应用于这些组进行治理。另外，AWS Organizations 与其他 AWS 服务进行了集成，以便在您的组织中跨账户指定中央配置、安全机制和资源共享。"
    },
    {
        "query":"AWS Organizations 在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"AWS Organizations 现已在所有 AWS 商业区域、AWS GovCloud（美国）区域和中国区域推出。AWS Organizations 的服务终端节点位于美国东部（弗吉尼亚北部），适用于商业组织；AWS GovCloud（美国西部），适用于 AWS GovCloud（美国）组织；以及由西云数据运营的 AWS 中国（宁夏）区域。"
    },
    {
        "query":"如何开始使用？",
        "intention":"知识问答",
        "reply":"首先，您必须先确定将哪个 AWS 账户作为管理账户（之前称为主账户）。您可以创建新 AWS 账户或选择现有账户。\n您还可以使用 [AWS CLI](https://aws.amazon.com/cli/)（针对命令行访问）或[开发工具包](https://docs.aws.amazon.com/organizations/latest/APIReference/API_CreateOrganization.html?org_product_faq_api)执行相同的步骤来创建新组织。\n注意：您只能使用并非其他组织成员的 AWS 账户开始创建新组织。\n有关更多信息，请参阅 [AWS Organizations 入门](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_getting-started.html?org_product_faq_gs)。"
    },
    {
        "query":"什么是 AWS Control Tower？",
        "intention":"知识问答",
        "reply":"AWS Control Tower 基于 AWS Organizations 等 AWS 服务构建，提供设置和管理新的安全多账户 AWS 环境的最简单方法。它建立了一个登录区，这是一个基于最佳实践蓝图的架构完善的多账户环境，并使用您可以选择的护栏实现监管。护栏是实施安全性、合规性和操作监管的 SCP 和 AWS Config 规则。"
    },
    {
        "query":"AWS Control Tower 和 AWS Organizations 之间有什么区别？",
        "intention":"知识问答",
        "reply":"[AWS Control Tower](https://aws.amazon.com/cn/controltower/?org_product_faq_CT) 基于 AWS Organizations 提供抽象、自动化和规范性的体验。它自动将 AWS Organizations 设置为底层 AWS 服务，以组织账户并使用 SCP 实施预防性护栏。Control Tower 和 Organizations 可以很好地协同工作。您可以使用 Control Tower 设置环境和护栏，然后通过 AWS Organizations，您可以进一步创建自定义策略（如标签、备份或 SCP），集中控制跨多个 AWS 账户使用 AWS 服务和资源。"
    },
    {
        "query":"AWS Control Tower 使用护栏。什么是护栏？",
        "intention":"知识问答",
        "reply":"护栏是针对安全性、操作和合规性的预打包 SCP 和 AWS Config 监管规则，客户可以选择并应用于企业范围或特定的账户组。护栏以通俗易懂的英语表示，并为您的 AWS 环境实施特定的监管策略，该策略可在组织单位 (OU) 内启用。"
    },
    {
        "query":"何时应使用 AWS Control Tower？",
        "intention":"知识问答",
        "reply":"AWS Control Tower 适用于希望使用内置最佳实践创建或管理其多账户 AWS 环境的客户。它为大规模管理您的 AWS 环境提供了规范性指导，并使您可以在不牺牲 AWS 为构建者提供的速度和敏捷性的情况下控制您的环境。如果您正在构建新的 AWS 环境，从 AWS 之旅开始，启动新的云计划，对 AWS 完全陌生，或者拥有现有的多账户 AWS 环境，您将从 AWS Control Tower 获益。"
    },
    {
        "query":"什么是组织？",
        "intention":"知识问答",
        "reply":"组织是指一系列 AWS 账户，您可以将其整理为一个层次结构并进行集中管理。"
    },
    {
        "query":"什么是 AWS 账户？",
        "intention":"知识问答",
        "reply":"AWS 账户是您 AWS 资源的容器。您可以在 AWS 账户中创建和管理您的 AWS 资源，且 AWS 账户会提供访问和计费等管理功能。\n使用多个 AWS 账户是扩展您的环境的最佳做法，因为它为成本提供了自然的计费边界，隔离了安全资源，提供了灵活性或个人和团队，同时还能适应新的业务流程。"
    },
    {
        "query":"什么是管理账户（以前称为主账户）？",
        "intention":"知识问答",
        "reply":"管理账户指您用于创建组织的 AWS 账户。使用管理账户，您可以在组织内创建其他账户，邀请其他账户加入您的组织并对此类邀请进行管理，以及从您的组织中删除账户。您还可以将策略与组织内的管理根、组织单元 (OU) 或账户等实体关联。管理账户是组织的最终拥有者，对安全性、基础设施和财务策略拥有最终控制权。该账户将承担付款人账户的职责，并负责支付其组织内所有账户产生的全部费用。您不能更改组织内的那个账户为管理账户。"
    },
    {
        "query":"什么是成员账户？",
        "intention":"知识问答",
        "reply":"成员账户是除管理账户以外的 AWS 账户，是组织的一部分。如果您是某个组织的管理员，您可以在该组织内创建成员账户，也可以邀请现有账户加入该组织。您还可以对成员账户应用策略。一个成员账户一次只能属于一个组织。"
    },
    {
        "query":"什么是管理根？",
        "intention":"知识问答",
        "reply":"管理根包含在管理账户中，是整理 AWS 账户的起始点。管理根是组织层次结构中最顶层的容器。在此根下，您可以创建 OU 以对账户进行逻辑分组，并将这些 OU 整理到最能满足您的业务需求的层次结构中。"
    },
    {
        "query":"什么是组织单元 (OU)？",
        "intention":"知识问答",
        "reply":"组织单元 (OU) 是组织内的一组 AWS 账户。OU 还可以包含允许您创建层次结构的其他 OU。例如，您可以将属于同一个部门的所有账户都归组到一个部门 OU。同样地，您也可以将运行安全服务的所有账户归组到一个安全 OU。当您需要对组织内的一组账户应用相同的控制时，OU 则非常有用。嵌套 OU 能够实现更小的管理单位。例如，您可以为每个工作负载创建 OU，然后在每个工作负载 OU 中创建两个嵌套 OU，以将生产工作负载与生产前工作负载分开。除直接指定给这些团队级 OU 的所有控制外，它们还会继承父 OU 的策略。"
    },
    {
        "query":"什么是策略？",
        "intention":"知识问答",
        "reply":"策略是指含有一个或多个语句的“文档”，这些语句用于定义您要应用于某组 AWS 账户的控件。AWS Organizations 支持以下策略："
    },
    {
        "query":"我能否按区域定义并管理我的组织？",
        "intention":"知识问答",
        "reply":"除在中国管理的组织外，所有组织实体均已实现全球可访问性，运行方式与 AWS Identity and Access Management (IAM) 目前的运行方式类似。在创建和管理组织时，您无需指定 AWS 区域，但您需要为中国使用的账户创建单独的组织。AWS 账户中的用户可以在提供 AWS 服务的所有地理区域使用此项服务。"
    },
    {
        "query":"我能否更改用作管理账户的 AWS 账户？",
        "intention":"知识问答",
        "reply":"不能。您不能更改用作管理账户的 AWS 账户。因此，请务必谨慎选择管理账户。"
    },
    {
        "query":"如何向我的组织添加 AWS 账户？",
        "intention":"知识问答",
        "reply":"请使用以下两种方法之一向您的组织添加 AWS 账户：\n方法 1：邀请现有账户加入您的组织\n1.以管理账户管理员的身份登录，然后导航至 AWS Organizations 控制台。\n2.选择“账户”选项卡。\n3.选择“添加账户”，然后选择“邀请账户”。\n4.提供您要邀请的账户的电子邮件地址或该账户的 AWS 账户 ID。\n注意：您可以邀请多个 AWS 账户，列出所有电子邮件地址或 AWS 账户 ID 并使用逗号将其分隔开来即可。\n指定的 AWS 账户将收到一封邀请其加入您组织的电子邮件。受邀 AWS 账户的管理员必须使用 AWS Organizations 控制台、AWS CLI 或 AWS Organizations API 来接受或拒绝请求。如果相应的管理员接受了您的邀请，其账户便会出现在您组织的成员账户列表中。[SCP](https://aws.amazon.com/organizations/faqs/#scps) 等任何适用策略都会在新添加的账户中自动执行。例如，如果您的组织将 SCP 与组织的根关联，系统将为新创建的账户直接执行 SCP。\n方法 2：在您的组织内创建 AWS 账户\n1.以管理账户管理员的身份登录，然后导航至 AWS Organizations 控制台。\n2.选择“账户”选项卡。\n3.选择“添加账户”，然后选择“创建账户”。\n4.为账户提供一个名称和一个电子邮件地址。\n您也可以使用 AWS 开发工具包或 AWS CLI 创建账户。对于这两种方法，添加新账户后，您可以将其移动到组织单元 (OU)。新账户会自动继承与 OU 关联的策略。"
    },
    {
        "query":"一个 AWS 账户能否是多个组织的成员？",
        "intention":"知识问答",
        "reply":"不能。一个 AWS 账户一次只能是一个组织的成员。"
    },
    {
        "query":"我能否访问在我的组织内创建的 AWS 账户？",
        "intention":"知识问答",
        "reply":"在 AWS 账户创建过程中，AWS Organizations 会创建一个 IAM 角色，该角色拥有新账户的全部管理权限。主账户中拥有相应权限的 IAM 用户和 IAM 角色可以担任此 IAM 角色，以获得访问新建账户的权限。"
    },
    {
        "query":"能否对我在组织中创建的 AWS 账户以编程方式设置 Multi-Factor Authentication (MFA)？",
        "intention":"知识问答",
        "reply":"不，当前不支持。"
    },
    {
        "query":"能否将通过 AWS Organizations 创建的 AWS 账户移动到其他组织？",
        "intention":"知识问答",
        "reply":"可以。但您必须首先将该账户从您的组织内移除，使之成为独立账户 (见下文)。将该账户变成独立账户后，即可邀请它加入其它组织。"
    },
    {
        "query":"我是否可以删除使用 Organizations 创建的 AWS 账户并将其作为独立账户？",
        "intention":"知识问答",
        "reply":"可以。当您使用 AWS Organizations 控制台、API 或 CLI 命令在组织内创建账户时，AWS 仅收集创建独立账户所需的提供的部分信息。对于您要将其变成独立账户的每个账户，您需要遵循以下要求：提供联系方式；同意 [AWS 客户协议](https://aws.amazon.com/cn/agreement/)；提供有效付款方式；以及选择支持计划。AWS 将使用该付款方式收取账户未绑定到组织期间发生的所有应收费 (非 AWS 免费套餐) AWS 活动的费用。有关更多信息，请参阅[从组织中删除成员账户](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_accounts_remove.html?org_product_faq_removeaccount)。"
    },
    {
        "query":"我在组织中可以管理多少个 AWS 账户？",
        "intention":"知识问答",
        "reply":"这要视具体情况而定。如果需要更多账户，请前往 [AWS Support 中心](https://console.aws.amazon.com/support/home)，打开支持案例申请增加账户数。"
    },
    {
        "query":"如何从组织删除 AWS 成员账户？",
        "intention":"知识问答",
        "reply":"您可以通过以下两种方法删除成员账户：要删除使用 Organizations 创建的账户，您可能还需要提供额外的信息。如果尝试删除账户失败，请前往 [AWS Support 中心](https://console.aws.amazon.com/support/home)，寻求有关删除账户的帮助。\n方法 1：通过登录管理账户删除受邀成员账户\n1.以主账户管理员的身份登录，然后导航至 AWS Organizations 控制台。\n2.在左窗格中，选择账户。\n3.选择要删除的账户，然后选择删除账户。\n4.如果相应的账户没有有效的付款方式，您必须提供一种付款方式。\n方法 2：通过登录成员账户删除受邀成员账户\n1.以管理员身份登录您要从组织中删除的成员账户。\n2.导航至 AWS Organizations 控制台。\n3.选择\\*退出组织\\*。\n4.如果相应的账户没有付款方式，您必须提供一种付款方式。"
    },
    {
        "query":"如何创建组织单元 (OU)？",
        "intention":"知识问答",
        "reply":"要创建 OU，请执行以下操作：\n1.以管理账户管理员的身份登录，然后导航至 AWS Organizations 控制台。\n2.选择组织账户选项卡。\n3.在层次结构中导航至您要创建 OU 的位置。您可以直接在根下创建，也可以在其他 OU 中创建。\n4.选择创建组织部门，为该 OU 提供名称。该名称在您的组织内必须是唯一的。\n注意：稍后您可以重命名该 OU。\n现在，您可以向该 OU 添加 AWS 账户了。您也可以使用 AWS CLI 和 AWS API 创建和管理 OU。"
    },
    {
        "query":"如何将成员 AWS 账户添加到 OU？",
        "intention":"知识问答",
        "reply":"请按照以下步骤将成员账户添加到 OU：\n1.在 AWS Organizations 控制台中，选择“组织账户”选项卡。\n2.选择相应的 AWS 账户，然后选择“移动账户”。\n3.在对话框中，选择要将 AWS 账户移至的 OU。\n或者，您也可以使用 AWS CLI 和 AWS API 将 AWS 账户添加到 OU。"
    },
    {
        "query":"一个 AWS 账户可以是多个 OU 的成员吗？",
        "intention":"知识问答",
        "reply":"不可以。一个 AWS 账户一次只能是一个 OU 的成员。"
    },
    {
        "query":"一个 OU 可以是多个 OU 的成员吗？",
        "intention":"知识问答",
        "reply":"不可以。一个 OU 一次只能是一个 OU 的成员。"
    },
    {
        "query":"我的 OU 层次结构中可以有多少层？",
        "intention":"知识问答",
        "reply":"您可以将 OU 嵌套 5 层。包括在最低 OU 中创建的根账户和 AWS 账户在内，您的层次结构可以为 5 层。"
    },
    {
        "query":"我可以在组织的哪些级别应用策略？",
        "intention":"知识问答",
        "reply":"您可以将策略关联到组织的根（应用于组织内的所有账户）、各个组织单元 (OU)（应用于包括嵌套 OU 在内的 OU 中的所有账户）或各个账户。"
    },
    {
        "query":"如何关联某条策略？",
        "intention":"知识问答",
        "reply":"您可以使用以下两种方法之一关联策略：\n有关更多信息，请参阅[管理策略](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies.html?org_product_faq_managepolicies)。"
    },
    {
        "query":"在我的组织中，策略是否会通过层次关联来继承？",
        "intention":"知识问答",
        "reply":"可以。例如，假设您已按照应用程序开发阶段 (开发、测试和生产) 将您的 AWS 账户整理到不同 OU 中。策略 P1 已关联到组织的根，策略 P2 已关联到 DEV OU，且策略 P3 已关联到 DEV OU 中的 AWS 账户 A1。在此设置下，P1、P2 和 P3 均会应用于账户 A1。  \n 有关更多信息，请参阅[关于服务控制策略](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_about-scps.html?org_product_faq_aboutSCP)。"
    },
    {
        "query":"AWS Organizations 支持哪些类型的策略？",
        "intention":"知识问答",
        "reply":"目前，AWS Organizations 支持以下策略："
    },
    {
        "query":"什么是服务控制策略 (SCP)？",
        "intention":"知识问答",
        "reply":"您可以使用服务控制策略 (SCP) 来控制您组织的账户中委托人（账户根、IAM 用户和 IAM 角色）可以访问哪些 AWS 服务操作。在决定账户中哪些委托人可以访问资源以向账户中的委托人授予访问资源的权限时，SCP 是必要条件，但不是充分条件。在已关联 SCP 的账户中，委托人的有效权限是 SCP 明确允许的操作与关联到该委托人的权限所明确允许操作的交集。例如，如果应用于某个账户的 SCP 指明允许的操作仅包括 Amazon EC2 操作，但同一个 AWS 账户中的委托人权限同时允许 EC2 操作和 Amazon S3 操作，则该委托人将仅可访问 EC2 操作。  \n 成员账户中的委托人（包括成员账户的根用户）不能删除或更改应用于该账户的 SCP。"
    },
    {
        "query":"SCP 是什么样的？",
        "intention":"知识问答",
        "reply":"SCPs 遵循与 IAM 策略相同的规则和语法。有关 SCP 语法的信息，请参阅 [SCP 语法](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_reference_scp-syntax.html)。关于 SCP 示例，请参阅[服务控制策略示例](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_example-scps.html)。\n黑名单示例  \n 以下 SCP 允许访问除 S3 操作 (PutObject) 之外的所有 AWS 服务操作。在应用此 SCP 的账户中，为其直接指定相应权限的所有委托人（账户根、IAM 用户和 IAM 角色）可以访问除 S3 PutObject 操作之外的任何操作。\n有关更多示例，请参阅[使用 SCP 的策略](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_about-scps.html#SCP_strategies)。"
    },
    {
        "query":"如果我将一条空 SCP 关联到某个 AWS 账户，这是否表示我在该 AWS 账户中允许所有 AWS 服务操作？",
        "intention":"知识问答",
        "reply":"不是。SCP 的行为与 IAM 策略相同：一条空 IAM 策略等同于默认拒绝。将空 SCP 与某个账户关联相当于关联一条明确拒绝所有操作的策略。"
    },
    {
        "query":"对于拥有 IAM 策略的组织和委托人，如果我对其应用 SCP，则其有效权限有哪些？",
        "intention":"知识问答",
        "reply":"在应用了 SCP 的 AWS 账户中授予委托人（账户根、IAM 用户和 IAM 角色）的有效权限是 SCP 所允许的权限与 IAM 权限策略授予委托人的权限的交集。例如，如果某个 IAM 用户拥有 \"Allow\": \"ec2:\\* \" 和 \"Allow\": \"sqs:\\* \"，与账户关联的 SCP 拥有 \"Allow\": \"ec2:\\* \" 和 \"Allow\": \"s3:\\* \"，则该 IAM 用户的最终权限为 \"Allow\": \"ec2:\\* \"，该委托人无法执行任何 Amazon SQS（SCP 不允许）操作或 S3 操作（IAM 策略不允许）。"
    },
    {
        "query":"能否模拟 SCP 对 AWS 账户产生的影响？",
        "intention":"知识问答",
        "reply":"能，IAM 策略模拟器可以包含 SCP 的影响。您可以在组织内的成员账户中使用策略模拟器，来了解 SCP 对账户中各个委托人产生的影响。成员账户中拥有适当 AWS Organizations 权限的管理员可以查看 SCP 是否影响您的成员账户中委托人 (账户根、IAM 用户和 IAM 角色) 的访问权限。  \n 有关更多信息，请参阅[服务控制策略](http://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html?org_product_faq_scp)。"
    },
    {
        "query":"创建和管理组织时，能否不应用 SCP？",
        "intention":"知识问答",
        "reply":"可以。由您决定要实施哪些策略。例如，您可以创建一个仅利用整合账单功能的组织。如此一来，您组织中的所有账户便具有一个付款人账户，可以自动享受默认的分级定价优惠。"
    },
    {
        "query":"在我组织中的 AWS 成员账户下，用户产生的使用费由谁支付？",
        "intention":"知识问答",
        "reply":"对于组织内账户的所有使用、数据和资源，由管理账户的拥有者负责支付相关费用。"
    },
    {
        "query":"我的账单能否反映出我在组织内创建的组织单元结构？",
        "intention":"知识问答",
        "reply":"不能。截至目前，您的账单不能反映出您在组织内定义的结构。您可以在各个 AWS 账户中使用[成本分配标签](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)对 AWS 费用进行归类和跟踪，且此项分配会显示在组织的整合账单中。"
    },
    {
        "query":"我为什么应该启用与 AWS Organizations 集成的 AWS 服务？",
        "intention":"知识问答",
        "reply":"AWS 服务已与 AWS Organizations 集成，从而为客户提供跨组织账户的集中管理和配置。这使您能够从一个地方跨账户管理服务，从而简化了部署和配置。"
    },
    {
        "query":"哪些 AWS 服务当前与 AWS Organizations 集成？",
        "intention":"知识问答",
        "reply":"有关与 AWS Organizations 集成的 AWS 服务的列表，请参阅[您可以与 AWS Organizations 结合使用的 AWS 服务](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_integrated-services-list.html?org_product_faq_services)。"
    },
    {
        "query":"如何启用 AWS 服务集成？",
        "intention":"知识问答",
        "reply":"要开始使用与 AWS Organization 集成的 AWS 服务，在 AWS 管理控制台中导航到该服务并启用集成。\n了解更多有关 AWS Organizations 的信息"
    },
    {
        "query":"什么是 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 是一种托管的、安全的云桌面服务。您可以使用 Amazon WorkSpaces 在几分钟内预置 Windows Amazon Linux 或 Ubuntu Linux 桌面，并快速扩展，从而为全球各地的员工提供数以千计的桌面。您只需要为启动的 Amazon WorkSpaces 按月付费或按小时付费。与传统的桌面和本地虚拟桌面基础架构（VDI）解决方案相比，可帮助您节省费用。Amazon WorkSpaces 可以帮助您消除管理清单、操作系统版本、补丁和虚拟桌面基础设施（VDI）的复杂性，这也有利于简化您的桌面交付策略。借助 Amazon WorkSpaces，您的用户能够选择运行快速的响应式桌面，该桌面可供他们随时随地从任何受支持的设备进行访问。"
    },
    {
        "query":"什么是 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpace 是一种可以代替传统桌面的基于云的虚拟桌面。WorkSpace 以包含操作系统、计算资源、存储空间和软件应用程序的捆绑包形式提供，让用户可以像使用传统桌面一样来执行日常任务。"
    },
    {
        "query":"如何连接到 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"用户可以从任何受支持的设备（包括 Windows 和 Mac 计算机、iPad、Android 平板电脑和[与 Android 兼容的 Chrome OS 设备](https://www.chromium.org/chromium-os/chrome-os-systems-supporting-android-apps)）使用免费的 Amazon WorkSpaces 客户端应用程序或通过 Chrome 或 Firefox Web 浏览器连接到 WorkSpace。用户将使用管理员设置的凭证进行连接，如果您已选择将 Amazon WorkSpaces 与现有的 Active Directory 域集成，则用户也可以使用现有的 Active Directory 凭证进行连接。用户连接到 WorkSpace 后，即可执行所有用台式计算机执行的常见任务。"
    },
    {
        "query":"如何开始使用 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"要开始使用 Amazon WorkSpaces，您需要一个 AWS 账户。您可以使用此账户登录 AWS 管理控制台，并为自己和组织中的任何其他用户快速预置 Amazon WorkSpaces。要预置 Amazon WorkSpace，首先从您的目录中选择一个用户。然后，为该用户选择一个 Amazon WorkSpaces 捆绑包。Amazon WorkSpaces 捆绑包会指定您需要的资源、要运行的桌面操作系统、要使用的存储容量以及要预先打包的软件应用程序。最后，为其 Amazon WorkSpace 选择一种运行模式 – 如果您想使用按月计费方式，请选择 AlwaysOn（始终开启）；如果您想使用按小时计费方式，请选择 AutoStop（自动停止）。在您预置好 WorkSpace 后，用户将收到一封电子邮件，其中包含有关如何连接到 WorkSpace 的说明。您可以按照此流程同时预置多个 WorkSpaces。"
    },
    {
        "query":"有哪些 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://aws.amazon.com/workspaces/details/#workspaces-bundles)找到有关 Amazon WorkSpaces 捆绑包的最新信息。"
    },
    {
        "query":"Amazon WorkSpaces 支持哪些流协议？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 支持两种协议，即 PCoIP 和 WorkSpaces 流协议 (WSP)。您选择的协议取决于多种因素，例如用户访问其 WorkSpaces 时所用的设备类型、您的 WorkSpaces 上使用的操作系统、用户将面临的网络条件，以及用户是否要求独特的功能对具体协议可用，例如 WSP 的双向视频和智能卡支持。请访问《Amazon WorkSpaces 管理指南》中的[适用于 Amazon WorkSpaces 的协议](https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces-protocols.html)以了解详情。"
    },
    {
        "query":"哪些操作系统可与 Amazon WorkSpaces 搭配使用？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 提供基于 Amazon Linux 2 LTS、Ubuntu WorkSpaces（构建于 Ubuntu Desktop 22.04 LTS 上）或 Windows 10 桌面体验构建的 Amazon Linux WorkSpaces。您可以选择是否由 Windows Server 2016 或 Windows Server 2019 为您的 Windows 10 桌面体验提供支持。如果贵组织有资格自带 Windows 桌面许可证，则您可以在您的 Amazon WorkSpaces 上运行 Windows 10 或 Windows 11 企业版操作系统。"
    },
    {
        "query":"对于 Amazon Linux WorkSpaces、Ubuntu WorkSpaces 和搭载 Windows 的 Amazon WorkSpaces，根卷和用户卷的映射对象是什么？",
        "intention":"知识问答",
        "reply":"对于 Amazon Linux WorkSpaces 和 Ubuntu WorkSpaces，根卷映射到 /，用户卷映射到 /home。\n对于 Windows，根卷映射到 C: drive，用户卷映射到 D: drive。"
    },
    {
        "query":"我能否将用户从 Amazon WorkSpaces Windows 7 捆绑包迁移到 Windows 10 捆绑包？",
        "intention":"知识问答",
        "reply":"可以。WorkSpaces 迁移可使 WorkSpaces 迁移到新的捆绑包或计算类型，并且保留用户卷数据。您可以执行迁移操作，以将您的用户移动到 Windows 10 桌面体验。要开始使用，请转至 Amazon WorkSpaces 控制台，选择 WorkSpace，点击“操作 > 迁移 WorkSpaces”，然后选择一个具有 Windows 10 桌面体验的目标捆绑包。"
    },
    {
        "query":"用户如何在完成预置后开始使用 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"在您预置好 Amazon WorkSpaces 后，用户会收到一封电子邮件，其中提供了关于从何处下载他们所需的 WorkSpaces 客户端以及如何连接到 WorkSpace 的说明。如果您未与现有 Active Directory 集成，用户将可以在首次尝试连接到 WorkSpace 时设置一个密码。如果您使用 AWS Directory Services AD Connector 与现有的 Active Directory 域集成，则用户可以使用常规的 Active Directory 凭证登录。"
    },
    {
        "query":"用户需要具备哪些条件才能使用 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"用户需要一个为其预置好的 Amazon WorkSpace，并拥有宽带互联网连接。要使用 Amazon WorkSpaces 客户端应用程序访问其 WorkSpace，他们需要一台受支持的客户端设备（PC、Mac、Linux、iPad、Android 平板电脑和与 Android 兼容的 Chrome OS 设备），并能通过 Internet 连接到打开的 TCP 端口 443 和用于 PCoIP 的 4172 或用于 WSP 的 4195，以及用于 PCoIP 的 UDP 端口 4172 或用于 WSP 的 4195。"
    },
    {
        "query":"用户连接到其 Amazon WorkSpace 后，能否使用自己的偏好设置对其进行个性化？",
        "intention":"知识问答",
        "reply":"管理员可以决定哪个用户可以个性化其 WorkSpace。默认情况下，用户可以使用其对墙纸、图标和快捷键等项目的最喜爱设置对其 WorkSpaces 进行个性化设置。这些设置将被保存，并存留到用户对其进行更改时为止。如果管理员要用组策略之类的工具锁定 WorkSpace（对于 Windows），用户个性化其 WorkSpace 的能力将受到限制。"
    },
    {
        "query":"用户能否在其 Amazon WorkSpace 上安装应用程序？",
        "intention":"知识问答",
        "reply":"默认情况下，用户被配置为其 WorkSpaces 的本地管理员。管理员可以更改此设置，并能限制用户使用群组策略之类的技术安装应用程序的能力。"
    },
    {
        "query":"Amazon WorkSpaces 是否具有持久性？",
        "intention":"知识问答",
        "reply":"是。每个 WorkSpace 都在分配给用户的单个实例上运行。应用程序和用户的文档和设置具有持久性。"
    },
    {
        "query":"用户是否需要 AWS 账户？",
        "intention":"知识问答",
        "reply":"不需要。只有在预置 WorkSpaces 时才需要 AWS 账户。要连接到 WorkSpaces，用户只需提供邀请电子邮件中随附的信息，用户在其 WorkSpace 预置完成后会收到这封邀请电子邮件。"
    },
    {
        "query":"如果我距我的 Amazon WorkSpace 所在区域较远，是否依然能够获得良好的用户体验？",
        "intention":"知识问答",
        "reply":"如果您距当前提供 Amazon WorkSpaces 的区域超过 2000 英里，您仍可使用该服务，但其响应能力可能会降低。检查性能的最简单方法是使用 Amazon WorkSpaces [连接运行状况检查网站](http://health.amazonworkspaces.com/)。您也可以参阅[区域性产品和服务](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)页面，详细了解 Amazon WorkSpaces 服务在不同区域的具体提供情况。"
    },
    {
        "query":"Amazon WorkSpaces 是否提供一组公共 API？",
        "intention":"知识问答",
        "reply":"是的，公共 API 可用于以编程方式创建和管理 Amazon WorkSpaces。您可以通过 [AWS CLI 和开发工具包](https://aws.amazon.com/tools/)获得 API；有关 API 的更多信息，请参阅此[文档](http://docs.aws.amazon.com/workspaces/latest/devguide/)。"
    },
    {
        "query":"Amazon WorkSpaces API 是否会在 AWS CloudTrail 中记录操作日志？",
        "intention":"知识问答",
        "reply":"是。通过 WorkSpaces API 对 Amazon WorkSpaces 执行的操作将包含在 CloudTrail 审核日志中。"
    },
    {
        "query":"Amazon WorkSpaces API 是否提供资源权限支持？",
        "intention":"知识问答",
        "reply":"是。您可以指定用户可以执行操作的 Amazon WorkSpaces 资源。有关详细信息，请参阅[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_iam.html)。"
    },
    {
        "query":"开始使用 Amazon WorkSpaces 时，是否需要使用 AWS 管理控制台？",
        "intention":"知识问答",
        "reply":"要开始使用 Amazon WorkSpaces，您需要使用 WorkSpaces 服务注册目录。您可以使用 AWS 管理控制台或 Amazon WorkSpaces API 在 WorkSpaces 服务中注册目录，然后再创建和管理 WorkSpaces。"
    },
    {
        "query":"能否在 AWS GovCloud（美国）区域部署我的 WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。您可以在 AWS GovCloud（美国）区域部署 WorkSpaces 以满足美国联邦、州和地方政府的要求。请[单击此处](https://aws.amazon.com/govcloud-us/)了解有关 AWS GovCloud（美国）区域的详细信息。"
    },
    {
        "query":"我是否能获得帮助以详细了解并注册 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"可以，Amazon WorkSpaces 专家可以回答问题并提供支持。[联系我们](https://aws.amazon.com/cn/contact-us/sales-support-workspaces/)，我们将在一个工作日内回复您，讨论 AWS 如何能为贵公司提供帮助。"
    },
    {
        "query":"Amazon Linux WorkSpaces 随附了哪些应用程序？",
        "intention":"知识问答",
        "reply":"要从自定义映像启动 Amazon WorkSpace，您首先需要将自定义映像与您希望 WorkSpace 使用的硬件类型进行配对，从而形成一个捆绑包。然后可以通过控制台发布此组合，当启动新的 WorkSpaces 时，选择该组合即可。"
    },
    {
        "query":"捆绑包和映像有什么不同？",
        "intention":"知识问答",
        "reply":"映像只包含操作系统、软件和设置。组合是映像和 WorkSpace 启动所依赖的硬件的集合。"
    },
    {
        "query":"可以创建多少自定义映像？",
        "intention":"知识问答",
        "reply":"作为管理员，您可以按需创建任意数量的自定义映像。Amazon WorkSpaces 会设置默认限制，但您可以单击[此处](https://console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase&limitType=service-code-workspaces)请求提高这些限制。要查看 Amazon WorkSpaces 的默认限制，请访问我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_limits.html)。"
    },
    {
        "query":"可不可以更新已有捆绑包中的映像？",
        "intention":"知识问答",
        "reply":"是的，您可以使用 WorkSpaces 控制台、API 或 CLI 将您的 WorkSpaces 映像复制到提供 WorkSpaces 的其他 AWS 区域。登录到 WorkSpaces 控制台，并从左侧的导航菜单导航到映像部分。只需选择要复制的映像，单击“操作”按钮，然后选择“复制映像”选项以开始。"
    },
    {
        "query":"如何判断我复制的映像是否可供我使用？",
        "intention":"知识问答",
        "reply":"一旦启动了复制操作，您将获得一个唯一的标识符，用于作为原始映像的副本而创建的新映像。您可以通过 WorkSpaces 控制台、API 或 CLI，使用该标识符在目的地区域查找该映像的状态。"
    },
    {
        "query":"我可以取消待处理的映像复制操作吗？",
        "intention":"知识问答",
        "reply":"一旦启动，您将无法取消待处理的映像复制操作。如果不需要目的地区域的映像，您可以将其删除。"
    },
    {
        "query":"复制映像是否会产生数据传输费？",
        "intention":"知识问答",
        "reply":"不会。在区域之间复制映像不会产生其他费用。仍将适用目的地 AWS 区域的帐户映像上限。一旦达到此限制，您将无法复制更多映像。"
    },
    {
        "query":"我可以将多个映像批量复制到其他区域吗？",
        "intention":"知识问答",
        "reply":"您可以将映像逐个复制到其他 AWS 区域。您可以使用 CopyWorkspaceImage API 以编程方式复制映像。"
    },
    {
        "query":"我可以将 BYOL 映像复制到其他 AWS 区域？",
        "intention":"知识问答",
        "reply":"是。如果目的地 AWS 区域已启用 BYOL，可以将 BYOL WorkSpace 映像复制到其他 AWS 区域。"
    },
    {
        "query":"我可以将映像复制到同一区域吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用复制映像操作在同一区域内复制 WorkSpaces 映像。"
    },
    {
        "query":"Amazon WorkSpaces 提供哪种类型的 Amazon Elastic Block Store（EBS）卷？",
        "intention":"知识问答",
        "reply":"在 2017 年 1 月 31 日之后启动的所有 Amazon WorkSpaces 均针对根和用户卷构建在通用型固态硬盘（SSD）EBS 卷上。在 2017 年 1 月 31 日之前启动的 Amazon WorkSpaces 均配置有 EBS 磁性卷。您可以使用磁性 EBS 卷通过重新构建 Amazon WorkSpaces 将其切换为 SSD EBS 卷（有关更多信息，请单击[此处](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_reset_workspace.html)）。您可以单击[此处](https://aws.amazon.com/ebs/details/)详细了解 SSD EBS 卷，单击[此处](https://aws.amazon.com/ebs/previous-generation/)详细了解磁性 EBS 卷。"
    },
    {
        "query":"即使自定义映像是使用搭载磁性 EBS 卷的 WorkSpaces 创建的，我也可以使用其启动搭载 SSD 卷的 WorkSpaces 吗？",
        "intention":"知识问答",
        "reply":"是。即使自定义映像是使用搭载磁性 EBS 卷的 WorkSpaces 创建的，您也可以使用其启动搭载 SSD 卷的 WorkSpaces。"
    },
    {
        "query":"如果我使用自己的 Windows 桌面许可 (BYOL)，是否需要使用搭载 SSD EBS 卷的 WorkSpaces 提供 AMI 构建版本？",
        "intention":"知识问答",
        "reply":"不需要。您可以使用自己在 BYOL 流程中构建的 AMI，而无需支付任何其他费用。"
    },
    {
        "query":"如何将应用程序部署给我的用户？",
        "intention":"知识问答",
        "reply":"对于如何将适当的应用程序集合部署给用户您享有充分的灵活性。首先，您要选择希望构建的映像类型，是基本型还是 Plus 型，这将决定 WorkSpaces 中的默应用程序。然后，您可以在 WorkSpace 上安装其他软件并创建自定义映像，以供用于启动更多 WorkSpace。有关更多详情，请参阅服务包[文档](http://docs.aws.amazon.com/console/workspaces/bundles)。"
    },
    {
        "query":"我可以在 Amazon WorkSpace 上安装哪些软件？",
        "intention":"知识问答",
        "reply":"对于 Amazon Linux，Amazon Linux 存储库中提供的所有应用程序均可兼容并能使用“yum install [软件包名称]”进行安装。\n对于Ubuntu WorkSpaces，您可以通过点击 Dock 中的“Ubuntu 软件”图标或在“活动”搜索栏中搜索“软件”来安装应用程序。\n对于 Windows，与 Windows Server 2016 或 Windows Server 2019 提供支持的 Windows 10 体验兼容的所有应用程序应该都能在您的 WorkSpaces 上运行。建议您在将软件交付更多用户使用之前，对您想部署在“测试” WorkSpace 上的任何软件进行测试。您有责任确保始终遵循与打算安装在 WorkSpace 上的任何软件相关的任何许可限制。"
    },
    {
        "query":"是否可以增加 Amazon WorkSpaces 存储卷的大小？",
        "intention":"知识问答",
        "reply":"是。您可以随时增加附加到 WorkSpace 的根卷和用户卷的大小。启动新的 WorkSpace 时，您可以为根卷和用户卷选择捆绑存储配置，或者选择比所提供的存储配置更大的首选存储空间。对于具有 80GB 根卷的存储配置，您可以为用户卷选择 10GB、50GB 或 100GB 存储配置。您可以使用 175GB 至 2000GB 根卷以及 100GB 至 2000GB 用户卷的存储配置。请注意，您需要将根卷设置为 175GB，以便将在 100GB 到1000GB 的范围内扩展根卷。启动 WorkSpace 后，只能使用上述配置将卷的大小增加到每个根卷和用户卷最大 2000GB。"
    },
    {
        "query":"是否可以减少存储卷的大小？",
        "intention":"知识问答",
        "reply":"不可以。为了确保您的数据得到保留，启动 WorkSpace 后两种卷的卷大小均不能减少。您可以启动 Value、Standard、Performance、Power 或 PowerPro WorkSpace 的最低根卷容量为 80GB、最低用户卷容量为 10GB。您可以启动 GPU 支持的 WorkSpace 的最低根卷容量为 100GB、最低用户卷容量为 100GB 。有关可配置存储的更多信息，请参阅[修改 WorkSpaces](http://docs.aws.amazon.com/workspaces/latest/adminguide/modify-workspaces.html)。\n除了根卷和用户卷的持久性存储之外，Graphics.g4dn 还提供 125GB 的临时本地存储，GraphicsPro.g4dn 提供 225GB 的临时本地存储。您无法更改临时本地存储的大小。您将在 WorkSpace 上找到名为“E:\\Temp\\_SSD”的临时本地存储卷。了解有关实例存储生命周期的更多信息，请参阅 [Amazon EC2 实例存储](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html)。"
    },
    {
        "query":"如何更改 Amazon WorkSpaces 存储卷的大小？",
        "intention":"知识问答",
        "reply":"您可以通过 Amazon WorkSpaces 管理控制台或通过 Amazon WorkSpaces API 更改存储卷的大小。\n如果 WorkSpaces 管理员启用了自助管理功能，WorkSpaces 用户还可以直接在 WorkSpaces 客户端中增加其存储卷的大小。"
    },
    {
        "query":"在重建 WorkSpace 时是否会保留其存储配置？",
        "intention":"知识问答",
        "reply":"是，在使用默认捆绑包时，每次重建都会保留 WorkSpaces 的存储分配大小。如果 WorkSpace 的卷已扩展并重建，即使捆绑包的驱动器大小较小，也会保留较大的卷大小。"
    },
    {
        "query":"在恢复 WorkSpace 时是否会保留其存储配置？",
        "intention":"知识问答",
        "reply":"是，在使用 WorkSpaces 默认捆绑包时，每次恢复都会保留现有的存储分配大小。例如，如果恢复根卷容量为 80GB、用户卷容量为 100GB 的 WorkSpace，那么重建的 WorkSpace 将具有容量为 80GB 的根卷和容量为 100GB 的用户卷。\n如果自定义捆绑包的存储分配大小增加，并且恢复的是关联 WorkSpace，那么 WorkSpace 卷容量将会增加，以匹配该捆绑包的新卷大小。"
    },
    {
        "query":"我在 WorkSpaces 迁移后可保留哪些数据？",
        "intention":"知识问答",
        "reply":"原始用户卷最新快照中的所有数据均将保留。对于 Windows WorkSpace，最新快照所捕获的 D 盘数据将在迁移后保留，C 盘将从目标捆绑包映像新建。此外，迁移尝试将数据从旧用户资料移动到新用户资料中。无法移动到新用户资料中的数据将保留在 .notMigrated 文件夹中。有关更多信息，请参阅相关[文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/migrate-workspaces.html)。"
    },
    {
        "query":"我能否将现有 WorkSpace 从公共捆绑包移动到自定义捆绑包中？",
        "intention":"知识问答",
        "reply":"是。借助 WorkSpaces 迁移功能，您可以将您的 WorkSpace 根卷替换为另一个捆绑包中的基本映像。迁移将使用来自目标捆绑包映像的新根卷和来自最新原始用户卷快照的用户卷重新创建工作区。有关迁移的详细信息，请参阅[文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/migrate-workspaces.html)。"
    },
    {
        "query":"迁移与重新构建的区别是什么？",
        "intention":"知识问答",
        "reply":"WorkSpaces 迁移使您能够切换到新捆绑包并重新生成您的用户资料。重新构建只是使用原始捆绑包的基本映像所生成的根卷刷新您的 WorkSpace。"
    },
    {
        "query":"如何我在迁移后重新构建 WorkSpace 将会发生什么？",
        "intention":"知识问答",
        "reply":"迁移将您的 WorkSpace 与新的捆绑包关联。而且迁移后的重新构建将使用新关联的捆绑包生成根卷。"
    },
    {
        "query":"是否可以扩展 Amazon WorkSpaces 的磁性存储卷？",
        "intention":"知识问答",
        "reply":"不可以，可配置的存储卷仅在使用固态硬盘 (SSD) 时可用。在 2017 年 2 月前发布的 WorkSpaces 可能仍然使用磁性存储卷。要从磁盘切换为 SSD，则需重建 WorkSpaces。"
    },
    {
        "query":"自定义映像如何影响根卷大小？",
        "intention":"知识问答",
        "reply":"默认情况下，从自定义映像启动的 WorkSpaces 的根卷大小与自定义映像的大小相同。例如，如果自定义映像的根卷大小为 100GB，则从该映像启动的所有 WorkSpaces 的根卷大小也为 100GB。在启动 WorkSpace 时或之后的任何时间，您都可以增加根卷大小。"
    },
    {
        "query":"是否可以在不执行 WorkSpaces 迁移的情况下更改 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"是。您可以使用 Amazon WorkSpaces 管理控制台或 WorkSpaces API 在 Value、Standard、Performance、Power 或 PowerPro 捆绑包之间切换。您切换硬件捆绑包时，WorkSpaces 将立即重启。当 WorkSpaces 重启后，将保留操作系统、应用程序、数据以及根卷和用户卷上分配的存储。\n例如，您可以启动 Standard 捆绑包（2 个 vCPU，4GiB），然后将两个卷上的卷大小扩展到 500GB。然后，您可以切换到 Performance 服务包（2 个 vCPU，7.5GiB），同时在扩展卷中保留操作系统、应用程序和数据。\n如果 WorkSpaces 管理员启用了自助服务管理功能，用户还可以直接在 WorkSpaces 客户端中更改其 WorkSpaces 捆绑包。"
    },
    {
        "query":"如何跟踪存储和捆绑包切换请求？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CloudTrail 来跟踪您所请求的更改。"
    },
    {
        "query":"目前，我自带 Windows 许可证。是否可以扩展存储卷并切换 WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"是。即使您自带 Windows 桌面许可证，也可以利用这两个功能。默认情况下，一周内您最多能为占总数 20% 的 WorkSpaces 切换 WorkSpaces 服务包。如要切换 20% 以上的 WorkSpaces，请[联系我们](https://aws.amazon.com/cn/contact-us/sales-support-workspaces/)。"
    },
    {
        "query":"在 AutoStop 模式下运行的 WorkSpace 是否需要运行才能将更改应用于捆绑包类型？",
        "intention":"知识问答",
        "reply":"不需要。当您做出更改时，我们启动未运行的 WorkSpace，应用捆绑包更改，然后进行重启，以便更改生效，最后再将它停止。例如，您将一个已停止的 Standard (2 个 vCPU，4GiB) WorkSpace 上的捆绑包类型更改为 Performance。我们会启动您的 Standard WorkSpace，应用服务包更改，然后重启。重启后，您的 WorkSpace 将应用 Performance 硬件 (2 个 vCPU，7.5GiB)。"
    },
    {
        "query":"多长时间可以增加一次 WorkSpace 的卷大小或变更一次 WorkSpace 硬件捆绑包？",
        "intention":"知识问答",
        "reply":"您可以在 6 小时内增加一次 WorkSpace 的卷大小或调高一次 WorkSpace 的硬件捆绑包。你还可以在 30 天内调低一次硬件捆绑包。对于新启动的 WorkSpace，您必须等待 6 个小时之后才能请求更大的服务包。\n例如，如果您在 12 月 5 日 11:00 增加 Standard WorkSpace 的根卷和用户卷大小，同时将其更改为 Performance WorkSpace，则可以在 12 月 5 日 16:00 再次增加根卷和用户卷大小并更改硬件服务包。如果您在 12 月 6 日 12:00 将 Performance WorkSpace 更改为 Standard WorkSpace，然后又想继续更改为更小的捆绑包 (Value)，则可以在 1 月 6 日 12:00 执行此更改。"
    },
    {
        "query":"Amazon WorkSpaces 是否提供支持 GPU 的云桌面？",
        "intention":"知识问答",
        "reply":"是。Amazon WorkSpaces 提供 Graphics、GraphicsPro 和 Graphics G4dn 系列。  \n Graphics 捆绑包用于通用型图形应用（如 CAD/CAM 软件、商业和工业建模、原型设计以及主流图形开发）。\nGraphicsPro 捆绑包还可用于性能密集型图形和计算应用（如 3D 可视化、图形渲染、视频编码、机器学习（ML）和高端游戏）。Graphics 和 GraphicsPro 捆绑包提供英语和日语版本。\nGraphics G4dn 系列包括两个捆绑包选项 - Graphics.g4dn 和 GraphicsPro.g4dn。两者都基于 EC2 G4dn 实例——业界最通用的 GPU 实例，用于依赖 OptiX 等 NVIDIA GPU 库的图形应用程序。对于工程、设计和架构应用等主流图形密集型应用，Graphics.g4dn 捆绑包是云中性价比最高的。GraphicsPro.g4dn 捆绑包适用于高端图形应用，如媒体制作、地震可视化和小型 ML 模型训练以及 ML 推理。[请参阅 EC2 G4dn 实例](https://aws.amazon.com/cn/ec2/instance-types/g4/)了解有关 G4dn 实例和 NVIDIA T4 GPU 的更多详细信息。"
    },
    {
        "query":"Amazon WorkSpaces 提供的支持 GPU 的捆绑包是什么？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 提供的支持 GPU 的捆绑包是针对受益于图形加速的工作负载进行优化的云桌面。您可以选择 Graphics、GraphicsPro、Graphics.g4dn 或 GraphicsPro.g4dn 捆绑包，具体取决于您的图形工作负载的性能要求和您的成本要求。\nGraphics 捆绑包非常适用于通用型图形工作负载，如用于提高办公效率的虚拟桌面和现代 Web 应用程序。每个 Graphics 捆绑包都随附一个具有 1536 个 CUDA 核心与 4GB 视频内存的 NVIDIA GPU。每个 Graphics 捆绑包都在用户卷上包含 8 个 vCPU、15GiB 的 RAM、4GB 的视频内存和 100GB 的存储空间，并且在根卷上包含 100GB 的通用型持久性存储。Graphics 捆绑包提供 Windows 10 桌面体验。\nGraphicsPro 捆绑包适用于电脑辅助设计、制造和工程软件等专业图形应用程序。GraphicsPro 捆绑包随附一个专用的虚拟工作站 GPU、NVIDIA M60，具有 2048 个并行处理内核，以及一个能够支持多达 10 个 H.265（HEVC）1080p30 流和多达 18 个 H.264 1080p30 流的硬件编码器。每个 GraphicsPro 捆绑包都包含 16 个 vCPU、122GiB 的 RAM、8GB 的视频内存，以及至少 100GB 的根卷和 100GB 的用户卷。GraphicsPro 捆绑包提供 Windows 10 虚拟工作站体验。\nGraphics G4dn 系列包括两个捆绑包选项 - Graphics.g4dn 和 GraphicsPro.g4dn。Graphics.g4dn 和 GraphicsPro.g4dn 都包含支持 RTX 的 NVIDIA T4 Tensor Core GPU（特有多精度 Turing Tensor Core 和 RT Core）、AWS 定制第二代英特尔® 至强® 可扩展（Cascade Lake）处理器，最高达 100 Gbps 的网络吞吐量，以及专为需要快速访问本地存储数据的应用程序而设计的本地 NVMe 存储。基于 g4dn 的捆绑包针对流媒体图形密集型应用程序进行了优化，该应用程序通过 NVIDIA OptiX 和 AI 增强可视化（如 AI 降噪和深度学习超级采样（DLSS））支持加速射线跟踪。这些捆绑包还可用于计算工作负载，如使用 CUDA 和 NVIDIA 的 GPU 加速深度学习框架等 NVIDIA 库的数据科学和机器学习。\nGraphics.g4dn 捆绑包适合寻求经济高效的支持 GPU 的 NVIDIA RTX 虚拟工作站的客户，供他们运行主流图形密集型应用程序，如电脑辅助设计（CAD）、模拟和地理空间信息系统（GIS）应用程序。Graphics.g4dn 捆绑包提供 g4dn.xlarge 实例，具有 4vCPU、16GB RAM、16GB 视频内存、125GB 临时 NVMe SSD 本地[实例存储](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html)，以及用于用户卷和根卷的最少 100GB 的持久性存储。Graphics.g4dn 捆绑包提供 Windows 10 虚拟工作站体验。\nGraphicsPro.g4dn 捆绑包专为高端图形工作负载而设计，例如媒体制作、渲染、数据科学、建筑和地震可视化应用程序。此外，它们还非常适合计算工作负载，包括智能视频分析（IVA）、小规模 ML 模型训练和 ML 推理。graphicsPro.g4dn 捆绑包提供有 16vCPU、64GB RAM、16GB 视频内存、225GB 临时 NVMe SSD 本地[实例存储，](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html)以及用于用户卷和根卷的最少 100GB 的持久性存储。GraphicsPro.g4dn 捆绑包提供 Windows 10 虚拟工作站体验。请参阅 EC2 G4dn 实例了解有关 G4dn 实例和 NVIDIA T4 GPU 的更多详细信息。"
    },
    {
        "query":"我可以在哪些 AWS 区域启动支持 GPU 的 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"您可以在以下 AWS 区域启动 Graphics 或 GraphicsPro 捆绑包：美国东部（弗吉尼亚北部）、美国西部（俄勒冈）、欧洲（爱尔兰）、欧洲（法兰克福）、亚太地区（悉尼）、亚太地区（东京）和亚太地区（新加坡）。您还可以在 AWS GovCloud（美国西部）区域中启动 GraphicsPro 捆绑包。\n您可以在以下 AWS 区域中启动 Graphics.g4dn 或 GraphicsPro.g4dn 捆绑包：美国东部（弗吉尼亚北部）、美国西部（俄勒冈）、加拿大（中部）、欧洲（法兰克福、爱尔兰、伦敦）、亚太地区（孟买、首尔、新加坡、悉尼和东京）以及南美洲（圣保罗）。"
    },
    {
        "query":"我可以为支持 GPU 的捆绑包创建自定义映像吗？",
        "intention":"知识问答",
        "reply":"是。从支持 GPU 的 Amazon WorkSpaces 捆绑包创建的自定义映像只能与相同类型的捆绑包结合使用。例如，您可以使用从 Graphics.g4dn 捆绑包创建的映像来启动 GraphicsPro.g4dn WorkSpace。但是，您无法使用从 Graphics 捆绑包创建的映像来启动 GraphicsPro WorkSpace 或基于 G4dn 的 WorkSpace。"
    },
    {
        "query":"如何开始使用支持 GPU 的 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon WorkSpaces 管理控制台或 Amazon WorkSpaces API 来启动 Graphics、GraphicsPro、Graphics.g4dn 或 GraphicsPro.g4dn 捆绑包。在启动新的 WorkSpace 时，直接选择相应的 Graphics 捆绑包即可。  您需要在启动支持 GPU 的捆绑包之前请求[提高配额](https://docs.aws.amazon.com/workspaces/latest/adminguide/workspaces-limits.html)。"
    },
    {
        "query":"支持 GPU 的 Amazon WorkSpaces 占用多少带宽？",
        "intention":"知识问答",
        "reply":"支持 GPU 的 Amazon WorkSpaces 捆绑包所使用的带宽取决于所执行的任务。如果屏幕上的变化不多，则所使用的带宽通常小于 300kbps。如果要在多个窗口之间切换环境，或者如果要对 3D 模型进行操作，所使用的带宽可能会达到 Mbps 级别。"
    },
    {
        "query":"Amazon WorkSpaces 是否提供使用 WSP 且启用了 GPU 的桌面？",
        "intention":"知识问答",
        "reply":"否。Amazon WorkSpaces 目前不提供启用了 GPU 的 WSP 捆绑包。"
    },
    {
        "query":"支持 GPU 的 WorkSpace 上提供哪些存储选项？",
        "intention":"知识问答",
        "reply":"支持 GPU 的所有 WorkSpaces 捆绑包都至少包含 100GB 用于用户卷和根卷的持久性存储。您可以在启动新的 WorkSpaces 时选择根卷和用户卷所需的存储量，并且可以随时增加存储分配。用户存储在附加到 WorkSpace 的“用户卷”中的数据将定期自动备份至 Amazon S3。\nGraphics G4dn 捆绑包还包含基于 NVMe 的本地 SSD 存储，称为[实例存储。](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html) 实例存储非常适合用于缓存和缓冲区等临时内容，因为在实例停止、终止或硬件出现故障时，实例存储卷中存储的数据不会持续存在。Graphics.g4dn 提供 125GB 的本地实例存储，GraphicsPro.g4dn 提供 225GB 的本地实例存储。您无法更改本地实例存储的大小。您将在 WorkSpace 上找到名为“E:\\Temp\\_SSD”的本地实例存储卷。了解有关实例存储生命周期的更多信息。 了解有关实例存储生命周期的更多信息，请参阅 [Amazon EC2 实例存储。](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html)"
    },
    {
        "query":"我是否可以将自有 Windows 桌面许可用于 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是，您可以将满足 Microsoft 许可要求的自有 Windows 10 或 Windows 11 桌面许可用于 WorkSpaces。借助 WorkSpaces，您可以在物理专用硬件上运行 Windows 10 桌面映像，这使得您在将自有许可用于 WorkSpaces 时能够维持 Windows 桌面的许可合规性。"
    },
    {
        "query":"可以将自有 Windows 桌面许可与支持 GPU 的 Amazon WorkSpaces 结合使用吗？",
        "intention":"知识问答",
        "reply":"是，您可以。如果您想这么做，请[联系我们](https://aws.amazon.com/cn/contact-us/sales-support-workspaces/)。"
    },
    {
        "query":"哪些 Windows 桌面许可版本可用于 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"如果您所在组织满足 Microsoft 制定的许可要求，那么您可以将自有 Windows 10 或 Windows 11 企业版许可用于 Amazon WorkSpaces。您不能将 Windows OEM 许可用于 Amazon WorkSpaces。如果您不确定是否具备使用自有 Windows 桌面许可的资格，请咨询 Microsoft。"
    },
    {
        "query":"将自有 Windows 桌面许可用于 Amazon WorkSpaces 有哪些好处？",
        "intention":"知识问答",
        "reply":"通过将自有 Windows 桌面许可用于 Amazon WorkSpaces，您的每个 Amazon WorkSpace 每月可节省 4 USD（按月计费）；如果您使用的是按小时计费方式，则每小时的使用费也会降低（有关更多信息，请参阅 Amazon WorkSpaces [定价页面](https://aws.amazon.com/workspaces/pricing/)）。此外，您现在还可以使用单个黄金映像来管理您的物理和虚拟桌面部署。"
    },
    {
        "query":"要将自有 Windows 桌面许可用于 Amazon WorkSpaces，需满足哪些要求？",
        "intention":"知识问答",
        "reply":"要将您的 Windows 10 或 Windows 11 桌面许可用于 Amazon WorkSpaces，您需要具有有效且合格的 Microsoft 批量许可 (VL) 协议以及软件保障合同和/或每个用户许可的 VDA。请咨询您的 Microsoft 代表，以确认您是否有资格将自有 Windows 桌面许可用于 Amazon WorkSpaces。"
    },
    {
        "query":"如要将我的自有 Windows 桌面许可用于 Amazon WorkSpaces，应如何开始操作？",
        "intention":"知识问答",
        "reply":"为了确保您的账户分配有足够的专用容量，请联系您的AWS 客户经理或销售代表为账户启用 BYOL。或者，您可以使用 Amazon WorkSpaces 创建一个技术支持案例，以开始使用 BYOL。\n为账户启用 BYOL 之后，您即可轻松将现有的 Windows 10 或 Windows 11 桌面操作系统用于 Amazon WorkSpaces。首先，使用 VM Import API 导入现有的 Windows 桌面操作系统。然后，使用 WorkSpaces 管理控制台中“Images”页面上的“Create Image”操作，基于导入的 VM 创建新的 WorkSpaces 映像。最后，使用 WorkSpaces 管理控制台中的“Bundles”选项卡创建一个自定义 WorkSpaces 服务包。然后，您可以通过 WorkSpaces 管理控制台为您的用户启动新创建的自定义 WorkSpaces 服务包作为新的 WorkSpaces。\n您可以在[我们的文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/byol-windows-images.html)中查看有关 BYOL 过程的更多信息。"
    },
    {
        "query":"如何在 Amazon WorkSpaces 上激活我的 Windows 10 或 Windows 11 桌面操作系统？",
        "intention":"知识问答",
        "reply":"要激活您的 Windows 10 或 Windows 11 桌面操作系统，您可以使用您的 VPC 中托管的现有 Microsoft 激活服务器，或者使用可从已经启动 Amazon WorkSpaces 的 VPC 中访问的现有 Microsoft 激活服务器。"
    },
    {
        "query":"我能否为上传至 Amazon WorkSpaces 的 Windows 10 或 Windows 11 桌面映像创建一个全新的自定义映像？",
        "intention":"知识问答",
        "reply":"可以。您可以使用标准 WorkSpaces 映像管理功能来进一步自定义 Windows 10 或 Windows 11 桌面映像，并在您的账户中将其保存为新的 Amazon Workspaces 映像。"
    },
    {
        "query":"我能否使用某个预先配置的公有捆绑包在同一目录下通过已引入 WorkSpaces 的自定义 Windows 捆绑包启动新的 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"不可以。为 Windows 10 或 Windows 11 桌面提供 BYOL 支持的自定义 WorkSpaces 是在物理专用硬件上启动的，以满足 Microsoft 的许可合规性要求。如要在标记为专用硬件的目录中启动 WorkSpaces，只能使用您创建的、包含 Windows 10 桌面映像的自定义捆绑包。\n如果您希望从公有捆绑包为同一域中的用户启动 WorkSpaces，则可以创建一个新的 AWS AD Connector 目录，并使之与 Windows 10 桌面 WorkSpaces 指向同一个 Microsoft Active Directory，然后通过 AWS 管理控制台或 WorkSpaces 开发工具包和 CLI 按常规方式从该目录中启动 WorkSpaces。"
    },
    {
        "query":"大概需要多长时间，我才能使用自有 Windows 桌面许可和映像启动 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"在执行“Create Image”操作之后，您可能需要几个小时才能使用自定义 Windows 桌面映像。您可以在 WorkSpaces 控制台、API 或 CLI 中查看自定义映像的状态。"
    },
    {
        "query":"能否在单个可用区启动我所有的专用 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"不能。在专用硬件上启动的 Amazon WorkSpaces 需要在两个可用区之间取得平衡。在创建要从中启动 Amazon WorkSpaces 的目录时，您需要为 Amazon WorkSpaces 选择若干个可用区，而后续启动的 Amazon WorkSpaces 会在您创建目录时所选的可用区之间实现自动负载均衡。"
    },
    {
        "query":"如果我终止在专用物理硬件上启动的 Amazon WorkSpaces，将会发生什么？",
        "intention":"知识问答",
        "reply":"当您不需要使用 Amazon WorkSpaces 时，您可将其终止。您只需为正在运行的 Amazon WorkSpaces 付费。"
    },
    {
        "query":"在专用物理硬件上重新构建、恢复或重新启动 Amazon WorkSpaces 会发生什么情况？",
        "intention":"知识问答",
        "reply":"重新构建、恢复或重新启动的 Amazon WorkSpaces 可能运行在为您的账户分配的任何可用的物理服务器上。重新启动、恢复或重新构建 Amazon WorkSpace，会导致该实例运行在为您的账户分配的其他物理服务器上。"
    },
    {
        "query":"如何为 BYOL WorkSpaces 订阅 Microsoft Office？",
        "intention":"知识问答",
        "reply":"导入 BYOL 映像时，可以选择是否要在映像中包含 Microsoft Office。如果选择包含，则会在映像创建过程中将 Office 自动安装在映像中。从该映像创建的 WorkSpaces 会从 AWS 自动订阅 Microsoft Office Professional。"
    },
    {
        "query":"哪个软件可作为 BYOL WorkSpaces 的 Office 捆绑包的一部分使用？",
        "intention":"知识问答",
        "reply":"对于 Windows 10 BYOL WorkSpaces，您可以选择Microsoft Office Professional 2016 或 2019。Windows 11 BYOL WorkSpaces 仅支持 Microsoft Office Professional 2019。"
    },
    {
        "query":"如何在我现有的 BYOL WorkSpaces 上订阅 Office 捆绑包？",
        "intention":"知识问答",
        "reply":"创建安装了 Office 捆绑包的 BYOL 映像后，可以使用 Amazon WorkSpaces 迁移功能将现有的 BYOL WorkSpaces 迁移到带有 Office 捆绑包的 WorkSpaces。迁移后，将保留原始用户卷的最新快照中的所有数据，并且将从新映像重新创建 C 驱动器。您可以将从某个服务包（没有 AWS 提供的 Office）创建的 WorkSpace 迁移到从某个服务包（具有 AWS 提供的 Microsoft Office）创建的另一个 WorkSpace，反之亦然。迁移时，根卷和用户卷上的数据都会保留。"
    },
    {
        "query":"如何获取 Office 捆绑包应用程序的更新？",
        "intention":"知识问答",
        "reply":"Office 更新是常规 Windows 更新的一部分。我们的映像创建过程将在创建过程中获取最新更新。我们建议您定期更新 Windows 基本映像，以及时获取所有最新的安全补丁和更新。"
    },
    {
        "query":"什么是 Amazon Linux WorkSpaces？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 是企业级云桌面，可让组织提供给开发人员、工程师、学生或办公人员，以便他们完成工作。"
    },
    {
        "query":"Amazon Linux WorkSpaces 有什么用处？",
        "intention":"知识问答",
        "reply":"开发人员可以使用他们最喜欢的应用程序（例如，AWS CLI、AWS SDK 工具、Visual Studio Code、Eclipse 和 Atom）开发软件。分析人员可以使用 MATLAB 和 Simulink 运行模拟。办公人员可以使用预先安装的应用程序，例如：使用 Libre Office 编辑文档、电子表格和演示文档；使用 Evolution 收发电子邮件；使用 Firefox 浏览网页；使用 GIMP 编辑图片；使用 Pidgin 进行即时通讯；以及更多。您随时可以从 Amazon Linux 存储库或其他基于 RPM 的 Linux 存储库安装更多应用程序。"
    },
    {
        "query":"Amazon Linux WorkSpaces 随附了哪些应用程序和工具？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 随附了一系列桌面实用程序和工具、开发工具以及通用型生产力应用程序。开发人员可以快速开始使用 OpenJDK 8、Python、C/C++、AWS CLI 和 AWS SDK 等软件包。普通办公人员可以使用 Libre Office 编辑文档、电子表格和演示文稿，使用 Firefox 浏览网页，使用 GIMP 编辑照片，使用 Pidgin 进行即时通讯，使用 Atril 查看 PDF 文档以及更多来完成日常生产力任务。您随时可以从 Amazon Linux 存储库或其他基于 RPM 的 Linux 存储库安装更多应用程序。"
    },
    {
        "query":"如何开始使用 Amazon Linux WorkSpaces？",
        "intention":"知识问答",
        "reply":"要开始使用，只需从配置的目录中创建或选择用户，然后选择 Amazon Linux WorkSpaces 捆绑包并启动即可。您的用户将通过电子邮件收到用于连接到其 WorkSpace 的指令。有关可用硬件服务包的列表，请参阅[此处](https://aws.amazon.com/workspaces/details/)。"
    },
    {
        "query":"Amazon Linux 支持哪种软件包管理器？",
        "intention":"知识问答",
        "reply":"Amazon Linux 基于 RPM，使用的是 yum 软件包管理器。"
    },
    {
        "query":"Amazon Linux WorkSpaces 随附了哪些存储库？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 已连接到 Amazon Linux 核心和附加存储库。您随时可以添加其他基于 RPM 的 Linux 存储库。"
    },
    {
        "query":"如何请求 Amazon Linux 存储库的新软件包？",
        "intention":"知识问答",
        "reply":"您可以使用[此处](https://forums.aws.amazon.com/forum.jspa?forumID=164)的 AWS 开发人员论坛请求 Amazon Linux 存储库的新软件包。能否添加软件包由 Amazon Web Services 全权决定。"
    },
    {
        "query":"如何接收 Amazon Linux WorkSpaces 的软件包更新？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 会定期地从 Amazon Linux 存储库进行补丁安装和更新。"
    },
    {
        "query":"Amazon Linux WorkSpaces 支持哪些目录类型？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 当前支持 Active Directory，一种在 AWS 上通过 AD Connector 和 Microsoft Active Directory 提供的本地目录。"
    },
    {
        "query":"Amazon Linux WorkSpaces 随附了哪些硬件捆绑包？",
        "intention":"知识问答",
        "reply":"Amazon Linux WorkSpaces 可以在 Amazon WorkSpaces 服务运行的所有区域中提供不同的硬件捆绑包。有关完整列表，请参阅[此处](https://aws.amazon.com/workspaces/pricing/)。"
    },
    {
        "query":"我是否可以自定义 Amazon Linux WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。您可以在 Amazon Linux WorkSpaces 上自定义设置和安装其他软件。您还可以使用 Amazon WorkSpaces 控制台或 API 创建自定义映像，并使用这些映像通过自定义设置为组织中的其他用户启动 WorkSpaces。"
    },
    {
        "query":"Amazon Linux WorkSpaces 上是否会默认启用 sudo 访问权限？",
        "intention":"知识问答",
        "reply":"默认情况下，Amazon Linux WorkSpaces 用户会获得 sudo 访问权限，但根用户无法获得。您随时可以通过编辑 /etc/sudoers 文件修改权限。"
    },
    {
        "query":"是否有 Amazon Linux WorkSpaces 捆绑包使用 WSP？",
        "intention":"知识问答",
        "reply":"是。Amazon WorkSpaces 在 AWS GovCloud（美国西部）区域提供装有 WSP 的 Linux，并支持智能卡、键盘和鼠标输入以及音频输出。"
    },
    {
        "query":"Amazon WorkSpaces 是否符合 HIPAA 的要求？",
        "intention":"知识问答",
        "reply":"是。如果您与 AWS 签订了有效的《商业合伙协议》，则可以结合使用 Amazon WorkSpaces 和与您的 BAA 相关联的 AWS 账户。如果您未与 AWS 签订有效的 BAA，请[联系我们](https://aws.amazon.com/contact-us/sales-support-workspaces/)，我们会让 AWS 销售团队代表与您联系。有关更多信息，请参阅 [HIPAA 合规性](https://aws.amazon.com/compliance/hipaa-compliance/)。"
    },
    {
        "query":"Amazon WorkSpaces 是否符合 PCI 的要求？",
        "intention":"知识问答",
        "reply":"是。Amazon WorkSpaces 符合 PCI 和支付卡行业数据安全标准 (PCI DSS)。PCI DSS 是由 PCI 安全标准委员会管理的专有信息安全标准，该委员会由 American Express、Discover Financial Services、JCB International、MasterCard Worldwide 和 Visa Inc 创建。PCI DSS 适用于存储、处理或传输持卡者数据 (CHD) 和/或敏感性身份验证数据 (SAD) 的所有实体，包括商家、处理机构、购买方、发行机构和服务提供商。PCI DSS 由多家支付卡品牌联合制定，由支付卡行业安全标准委员会管理。有关更多信息，请参阅 [PCI DSS 合规性](https://aws.amazon.com/compliance/pci-dss-level-1-faqs/)。"
    },
    {
        "query":"要登录 Amazon WorkSpaces，用户需要使用哪些凭证？",
        "intention":"知识问答",
        "reply":"用户使用独有的凭证登录自己的 WorkSpace，他们可以在 WorkSpace 预置后创建这些凭证。如果您已将 Amazon WorkSpaces 服务与现有的 Active Directory 域集成，用户将可以使用他们的常规 Active Directory 凭证进行登录。Amazon WorkSpaces 还可与您现有的 RADIUS 服务器集成，以启用多重身份验证（MFA）。 此外，WorkSpaces 与您的 SAML 2.0 身份提供者（IdP） 集成，以便您可以将 IdP 提供的安全功能扩展到 WorkSpaces，包括多重（MFA）和上下文访问。"
    },
    {
        "query":"我能否控制可访问我的 Amazon WorkSpaces 的客户端设备？",
        "intention":"知识问答",
        "reply":"是。您可以根据客户端操作系统类型，也可以使用数字证书限制对 Amazon WorkSpaces 的访问。您可以选择阻止或允许 macOS、Microsoft Windows、Linux、iPadOS、Android、Chrome OS、零客户端和 WorkSpaces Web Access 客户端的访问。"
    },
    {
        "query":"什么是数字证书？",
        "intention":"知识问答",
        "reply":"数字证书是一种在指定时间段内有效的数字形式的身份，用作可提供关于某个实体的身份信息及其他支持信息的凭证。数字证书由证书颁发机构 (CA) 签发，并且 CA 保证证书中信息的有效性。"
    },
    {
        "query":"哪些设备使用数字证书控制对 Amazon WorkSpaces 的访问？",
        "intention":"知识问答",
        "reply":"可以使用数字证书阻止或允许从 macOS 或 Microsoft Windows 客户端设备对 WorkSpaces 的访问。"
    },
    {
        "query":"如何使用数字证书控制对 Amazon WorkSpaces 的访问？",
        "intention":"知识问答",
        "reply":"要使用数字证书阻止或允许对 Amazon WorkSpaces 的访问，请将根证书上传到 WorkSpaces 管理控制台，并将客户端证书分发给您想信任的 macOS、Windows、Android 和[与 Android 兼容的 Chrome OS 设备](https://www.chromium.org/chromium-os/chrome-os-systems-supporting-android-apps)。要分发客户端证书，请使用 Microsoft System Center Configuration Manager (SCCM) 或 Mobile-Device Management (MDM) 软件等您的首选解决方案。有关更多信息，请参阅[仅限受信任的设备访问 WorkSpaces](http://docs.aws.amazon.com/workspaces/latest/adminguide/trusted-devices.html)。"
    },
    {
        "query":"可以将多少个根证书导入 Amazon WorkSpaces 目录？",
        "intention":"知识问答",
        "reply":"对于每个 Amazon WorkSpaces 目录，您可以导入最多两个根证书，分别用于 macOS 和 Microsoft Windows 设备。如果导入了两个根证书，则 WorkSpaces 会将两个根证书都呈现给客户端设备，而客户端设备将使用与任一根证书关联的第一个证书。"
    },
    {
        "query":"如果不使用数字证书，是否可以控制客户端设备对 Amazon WorkSpaces 的访问？",
        "intention":"知识问答",
        "reply":"是。您可以只使用设备类型控制对 Amazon WorkSpaces 的访问。"
    },
    {
        "query":"能否使用数字证书控制从 iPadOS 或零客户端对 Amazon WorkSpaces 的访问？",
        "intention":"知识问答",
        "reply":"目前，Amazon WorkSpaces 仅可将数字证书与 macOS 和 Microsoft Windows、Android 和与 Android 兼容的 Chrome OS 设备结合使用。"
    },
    {
        "query":"什么是 Multi-Factor Authentication (MFA)？",
        "intention":"知识问答",
        "reply":"Multi-Factor Authentication 可为身份验证流程提供多一层的安全防护。用户必须提供他们已知的信息 (例如，密码) 和已有信息 (如硬件或软件生成的一次性密码 [OTP]) 来证明其身份。"
    },
    {
        "query":"MFA 支持哪些交付方法？",
        "intention":"知识问答",
        "reply":"Amazon 支持通过硬件和软件令牌交付的一次性密码。目前尚不支持带外商标，如 SMS 。"
    },
    {
        "query":"是否支持 Google Authenticator 和其他虚拟 MFA 解决方案？",
        "intention":"知识问答",
        "reply":"Google Authenticator 可与 RADIUS 结合使用。如果您运行的是基于 Linux 的 RADIUS 服务器，那么可将 RADIUS 服务器群配置成通过可插入验证模块 (PAM) 库使用 Google Authenticator。"
    },
    {
        "query":"哪些 Amazon WorkSpaces 客户端应用程序支持 Multi-Factor Authentication (MFA)？",
        "intention":"知识问答",
        "reply":"以下平台上的 Amazon WorkSpaces 客户端应用程序支持 MFA：Windows、Mac、Linux、Chromebook、iOS、Fire、Android 和 PCoIP 零客户端。使用 Web Access 访问 Amazon WorkSpaces 时，还支持 MFA。"
    },
    {
        "query":"如果用户忘记访问 Amazon WorkSpace 的密码，会怎么样？",
        "intention":"知识问答",
        "reply":"如果您使用 AD Connector 或 AWS Microsoft AD 与现有的 Active Directory 域集成，用户则需要针对您的域按照现有找回丢失密码流程操作，如联系内部帮助台。如果用户使用 WorkSpaces 服务所管理的目录中存储的凭证，他们可以通过单击 Amazon WorkSpaces 客户端应用程序中的“忘记密码”链接重置密码。"
    },
    {
        "query":"如何保护 Amazon WorkSpaces 免受恶意软件和病毒的危害？",
        "intention":"知识问答",
        "reply":"您可以在用户的 WorkSpaces 上安装您选择的杀毒软件。用户可以通过 Plus 捆绑包选项访问杀毒软件，您可以从[此处](https://aws.amazon.com/workspaces/details/#workspaces-bundles)了解更多详细信息。如果您选择安装自己的杀毒软件，请确保它不会封锁用于 PCoIP 的 UDP 端口 4172 以及用于 WSP 的 UDP 端口 4195，因为这样会阻止用户连接到 WorkSpaces。"
    },
    {
        "query":"如何取消用户对 Amazon WorkSpace 的访问权限？",
        "intention":"知识问答",
        "reply":"如需取消用户对 WorkSpace 的访问权限，您可以从 WorkSpaces 服务管理的目录或与 WorkSpaces 服务集成的现有 Active Directory 中禁用他们的账户。"
    },
    {
        "query":"WorkSpaces 能否与 AWS Identity and Access Management (IAM) 配合使用？",
        "intention":"知识问答",
        "reply":"是。请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/create_iam_user.html)。"
    },
    {
        "query":"是否可以选择组织部门 (OU)，其中对 WorkSpaces 负责的计算机账户在我的 Active Directory 中创建？",
        "intention":"知识问答",
        "reply":"是。您可以设置默认的组织部门 (OU)，即在 Active Directory 中创建 WorkSpaces 的计算机账户。这个 OU 可以是包含您的用户的域的一部分，也可以是与包含您的用户的域有信任关系的域的一部分，还可以是目录中子域的一部分。有关更多详情，请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/create_iam_user.html)。"
    },
    {
        "query":"是否可以使用 Amazon VPC 安全组来限制对我的网络中或出自互联网中我的 WorkSpaces 的资源（应用程序、数据库）的访问？",
        "intention":"知识问答",
        "reply":"是。可以使用 Amazon VPC 安全组来限制对您的网络中或出自互联网中我的 WorkSpace 的资源的访问。可以在 VPC 中为 WorkSpace 网络界面选择一个默认的 Amazon VPC 安全组作为 WorkSpace 控制台中目录详细信息的一部分。有关更多详情，请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/create_iam_user.html)。"
    },
    {
        "query":"什么是 IP 访问控制组？",
        "intention":"知识问答",
        "reply":"IP 访问控制组是一项功能，可让您指定允许访问 WorkSpaces 的受信任 IP 地址。访问控制组由一组规则组成，每个规则指定允许的特定 IP 地址或地址范围。您可以创建最多 25 个 IP 访问控制组，每组最多可包含 10 个规则，用于指定可访问您的 Amazon WorkSpaces 的 IP 地址或 IP 范围。"
    },
    {
        "query":"我可以为 WorkSpaces 实施基于 IP 地址的访问控制吗？",
        "intention":"知识问答",
        "reply":"是。使用此功能，您可以创建最多 25 个 IP 访问控制组，每组最多可包含 10 个规则，用于指定可访问您的 Amazon WorkSpaces 的 IP 地址或 IP 范围。"
    },
    {
        "query":"我如何实施基于 IP 地址的访问控制？",
        "intention":"知识问答",
        "reply":"有关详细信息，请参阅 [IP 访问控制组](https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces-ip-access-control-groups.html)。"
    },
    {
        "query":"基于 IP 地址的访问控制是否适用于所有 WorkSpaces 客户端？",
        "intention":"知识问答",
        "reply":"可以。此功能可用于 macOS、iPad、Windows 桌面、Android 平板电脑和 Web Access。此功能还支持使用 MFA 的零客户端。"
    },
    {
        "query":"哪些零客户端配置与基于 IP 的访问控制功能兼容？",
        "intention":"知识问答",
        "reply":"使用 MFA 的零客户端以及任何不使用 PCoIP 连接管理器连接到 WorkSpaces 的兼容零客户端可以与基于 IP 的访问控制结合使用。如果启用基于 IP 的访问控制，任何通过 PCoIP 连接管理器的连接都将无法访问 WorkSpaces。"
    },
    {
        "query":"是否存在任何非白名单 IP 地址可以访问 WorkSpace 的情形？",
        "intention":"知识问答",
        "reply":"是。如果启用 Web Access，则在通过 Web Access 客户端访问 WorkSpaces 时，如果在用户的凭据经过验证后并且在 WorkSpace 会话开始启动前，IP 地址从白名单 IP 更改为非白名单 IP 地址，则将允许非白名单 IP 地址。初始连接需要白名单 IP 地址。"
    },
    {
        "query":"如果用户通过网络地址转换 (NAT) 访问 WorkSpaces，则如何将 IP 地址列入白名单？",
        "intention":"知识问答",
        "reply":"您将需要使用此功能将您的公有 IP 列入白名单，因此如果您拥有 NAT，则将需要允许来自它的 IP 进行访问。在这种情况下，每当用户通过 NAT 访问 WorkSpaces 时，将允许您进行访问。"
    },
    {
        "query":"应如何将 VPN 的 IP 地址列入白名单？",
        "intention":"知识问答",
        "reply":"如果您想允许从 VPN 进行访问，则将需要添加 VPN 的公有 IP。在这种情况下，每当用户通过公有 IP 已列入白名单的 VPN 访问 WorkSpaces 时，将允许您进行访问。"
    },
    {
        "query":"是否可以为最终用户登录体验自定义登录工作流？",
        "intention":"知识问答",
        "reply":"WorkSpaces 支持使用 URI（统一资源标识符）WorkSpaces：// 打开 WorkSpaces 客户端，并可选择输入注册码，用户名和/或 Multi-Factor Authentication (MFA) 代码（如果贵组织使用 MFA）。"
    },
    {
        "query":"如何启用 URI？",
        "intention":"知识问答",
        "reply":"您可以按照《Amazon WorkSpaces 管理指南》内[自定义用户登录 WorkSpaces 的方式](https://docs.aws.amazon.com/workspaces/latest/adminguide/customize-workspaces-user-login.html)中记录的 WorkSpaces URI 格式创建独特的 URI 链接。通过向用户提供这些链接，您允许他们在任何安装了 WorkSpaces 客户端的设备上使用 URI。如果您选择包含注册码、用户名和/或 MFA 信息，URI 链接可能包含人类可读的敏感信息，因此请注意您共享 URI 信息的方式和对象。"
    },
    {
        "query":"Amazon WorkSpaces 是否支持加密？",
        "intention":"知识问答",
        "reply":"是。Amazon WorkSpaces 支持根卷和用户卷加密。Amazon WorkSpaces 使用在创建 WorkSpace 时即可加密的 EBS 卷，为静态存储的数据、输入/输出至卷的磁盘和从卷创建的快照进行加密。Amazon WorkSpaces 集成了 AWS KMS 服务，可让您指定加密卷时想要使用的密钥。"
    },
    {
        "query":"哪些 Amazon WorkSpaces 捆绑包类型支持加密？",
        "intention":"知识问答",
        "reply":"所有 Amazon WorkSpaces 硬件和软件捆绑包类型均支持加密。其中包括 Windows 10 桌面体验以及 Value、Standard、Performance、Power、PowerPro、Graphics、GraphicsPro、Graphics.g4dn 和 GraphicsPro.g4dn 捆绑包。此外，还包括所有 Plus 应用程序捆绑包。此外，任何自定义捆绑包也支持加密。"
    },
    {
        "query":"如何加密新的 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"从控制台或 Amazon WorkSpaces API 创建新的 Amazon WorkSpace 时，您可以指定想要加密的卷以及从您的 KMS 密钥中选择用于加密的密钥 ARN。请注意，启动 WorkSpace 时，您可以指定是否对用户卷、根卷或这两者进行加密，并且所提供的密钥将用于加密指定的卷。"
    },
    {
        "query":"Amazon WorkSpaces 能否为我创建 KMS 密钥？",
        "intention":"知识问答",
        "reply":"在您通过 AWS 管理控制台首次尝试启动 WorkSpace 时，Amazon WorkSpaces 会创建一个默认主密钥。您无法管理默认主密钥的生命周期。要控制密钥的整个生命周期，请配置 WorkSpaces 以使用 KMS 自定义客户主密钥 (CMK)。要创建 KMS 自定义 CMK，请访问 KMS 控制台或使用 KMS API 来创建自己的密钥。请注意，您可以对您的 WorkSpaces 使用由 KMS 生成的默认密钥，该默认密钥将在您通过 AWS 管理控制台首次尝试启动加密的 Amazon WorkSpaces 时提供。"
    },
    {
        "query":"使用 KMS 密钥加密 Amazon WorkSpaces 的先决条件是什么？",
        "intention":"知识问答",
        "reply":"为了可以使用 KMS 密钥来加密 Amazon WorkSpaces，该密钥不得禁用，也不应超出其限制（请在[此处](http://docs.aws.amazon.com/kms/latest/developerguide/limits.html)了解有关限制的更多信息）。您还需要具有与该密钥相关的正确权限和策略，以将其用于加密。要详细了解密钥所需的正确权限和策略，请参阅我们的[文档](http://docs.aws.amazon.com/kms/latest/developerguide/services-workspaces.html)。"
    },
    {
        "query":"如果我的 KMS 密钥不符合上述先决条件，我将如何获得通知？",
        "intention":"知识问答",
        "reply":"当您使用指定的密钥启动新的 WorkSpace 时，WorkSpaces 服务将验证该密钥是否有效以及是否有资格用于加密。如果密钥无效，则启动过程将迅速失败并通知您与该密钥相关的错误。请注意，如果您在创建工作区时更改了密钥设置，则预置可能会失败，系统将通过 AWS 管理控制台或 DescribeWorkSpaces API 调用向您通知该故障。"
    },
    {
        "query":"我如何判断哪些 Amazon WorkSpaces 已经加密而哪些没有？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 管理控制台或使用 Amazon WorkSpaces API 查看 WorkSpace 是否已加密。除此之外，您还能够判断出 WorkSpace 上的哪些卷进行了加密，以及用于加密 WorkSpace 的密钥 ARN。例如，DescribeWorkSpaces API 调用将返回有关哪些卷 (用户和/或根) 已加密和用于加密 WorkSpace 的密钥 ARN 的信息。"
    },
    {
        "query":"我能否在正在运行的 Amazon WorkSpace 上启用卷加密？",
        "intention":"知识问答",
        "reply":"仅支持在创建和启动 WorkSpace 期间加密 WorkSpaces。"
    },
    {
        "query":"如果我禁用了 KMS 控制台中的密钥，正在运行的 Amazon WorkSpace 会怎么样？",
        "intention":"知识问答",
        "reply":"如果您禁用的是用于加密 WorkSpace 用户卷的 KMS 密钥，则正在运行的 WorkSpace 将不受影响。用户将不受打扰，能够登录和使用 WorkSpace。然而，对于使用已禁用的（或密钥上的权限/策略已修改的）KMS 密钥进行了加密的 WorkSpaces，其重新启动、重新构建和恢复的流程将失败。如果重新启用了密钥和/或恢复了正确的权限/策略，则重新启动、重新构建和恢复 WorkSpace 的流程将再次正常运行。"
    },
    {
        "query":"能否对正在运行的 Amazon WorkSpace 禁用加密功能？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 不支持对正在运行的 WorkSpace 禁用加密功能。一旦 WorkSpace 启动时已启用了加密功能，则它将始终保持加密状态。"
    },
    {
        "query":"已加密用户卷的快照是否也要加密？",
        "intention":"知识问答",
        "reply":"是。用户卷的所有快照都将使用创建 WorkSpace 时用来加密其用户卷的同一密钥进行加密。用户卷一旦加密，会在其整个生命周期内一直保持加密状态。"
    },
    {
        "query":"我是否可以重新构建已加密的 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"是。只要用来加密 WorkSpace 的密钥仍然有效，就可以重新构建 WorkSpace。重新构建后，WorkSpace 卷使用原始密钥加密并保持加密状态。"
    },
    {
        "query":"我是否可以恢复已加密的 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"是。只要用来加密 WorkSpace 的密钥仍然有效，就可以恢复 WorkSpace。恢复后，WorkSpace 卷使用原始密钥加密并保持加密状态。"
    },
    {
        "query":"我能否从已加密的 WorkSpace 中创建自定义映像？",
        "intention":"知识问答",
        "reply":"不支持从已加密的 WorkSpace 中创建自定义映像。"
    },
    {
        "query":"WorkSpace 的性能是否会因卷加密而受到影响？",
        "intention":"知识问答",
        "reply":"您应该会在加密卷上看到最少的 IOPS 延迟增量。"
    },
    {
        "query":"加密是否会影响 Amazon WorkSpace 的启动时间？",
        "intention":"知识问答",
        "reply":"只需要用户卷加密的 WorkSpace 的启动时间与未加密的 WorkSpace 的启动时间类似。需要根卷加密的 WorkSpace 的启动时间将增加几分钟。"
    },
    {
        "query":"BYOL WorkSpaces 是否支持加密？",
        "intention":"知识问答",
        "reply":"是。Amazon WorkSpaces 将支持 BYOL WorkSpaces 加密。"
    },
    {
        "query":"我能否使用相同的 KMS 密钥来加密不同区域中的 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"不能。一个区域中的加密资源不能在不同区域中使用，因为 KMS 密钥属于创建它的区域。"
    },
    {
        "query":"我是否可以轮换我的 KMS 密钥？",
        "intention":"知识问答",
        "reply":"是。您可以使用 KMS 来轮换您的自定义 CMK。您可以将您创建的自定义 CMK 配置为每年由 KMS 自动轮换。进行 CMK 轮换前，已加密的 WorkSpaces 不受任何影响，将按预期工作。"
    },
    {
        "query":"在哪里可以下载 Amazon WorkSpaces 客户端应用程序？",
        "intention":"知识问答",
        "reply":"您可以从[客户端下载网站](https://clients.amazonworkspaces.com/)免费下载 Amazon WorkSpaces 客户端应用程序。"
    },
    {
        "query":"我能否在 Amazon WorkSpaces 上使用任何其他客户端（例如 RDP 客户端）？",
        "intention":"知识问答",
        "reply":"不能。您可使用 AWS 提供的任何免费客户端（包括适用于 Windows、macOS、iPadOS、Android 平板电脑和与 Android 兼容的 Chrome OS 设备结合使用的客户端应用程序，或者 Chrome 或 Firefox Web 浏览器）访问 Amazon WorkSpaces。"
    },
    {
        "query":"Amazon WorkSpaces 客户端应用程序支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"请参阅 [WorkSpaces 客户端](https://docs.aws.amazon.com/workspaces/latest/userguide/amazon-workspaces-clients.html)文档。"
    },
    {
        "query":"Amazon WorkSpaces 客户端应用程序支持哪些移动设备？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 客户端可在以下设备中使用：\n• 基于 Apple iPadOS 的 iPad、iPad Pro、iPad Mini、iPad Air  \n • 与 Android 兼容的 Chrome OS 设备   \n • Android 手机和平板电脑\n尽管我们期望运行 Android 8.1+ 版的其他主流 Android 平板电脑可以完美运行 Amazon WorkSpaces 客户端，但可能有些型号存在兼容性问题。如果您想知道某种设备是否受支持，请通过 Amazon WorkSpaces [论坛](https://forums.aws.amazon.com/forum.jspa?forumID=164)告诉我们。"
    },
    {
        "query":"什么是 PCoIP 零客户端？",
        "intention":"知识问答",
        "reply":"PC-over-IP (PCoIP) 零客户端是一种单一用途的硬件设备，可以访问 Amazon WorkSpaces。零客户端使用的硬件专门针对 PCoIP 协议进行过优化，其设计决定了其只需要非常少的管理干预。"
    },
    {
        "query":"我是否可以将 PCoIP 零客户端与 Amazon WorkSpaces 相结合使用？",
        "intention":"知识问答",
        "reply":"可以，Amazon WorkSpaces 与具有 Teradici Tera2 芯片组的 PCoIP 零客户端兼容。PCoIP 零客户端仅可与 PCoIP WorkSpaces 结合使用，而不能与 WSP WorkSpaces 结合使用。如需与 Amazon WorkSpaces 兼容的零客户端的完整列表，请参阅 [Teradici 的网站](https://www.teradici.com/)。"
    },
    {
        "query":"在 AutoStop 运行模式下运行的 Amazon WorkSpace 是否会在停止运行时保留应用程序的状态和数据？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 在停止运行时会保留应用程序的数据和状态。在您重新连接时，Amazon WorkSpace 将恢复所有打开的文件，且所有正在运行的程序都将保持不变。AutoStop Graphics.g4dn、GraphicsPro.g4dn、Graphics 和 GraphicsPro WorkSpaces 在其停止时不会保留数据状态和程序。对于这些 Autostop WorkSpaces，我们建议您每次使用完后都保存您的工作。"
    },
    {
        "query":"当 Amazon WorkSpace 停止运行后，如何重新启动它？",
        "intention":"知识问答",
        "reply":"只需从 Amazon WorkSpaces 客户端应用程序登录您的 Amazon WorkSpace，该服务便会自动重启 Amazon WorkSpace。在您首次尝试登录时，客户端应用程序会通知您，您的 Amazon WorkSpace 之前已停止运行，重新启动 WorkSpace 将发起新会话。"
    },
    {
        "query":"Amazon WorkSpace 在我尝试登录多久后可用？",
        "intention":"知识问答",
        "reply":"如果您的 Amazon WorkSpace 没有停止运行，则几乎可以即时连接。如果您的 Amazon WorkSpace 已停止运行，则在大多数情况下，它将在两分钟内可用。对于 BYOL AutoStop WorkSpaces，大量的并发登录可能会导致 WorkSpace 的可用时间显著增加。如果您希望很多用户同时登录到 BYOL AutoStop WorkSpaces，请咨询您的客户经理以获得建议。"
    },
    {
        "query":"哪些客户端外围设备可用于 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 客户端支持：\n答：大部分模拟耳机和 USB 耳机均可用于通过搭载 Windows 的 WorkSpace 进行的音频对话。对于 USB 耳机，您应该确保它们在您的客户端计算机上显示为播放设备。"
    },
    {
        "query":"我可以使用内置的麦克风和扬声器进行音频通话吗？",
        "intention":"知识问答",
        "reply":"是。为了获得最佳体验，我们建议您使用耳机来进行音频通话。在通过某些通信应用程序进行音频通话时，如果使用内置的耳机和扬声器，您可能会听到回声。"
    },
    {
        "query":"Audio-in 是否适用于 Android、iPadOS 和兼容 Android 的 Chrome OS 设备等移动客户端？",
        "intention":"知识问答",
        "reply":"Windows、macOS、Android 和 iPadOS 客户端均支持音频输入功能。"
    },
    {
        "query":"如何为我的 WorkSpaces 启用音频输入功能？",
        "intention":"知识问答",
        "reply":"所有新的 WorkSpaces 均已启用音频输入功能。对于搭载 Windows 的 WorkSpaces，要启用 WorkSpaces 的音频输入功能，需要在您的 WorkSpaces 中拥有本地登录访问权限。如果您有限制用户在 WorkSpace 中本地登录的组策略，我们会检测到该策略，并且不会将音频输入功能的更新应用于 WorkSpace。您可以删除相关组策略。这样一来，在下次重启后，系统便会启用音频输入功能。"
    },
    {
        "query":"如何优化 Amazon Connect 的音频质量？",
        "intention":"知识问答",
        "reply":"Amazon Connect 的音频优化功能可在 WorkSpaces 目录级别使用。此功能让客户能够将 CCP（联系控制面板）的音频流量从 WorkSpaces 流式传输到本地端点进行处理，从而解决与网络状况不佳有关的质量问题。"
    },
    {
        "query":"WorkSpaces 是否支持采用高 DPI 屏幕的设备？",
        "intention":"知识问答",
        "reply":"是的。Amazon WorkSpaces 桌面客户端应用程序将自动扩展会话屏幕，使其匹配本地设备的 DPI 设置。"
    },
    {
        "query":"如果使用四台显示器或使用 4K 超高清分辨率，我的带宽使用率是否会增加？",
        "intention":"知识问答",
        "reply":"是。WorkSpaces 的带宽要求取决于两个因素：(a) 它需要流式传输到的屏幕数量及 (b) 每个屏幕上发生像素变化的数量。"
    },
    {
        "query":"Amazon WorkSpaces 是否会记得不同会话的显示器设置？",
        "intention":"知识问答",
        "reply":"系统会保留全屏模式设置。如果您在全屏模式下退出 WorkSpaces 会话，您可以在下次登录时进入全屏模式。但是，系统不会保存显示配置。每当您启动 WorkSpaces 会话时，客户端应用程序便会提取您所使用的本地设置配置的 EDID，并将其发送到 WorkSpaces 主机以提供最佳显示体验。"
    },
    {
        "query":"如果我从其他桌面连接我的 WorkSpace，我的显示设置会如何？",
        "intention":"知识问答",
        "reply":"如果您从其他台式机连接，则该计算机的显示设置将可以优先提供最佳显示体验。"
    },
    {
        "query":"iPad 和 Android 应用程序是否支持键盘/鼠标输入？",
        "intention":"知识问答",
        "reply":"Android 客户端支持键盘和鼠标输入。iPad 客户端支持键盘蓝牙鼠标输入。尽管我们预计多数主流键盘和鼠标设备可以正常使用，但可能有些设备存在兼容性问题。如果您想知道某种设备是否受支持，请通过 [Amazon WorkSpaces 论坛](https://forums.aws.amazon.com/forum.jspa?forumID=164)告诉我们。"
    },
    {
        "query":"我能否通过 Web 浏览器访问 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"能，您可以使用 Amazon WorkSpaces Web Access 通过支持 PCoIP WorkSpaces的 Chrome 或 Firefox Web 浏览器以及支持 WSP WorkSpaces 的任何基于 Chromium 的 Wed 浏览器登录搭载 Windows 的 Amazon WorkSpace。您无需安装任何软件，即可从能够访问公共 Internet 的任何网络进行连接。为了开始使用，您的 WorkSpaces 管理员需要从 AWS 控制台的 WorkSpaces Directory Details – Access Control Options（WorkSpaces 目录详情 – 访问控制选项）部分中启用 Web Access。完成这些步骤后，要通过浏览器访问您的 WorkSpace，您只需使用受支持的浏览器访问 [Amazon WorkSpaces Web Access](https://clients.amazonworkspaces.com/webclient) 页面，输入您的 WorkSpaces 注册代码，然后使用您的用户名和密码登录 WorkSpace 即可。"
    },
    {
        "query":"什么是 Amazon WorkSpaces Web Access？",
        "intention":"知识问答",
        "reply":"凭借 Amazon WorkSpaces Web Access，您可以在能连接公有互联网的电脑上，运行支持 PCoIP WorkSpaces 的 Chrome 或 Firefox Web 浏览器，以及支持 WSP WorkSpaces、基于 Chromium 的任何 Web 浏览器访问搭载 Windows 的 Amazon WorkSpace。Web Access 还允许用户使用本机 Amazon WorkSpaces 客户端应用程序连接到其 WorkSpace。用户可在 Web Access 和本机客户端应用程序之间选择。Web Access 可从[此处](https://clients.amazonworkspaces.com/webclient)进行访问。"
    },
    {
        "query":"我可以从哪些 Web 浏览器和操作系统访问 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"通过 PCoIP WorkSpaces，Web Access 可与最新 Google Chrome 和 Firefox 版本配合使用。通过 WSP WorkSpaces，Web Access 可与任何基于 Chromium 的 Web 浏览器配合使用，包括 Google Chrome 和 Microsoft Edge。Web Access 可从 Windows、macOS 或 Linux 计算机获得支持。目前不支持移动设备。"
    },
    {
        "query":"我能否为非英语版 Amazon WorkSpaces 启用 Web Access？",
        "intention":"知识问答",
        "reply":"是。具有基于英语（美国）、日语、韩语和法语（加拿大）版本的 Windows 桌面的 WorkSpaces 目前提供 Web Access 支持。"
    },
    {
        "query":"我是否需要安装其他软件才能通过 Web 浏览器访问 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"否，您无需安装任何程序、附件或插件，即可通过支持的 Web 浏览器访问 Amazon WorkSpaces。"
    },
    {
        "query":"如何开始使用 Web Access 登录 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"首先，您需要为 Amazon WorkSpace 启用 Web Access。这可由您的 IT 管理员通过 AWS 管理控制台完成。完成后，您便可使用 Web Access（可从此处进行访问）登录。首次登录时，系统会要求您输入欢迎电子邮件中提供的注册代码。"
    },
    {
        "query":"如何知道我的 Amazon WorkSpace 是否已启用 Web Access？",
        "intention":"知识问答",
        "reply":"如果您的 Amazon WorkSpace 已设为禁用 Web Access，则您在尝试登录时会收到一条错误消息，通知您联系您的系统管理员以启用 Web Access。"
    },
    {
        "query":"在任何网络上是否均可使用 Web Access 访问 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。您可在能够访问公共网络的任何网络上使用 Web Access。如果您能够浏览网页，则可以连接到 Amazon WorkSpace。"
    },
    {
        "query":"有哪些 Amazon WorkSpaces 捆绑包支持 Web Access？",
        "intention":"知识问答",
        "reply":"您可以使用 Web Access 连接到搭载 Windows 10 或 Windows Server 2016 操作系统的 Amazon WorkSpaces Value、Standard、Performance、Power 和 PowerPro 捆绑包。由 Windows Server 2019 和 Windows 11 提供支持的 WorkSpaces 仅支持使用 WSP 的 Web Access。支持 GPU 的 WorkSpaces 和 Amazon Linux WorkSpaces 当前不支持 Web Access。 Ubuntu WorkSpaces 支持 Web Access。"
    },
    {
        "query":"通过 Web Access 连接到 Amazon WorkSpace 后，我可以使用哪些本地设备？",
        "intention":"知识问答",
        "reply":"您可以将鼠标和键盘用作输入设备。本地外围设备 (包括打印机、USB 驱动器、网络摄像头和麦克风) 将不可用。尽管剪贴板重定向在您的本地操作系统和 Amazon WorkSpace 上无法正常使用，但是您可以在 WorkSpace 内进行复制和粘贴操作。"
    },
    {
        "query":"Web Access 在哪些地区提供？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces Web Access 在 Amazon WorkSpaces 可用的所有地区中提供。"
    },
    {
        "query":"是否需要输入注册代码才能使用 Web Access？",
        "intention":"知识问答",
        "reply":"首次使用 Web Access 登录时，系统会要求您输入欢迎电子邮件中提供的注册代码。目前，Web Access 尚未提供存储多个不同注册代码的功能。"
    },
    {
        "query":"使用 Web 浏览器访问 Amazon WorkSpace 时，如何控制会话？",
        "intention":"知识问答",
        "reply":"您可以使用浏览器窗口顶部的连接栏来控制会话。您可以使用连接栏断开连接、进入和退出全屏模式，以及向 Amazon WorkSpace 发送“Ctrl-Alt-Del”键序列。连接栏可以固定在某个位置，也可以设置为自动隐藏。"
    },
    {
        "query":"通过 Web 浏览器访问 Amazon WorkSpace 时，如何将其断开连接？",
        "intention":"知识问答",
        "reply":"您可以使用连接栏中的“断开连接”命令、通过关闭浏览器选项卡或退出浏览器程序来断开连接。Web Access 不支持重新连接到 Amazon WorkSpace，因此您必须再次登录才能重新连接。"
    },
    {
        "query":"Amazon WorkSpaces 是否支持其他客户端设备和虚拟桌面操作系统？",
        "intention":"知识问答",
        "reply":"我们不断审视我们的发展计划，以便查看我们能够添加哪些功能来满足客户要求。如果您希望 Amazon WorkSpaces 支持某一种客户端设备或虚拟桌面操作系统，请发送电子邮件给我们，告诉我们您的具体要求。"
    },
    {
        "query":"启用 Multi-Factor Authentication (MFA) 时，最终用户有何体验？",
        "intention":"知识问答",
        "reply":"用户在提供其 OTP 后，系统还将提示其输入 Active Directory 用户名和密码。用户通过 Active Directory 和 RADIUS 验证后，即可登录到其 Amazon WorkSpace。要了解更多信息，请访问我们的文档。"
    },
    {
        "query":"如何确定运行 Amazon WorkSpaces 的最佳地区？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 连接状况检查网站会比较每个 Amazon WorkSpaces 地区的连接速度，然后为您推荐速度最快的地区。"
    },
    {
        "query":"Amazon WorkSpaces 支持哪些语言？",
        "intention":"知识问答",
        "reply":"提供 Windows 10 桌面体验的 Amazon WorkSpaces 捆绑包当前支持英语（美国）、法语（加拿大）、韩语和日语。您还可以直接从 Microsoft 下载并安装适用于 Windows 的语言包。有关更多信息，请访问[此页面](https://support.microsoft.com/en-us/help/14236/language-packs)。Amazon WorkSpaces 客户端应用程序当前支持英语（美国）、德语、中文（简体）、日语、法语（加拿大）、韩语和葡萄牙语。"
    },
    {
        "query":"我是否可以使用 SmartCard 而非用户名/密码访问访问我的 WorkSpaces？",
        "intention":"知识问答",
        "reply":"是 - WSP WorkSpaces 可通过 SmartCard 访问，而不必提供用户名/密码。如果您使用 Active Directory Connector 并将目录 API 设置为启用的智能卡，则可通过智能卡访问 WorkSpaces。注意：PCoIP WorkSpaces 不支持 SmartCard 功能。"
    },
    {
        "query":"官方支持哪些类型的 SmartCard？",
        "intention":"知识问答",
        "reply":"WorkSpaces 官方支持 CAC 和 PIV SmartCard。"
    },
    {
        "query":"在会话中可以同时使用多少 SmartCard",
        "intention":"知识问答",
        "reply":"WorkSpaces 每次只能处理一个会话中 SmartCard"
    },
    {
        "query":"SmartCard 支持是否在所有区域中均可获得？",
        "intention":"知识问答",
        "reply":"在 WorkSpaces 外部使用的会话中 SmartCard 支持已在支持 WSP 的所有区域推出。对 SmartCard 的会话前身份验证仅可用于 AWS GovCloud（美国西部）区域的 WSP WorkSpaces。"
    },
    {
        "query":"Amazon WorkSpaces 服务是否有维护时段？",
        "intention":"知识问答",
        "reply":"是。 默认情况下，Amazon WorkSpaces 为 AlwaysOn WorkSpaces 和 AutoStop WorkSpaces 启用维护时段。\n对于 AlwaysOn（每月）WorkSpaces，维护计划由 WorkSpace 上的操作系统设置控制。默认的维护时段为每周日凌晨 00:00 到 04:00 之间的 4 个小时（该时间段基于为 Amazon WorkSpaces 设置的时区设置）。在此时间内，WorkSpaces 不可用。\n对于 AutoStop（每小时）WorkSpaces，默认的维护时段通常从每月第三个星期一开始，以 WorkSpaces 的 AWS 区域的时区为基准，每天 00:00 到 05:00。维护时段最长会持续两周。WorkSpace 可以在维护时段内的任何一天进行维护。您可以在 WorkSpaces 管理控制台设置 AutoStop WorkSpaces 的维护模式。有关更多信息，请参阅 [管理 WorkSpace 运行模式](https://docs.aws.amazon.com/workspaces/latest/adminguide/running-mode.html)。目前，AutoStop WorkSpaces 的维护时段尚不可配置。"
    },
    {
        "query":"可以选择取消 WorkSpaces 的维护时段吗？",
        "intention":"知识问答",
        "reply":"强烈推荐定期维护 WorkSpaces。如果您想要按照自己的 WorkSpaces 维护计划运行，您可以选择取消 Windows WorkSpaces 的默认维护时段服务。\n对于 AutoStop（每小时）WorkSpaces，您可以禁用[控制台](https://docs.aws.amazon.com/workspaces/latest/adminguide/running-mode.html#set-maintenance-mode)上的“维护”模式。对于 AlwaysOn Windows WorkSpaces，维护时段由系统设置控制，并且通过[自动更新 GPO 设置](https://docs.microsoft.com/de-de/security-updates/windowsupdateservices/18127451)进行配置。目前，您无法选择取消 AlwaysOn Amazon Linux 和 Ubuntu WorkSpaces 的维护时段。"
    },
    {
        "query":"Amazon WorkSpaces 是否需要进行软件更新？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 为用户提供 Amazon Linux 云桌面、Windows 10 体验，该操作系统由 Windows Server 2016/2019 提供。基础操作系统和安装在 WorkSpace 中的所有应用程序可能都需要更新。"
    },
    {
        "query":"如何通过软件更新来对 Amazon WorkSpaces 进行修补？",
        "intention":"知识问答",
        "reply":"默认情况下，Amazon WorkSpaces 已配置为安装软件更新。Amazon Linux 和 Ubuntu WorkSpaces 将进行更新，以安装最新的安全补丁和软件补丁，而搭载 Windows 的 Amazon WorkSpaces 会启用“Windows 更新”。您可以自定义这些设置，或者使用另一种补丁管理方法。系统会在每周日凌晨 2 点安装更新。"
    },
    {
        "query":"接收 Amazon WorkSpaces 服务的更新需要采取什么操作？",
        "intention":"知识问答",
        "reply":"您不需要进行任何操作。更新会在维护时段自动发送到您的 Amazon WorkSpaces。在维护时段，您的 WorkSpaces 可能不可用。"
    },
    {
        "query":"能否关闭 Amazon WorkSpaces 服务的软件更新？",
        "intention":"知识问答",
        "reply":"不能。Amazon WorkSpaces 服务需要进行这些更新，以确保用户的 WorkSpaces 能够正常运作。"
    },
    {
        "query":"我不希望 Windows Update 自动更新我的 Amazon WorkSpaces。如何控制更新并确保它们提前进行了测试？",
        "intention":"知识问答",
        "reply":"您可以在 WorkSpaces 中完全控制 Windows Update 配置，并且可以使用 Active Directory 群组策略将其配置为满足您的确切要求。如果您想获得补丁的预先通知以便进行适当计划，我们建议您参阅 [Microsoft 安全性公告预先通知](https://blogs.technet.microsoft.com/msrc/)以了解更多信息。"
    },
    {
        "query":"如何将应用程序的更新安装在提供的 WorkSpaces 中？",
        "intention":"知识问答",
        "reply":"搭载 Amazon Linux 和 Ubuntu 的 Amazon WorkSpaces 通过在每个 WorkSpaces 区域中托管的预配置 Amazon Linux yum 或 Ubuntu（APT 或 Snap）存储库进行更新，并自动安装更新。需要重启的补丁和更新在我们的每周维护时段进行安装。\n对于其它所有应用程序，如果有一个可用，可通过自动更新服务发送每个应用程序的更新。对于没有自动更新服务的应用程序，您需要对软件买方推荐的更新方法进行评估，并在需要时采用该方法。"
    },
    {
        "query":"如何管理我的 WorkSpaces？",
        "intention":"知识问答",
        "reply":"您可以通过 WorkSpaces 管理控制台预置、重启、重建、恢复和删除 WorkSpaces。要管理 WorkSpaces 的基础操作系统，您可以使用标准的 Microsoft Active Directory 工具（如组策略或您所选的 Linux 编排工具）来管理 WorkSpaces。在您将 WorkSpace 与现有的 Active Directory 域集成时，您可以使用您用于现有本地桌面的工具和方法来管理 WorkSpaces。如果您未集成现有的 Active Directory，您可以设置目录管理 WorkSpace 来执行管理任务。请参阅[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_administration.html)以了解更多信息。\n您还可以启用自助管理，为 WorkSpaces 用户提供自行执行常见任务的功能。启用此功能后，WorkSpaces 用户可以直接从 WorkSpaces 客户端执行重启、重建、恢复、增加卷大小、更改计算类型和更改运行模式等操作，而无需 IT 或帮助台干预。"
    },
    {
        "query":"我是否可以使用标签来对我的 Amazon WorkSpaces 资源进行分类？",
        "intention":"知识问答",
        "reply":"是，您可以为现有的 Amazon WorkSpaces 资源分配标签，包括WorkSpaces、使用 WorkSpaces 注册的目录、映像、自定义捆绑包和 IP 访问控制组。您还可以在创建新的 Amazon WorkSpaces 和新的 IP 访问控制组期间分配标签。通过 AWS 管理控制台、AWS 命令行界面或 Amazon WorkSpaces API，您最多可为每个 Amazon WorkSpaces 资源分配 50 个标签（键/值对）。要详细了解如何将标签分配给 Amazon WorkSpaces 资源，请按照此网页上列出的步骤操作：[标记 WorkSpaces 资源](https://docs.aws.amazon.com/workspaces/latest/adminguide/tag-workspaces-resources.html)。"
    },
    {
        "query":"我可以控制用户能否访问 Amazon WorkSpaces Web Access 吗？",
        "intention":"知识问答",
        "reply":"是。您可以访问目录详情页面，通过 AWS 管理控制台来控制是否可以使用 Web Access 访问目录中的 Amazon WorkSpaces。注意：此设置只能用于目录中的所有 Amazon WorkSpaces，而不能用于单个 Amazon WorkSpace 级别。"
    },
    {
        "query":"重启和重建 WorkSpace 之间有何差异？",
        "intention":"知识问答",
        "reply":"重启与常规的操作系统 (OS) 重启完全相同。重建将保留 WorkSpace 上的用户卷，但会使 WorkSpace 返回其原始状态（系统盘上的任何更改都将不会保留）。"
    },
    {
        "query":"WorkSpaces 重建和恢复之间有何差异？",
        "intention":"知识问答",
        "reply":"重建将保留 WorkSpace 上的用户卷，但会使 WorkSpace 返回其原始状态（系统盘上的任何更改都将不会保留）。恢复将同时保留 WorkSpace 上的根卷和用户卷，但会使 WorkSpace 返回服务检测到的上一次正常运行状态。"
    },
    {
        "query":"如何删除不再需要的 Amazon WorkSpace？",
        "intention":"知识问答",
        "reply":"如需删除您不再需要的 WorkSpace，您可以“删除”WorkSpace。这样将会删除支持 WorkSpace 的基础实例，且 WorkSpace 将不再存在。删除 WorkSpace 后，附加在 WorkSpace 的卷中存储的任何数据也会被删除，所以请确认您在删除 WorkSpace 之前已保存您必须保留的任何数据。"
    },
    {
        "query":"能否为每个用户提供多个 Amazon Workspace？",
        "intention":"知识问答",
        "reply":"不能。目前，您只能为每个用户提供一个 WorkSpace。"
    },
    {
        "query":"我可以启动多少个 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"您可以按需启动任意数量的 Amazon WorkSpaces。Amazon WorkSpaces 会设置默认限制，但您可以单击[此处](https://console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase&limitType=service-code-workspaces)请求提高这些限制。要查看 Amazon WorkSpaces 的默认限制，请访问我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_limits.html)。"
    },
    {
        "query":"使用 Amazon WorkSpace 时需要多大的网络带宽？",
        "intention":"知识问答",
        "reply":"使用 WorkSpace 所需的带宽取决于您在 WorkSpace 上进行的操作。对于一般性的办公使用，建议网络下载速度应在 300Kbps 到 1Mbps 之间。对于需要处理大量图形的工作，建议网络下载速度为 3Mbps。"
    },
    {
        "query":"访问 WorkSpace 时的最大建议网络延迟是多少？",
        "intention":"知识问答",
        "reply":"对于 PCoIP，最大往返延迟推荐值为 250 ms，但最佳用户体验在低于 100 ms 时达到。当 RTT 超过 375ms 时，WorkSpaces 客户端连接终止。对于 WorkSpaces 流协议 (WSP)，在往返延迟低于 250ms 达到最佳用户体验。如果 RTT 在 250ms 到 400ms 之间，用户可访问 WorkSpace，但是性能会下降。"
    },
    {
        "query":"是否存在适合于我的 WorkSpaces 的建议电源计划或电源设置？",
        "intention":"知识问答",
        "reply":"是。对于运行 Windows 的 WorkSpaces，我们建议在 Windows 中选择“高性能”电源计划。  对于运行 Linux 的 WorkSpaces，您应选择可优化性能的电源计划。"
    },
    {
        "query":"WorkSpaces 是否需要对我的网络更新任何服务质量配置？",
        "intention":"知识问答",
        "reply":"如果您想在您的网络上针对 WorkSpaces 流量实施服务质量，则应优先考虑 WorkSpaces 交互式视频流，该视频流由用于 PCoIP 的 UDP 端口 4172 和用于 WSP 的端口 4195 上的实时流量组成。如有可能，应在 VoIP 之后优先考虑该流量，以提供最佳用户体验。"
    },
    {
        "query":"Amazon WorkSpaces 所在区域是否支持 MFA？",
        "intention":"知识问答",
        "reply":"所有[提供 Amazon WorkSpaces 的 AWS 区域](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)均支持 MFA。"
    },
    {
        "query":"设置 PCoIP 零客户端的先决条件是什么？",
        "intention":"知识问答",
        "reply":"零客户端应更新至固件版本 4.6.0（或更高版本）。WorkSpace 将需要使用 PCoIP 协议，WSP 协议不支持 PCoIP 零客户端。您需要运行 [PCoIP 连接管理器](http://docs.aws.amazon.com/workspaces/latest/adminguide/enable_zero_client.html)来支持客户端成功连接至 Amazon WorkSpaces。请参阅 Amazon WorkSpaces 文档，了解有关如何正确设置 PCoIP 连接管理器的[分步指南](http://docs.aws.amazon.com/workspaces/latest/adminguide/zero_client_help.html)，以及有关如何[查找和安装零客户端所需的必要固件](http://docs.aws.amazon.com/workspaces/latest/adminguide/zero_client_help.html)的帮助信息。"
    },
    {
        "query":"如何获得有关 Amazon WorkSpaces 的支持？",
        "intention":"知识问答",
        "reply":"您可以从 [AWS Support](https://aws.amazon.com/contact-us/) 获得帮助，也可以在 [Amazon WorkSpaces 论坛](https://forums.aws.amazon.com/forum.jspa?forumID=164)中发布帖子。"
    },
    {
        "query":"Amazon WorkSpaces 是如何计费的？",
        "intention":"知识问答",
        "reply":"您可以按小时或者按月支付 Amazon WorkSpaces 费用。您只需为启动的 WorkSpaces 付费，无需投入前期费用和订立长期合约。Amazon WorkSpaces 的使用费包含基础设施（通过流式处理向用户提供桌面体验所需的计算、存储和带宽）和服务包中各软件应用程序的使用费。"
    },
    {
        "query":"Amazon WorkSpace 的成本是多少？",
        "intention":"知识问答",
        "reply":"请参阅我们的[定价页面](https://aws.amazon.com/workspaces/pricing/)，了解最新信息。"
    },
    {
        "query":"如何使我的 Amazon WorkSpaces 开始按小时计费？",
        "intention":"知识问答",
        "reply":"要使启动的 Amazon WorkSpace 按小时计费，您只需选择一个用户和一个 Amazon WorkSpaces 捆绑包（一种计算资源和存储空间配置），并指定 AutoStop 运行模式即可。这样一来，在您的 Amazon WorkSpace 创建完成后，它将会按小时计费。"
    },
    {
        "query":"Amazon WorkSpaces 的按月计费和按小时计费有什么区别？",
        "intention":"知识问答",
        "reply":"按月计费时，您只需支付固定的月服务费即可在当月无限制使用 Amazon WorkSpaces，并能够随时快速访问正在运行的 Amazon WorkSpace。按小时计费时，您可以按小时支付 Amazon WorkSpaces 的使用费，这样，当您的用户只需零星地访问他们的 Amazon WorkSpaces 时，可以为您节省 AWS 账单费用。当按小时计费的 Amazon WorkSpaces 未使用时，它们将在指定的非活动时间之后自动停止运行，小时使用计费也会随即暂停。"
    },
    {
        "query":"如何为我的 Amazon WorkSpaces 选择按小时计费或按月计费？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 支持两种运行模式，即 AutoStop 和 AlwaysOn。当您支付固定的月服务费，以便在期间无限制使用 Amazon WorkSpaces 时，则需要选择 AlwaysOn 运行模式。当您的用户需要高可用性和对他们的桌面进行即时访问时，特别是当很对用户需要同时登录 WorkSpaces 时，这是最好的选择。AutoStop 运行模式允许您按小时支付 Amazon WorkSpaces 费用。如果您的用户可以等待大约 2 分钟来启动偶然使用的流媒体桌面，这种运行模式是最好的。请咨询您的客户经理了解有关登录并发和运行模式的更多信息。您可以轻松地选择按月计费或按小时计费，只需在通过 AWS 管理控制台、Amazon WorkSpaces API 或 Amazon WorkSpaces 命令行界面启动 Amazon WorkSpaces 时选择相应的运行模式即可。您还可以随时在 Amazon WorkSpaces 的两种运行模式之间进行切换。"
    },
    {
        "query":"我能否强制提早暂停小时计费？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 管理控制台或使用 Amazon WorkSpaces API 手动停止 Amazon WorkSpaces。对于按月计费的 Amazon WorkSpaces，如要终止与之相关的月服务费，您需要将 Amazon WorkSpaces 从您的账户中删除 (注意：此操作同时会删除存储在这些 Amazon WorkSpaces 中的所有数据)。"
    },
    {
        "query":"我可以在按小时计费和按月计费之间进行切换吗？",
        "intention":"知识问答",
        "reply":"可以，您可以随时将您的 Amazon WorkSpaces 从按小时计费切换为按月计费，具体方法是：通过 AWS 管理控制台或 Amazon WorkSpaces API 将运行模式切换为“AlwaysOn”。切换后，计费方式会立即从按小时计费更改为按月计费，您需要针对“AlwaysON”模式下当月剩余天数支付根据基本每月费率按比例算出的金额，以及已针对该月收取的每月和小时“AutoStop”使用费用。除非您将运行模式改回“AutoStop”，否则 Amazon WorkSpaces 将继续按月收费。\n您可以通过 AWS 管理控制台或 Amazon WorkSpaces API 将运行模式设置为“AutoStop”，从而将按月计费切换为按小时计费。从按月计费更改为按小时计费将在下个月生效，因为您已经支付了当月的 Amazon WorkSpaces 使用费。除非您将运行模式改回“AlwaysOn”，否则 Amazon WorkSpaces 将继续按小时收费。请注意，计费续订发生于每月第一天的 UTC 时间 00:00。\n如果 WorkSpaces 管理员启用了自助管理功能，WorkSpaces 用户还可以直接在 WorkSpaces 客户端中切换按月和按小时计费。"
    },
    {
        "query":"如果我的 Amazon WorkSpace 使用时间没有达到一个整月，是否可以按比例支付使用费？",
        "intention":"知识问答",
        "reply":"如果您使用的是按月计费，则需要按足月支付 Amazon WorkSpaces 的使用费。如果您使用的是按小时计费 (AutoStop 运行模式)，则需要支付 Amazon WorkSpaces 在运行或维护时段的小时使用费，外加针对固定基础设施成本收取的月服务费。在这两种情况下，只有第一个月的月服务费是按比例计算的。"
    },
    {
        "query":"如果我在某个月没有使用 Amazon WorkSpaces，是否需要支付与按小时计费相关的一小笔月服务费？",
        "intention":"知识问答",
        "reply":"是的，您需要为您选择的 Amazon WorkSpaces 捆绑包支付很少的月服务费。如果您选择了 Amazon WorkSpaces Plus 捆绑包，则还需支付软件订阅费。您可以从[此处](https://aws.amazon.com/workspaces/pricing/)的定价页面查看所有 Amazon WorkSpaces 的月服务费。"
    },
    {
        "query":"我能否监控 Amazon WorkSpaces 的运行小时数？",
        "intention":"知识问答",
        "reply":"可以，通过 Amazon CloudWatch 的“UserConnected”指标，您将能够监控您的 Amazon WorkSpaces 在特定时段内运行的总时数。"
    },
    {
        "query":"Amazon WorkSpaces 定价是否包含带宽成本？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 定价包含用户客户端与其 WorkSpace 之间的网络流量成本。WorkSpaces 产生的 Web 流量（例如，访问公共互联网或下载文件所产生的流量）费用将按[此处](https://aws.amazon.com/ec2/pricing/on-demand/)列出的当前 AWS EC2 数据传输费率单独收取。"
    },
    {
        "query":"我能否使用自定义映像启动按小时计费的 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。您可以从您创建并上传的映像启动按小时计费的 Amazon WorkSpaces。从自定义映像启动 Amazon WorkSpaces 不产生额外费用。您只需要为创建自定义映像时所使用的同一个底层组合付费。"
    },
    {
        "query":"使用 Amazon WorkSpaces 客户端应用程序是否需要付费？",
        "intention":"知识问答",
        "reply":"下载 Amazon WorkSpaces 客户端应用程序无需支付额外费用，您可以根据需要将客户端安装到任意数量的设备上。您可以从[此处](https://clients.amazonworkspaces.com/)进行访问。"
    },
    {
        "query":"我是否可以在我的 AWS 月度账单报告上使用标签来获取有关 Amazon WorkSpaces 使用情况和成本的详细信息？",
        "intention":"知识问答",
        "reply":"可以。通过将标签设置为在月度成本分配报告上显示，您的 AWS 月度账单中也将包括这些标签。这样，您便可以根据需要轻松跟踪成本。为此，您首先需要按照以下网页中列出的步骤将标签分配给您的 Amazon WorkSpaces：[标记 WorkSpaces](https://docs.aws.amazon.com/workspaces/latest/adminguide/tag-workspaces-resources.html)。接下来，按照以下网页中列出的步骤选择您的成本分配报告中要包括的标签键：[设置月度成本分配报告](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/configurecostallocreport.html)。"
    },
    {
        "query":"学校、大学和公共机构需要满足哪些要求才能降低 WorkSpaces 许可费？",
        "intention":"知识问答",
        "reply":"学校、大学和公共机构可能有资格享受较低的 WorkSpaces 许可费用。有关资格要求，请参阅 [Microsoft 许可条款和文档](http://www.microsoftvolumelicensing.com/DocumentSearch.aspx?Mode=3&DocumentTypeId=7)。如果您认为自己有可能符合要求，请访问[此处](https://console.aws.amazon.com/support/home#/case/create?issueType=customer-service&serviceCode=billing&categoryCode=qualify-as-educational-institution)，通过 AWS Support Center 创建案例。选择“关于”：<Account and Billing Support>、服务：<Billing>、类别：<Qualify as Educational institution>，然后输入所需信息。我们将审核您的信息，并与您合作来降低您的费用。"
    },
    {
        "query":"学校、大学或公共机构需要提供哪些信息才能获得资格？",
        "intention":"知识问答",
        "reply":"您需要向 AWS 提供贵机构的完整法定名称、主要办公地址以及公共网站 URL。AWS 将根据这些信息判断您能否作为合格教育机构享受 WorkSpaces 的低用户费用。请注意：您对 Microsoft 软件的使用受 Microsoft 条款的约束。您有责任遵守 Microsoft 的许可要求。如果您对 Microsoft 软件许可或权利有任何疑问，请咨询您的法律团队、Microsoft 或 Microsoft 分销商。您同意我们向 Microsoft 提供相关信息，以便在您使用 Amazon WorkSpaces 时应用教育定价。"
    },
    {
        "query":"在我的 WorkSpace 和最终用户设备之间传输数据是否需要付费？",
        "intention":"知识问答",
        "reply":"服务费用包括 WorkSpace 和最终用户设备之间的数据传输费用，除非您通过 VPN 进行传输，在这种情况下，除了适用的互联网数据传输费用外，您还需要支付 VPN 数据传输费用。其他 WorkSpace 数据传输将根据 Amazon EC2 数据传输定价计费。"
    },
    {
        "query":"我有资格获得 Amazon WorkSpaces 免费套餐吗？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 免费套餐面向新的 AWS 客户或现有的从未使用过 WorkSpaces 的 AWS 客户提供。客户必须是 WorkSpaces 的新 Amazon 客户，并且其账户不在 AWS 合作伙伴账户下。"
    },
    {
        "query":"免费套餐中包含了哪些 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon WorkSpaces 免费套餐预置两个标准 WorkSpaces 捆绑包，其中根卷为 80GB，用户卷为 50GB。WorkSpaces 标准捆绑包提供了一个配备 2 个 vCPU、4GB 内存以及 SSD 存储（80GB 根卷和 50GB 用户卷）的云桌面，并且您可以在 Amazon Linux WorkSpaces 与提供 Windows 10 桌面体验（两者均由 Windows Server 提供支持）的 Amazon WorkSpaces 之间进行选择。和所有 WorkSpace 一样，您的 WorkSpace 随附了预先安装的应用程序，并且能够访问包含 50GB 存储容量的 Amazon WorkDocs。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"Amazon WorkSpaces 免费套餐包含什么？",
        "intention":"知识问答",
        "reply":"WorkSpaces 免费套餐包含两个 Standard WorkSpaces 捆绑包（包括 80GB 根卷和 50GB 用户卷），每月提供 40 小时的组合使用时长，期限为前三个账单周期。和所有捆绑包一样，您的 WorkSpace 随附预安装的应用程序，并且能够访问包含 50 GB 存储容量的 [Amazon WorkDocs](https://aws.amazon.com/cn/workdocs/)。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/cn/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"可以使用免费套餐的其他 Amazon WorkSpaces 捆绑包吗？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 免费套餐仅包含标准捆绑包。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"Amazon WorkSpaces 免费套餐的有效期限是多久？",
        "intention":"知识问答",
        "reply":"免费套餐从您启动首个 Amazon WorkSpace 开始计算，于三个账单周期后结束。例如，如果您在本月 15 日启动了首个 WorkSpace，则免费套餐将于下月月底结束。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/cn/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"如果我的免费套餐在第一个月使用了不到 40 小时，剩下的时间会结转到下月吗？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 免费套餐每月一共提供 40 小时的组合使用时长。未用时长会在进入新的日历月后失效。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"如果我的 WorkSpaces 免费套餐在一个日历月的使用时间超过 40 小时，会怎么样？",
        "intention":"知识问答",
        "reply":"如果您在免费套餐月的使用时间超过 40 小时，将按照 Amazon WorkSpaces 的现行小时费率计费。限时促销优惠可能会通过免费套餐提供，请参阅 WorkSpaces [定价页面](https://aws.amazon.com/workspaces/pricing/)以了解最新信息。"
    },
    {
        "query":"如果我在免费套餐到期之前将 Amazon WorkSpaces 从 AutoStop（按小时计费）转为 AlwaysOn（按月计费），会怎么样？",
        "intention":"知识问答",
        "reply":"要使用免费套餐，您的 Amazon WorkSpaces 需要在 AutoStop 运行模式下运行。您可以将 WorkSpaces 的运行模式更改为 AlwaysOn，但此操作会使您的 WorkSpaces 转变为按月计费，并且您的免费套餐使用期限将结束。"
    },
    {
        "query":"Amazon WorkSpaces 免费套餐的有效期结束后将会怎样？",
        "intention":"知识问答",
        "reply":"免费套餐的有效期结束后，将按现行小时费率对您的 Amazon WorkSpaces 计费。此外，还会开始计算基础设施的月度使用费。有关现行费率，请参阅 [Amazon WorkSpaces 定价](https://aws.amazon.com/workspaces/pricing/)。"
    },
    {
        "query":"如何追踪 Amazon WorkSpaces 免费套餐的使用情况？",
        "intention":"知识问答",
        "reply":"要追踪 Amazon WorkSpaces 的使用情况，请前往 AWS 管理控制台的“我的账户”页面，然后按服务和区域查看您的当前和历史活动。您也可以下载使用情况报告。有关更多信息，请参阅[通过计费报告了解您的使用情况](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports.html)。"
    },
    {
        "query":"能否使用 HTTPS 代理连接 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"能，您可以配置 WorkSpaces 客户端应用程序以使用 HTTPS 代理服务器。请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/windows_client_help.html)以了解更多信息。"
    },
    {
        "query":"能否将 Amazon WorkSpaces 连接到 VPC？",
        "intention":"知识问答",
        "reply":"是。第一次连接 WorkSpaces 管理控制台时，您可以选择简单的“开始”链接创建新 VPC 和两个相关的子网以及一个 Internet 网关和一个包含您的用户的目录。如果您选择直接访问控制台，您可以选择将 WorkSpaces 连接到哪个 VPC。如果您的 VPC 通过 VPN 连接与本地网络相连接，则您的 WorkSpace 可以与本地网络通信 (您可以使用所有通常的配置选项 [如安全组、网络 ACL 和路由表] 对 VPC 中的网络访问施以常见的控制)。"
    },
    {
        "query":"能否将现有的 Active Directory 连接到 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。您可以使用 AD Connector 或 AWS Microsoft AD 与现有本地 Active Directory 集成。"
    },
    {
        "query":"Amazon WorkSpaces 能否连接 Internet 以便浏览网站、下载应用程序？",
        "intention":"知识问答",
        "reply":"是。您可以基于常规 VPC 配置全面控制您的 Amazon WorkSpaces 连接 Internet 的方式。根据您的需要，您可以部署 NAT 实例以连接 Internet，将弹性 IP 地址 (EIP) 分配到与工作区关联的弹性网络接口 (ENI)，也可以通过利用到本地网络的连接，使您的 WorkSpaces 可以访问 Internet。"
    },
    {
        "query":"我是否可以将 IPv6 地址用于 Amazon WorkSpaces 捆绑包？",
        "intention":"知识问答",
        "reply":"是。您可以将 IPv6 地址用于 Value、Standard、Performance、Power、PowerPro、GraphicsPro、Graphics.g4dn 和 GraphicsPro.g4dn 捆绑包。目前，Graphics 捆绑包不支持 IPv6 地址。"
    },
    {
        "query":"Amazon WorkSpaces 能否连接到 Amazon EC2 中运行的应用程序，如文件服务器？",
        "intention":"知识问答",
        "reply":"是。WorkSpaces 可以连接到在 Amazon EC2 (在“典型”和 VPC 联网环境中) 中运行的应用程序，如文件服务器。您只需要确保对合适的路由表条目、安全组和网络 ACL 进行了配置，从而使 WorkSpace 能够到达您希望其连接到的 EC2 资源。"
    },
    {
        "query":"将数字证书用于 Amazon WorkSpaces 需要满足哪些先决条件？",
        "intention":"知识问答",
        "reply":"要使用证书管理可访问 Amazon WorkSpaces 的客户端设备，您需要使用 Microsoft System Center Configuration Manager (SCCM) 或 Mobile-Device Management (MDM) 软件解决方案等首选解决方案，将客户端证书分发给您想信任的设备。您的根证书已导入 WorkSpaces 管理控制台。有关更多信息，请参阅[限制受信任的设备对 WorkSpaces 的访问](http://docs.aws.amazon.com/workspaces/latest/adminguide/trusted-devices.html)。"
    },
    {
        "query":"在 Amazon WorkSpaces 上启用 MFA 有哪些先决条件？",
        "intention":"知识问答",
        "reply":"若要在 WorkSpaces 上启用 MFA，您需要配置 AD Connector 并具有本地 RADIUS 服务器。您的本地网络必须允许通过默认的 RADIUS 服务器端口 (1812) 从 AD Connector 服务器传入的入站流量。此外，您必须确保 Active Directory 和 RADIUS 服务器的用户名一致。要了解更多信息，请访问我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/prep_connect.html#mfa_prereqs)。"
    },
    {
        "query":"使用 Amazon WorkSpaces 服务是否需要设置目录？",
        "intention":"知识问答",
        "reply":"您对其预置了 WorkSpace 的每个用户都需要包含在目录中，但您必须自行预置目录。您可以让 WorkSpaces 服务为您创建并管理目录，并在预置 WorkSpace 时在该目录中创建用户。或者，您可以将 WorkSpaces 与现有的本地 Active Directory 集成，从而使用户能够继续使用其现有的凭证，这意味着，他们可以获得现有应用程序的无缝应用程序。"
    },
    {
        "query":"如果我使用 Amazon WorkSpaces 服务为我创建的目录，我能否对其进行配置或自定义？",
        "intention":"知识问答",
        "reply":"是。有关更多详情，请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/managing_a_directory.html)。"
    },
    {
        "query":"是否可以将 Amazon WorkSpaces 与我的现有本地 Active Directory 集成？",
        "intention":"知识问答",
        "reply":"是。您可以使用 AD Connector 或 AWS Microsoft AD 与现有本地 Active Directory 集成。"
    },
    {
        "query":"如何将 Amazon WorkSpaces 与我的本地 Microsoft Active Directory 集成？",
        "intention":"知识问答",
        "reply":"可通过两种方法将 Amazon WorkSpaces 与您的本地 Microsoft Active Directory (AD) 集成：您可以为您的 AWS Microsoft AD 域控制器设置内部信任关系，或者使用 AD Connector 代理 AD 身份验证请求。\n要在您的本地 Microsoft AD 和 AWS Microsoft AD 之间配置内部信任关系，请参阅[此处的文档](http://docs.aws.amazon.com/directoryservice/latest/admin-guide/setup_trust.html)。要配置 AD Connector，请参阅[此处](http://docs.aws.amazon.com/directoryservice/latest/admin-guide/create_ad_connector.html)的文档。\n建立信任后，您可以直接在 Amazon WorkSpaces 控制台中选择用户账户所在的域，然后继续为用户预置 WorkSpaces。请注意，对于每个 AWS Microsoft AD 的实例，域中的用户名必须是独一无二的。"
    },
    {
        "query":"可通过两种方法将 Amazon WorkSpaces 与我的本地 Microsoft Active Directory 集成，我应该使用哪种方法？",
        "intention":"知识问答",
        "reply":"您可以通过两种方法将 Amazon WorkSpaces 与您的本地 Microsoft Active Directory (AD) 集成：为您的 AWS Microsoft AD 域控制器设置内部信任关系，或者使用 AD Connector 代理 AD 身份验证请求。\n使用建立内部信任关系这一方法时，您只需要在本地 AD 和 AWS Microsoft AD 域控制器之间建立一种单一的信任关系即可。您可以将 Amazon WorkSpaces 分配给您的任一本地域中的用户，AWS Microsoft AD 会自动发现身份验证请求并将其路由至相应的域控制器。如果您的环境由多个本地 Microsoft AD 域组成，那么您适合采用这种方法。\n使用 AD Connector 时，您的每个本地 Microsoft AD 域都需要单独的 AD Connector，并且您需要为用户分配 WorkSpaces。使用 AD Connector 这种方法适用于只有一个本地域的环境或概念验证项目。\n有关更多信息，请[访问此页面](https://docs.aws.amazon.com/directoryservice/latest/admin-guide/what_is.html)。"
    },
    {
        "query":"在已与 AWS Microsoft AD 之间建立内部信任关系后，我是否可以使用 Amazon WorkSpaces API 为域中的用户创建新的 WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。使用 Amazon WorkSpaces API 启动 WorkSpaces 时，您需要采用如下格式将域名指定为用户名称的一部分：“NETBIOS\\username”或“corp.example.com\\username”。有关更多信息，请[访问此页面](http://docs.aws.amazon.com/workspaces/latest/adminguide/wsp_create_workspace.html#launch-workspace-trusted-domain)。"
    },
    {
        "query":"是否可以将我的本地 Microsoft Active Directory 的相同组策略对象设置应用于 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。如果您要在本地 Microsoft AD 和 AWS Microsoft AD 域控制器之间建立信任关系，则需要确保您的组策略对象 (GPO) 设置已复制到域中，然后这些设置才能应用于 Amazon WorkSpaces。如果您要使用 AD Connector，那么与您域中的其他任何计算机类似，您的 GPO 设置将应用于您的 WorkSpace。"
    },
    {
        "query":"我能否使用 WorkSpaces 服务为我创建的目录将 Active Directory 策略应用到我的 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"是。有关更多详情，请参阅我们的[文档](http://docs.aws.amazon.com/workspaces/latest/adminguide/managing_a_directory.html)。"
    },
    {
        "query":"如果移除了我的所有 Amazon WorkSpaces，我的目录会出现什么情况？",
        "intention":"知识问答",
        "reply":"您可以将您的 AWS 目录保留在云中，并用它将 EC2 实例[加入域](https://aws.amazon.com/directoryservice/details/#Domain_Join)，或[向目录用户提供](https://aws.amazon.com/directoryservice/details/)对 AWS 管理控制台的访问权。此外，您还可以删除您的目录。\n如果连续 30 天没有 WorkSpaces 用于您的 Simple AD 或 AD Connector，则该目录将自动取消注册，以便在 Amazon WorkSpaces 中使用，并且将根据 AWS Directory Service [定价条款](https://aws.amazon.com/directoryservice/pricing/)向您收取此目录的费用。 如果您删除了 Simple AD 或 AD Connector，当您想重新开始使用 WorkSpaces 时，可以随时创建一个新的 AD 或 AD 连接器。"
    },
    {
        "query":"哪些 AWS Directory Services 支持使用 PCoIP 零客户端？",
        "intention":"知识问答",
        "reply":"PCoIP 零客户端可与 AWS 的 AD Connector 和 Simple AD 目录服务配合使用。目前，零客户端无法与 AWS Directory Service for Microsoft Active Directory 搭配使用。"
    },
    {
        "query":"Amazon CloudWatch 会监控 Amazon WorkSpaces 的哪些方面？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 与 CloudWatch Metrics 和 CloudWatch Events 集成。\n您可以利用 Amazon CloudWatch Metrics 检查各个 WorkSpaces 和一个目录中的所有 WorkSpaces 的运行状况和连接指标。您可以基于这些指标设置 CloudWatch Alarms，以使其在 WorkSpaces 运行状况发生变化时，或者在您的用户无法连接到其 WorkSpaces 时发出警报。\n您可以使用 CloudWatch Events 查看、搜索、下载、存档、分析和响应成功的 WorkSpaces 登录。Amazon WorkSpaces 客户端应用程序在用户成功登录 WorkSpace 时将 WorkSpaces Access 事件发送到 CloudWatch Events。所有 Amazon WorkSpaces 客户端应用程序都会发送这些事件。"
    },
    {
        "query":"我能否监控 Amazon WorkSpaces 的运行小时数？",
        "intention":"知识问答",
        "reply":"可以，通过 Amazon CloudWatch 的“UserConnected”指标，您将能够监控您的 Amazon WorkSpaces 在特定时段内运行的总时数。"
    },
    {
        "query":"可以在哪些区域将 CloudWatch Metrics 用于 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"所有提供 Amazon WorkSpaces 的 [AWS 区域](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)都支持将 CloudWatch Metrics 用于 WorkSpaces。"
    },
    {
        "query":"如何开始将 CloudWatch Metrics 用于我的 Amazon WorkSpaces？",
        "intention":"知识问答",
        "reply":"默认情况下，对所有 WorkSpaces 启用 CloudWatch Metrics。访问 AWS 管理控制台，以查看指标和设置警报。"
    },
    {
        "query":"针对 Amazon WorkSpaces 客户端应用程序和 PCOIP 零客户端，支持哪些指标？",
        "intention":"知识问答",
        "reply":"请参阅[文档](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/wsp-metricscollected.html)，详细了解 Amazon WorkSpaces 的 Amazon CloudWatch 指标。"
    },
    {
        "query":"针对 Amazon WorkSpaces Web Access 使用情况，支持哪些指标？",
        "intention":"知识问答",
        "reply":"目前支持以下指标，用于报告 Amazon WorkSpaces Web Access 使用情况：  \n • Available  \n • Unhealthy  \n • UserConnected  \n • Maintenance\n请参阅[文档](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/wsp-metricscollected.html)，详细了解 Amazon WorkSpaces 的 Amazon CloudWatch 指标。"
    },
    {
        "query":"Amazon WorkSpaces 生成哪些 CloudWatch 事件？",
        "intention":"知识问答",
        "reply":"成功的 WorkSpace 登录。Amazon WorkSpaces 在用户从任何 WorkSpaces 客户端应用程序成功登录 WorkSpace 时将访问事件信息发送到 CloudWatch Events。"
    },
    {
        "query":"如何对 WorkSpaces 利用 CloudWatch Events？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch Events 查看、搜索、下载、存档、分析事件并基于您配置的规则响应事件。您可以使用 CloudWatch 下的 AWS 控制台查看 CloudWatch Events 并与之交互，也可以使用 Lambda、ElasticSearch、Splunk 和其他使用 Kinesis Streams 或 Firehose 的合作伙伴解决方案等服务，根据您的事件数据采取行动。对于存储，CloudWatch Events 建议使用 Kinesis 将数据推送到 S3。有关如何使用 CloudWatch Events 的更多信息，请参阅 [Amazon CloudWatch Events 用户指南](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html)。"
    },
    {
        "query":"WorkSpaces 访问事件包含哪些信息？",
        "intention":"知识问答",
        "reply":"事件表示为 JSON 对象，其中包括 WAN IP 地址、WorkSpaces ID、目录 ID、操作类型（例如登录）、OS 平台、时间戳以及每次成功登录 WorkSpaces 的成功/失败指示符。有关更多详情，请在[此处](https://docs.aws.amazon.com/workspaces/latest/adminguide/cloudwatch-events.html)参阅我们的文档。"
    },
    {
        "query":"能否从 Amazon WorkSpace 进行打印？",
        "intention":"知识问答",
        "reply":"能，搭载 Windows 的 Amazon WorkSpaces 支持本地打印机、网络打印机和云打印服务。搭载 Amazon Linux 的 Amazon WorkSpaces 支持网络打印机和云打印服务。"
    },
    {
        "query":"如何为 Amazon WorkSpace 启用打印机自动重定向功能？",
        "intention":"知识问答",
        "reply":"默认情况下，本地打印机自动重定向被禁用。您可以使用“组策略”设置来启用此功能。这将确保您每次连接到 WorkSpace 时都将本地打印机设置为默认打印机。"
    },
    {
        "query":"我如何用本地打印机进行打印？",
        "intention":"知识问答",
        "reply":"如果您已配置了本地打印机，在您下次连接到 WorkSpace 时，WorkSpaces 打印机菜单中将显示此打印机。如果未配置，则需要在 WorkSpace 之外配置本地打印机。完成配置后，从打印菜单中选择本地打印机，然后选择打印即可。"
    },
    {
        "query":"为什么我看不到打印菜单中的本地打印机？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 已支持大多数打印机。如果您的打印机未予识别，则可能需要在 WorkSpace 上安装适当的设备驱动程序。"
    },
    {
        "query":"我如何用网络打印机进行打印？",
        "intention":"知识问答",
        "reply":"任何与您的 Amazon WorkSpace 位于同一网络中且受 Windows Server 2016/2019 支持的打印机均可以添加为网络打印机。添加网络打印机后，即可在应用程序中选择该打印机进行打印。"
    },
    {
        "query":"我可以在 Amazon WorkSpace 使用云打印服务吗？",
        "intention":"知识问答",
        "reply":"您可以在 WorkSpace 上使用云打印服务，包括但不限于 Cortado ThinPrint®。"
    },
    {
        "query":"我可以从平板电脑或 Chromebook 进行打印吗？",
        "intention":"知识问答",
        "reply":"用于平板电脑和与 Android 兼容的 Chrome OS 设备的 Amazon WorkSpaces 客户端支持云打印服务，包括但不限于 Cortado ThinPrint®。目前不支持本地和网络打印。"
    },
    {
        "query":"Amazon WorkSpaces 提供哪些自助管理功能？",
        "intention":"知识问答",
        "reply":"您可以选择让用户自行完成常见的 WorkSpace 管理任务，包括重新启动、重建、更改计算类型和更改磁盘大小。您还可以让用户从按月结算更改为按小时结算（以及反向更改）。您可以选择直接在 WorkSpaces 管理控制台中启用所需的具体自助管理功能。"
    },
    {
        "query":"我该如何为 WorkSpaces 用户启用自助管理功能？",
        "intention":"知识问答",
        "reply":"使用 WorkSpaces 注册目录时，默认情况下会启用自助管理功能。您可以在注册目录时选择不启用它们。\n您可以通过 WorkSpaces 控制台修改特定自助管理功能。在“目录”页面上，选择要为自助管理修改的目录。接下来，在“操作”菜单下选择“更新详细信息”。您可以在“用户自助服务权限”部分中找到所有自助管理功能选项。您也可以使用 WorkSpaces API 修改自助服务管理功能。"
    },
    {
        "query":"最终用户如何才能访问自助管理功能？",
        "intention":"知识问答",
        "reply":"用户可以通过 Windows、Mac、Android 和 支持 Android 应用程序的 Chrome OS 设备上的 WorkSpaces 客户端使用自助管理功能。"
    },
    {
        "query":"我是否需要登录 WorkSpaces 才能使用自助管理功能？",
        "intention":"知识问答",
        "reply":"是的，您必须通过身份验证才能使用自助管理功能。"
    },
    {
        "query":"在执行自助管理操作期间，我能否继续使用我的 WorkSpace？",
        "intention":"知识问答",
        "reply":"您可以在更改磁盘大小或运行模式期间继续使用 WorkSpace。重新启动、重建、恢复和更改计算类型都需要断开与 WorkSpaces 会话的连接。"
    },
    {
        "query":"如何通过 Amazon WorkSpaces 获得高可用性？",
        "intention":"知识问答",
        "reply":"要减少维护和中断事件造成的停机时间，请在多个区域部署 WorkSpaces，确保区域 WorkSpaces 维护计划不重叠。使用跨区域重定向，以便您可以将用户定向到未进行维护的 WorkSpaces 区域。有关 WorkSpaces 跨区域重定向的更多信息，请参阅 [Amazon WorkSpaces 文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/cross-region-redirection.html \"Amazon WorkSpaces 文档\")。"
    },
    {
        "query":"如何计划 WorkSpaces 的灾难恢复？",
        "intention":"知识问答",
        "reply":"将 WorkSpaces 多区域弹性与跨区域重定向结合使用，在次要 WorkSpaces 区域中部署冗余虚拟桌面基础设施，并设计跨区域失效转移策略，为中断事件做好准备。利用域名系统（DNS）失效转移和运行状况检查功能，WorkSpaces 跨区域重定向可以让您的用户在主要 WorkSpaces 区域无法访问时登录灾难恢复区域中的 WorkSpaces。要了解更多信息，请参阅有关 WorkSpaces 多区域弹性和跨区域重定向的 [Amazon WorkSpaces 文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/business-continuity.html)。"
    },
    {
        "query":"如何通过跨区域重定向定义 WorkSpaces 的主区域和备份区域？",
        "intention":"知识问答",
        "reply":"您可以通过在 DNS 上为 FQDN 配置路由策略来定义区域优先级。有关更多信息，请参阅 [Amazon WorkSpaces 文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/cross-region-redirection.html)。"
    },
    {
        "query":"启用跨区域重定向后，我的旧注册代码还能用吗？",
        "intention":"知识问答",
        "reply":"可以。旧注册代码仍可以使用。用户可以使用旧的注册代码或完全限定的域名 (FQDN) 进行注册。跨区域重定向仅在最终用户使用 FQDN 注册时有效。"
    },
    {
        "query":"我可以将内部域名用于跨区域重定向吗？",
        "intention":"知识问答",
        "reply":"可以。WorkSpaces 跨区域重定向既可以使用公共域名，也可以使用私有 DNS 区域中的域名。如果您的最终用户使用来自公共互联网的私有 FQDN，则 WorkSpaces 客户端将返回错误，报告注册代码无效。"
    },
    {
        "query":"哪些 AWS 区域支持 WorkSpaces 跨区域重定向？",
        "intention":"知识问答",
        "reply":"WorkSpaces 跨区域重定向功能在所有[提供 Amazon WorkSpaces 的 AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)均可使用，AWS GovCloud 和中国区域除外。"
    },
    {
        "query":"哪些客户端类型支持 WorkSpaces 跨区域重定向？",
        "intention":"知识问答",
        "reply":"Windows、macOS 和 Linux WorkSpaces 客户端均支持跨区域重定向。"
    },
    {
        "query":"如何计划 WorkSpaces 的灾难恢复？",
        "intention":"知识问答",
        "reply":"将 WorkSpaces 多区域弹性\\*\\* 与跨区域重定向结合使用，在次要 WorkSpaces 区域中部署冗余虚拟桌面基础设施，并设计跨区域失效转移策略，为中断事件做好准备。利用域名系统（DNS）失效转移和运行状况检查功能，WorkSpaces 跨区域重定向可以让您的用户在主要 WorkSpaces 区域无法访问时登录灾难恢复区域中的 WorkSpaces。要了解更多信息，请参阅 [Amazon WorkSpaces 文档](https://docs.aws.amazon.com/workspaces/latest/adminguide/business-continuity.html)中有关 WorkSpaces 多区域弹性和跨区域重定向的内容。"
    },
    {
        "query":"最新版本的 WSP 支持哪些客户端和主机操作系统？  答：您必须使用支持 WSP 的 WorkSpaces 客户端连接到运行最新 WSP 主机代理的 WorkSpaces 主机。使用下表确定哪些客户端和主机代理支持 WSP 和版本要求。",
        "intention":"知识问答",
        "reply":"|  |  |  |  |\n| --- | --- | --- | --- |\n|  | 操作系统 | WSPv2 支持 | 版本要求 |\n| 主机 | Windows WorkSpace | Y | WSP 主机代理版本 2.0.0.312 或更高版本 |\n| Ubuntu WorkSpace | Y | WSP 主机代理版本 2.1.0.501 或更高版本 |\n| Amazon Linux WorkSpace | Y | WSP 主机代理版本 2.0.0.596 或更高版本 |\n| 客户端 | Windows 原生客户端 | Y | Windows 客户端版本 5.1.0.3029 或更高版本 |\n| macOS 原生客户端 | Y | MacOS 主机代理版本 5.5.0 或更高版本 |\n| Web 访问客户端 | Y | 使用 [Web 访问 URL](https://clients.amazonworkspaces.com/webclient) 登录 |\n| iPad 客户端 | N | 不支持 |\n| Linux 客户端 | N | 不支持 |\n| Android 客户端 | N | 不支持 |\n操作系统\nWSPv2 支持\n版本要求\nWindows WorkSpace\nY\nWSP 主机代理版本 2.0.0.312 或更高版本\nUbuntu WorkSpace\nY\nWSP 主机代理版本 2.1.0.501 或更高版本\nAmazon Linux WorkSpace\nY\nWSP 主机代理版本 2.0.0.596 或更高版本\nWindows 原生客户端\nY\nWindows 客户端版本 5.1.0.3029 或更高版本\nmacOS 原生客户端\nY\nMacOS 主机代理版本 5.5.0 或更高版本\nWeb 访问客户端\nY\n使用 [Web 访问 URL](https://clients.amazonworkspaces.com/webclient) 登录\niPad 客户端\nN\n不支持\nLinux 客户端\nN\n不支持\nAndroid 客户端\nN\n不支持"
    },
    {
        "query":"是否可以在 Amazon WorkSpaces 上使用 Microsoft Office？",
        "intention":"知识问答",
        "reply":"Amazon WorkSpaces 通过 Microsoft Office Professional Plus 捆绑包提供包含实例上预先安装的 Microsoft Office 的许可证。\n问：是否可以从 AWS 为我的 WorkSpaces 购买 Microsoft Office 永久许可证？\nMicrosoft 许可不允许在托管环境（如 WorkSpaces）下转售 AWS 或提供永久许可证。AWS 使用服务提供商许可协议（SPLA），允许 AWS 按月许可符合许可资格的 Microsoft 产品，如 Microsoft Office。在这种情况下，Microsoft Office 许可包含在每月的 WorkSpaces 账单中。"
    },
    {
        "query":"Microsoft Office 2016 和 2019 很快将不受支持。我如何确保我的最终用户能够继续在 Amazon Workspaces 上使用 Microsoft Office？   到 2025 年 10 月 14 日为止，Microsoft 延长支持 Microsoft Office 2016/2019。延长支持到期后，AWS 计划继续提供这些软件包，它们仍有资格接收 Microsoft 的安全更新。",
        "intention":"知识问答",
        "reply":"| 产品 | URL | 主流结束日期 | 延长结束日期 |\n| --- | --- | --- | --- |\n| Microsoft Office 2016 | [https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016](https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016 \"https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016\") | 2020 年 10 月 13 日 | 2025 年 11 月 14 日 |\n| Microsoft Office 2019 | [https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019](https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019 \"https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019\") | 2023 年 10 月 10 日   | 2025 年 10 月 14 日   |\n产品\nURL\n主流结束日期\n延长结束日期\nMicrosoft Office 2016\n[https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016](https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016 \"https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2016\")\n2020 年 10 月 13 日\n2025 年 11 月 14 日\nMicrosoft Office 2019\n[https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019](https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019 \"https://docs.microsoft.com/en-us/lifecycle/products/microsoft-office-2019\")\n2023 年 10 月 10 日\n\n2025 年 10 月 14 日"
    },
    {
        "query":"延长结束日期到期后会发生什么？",
        "intention":"知识问答",
        "reply":"Microsoft Office 2016/2019 延长结束日期到期后，WorkSpaces 的 Office 2016/2019 公共捆绑包也将终止，您无法再使用公共捆绑包启动新的 WorkSpaces。但是，您现有的自定义捆绑包将继续正常运行。您还可以选择将现有自定义捆绑包升级到最新版本的 Microsoft Office，如 Microsoft Office 2021。"
    },
    {
        "query":"延长结束日期到期后，运行 Microsoft Office 2016/2019 的 WorkSpaces 会发生什么？",
        "intention":"知识问答",
        "reply":"您可以继续使用运行 Office 2016/2019 的 WorkSpaces，但是 Office 软件包无法再使用支持或安全更新。"
    },
    {
        "query":"如何从我的 Amazon WorkSpaces 卸载 M365 并使用 Office Professional Plus 捆绑包？",
        "intention":"知识问答",
        "reply":"您可以[将现有 WorkSpaces 迁移](https://docs.aws.amazon.com/workspaces/latest/adminguide/migrate-workspaces.html)到已预先安装 Office 2016 或 2019 的捆绑包。对于 BYOL WorkSpaces，创建带有 Office 2016/2019 订阅的新 BYOL 捆绑包。BYOL 图像摄取过程中，您可以选择通过 AWS 订阅 Microsoft Office Professional 2016（32 位）或 2019（64 位）。对于非 BYOL WorkSpaces，您可以将现有 WorkSpaces 迁移到“Windows Server 2016/2019 Powered WorkSpaces 的 Plus 应用程序捆绑包”。迁移后，您的最终用户将保留其用户卷，同时将使用安装的 Office 2016/2019 重新创建根卷。\n了解有关 Amazon WorkSpaces 定价的更多信息"
    },
    {
        "query":"AWS KMS 提供哪些密钥管理功能？",
        "intention":"知识问答",
        "reply":"您可以执行以下密钥管理功能："
    },
    {
        "query":"当密钥在 AWS KMS 中轮换之后，我是否必须重新加密数据？ 如果您选择让 AWS KMS 自动轮换密钥，则无需重新加密数据。AWS KMS 会自动保留旧版密钥，以用于根据旧版密钥解密已加密的数据。对 AWS KMS 中密钥的所有新加密请求都会按照最新版密钥加密。",
        "intention":"知识问答",
        "reply":"如果您手动轮换导入的密钥或自定义密钥存储密钥，根据您是否要保留旧版密钥，可能需要重新对数据进行加密"
    },
    {
        "query":"我能否从 AWS KMS 中删除密钥？ 可以。您可以设定计划以删除在 AWS KMS 中创建的 AWS KMS 密钥和相关元数据，可配置的等待期为 7 到 30 天。该等待期可帮助您验证删除密钥会对依赖它的应用程序和用户产生何种影响。默认的等待期为 30 天。在等待期内，您可以取消密钥删除操作。计划删除的密钥将无法使用，直到您在等待期内取消删除操作。如果您不取消删除操作，在可配置的等待期结束时，密钥会被删除。一旦密钥被删除，您就无法再使用它。使用被删除的根密钥保护的所有数据将无法访问。",
        "intention":"知识问答",
        "reply":"对于使用导入密钥材料的客户 AWS KMS 密钥，您可以通过两种方式删除密钥材料，而无需删除 AWS KMS 密钥 ID 或元数据。第一，您可以按需删除无等待期的导入密钥材料。第二，在将密钥材料导入 AWS KMS 密钥中时，您可以规定一个到期时间，设定 AWS 在删除您导入的密钥材料前可以使用其多久。如果您需要再次使用，则可以将密钥材料重新导入 AWS KMS 密钥。"
    },
    {
        "query":"在哪些场景下应该使用 AWS Private Certificate Authority（CA），而不是 AWS KMS？ 使用 AWS Private CA 服务的主要原因是提供公共密钥基础设施（PKI），以用于标识实体和保护网络连接。PKI 提供一些流程和机制（主要使用 X.509 证书）围绕着公共密钥加密运算设置结构。证书提供身份和公共密钥之间的关联。证书颁发机构发放证书的认证流程让受信任的证书颁发机构通过对证书签名来声明其他实体的身份。PKI 提供身份、分布式信任、密钥生命周期管理以及通过撤销发布的证书状态。这些功能为 AWS KMS 提供的底层非对称加密密钥和算法增加了重要的流程和基础设施。",
        "intention":"知识问答",
        "reply":"AWS Private CA 可帮助您颁发证书以标识 Web 和应用服务器、服务网格、VPN 用户、内部 API 端点和 AWS IoT Core 设备。证书可帮助您确定这些资源的身份，并创建加密的 TLS/SSL 通信通道。如果您考虑使用非对称密钥来终止 Web 或应用服务器、Elastic Load Balancer、API Gateway 端点、Amazon Elastic Compute Cloud (EC2) 实例或容器上的 TLS，应考虑使用 AWS Private CA 颁发证书和提供 PKI 基础设施。\n相比之下，AWS KMS 可以帮助您生成、管理和使用非对称密钥进行不需要证书的数字签名和加密操作。虽然证书支持在不受信任参与方之间验证发送者和接收者的身份，但 AWS KMS 提供的原始非对称操作类型通常适用于您有其他机制来提供身份，或者不需要证明身份即可获得所需安全益处的情况。"
    },
    {
        "query":"AWS 如何保护我创建的 KMS 密钥？ AWS KMS 旨在确保包括 AWS 员工在内的任何人都无法从该服务中检索您的纯文本 KMS 密钥。AWS KMS 使用已经通过 FIPS 140-2 验证或正在进行验证的硬件安全模块 (HSM) 来保护密钥的机密性和完整性。您的纯文本 KMS 密钥永远不会离开 HSM，也永远不会被写入磁盘中，只会在执行您请求的加密操作期间在 HSM 的易失性内存中使用它。对服务主机上的软件以及 AWS KMS HSM 固件的更新由 Amazon 的内部独立小组以及符合 FIPS 140-2 规定的 NIST 认证的实验审计和审核的多方访问控件控制。",
        "intention":"知识问答",
        "reply":"有关安全控件的更多详细信息，请查看 [AWS KMS 加密详情技术文件](https://docs.aws.amazon.com/kms/latest/cryptographic-details/intro.html)。您还可以查看[适用于 AWS KMS HSM 的 FIPS 140-2 证书](https://csrc.nist.gov/projects/cryptographic-module-validation-program/certificate/4523)以及相关联的[安全策略](https://csrc.nist.gov/CSRC/media/projects/cryptographic-module-validation-program/documents/security-policies/140sp4523.pdf)，以详细了解 AWS KMS HSM 对 FIPS 140-2 的安全要求的满足情况。此外，您还可以请求下载一份由 [AWS Artifact](https://aws.amazon.com/cn/artifact/) 提供的系统和组织控件（SOC）报告，以详细了解该服务用于保护您的 KMS 密钥的安全控件。"
    },
    {
        "query":"使用 AWS KMS 就能符合支付卡行业数据安全标准 (PCI DSS 3.2.1) 中的加密和密钥管理要求吗？ 可以。经过验证，AWS KMS 拥有功能和安全控件，可帮助您满足加密和密钥管理要求（主要涉及 PCI DSS 3.2.1 的第 3.5 和 3.6 节）。",
        "intention":"知识问答",
        "reply":"如需详细了解 AWS 中符合 PCI DSS 规定的服务，请参阅 [PCI DSS 常见问题](https://aws.amazon.com/cn/compliance/pci-dss-level-1-faqs/)。"
    },
    {
        "query":"AWS KMS 与 CloudHSM 相比如何？ CloudHSM 在 Amazon Virtual Private Cloud（VPC）中提供了一个经过验证的单租户 HSM 集群，以存储和使用您的密钥。您对如何通过独立于 AWS 的身份验证机制使用您的密钥拥有独家控制权。您与 CloudHSM 集群中密钥的交互方式与您与 Amazon EC2 中运行的应用程序的交互方式相似。您可以通过 PKCS#11、Java JCE 或 Microsoft CNG 界面使用 CloudHSM 支持各种使用案例，如数字权限管理 (DRM)、公有密钥基础设施 (PKI)、文档签名和加密函数。",
        "intention":"知识问答",
        "reply":"AWS KMS 可帮助您控制您的应用程序和受支持 AWS 产品通过单个控制台在全世界多个区域使用的加密密钥。该服务使用已经或正在申请获得 FIPS 140-2 验证的 FIPS HSM 来保护您的密钥的安全性。在 AWS KMS 中对您所有的密钥进行集中化管理有助于您实施关于谁能在何种条件下使用您的密钥、它们何时轮换以及谁能管理它们的策略。AWS KMS 与 CloudTrail 的集成，使您能够审计您的密钥使用情况，以支持法规和合规性活动。如果您要通过[与 AWS KMS 集成的其他 AWS 服务](https://aws.amazon.com/cn/kms/features/#AWS_Service_Integration)直接调用服务 API，请使用 AWS 开发工具包通过您的应用程序与 AWS KMS 交互，如果您要执行客户端加密，请使用 [AWS Encryption SDK](https://docs.aws.amazon.com/encryption-sdk/latest/developer-guide/introduction.html) 通过您的应用程序与 AWS KMS 交互。"
    },
    {
        "query":"如何将 AWS KMS 连接到 CloudHSM？ AWS KMS 自定义密钥存储功能既有 CloudHSM 的控制能力，又有 AWS KMS 的集成性和易用性。您可以配置自己的 CloudHSM 集群，并授权 AWS KMS 将其用作您的密钥的专用密钥存储，而不是默认 AWS KMS 密钥存储。当您在 AWS KMS 中创建密钥时，可以选择在您的 CloudHSM 集群中生成密钥材料。在自定义密钥存储中生成的 KMS 密钥绝对不会以纯文本形式离开 CloudHSM 集群中的 HSM，所有使用这些密钥的 AWS KMS 操作都仅在 HSM 中执行。在所有其他方面，存储在您的自定义密钥存储中的 KMS 密钥都与其他 AWS KMS 密钥一致。",
        "intention":"知识问答",
        "reply":"确定自定义密钥存储是否适用于您的其他指南可以在此[博客](https://aws.amazon.com/blogs/security/are-kms-custom-key-stores-right-for-you/)中找到。"
    },
    {
        "query":"我已经将 AWS KMS 与标准 KMS 密钥、导入的 KMS 密钥或存储在 CloudHSM 集群中的密钥一起使用。我可以将这些 KMS 密钥迁移到 XKS 或重新加密 XKS 密钥下的现有加密密钥吗？ 所有 XKS 密钥都必须在 KMS 中作为新密钥创建。不能将现有的 KMS 密钥迁移到外部密钥管理器中托管的 XKS 密钥中。",
        "intention":"知识问答",
        "reply":"假设 AWS 服务或您自己的应用程序支持该操作，您可以在新生成的 XKS 密钥下重新加密现有数据。许多 AWS 服务都可以帮助您复制加密的资源，并指定一个新的 KMS 密钥来加密副本。您可以在 AWS 服务提供的 COPY 命令中配置 XKS 密钥。通过调用 KMS ReEncrypt API 并配置 XKS 密钥，您可以在自己的应用程序中重新加密客户端加密数据。"
    },
    {
        "query":"我可以为 XKS 密钥构建哪些类型的授权策略？ 用于其他 KMS 密钥的所有常见 AWS KMS 授权机制（IAM 策略、AWS KMS 密钥策略、授权）均可以相同的工作方式用于外部密钥存储中的 KMS 密钥。",
        "intention":"知识问答",
        "reply":"此外，您和/或您的外部密钥管理器合作伙伴能够基于从 AWS KMS 发送到 XKS 代理的每个请求中包含的请求元数据来实施第二层授权控制。这些元数据包括调用 AWS 用户/角色、KMS 密钥 ARN 和请求的特定 KMS API。这使得您可以在外部密钥管理器中对密钥的使用应用细粒度授权策略，而不仅仅是信任来自 AWS KMS 的任何请求。使用这些请求属性的策略执行选择由您的单个 XKS 代理实现决定。"
    },
    {
        "query":"如果我选择 XKS 而不是使用 AWS KMS 中生成和存储的标准 KMS 密钥，我需要承担哪些风险？ 可用性风险：  您负责 XKS 代理和外部密钥材料的可用性。该系统必须具有高可用性，以验证无论何时您需要 XKS 密钥来解密加密资源或加密新数据，AWS KMS 都可以成功连接到 XKS 代理，而 XKS 代理本身可以连接到您的外部密钥管理器，以使用密钥完成必要的加密操作。例如，假设您使用 XKS 密钥加密了 EBS 卷，现在您想启动 EC2 实例并附加该加密卷。EC2 服务将向 AWS KMS 传递该卷的唯一加密数据密钥，以对其进行解密，以便在 Nitro 卡的易失性存储器中提供该密钥，以便对该卷的读/写操作进行解密和加密。如果 XKS 代理或外部密钥管理器无法用于解密卷密钥，则 EC2 实例将无法启动。在这些类型的故障中，AWS KMS 会返回 KMSInvalidStateException，指出 XKS 代理不可用。现在，您可以根据 KMS 提供的错误消息来确定 XKS 代理和密钥管理器不可用的原因。",
        "intention":"知识问答",
        "reply":"耐久性风险：因为在 AWS 以外的系统中，密钥由您控制，因此您对创建的所有外部密钥的耐久性全权负责。如果 XKS 密钥的外部密钥永久丢失或删除，则在 XKS 密钥下加密的所有加密文字都不可恢复。\n性能风险：您负责验证 XKS 代理和外部密钥存储基础设施的设计是否具有足够的性能特征，以满足您的需求。由于使用 XKS 密钥的每个请求都需要连接到外部密钥存储，因此如果 AWS KMS 的请求速率超过 XKS 代理或外部密钥管理器可以支持的请求速率，XKS 代理可能会成为瓶颈。此外，如果从 AWS KMS 到 XKS 代理的单个请求（包括一次重试）所用的时间超过 500ms\\*，AWS KMS 将向其调用客户端返回 400 错误，从而有效地通知您的 XKS 密钥不可用，调用客户端不应重试。此行为旨在最大限度地降低上游 AWS 服务或您自己的应用程序对基础设施连接问题导致的偶发过度延迟做出反应的风险。\n\\*AWS KMS 将尝试对任何需要 250ms 的请求进行一次重试。如果重试请求的时间也超过 250ms，则将向调用客户端返回 400 错误。"
    },
    {
        "query":"What is the typical deployment model for AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports two primary deployment types: centralized and distributed. When distributed, the AWS Network Firewall can be deployed within each of your [Amazon VPCs](https://aws.amazon.com/vpc/) for enforcement closer to the applications. AWS Network Firewall also supports a centralized deployment as a VPC attachment to your [AWS Transit Gateway](https://aws.amazon.com/transit-gateway/). With the Network Firewall in Transit Gateway mode, which maintains symmetric routing to the same zonal firewall, you can filter a variety of inbound and outbound traffic to or from Internet Gateways, Direct Connect gateways, PrivateLink, VPN Site-to-Site and Client gateways, NAT gateways, and even between other attached VPCs and subnets."
    },
    {
        "query":"How do I enable AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall is deployed as an endpoint service, similar to other network services such as AWS PrivateLink. Your AWS Network Firewall endpoint must be deployed in a dedicated subnet within your Amazon VPC, with a minimum size of /28. AWS Network Firewall inspects all traffic that is routed to the endpoint, which is the mechanism for path insertion and filtering. Through the AWS Firewall Manager Console, or through partner solutions that integrate with AWS Firewall Manager, you can centrally build configurations and policies using various rule types, such as stateless access control lists (ACLs), stateful inspection, and intrusion prevention systems (IPSs). Because AWS Network Firewall is an AWS managed service, AWS takes care of scaling, availability, resiliency, and software updates."
    },
    {
        "query":"Can AWS Network Firewall manage security across multiple AWS accounts?",
        "intention":"知识问答",
        "reply":"Yes. AWS Network Firewall is a regional service and secures network traffic at an organization and account level. For maintaining policy and governance across multiple accounts, you may want to use [AWS Firewall Manager](https://aws.amazon.com/firewall-manager/)."
    },
    {
        "query":"What’s a firewall policy?",
        "intention":"知识问答",
        "reply":"An AWS Network Firewall policy defines the monitoring and protection behavior of a firewall. The details of that behavior are defined in the rule groups that you add to your policy or in certain default policy settings. To use a firewall policy, you associate the policy with one or more firewalls."
    },
    {
        "query":"What types of firewall rules are supported?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports both stateless and stateful rules. Stateless rules consist of network access control lists (ACLs), which can be based on source and destination IP addresses, ports, or protocols. Stateful, or Layer-4, rules are also defined by source and destination IP addresses, ports, and protocols but differ from stateless rules in that they maintain and secure connections or sessions throughout the life of the connection or session."
    },
    {
        "query":"What’s a rule group?",
        "intention":"知识问答",
        "reply":"A rule group is a reusable set of firewall rules for inspecting and filtering network traffic. You can use stateless or stateful rule groups to configure the traffic inspection criteria for your firewall policies. You can create your own rule groups or you can use rule groups that are managed by AWS Marketplace Sellers. For more information, please refer to the [AWS Network Firewall Developer Guide](https://docs.aws.amazon.com/network-firewall/latest/developerguide/)."
    },
    {
        "query":"Which AWS tools can I use to log and monitor my AWS Network Firewall activity?",
        "intention":"知识问答",
        "reply":"You can log your AWS Network Firewall activity to an Amazon S3 bucket for further analysis and investigation. You can also use Amazon Kinesis Firehose to port your logs to a third-party provider."
    },
    {
        "query":"Can I use AWS Network Firewall with my Transit Gateway (TGW)?",
        "intention":"知识问答",
        "reply":"Yes. You can deploy AWS Network Firewall within your VPC and then attach that VPC to a TGW. For more information about this configuration, see the [Deployment models for AWS Network Firewall](https://aws.amazon.com/blogs/networking-and-content-delivery/deployment-models-for-aws-network-firewall/) blog post."
    },
    {
        "query":"Can I use AWS Network Firewall with AWS Gateway Load Balancer (GWLB)?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall already uses AWS Gateway Load Balancer to provide elastic scalability for the firewall endpoint and does not require separate integration. You can observe this by checking the firewall endpoint elastic network interface (ENI), which uses “gateway\\_load\\_balancer\\_endpoint” type."
    },
    {
        "query":"Which types of outbound traffic control does AWS Network Firewall support?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports the following types of outbound traffic control: HTTPS (SNI)/HTTP protocol URL filtering, Access Control Lists (ACLs), DNS query, and protocol detection."
    },
    {
        "query":"Can AWS Network Firewall inspect encrypted traffic?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall does support deep packet inspection for encrypted traffic."
    },
    {
        "query":"How do I configure TLS inspection on AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"You can configure AWS Network Firewall TLS inspection from either the Amazon VPC Console or the Network Firewall API. Set up is a 3-step process. Follow the steps in the AWS Network Firewall service documentation to 1) provision certificates and keys, 2) create a TLS inspection configuration, and 3) apply the configuration to a firewall policy."
    },
    {
        "query":"Which TLS versions does AWS Network Firewall support?",
        "intention":"知识问答",
        "reply":"The service supports TLS version 1.1, 1.2, and 1.3 with the exception of encrypted client hello (ECH) and encrypted SNI (ESNI)."
    },
    {
        "query":"Which cipher suites are supported by AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports all cipher suites supported by AWS Certificate Manager (ACM). Refer to TLS inspection considerations in the service documentation for details."
    },
    {
        "query":"Is there any additional cost to use TLS inspection?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall pricing is based on the number of firewalls deployed and the amount of traffic inspected. Please visit AWS Network Firewall Pricing for more information about ingress TLS inspection cost."
    },
    {
        "query":"Are there any known performance implications for TLS inspection?",
        "intention":"知识问答",
        "reply":"We expect to maintain the current AWS Network Firewall bandwidth performance with this new feature release. We recommend that customers conduct their own testing using their rulesets to ensure the service meets their performance expectations."
    },
    {
        "query":"What is AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall is a managed service that makes it easy to deploy essential network protections for all of your Amazon Virtual Private Clouds (VPCs). The service can be set up with just a few clicks and scales automatically with your network traffic so you don't have to worry about deploying and managing any infrastructure. Network Firewall’s flexible rules engine lets you define firewall rules that give you fine-grained control over network traffic, such as blocking outbound Server Message Block (SMB) requests to prevent the spread of malicious activity. You can also import rules you’ve already written in common open source rule formats or import compatible rules sourced from AWS partners. AWS Network Firewall works together with AWS Firewall Manager so you can build policies based on AWS Network Firewall rules and then centrally apply those policies across your VPCs and accounts."
    },
    {
        "query":"What are the key benefits of AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"The AWS Network Firewall infrastructure is managed by AWS, so you don’t have to worry about building and maintaining your own network security infrastructure. AWS Network Firewall works with AWS Firewall Manager, so you can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. AWS Network Firewall has a highly flexible rules engine, so you can build custom firewall rules to protect your unique workloads. AWS Network Firewall supports thousands of rules, and the rules can be based on domain, port, protocol, IP addresses, and pattern matching."
    },
    {
        "query":"How does AWS Network Firewall protect my VPC?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall includes features that protect from common network threats. AWS Network Firewall’s stateful firewall can incorporate context from traffic flows, like tracking connections and protocol identification, to enforce policies such as preventing your VPCs from accessing domains using an unauthorized protocol. AWS Network Firewall’s intrusion prevention system (IPS) provides active traffic flow inspection so you can identify and block vulnerability exploits using signature-based detection. AWS Network Firewall also offers web filtering that can stop traffic to known-bad URLs and monitor fully qualified domain names."
    },
    {
        "query":"When should I use AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall gives you control and visibility of VPC-to-VPC traffic to logically separate networks hosting sensitive applications or line-of-business resources. AWS Network Firewall provides URL, IP address, and domain-based outbound traffic filtering to help you meet compliance requirements, stop potential data leaks, and block communication with known malware hosts. AWS Network Firewall secures AWS Direct Connect and AWS VPN traffic running through AWS Transit Gateway from client devices and your on-premises environments. AWS Network Firewall protects application availability by filtering inbound Internet traffic using features such as Access Control List (ACL) rules, stateful inspection, protocol detection, and intrusion prevention."
    },
    {
        "query":"Can I use AWS Network Firewall for protection against DDoS attacks?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall is designed to protect and control access to and from your VPC, but not to mitigate volumetric attacks, like distributed denial of service (DDoS), that can impact the availability of your application. To protect against DDoS attacks and ensure application availability, we recommend customers review and adhere to our [AWS Best Practices for DDoS Resiliency](https://docs.aws.amazon.com/whitepapers/latest/aws-best-practices-ddos-resiliency/welcome.html), and also explore [AWS Shield Advanced](https://aws.amazon.com/shield/), which offers managed DDoS protection customized to your specific application traffic."
    },
    {
        "query":"How is AWS Network Firewall different from other firewall offerings on AWS and the AWS Marketplace?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall complements existing network and application security services on AWS by providing control and visibility to Layer 3-7 network traffic for your entire VPC. Depending on your use case, you may choose to implement AWS Network Firewall along your existing security controls, such as Amazon VPC Security Groups, AWS Web Application Firewall rules, or AWS Marketplace appliances."
    },
    {
        "query":"How much does AWS Network Firewall cost?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall pricing is based on the number of firewalls deployed and the amount of traffic inspected. Please visit [AWS Network Firewall Pricing](https://aws.amazon.com/network-firewall/pricing/) for more information."
    },
    {
        "query":"In which AWS regions is AWS Network Firewall available?",
        "intention":"知识问答",
        "reply":"For more information on regional availability for AWS Network Firewall, see the [AWS region table](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)."
    },
    {
        "query":"Which partners have solutions that work with AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"A number of AWS Partner Network (APN) Partners offer products that complement existing AWS services to enable you to deploy a seamless and comprehensive security architecture across AWS and your on-premises environment. For a current list of APN Partners offering products that complement AWS Network Firewall, see [AWS Network Firewall partners](https://aws.amazon.com/network-firewall/partners/)."
    },
    {
        "query":"Does AWS Network Firewall offer a Service Level Agreement?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall offers a [Service Level Agreement](https://aws.amazon.com/network-firewall/sla/) with an uptime commitment of 99.99%. AWS Network Firewall enables you to automatically scale your firewall capacity up or down based on traffic load to maintain steady, predictable performance to minimize costs."
    },
    {
        "query":"What are the service quotas for AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall is subject to service quotas for the number of firewalls, firewall policies, and rules groups that you can create and for other settings, such as the number of stateless or stateful rule groups you can have in a single firewall policy. For additional details about service quotas, including information about how to request a service quota increase, see the [AWS Network Firewall quotas page](https://docs.aws.amazon.com/network-firewall/latest/developerguide/quotas.html)."
    },
    {
        "query":"What is the typical deployment model for AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports two primary deployment types: centralized and distributed. When distributed, the AWS Network Firewall can be deployed within each of your [Amazon VPCs](https://aws.amazon.com/vpc/) for enforcement closer to the applications. AWS Network Firewall also supports a centralized deployment as a VPC attachment to your [AWS Transit Gateway](https://aws.amazon.com/transit-gateway/). With the Network Firewall in Transit Gateway mode, which maintains symmetric routing to the same zonal firewall, you can filter a variety of inbound and outbound traffic to or from Internet Gateways, Direct Connect gateways, PrivateLink, VPN Site-to-Site and Client gateways, NAT gateways, and even between other attached VPCs and subnets."
    },
    {
        "query":"How do I enable AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall is deployed as an endpoint service, similar to other network services such as AWS PrivateLink. Your AWS Network Firewall endpoint must be deployed in a dedicated subnet within your Amazon VPC, with a minimum size of /28. AWS Network Firewall inspects all traffic that is routed to the endpoint, which is the mechanism for path insertion and filtering. Through the AWS Firewall Manager Console, or through partner solutions that integrate with AWS Firewall Manager, you can centrally build configurations and policies using various rule types, such as stateless access control lists (ACLs), stateful inspection, and intrusion prevention systems (IPSs). Because AWS Network Firewall is an AWS managed service, AWS takes care of scaling, availability, resiliency, and software updates."
    },
    {
        "query":"Can AWS Network Firewall manage security across multiple AWS accounts?",
        "intention":"知识问答",
        "reply":"Yes. AWS Network Firewall is a regional service and secures network traffic at an organization and account level. For maintaining policy and governance across multiple accounts, you may want to use [AWS Firewall Manager](https://aws.amazon.com/firewall-manager/)."
    },
    {
        "query":"What’s a firewall policy?",
        "intention":"知识问答",
        "reply":"An AWS Network Firewall policy defines the monitoring and protection behavior of a firewall. The details of that behavior are defined in the rule groups that you add to your policy or in certain default policy settings. To use a firewall policy, you associate the policy with one or more firewalls."
    },
    {
        "query":"What types of firewall rules are supported?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports both stateless and stateful rules. Stateless rules consist of network access control lists (ACLs), which can be based on source and destination IP addresses, ports, or protocols. Stateful, or Layer-4, rules are also defined by source and destination IP addresses, ports, and protocols but differ from stateless rules in that they maintain and secure connections or sessions throughout the life of the connection or session."
    },
    {
        "query":"What’s a rule group?",
        "intention":"知识问答",
        "reply":"A rule group is a reusable set of firewall rules for inspecting and filtering network traffic. You can use stateless or stateful rule groups to configure the traffic inspection criteria for your firewall policies. You can create your own rule groups or you can use rule groups that are managed by AWS Marketplace Sellers. For more information, please refer to the [AWS Network Firewall Developer Guide](https://docs.aws.amazon.com/network-firewall/latest/developerguide/)."
    },
    {
        "query":"Which AWS tools can I use to log and monitor my AWS Network Firewall activity?",
        "intention":"知识问答",
        "reply":"You can log your AWS Network Firewall activity to an Amazon S3 bucket for further analysis and investigation. You can also use Amazon Kinesis Firehose to port your logs to a third-party provider."
    },
    {
        "query":"Can I use AWS Network Firewall with my Transit Gateway (TGW)?",
        "intention":"知识问答",
        "reply":"Yes. You can deploy AWS Network Firewall within your VPC and then attach that VPC to a TGW. For more information about this configuration, see the [Deployment models for AWS Network Firewall](https://aws.amazon.com/blogs/networking-and-content-delivery/deployment-models-for-aws-network-firewall/) blog post."
    },
    {
        "query":"Can I use AWS Network Firewall with AWS Gateway Load Balancer (GWLB)?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall already uses AWS Gateway Load Balancer to provide elastic scalability for the firewall endpoint and does not require separate integration. You can observe this by checking the firewall endpoint elastic network interface (ENI), which uses “gateway\\_load\\_balancer\\_endpoint” type."
    },
    {
        "query":"Which types of outbound traffic control does AWS Network Firewall support?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports the following types of outbound traffic control: HTTPS (SNI)/HTTP protocol URL filtering, Access Control Lists (ACLs), DNS query, and protocol detection."
    },
    {
        "query":"Can AWS Network Firewall inspect encrypted traffic?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall does support deep packet inspection for encrypted traffic."
    },
    {
        "query":"How do I configure TLS inspection on AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"You can configure AWS Network Firewall TLS inspection from either the Amazon VPC Console or the Network Firewall API. Set up is a 3-step process. Follow the steps in the AWS Network Firewall service documentation to 1) provision certificates and keys, 2) create a TLS inspection configuration, and 3) apply the configuration to a firewall policy."
    },
    {
        "query":"Which TLS versions does AWS Network Firewall support?",
        "intention":"知识问答",
        "reply":"The service supports TLS version 1.1, 1.2, and 1.3 with the exception of encrypted client hello (ECH) and encrypted SNI (ESNI)."
    },
    {
        "query":"Which cipher suites are supported by AWS Network Firewall?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall supports all cipher suites supported by AWS Certificate Manager (ACM). Refer to TLS inspection considerations in the service documentation for details."
    },
    {
        "query":"Is there any additional cost to use TLS inspection?",
        "intention":"知识问答",
        "reply":"AWS Network Firewall pricing is based on the number of firewalls deployed and the amount of traffic inspected. Please visit AWS Network Firewall Pricing for more information about ingress TLS inspection cost."
    },
    {
        "query":"Are there any known performance implications for TLS inspection?",
        "intention":"知识问答",
        "reply":"We expect to maintain the current AWS Network Firewall bandwidth performance with this new feature release. We recommend that customers conduct their own testing using their rulesets to ensure the service meets their performance expectations."
    },
    {
        "query":"什么是 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 是一种安全的托管型商务电子邮件与日历服务，支持现有的桌面和移动客户端。通过 Amazon WorkMail，用户能够使用 Microsoft Outlook、Web 浏览器或其本机 iOS 和 Android 电子邮件应用程序无缝访问电子邮件、通讯录和日历。您可以将 Amazon WorkMail 与您现有的公司目录相集成，同时还能控制用于加密数据的密钥以及用于存储数据的位置。"
    },
    {
        "query":"如何开始使用 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"您需要一个 [AWS 账户](https://aws-portal.amazon.com/gp/aws/developer/registration/index.html)才能开始使用 Amazon WorkMail。您可以使用此账户登录 [AWS 管理控制台](https://console.aws.amazon.com/workmail)并创建一个组织，添加您的域，以及创建用户、组或资源。有关入门的更多信息，请参阅 [Amazon WorkMail 文档](https://aws.amazon.com/documentation/workmail/)。"
    },
    {
        "query":"我可以使用哪些客户端来访问 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"您可以从 Windows、Mac OS X 设备和支持 Microsoft Exchange ActiveSync 协议的移动设备（包括 iPhone、iPad、Kindle Fire、Fire Phone、Android、Windows Phone 以及 BlackBerry 10）上的 Microsoft Outlook 客户端访问 Amazon WorkMail。此外，您也可以使用 Mac OS X 上的 Apple Mail 应用程序或者使用 Amazon WorkMail Web 应用程序通过 Web 浏览器安全地访问 Amazon WorkMail。"
    },
    {
        "query":"Amazon WorkMail 是否支持辅助功能？",
        "intention":"知识问答",
        "reply":"支持，您可以将屏幕读取器和键盘快捷键与 Amazon WorkMail Web 应用程序结合使用以实现更轻松的访问；您可以在“使用辅助功能”文档页面（单击[此处](http://docs.aws.amazon.com/workmail/latest/userguide/accessibility.html)）了解有关这些功能的更多信息。此外，受支持桌面和移动客户端（参见下面的列表）中提供的可访问性功能还可与 Amazon WorkMail 配合使用。"
    },
    {
        "query":"Amazon WorkMail 中的邮箱存储限制是多大？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 提供的邮箱存储大小限制为 50GB。"
    },
    {
        "query":"从 Amazon WorkMail 最大能发送多大的电子邮件？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 的出站和进站电子邮件最大大小为 29MB 未编码数据。消息以 MIME 格式发送和接收。出站和进站 MIME 消息的最大大小为 40MB。"
    },
    {
        "query":"我能否与我所在组织的其他用户共享我的日历？",
        "intention":"知识问答",
        "reply":"能。Amazon WorkMail 提供与同事共享日历的功能。"
    },
    {
        "query":"Amazon WorkMail 是否提供资源预定？",
        "intention":"知识问答",
        "reply":"是的。Amazon WorkMail 可提供创建会议室、投影仪和其他设备等资源邮箱的选项。通过资源邮箱，用户将能够把资源包含在会议邀请中，从而预留房间或设备。"
    },
    {
        "query":"Amazon WorkMail 是否支持电子邮件归档？",
        "intention":"知识问答",
        "reply":"可以启用电子邮件日志功能，以捕获和保存现有归档解决方案中的消息。"
    },
    {
        "query":"是否可以在 Amazon WorkMail 上设置电子邮件重定向规则？",
        "intention":"知识问答",
        "reply":"可以，您可以为 Amazon WorkMail 邮箱配置电子邮件重定向规则。您可以在桌面电子邮件应用程序 (如 Microsoft Outlook) 中设置电子邮件重定向规则，也可以使用 Amazon WorkMail Web 应用程序来设置。您需要确保您的域的 Amazon Simple Email Service (Amazon SES) 身份策略处于最新状态，以便利用电子邮件重定向规则。请访问[此](http://docs.aws.amazon.com/workmail/latest/adminguide/editing_domains.html)页面，详细了解如何更新您的域的 Amazon SES 身份策略。"
    },
    {
        "query":"使用 Amazon WorkMail 时，我可以创建的组织和用户数量有限制吗？",
        "intention":"知识问答",
        "reply":"没有，您可以创建的组织和用户数量没有限制。"
    },
    {
        "query":"我可以向每个用户发送的邮件数量有限制吗？",
        "intention":"知识问答",
        "reply":"只有发送外部邮件时才有限制，例如，发送到您的组织之外的收件人的邮件数量。组织中的每个用户每天可以向最多 10000 个外部收件人发送邮件，且 AWS 账户的外部收件人总数每天限制为 100000 人。新 Amazon WorkMail 账户的限制最初可能会低于此处所描述的限制；请参阅 [AWS Service Limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_workmail) 了解更多信息。\nAmazon WorkMail 是一种企业电子邮件服务，并不专门用于批量电子邮件服务。对于批量电子邮件服务，请参阅 [Amazon Simple Email Service](https://aws.amazon.com/cn/ses/)。"
    },
    {
        "query":"使用 Amazon WorkMail SMTP 网关有什么限制吗？",
        "intention":"知识问答",
        "reply":"有。如需详细了解使用 SMTP 的限制条件，请参阅 [AWS Service Limits](http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_workmail)。"
    },
    {
        "query":"每个用户可以接收的邮件数量有限制吗？",
        "intention":"知识问答",
        "reply":"每个用户可以接收的邮件数量没有限制。但是，如果在短时间内有大量电子邮件进入，我们可能会使邮件排队等待或拒绝（并向发件人发送退信）。请参阅 [AWS Service Limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_workmail)了解更多信息。"
    },
    {
        "query":"评估使用情况时会议请求是否计入邮件限制？",
        "intention":"知识问答",
        "reply":"评估这些限制时，会考虑发送给其他用户的所有邮件。其中包括电子邮件、会议请求、会议响应、任务请求，以及按照规则自动转发或重定向的所有邮件。"
    },
    {
        "query":"Amazon WorkMail 是否支持公用文件夹？",
        "intention":"知识问答",
        "reply":"不支持，WorkMail 没有提供公用文件夹。"
    },
    {
        "query":"Amazon WorkMail Web 应用程序提供哪些功能？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail Web 应用程序提供用户随处访问电子邮件、日历、联系人和任务的权限。用户还可以访问共享日历、访问全球地址簿、管理自动回复和预定资源。"
    },
    {
        "query":"Amazon WorkMail Web 应用程序可用于哪些浏览器？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail Web 应用程序支持以下浏览器，包括 Firefox、Chrome、Safari 和 Edge。有关更多信息，请参阅[登录 Amazon WorkMail Web 应用程序](http://docs.aws.amazon.com/workmail/latest/userguide/using_web_application.html)。"
    },
    {
        "query":"Amazon WorkMail Web 应用程序提供哪些语言版本？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail Web 应用程序目前提供英语、法语和俄语版本。"
    },
    {
        "query":"我能否在移动设备上使用 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"能。Amazon WorkMail 与大多数支持 Microsoft Exchange ActiveSync 协议的主要移动设备兼容，包括 iPad、iPhone、Kindle Fire、Fire Phone、Android、Windows Phone 和 BlackBerry 10。"
    },
    {
        "query":"Amazon WorkMail 支持什么移动设备策略？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 让您能够要求在设备上设置 PIN 码或密码、配置密码的强度、要求尝试登录几次后锁住设备以及要求给设备与存储卡加密。"
    },
    {
        "query":"Amazon WorkMail 是否提供远程擦除移动设备的功能？",
        "intention":"知识问答",
        "reply":"提供。Amazon WorkMail 提供远程擦除功能。远程擦除操作可由 IT 管理员通过 AWS 管理控制台执行。"
    },
    {
        "query":"我能否在 Microsoft Windows 上将 Amazon WorkMail 与 Microsoft Outlook 配合使用？",
        "intention":"知识问答",
        "reply":"能。Amazon WorkMail 可为 Microsoft Windows 上的 Microsoft Outlook 2007、2010、2013 和 2016 提供原生支持。"
    },
    {
        "query":"连接 Microsoft Outlook 与 Amazon WorkMail 时是否需要任何其他软件？",
        "intention":"知识问答",
        "reply":"不需要，Amazon WorkMail 可为最新版的 Microsoft Outlook 提供原生支持，连接 Microsoft Outlook 时不需要任何其他软件。"
    },
    {
        "query":"我能否在 Mac OS X 上将 Amazon WorkMail 与 Microsoft Outlook 配合使用？",
        "intention":"知识问答",
        "reply":"可以。Amazon WorkMail 可以在 Mac OS X 上为 Microsoft Outlook 2011 和 Microsoft Outlook 2016 提供本机支持。"
    },
    {
        "query":"我能否在 Mac OS X 上将 Amazon WorkMail 与其他客户端配合使用？",
        "intention":"知识问答",
        "reply":"能。Amazon WorkMail 可为 Mac OS X（10.6 及以上版本）上的 Apple Mail 和日历应用程序提供原生支持。"
    },
    {
        "query":"Amazon WorkMail 用户订阅是否包含 Microsoft Outlook 许可证？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 不包含 Microsoft Outlook 许可证。要将 Microsoft Outlook 与 Amazon WorkMail 配合使用，您必须从 Microsoft 获得有效的许可证。"
    },
    {
        "query":"Amazon WorkMail 是否支持 Microsoft Outlook 2010、2013 和 2016 的即点即用版本？",
        "intention":"知识问答",
        "reply":"支持。Amazon WorkMail 支持 Microsoft Outlook 2010、2013 和 2016 的即点即用版本。"
    },
    {
        "query":"我可以使用现有的 POP3 或 IMAP 客户端应用程序访问我的 Amazon WorkMail 邮箱吗？",
        "intention":"知识问答",
        "reply":"您可以使用支持 IMAP 协议的客户端应用程序访问您的 Amazon WorkMail 邮箱。Amazon WorkMail 目前不支持访问基于 POP3 协议的电子邮件。"
    },
    {
        "query":"使用 IMAP 客户端应用程序时，是否可以访问 Amazon WorkMail 邮箱中的所有项目？",
        "intention":"知识问答",
        "reply":"IMAP 协议支持对电子邮件的访问，但不支持对日历项、联系人、备注或任务的访问。"
    },
    {
        "query":"使用 IMAP 客户端应用程序时，是否可以看到所有的电子邮件文件夹？",
        "intention":"知识问答",
        "reply":"是的。您可以看到包含电子邮件的所有文件夹并可以使用 IMAP 客户端应用程序访问这些文件夹。"
    },
    {
        "query":"我如何使用 IMAP 电子邮件客户端应用程序发送电子邮件？",
        "intention":"知识问答",
        "reply":"您可以通过配置 IMAP 电子邮件客户端，以使用 Amazon WorkMail SMTP 网关发送电子邮件。Amazon WorkMail SMTP 地址显示在 [AWS 区域和终端节点](https://docs.aws.amazon.com/general/latest/gr/rande.html#wm_region)中。"
    },
    {
        "query":"什么是 Amazon WorkMail SMTP 网关？",
        "intention":"知识问答",
        "reply":"简单邮件传输协议 (SMTP) 网关是一个 Amazon WorkMail 服务，借助此服务，您可以提交电子邮件信息，将它同时发送至内部和外部收件人。有关更多信息，请参阅[连接您的客户端 IMAP 应用程序](https://docs.aws.amazon.com/workmail/latest/userguide/using_IMAP_client.html)。"
    },
    {
        "query":"借助 Amazon WorkMail SMTP 网关，我可以使用什么电子邮件客户端应用程序发送电子邮件？",
        "intention":"知识问答",
        "reply":"借助 Amazon WorkMail SMTP 网关，您可以使用任何支持 SMTP 协议的电子邮件客户端发送电子邮件，其中包括 Microsoft Outlook、Apple Mail 或 Mozilla Thunderbird 等热门电子邮件客户端。"
    },
    {
        "query":"要使用 Amazon WorkMail 服务，是否需要设置目录？",
        "intention":"知识问答",
        "reply":"您添加到您的 Amazon WorkMail 组织的每个用户都需要包含在目录中，但您不必自行预配置目录。您可以通过 AWS Directory Service AD 连接器将现有 Microsoft Active Directory 与 Amazon WorkMail 集成，也可以运行 AWS Directory Service for Microsoft Active Directory Enterprise Edition (“Microsoft AD”)，这样您就不必管理两个地方的用户，用户也可以继续使用其现有的 Microsoft Active Directory 凭证。或者，您也可以让 Amazon WorkMail 为您创建和管理 Simple AD 目录，并在将用户添加到您的 Amazon WorkMail 组织时创建该目录中的用户。"
    },
    {
        "query":"如何与现有的 Microsoft Active Directory 相集成？",
        "intention":"知识问答",
        "reply":"您可以通过设置 AWS Directory Service AD Connector 或 Microsoft AD 和为该目录启动 Amazon WorkMail 来集成现有 Microsoft Active Directory。您配置该集成后，可以选择要为您的现有目录中的用户列表里的哪些用户启用 Amazon WorkMail，并且用户可以使用其现有 Active Directory 证书登录 Amazon WorkMail。"
    },
    {
        "query":"我能否将现有域名与 Amazon WorkMail 一起使用？",
        "intention":"知识问答",
        "reply":"能。您可以使用 AWS 管理控制台将现有域名添加到 Amazon WorkMail。在域名可以使用之前，您必须验证域名的所属关系。您可以通过将 DNS 记录添加到您的 DNS 服务器来验证所属关系。"
    },
    {
        "query":"我能否向一个用户账户分派多个电子邮件地址？",
        "intention":"知识问答",
        "reply":"能。您可以使用 AWS 管理控制台将多个电子邮件地址分派到一个用户账户。"
    },
    {
        "query":"我能否创建分配组来向多个用户传输电子邮件？",
        "intention":"知识问答",
        "reply":"能。您可以使用 AWS 管理控制台创建新的分配组或从您的 Microsoft Active Directory 启用已有分配组。这些分配组可从“Global Address Book”查看。用户还可以使用 Microsoft Outlook 或 Amazon WorkMail Web 应用程序创建个人分配组。"
    },
    {
        "query":"如果用户忘记访问 Amazon WorkMail 的密码，该怎么办？",
        "intention":"知识问答",
        "reply":"如果将 Amazon WorkMail 和现有的 Active Directory 域相集成，那么，对于现有域，用户将遵循现有的密码丢失流程，如联系内部帮助台。如果账户已与 Simple AD 目录集成，并且用户忘记了密码，那么该账户的 IT 管理员可以从 AWS 管理控制台重置密码。"
    },
    {
        "query":"IT 管理员如何取消用户对 Amazon WorkMail 的访问权？",
        "intention":"知识问答",
        "reply":"账户的 IT 管理员可以使用 AWS 管理控制台删除用户对 Amazon WorkMail 的访问权限。"
    },
    {
        "query":"Amazon WorkMail 是否提供管理 API？",
        "intention":"知识问答",
        "reply":"不提供，Amazon WorkMail 目前不提供管理 API。"
    },
    {
        "query":"Amazon WorkMail 是否提供开发工具包？",
        "intention":"知识问答",
        "reply":"是的。Amazon WorkMail 提供了一个管理性 SDK，因此，您可以在本机将 WorkMail 与现有服务集成。这一软件开发工具包可通过 API 调用支持编程用户、电子邮件组和会议室，或进行设备资源管理。这就意味着您现有的 IT 服务管理工具、工作流程和第三方应用程序可以自动进行 WorkMail 迁移并执行管理任务。要了解更多信息，请访问我们的 [API 参考](https://docs.aws.amazon.com/workmail/latest/APIReference/Welcome.html)。\n此外，Amazon WorkMail 还提供一个软件开发工具包，用于获取贵组织正在发送或正在接收的电子邮件的内容。您可以将此软件开发工具包与[电子邮件流规则](https://docs.aws.amazon.com/workmail/latest/adminguide/email-flows.html)相结合使用，来触发正在发送或接收的邮件上的 Lambda，并获取全部消息，以便进行分析或与其他系统集成。要了解更多信息，请参阅 [API 参考](https://docs.aws.amazon.com/workmail/latest/APIReference/API_messageflow_GetRawMessageContent.html)。"
    },
    {
        "query":"如何开始使用电子邮件日志？",
        "intention":"知识问答",
        "reply":"可以在 Amazon WorkMail 管理控制台的组织设置下设置电子邮件日志。您可以启用电子邮件日志，指定日志电子邮件要发送到哪个电子邮件地址，以及指定要将报告发送到哪个电子邮件地址。"
    },
    {
        "query":"是否可以对一组特定的操作或用户应用电子邮件日志？",
        "intention":"知识问答",
        "reply":"不可以。目前的电子邮件日志是一项全局设置，将应用于所有入站和出站的电子邮件以及所有用户。"
    },
    {
        "query":"电子邮件日志是否会应用于密送 (BCC) 字段中的收件人？",
        "intention":"知识问答",
        "reply":"会的。使用 BCC 收件人发送的电子邮件会使用电子邮件日志功能进行记录。"
    },
    {
        "query":"日志报告是否会显示 BCC 字段中的电子邮件收件人？",
        "intention":"知识问答",
        "reply":"对于出站电子邮件，日志报告将包含 BCC 字段中的收件人详情。对于入站电子邮件，仅当 BCC 字段中的收件人是您的 Amazon WorkMail 组织成员时，日志报告才会包含这些收件人的详情。"
    },
    {
        "query":"标为垃圾邮件的电子邮件是否会记入日志？",
        "intention":"知识问答",
        "reply":"是的，会记入。"
    },
    {
        "query":"标为包含病毒的电子邮件是否会记入日志？",
        "intention":"知识问答",
        "reply":"不会。包含病毒的电子邮件将被删除，且不会记入日志。"
    },
    {
        "query":"如果向日志目标邮箱发送失败，会怎样？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 会在接下来 12 小时内继续尝试将日志邮件发往日志目标邮箱。如果连续失败，将向您在 Amazon WorkMail 管理控制台中指定的地址发送故障报告。"
    },
    {
        "query":"日志发送失败报告中包含哪些内容？",
        "intention":"知识问答",
        "reply":"当日志电子邮件无法发送到主日志地址时，会向您在 Amazon WorkMail 管理控制台中指定的日志发送失败报告电子邮件地址发送一份报告。此报告包含每一封发送失败的日志邮件的相关信息，但不会显示原始邮件的内容。"
    },
    {
        "query":"日志电子邮件从哪个电子邮件地址发出？",
        "intention":"知识问答",
        "reply":"日志电子邮件从 amazonjournaling@<alias>.awsapps.com 发出，其中 <alias> 是您的 Amazon WorkMail 组织名。"
    },
    {
        "query":"哪些 SMTP 标头会被日志代理程序用来识别日志邮件？",
        "intention":"知识问答",
        "reply":"“X-WM-Journal-Report”标头将用来标识日志邮件。此标头将被签名，因此无法模拟。"
    },
    {
        "query":"日志邮件是否计入发送限制？",
        "intention":"知识问答",
        "reply":"不会，只要允许用户发送邮件，就会发送日志邮件。这些不会计入该用户的发送限制。在接收邮件时，只要可以将其发送给用户就会发送日志邮件。"
    },
    {
        "query":"如何将邮箱从我的现有电子邮件解决方案迁移到 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"您可以使用首选 Amazon WorkMail 迁移提供商提供的解决方案将现有邮箱迁移至 Amazon WorkMail。要查看提供商列表，请访问[此](https://aws.amazon.com/workmail/details/)网页。如果您是从 Microsoft Exchange Server 2013 或 2010 进行迁移，则可以设置互操作性，以便尽可能减少您的最终用户受到的影响。"
    },
    {
        "query":"Amazon WorkMail 是否支持与 Microsoft Exchange Server 的互操作性？",
        "intention":"知识问答",
        "reply":"支持，Amazon WorkMail 支持与 Microsoft Exchange Server 2013 和 2010 的互操作性。您可以在[此处](https://docs.aws.amazon.com/workmail/latest/adminguide/interoperability.html)了解如何设置互操作性。"
    },
    {
        "query":"Amazon WorkMail 支持哪些互操作功能？",
        "intention":"知识问答",
        "reply":"互操作性让您可以将同一公司域用于 Microsoft Exchange 和 Amazon WorkMail 中的所有邮箱。您的用户可以通过在两种环境中双向分享日程空闲信息来顺利安排会议，并通过统一的全局地址簿访问用户与资源信息。"
    },
    {
        "query":"Amazon WorkMail 互操作性支持哪些版本的 Microsoft Exchange Server？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 提供与 Microsoft Exchange Server 2013 和 2010 的互操作性支持。"
    },
    {
        "query":"使用互操作性功能需要额外付费吗？",
        "intention":"知识问答",
        "reply":"不需要。互操作性功能的费用包含在 Amazon WorkMail 的每邮箱定价之中。"
    },
    {
        "query":"用户是否可以使用其现有 Microsoft Active Directory 凭证访问 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"可以，用户可以使用其现有 Microsoft Active Directory 凭证连接到 Amazon WorkMail。"
    },
    {
        "query":"Amazon WorkMail 上的邮箱是否会和我的 Microsoft Exchange Server 上的邮箱使用相同的域？",
        "intention":"知识问答",
        "reply":"会的。要实现这一点，您需要在 Microsoft Exchange 和 Amazon WorkMail 之间启用电子邮件路由，以便这两种环境下的邮箱可以使用相同的企业域。要设置电子邮件路由，您可以按照[此处](https://docs.aws.amazon.com/workmail/latest/adminguide/interoperability.html)列出的步骤操作。"
    },
    {
        "query":"建立互操作性之后，由哪个电子邮件平台来处理接收的电子邮件？",
        "intention":"知识问答",
        "reply":"您的本地 Microsoft Exchange Server 会处理所有接收的电子邮件。如果您在迁移时使用了互操作性，则可以在完成迁移后将您的 MX 记录切换为指向 Amazon WorkMail。"
    },
    {
        "query":"是否可以仅限我的 VPC 访问我的 Microsoft Exchange Server？",
        "intention":"知识问答",
        "reply":"不可以，您无法仅限您的 VPC 访问 Exchange Server。目前为止，您的本地 Microsoft Exchange 环境的 EWS 终端节点需要公开开放。"
    },
    {
        "query":"Amazon WorkMail 是否支持与 Microsoft Exchange 双向共享日历忙/闲信息？",
        "intention":"知识问答",
        "reply":"支持，互操作性可让您在 Amazon WorkMail 和 Microsoft Exchange 环境中双向共享日历忙/闲信息。请按照此处列出的步骤操作。"
    },
    {
        "query":"执行双向日历忙/闲信息查找时，Amazon WorkMail 如何与我的本地 Microsoft Exchange Server 交互？",
        "intention":"知识问答",
        "reply":"您需要在 Amazon WorkMail 和 Microsoft Exchange 上配置可用性设置，然后才能共享日历忙/闲信息。Amazon WorkMail 使用您的 Microsoft Exchange Server 的 EWS URL 来执行忙/闲查找。Amazon WorkMail 使用 Exchange 服务帐户登录 Exchange，然后读取用户在 Microsoft Exchange 组织中的忙/闲数据。\n对于从您的 Microsoft Exchange Server 执行的对 Amazon WorkMail 用户的忙/闲查找，Exchange 会执行 Autodiscover 请求并使用 Amazon WorkMail 服务帐户连接到 Amazon WorkMail EWS 终端节点。  \n 您可以在[此处](https://docs.aws.amazon.com/workmail/latest/adminguide/interoperability.html)找到相关更多信息。"
    },
    {
        "query":"我是否需要在本地 Microsoft Exchange Server 上设置联合？",
        "intention":"知识问答",
        "reply":"不需要，对于与 Amazon WorkMail 的互操作性支持，您无需在自己的 Microsoft Exchange Server 上设置联合。"
    },
    {
        "query":"如果已启用互操作性，我是否也可以在忙/闲详细信息中查看主题和位置？",
        "intention":"知识问答",
        "reply":"可以，要查看主题和位置信息，服务帐户用户需要拥有对此类信息的访问权限。"
    },
    {
        "query":"Amazon WorkMail 用户是否可以管理 Microsoft Exchange 上的用户所共享的日历或文件夹（或者相反）？",
        "intention":"知识问答",
        "reply":"不可以，对于日历委托或访问共享文件夹，用户双方需要位于同一电子邮件平台上。我们建议将使用日历和邮箱委托的用户放在同一批次中迁移。"
    },
    {
        "query":"Amazon WorkMail 如何与本地 Microsoft Exchange Server 交互，以便创建统一的全局地址簿？",
        "intention":"知识问答",
        "reply":"启用互操作性支持后，Amazon WorkMail 会使用 AD Connector，每四小时与您的本地 Active Directory 同步一次地址簿。所有 Microsoft Exchange 用户、组和资源均会被自动添加到 Amazon WorkMail 地址簿中。"
    },
    {
        "query":"所有 Microsoft Exchange Server 对象是否都会被同步到 Amazon WorkMail 全局地址簿中？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 会同步 Microsoft Exchange Server 中的用户、组、资源和联系人。Amazon WorkMail 不会同步动态组或地址列表。如果 Microsoft Exchange 全局地址簿中包含这些对象，他们不会出现在 Amazon WorkMail 中。"
    },
    {
        "query":"如果未启用互操作性支持，Amazon WorkMail 是否仍然会与 Active Directory 同步？",
        "intention":"知识问答",
        "reply":"是的，如果禁用互操作性支持，Amazon WorkMail 仍然会与 Active Directory 同步。在这种情况下，只有对 Amazon WorkMail 用户和组的更改会被同步。"
    },
    {
        "query":"Microsoft Outlook 离线地址簿是否也会包含所有 Microsoft Exchange 用户、组和资源？",
        "intention":"知识问答",
        "reply":"是的，Microsoft Outlook 离线地址簿会包含 Amazon WorkMail 和 Microsoft Exchange 用户、组和资源。"
    },
    {
        "query":"我的分配组能否将 Amazon WorkMail 用户和 Microsoft Exchange 用户包含为成员？",
        "intention":"知识问答",
        "reply":"是的，您可以让 Amazon WorkMail 用户和 Microsoft Exchange 用户成为分配组的成员。"
    },
    {
        "query":"启用互操作性支持后，我是否仍然能够在 Amazon WorkMail 中创建新资源？",
        "intention":"知识问答",
        "reply":"不能。要在 Amazon WorkMail 中创建新资源，您首先需要禁用互操作性支持。创建新资源后，您可以再次开启互操作性支持。这样可以确保资源被同步回 Microsoft Exchange Server。"
    },
    {
        "query":"什么是电子邮件流规则？",
        "intention":"知识问答",
        "reply":"对于出站邮件，您可以创建电子邮件流规则来筛选电子邮件或者路由到 SMTP 终端节点或 AWS Lambda 函数。示例包括："
    },
    {
        "query":"什么类型的电子邮件数据会传递给 Lambda 函数？",
        "intention":"知识问答",
        "reply":"Lambda 函数将接收电子邮件的消息 ID、发件人、收件人和主题。"
    },
    {
        "query":"从我的 Lambda 检索电子邮件内容时，该内容以什么格式提供？",
        "intention":"知识问答",
        "reply":"WorkMailMessageFlow 开发工具包将返回正在处理的消息的原始 MIME 内容。您可以使用[适用于 Java 的 JavaMail](https://www.oracle.com/technetwork/java/javamail/index.html) 或[适用于 Python 的 email.parser](https://docs.python.org/3/library/email.parser.html) 等常见 MIME 处理库，将此内容转换成更易于解析的结构化格式。"
    },
    {
        "query":"可以使用 Lambda 函数更新电子邮件消息的内容吗？",
        "intention":"知识问答",
        "reply":"可以，您可以先使用 Lambda 函数中的 WorkMailMessageFlow 的开发工具包更新电子邮件消息的内容，然后再进行发送或传递。应将邮件流规则的 Lambda 操作配置为同步运行 Lambda，更改才能生效。请参阅[使用 AWS Lambda 更新消息内容](https://docs.aws.amazon.com/workmail/latest/adminguide/update-with-lambda.html)，了解更多信息。\n您可以在 Amazon WorkMail 管理控制台中导航至“组织设置”来设置规则。您可以在“电子邮件流规则”选项卡中创建、修改和删除流规则。"
    },
    {
        "query":"我可以根据 IP 地址或范围进行筛选吗？",
        "intention":"知识问答",
        "reply":"[Amazon Simple Email Service](https://aws.amazon.com/ses/) 已支持基于 IP 的筛选。请参阅[为 Amazon SES 电子邮件接收创建 IP 地址筛选器](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/receiving-email-ip-filters.html)，了解有关基于 IP 的筛选的更多信息。"
    },
    {
        "query":"如果被指定为可绕过垃圾邮件检查的来源发来的电子邮件包含病毒，会出现什么情况？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 会扫描所有进出电子邮件，以检查其中是否包含垃圾内容、恶意软件和病毒。不管您是否配置了流规则，所有包含病毒的电子邮件都将被丢弃且不会进行传输。"
    },
    {
        "query":"如果电子邮件流规则重叠，会出现什么情况？",
        "intention":"知识问答",
        "reply":"如果您的电子邮件与多条电子邮件流规则匹配，系统将应用最具体的规则中指定的操作。例如，针对特定电子邮件地址的规则的优先级将高于针对整个域的规则。如果多条规则的具体程度相同，系统将应用最具限制性的操作（例如，丢弃邮件的优先级将高于退回邮件）。有关更多信息，请参阅[管理电子邮件流​](https://docs.aws.amazon.com/workmail/latest/adminguide/email-flows.html)。"
    },
    {
        "query":"在将其应用于真实电子邮件之前，如何测试电子邮件流规则？",
        "intention":"知识问答",
        "reply":"您可以使用单个电子邮件地址创建一个规则作为发件人域或地址条件，然后选择要使用的操作。然后，您可以将测试电子邮件发送到您选择的单个地址或从该地址发送测试电子邮件，以确认该规则的行为符合您的期望。对结果满意后，您可以将规则扩展到其他发件人域或地址。\n使用 Lambda 规则时，您还可以在 AWS Lambda 控制台中使用虚拟请求事件测试 Lambda。有关事件数据的示例，请参见 [Lambda 事件数据](https://docs.aws.amazon.com/workmail/latest/adminguide/lambda.html#lambda-data)。有关从 Lambda 控制台调用 Lambda 的更多信息，请参见[调用 Lambda 函数](https://docs.aws.amazon.com/lambda/latest/dg/getting-started-create-function.html#get-started-invoke-manually)。"
    },
    {
        "query":"对于我可以创建的规则数量是否有限制？",
        "intention":"知识问答",
        "reply":"有。​要详细了解有关电子邮件流规则的限制，请参阅 [AWS Service Limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_workmail)。"
    },
    {
        "query":"规则需要多长时间才能生效？",
        "intention":"知识问答",
        "reply":"规则在创建后即会生效。"
    },
    {
        "query":"数据如何传输到 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"所有中转数据都采用行业标准 SSL 进行加密。我们的 Web 应用程序和移动与桌面客户端使用 SSL 将数据传输到 Amazon WorkMail。"
    },
    {
        "query":"我能否选择存储数据的 AWS 区域？",
        "intention":"知识问答",
        "reply":"能。您可以选择用于存储您的组织数据的 AWS 区域。请参阅[区域产品和服务页面](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)，了解 Amazon WorkMail 在不同区域的具体提供情况。"
    },
    {
        "query":"如何决定要使用哪个 AWS 区域？",
        "intention":"知识问答",
        "reply":"根据您的需求，要考虑下面几个因素，包括使用特定的 AWS 区域能否让您满足监管和合规性要求。一般情况下，我们建议您在最靠近大多数用户所在地区的区域设置您的 Amazon WorkMail 组织，以降低数据访问延迟。"
    },
    {
        "query":"Amazon WorkMail 如何防御恶意软件/病毒？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 可扫描所有进出邮件，防止垃圾邮件、恶意软件和病毒，帮助保护您的客户不受恶意电子邮件的侵害。"
    },
    {
        "query":"Amazon WorkMail 是否提供对移动设备策略的支持以保护存储在移动设备上的数据？",
        "intention":"知识问答",
        "reply":"提供。Amazon WorkMail 让您能够要求在您的用户的设备上设置 PIN 码或密码、配置密码的强度、要求尝试登录失败几次后锁住设备、要求在空闲超时后锁定屏幕以及要求给设备与存储卡加密。"
    },
    {
        "query":"我如何管理用于加密 Amazon WorkMail 中的数据的加密密钥？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 与 Amazon Key Management Service 集成，以便加密您的数据。密钥管理可从 Amazon IAM 控制台执行。有关 AWS Key Management Service 的更多信息，请参阅 [Amazon AWS Key Management 开发人员指南](https://docs.aws.amazon.com/kms/latest/developerguide/overview.html)。"
    },
    {
        "query":"什么数据是使用我的加密密钥加密的？",
        "intention":"知识问答",
        "reply":"所有电子邮件内容、附件、邮箱的数据元都是使用该用户所在组织的客户管理的密钥加密的。"
    },
    {
        "query":"使用 IMAP 协议访问 Amazon WorkMail 邮箱时，电子邮件是否已加密？",
        "intention":"知识问答",
        "reply":"是的。所有电子邮件在传输过程中通过客户端与服务器之间建立的安全连接进行加密，而且存储在 Amazon WorkMail 中的所有静态电子邮件都会进行加密。"
    },
    {
        "query":"Amazon WorkMail 是否支持 S/MIME 对电子邮件进行签名和加密？",
        "intention":"知识问答",
        "reply":"支持。Amazon WorkMail 支持在 Microsoft Outlook 客户端和特定的移动设备（如 Apple iPhone 和 iPad）中使用 S/MIME 签名和加密。Amazon WorkMail Web 应用程序目前不支持 S/MIME 签名和加密。"
    },
    {
        "query":"Amazon WorkMail 支持哪些合规性认证？",
        "intention":"知识问答",
        "reply":"Amazon Web Services 已获得 ISO 27001、ISO 27017 和 ISO 27018 认证。在美国东部（弗吉尼亚州北部）、美国西部（俄勒冈）和欧洲（爱尔兰）区域中使用 Amazon WorkMail 都在认证范围内。您可以在网站的 [AWS 云合规性](https://aws.amazon.com/compliance/)部分了解有关这些认证的更多信息。  \n 您还可以请求获得一份由 [AWS 合规性](https://pages.awscloud.com/compliance-contact-us.html)提供的服务组织控制 (SOC) 报告，以详细了解 AWS 用于保护您的数据的安全控件。"
    },
    {
        "query":"AWS 如何使用 Amazon WorkMail 电子邮件的内容？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 中的内容归您所有，同时您拥有 Amazon WorkMail 电子邮件的完整所有权和控制权。除非经过您的授权，否则我们不会查看、使用或移动您 Amazon WorkMail 账户的内容。"
    },
    {
        "query":"如何将 Amazon WorkMail 与 Amazon WorkDocs 相集成？",
        "intention":"知识问答",
        "reply":"Amazon WorkDocs 集成让用户能够轻松地从 Amazon WorkMail Web 应用程序分发大文档、保留对通过电子邮件分发的敏感文档的控制以及在 Amazon WorkDocs 中安全保存电子邮件的附件。"
    },
    {
        "query":"我如何开始使用 Amazon WorkDocs 集成？",
        "intention":"知识问答",
        "reply":"要使用 Amazon WorkDocs 集成，您的组织首先需要激活 Amazon WorkDocs，您可以在 AWS 管理控制台中为您的组织激活 Amazon WorkDocs。完成此操作后，您可以使用 Amazon WorkDocs 管理面板为您的用户启用 Amazon WorkDocs。为用户启用 Amazon WorkDocs 后,他们可以开始在 Amazon WorkMail Web 应用程序中使用 Amazon WorkDocs。  \n 如果您的组织和用户已经在使用 Amazon WorkDocs，则您的用户可在启动 Amazon WorkMail 后立即使用集成。"
    },
    {
        "query":"我能否在不使用 Amazon WorkDocs 的情况下使用 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"能，但是您将无法在 Amazon WorkMail Web 应用程序中使用 Amazon WorkDocs 集成。"
    },
    {
        "query":"如何将 Amazon WorkMail 与 Amazon Simple Email Service 相集成？",
        "intention":"知识问答",
        "reply":"Amazon WorkMail 使用 Amazon Simple Email Service 来发送所有出站电子邮件。可以在 Amazon Simple Email Service 控制台中管理测试电子邮件域和您的实际使用域。"
    },
    {
        "query":"我是否需要提高 Amazon SES 发送限制才能使用 Amazon WorkMail？",
        "intention":"知识问答",
        "reply":"不需要。无需提高 Amazon SES 发送限制即可搭配使用 Amazon WorkMail。在使用 Amazon SES 时，如果通过 Amazon SES API 从 AWS 账户批量发送电子邮件，这时 SES 限制才适用。"
    },
    {
        "query":"Amazon WorkMail 是否与 AWS CloudTrail 集成？",
        "intention":"知识问答",
        "reply":"是的。CloudTrail 可从 WorkMail 控制台或者 WorkMail 或 WorkMail API 操作中捕获 API 调用。使用 CloudTrail 收集的信息，您可以跟踪向 WorkMail 发出的请求、从中发出请求的 IP 地址、发出请求者、请求发出时间，等等。要了解有关 CloudTrail 的更多信息，包括如何对其进行配置和启用，请参阅 [AWS CloudTrail 用户指南](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-user-guide.html)。要了解有关如何记录 WorkMail API 调用日志的更多信息，请参阅[使用 AWS CloudTrail 记录 Amazon WorkMail API 调用](https://docs.aws.amazon.com/workmail/latest/adminguide/logging-using-cloudtrail.html)。"
    },
    {
        "query":"在 Amazon WorkMail 中使用 AWS CloudTrail 需要付费吗？",
        "intention":"知识问答",
        "reply":"在 WorkMail 中使用 CloudTrail 不需要支付额外的 WorkMail 费用。使用 CloudTrail 交付事件可能需要支付相关费用。有关详细信息，请参阅 [CloudTrail 定价](https://aws.amazon.com/cloudtrail/pricing/)。"
    },
    {
        "query":"WorkMail 是否提供电子邮件指标？",
        "intention":"知识问答",
        "reply":"是的，WorkMail 会将免费发送、接收和退回的电子邮件的指标记录在 CloudWatch 指标中"
    },
    {
        "query":"WorkMail 是否提供消息追踪？",
        "intention":"知识问答",
        "reply":"是的，WorkMail 提供了在 CloudWatch logs 中启用 WorkMail 监控的选项。激活日志记录时，您可以定义要登录的 CloudWatch 日志组以及日志保留期。然后，WorkMail 将记录有关接收和发送的消息、应用规则的时间、启动消息日志的时间以及退回消息的详细信息。"
    },
    {
        "query":"WorkMail 监控中记录了哪些数据？",
        "intention":"知识问答",
        "reply":"如果激活日志记录，WorkMail 会记录信封数据，如发件人和收件人。不记录消息正文。"
    },
    {
        "query":"我如何对消息进行查询？",
        "intention":"知识问答",
        "reply":"CloudWatch 提供了洞察功能，允许对 CloudWatch logs 进行快速简单的查询。"
    },
    {
        "query":"我的公司如何为 Amazon WorkMail 的使用付费？",
        "intention":"知识问答",
        "reply":"开始使用 Amazon WorkMail 时，没有预付费用，也无需订立使用合约。月底时，向您收取当月的使用费。要查看当前账单周期的预计费用，您可以登录 AWS 管理控制台并单击“Account Activity”。 您可以开始使用 Amazon WorkMail 的免费试用版，并在前 30 天免费激活 25 个用户。您可以立即通过 [WorkMail 控制台](https://console.aws.amazon.com/workmail/home)开始使用。\n您将按每月的用户账户数量付费。本月的计费用户数依整个月份内活动用户数的平均数决定。对于每个用户账户，您的公司将按月支付订阅费。如果用户账户不是在该月第一天激活的，则将根据活动天数按比例收取该账户的月订阅费。但是，如果用户停用了，则该月的剩余天数不会累计积分。按比例计算实际服务的小时数（而非仅天数），并且是给定月份中日历天数的实际数字。有关定价原理的更多信息，请参阅[定价页](https://aws.amazon.com/workmail/pricing/)。"
    },
    {
        "query":"Amazon WorkMail 是否提供免费试用版？",
        "intention":"知识问答",
        "reply":"是的。您可以在您注册 Amazon WorkMail 后的前 30 天，免费激活 25 个用户。在此期限结束后，您将为所有活跃用户付费，除非您删除这些用户账户或注销您的 Amazon WorkMail 账户。"
    },
    {
        "query":"我是否需要为创建或使用资源（如会议室）付费？",
        "intention":"知识问答",
        "reply":"不需要。在 Amazon WorkMail 中创建或使用资源是免费的。"
    },
    {
        "query":"AWS Compute Optimizer 是什么？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 可帮助您使用机器学习来分析历史利用率指标，从而确定最佳的 AWS 资源配置，例如 Amazon Elastic Compute Cloud (EC2) 实例类型、AWS Fargate 上的 Amazon Elastic Container Service (ECS) 服务的任务大小、Amazon Elastic Block Store (EBS) 卷配置和 AWS Lambda 函数内存大小。AWS Compute Optimizer 提供了一组 API 和控制台体验，可通过为您的 AWS 工作负载推荐最佳的 AWS 资源来帮助您降低成本并提高工作负载性能。"
    },
    {
        "query":"AWS Compute Optimizer 可以用来做什么？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 提供直观且易于操作的 AWS 资源建议，以帮助您快速确定适合工作负载的最佳 AWS 资源，而无需具备专业知识或花费大量时间和金钱。AWS Compute Optimizer 控制台为您提供由 AWS Compute Optimizer 分析的所有资源和建议的全局、跨账户视图，以便您可以快速确定最具影响力的优化机会。"
    },
    {
        "query":"如何开始使用 AWS Compute Optimizer？",
        "intention":"知识问答",
        "reply":"要注册 AWS Compute Optimizer，请转到 AWS Compute Optimizer 控制台，然后单击 “opt in”（选择加入）。 要访问此服务，您必须拥有 AWS 账户。选择加入后，AWS Compute Optimizer 将立即开始分析您的 AWS 资源并开始提供建议。首次选择 AWS Compute Optimizer 时，可能最多需要 24 个小时才能完全分析您账户中的 AWS 资源。"
    },
    {
        "query":"AWS Compute Optimizer 使用哪些数据为我提供建议？",
        "intention":"知识问答",
        "reply":"选择加入 AWS Compute Optimizer 即表示您授权该服务使用 AWS 资源配置数据和 CloudWatch 指标。之所以需要此数据，是因为 AWS Compute Optimizer 需要识别要评估的资源，并且需要足够的历史指标才能提供建议。"
    },
    {
        "query":"什么时候应该使用 AWS Compute Optimizer EC2 实例类型建议？什么时候应该使用 AWS Cost Explorer EC2 资源大小调整建议？",
        "intention":"知识问答",
        "reply":"Cost Explorer 资源大小调整建议和 Compute Optimizer 使用相同的建议引擎。Compute Optimizer 提供建议，帮助客户确定其工作负载的最佳 EC2 实例类型。Cost Explorer 控制台和 API 会显示这些可能有助于节约成本的建议的子集，并使用客户特定的成本和节省信息（例如，账单信息、可用抵扣金、投资回报和 Savings Plans）加以补充，从而帮助成本-管理所有者通过基础设施调整快速发现节约机会。Compute Optimizer 控制台及其 API 会提供所有建议，而不考虑成本影响。工程团队可以使用 Compute Optimizer 来评估其工作负载的性价比权衡，接收包含额外数据（例如内存指标）的建议，并评估预计的资源利用率和性能风险。"
    },
    {
        "query":"AWS Compute Optimizer 为每个 AWS 资源提供多少个建议选项？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 为 Amazon Elastic Compute Cloud (EC2)、Amazon Elastic Block Store (EBS) 和 EC2 Auto Scaling 组提供最多三个资源建议选项。AWS Compute Optimizer 为 AWS Lambda 函数提供一个内存大小建议，并为 AWS Fargate 上的 Amazon Elastic Container Service (ECS) 服务提供一个任务级 CPU 和内存大小建议。"
    },
    {
        "query":"AWS Compute Optimizer 是否可为所有 AWS 资源提供建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 为选定类型的 EC2 实例、EC2 Auto Scaling 组、EBS 卷、AWS Fargate 上的 Amazon ECS 服务以及 Lambda 函数提供建议。"
    },
    {
        "query":"AWS Compute Optimizer 需要分析多少数据来生成建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 需要分析过去 14 天的指标来生成建议。"
    },
    {
        "query":"我如何确定最大的成本节约和性能改进机会？",
        "intention":"知识问答",
        "reply":"您可以通过两组新的控制面板级指标快速确定并按优先级排列优化机会：节约机会和性能提高机会。\n节约机会指标采用 Compute Optimizer 建议，量化您在账户层面、资源类型层面或资源层面可以实现的 Amazon EC2、Amazon EBS、AWS Fargate 上的 Amazon ECS 服务以及 AWS Lambda 的每月节约量。您可以利用这些指标评估并按优先级排列成本效率机会，监测长时间的成本效率。性能提高机会指标量化账户层面和资源类型层面配置不足的资源的百分比和数量。您可以利用这些指标评估并按优先级排列解决资源瓶颈风险的性能提高机会。"
    },
    {
        "query":"什么是增强的基础架构指标？",
        "intention":"知识问答",
        "reply":"增强的基础设施指标是 EC2 实例的一种付费 Compute Optimizer 功能，可以提高建议的准确性和与每月或每季度利用率模式的工作负载的相关性。激活该功能后，Compute Optimizer 会自动接收和分析比默认 Compute Optimizer 选项高出 6 倍的利用率指标历史记录（与原来的 14 天相比增加到最多 3 个月历史）。您可以通过 [Compute Optimizer 控制台](https://console.aws.amazon.com/compute-optimizer/home)或 API，在企业、账户或资源级为所有现有和新建的 EC2 实例及 Auto Scaling 组激活该功能。"
    },
    {
        "query":"增强的基础架构指标的成本是多少？",
        "intention":"知识问答",
        "reply":"访问 Compute Optimizer [定价页面](https://aws.amazon.com/cn/compute-optimizer/pricing/)了解更多信息。"
    },
    {
        "query":"AWS Compute Optimizer 支持为哪些类型的 EC2 实例生成建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 支持为 M、C、R、T、X、I、D、H 和 Z 实例系列的独立 EC2 实例生成 EC2 实例类型和大小建议。有关支持的 EC2 实例类型的完整列表，请参阅[文档](https://docs.aws.amazon.com/compute-optimizer/latest/ug/requirements.html#requirements-ec2-instances)。"
    },
    {
        "query":"AWS Compute Optimizer 使用哪些数据为我生成 EC2 实例建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 会在生成 EC2 实例类型建议时分析默认的 CloudWatch 指标，如 CPU 使用率、每秒网络包数、本地存储吞吐量和本地存储 IOPS 等。EC2 实例需要累积 30 小时的指标才能获得建议。"
    },
    {
        "query":"AWS Compute Optimizer 是否会分析我的 EC2 实例内存指标？",
        "intention":"知识问答",
        "reply":"如果您使用 CloudWatch 代理发布内存利用率，则 AWS Compute Optimizer 会自动分析 CloudWatch 代理在“CWAgent”命名空间中发布的内存指标。"
    },
    {
        "query":"如果我没有针对 EC2 实例的内存指标，该怎么办？",
        "intention":"知识问答",
        "reply":"如果硬件资源（例如内存）的指标不可用，则 AWS Compute Optimizer 将尝试避免生成缩小规模的建议。"
    },
    {
        "query":"AWS Compute Optimizer 如何确定建议的 EC2 实例选项的性能风险？",
        "intention":"知识问答",
        "reply":"性能风险表示实例类型无法满足您的工作负载资源需求的可能性。Compute Optimizer 能够为推荐实例的各个资源维度单独计算性能风险分数，包括 CPU、存储、EBS 吞吐量、EBS IOPS、磁盘吞吐量、磁盘 IOPS、网络吞吐量以及网络 PPS。对于每一个资源维度，性能风险分数将根据给定资源维度内可能受限容量的历史回顾时期时间比例计算。推荐实例的性能风险将计算为各分析资源规格的最达性能风险分数。"
    },
    {
        "query":"AWS Compute Optimizer 如何帮助我了解建议的 EC2 实例选项？",
        "intention":"知识问答",
        "reply":"如果您使用建议的选项，则 AWS Compute Optimizer 会预测您的 EC2 实例可能的 CPU 和内存利用率，以便您了解使用建议选项的情况下工作负载的性能。AWS Compute Optimizer 还列示了当前实例与推荐实例类型之间的配置区别，因此您可以了解所需的更新，以将您的工作负载从当前实例迁移至推荐实例类型。"
    },
    {
        "query":"交付建议时，AWS Compute Optimizer 是否考虑了 EC2 实例定价信息？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 确定适合您工作负载的最佳 AWS 资源列表后，会结合各种定价方式（例如按需定价）以及预期的性能风险来对建议进行排名。AWS Compute Optimizer 不考虑瞬时定价因素，例如实时定价。"
    },
    {
        "query":"AWS Compute Optimizer 支持为哪些类型的 Auto Scaling 组生成建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 为具有固定组大小的 EC2 Auto Scaling 组提供 EC2 实例类型和大小建议，也就是说，将所需值、最小值和最大值全部设置为相同的值，并且不附加扩展策略。此外，Auto Scaling 组所有的成员实例都必须为 M、C、R、T、X、I、D、H 和 z 实例系列类型。现在，Compute Optimizer 不支持配置了混合实例策略的 Auto Scaling 组。有关支持的 EC2 实例类型的完整列表，请参阅[文档](https://docs.aws.amazon.com/compute-optimizer/latest/ug/requirements.html#requirements-ec2-instances)。"
    },
    {
        "query":"AWS Compute Optimizer 使用哪些数据为我的自动扩缩组生成建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 需要至少连续 30 小时的指标才能为自动扩缩组生成建议。AWS Compute Optimizer 分析每个成员 EC2 实例的默认 CloudWatch 指标（例如 CPU 利用率和网络 I/O 指标）以及自动扩缩组配置（例如扩展策略和关联的启动模板）。"
    },
    {
        "query":"AWS Compute Optimizer 支持为哪些类型的 EBS 卷生成建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 支持通用型 EBS 卷 (gp2/gp3)、预调配 IOPS EBS 卷 (io1/io2/io2 BX) 和 HDD EBS 卷 (st1/sc1)。AWS Compute Optimizer 还为您的 EBS 磁性介质卷提供迁移到最新一代 EBS 卷的建议。"
    },
    {
        "query":"AWS Compute Optimizer 使用哪些数据为我生成 EBS 卷建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 需要至少 30 个连续小时的指标才能为 EBS 卷生成建议。AWS Compute Optimizer 会分析 EBS 卷的默认 CloudWatch 指标，例如 IOPS 和吞吐量指标。"
    },
    {
        "query":"AWS Compute Optimizer 如何确定建议的 EBS 卷选项的性能风险？",
        "intention":"知识问答",
        "reply":"性能风险表示建议的选项不符合工作负载的性能要求的可能性。性能风险越高，您可能需要花费越多的精力来验证建议的 EBS 卷配置是否满足您的工作负载的性能要求。"
    },
    {
        "query":"交付建议时，AWS Compute Optimizer 是否考虑了 EBS 卷定价信息？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 确定适合您的工作负载的最佳 EBS 卷配置列表后，会结合公共 EBS 定价以及预期的性能风险来对建议进行排名。"
    },
    {
        "query":"Compute Optimizer 支持哪种类型的 Lambda 函数？",
        "intention":"知识问答",
        "reply":"Compute Optimizer 帮助您优化两种类别 Lambda 函数。第一种类别包括可能在内存大小方面过度预置的 Lambda 函数。您可以考虑缩小这些函数的内存大小来节约成本。第二种类别包括可能从额外 CPU 处理能力中获益的计算密集型 Lambda 函数。您可以考虑增大其内存大小，以便触发对这些函数可用的 CPU 中的等效增加，并缩短运行时。对于不属于这两种类别的函数，Compute Optimizer 不会为它们提供建议。"
    },
    {
        "query":"Compute Optimizer 使用哪些数据为我生成 Lambda 函数建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 会分析 14 天的 Lambda 函数调用历史，包括函数运行时、使用的 CPU 时间以及内存使用情况等，来为您提供建议。"
    },
    {
        "query":"交付建议时，Compute Optimizer 是否考虑了 Lambda 函数定价信息？",
        "intention":"知识问答",
        "reply":"是。在 Compute Optimizer 为您的 Lambda 函数确定最优内存大小以后，它会综合考虑公开的 Lambda 定价、预期函数运行时，以及在过去 14 天里函数的调用次数来计算“可能的”成本金额。您可以使用此金额来了解如果按建议方案设置 Lambda 函数的内存大小，它的成本将会是多少。"
    },
    {
        "query":"ACO 支持为 AWS Fargate 上的 Amazon ECS 提供哪些类型的建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 为在 AWS Fargate 上运行的 Amazon ECS 服务提供任务级 CPU 和内存大小建议。"
    },
    {
        "query":"AWS Compute Optimizer 使用哪些数据为我在 AWS Fargate 上的 Amazon ECS 服务提供建议？",
        "intention":"知识问答",
        "reply":"AWS Compute Optimizer 需要至少 24 小时的指标才能为 AWS Fargate 上的 Amazon ECS 服务生成建议。AWS Compute Optimizer 会分析 AWS Fargate 上的 Amazon ECS 服务的 CPU 和内存利用率数据。"
    },
    {
        "query":"AWS Compute Optimizer 如何帮助我了解针对 AWS Fargate 上的 Amazon ECS 服务的建议？",
        "intention":"知识问答",
        "reply":"如果您按照建议配置 AWS Fargate 上的 Amazon ECS 服务，AWS Compute Optimizer 会预测其可能的 CPU 和内存利用率，以便您了解您的工作负载在建议配置下的执行情况。"
    },
    {
        "query":"交付建议时，AWS Compute Optimizer 是否会考虑 AWS Fargate 定价信息？",
        "intention":"知识问答",
        "reply":"会。在 Compute Optimizer 为 AWS Fargate 上的 Amazon ECS 服务确定最佳 CPU 和内存大小后，它会结合公开的 AWS Fargate 定价、新的 CPU 和内存配置以及过去 14 天的运行时历史来计算“可能”的成本。您可以使用此信息了解如果将 CPU 和内存大小设置为建议选项，您的 AWS Fargate 上的 Amazon ECS 服务的成本是多少。"
    },
    {
        "query":"AWS Compute Optimizer 是否与 AWS Organizations 集成？",
        "intention":"知识问答",
        "reply":"是，AWS Compute Optimizer 已与 AWS Organizations 集成，让您可以查看组织内的所有建议。要使用此功能，组织必须启用“所有功能”，并且您必须作为组织的主账户登录。"
    },
    {
        "query":"我的应用程序组件在其自己的 AWS 账户中运行。我是否可以使用 X-Ray 来收集各个 AWS 账户中的数据？ 可以，X-Ray 代理可担任角色，以便将数据发布到与它在其中运行的账户不同的账户中。这使您能够将来自应用程序各组件的数据发布到中央账户中。",
        "intention":"知识问答",
        "reply":"了解有关 AWS X-Ray 定价的更多信息"
    },
    {
        "query":"我使用 AWS Chatbot 可以获取哪些通知？ 您可以收到来自 AWS 服务的通知，如 CloudWatch 告警、运行状况事件、Security Hub 检测结果、Budgets 提醒，以及 CloudFormation 堆栈事件。 您还可以收到 Amazon EventBridge 支持的大多数 AWS 服务事件的通知。有关支持的服务的完整列表，请参阅 AWS Chatbot 文档。  问：可以使用 AWS Chatbot 运行哪种命令？ AWS Chatbot 支持大多数 AWS 服务的只读和变化 CLI 命令。AWS Chatbot 不支持与凭证、授权和 AWS Identity and Access Management (IAM) 权限相关的服务和操作命令，如 IAM、STS、KMS 和 EC2.GetPasswordData。此外，您可以指定防护机制策略权限，定义频道中的可用命令。AWS Chatbot 命令使用大家熟悉的 AWS CLI 语法。要键入命令，请键入“@aws <command>”，在消息中提到 AWS Chatbot。 AWS Chatbot 将提供命令线索，如果使用的语法错误，将提示您需要的其他命令参数。",
        "intention":"知识问答",
        "reply":"问：如何开始使用 AWS Chatbot？  \n 要开始使用 AWS Chatbot，请转到 AWS Chatbot 控制台，为 Microsoft Teams、Slack 或 Chime 创建配置，并将 AWS Chatbot 添加到频道或聊天室。"
    },
    {
        "query":"何时应使用 AWS Chatbot？ AWS Chatbot 可帮助您的整个团队随时了解 AWS 环境中运行的应用程序的操作事件、安全发现或预算警报并对其作出响应和解决。如果使用 AWS Chatbot 支持的聊天应用程序，则可以将 AWS Chatbot 配置为在团队频道或聊天室中发布通知并运行命令，以便您的整个团队可以查看这些通知并快速采取行动。例如，您可以设置 CloudWatch 告警，进入“Cloud DevOps”聊天频道，DevOps 工程师可以在其中查看告警，发生事件后立刻检索诊断信息，讨论迁移计划，通过从聊天频道配置 AWS 资源或运行 AWS Systems Manager 运行手册来解决告警。  问：AWS Chatbot 与 Amazon Lex 的不同之处在哪里？ AWS Chatbot 是预构建的交互式座席，设计用于监控、操作您的 AWS 资源（ChatOps）并与之交互。借助 AWS Chatbot，您可以安全地接收警报，从 Amazon CloudWatch 和 AWS GuardDuty 等服务请求诊断信息，并通过运行 CLI 命令（如执行 AWS System Manager 运行手册，或增加 Microsoft Teams 或 Slack 频道中 AWS Lambda 并行限制的命令）来解决事件。",
        "intention":"知识问答",
        "reply":"Amazon Lex 提供高级深度学习功能，包括用于语音文本转换的自动语音识别（ASR）和自然语言理解（NLU），可识别意图并构建逼真交互。这可以让您快速和轻松构建自己复杂的自然语言对话机器人。"
    },
    {
        "query":"AWS Chatbot 支持 AWS CloudFormation 吗？ 您可以使用 AWS CloudFormation 预置 Microsoft Teams 和 Slack 频道配置。当前不支持使用 AWS CloudFormation 预置 Chime webhook 配置。",
        "intention":"知识问答",
        "reply":"问：AWS Chatbot 在哪些 AWS 区域提供？  \n AWS Chatbot 是一项全球服务，可用于所有商业 AWS 区域。您可以在单个 AWS Chatbot 配置中组合来自多个区域的 Amazon SNS 主题。有关上市情况的详细信息，请参阅 [AWS 区域产品和服务表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。\n问：AWS Chatbot 可以处理 AWS Chatbot 使用所在 AWS 区域以外的数据吗？   \n AWS Chatbot 是一项全球性服务，我们可以在任何商业 AWS 区域存储或处理客户信息，如 Chatbot 配置与权限、Microsoft Teams 团队标识符、Slack 工作区标识符和频道名称、通知、用户输入和 AWS Chatbot 生成的响应与图像。\n您可以联系 AWS Support，请求删除用于分析的数据，提高账户相关的服务质量。您的信任、隐私与数据安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的数据，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/cn/compliance/data-privacy-faq/)。\n如果选择使用数据改进和提高 AWS Chatbot 以及其他 Amazon 机器学习/人工智能技术的质量，将从所有 AWS 区域移除您的数据。有关如何选择退出的更多信息，请联系 AWS Support。"
    },
    {
        "query":"什么是 Amazon Rekognition？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 作为一项服务，能够让您轻松地将功能强大的可视化分析添加到应用程序。借助 Rekognition Image，您可以轻松构建功能强大的应用程序来搜索、验证和组织数百万个图像。借助 Rekognition Video，您可以从存储的流视频或实时流视频中提取基于运动的上下文，并帮助您对其进行分析。\nRekognition Image 是一种图像识别服务，可以检测物体、场景、活动、地标、人脸、主色和图像质量。Rekognition Image 还可以提取文本、识别名人以及图像中的不当内容。您还可以使用该服务搜索和比较面孔。\nRekognition Video 是一种视频识别服务，可以检测活动；了解帧中人物的移动情况；识别在 Amazon S3 中存储的视频中的对象、名人和不当内容以及实时视频流。Rekognition Video 可以通过视频检测人物并对其进行跟踪，即使他们的面孔不可见或整个人可能进出场景。例如，可将其用于某个应用程序，当有人将包裹送到您家门口时发送实时通知。借助 Rekognition Video，您还可以编制诸如对象、活动、场景、地标、名人及面孔等元数据的索引，从而使视频搜索变得容易。"
    },
    {
        "query":"什么是深度学习？",
        "intention":"知识问答",
        "reply":"深度学习是机器学习的一个子领域，是人工智能的重要分支之一。其目的是通过使用具有由多个线性和非线性变换组成的多个处理层的深度图来从原始数据推断高级抽象。深度学习大致上基于大脑中的信息处理和通信模型。深度学习使用从大量的注释数据中学到的特征代替人工编写的特征。其通过利用高效算法迭代估计深度图中成千上万的参数来进行学习。\n卷积深度神经网络 (CNN)、递归神经网络等几种深度学习架构业已在计算机视觉、语音识别、自然语言处理和音频识别中得到了应用，以产生关于各种任务的最前沿结果。\nAmazon Rekognition 是 Amazon AI 系列服务的一部分。Amazon AI 服务使用深度学习技术来理解图像、将文本转换成逼真的语音以及构建直观的会话文本和语音界面。"
    },
    {
        "query":"使用 Amazon Rekognition 需要具备深度学习方面的专业技能吗？",
        "intention":"知识问答",
        "reply":"不需要。借助 Amazon Rekognition，您不必构建、维护或升级深度学习管道。\n为在复杂的计算机视觉任务 (如对象和场景检测、面部分析和面部识别) 方面获得准确的结果，需要对深度学习系统进行适当调整并为其提供海量带有标签的真实数据进行训练。获取、清理和准确地标记数据是一项耗时且代价高昂的任务。此外，训练深度神经网络需要付出昂贵的计算成本，并且通常需要使用图形处理单元 (GPU) 构建的自定义硬件。\nAmazon Rekognition 是一种完全托管式服务，已预先进行过图像和视频识别任务方面的训练，因此，您不必投入时间和资源创建深度学习管道。Amazon Rekognition 会继续通过融入最新的研究成果和获取新的训练数据来提高其模型的准确度。这使您能够专注于设计和开发高价值的应用程序。"
    },
    {
        "query":"Amazon Rekognition 最常见的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"Rekognition Image 最常见的使用案例包括：\nRekognition Video 最常见的使用案例包括："
    },
    {
        "query":"如何开始使用 Amazon Rekognition？",
        "intention":"知识问答",
        "reply":"如果还没有注册 Amazon Rekognition，您可以单击 [Amazon Rekognition 页面](https://aws.amazon.com/rekognition/)上的“Try Amazon Rekognition”(试用 Amazon Rekognition) 按钮，然后完成注册过程。您必须拥有 Amazon Web Services 账户才能访问此服务；如果还没有账户，则在注册期间，系统将提示您创建一个账户。注册后，您可以通过 [Amazon Rekognition 管理控制台](https://console.aws.amazon.com/rekognition/home)使用您自己的图像和视频试用 Amazon Rekognition，或下载 [Amazon Rekognition 开发工具包](https://aws.amazon.com/rekognition/developers/#sdk)来开始创建您自己的应用程序。有关更多信息，请参阅我们的分步[入门指南](http://docs.aws.amazon.com/rekognition/latest/dg/what-is.html)。"
    },
    {
        "query":"Amazon Rekognition 支持哪些图像和视频格式？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition Image 目前支持 JPEG 和 PNG 图像格式。您可以提交 S3 对象或字节数组形式的图像。Amazon Rekognition Video 操作可以分析存储在 Amazon S3 存储桶中的视频。视频必须使用 H.264 编解码器进行编码。支持的文件格式为 MPEG-4 和 MOV。编解码器是软件或硬件，可以压缩数据以加快传送，并将接收到的数据解压缩为其原始形式。H.264 编解码器通常用于录制、压缩和分配视频内容。视频文件格式可能包含一个或多个编解码器。如果 MOV 或 MPEG-4 格式的视频文件不适用于 Rekognition Video，请检查用于编码视频的编解码器是否为 H.264。"
    },
    {
        "query":"Amazon Rekognition 支持多大的文件大小？",
        "intention":"知识问答",
        "reply":"以 S3 对象形式传递时，Amazon Rekognition Image 支持高达 15MB 的图像文件大小；以图像字节数组形式提交时，它支持高达 5MB 的图像文件大小。以 S3 文件形式传递时，Amazon Rekognition Video 支持大小高达 10 GB 的文件和时间长达 6 小时的视频。"
    },
    {
        "query":"图像分辨率如何影响 Rekognition Image API 结果的质量？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 支持各种图像分辨率。为获得最佳效果，我们建议使用 VGA (640x480) 或更高的分辨率。Amazon Rekognition 接受的最低图像分辨率为 80 x 80 像素，但低于 QVGA (320 x 240) 的图像可能会增大遗漏面孔、对象或不当内容的几率。"
    },
    {
        "query":"Amazon Rekognition Image 能够检测和分析多小的对象？",
        "intention":"知识问答",
        "reply":"一般来说，请确保图片中存在的最小对象或面部至少占据图片较短一边（以像素为单位）的 5%。例如，如果您使用 1600x900 的图像，则最小的面部或对象在任一维度上应至少为 45 个像素。"
    },
    {
        "query":"如何获取人工审核的 Amazon Rekognition 预测？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 可直接与 [Amazon Augmented AI (Amazon A2I)](https://aws.amazon.com/cn/augmented-ai/) 集成，以便您可以轻松地将低置信度预测从Amazon Rekognition 图像传送给人工审核者。使用用于内容审核的 Amazon Rekognition API 或 Amazon A2I 控制台，您可以指定 Amazon A2I 将预测传送给审核者时所处的条件，该条件可以是置信度阈值或随机抽样百分比。如果您指定置信度阈值，Amazon A2I 将仅传送那些低于该阈值的预测进行人工审核。您可以随时调整这些阈值，以确保在准确性和经济效益性之间实现适当均衡。或者，如果您指定采样百分比，Amazon A2I 将传送随机预测样本进行人工审核。这可以帮助您实施审计，以定期监控预测的准确性。Amazon A2I 还为审核人员提供了一个 Web 界面，其中包含他们完成审核任务所需的所有说明和工具。有关使用 Amazon Rekognition 实施人工审核的更多信息，请参阅 [Amazon A2I 网页](https://aws.amazon.com/cn/augmented-ai/)。"
    },
    {
        "query":"视频分辨率如何影响 Rekognition Video API 结果的质量？",
        "intention":"知识问答",
        "reply":"系统经过训练可识别大于 32 像素 (在最短的维度上) 的面孔，这些面孔将转换为可识别的最小面孔大小，在 QVGA 分辨率下大约 1/7 的屏幕较小维度到高清 1080p 分辨率下 1/30 的屏幕维度之间变化。例如，在 VGA 分辨率下，对于小于 1/10 屏幕较小维度的面孔，用户应期望较低的效果。"
    },
    {
        "query":"还有什么可以影响 Rekognition Video API 的质量？",
        "intention":"知识问答",
        "reply":"除了视频分辨率之外，严重模糊、快速移动的人物、照明条件、姿势也可能会影响 API 的质量。"
    },
    {
        "query":"适合 Rekognition Video API 的首选用户视频内容是什么？",
        "intention":"知识问答",
        "reply":"此 API 最适合在正常色彩和照明条件下使用正面视野拍摄的消费者和专业视频。此 API 未针对黑白、IR 或极端照明条件进行了测试。建议对误报敏感的应用程序丢弃置信度得分低于所选 (特定于应用程序) 置信度得分的输出。"
    },
    {
        "query":"Amazon Rekognition 在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"如需获取已推出 Amazon Rekognition 的全部区域列表，请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"什么是标签？",
        "intention":"知识问答",
        "reply":"标签是基于其内容在图像中找到的对象、场景或概念。例如，热带海滩上的人物照片可能包含“人物”、“水”、“沙”、“棕榈树”和“泳装”(对象)、“海滩”(场景)、“户外”(概念) 等标签。"
    },
    {
        "query":"什么是置信度得分，如何使用它？",
        "intention":"知识问答",
        "reply":"置信度得分是一个介于 0 与 100 之间的数字，用于指示给定预测正确的概率。以上面的热带海滩为例，如果对象和场景检测过程对于标签“水”返回 99 的置信度分数，对于标签“棕榈树”返回 35，则说明这张图像很有可能包含水但不包含棕榈树。\n对检测错误 (假阳性) 非常敏感的应用程序应丢弃置信度得分低于某一阈值的结果。最佳阈值因应用而异。在许多情况下，将最低置信度值设为高于默认值可获得最佳的用户体验。"
    },
    {
        "query":"什么是对象和场景检测？",
        "intention":"知识问答",
        "reply":"对象和场景检测是指分析图片或视频，根据其视觉内容分配标签的过程。Amazon Rekognition Image 通过 [DetectLabels API](http://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html) 来完成此操作。 您可以使用此 API 自动识别数千种对象、场景和概念，并为每个标签返回置信度得分。DetectLabels 使用的默认置信度阈值为 50。对象和场景检测是需要搜索和组织大型图像库的客户的理想选择，如依赖于用户生成内容的消费者和生活方式应用、寻求改进其定位算法的广告技术公司等。"
    },
    {
        "query":"Amazon Rekognition 能否检测对象位置并返回边界框？",
        "intention":"知识问答",
        "reply":"能，Amazon Rekognition 可以在图片和视频中检测到许多常见对象的位置，例如“人”、“汽车”、“枪”或“狗”。对于所找到的对象的每个实例，您可以获得边框的坐标，以及置信度分数。有关对象边界框的 API 响应结构的更多详情，请参阅[本文档](https://docs.aws.amazon.com/rekognition/latest/dg/labels-detect-labels-image.html)。"
    },
    {
        "query":"Amazon Rekognition 能否提供有关检测到的标签间关系的信息？",
        "intention":"知识问答",
        "reply":"能，对于找到的每个标签，Amazon Rekognition 都会返回其父项、别名和类别（如果存在）。父项按层次顺序返回到“父项”字段中。第一个父标签是直接父项，后面的标签则是父项的父项。例如，当识别出“汽车”时，Amazon Rekognition 将返回两个父标签：“车辆”（父项）和“交通运输”（父项的父项）。别名是与主标签具有相同含义的标签，并在“别名”字段中返回。例如，由于“手机”是“移动电话”的别名，因此 Amazon Rekognition 会在“手机”标签的“别名”字段中返回“移动电话”。类别根据共同主题对标签进行分组，并在“类别”字段中返回。例如，由于“狗”是“动物和宠物”类别下的标签，因此 Amazon Rekognition 会在“狗”标签的“类别”字段中返回“动物和宠物”。有关受支持标签及其分类的完整列表的更多详细信息，请访问 [Amazon Rekognition 标签检测文档](https://docs.aws.amazon.com/rekognition/latest/dg/labels.html)。"
    },
    {
        "query":"Amazon Rekognition 支持哪些类型的标签？",
        "intention":"知识问答",
        "reply":"Rekognition 支持数千种属于常见类别的标签，包括但不限于："
    },
    {
        "query":"对于视频分析，对象和场景检测有何不同？",
        "intention":"知识问答",
        "reply":"Rekognition Video 使您能够自动识别数以千计的对象（如车辆或宠物）和活动（如庆祝会或舞会），并为您提供每个标签的时间戳和置信度分数。它还依赖视频中的运动和时间上下文准确地识别复杂的活动（如“吹蜡烛”或“灭火”）。"
    },
    {
        "query":"我找不到需要的标签。如何申请新标签？",
        "intention":"知识问答",
        "reply":"请通过 Amazon Rekognition 控制台向我们发送您的标签请求，方法是在“搜索所有标签”部分的输入字段中键入标签名称，然后单击“请求 Rekognition 检测”所请求的标签。Amazon Rekognition 会根据客户反馈不断扩展其标签目录。"
    },
    {
        "query":"什么是 Image Properties？",
        "intention":"知识问答",
        "reply":"Image Properties 是 Amazon Rekognition Image 的一项功能，用于检测主色和图像质量。它可以检测整个图像的主色、图像前景、图像背景，以及具有局部边界框的对象，还可以通过亮度、锐度和对比度得分来衡量图像质量。可以使用 IMAGE\\_PROPERTIES 作为输入参数，通过 DetectLabels API 来调用 Image Properties，无论是否使用 GENERAL\\_LABEL 输入参数进行标签检测。要了解更多信息，请访问 [Amazon Rekognition 标签检测文档](https://docs.aws.amazon.com/rekognition/latest/dg/labels-detect-labels-image.html)。"
    },
    {
        "query":"如何确定主色？",
        "intention":"知识问答",
        "reply":"Image Properties 会返回四种格式的主色：RGB、十六进制代码、CSS 颜色和简化颜色。Amazon Rekognition 首先按像素百分比识别主色，然后将这些颜色映射到 [140 CSS 调色板](https://www.w3schools.com/cssref/css_colors.php)、RGB、十六进制代码和 12 种简化颜色（即“绿色”、“粉色”、“黑色”、“红色”、“黄色”、“青色”、“棕色”、“橙色”、“白色”、“紫色”、“蓝色”、“灰色”）。默认情况下，除非客户指定要返回的颜色数，否则 Image Properties 会返回十（10）种主色，。API 最多可以返回 12 种主色。"
    },
    {
        "query":"如何解释亮度、锐度和对比度分数？",
        "intention":"知识问答",
        "reply":"Image Properties 会为每个亮度、锐度和对比度分数提供一个介于 0 到 100 之间的值。例如，曝光不足的图像将返回低亮度分数，而明亮的图像将返回高亮度分数。"
    },
    {
        "query":"如何检查 Amazon Rekognition 是否已更新其模型？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 会返回 LabelModelVersion 参数，您可通过该参数了解模型是否已更新。对象和场景检测模型会根据客户反馈经常更新。"
    },
    {
        "query":"我是否可以使用自定义标签分析面部、自定义文本检测？",
        "intention":"知识问答",
        "reply":"否。自定义标签用于查找图像中的对象和场景。自定义标签不适用于分析面部、自定义文本检测。您应该使用其他 Rekognition API 执行这些任务。请参阅文档了解面部分析、文本检测。"
    },
    {
        "query":"我是否可以使用自定义标签查找不安全的图像内容？",
        "intention":"知识问答",
        "reply":"可以。自定义标签用于查找图像中的对象和场景。对自定义标签进行训练后，可以检测特定于用例的不安全图像内容，可以检测特定于您用例的不安全图像内容。此外，请参阅审核 API 文档，以检测通用的不安全图像内容。"
    },
    {
        "query":"训练一个自定义模型需要多少图像？",
        "intention":"知识问答",
        "reply":"训练自定义模型所需的图像数量取决于您希望模型预测的自定义标签的变化和训练数据的质量。例如，叠加在图像上的一个独特徽标可以通过 1-2 个训练图像检测到，而需要在很多变体（规模、看法、变形）下检测的更为精细的徽标可能需要按顺序使用具有高质量注释的数十个到数百个训练示例。如果您已经有很多带有标签的图像，我们建议使用尽可能多的图像来训练模型。请参阅文档了解最大训练数据集大小的限制。\n虽然有时候可能需要数百个图像来训练具有高准确度的自定义模型，但使用自定义标签，您可以先对每个标签使用数十个图像来训练模型，审核您的测试结果以了解哪里不起作用，然后相应地添加新训练图像并再次训练以迭代改进您的模型。"
    },
    {
        "query":"我应该为我的自定义模型预置多少推理计算资源？",
        "intention":"知识问答",
        "reply":"所需的并行推理计算资源数量取决于您在给定时间点需要处理的图像数量。单个资源的吞吐量取决于图像大小、图像复杂性（检测到的图像显示出多少）和自定义模型复杂性等因素。我们建议您监测您预置自定义模型所需的频率及一次需要处理的图像数量，以便最有效地安排自定义模型的预置。  \n 如果您希望定期处理图像（例如，每天一次或每周一次，或一天中预定的时间），则应在预定时间开始预置您的自定义模型，处理所有图像，然后停止预置。如果您不停止预置，即使不处理任何图像，也会向您收取费用。"
    },
    {
        "query":"什么是内容审核？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 使用深度学习来检测明显或暗示性的成人内容、暴力内容、武器、视觉干扰内容、毒品、酒精、烟草、仇恨符号、赌博，以及图像和视频中的粗鲁手势。除了根据存在的不当或冒犯性内容对图像或视频进行标记之外，Amazon Rekognition 还会返回一个带有置信度的分级标签列表。这些标签会指明所检测到的内容类型的特定子类别，从而让开发人员能够进行更细化的控制，以便筛选和管理大量用户生成的内容 (UGC)。这一 API 可以用于社交和交友网站、相片分享平台、博客和论坛、儿童应用程序、电子商务网站、娱乐和在线广告服务等应用场景。"
    },
    {
        "query":"Amazon Rekognition 会检测哪些类型的不当、冒犯性和不想要的内容？",
        "intention":"知识问答",
        "reply":"您可在[此处](https://docs.aws.amazon.com/rekognition/latest/dg/moderation.html)找到 Amazon Rekognition 检测到的内容类别的完整列表。\nAmazon Rekognition 可以返回一个分级标签列表，并附带检测到的每个标签的置信度。例如，对于一张不当图像，Rekognition 可能会返回最高级别的标签“明显的裸露”及其置信度。开发人员可以使用这些元数据总体标记内容，例如需要对所有类型的明显成人内容进行标记时。同时，Rekognition 还会提供“男性裸体图形”等更多信息及其置信度，从而返回细化到第二级别的信息。开发人员可以利用这一信息来构建更为复杂的筛选逻辑，从而服务于不同地域和人口统计学。\n请注意，内容审核 API 并不能筛选出所有不当或冒犯性的内容。另外，此 API 无法检测出某个图片是否包含违法内容（如儿童色情内容）或不正常成人内容。\n如果您需要检测图片中其他类型的不当内容，请通过下文介绍的反馈流程联系我们。"
    },
    {
        "query":"如何才能知道我目前使用的是哪个模型版本？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 会定期完善其模型。要跟踪模型版本，您可以使用 API 响应中的“ModerationModelVersion”字段。"
    },
    {
        "query":"如何确保 Amazon Rekognition 符合我的图像或视频审核使用案例的准确度目标？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 的内容审核模型已经经过调整和大规模测试，但我们不建议您用自己的数据集来测量准确性和衡量性能。\n您可以在 API 请求中使用“MinConfidence”参数，以便在内容检测 (灵敏度) 和检测准确性 (精度) 之间实现平衡。如果降低“MinConfidence”，您可能会检测出大多数不当内容，但也有可能检测出事实上不属于不当内容的内容。如果提高“MinConfidence”，您可能会确保检测出的所有内容事实上都是不当内容，但可能不会标记出某些不当内容。"
    },
    {
        "query":"怎样向 Rekognition 提供反馈以便改进内容审核 API？",
        "intention":"知识问答",
        "reply":"请通过 [AWS 客户支持](https://aws.amazon.com/cn/premiumsupport/)向我们发送您的请求。Amazon Rekognition 会根据客户反馈持续扩大检测到的不当内容的类型。请注意，该反馈流程不适用于违法内容（例如儿童色情内容）。"
    },
    {
        "query":"什么是面部分析？",
        "intention":"知识问答",
        "reply":"面部分析是检测图像中的面部并从中提取相关面部属性的过程。Amazon Rekognition Image 接收并返回图像中检测到的每副面孔的边界框以及诸如性别、太阳镜的存在和面部标记点等属性。Rekognition Video 将返回在视频中检测到的带有时间戳的面孔、位置、边界框以及面部标记点。"
    },
    {
        "query":"我可以从 Amazon Rekognition 获得哪些面部属性？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 可以针对检测到的每副面孔返回以下面部属性，以及每个属性的边界框和置信度得分："
    },
    {
        "query":"什么是面部姿态？",
        "intention":"知识问答",
        "reply":"面部姿态是指检测到的面部在俯仰、翻滚和偏转轴上的旋转。这些参数中的每一个都返回为 -180 到 +180 度之间的角度。面部姿态可用于查找面部边界多边形 (与矩形边界框相对) 的方向、测量变形、精确跟踪面部等。"
    },
    {
        "query":"什么是面部质量？",
        "intention":"知识问答",
        "reply":"面部质量使用锐度和亮度这两个参数来描述检测到的面部图像的质量。两个参数都返回为 0 和 1 之间的值。您可以对这些参数应用阈值，以筛选照明充足和锐利的面部。这对于对面部图片质量要求较高的应用（如面部比较和面部识别）非常有用。"
    },
    {
        "query":"什么是面部标记？",
        "intention":"知识问答",
        "reply":"面部标记是一组突出点，通常位于关键面部组成部分 (如眼睛、鼻子和嘴) 的边角、尖端或中点处。Amazon Rekognition [DetectFaces API](http://docs.aws.amazon.com/rekognition/latest/dg/API_DetectFaces.html) 返回一组面部标记，可用于裁剪面部、进行面部变形、覆盖自定义遮罩以创建自定义筛选器等。\n问：可以在一张图像中检测多少副面孔？\n您可以使用 Amazon Rekognition 在一张图像中检测多达 100 副面孔。"
    },
    {
        "query":"对于视频分析，面部分析有何不同？",
        "intention":"知识问答",
        "reply":"借助 Rekognition Video，您可以在视频中找到相应面孔并分析面孔属性，如是否面带微笑、眼睛是否睁着或是否在表达情感。Rekognition Video 将返回检测到的带有时间戳的面孔、检测到的每副面孔的位置、边界框以及诸如左眼、右眼、鼻子、左嘴角、右嘴角等标记点。这些位置和时间信息可用于随时间轻松地跟踪用户情绪，并提供诸如自动面孔边框、高光或裁剪等其他功能。视频分析不支持用户搜索。"
    },
    {
        "query":"除了视频分辨率之外，还有什么可以影响 Rekognition Video API 的质量？",
        "intention":"知识问答",
        "reply":"除了视频分辨率之外，优质和有代表性的面部 (属于要搜索的面部集合) 具有重大影响。将每个人的多个面孔实例与胡子、眼镜、姿势（侧貌和正貌）等变量结合使用将会显著改善效果。通常，移动非常快速的人物可能会降低灵敏度。另外，模糊的视频也可能会降低质量。"
    },
    {
        "query":"什么是面部比较？",
        "intention":"知识问答",
        "reply":"面孔比较是将一副面孔与一副或多副面孔进行比较以测量相似性的过程。借助 [CompareFaces API](http://docs.aws.amazon.com/rekognition/latest/dg/API_CompareFaces.html)，您可以通过 Amazon Rekognition Image 测量两张图像中的面部属于同一个人的可能性。API 将源输入图像中的面孔与在目标输入图像中检测到的每副面孔进行比较，并针对每次比较返回相似度得分。您还能够获得检测到的每副面孔的边界框和置信度得分。您可以利用面部比较技术以近乎实时的方式根据某人的档案照片验证其身份。"
    },
    {
        "query":"可以使用包含多副面孔的源图像吗？",
        "intention":"知识问答",
        "reply":"可以。如果源图像包含多副面孔，[CompareFaces](http://docs.aws.amazon.com/rekognition/latest/dg/API_CompareFaces.html) 会检测最大的面孔并使用它来与在目标图像中检测到的每副面孔进行比较。"
    },
    {
        "query":"可以对多少副面孔进行比较？",
        "intention":"知识问答",
        "reply":"您可以将源图像中的一副面孔与目标图像中的多达 15 副检测到的面孔进行比较。"
    },
    {
        "query":"什么是面孔搜索？",
        "intention":"知识问答",
        "reply":"面孔搜索是使用输入面孔在存储面孔集合中搜索相似匹配面孔的过程。借助面孔搜索，您可以轻松构建进行银行付款的多重身份验证、面向员工的自动化楼宇进出管理系统等应用程序。"
    },
    {
        "query":"什么是面孔集合？如何创建？",
        "intention":"知识问答",
        "reply":"面孔集合是面孔向量（即面孔的数学表示形式）的可搜索索引。Rekognition 不会在您的集合中存储面孔图像。利用 CreateCollection API，您可以轻松地在受支持的 AWS 区域中创建集合并获取一个 Amazon 资源名称（ARN）。每个面孔集合都具有与其关联的唯一 CollectionId。"
    },
    {
        "query":"如何将面孔添加到集合中进行搜索？",
        "intention":"知识问答",
        "reply":"要向现有的面孔集合中添加面孔，请使用 IndexFaces API。此 API 接受 S3 对象或图像字节数组形式的图像，并将检测到的面孔向量表示添加到面孔集合中。IndexFaces 会为添加的每个面孔向量返回一个唯一的 FaceId 和面孔边界框。\n使用 CreateUser 和 AssociateFaces API 可以聚合同一个人的多个面孔矢量，从而创建和存储用户向量。用户向量比单个面孔向量更可靠，因为它们包含多个面孔向量，这些向量具有不同程度的照明度、清晰度、姿势、外观差异等。与使用单个面孔向量的面孔搜索相比，使用用户向量进行面孔搜索可以显著提高准确性。用户向量与关联的面孔向量存储在同一个集合中。"
    },
    {
        "query":"如何从集合中删除面孔？",
        "intention":"知识问答",
        "reply":"要从现有的面孔集合中删除面孔，请使用 DeleteFaces API。此 API 将对使用 CollectionId 提供的面孔集合执行操作，删除与 FaceId 列表对应的条目。如果 FaceID 与用户向量相关联，则首先需要使用 DisassoicateFaces API 调用将其从用户向量中删除。此外，您还可以使用 DeleteUsers API 从现有集合中删除用户。\n有关添加和删除面孔的详细信息，请参阅我们的“管理集合”示例。"
    },
    {
        "query":"如何在面孔集合中搜索用户？",
        "intention":"知识问答",
        "reply":"创建用户和关联的 FaceID 后，可以使用图片（SearchUsersByImage）、用户 ID（SearchUsers）或 FaceID（SearchUsers）进行搜索。这些 API 接受一副输入面孔并返回一组按相似度得分从高到低排列的匹配面孔。有关更多详情，请参阅我们的“搜索用户”示例。"
    },
    {
        "query":"如何在面孔集合中搜索面孔？",
        "intention":"知识问答",
        "reply":"创建好带有索引的面部集合后，您可以使用图片 ([SearchFaceByImage](http://docs.aws.amazon.com/rekognition/latest/dg/API_SearchFacesByImage.html)) 或 FaceId ([SearchFaces](http://docs.aws.amazon.com/rekognition/latest/dg/API_SearchFaces.html)) 在其中搜索面部。这些 API 接受一副面孔并返回一组按相似度得分从高到低排列的匹配面部。有关更多详情，请参阅我们的[搜索面孔](https://docs.aws.amazon.com/rekognition/latest/dg/search-face-with-id-procedure.html)示例。"
    },
    {
        "query":"视频分析的面孔搜索有何不同？",
        "intention":"知识问答",
        "reply":"Rekognition Video 允许您针对具有数千万个面孔的集合进行实时面孔搜索。首先，创建一个面部集合，您可以将面孔存储在该集合中，这是面孔特征的矢量表示。然后，Rekognition 会在整个视频中搜索面孔集合，找出看着相似的面孔。Rekognition 将针对视频中的每个面孔返回一个置信度得分，以便您可以在应用程序中显示可能匹配的结果。视频分析不支持用户搜索。"
    },
    {
        "query":"除了视频分辨率之外，还有什么可以影响 Video API 的质量？",
        "intention":"知识问答",
        "reply":"除了视频分辨率之外，优质和有代表性的面部 (属于要搜索的面部集合) 具有重大影响。将每个人的多个面部实例与胡子、眼镜、姿势 (侧貌和正貌) 等变量结合使用将会显著改善效果。通常，移动非常快速的人物可能会降低灵敏度。另外，模糊的视频也可能会降低质量。"
    },
    {
        "query":"什么是名人识别？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 的名人识别是基于深度学习的易用 API，用于检测和识别某一领域中著名、显赫和成绩突出的人士。构建的 RecognizeCelebrities API 可以规模化运营，并能识别许多行业的名人，如政治家、体育运动员、商业、娱乐和媒体名人等。我们的名人识别功能非常适合需要根据自己独特兴趣索引和搜索名人数字图片库的客户。"
    },
    {
        "query":"通过名人识别 API 可以识别哪些人？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 只能识别深度学习模型经训练后能够识别的名人。请注意，RecognizeCelebrities API 并不是权威名单，也决不是详尽的名人列表。此功能旨在根据客户的需求和反馈包括尽可能多的名人。我们会不断添加新名称，但如果被其他团体或我们的客户视为名人的人员未被“名人识别”所识别，这并不表示我们对其名人身份的看法。如果您希望看到“名人识别”所识别出的其他名人，请提交反馈。"
    },
    {
        "query":"通过 Amazon Rekognition API 识别的名人是否可以申请从此功能中删除？",
        "intention":"知识问答",
        "reply":"可以。如果名人希望从此功能中删除，则他或她可以向 AWS 客户支持发送电子邮件，我们将处理此删除请求。"
    },
    {
        "query":"支持哪些来源提供有关名人的其他消息？",
        "intention":"知识问答",
        "reply":"API 支持一个可选的来源列表，用于提供有关名人的其他信息，以此作为 API 响应的一部分。目前，如果有 IMDB URL，我们就会提供。我们可能会在以后添加其他来源。"
    },
    {
        "query":"对于视频分析，名人识别有何不同？",
        "intention":"知识问答",
        "reply":"借助 Rekognition Video，您可以检测和识别知名人士在视频中出现的时间和位置。时间编码的输出包括名人的姓名和唯一 ID、边界框坐标、置信度得分和指向名人相关内容的 URL，例如，名人的 IMDB 链接。即使有时脸部被遮挡，也会在视频中检测到名人。通过此功能，您可以为数字视频库编制索引并搜索它们，获取与您的特定营销和媒体需求相关的使用案例。"
    },
    {
        "query":"除了视频分辨率之外，还有什么可以影响 Rekognition Video API 的质量？",
        "intention":"知识问答",
        "reply":"移动非常快速的名人和模糊的视频可能会影响 Rekognition Video API 的质量。另外，男演员/女演员常用的浓妆和伪装也会影响质量。"
    },
    {
        "query":"什么是文本检测？",
        "intention":"知识问答",
        "reply":"文本检测是 Amazon Rekognition 的一项功能，您可借助它来检测和识别图像或视频中的文本，如街道名称、标题、产品名称、叠加图形、视频字幕和车辆牌照。文本检测专门用于真实的图像和视频，而不是文档图像。Amazon Rekognition 的 DetectText API 接收图像并返回每个检测到的字符串的文本标签和边界框以及置信度分数。例如，在图像共享和社交媒体应用程序中，您可以根据包含相同文本标签的图像索引启用可视化搜索。在安全应用程序中，您可以根据交通摄像头拍摄的图像中的车牌号识别车辆。同样，对于视频，您可以使用 StartTextDetection 和 GetTextDetection API 检测文本并获得每次检测的置信度评分和时间戳。在媒体和娱乐应用程序中，您可以创建文本元数据，以支持搜索相关内容，如新闻、体育成绩、商业广告和标题。您还可以查看检测到的违反策略或合规性的文本，例如垃圾邮件发送者覆盖的电子邮件地址或电话号码。"
    },
    {
        "query":"Amazon Rekognition 文本检测支持哪种类型的文本？",
        "intention":"知识问答",
        "reply":"文本检测专门用于真实的图像和视频，而不是文档图像。它支持大多数拉丁语脚本中的文本和嵌入各种布局、字体和样式，以及以各种方向作为横幅和海报覆盖在背景对象上的数字。文本检测可识别每个图像或视频帧中最多 50 个字符序列，并将它们列为单词和行。文本检测支持文本从水平轴旋转最多 -90 至 +90 度。"
    },
    {
        "query":"是否可以将文本检测限制为图像或视频帧中的特定区域？",
        "intention":"知识问答",
        "reply":"可以，您可以使用文本检测筛选选项在 API 请求中指定最多 10 个感兴趣区域 (ROI)。Amazon Rekognition 将仅返回这些区域内的文本。"
    },
    {
        "query":"是否可以按单词置信度或边界框大小过滤文本检测？",
        "intention":"知识问答",
        "reply":"可以，在 API 请求中，您可以使用文本检测筛选选项为最小置信度评分或最小边界框尺寸指定阈值。"
    },
    {
        "query":"如何向 Rekognition 提供反馈以便改进其文本识别？",
        "intention":"知识问答",
        "reply":"请通过 [AWS 客户支持](https://aws.amazon.com/premiumsupport/)向我们发送您的请求。Amazon Rekognition 会根据客户反馈持续扩大识别出的文本内容类型。"
    },
    {
        "query":"Amazon Rekognition 可以检测到哪些个人防护装备 (PPE)？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 的“DetectProtectiveEquipment”可以检测常见类型的面罩、手套和头罩。要了解更多信息，请参阅[功能文档](https://docs.aws.amazon.com/rekognition/latest/dg/ppe-detection.html)。您还可以使用 Amazon Rekognition 自定义标签来检测 PPE，例如醒目的背心、安全护目镜和您企业独有的其他 PPE。 要了解如何使用 Amazon Rekognition 自定义标签进行自定义 PPE 检测，请访问 [Github 存储库](https://github.com/aws-samples/amazon-rekognition-custom-ppe-detection-with-custom-labels)。"
    },
    {
        "query":"Amazon Rekognition 能否检测防护装备位置并返回边界框？",
        "intention":"知识问答",
        "reply":"能。Amazon Rekognition 的“DetectProtectiveEquipment”API 可以检测防护装备的位置，如图像中人员佩戴的面罩、手套和头罩。对于所检测到的每个防护装置，您可以获得边界框矩形坐标，以及置信度得分。有关 API 响应的详细信息，请参阅[文档](https://docs.aws.amazon.com/rekognition/latest/dg/ppe-detection.html)。"
    },
    {
        "query":"该服务能否检测出面罩是否佩戴正确？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 的“DetectProtectiveEquipment”API 输出为检测到的每个防护装置提供“CoversBodyPart”值 (true/false) 和置信度布尔值。这提供了有关佩戴人员是否将防护装备佩戴在身体相应部位信息。对相应身体部位上是否存在防护装备的预测有助于过滤出 PPE 在图像中但实际上未佩戴在人身上的情况。但是，它并不表示或暗示该人员已得到防护装备的充分保护，或该人员已正确佩戴防护装备。"
    },
    {
        "query":"Amazon Rekognition PPE 检测能否识别被检测的人员？",
        "intention":"知识问答",
        "reply":"不能。Amazon Rekognition PPE 检测不能执行面部识别或面部比较，无法识别被检测的人员。"
    },
    {
        "query":"在哪里可以找到有关 API 限制和延迟的更多信息？",
        "intention":"知识问答",
        "reply":"请参阅 [Amazon Rekognition PPE 检测文档](https://docs.aws.amazon.com/rekognition/latest/dg/ppe-detection.html)以获取 API 限制和延迟的最新详细信息。"
    },
    {
        "query":"如何将工作场所摄像头拍摄的图像发送至 Amazon Rekognition？",
        "intention":"知识问答",
        "reply":"您可通过多种方式采集工作场所摄像头拍摄的图像。请参阅 [Amazon Rekognition PPE 检测博客](https://aws.amazon.com/blogs/machine-learning/automatically-detecting-personal-protective-equipment-on-persons-in-images-using-amazon-rekognition/)了解更多信息。"
    },
    {
        "query":"PPE 检测如何定价？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition PPE 检测的定价类似于其他 Amazon Rekognition Image API，根据图像定价。要了解更多信息，请访问 [Amazon Rekogntion 定价页面](https://aws.amazon.com/cn/rekognition/pricing/)。"
    },
    {
        "query":"Amazon Rekognition Streaming Video Events 的工作原理是什么？ 您可以使用新的或现有的 Kinesis Video Streams 开启 Amazon Rekognition Streaming Video 事件。在为 Amazon Rekognition 配置流式传输处理器设置时，您可以选择想要检测的标注（人、宠物或包裹）、Rekognition 为每个事件应该处理的视频持续时间（每个运动事件最多 120 秒）和/或要通过 Rekognition 处理的帧上的感兴趣区域。Rekognition Streaming Video Event API 仅在您向 Rekognition 发送通知开启处理视频流式传输时才会处理视频。",
        "intention":"知识问答",
        "reply":"连接的摄像头上检测到运动时，您可以向 Rekognition 发送通知，以开启处理视频流式传输。Rekognition 会处理相应的 Kinesis Video Stream，即运动后检测，以寻找您指定的所需对象。一旦检测到所需对象，Amazon Rekognition 将向您发送通知。此通知包括检测到的对象、边界框、对象的放大图像和时间戳。"
    },
    {
        "query":"如何在视频中找到每次检测的时间线？ Amazon Rekognition Video 按时间戳或视频片段返回标签结果。您可以使用 GetLabelDetection API 中的 AggregateBy 输入参数来选择您希望如何组织这些结果。",
        "intention":"知识问答",
        "reply":"要了解有关时间戳和片段的更多信息并查看示例 API 响应，请访问[检测视频中的标签](https://docs.aws.amazon.com/rekognition/latest/dg/labels-detecting-labels-video.html)。"
    },
    {
        "query":"Amazon Rekognition Video 可以检测哪些类型的媒体分析片段？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition Video 可以检测下列类型的一段或完整媒体分析：\nAmazon Rekognition Video 为每个检测到整体提供开始、结束、持续时间和时间代码，并为它们各自提供时间戳（毫秒）、SMPTE 格式代码和帧编号选项。"
    },
    {
        "query":"如何开始使用 Amazon Rekognition Video 进行媒体分析？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition Video [片段检测 API](https://docs.aws.amazon.com/rekognition/latest/dg/segments.html) 提供了媒体分析功能。这是一个[异步 API](https://docs.aws.amazon.com/rekognition/latest/dg/api-video.html)，由以下两个操作组成：[*StartSegmentDetection*](https://docs.aws.amazon.com/rekognition/latest/dg/API_StartSegmentDetection.html)（用于启动分析）和 *[GetSegmentDetection](https://docs.aws.amazon.com/rekognition/latest/dg/API_GetSegmentDetection.html)*（用于获取分析结果）。要开始使用，请参阅[文档](https://docs.aws.amazon.com/rekognition/latest/dg/segment-api.html)。\n如果您想可视化媒体分析的结果，或者甚至尝试将自己的视频与其他 Amazon AI 服务（例如 Amazon Transcribe）一起使用，请使用 [Media Insights 应用程序](https://github.com/awslabs/aws-media-insights) – 一种无服务器框架和演示应用程序，可使用 AWS Machine Learning 和媒体服务轻松为您的视频、音频、文本和图像资源生成见解并开发应用程序。您可以使用提供的 AWS CloudFormation 模板轻松地加速自己的演示应用程序，以试验自己的视频并显示分析结果。"
    },
    {
        "query":"什么是帧精确时间码？",
        "intention":"知识问答",
        "reply":"帧精确时间码为视频或实体的相关片段提供精确的帧编号。媒体公司通常使用 SMPTE（美国电影电视工程师协会）格式 hours:minutes:seconds:frame number（例如 00:24:53:22）处理时间码。"
    },
    {
        "query":"Amazon Rekognition Video 片段检测帧是否准确？",
        "intention":"知识问答",
        "reply":"是的，Amazon Rekognition Video 片段检测 API 提供了帧精确 SMPTE 时间码，以及每次检测开始和结束的毫秒时间戳。"
    },
    {
        "query":"Amazon Rekognition Video 片段检测可以处理哪些类型的帧速率格式？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition Video 片段检测可自动处理整数、小数和掉帧标准（帧速率介于 15 至 60fps 之间）。例如，片段检测支持常见的帧速率（例如 23.976fps、25fps、29.97fps 和 30fps）。在每种情况下，都使用帧速率信息来提供帧精确时间码。"
    },
    {
        "query":"我可以应用哪些筛选选项？",
        "intention":"知识问答",
        "reply":"您可以在提出 API 请求时为每个片段类型指定最低置信度。例如，您可以筛选出置信度得分低于 70% 的任何片段。对于黑框检测，您还可以控制视为黑色像素的最大像素亮度，例如，值 40 代表颜色范围 0 到 255。此外，您还可以控制将框归类为黑框要求该框中的像素达到此黑色像素亮度标准的百分比，例如 99%。使用这些筛选条件，在检测黑框时您还可以考虑变化的视频质量和格式。例如，与现代数字视频相比，从磁带存档回收的视频可能噪声很高，并且黑度等级不同。有关更多详细信息，请参阅[此页面](https://docs.aws.amazon.com/rekognition/latest/dg/API_StartSegmentDetection.html)。"
    },
    {
        "query":"Amazon Rekognition 如何统计已处理的图像数量？",
        "intention":"知识问答",
        "reply":"对于接受图像作为输入的 API，Amazon Rekognition 会将已分析图像的实际数量统计为已处理的图像数量。DetectLabels、DetectModerationLabels、DetectFaces、IndexFaces、RecognizeCelebrities 以及 SearchFaceByImage 和 Image Properties 都属于这一类别。对于 CompareFaces API，当需要传递两张图像作为输入时，只有源图像会被计入已处理的图像数量。\n对于不需要图像作为输入参数的 API 调用，Amazon Rekognition 将每次 API 调用计入已处理的图像数量。SearchFaces 属于此类别。\n其余的 Amazon Rekognition API（ListFaces、DeleteFaces、CreateCollection、DeleteCollection 和 ListCollections）不计入已处理的图像数量。"
    },
    {
        "query":"Amazon Rekognition 如何统计已处理的视频的分钟数？",
        "intention":"知识问答",
        "reply":"对于已存档的视频，Amazon Rekognition 会统计由 API 成功处理的视频的分钟数，并根据时间计费。对于实时流视频，您可以为我们成功处理的视频每五秒收费一次。"
    },
    {
        "query":"在我的面部集合中存储特征向量需要付费吗？",
        "intention":"知识问答",
        "reply":"是的。Amazon Rekognition 每月向每 1000 张面部向量收取 0.01 USD 的费用。有关详细信息，请参阅[定价页面](https://aws.amazon.com/rekognition/pricing/)。"
    },
    {
        "query":"Amazon Rekognition 是否参与 AWS 免费套餐？",
        "intention":"知识问答",
        "reply":"是的。作为 [AWS 免费使用套餐](https://aws.amazon.com/free/)的一部分，您可以免费开始使用 Amazon Rekognition。注册后，Amazon Rekognition 新客户在前 12 个月可享受：每月免费分析 5000 张图像。在此免费套餐中，您可以使用所有 Amazon Rekognition API（Image Properties 除外），而且还能免费存储多达 1000 张面部图像。此外，Amazon Rekognition Video 客户第一年可以每月免费分析 1000 分钟的视频。"
    },
    {
        "query":"Amazon Rekognition Video 能否处理存储在 Amazon S3 上的图像？",
        "intention":"知识问答",
        "reply":"可以。您只需将 Amazon Rekognition API 指向您的 S3 存储桶，就可以开始分析存储在 Amazon S3 中的图像。您不需要移动数据。有关如何在 Amazon Rekognition API 调用中使用 S3 对象的更多详情，请参阅我们的[检测标签练习](https://docs.aws.amazon.com/rekognition/latest/dg/labels-detecting-labels-video.html)。"
    },
    {
        "query":"使用 Amazon Rekognition 时，我能否使用另一个区域中的 Amazon S3 存储桶中存储的图像？",
        "intention":"知识问答",
        "reply":"不能。请确保您要使用的 Amazon S3 存储桶与您的 Amazon Rekognition API 终端节点位于同一个区域内。"
    },
    {
        "query":"如何使用 Amazon Rekognition 批量处理多个图像文件？",
        "intention":"知识问答",
        "reply":"您可以按照 [GitHub 上的 Amazon Rekognition 批处理示例](https://github.com/jhy/RekognitionS3Batch)中所述的步骤批量处理您的 Amazon S3 图像。"
    },
    {
        "query":"如何结合使用 AWS Lambda 与 Amazon Rekognition？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 提供对 AWS Lambda 的无缝访问，并让您能够对 Amazon S3、Amazon DynamoDB 等 AWS 数据存储进行基于触发器的图像分析。要将 Amazon Rekognition 与 AWS Lambda 配合使用，请按照[此处](http://docs.aws.amazon.com/lambda/latest/dg/with-on-demand-https-example-configure-event-source_2.html)介绍的步骤进行操作，并选择 Amazon Rekognition 蓝图。"
    },
    {
        "query":"Amazon Rekognition 是否可与 AWS CloudTrail 搭配使用？",
        "intention":"知识问答",
        "reply":"可以。Amazon Rekognition 支持将以下操作作为事件记录到 CloudTrail 日志文件中：CreateCollection、DeleteCollection、CreateStreamProcessor、DeleteStreamProcessor、DescribeStreamProcessor、ListStreamProcessors 和 ListCollections。有关与 AWS CloudTrail 集成的 Amazon Rekognition API 调用的更多详细信息，请参阅“使用 AWS CloudTrail 记录 Amazon Rekonition API 调用”。"
    },
    {
        "query":"是否存储由 Amazon Rekognition 处理的图片和视频输入，以及如何由 AWS 使用？",
        "intention":"知识问答",
        "reply":"除非您根据下文说明选择退出，否则 Amazon Rekognition 可以存储和使用仅由该服务单独处理的图片和视频输入，提供和维护服务，并且改进和提高 Amazon Rekognition 及其他 Amazon 机器学习/人工智能技术的质量。使用您的内容对于持续改进您的 Amazon Rekognition 客户体验（包括相关技术的开发和培训）至关重要。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。您可以通过使用 AWS Organizations 退出策略选择不再使用您的图片和视频输入来改进或提高 Amazon Rekognition 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"是否可以删除 Amazon Rekognition 存储的图片和视频输入？",
        "intention":"知识问答",
        "reply":"可以。您可以通过联系 [AWS Support](https://aws.amazon.com/contact-us/)，请求删除与您的账户相关联的图像和视频。删除图片和视频输入会使您的 Amazon Rekognition 体验变差。"
    },
    {
        "query":"谁有权访问由 Amazon Rekognition 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问由 Amazon Rekognition 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"我是否仍然拥有由 Amazon Rekognition 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"由 Amazon Rekognition 处理的内容是否会移到使用 Amazon Rekognition 的 AWS 区域之外？",
        "intention":"知识问答",
        "reply":"由 Amazon Rekognition 处理的任何内容都将静态加密并存储在您使用 Amazon Rekognition 的 AWS 区域中。除非您按照下文说明选择退出，否则 Amazon Rekognition 处理的部分内容可能存储在另一个 AWS 区域中，仅用于持续改进和开发您的 Amazon Rekognition 客户体验及其他 Amazon 机器学习/人工智能技术。您可以通过联系 AWS Support，请求删除与您的账户相关联的图像和视频。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。如果您选择不再使用您的内容来改进和提升 Amazon Rekognition 及其他 Amazon 机器学习/人工智能技术的质量，您的内容将不会存储在其他 AWS 区域中。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"是否可以将 Amazon Rekognition 用于针对不满 13 岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 Amazon Rekognition 服务条款的规定，包括按照 COPPA 的要求来提供任何需要的通知并获得任何需要的、可验证的家长同意，才能将 Amazon Rekognition 用于全部或部分针对不满 13 岁的儿童的网站、项目或其他应用程序。"
    },
    {
        "query":"怎样确定我的网站、项目或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、计划或其他应用是否受 COPPA 约束的指南，请直接参阅[美国联邦贸易委员会](https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions)提供并维护的各种资源。 该网站还提供有关如何确定某种服务是否全部或部分面向不满 13 岁儿童的信息。"
    },
    {
        "query":"Amazon Rekognition 服务是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 服务符合 HIPAA 要求，包含在 AWS 商业伙伴协议 (AWS BAA) 中。如果您已签订 AWS BAA，Amazon Rekognition 将仅根据 AWS BAA 条款使用、披露和维护您的受保护健康信息 (PHI)。"
    },
    {
        "query":"如何控制对 Amazon Rekognition 的用户访问？",
        "intention":"知识问答",
        "reply":"Amazon Rekognition 与 [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam) 集成。 您可以使用 AWS IAM 策略确保只有授权用户才能访问 Amazon Rekognition API。有关更多详细信息，请参阅 [Amazon Rekognition 身份验证和访问控制页面](http://docs.aws.amazon.com/rekognition/latest/dg/authentication-and-access-control.html)。"
    },
    {
        "query":"如何举报潜在的 Amazon Rekognition 滥用行为？",
        "intention":"知识问答",
        "reply":"如果怀疑他人以滥用或非法的方式使用 Amazon Rekognition，或侵犯了您或他人的权利，[请举报此类使用行为，AWS 将调查此问题](https://pages.awscloud.com/rekognition-abuse.html)。\n详细了解 Amazon Rekognition 定价"
    },
    {
        "query":"什么是 AWS Snowball？",
        "intention":"知识问答",
        "reply":"AWS Snowball 是一项可提供安全、耐用设备的服务，使您能够将 AWS 计算和存储功能引入到您的边缘环境中，并在 AWS 中传入和传出数据。这些耐用设备通常是指 AWS Snowball 或 AWS Snowball Edge 设备。以前，AWS Snowball 专指这些设备的早期硬件版本，然而，该模式已被更新硬件所取代。现在，AWS Snowball 服务通过 Snowball Edge 设备运行，其中包括板载计算功能和存储功能。"
    },
    {
        "query":"什么是 AWS Snowball Edge？",
        "intention":"知识问答",
        "reply":"AWS Snowball Edge 是 AWS Snowball 服务提供的一款边缘计算和数据传输设备。它具有板载存储和出色的计算能力，可以为边缘站点的使用案例提供精选的 AWS 服务。Snowball Edge 提供两种选项，Storage Optimized 和 Compute Optimized，支持在船舶、风车和远程工厂等断开连接的环境中在本地处理和收集数据。请[单击此处](https://aws.amazon.com/cn/snowball/features/)，详细了解其功能。"
    },
    {
        "query":"原始的 50 TB 和 80 TB AWS Snowball 设备会怎样？",
        "intention":"知识问答",
        "reply":"原始 Snowball 设备已退出服务状态，Snowball Edge Storage Optimized 现在已成为数据传输使用的主要设备。"
    },
    {
        "query":"我能否继续订购原始的 Snowball 50TB 和 80TB 设备？",
        "intention":"知识问答",
        "reply":"不能。现在，对于数据传输需求，请选择 Snowball Edge Storage Optimized 80TB 或 210TB 设备。"
    },
    {
        "query":"Snowball Edge 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"首先，请根据您需要传输的数据量和本地处理所需的计算，在 AWS 管理控制台中请求一个或多个 Snowball Edge Compute Optimized 或 Snowball Edge Storage Optimized 设备。在发运给您之前，设备上会自动配置、加密和预安装您选择的存储桶、数据、Amazon EC2 AMI 和 Lambda 函数。收到货后，您将设备连接到本地网络并手动或通过 DHCP 自动设置 IP 地址。然后，使用 Snowball Edge 客户端软件、任务清单和解锁代码验证 Snowball Edge 设备或集群的完整性，并将其解锁以供使用。生成的清单和解锁代码是唯一的，并通过加密逻辑绑定到您的账户和发运给您的 Snowball Edge，并且不能与任何其他设备一起使用。复制到 Snowball Edge 的数据会自动加密并存储在您指定的存储桶中。\n所有物流和运输均由 Amazon 完成，因此，当您完成复制并准备好运回设备时，E Ink 运输标签将自动更新回邮地址，以确保将 Snowball Edge 设备运送到正确的 AWS 机构。设备发运后，您可以通过 Amazon Simple Notification Service (Amazon SNS) 发送的邮件、生成的文本和电子邮件或直接从控制台接收跟踪状态。\nSnowball Edge 资源的所有管理工作都可以在 AWS 管理控制台中执行，这些操作需要系统工程师的参与。"
    },
    {
        "query":"Snowball Edge 和 Snowball 之间有什么区别？",
        "intention":"知识问答",
        "reply":"AWS Snowball 现在是指整体服务，而 Snowball Edge 是指服务使用的当前设备的类型 – 有时统称为 AWS Snowball 设备。最初，早期的 Snowball 硬件设计仅用于数据传输。Snowball Edge 拥有可在本地运行计算的额外功能，即便没有网络连接也可以进行。"
    },
    {
        "query":"Snowball Edge Storage Optimized 和 Snowball Edge Compute Optimized 选项之间有什么区别？",
        "intention":"知识问答",
        "reply":"如果您需要将大量 TB 到 PB 级数据安全快速地传输到 AWS，那么 Snowball Edge Storage Optimized 是最理想的选择。它也非常适合运行 IoT 数据聚合和转换等通用分析。它提供高达 80TB 或 210TB 的存储空间和 10Gb、40Gb 或 100Gb 的网络连接，以满足大规模数据传输和预处理应用场景的需求。我们建议将 Snowball Edge Compute Optimized 用于需要在将数据传输到 AWS 之前访问强大的计算和高速存储以进行数据处理的使用案例。它采用 104 个 vCPU、28TB 的 NVMe SSD 和高达 100Gb 的网络，可运行高分辨率视频处理、高级物联网数据分析以及连接受限环境中机器学习模型的实时优化等应用。有关更多详细信息，请参阅[文档](https://docs.aws.amazon.com/snowball/latest/developer-guide/device-differences.html)。"
    },
    {
        "query":"Snowball Edge 适合什么样的用户使用？",
        "intention":"知识问答",
        "reply":"如果您需要在险峻、严苛、移动或断开连接（或间歇性连接）的环境中运行计算，则可以考虑 Snowball Edge。对于带宽无法满足高速在线传输服务（如 AWS DataSync）需求的大型数据传输和迁移，也可以考虑它。  \n   \n 如果您需要将 TB 到 PB 级数据安全快速地传输到 AWS，那么 Snowball Edge Storage Optimized 是最理想的数据传输选择。如果您有大量积压数据要传输或经常收集需要传输到 AWS 的数据，而您的存储所在位置没有高带宽的 Internet 连接或其成本十分高昂，则可以使用 Snowball Edge Storage Optimized。  \n   \n 您也可以使用 Snowball Edge 运行边缘计算工作负载，如在 Snowball Edge 群集上执行本地数据分析并将数据写入 Amazon S3 兼容端点。您可以利用 NFS 文件接口等内置功能将其简化到现有工作流程中并将文件迁移到设备，同时保留文件元数据。\nSnowball Edge 可以在偏远的地点或恶劣的工作环境中运行，例如车间、石油和天然气钻井平台、矿场、医院和行驶中的运载工具上。Snowball Edge 经过预配置，不必连接 Internet，因此数据处理和收集操作可在独立的操作环境中进行。Snowball Edge 让您可以像完全连接 AWS 一样，在边缘运行相同的软件并使用精选的 AWS 功能。"
    },
    {
        "query":"是否可以使用 Snowball Edge 将数据从一个 AWS 区域迁移到另一个 AWS 区域？",
        "intention":"知识问答",
        "reply":"不可以。Snowball Edge 的用途是充当将大量数据传入和传出指定 AWS 区域的数据传输解决方案。对于需要在多个 AWS 区域之间进行数据传输的情况，我们建议您使用 S3 跨区域复制作为替代解决方案。"
    },
    {
        "query":"使用 Snowball Edge 可以传输多少数据？",
        "intention":"知识问答",
        "reply":"使用 Snowball Edge 几乎可以传输任意数量的数据，从几 TB 到很多 PB 不等。使用一个 Snowball Edge Storage Optimized 设备最多可传输约 80TB，使用多台设备可以并行或按顺序传输更大的数据集。"
    },
    {
        "query":"传输数据需要多长时间？",
        "intention":"知识问答",
        "reply":"数据传输速度受很多因素影响，其中包括本地网络速度、文件大小以及从本地服务器读取数据的速度。使用 Snowball Edge 将多达 80TB 数据传输到 AWS 从始到终大约需要一周的时间，其中包括在 AWS 数据中心的正常运输和处理时间。"
    },
    {
        "query":"我在执行特定作业时可以持有 Snowball Edge 多长时间？",
        "intention":"知识问答",
        "reply":"出于安全考虑，使用 AWS Snowball Edge 设备的作业必须在准备好后的 360 天内完成。如果您需要将一台或多台设备保留超过 360 天，请联系 AWS Support。否则在 360 天后，设备将被锁定，无法再访问，且必须返回。如果 AWS Snowball Edge 设备在导入作业期间被锁定，我们仍可以将设备上的现有数据传输到 Amazon S3。"
    },
    {
        "query":"Snowball Edge 设备有哪些规格？",
        "intention":"知识问答",
        "reply":"请查看 [AWS Snowball 功能页面](https://aws.amazon.com/cn/snowball-edge/features/)获取功能详细信息，并查看 [Snowball Edge 文档页面](https://docs.aws.amazon.com/snowball/latest/developer-guide/getting-started.html)获取完整的硬件规格列表，包括网络连接、散热及电源要求、产生的噪音和尺寸等。"
    },
    {
        "query":"Snowball Edge 支持哪些网络接口？",
        "intention":"知识问答",
        "reply":"用于数据传输设备的 Snowball Edge Storage Optimized 有两个 10G RJ45 端口、一个 10/25G SFP28 端口和一个 40G/100G QSFP28 端口。  \n   \n 用于边缘计算设备的 Snowball Edge Storage Optimized 有一个 10G RJ45 端口、一个 10/25G SFP28 端口和一个 40G QSFP+ 端口。\nSnowball Edge Compute Optimized 设备（包括 GPU 选项）有两个 10G RJ45 端口、一个 10/25G SFP28 端口和一个 40G/100G QSFP28 端口。"
    },
    {
        "query":"Snowball Edge 的默认运送方式是什么？ 我可以选择加急送货吗？",
        "intention":"知识问答",
        "reply":"Snowball Edge 默认使用 UPS 两日送达运输。如果您的作业对时间要求严格，可以选择加急送货。"
    },
    {
        "query":"Snowball Edge 支持 EC2 实例吗？",
        "intention":"知识问答",
        "reply":"支持。Snowball Edge Storage Optimized 选项支持 SBE1 实例。  \n   \n Snowball Edge Compute Optimized 选项具有功能更加强大、规模更大的实例 sbe-c，适用于计算密集型应用程序。  \n   \n 具有可选 GPU 的 Snowball Edge Compute Optimized 设备可以使用 sbe-g 实例来加速应用程序的性能。  \n   \n 借助对 Snowball Edge 设备上 EC2 兼容实例的支持，您可以在 EC2 上完成构建和测试，然后在 Snowball Edge 上运行 AMI 以处理偏远位置和网络连接断开位置中的工作负载。"
    },
    {
        "query":"如何将 GPU 与 AWS Snowball Edge 的 SBE 实例一起使用？",
        "intention":"知识问答",
        "reply":"AWS Snowball Edge Compute Optimized 上的 GPU 选项附带 SBE-G 实例，可以利用板载 GPU 加速应用程序性能。收到设备后，选择使用 SBE-G 实例的选项，以便将板载 GPU 与您的应用程序配合使用。"
    },
    {
        "query":"我何时应该在 AWS Snowball Edge 上使用 EC2 兼容实例？",
        "intention":"知识问答",
        "reply":"如果您的应用程序在边缘运行，并作为虚拟机（一种 Amazon 系统映像，简称“AMI”）进行管理和部署，则您应该使用 EC2 兼容实例。"
    },
    {
        "query":"是否可以将多台 Snowball Edge 设备用于高可用性存储？",
        "intention":"知识问答",
        "reply":"可以，您可以将多台 Snowball Edge Compute Optimized 设备集群化为更大的持久存储池，该存储池具有单个 Amazon S3 兼容端点。例如，如果您有 16 台 Compute Optimized 设备，则可以将它们配置为单个集群，从而提供 S3 兼容端点和 500TB 存储空间。或者，可以单独使用这些设备而不将其集群化，每台设备都提供一个独立的 S3 兼容端点和 31TB 可用存储空间。使用 Snowball Edge Compute Optimized 设备时，无法使用 Amazon S3 兼容存储创建持久集群。"
    },
    {
        "query":"我什么时候会考虑创建存储集群？",
        "intention":"知识问答",
        "reply":"借助 Snowball Edge 存储集群，您可以提高本地存储的持久性和可扩展性。存储集群化将创建持久、可扩展、与 S3 兼容的本地存储。AWS Snowball Edge 存储集群允许您根据自己的需求，通过添加或移除设备来增加或减少本地存储容量，让您不再需要购买昂贵的硬件。"
    },
    {
        "query":"如何开始在 Snowball Edge 上进行本地计算？",
        "intention":"知识问答",
        "reply":"您可以在创建 AWS Snowball Edge 任务期间使用 AWS 管理控制台、AWS Snowball 软件开发工具包或 AWS CLI 为基于现代分布式容器的应用程序启用 EKS-A，以及 Amazon EC2 AMI 或 Lambda 函数。"
    },
    {
        "query":"是否可以使用现有的 Amazon EC2 API 在设备上启动、停止和管理实例？",
        "intention":"知识问答",
        "reply":"支持。AWS Snowball Edge 提供与 Amazon EC2 兼容的终端节点，可用于在 AWS Snowball Edge 上启动、停止和管理实例。该终端节点与 AWS CLI 和 AWS 软件开发工具包兼容。"
    },
    {
        "query":"AWS Snowball Edge 支持哪些 Amazon EC2 功能？",
        "intention":"知识问答",
        "reply":"AWS Snowball Edge 上运行的 Amazon EC2 终端节点可提供一组 EC2 功能，对于客户的边缘计算场景非常有用。其中包括运行、终止和描述已安装的 AMI 和正在运行的实例的 API。Snowball Edge 还支持 EC2 映像的数据块存储，该存储使用一组 Amazon EBS API 命令进行管理。"
    },
    {
        "query":"是否可以将现有的 Amazon EBS 卷与 AWS Snowball Edge 搭配使用？",
        "intention":"知识问答",
        "reply":"不能。目前，您不能将现有的 EBS 卷与 AWS Snowball Edge 结合使用，但 Snowball Edge 可以提供数据块存储卷，该卷可以使用兼容 EBS 的 API 进行管理。"
    },
    {
        "query":"要在 AWS Snowball Edge 上运行 Amazon EC2 实例，需要执行哪些操作？",
        "intention":"知识问答",
        "reply":"要运行实例，请在创建作业期间提供 AMI ID 并在给您运送设备时预装映像。"
    },
    {
        "query":"是否可以将其他管理程序的映像转化到 AMI 中或反向操作？",
        "intention":"知识问答",
        "reply":"支持。您可以使用 EC2 VM Import/Export 服务将 KVM/VMware 映像导入或导出 AMI。请参阅 [VM Import/Export 文档](https://aws.amazon.com/ec2/vm-import/)了解更多详细信息。\n如果要运行许可软件，包括除 AWS Snowball 服务提供的操作系统以外的操作系统，则必须执行此操作。"
    },
    {
        "query":"使用这项功能，可以运行哪些操作系统？",
        "intention":"知识问答",
        "reply":"Snowball Edge 上的 Amazon EC2 为各种免费使用的操作系统 (OS)（如 Ubuntu 和 CentOS）提供默认支持。他们将作为 AMI 显示，不经过任何修改就可以加载到 Snowball 边缘中。要在 Snowball Edge EC2 实例上运行需要许可证的其他操作系统，您必须提供自己的许可证，然后使用 [Amazon EC2 VM Import/Export（VMIE）](https://docs.aws.amazon.com/vm-import/latest/userguide/what-is-vmimport.html)导出 AMI。"
    },
    {
        "query":"可以在 sbe-c 实例上运行哪些工作负载？",
        "intention":"知识问答",
        "reply":"sbe-c 实例配备多达 104 个 vCPU、根卷的临时实例存储和 418GB 内存，以在几乎没有 Internet 连接的环境中运行各种各样的计算密集型应用程序，如高级机器学习、全运动视频分析、LAMP 堆栈和 EC2 托管的容器。SBE-C 实例还可以将 Snowball Edge NVMe SSD 和 HDD 数据块存储用于永久性卷。"
    },
    {
        "query":"如何确保 AMI 可在 AWS Snowball Edge 的 EC2 兼容实例上兼容运行？",
        "intention":"知识问答",
        "reply":"绝大多数情况下，AWS 中 C5 实例类型上运行的 AMI 与 AWS Snowball Edge Storage Optimized 上的 SBE1 实例兼容。我们建议您先在 C5 实例类型中测试应用程序，以确保它们可以在 Snowball Edge Storage Optimized 设备上运行。\n绝大多数情况下，AWS 中 M5a 实例类型上运行的 AMI 与 AWS Snowball Edge Compute Optimized 上的 SBE-C 实例兼容。对于 AWS Snowball Edge Compute Optimized 设备上运行的 SBE-C 实例，我们建议您在 M5a 实例类型上测试您的应用程序。\n对于具有 GPU 选项的 Snowball Edge Compute Optimized 的 SBE-G 实例类型，我们建议您首先在 EC2 P3 实例类型上测试您的应用程序。"
    },
    {
        "query":"是否可以在设备上安装多个实例？",
        "intention":"知识问答",
        "reply":"支持。您可以在设备上运行多个实例，只要所有实例使用的总资源均在[您的 Snowball Edge 设备的限制范围内](https://docs.aws.amazon.com/snowball/latest/developer-guide/ec2-edge-limits.html)。"
    },
    {
        "query":"如何在 AWS Snowball Edge 集群上使用 sbe-c 和 sbe-g 实例？",
        "intention":"知识问答",
        "reply":"所有 EC2 兼容实例都可以在 AWS Snowball Edge 集群的每个节点上运行。使用 AWS 控制台预置 AWS Snowball Edge 集群时，您可以提供要在每个集群节点上运行的实例的详细信息，例如，要运行的 AMI 以及要使用的实例类型和大小。您可以针对集群的每个节点使用相同或不同的 AMI。  \n   \n 问：如何手动启动实例？\n每个 AMI 都有一个相关的 AMI ID。您可以通过提供此 ID 使用 run-instance 命令启动实例。运行此命令会返回一个 instance-id 值，可用于管理此实例。"
    },
    {
        "query":"如何管理 AWS Snowball Edge 上的实例？",
        "intention":"知识问答",
        "reply":"您可以使用 describe-images 命令检查设备上安装的所有映像的状态。要查看设备上运行实例中的活跃实例，您可以使用 describe-instance-status 命令。"
    },
    {
        "query":"如何终止现有实例？",
        "intention":"知识问答",
        "reply":"您可以使用 terminate-instance 命令终止正在运行的实例。"
    },
    {
        "query":"如何保护传输中的 AMI？",
        "intention":"知识问答",
        "reply":"Snowball Edge 采用 256 位加密对包括 AMI 在内的所有数据进行加密。您可以使用 [AWS Key Management Service (KMS)](https://aws.amazon.com/cn/kms/) 管理加密密钥。您的密钥不会存储在此设备上，并且您需要有密钥和解锁码才能在本地使用此设备。除了使用防拆封外壳外，Snowball Edge 还采用行业标准可信平台模块 (TPM)，能够检测对硬件、固件或软件进行的越权修改。AWS 会通过外观和加密方式检查每台设备是否有篡改迹象。"
    },
    {
        "query":"如何处理 AWS Snowball Edge 上计算实例的软件许可问题？",
        "intention":"知识问答",
        "reply":"您要负责为实例上运行的所有软件获取许可。具体来说，对于 Windows 操作系统，您可以在 EC2 的 AMI 中安装获得许可的操作系统，然后使用 [VM Import/Export](https://docs.aws.amazon.com/vm-import/latest/userguide/what-is-vmimport.html) 将 AMI 加载到您的 Snowball Edge 设备，以此将现有许可用于此设备上正在运行的实例。"
    },
    {
        "query":"如何在 Snow 设备上开始使用最新的 AWS IoT Greengrass？",
        "intention":"知识问答",
        "reply":"AWS IoT Greengrass 是一种 IoT 边缘运行时（从 2.0 版起为开源）以及能够帮助您在自己的设备上构建、部署和管理 IoT 应用程序的云服务。运行 AWS IoT Greengrass 的 AWS Snow 设备可以作为 IoT 枢纽、数据聚合点、应用程序监视器或轻量级分析引擎进行操作。\n要开始在 AWS Snow 设备上使用 AWS IoT Greengrass，请遵循下面列出的步骤："
    },
    {
        "query":"什么是 AWS Snowball Edge 上的数据块存储？",
        "intention":"知识问答",
        "reply":"您可以同时在 Snowball Edge Compute Optimized 和 Snowball Edge Storage Optimized 设备上运行数据块存储。您可以使用 Amazon EBS 功能的子集将数据块存储卷附加到 EC2 实例，这些功能使您能够在 Snowball Edge 设备上为 EC2 实例配置和管理卷。"
    },
    {
        "query":"为什么要使用 AWS Snowball Edge 数据块存储？",
        "intention":"知识问答",
        "reply":"Snowball Edge 数据块存储使您能够为设备上基于 Amazon EC2 的应用程序设置多个永久性数据块存储卷（除了根卷之外）。这样可以为 Snowball Edge 上运行的 EC2 应用程序提供比仅使用根卷可以达到的更高的性能和更多的存储容量。现在，您可以将多个卷附加到您的 EC2 实例。附加到 Snowball Edge 上的 EC2 实例的卷的持续周期与实例的运行寿命无关，这样一来，您可以在 Snowball Edge 上部署多个应用程序并且可以根据需要启动和停止应用程序。"
    },
    {
        "query":"我可以使用哪种类型的数据块存储卷，每种卷类型可以使用多少容量？",
        "intention":"知识问答",
        "reply":"Snowball Edge 数据块存储提供性能优化的 SSD 卷 (sbp1) 和容量优化的 HDD 卷 (sbg1)，从而可以满足各种数据处理和数据收集应用程序的 IOPS 和吞吐量要求。数据块存储卷的最大大小为每个卷 10TB，您最多可以在 Snowball Edge 上的任何一个 EC2 实例中附加 10 个卷。\n在 Snowball Edge Compute Optimized 上，您最多可以为 sbp1 卷使用 7TB NVMe SSD，这对于机器学习等延迟敏感性应用程序非常有益。在 Snowball Edge Storage Optimized 上，您最多可以为 sbp1 卷使用 1 TB 的 SATA SSD，这对于预处理数据非常有益。\n在 Snowball Edge Storage Optimized 和 Compute Optimized 设备中，您都可以使用容量优化的卷 sbg1 在 HDD 上存储数据。这种卷类型适合数据收集和 IOPS 密集型较低的应用程序。它的最大卷大小为 10TB，而且您可以为任何实例附加多个卷。您最多可以为 Snowball Edge Storage Optimized 上的 sbg1 使用 86TB HDD 存储。您最多可以为 Snowball Edge Compute Optimized 上的 sbg1 使用 40TB HDD 存储。"
    },
    {
        "query":"如何开始在 Snowball Edge 上使用数据块存储？",
        "intention":"知识问答",
        "reply":"默认情况下，所有的 Snowball Edge 设备现在都随附有数据块存储功能。当您解锁设备后，您可以使用 AWS CLI 或软件开发工具包创建卷并将它们附加到 Amazon EC2 实例上。您可以在每个 EC2 实例上附加多个卷，但任何时候，一个卷都只能附加到一个实例上。"
    },
    {
        "query":"Snowball Edge 数据块存储与 Amazon EBS 有何不同？",
        "intention":"知识问答",
        "reply":"Snowball Edge 数据块存储具有与 Amazon EBS 卷不同的性能、可用性和持久性特性。而且，它只提供 Amazon EBS 功能子集。例如，Snowball Edge 数据块存储当前不支持快照功能。请参阅 [Snowball Edge 的技术文档](https://docs.aws.amazon.com/snowball/)，了解受支持的 API 的完整列表。"
    },
    {
        "query":"SBE 数据块存储支持哪些 Amazon EBS API？",
        "intention":"知识问答",
        "reply":"要与 SBE 上的数据块存储交互，您可以使用、创建、删除、附加、分离和描述卷的 EBS API。请参阅 [Snowball Edge 的技术文档](https://docs.aws.amazon.com/snowball/)，了解受支持的 API 的完整列表。"
    },
    {
        "query":"我可以在 Snowball Edge 上使用哪些 Amazon 系统映像来利用数据块存储？",
        "intention":"知识问答",
        "reply":"Snowball Edge 上运行的任何 Amazon 系统映像 (AMI) 一次最多可以访问 10 个数据块存储卷。AWS 提供的一般 AMI 和自定义 AMI 可以访问任何数据块存储卷。使数据块存储卷工作时，不需要满足任何特殊要求。然而，有些操作系统的性能比特定驱动程序好。请参阅 [Snowball Edge 技术文档](https://docs.aws.amazon.com/snowball/)了解详细信息。"
    },
    {
        "query":"一台设备上的卷是否可以被另一台设备上运行的 Amazon EC2 实例访问？",
        "intention":"知识问答",
        "reply":"一台 Snowball Edge 上创建的卷只能被该设备上运行的 EC2 实例访问。\n如何监控各种卷使用的存储容量？\n您可以使用 Snowball 客户端的 [describe-device](https://docs.aws.amazon.com/snowball/latest/developer-guide/using-client-commands.html#client-status) 命令监控设备上使用的数据块存储量。当创建卷时，请求的所有存储容量均根据可用容量分配给该卷。"
    },
    {
        "query":"我能否将数据块存储上存储的数据传输到云中的 Amazon EBS 卷？",
        "intention":"知识问答",
        "reply":"不能直接传输。当设备返回 AWS 时，Snowball Edge 上的数据块存储卷上的数据会被删除。如果您希望将数据保存在块存储卷中，则必须将数据复制到 Amazon S3 适配器（对于数据迁移作业）或 Amazon S3 兼容存储（对于边缘计算设备）。当设备作为导入作业的一部分返回 AWS 时，来自 Amazon S3 适配器的数据将被复制到您的 S3 存储桶中。对于边缘计算，当连接到 AWS 区域时，您可以使用 AWS DataSync 在区域中的 S3 存储桶和设备上的 S3 存储桶之间在线来回传输数据。"
    },
    {
        "query":"我能否在相同设备上操作对象和数据块存储？",
        "intention":"知识问答",
        "reply":"是的，在单个设备部署中，您可以在 Snow 上使用与 Amazon S3 兼容的存储，并在同一 Snowball Edge 计算优化设备上使用块存储。用于 sbg1 卷的对象存储和块存储共享相同的数据磁盘容量，并在下订单时预先配置。底层存储功能协同工作，从而使数据块或对象存储的 I/O 需求增长不会损害其他存储的可用性和性能。  请注意，在集群部署中，数据磁盘上的所有存储都用于 Amazon S3 容量，不支持此操作。"
    },
    {
        "query":"从 AWS 管理控制台订购 Snowball Edge 时，是否需要配置卷或任何存储资源？",
        "intention":"知识问答",
        "reply":"否，您可以在收到设备后将卷添加到您的 Amazon EC2 实例。"
    },
    {
        "query":"我是否需要在数据块和对象存储之间分配设备上的存储资源？",
        "intention":"知识问答",
        "reply":"否。您可以根据您的应用程序需求动态添加或删除卷和对象。"
    },
    {
        "query":"卷是否已默认加密？",
        "intention":"知识问答",
        "reply":"Snowball Edge 在设计时考虑到了最敏感数据的安全性。写入数据块卷的所有数据都使用您通过 AWS Key Management Service (KMS) 提供的密钥进行加密。所有卷都使用 Snowball Edge 作业创建期间选择的相同密钥进行了加密。密钥不会在设备上永久存储，断电后即擦除。"
    },
    {
        "query":"实现 Snowball Edge 数据块存储最佳性能的最佳做法是什么？",
        "intention":"知识问答",
        "reply":"使用数据块存储附加的其他卷提供的性能最多比根卷高 10 倍。我们建议您使用相对较小的根卷，并创建其他数据块存储卷来为您的 Amazon EC2 应用程序存储数据。请参阅 [Snowball Edge 的技术文档](https://docs.aws.amazon.com/snowball/latest/developer-guide/BestPractices.html)，以了解性能最佳实践和建议的驱动程序。"
    },
    {
        "query":"哪些区域提供 Snowball Edge？",
        "intention":"知识问答",
        "reply":"请参阅[区域服务可用性](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)页面，了解最新信息。"
    },
    {
        "query":"能否将 Snowball Edge 运送到其他 AWS 区域？",
        "intention":"知识问答",
        "reply":"不能。Snowball Edge 设备设计为在您的 S3 存储桶所在 AWS 区域内请求和使用。不能从一个区域请求设备，然后返回到另一个区域。用于从欧盟 AWS 区域导入和导出数据的 Snowball Edge 设备可以在其他欧盟成员国中的任何国家/地区使用。请参阅[区域服务可用性](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)页面，了解最新信息。"
    },
    {
        "query":"Snowball Edge 会对我的数据加密吗？",
        "intention":"知识问答",
        "reply":"Snowball Edge 采用 256 位加密对所有数据加密。您可以使用 AWS Key Management Service (AWS KMS) 管理加密密钥。您的密钥永远不会存储在该设备上，当设备断开连接并准备运回 AWS 时所有内存都将被擦除。"
    },
    {
        "query":"Snowball Edge 如何以物理方式保护我的数据？",
        "intention":"知识问答",
        "reply":"Snowball Edge 使用防篡改外壳，同时采用行业标准受信任平台模块 (TPM)，该模块能够检测对硬件、固件或软件进行的越权修改。AWS 通过外观和加密方式检查每台设备是否有篡改迹象，验证 TPM 是否未检测到任何更改。"
    },
    {
        "query":"Snowball Edge 如何以数字方式帮助保护我的数据？",
        "intention":"知识问答",
        "reply":"Snowball Edge 在设计时考虑到了最敏感数据的安全性。所有数据都使用您通过 AWS Key Management Service (KMS) 提供的密钥进行加密。密钥不会在设备上永久存储，断电后即擦除。应用程序和 Lambda 函数在物理隔离的环境中运行，无法访问存储。最后，在您的数据传输到 AWS 以后，我们会依据美国国家标准与技术研究院制定的标准从设备上擦除您的数据。Snowball Edge 设备针对攻击进行了强化保护，所有配置文件都用密钥进行加密和签名，而密钥永远不会出现在该设备上。"
    },
    {
        "query":"有没有什么办法能轻松地跟踪我的数据传输任务？",
        "intention":"知识问答",
        "reply":"Snowball Edge 使用创新的电子墨水运输标签，该标签的设计可确保设备自动发送到正确的 AWS 设施。在您完成数据传输任务以后，可以使用 Amazon SNS 生成的文本消息或电子邮件和控制台进行跟踪。"
    },
    {
        "query":"我能否获得从我的账户发起的所有 Snowball API 调用的历史记录，以便用于安全分析和运营方面的故障排除？",
        "intention":"知识问答",
        "reply":"支持。要接收从您账户发起的 Snowball API 调用的历史记录，您只需在 AWS 管理控制台中启用 CloudTrail 即可；Snowball 中的以下 API 调用不会记录和传递：DescribeAddress（响应中）、CreateAddress（请求中）、DescribeAddresses（响应中）。"
    },
    {
        "query":"如何将我的数据传输到 Snowball Edge？",
        "intention":"知识问答",
        "reply":"在您连接并激活 Snowball Edge 之后，就可以通过 S3 兼容终端节点或 NFS 文件接口（在设备上都有提供）将本地资源中的数据传输到该设备。您也可以使用 Snowball 客户端复制数据。有关更多信息，请参阅 [Snowball Edge 文档](https://docs.aws.amazon.com/snowball/index.html)。  \n   \n 问：当我将数据复制到 Snowball Edge 上并将 Snowball Edge 运回 AWS 后，何时可以删除磁盘上的数据？\n等待确认 AWS 已收到 Snowball Edge 且您的数据已成功传输到适当的 S3 存储桶中，然后再删除您的磁盘上的任何数据。虽然 AWS 在 S3 传输期间确认已将文件完整复制到 Snowball Edge 中，但在将数据从您的磁盘中删除之前，您仍要负责确认数据的完整性。AWS 对复制或传输过程中丢失或损坏的任何数据不负任何责任。"
    },
    {
        "query":"当数据传输到 Snowball Edge 之后我需要做什么？",
        "intention":"知识问答",
        "reply":"数据传输任务完成后，Snowball Edge 上的电子墨水显示屏会自动更新回邮运输标签以指示要运送到的正确 AWS 设施。您只需将 Snowball Edge 交给最近的 UPS 即可。您可以通过 Amazon SNS 生成的文本消息或电子邮件，或者直接在 AWS 管理控制台中跟踪您传输任务的状态。"
    },
    {
        "query":"是否有可能在返回 AWS 后停止从 AWS Snowball 设备摄入数据？",
        "intention":"知识问答",
        "reply":"是。您可以通过取消 AWS Snow 管理控制台中的任务或联系 AWS Support 来停止向 Amazon Simple Storage Service (Amazon S3) 存储桶摄入数据。"
    },
    {
        "query":"导入完成后，是否可以阻止返回的 AWS Snowball 设备上的数据被删除？",
        "intention":"知识问答",
        "reply":"否。AWS 根据 NIST 800-88 标准使用自动化的工作流程安全地删除数据摄入，并通过完全擦除 Snowball 设备来清理返回的设备。此外，在数据导入完成后，无法将相同的设备返回给您。"
    },
    {
        "query":"我最快多久能够访问导出的数据？",
        "intention":"知识问答",
        "reply":"我们通常会在收到申请之后的 24 小时内开始导出数据，导出数据可能需时一周。任务完成且设备就绪后，我们将使用您在创建任务时选择的发货选项将其发送给您。"
    },
    {
        "query":"对于加载到 Amazon S3 中的数据，我是否会获得校验和或者任何类型的收据？",
        "intention":"知识问答",
        "reply":"是。AWS 将导入日志报告保存到您的存储桶。此报告包含逐个文件的信息，如上传的日期和时间、Amazon S3 密钥、MD5 校验和，以及字节数等。有关更多详细信息，请参阅 [文档](https://docs.aws.amazon.com/snowball/latest/developer-guide/validation.html \"AWS 文档\")。"
    },
    {
        "query":"我为我的 Amazon S3 存储桶创建了一个导出任务，它包含位于 Amazon S3 Glacier 存储类中的键。这些键是否将导出？",
        "intention":"知识问答",
        "reply":"Amazon S3 工作流中的 Snowball 导出任务不能访问存储在 Amazon S3 Glacier 或 Amazon S3 Glacier Deep Archive 存储类中的对象。您必须首先从 Glacier 或 Glacier Deep 归档中恢复这些对象至少 10 天，或直到 Snow 导出任务完成，以确保这些恢复的对象成功复制到 Snowball 设备。"
    },
    {
        "query":"为何要使用大型数据迁移管理器？",
        "intention":"知识问答",
        "reply":"大型数据迁移管理器可帮助您规划和监控从最小 500TB 到 PB 级的大数据迁移。首先，大型数据迁移管理器使您能够为迁移项目创建计划，使用多台 AWS Snow 系列设备完成 PB 级的数据迁移或从崎岖的坚固便携的边缘设备进行数据移动。制定一个计划可以帮助您和您使用 Snow 的合作伙伴在项目目标上达成一致，比如要迁移的数据大小和项目持续时间。一旦制定了计划，大型数据迁移管理器将在 AWS Snow 系列管理控制台中提供一个中心位置，让您随时了解所有 Snow 任务的进度（未完成任务的数量、当前摄入的数据等），并查看下一个任务订单的预计安排。最后，您可以在监控迁移时控制项目计划，并在认为合适的时候延长或结束迁移。\n在启动大型数据迁移管理器之前，您必须自己跟踪所有这些信息，并花时间与合作伙伴和 AWS 协调，以跟踪数据摄入进度和下达任务订单。大型数据迁移管理器通过跟踪所有项目细节，为您节省时间和精力，并允许您专注于数据迁移的总体目标。"
    },
    {
        "query":"如何开启使用大型数据迁移管理器？",
        "intention":"知识问答",
        "reply":"首先，在 AWS 管理控制台中创建数据迁移或数据移动项目计划。在创建计划时，系统会提示您输入导入任务类型的详细信息，包括计划名称、服务访问角色和通知首选项。创建计划后，您需要创建一个站点，以便运送 Snow 设备。站点信息详细信息包括每个站点的名称和运输地址、数据量、并发 Snow 任务数量、Snow 任务类型、Snow 设备、完成率（根据上次监控的数据）、项目开启和结束日期。创建站点后，您可以查看自动创建的 Snow 任务订单安排，这有助于您知道何时下达 Snow 任务订单。您可以从以前的现有任务中进行克隆，也可以将已创建的任务添加到站点中。\n问：如何使用大型数据迁移管理器更新项目计划？\n您可以通过以下两种方式之一更新项目计划：(1) 通过更新数据量、并发 Snow 任务数量来修改计划信息，或 (2) Snow 的数据迁移管理器会计算每个站点的平均 Snow 任务持续时间（从订单创建到完成）和平均完成率，以自动调整计划。数据迁移管理器然后会使用这些计划更新来调整您的订单计划，以通知您项目状态以及是否需要额外的 Snow 任务。\n问：如何使用大型数据迁移管理器监控 Snow 任务？\n您可以使用数据迁移管理器控制面板或查看项目计划摘要来监控 Snow 任务。使用数据迁移管理器控制面板，您可以快速监控项目状态，并一目了然地发现问题。有了这一新功能，您可以跟踪整个迁移或数据移动传输进度、剩余时间、Snow 任务状态、站点状态、平均 Snow 任务完成率、平均 Snow 任务持续时间，以及整个计划和站点的下一个订单安排。\n问：使用大型数据迁移管理器需要付费吗？\n不需要。使用 AWS Snow 系列的客户就可以使用大型数据迁移管理器。\n问：大型数据迁移管理器在哪些区域可用？\n大型数据迁移管理器适用于所有 Snowball 边缘设备可用的商业区域。"
    },
    {
        "query":"什么是适用于 Snow 系列的 AWS OpsHub？",
        "intention":"知识问答",
        "reply":"AWS OpsHub 是一种应用程序，您可以在 [Snowball 资源页面](https://aws.amazon.com/cn/snowball/resources/)下载。 它提供用于管理 AWS Snow 系列设备的图形用户界面。借助 AWS OpsHub，您可以轻松设置和管理 AWS Snowball 设备，从而快速部署边缘计算工作负载并简化将数据迁移到云的过程。只需在 AWS OpsHub 中单击几下，即可轻松解锁和配置设备，拖放数据到设备，在设备上启动和管理 EC2 实例或监控设备指标。AWS OpsHub 在全球均可用，且不会额外收费。"
    },
    {
        "query":"适用于 Snow 系列的 AWS OpsHub 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"AWS OpsHub 是一款您可以下载并安装在任何 Windows 或 Mac 客户端计算机（如笔记本电脑）上的应用程序。安装 AWS OpsHub 并将 AWS Snow 系列设备放置在现场后，打开 AWS OpsHub 并解锁设备。然后，您将看到一个显示设备及其系统指标的控制面板。然后，只需单击几下鼠标，您便可以部署边缘应用程序或将数据迁移至设备。"
    },
    {
        "query":"我能否在我于 AWS OpsHub 发布之前订购的 Snow 系列设备上使用 AWS OpsHub？",
        "intention":"知识问答",
        "reply":"是的。但是，任务自动化功能只在 AWS OpsHub 于 2020 年 4 月 16 日发布后订购的 Snow 系列设备上提供。所有其他功能都将适用于所有设备，包括在 AWS OpsHub 发布之前订购的设备。"
    },
    {
        "query":"我何时应使用 AWS OpsHub，何时应使用 AWS 管理控制台？",
        "intention":"知识问答",
        "reply":"AWS OpsHub 用于管理和运行您的 AWS Snow 系列设备，以及在其上运行的 AWS 服务。AWS OpsHub 是运行于笔记本电脑等本地客户端计算机上的应用程序，在断开连接和连接的环境下均可运行。不同的是，AWS 管理控制台用于管理和运行在云中运行的 AWS 服务。AWS 管理控制台是基于网络的应用程序，在连接到互联网的情况下运行。"
    },
    {
        "query":"如何让我的 AWS OpsHub 软件保持最新？",
        "intention":"知识问答",
        "reply":"当运行 AWS OpsHub 的客户端计算机连接到互联网时，AWS OpsHub 会自动检查 AWS OpsHub 软件更新。如有软件更新，系统将向您发送通知，并向您提供下载并更新最新软件的选项。此外，您可以访问 [Snowball 资源页面](https://aws.amazon.com/cn/snowball/resources/)，并检查是否有 AWS OpsHub 的最新版本。"
    },
    {
        "query":"AWS OpsHub 是否会对我传输到 AWS Snow 系列设备上的数据进行验证和加密？",
        "intention":"知识问答",
        "reply":"是的。利用 AWS OpsHub 复制数据到 AWS Snow 系列设备时，将使用校验和确保您复制到设备的数据与原始数据一致。此外，所有写入到 AWS Snow 系列设备的数据都将默认加密。"
    },
    {
        "query":"我可以购买 Snowball Edge 设备吗？",
        "intention":"知识问答",
        "reply":"我们只以即付即用的形式根据作业提供设备，不出售。"
    },
    {
        "query":"我为什么要使用 AWS Snowball 迁移磁带数据？",
        "intention":"知识问答",
        "reply":"使用带磁带网关的 Snowball Edge Storage Optimized 设备时，您可以快速、安全地将千兆字节的物理磁带数据迁移到 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive --在不更改基于磁带的备份工作流的情况下降低数据存储成本。"
    },
    {
        "query":"如何开始使用 Snowball 迁移磁带数据？",
        "intention":"知识问答",
        "reply":"要开始，请在 AWS Snow 系列控制台订购一台带磁带网关的Snowball Edge Storage Optimized 设备。当您接收设备时，解锁，然后连接到您的本地网络。然后启动磁带网关，它看起来像一个物理磁带库。使用现有备份应用程序连接到 AWS 并将数据从物理磁带复制到磁带网关上的虚拟磁带。\n完成数据拷贝后，将 Snowball Edge 设备运回 AWS。您的数据将存储在 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive 存储级中。您可以通过 AWS Storage Gateway 控制台查看存储在 AWS 上的虚拟磁带，并通过作为虚拟机或硬件设备在本地运行或 Amazon Elastic Compute Cloud（Amazon EC2）实例上运行的磁带网关访问其中的数据。"
    },
    {
        "query":"我可以使用 Snowball 将 AWS 上存储的虚拟磁带导出到我的本地部署的数据中心吗？",
        "intention":"知识问答",
        "reply":"不可以，您不能使用 Snowball 将AWS上存储的虚拟磁带导出到数据中心。您可以使用带磁带网关的 Snowball Edge Storage Optimized 设备将数据导入到 AWS 中。要检索存储在 AWS 上的虚拟磁带，可以使用作为虚拟机或硬件设备在本地运行的磁带网关，或在 Amazon EC2 实例上运行。"
    },
    {
        "query":"我将数据复制到 Snowball 上并将设备运回 AWS 后，何时可以删除物理磁带上的数据？",
        "intention":"知识问答",
        "reply":"在删除物理磁带上的任何数据之前，请等待确认 AWS 已收到 Snowball Edge Optimized 设备，并且您的数据已作为虚拟磁带成功传输到 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive。要访问虚拟磁带，请导航到 AWS Storage Gateway 控制台。虽然 AWS 在迁移期间确认已将文件完整复制到 Snowball Edge 设备中，但在将数据从您的物理磁带删除之前，您仍要负责确认数据的完整性。AWS 对复制或传输过程中丢失或损坏的任何数据不负任何责任。"
    },
    {
        "query":"可以在 AWS 的什么位置上存储我的虚拟磁带？",
        "intention":"知识问答",
        "reply":"您可以选择将虚拟磁带存储在您在 AWS Snow 系列控制台中订购 Snowball Edge storage Optimized 设备时指定的 AWS 区域中的 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive 存储类中。"
    },
    {
        "query":"如何访问虚拟磁带中的数据？",
        "intention":"知识问答",
        "reply":"在从备份应用程序导出虚拟磁带之前，您可以在 Snowball 上读写虚拟磁带。导出虚拟磁带后，将无法访问存储在 Snowball 上的数据。将 Snowball Edge Storage Optimized 设备运回 AWS 并完成物理磁带到虚拟磁带的传输后，您可以通过作为虚拟机或硬件设备在本地运行的磁带网关访问存储在虚拟磁带上的数据，或在 AWS 上的 Amazon EC2 实例上运行。"
    },
    {
        "query":"我与 AWS 的网络连接是否用于数据迁移？",
        "intention":"知识问答",
        "reply":"不，您与 AWS 的网络连接不用于数据迁移。备份应用程序中的数据将复制到 Snowball Edge Storage Optimized 设备，而不是通过网络与 AWS 同步。"
    },
    {
        "query":"在 AWS Storage Gateway 中，我在哪里可以了解有关磁带网关的更多信息？",
        "intention":"知识问答",
        "reply":"磁带网关是 Storage Gateway 中的磁带存储接口。[了解有关磁带网关的更多信息 »](https://aws.amazon.com/cn/storagegateway/vtl/)"
    },
    {
        "query":"Snowball Edge 是否支持 API 访问？",
        "intention":"知识问答",
        "reply":"支持。Snowball 作业管理 API 提供对 Snowball 或 Snowball Edge 作业创建和管理功能的编程式访问。这是一种基于标准的简单 REST Web 服务接口，旨在与任何 Internet 开发环境配合使用。"
    },
    {
        "query":"Snowball 任务管理 API 有何用途？",
        "intention":"知识问答",
        "reply":"借助 [AWS Snowball 任务管理 API](https://docs.aws.amazon.com/snowball/latest/api-reference/api-reference.html)，合作伙伴和客户可以构建自定义集成，用以管理请求 Snowball 和传递任务状态的流程。该 API 提供了一种简单的 Web 服务接口，可用于从 Web 上的任意位置创建、列出、更新和取消任务。使用此 Web 服务，开发人员可以轻松构建管理 Snowball 任务的应用程序。要了解更多信息，请参阅 [AWS Snowball 文档](https://docs.aws.amazon.com/snowball/latest/ug/whatissnowball.html)。"
    },
    {
        "query":"什么是 S3 Adapter？",
        "intention":"知识问答",
        "reply":"[S3 SDK Adapter for Snowball](https://aws.amazon.com/snowball/resources/#tools) 提供与 S3 兼容的接口，以便在数据迁移用例的 Snowball 或 Snowball Edge 上读取和写入数据。"
    },
    {
        "query":"S3 Adapter 有何用途？",
        "intention":"知识问答",
        "reply":"使用 S3 Adapter，客户可以帮助应用程序将文件和非文件源的数据写入 Snowball 或 Snowball Edge 设备上的 S3 存储桶。它还具有复制数据的接口，所采用的加密方法与 Snowball 客户端提供的加密方法相同。有关更多信息，请参阅 [AWS Snowball 文档](https://docs.aws.amazon.com/snowball/latest/api-reference/api-reference.html)。"
    },
    {
        "query":"为什么要使用 S3 Adapter 而不是 Snowball 客户端？",
        "intention":"知识问答",
        "reply":"[Snowball 客户端](https://aws.amazon.com/snowball/resources/#Tools)是一种一站式工具，能够将基于文件的数据轻松复制到 Snowball。钟爱紧密集成的客户可以使用 S3 Adapter 轻松扩展其现有应用程序和工作流，在数据迁移用例中与 Snowball 无缝集成。"
    },
    {
        "query":"使用 S3 Adapter 时，如何保障数据安全？",
        "intention":"知识问答",
        "reply":"S3 Adapter 写入数据时所用的加密机制与 Snowball 客户端提供的高级加密机制相同。"
    },
    {
        "query":"Snowball S3 Adapter 支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"S3 Adapter 通过与语言无关的 REST 进行通信。\n问：我为什么要使用 Snow 上的 Amazon S3 兼容存储？\n您可以使用 Snow 上的 Amazon S3 兼容存储来运行需要在坚固、移动边缘或断开连接的环境中存储 S3 对象，以进行本地数据处理或驻留用例的应用程序。例如，现在可以将利用 Amazon S3 在区域内进行机器学习推理或数据分析的应用程序部署在边缘的 AWS Snow 设备上，以便在接近最终用户的情况下做出实时决策，或满足数据驻留要求。\n问：Snow 上的 Amazon S3 兼容存储支持哪些 S3 API 和功能？\nSnow 上的 Amazon S3 兼容存储支持诸如 GetObject, PutObject、DeleteObject、多部件上传、对象标记、CreateBuckets、DeleteBuckets、BucketLifecycle 和 List 等存储桶和对象 API。Snow 上的 Amazon S3 兼容存储支持使用 SSE-S3 或 SSE-C 进行加密、使用 Snow IAM 进行身份验证和授权、内置弹性等高级功能以及灵活的多节点 (3-16) 部署选项。Snow 上的 Amazon S3 兼容存储是对 Snow 上当前 S3 适配器实施的增强，它具有主要为数据传输用例设计的有限 API 支持\n问：我可以将哪些 AWS Snow Family 设备与 Amazon S3 兼容存储一起使用？\nAmazon S3 兼容存储在 Snowball Edge Compute Optimized 设备上可用，适用于本地边缘计算和存储用例。\n问：如何监控 Snow 上的 Amazon S3 兼容存储的运行状况？\nSnow 上的 Amazon S3 兼容存储会持续监控设备或集群的运行状况。后台进程会对数据不一致和临时故障做出响应以修复和恢复数据，从而确保弹性。如果出现不可恢复的硬件故障，Snow 上的 Amazon S3 兼容存储可以继续运行，并通过电子邮件主动发送通知，提示客户与 AWS 合作更换故障设备。当设备连接时，AWS 还会在远程监控功能开启时收到这些通知，以便主动与客户互动。您可以随时在 OpsHub 上本地查看服务和设备运行状况。\n问：我存储在 Snow 上的 Amazon S3 兼容存储上的数据是否经过加密？\n是的。存储在 Snow 上的 Amazon S3 兼容存储中的数据使用服务器端加密进行加密。Snow 上的 Amazon S3 兼容存储同时支持 SSE-S3 和 SSE-C 加密选项。服务器端加密仅加密对象数据，不加密对象元数据。\n问：我可以为 Snow 上的 Amazon S3 兼容存储分配多少容量？\nSnow 上的 Amazon S3 兼容存储上的 S3 容量取决于 Snow 设备的数量和类型。对于单节点部署，您可以在 Snowball Edge Compute Optimized 设备上为多节点集群设置预置最多 31TB 的精细 S3 容量，设备上的所有存储容量都分配给 Snow 上的 Amazon S3 兼容存储。您可以在 16 节点的 Snowball Edge Compute Optimized 设备集群上预置最多 500TB 的容量。问： 如何监控 Snow 的 Amazon S3 兼容存储的运行状况？Snow 上的 Amazon S3 兼容存储会持续监控设备或集群的运行状况。后台进程会对数据不一致和临时故障做出响应以修复和恢复数据，从而确保弹性。如果出现不可恢复的硬件故障，Snow 上的 Amazon S3 兼容存储可以继续运行，并通过电子邮件主动发送通知和 MQTT 消息，提示客户与 AWS 合作更换故障设备。当设备连接时，AWS 还会在远程监控功能开启时收到这些通知，以便主动与客户互动。您可以随时在 OpsHub 上本地查看服务和设备运行状况。\n了解如何开始使用 AWS Snowball"
    },
    {
        "query":"在生命周期终止（EOL）日期之后，我的 AWS DeepLens 资源会怎样？",
        "intention":"知识问答",
        "reply":"2024 年 1 月 31 日之后，所有对 AWS DeepLens 模型、项目和设备信息的引用都将从 AWS DeepLens 服务中删除。您将无法再从您的 AWS 管理控制台发现或访问 AWS DeepLens 服务，并且调用 AWS DeepLens API 的应用程序将不再工作。"
    },
    {
        "query":"在 EOL 日期之后，我是否需要为账户中剩余的 AWS DeepLens 资源付费？",
        "intention":"知识问答",
        "reply":"AWS DeepLens 创建的资源，例如 Amazon S3 存储桶、AWS Lambda 函数、AWS IoT 事物和 AWS Identity and Access Management (IAM) 角色，在 2024 年 1 月 31 日之后将继续存在于各自的服务中。为了避免在 AWS DeepLens 不受支持后继续被收取费用，请按照以下所有[步骤删除这些资源](https://docs.aws.amazon.com/deeplens/latest/dg/deeplens-end-of-life.html#delete-dl-cloud-resources.html)。"
    },
    {
        "query":"我可以在生命周期终止（EOL）日期后部署我的 AWS DeepLens 项目吗？",
        "intention":"知识问答",
        "reply":"您可以在 2024 年 1 月 31 日之前部署 AWS DeepLens 项目。该日期之后，您将无法访问 AWS DeepLens 控制台或 API，并且任何调用 AWS DeepLens API 的应用程序都将无法运行。"
    },
    {
        "query":"我的 AWS DeepLens 设备会继续接收安全更新吗？",
        "intention":"知识问答",
        "reply":"AWS DeepLens 在 2024 年 1 月 31 日之后不再更新。虽然部署在 AWS DeepLens 设备上的某些应用程序可能会在 EOL 日期之后继续运行，但 AWS 不提供与 AWS DeepLens 软件或硬件相关的任何问题的补救措施，也不对这些问题负责。"
    },
    {
        "query":"我如何才能继续获得 AWS AI/ML 的实践经验？",
        "intention":"知识问答",
        "reply":"我们建议您尝试我们的其他动手机器学习工具。借助 [AWS DeepRacer](https://aws.amazon.com/deepracer/)，使用基于云的 3D 赛车模拟器为 1/18 比例的自主赛车创建强化学习模型。使用 [Amazon SageMaker Studio Lab](https://aws.amazon.com/sagemaker/studio-lab/)，在无需设置的免费开发环境中学习和试验。使用 [Amazon Rekognition](https://aws.amazon.com/rekognition/) 自动执行图像和视频分析，或使用 [AWS Panorama](https://aws.amazon.com/panorama/) 通过边缘计算机视觉改进您的操作。"
    },
    {
        "query":"我应该如何处理我的 AWS DeepLens 设备？",
        "intention":"知识问答",
        "reply":"我们鼓励您通过 Amazon Recycling Program [回收](https://amazonrecycling-us.re-teck.com/recycling/home)您的 AWS DeepLens 设备。Amazon 将承担与运输和回收相关的费用。"
    },
    {
        "query":"什么是 AWS DeepLens？",
        "intention":"知识问答",
        "reply":"AWS DeepLens 是全球首款支持深度学习的视频摄像头，让各种技能水平的开发人员都可以通过计算机视觉实践教程、示例代码和预构建的模型来发展自己的机器学习技能。"
    },
    {
        "query":"有哪些示例项目可用？",
        "intention":"知识问答",
        "reply":"有 7 个示例项目可用：\n1.对象检测\n2.热狗与不是热狗\n3.猫和狗\n4.艺术风格转移\n5.动作检测\n6.人脸检测\n7.鸟分类"
    },
    {
        "query":"AWS DeepLens 是否附带 Alexa？",
        "intention":"知识问答",
        "reply":"否。AWS DeepLens 不附带 Alexa 或任何远场音频功能。但 AWS DeepLens 采用的 2D 麦克风阵列能够运行自定义音频模型（需要额外编程）。"
    },
    {
        "query":"我的设备底部为什么标记有 \"v1.1\"？",
        "intention":"知识问答",
        "reply":"AWS DeepLens（2019 年版）设备底部标记有 “v1.1”。我们对用户体验进行了重大改进，包括入站、教程和额外的传感器兼容性支持，如来自 Intel Real Sense 的深度传感器。\n原始 AWS DeepLens 不能通过软件更新升级到 v1.1。一些设备修改（包括简化的入门培训）为硬件更改。"
    },
    {
        "query":"我能在设备上运行哪些深度学习框架？",
        "intention":"知识问答",
        "reply":"AWS DeepLens（2019 年版本）针对 Apache MXNet、TensorFlow 和 Caffe 进行了优化。\n问：AWS DeepLens 能够达到怎样的性能？  \n   \n 性能表现为每秒推理的图像数量和延迟。不同的模型有不同的每秒推理性能。当批处理大小为 1 时，基准推理性能为 AlexNet 上 14 张图像/秒，ResNet 50 上 5 张图像/秒。延迟由 DeepLens 所连接的网络的特性决定。"
    },
    {
        "query":"AWS DeepLens 支持哪些 MXNet 网络架构层？",
        "intention":"知识问答",
        "reply":"AWS DeepLens 支持 20 种不同的网络架构层。受支持的架构层包括："
    },
    {
        "query":"包装盒内有哪些内容？怎样开始使用？",
        "intention":"知识问答",
        "reply":"开发人员可以在包装盒内找到一份入门指南、一台 AWS DeepLens 设备、一个区域特定的电源线和适配器、USB 电缆和一个 32GB microSD 卡。您需要使用笔记本电脑或 PC 上的浏览器来配置 DeepLens 设备，通过 AWS DeepLens 控制台，其设置和配置工作只要几分钟即可完成。\n3 个 10 分钟教程引导您完成入门：\n1.[创建和部署项目](https://aws.amazon.com/getting-started/tutorials/create-deploy-project-deeplens/)  \n 2.[扩展项目](https://aws.amazon.com/getting-started/tutorials/extend-deeplens-project/)  \n 3.[使用 Amazon SageMaker 构建 AWS DeepLens 项目](https://aws.amazon.com/getting-started/tutorials/build-deeplens-project-sagemaker/)"
    },
    {
        "query":"为什么一个 USB 端口被标记为注册？",
        "intention":"知识问答",
        "reply":"在 AWS DeepLens（2019 年版）上，标记为注册的 USB 端口将在注册过程中用于将 AWS DeepLens 注册到您的 AWS 账户。\n用于注册的 USB 端口被配置为从端口。因此，它不能用于键盘或其他主端口设置。如果您需要连接多个端口，我们建议使用 USB 集线器。\n\n问：我能否在设备上训练模型？\n不能。AWS DeepLens 可以使用经过训练的模型运行推理或预测。您可以在 Amazon SageMaker 这种用于训练和托管模型的机器学习平台中训练模型。AWS DeepLens 提供简单的一键式部署功能，可以从 Amazon SageMaker 发布经过训练的模型。"
    },
    {
        "query":"AWS DeepLens 集成了哪些 AWS 服务？",
        "intention":"知识问答",
        "reply":"DeepLens 经过预配置，可以与 AWS Greengrass、Amazon SageMaker 和 Amazon Kinesis Video Streams 集成。您可以将 AWS DeepLens 与许多其他 AWS 服务集成，例如 Amazon S3、Amazon Lambda、Amazon Dynamo 和 Amazon Rekognition。"
    },
    {
        "query":"能否以 SSH 方式连接 AWS DeepLens？",
        "intention":"知识问答",
        "reply":"能。AWS DeepLens 的简单易用，也可供高级开发人员使用。您可以使用 ssh aws\\_cam@ 命令以 SSH 方式连接设备\n问：AWS DeepLens 支持哪些编程语言？\n您可以用 Python 2.7 以本地方式在摄像头数据流上定义和运行模型。\n问：运行模型是否需要连接 Internet？\n您可以运行已部署到 AWS DeepLens 上的模型，无需连接 Internet。但是在开始的时候，您需要连接 Internet 才能将模型从云部署到设备。模型传输之后，AWS DeepLens 可以在本地设备上执行推理，不需要连接云。但是，如果您的项目中有需要与云进行交互的组件，那么您需要为这些组件启用 Internet。\n问：能否在 AWS DeepLens 上运行自己的自定义模型？\n可以。您也可以从头开始创建自己的项目：使用 AWS SageMaker 平台准备数据并使用托管的 Jupyter Notebook 训练模型，然后将训练过的模型发布到您的 AWS DeepLens 上进行测试和完善。您也可以在 S3 中指定模型架构和网络权值文件的位置，从而将外部训练的模型导入 AWS DeepLens。"
    },
    {
        "query":"什么是 AWS Amplify？",
        "intention":"知识问答",
        "reply":"AWS Amplify 包含一组工具（开源框架、可视化开发环境、控制台）和服务（Web 应用程序和静态网站托管），可加速 AWS 上的移动应用程序和 Web 应用程序的开发进程。  \n   \n Amplify 的开源框架包含一系列固定的库、UI 组件和一个命令行界面 (CLI)，用于构建应用程序后端并将其与您的 iOS、Android、Web 和 React Native 应用程序集成。该框架利用一套核心的 AWS 云服务来提供离线数据、身份验证、分析、推送通知和大规模机器人等功能。  \n   \n 通过与 Amplify CLI 无缝配合的点击式可视化体验，Amplify Studio 可进一步简化后端的配置和前端 UI。Amplify Studio 还包括用于管理应用程序内容和用户的功能。  \n   \n AWS Amplify 还提供完全托管的 Web 应用程序和静态网站托管服务，以托管前端 Web 应用程序、创建/删除后端环境、在前端和后端设置 CI/CD。  \n   \n 最后，作为更广泛的前端 Web 和移动开发工具和服务集的一部分，您可以使用 AWS Device Farm 在真正的 iOS 设备、Android 设备和 Web 浏览器上测试应用程序。"
    },
    {
        "query":"使用 AWS Amplify 如何付费？",
        "intention":"知识问答",
        "reply":"使用 Amplify 的开源框架（库、UI 组件、CLI）或 Amplify Studio 时，您只需为使用的基本 AWS 服务付费。使用这些工具不会产生额外费用。要了解有关 AWS Amplify 托管、Amplify 完全托管 Web 应用程序和静态网站托管服务定价的信息，请访问 [AWS Amplify 定价页面](https://aws.amazon.com/cn/amplify/pricing/)。要了解 AWS Device Farm 的定价，请访问 [AWS Device Farm 定价页面](https://aws.amazon.com/cn/device-farm/pricing/)。"
    },
    {
        "query":"AWS Amplify 托管与 Amplify 开源框架有何关联？",
        "intention":"知识问答",
        "reply":"AWS Amplify 包含工具（开源框架和可视化开发环境）和完全托管 Web 托管服务。框架（库、UI 组件、CLI）中的工具、Amplify Studio、控制台和静态 Web 托管服务可以一起使用或单独使用。  \n   \n 例如，您可以通过 AWS 控制台前往 AWS Amplify 部署和托管单页面应用 (SPA) 前端和静态网站，不论它们是否使用 Amplify 库。  \n   \n 如果使用 Amplify CLI 为您的应用程序配置后端资源，则 AWS Amplify 的静态 Web 托管服务可提供额外的功能。每次签入时，AWS Amplify 会在部署前端之前预置或更新这些后端资源。支持各种配置，例如每个分支上隔离的后端部署或各分支间共享的后端部署（使用 AWS Amplify 的 Web 托管服务时）。"
    },
    {
        "query":"我在哪里能找到有关 AWS Amplify 的最新新闻？",
        "intention":"知识问答",
        "reply":"访问我们的[博客](https://aws.amazon.com/blogs/?filtered-posts.q=Amplify&filtered-posts.q_operator=AND&awsf.blog-master-category=category%23mobile-services)和[最新功能](https://aws.amazon.com/new/?whats-new-content.sort-by=item.additionalFields.postDateTime&whats-new-content.sort-order=desc&whats-new-content-all.sort-by=item.additionalFields.postDateTime&whats-new-content-all.sort-order=desc&awsf.whats-new-products=*all&awsf.whats-new-mobile=general-products%23aws-amplify#wn-mobile-services)页面。"
    },
    {
        "query":"如何使用 Amplify 库、CLI 和 Amplify Studio？",
        "intention":"知识问答",
        "reply":"使用 Amplify 库，您只需编写几行代码，就可以快速向您的应用程序添加功能，例如离线数据、多因素身份验证、分析等。您可以直接通过 Amplify CLI 或 Amplify Studio 使用直观的指导工作流配置基础云服务，例如 AWS AppSync、Amazon Cognito、Amazon Pinpoint、AWS Lambda、Amazon S3 或 Amazon Lex，最大程度地缩短设置和管理后端服务所需的时间。"
    },
    {
        "query":"Amplify 库支持哪些语言和平台？",
        "intention":"知识问答",
        "reply":"Amplify 库支持 iOS、Android、Web、Flutter 和 React Native 应用程序。对于 Web 应用程序，与 React、Ionic、Angular 和 Vue.js 深度集成。"
    },
    {
        "query":"即使不使用 CLI 也可以使用 Amplify 库吗？",
        "intention":"知识问答",
        "reply":"可以。这些库可用于访问在未使用 Amplify CLI 的情况下创建的后端资源。"
    },
    {
        "query":"Amplify 功能如何与 AWS 云服务搭配使用？",
        "intention":"知识问答",
        "reply":"Amplify 功能是基于您需要与应用程序集成的使用案例进行组织的，例如离线数据、多因素身份验证、分析等。当您使用 Amplify CLI 或 Amplify Studio 配置这些功能时，系统会为您预置必要的 AWS 云服务。配置一直保留在 CloudFormation 模板中，这些模板可嵌入源控制，并与其他开发人员进行共享。当您通过 Amplify 库将这些功能添加到您的应用程序时，该库会对 AWS 服务执行必要的调用。例如，“amplify add analytics”将配置 Amazon Pinpoint。然后，当您在应用程序中使用来自 Amplify 库的 Analytics API 时，会对 Pinpoint 执行必要的调用。"
    },
    {
        "query":"AWS Amplify 如何关联至适用于 iOS 和 Android 的 AWS 移动开发工具包？",
        "intention":"知识问答",
        "reply":"Amplify iOS 和 Amplify Android 是构建利用 AWS 服务的 iOS 和 Android 应用程序的推荐方式，无论您是否使用 Amplify CLI 对它们进行了配置。点击[此处](https://docs.amplify.aws/start)开始使用。如果您的应用程序已经使用以前的适用于 iOS 和 Android 的 AWS 移动开发工具包进行了构建，则可参阅[此处](https://docs.amplify.aws/sdk/q/platform/android)的文档。"
    },
    {
        "query":"什么是 Amplify Studio？",
        "intention":"知识问答",
        "reply":"Amplify Studio 是一个可视化界面，用于在 AWS 控制台外配置和维护应用程序后端并创建前端 UI。在启动应用程序后，开发人员和非开发人员都能够使用 Amplify Studio 来管理应用程序内容和用户。"
    },
    {
        "query":"为何 Amplify Studio 在 AWS 控制台外部？",
        "intention":"知识问答",
        "reply":"Amplify Studio 可从 AWS 控制台外部访问，帮助不熟悉 AWS 的前端开发人员快速高效地使用 AWS 工具。Amplify Studio 可提供构建云连接 Web 或移动应用程序所需功能的简化视图（包括后端和前端 UI）。Amplify Studio 还可为非开发人员（QA 测试人员、PM）提供轻松访问权限，以管理应用程序内容和用户，而无需开发人员确定正确的 IAM 角色和策略。"
    },
    {
        "query":"什么是 Amplify 控制台，它与管理 Amplify Studio 有何不同？",
        "intention":"知识问答",
        "reply":"Amplify 控制台是 AWS 管理控制台内应用程序的控制中心。AWS Amplify 控制台为您显示应用程序的所有前端环境和后端环境，而 Amplify Studio 具有与每个单独后端环境相关联的唯一实例。\n通过 Amplify 控制台，您可以访问 AWS Amplify 的完全托管 Web 托管服务，以设置 Web 托管、全栈 CI/CD、添加自定义域、克隆/删除多个后端环境，并导航至基础 AWS 服务控制台。另一方面，Amplify Studio 用于配置和维护应用程序后端 – 添加功能，如身份验证、数据、函数。启动应用程序后，Amplify Studio 还可为非开发人员（QA、PM）提供一种管理应用程序内容和用户的方法。"
    },
    {
        "query":"什么是 AWS Amplify 的 Web 托管服务？",
        "intention":"知识问答",
        "reply":"除了 AWS Amplify 的开发工具和功能外，AWS Amplify 还提供完全托管的 Web 应用程序和静态网站托管服务，该服务可直接从 AWS 控制台访问。AWS Amplify 的静态 Web 托管服务提供构建、部署和托管具有无服务器后端的单页面 Web 应用程序或静态网站的完整工作流程。持续部署允许开发人员在将每个代码提交到 Git 存储库时部署 Web 应用程序更新。构建成功后，应用程序将部署并托管在 amplifyapp.com 子域中。开发人员可以连接他们的自定义域来开始接收生产流量。"
    },
    {
        "query":"我可以构建和部署什么类型的 Web 应用程序？",
        "intention":"知识问答",
        "reply":"除了 AWS Amplify 的开发工具和功能外，AWS Amplify 还为 Web 应用程序和静态网站提供完全托管的静态 Web 托管服务，该服务可直接从 AWS 控制台访问。AWS Amplify 的静态 Web 托管服务提供构建、部署和托管具有无服务器后端的单页面 Web 应用程序或静态网站的完整工作流程。持续部署允许开发人员在将每个代码提交到 Git 存储库时部署 Web 应用程序更新。构建成功后，应用程序将部署并托管在 amplifyapp.com 子域中。开发人员可以连接他们的自定义域来开始接收生产流量。"
    },
    {
        "query":"如何开始使用 AWS Amplify 的 Web 托管服务？",
        "intention":"知识问答",
        "reply":"要开始使用，请在 AWS 控制台中转到 AWS Amplify 并连接源存储库。AWS Amplify 可自动确定所使用的前端框架，然后构建应用程序并将其部署到全球可用的内容分发网络 (CDN)。Amplify 可检测使用 Amplify CLI 或 Amplify Studio 添加的后端功能，并可以在与前端相同的部署中部署必要的 AWS 资源。AWS Amplify 将快速构建和部署 Web 应用程序，并将 Web 应用程序托管在具有友好 URL 的全球可用内容分发网络 (CDN) 上（例如：[https://master.appname.amplifyapp.com](https://master.appname.amplifyapp.com/)）。要开始使用，请在 AWS 控制台上转到 [AWS Amplify](https://us-west-2.console.aws.amazon.com/amplify/home#/create)。"
    },
    {
        "query":"什么是 AWS Amplify“应用程序”？",
        "intention":"知识问答",
        "reply":"AWS Amplify“应用程序”是项目容器。每个应用程序项目都包含从源存储库连接的分支列表。可以连接其他功能分支、自定义域，或者从应用程序项目访问生成日志。"
    },
    {
        "query":"什么是持续部署？",
        "intention":"知识问答",
        "reply":"持续部署是一种针对软件版本的 DevOps 策略，其中提交到存储库的每个代码都会自动发布到生产环境或临时环境中。通过确保托管的 Web 应用程序始终反映存储库中的最新代码，此做法可以缩短上市时间。"
    },
    {
        "query":"AWS Amplify 静态 Web 托管服务支持哪些 Git 源代码提供商？",
        "intention":"知识问答",
        "reply":"您可以从 GitHub、BitBucket、GitLab 和 AWS CodeCommit 连接私有和公共存储库。"
    },
    {
        "query":"AWS Amplify 的 Web 托管服务是否存储我的 Git 访问令牌？",
        "intention":"知识问答",
        "reply":"AWS Amplify 从不存储来自存储库的访问令牌。一旦您授权 AWS Amplify，我们将从源提供商那里获取访问令牌。我们只需将令牌传递到控制台，之后，与 GitHub API 的所有通信都将直接从浏览器进行。配置持续部署之后，令牌将被永久丢弃。"
    },
    {
        "query":"AWS Amplify 的 Web 托管服务支持私有 Git 服务器吗？",
        "intention":"知识问答",
        "reply":"我们目前不支持私有 Git 服务器。"
    },
    {
        "query":"什么是环境变量？ 如何使用？",
        "intention":"知识问答",
        "reply":"环境变量是应用程序在运行时需要的配置。这些配置可能包括数据库连接详细信息、第三方 API 密钥、不同的自定义参数和密钥。公开这些配置的最佳方式是使用环境变量。可以在创建应用程序时添加环境变量，也可以通过进入应用程序设置来完成。所有环境变量都经过加密，以防止恶意访问。在键和值文本框中添加所有应用程序环境变量。默认情况下，AWS Amplify 跨所有分支应用环境变量，因此您在连接新分支时不必重新输入变量。输入所有变量后，单击“保存”。"
    },
    {
        "query":"构建任务运行时会发生什么？",
        "intention":"知识问答",
        "reply":"AWS Amplify 将创建一个临时计算容器（4 vCPU、7GB RAM），下载源代码，运行项目中配置的命令，将生成的构件部署到 Web 托管环境中，然后销毁计算容器。在构建期间，AWS Amplify 会将构建输出流式传输到服务控制台。"
    },
    {
        "query":"如何利用 AWS Amplify 的 Web 托管服务同时使用多个环境？",
        "intention":"知识问答",
        "reply":"每次开发人员将代码推送到新分支时，AWS Amplify 都会利用 Git 的分支模型创建新环境。在典型的开发团队中，开发人员将他们的“主”分支部署到生产环境中，将“开发”分支保留为暂存，并在开发新功能时创建功能分支。AWS Amplify Console 可以创建链接到每个连接分支的前端和后端环境。这允许开发人员在沙盒环境中工作，并使用“Git”作为合并代码和解决冲突的机制。更改一旦合并到主（或生产）分支中，就会自动推送到生产环境中。"
    },
    {
        "query":"什么是原子部署？",
        "intention":"知识问答",
        "reply":"每个部署都是原子部署，这意味着部署完成后便可以查看站点。通过确保仅在整个部署过程完成后更新 Web 应用程序，原子部署消除了维护时段。然后，最终用户可以立即使用新版本的 Web 应用程序，而无需开发人员使 CDN 缓存失效。"
    },
    {
        "query":"托管新式 Web 应用程序与托管传统 Web 应用程序有何不同？",
        "intention":"知识问答",
        "reply":"托管新式 Web 应用程序不需要 Web 服务器，并且可以使用内容分发网络来存储静态内容（HTML、CSS 和 JavaScript 文件）。AWS Amplify 利用 [Amazon CloudFront 全球边缘网络](https://aws.amazon.com/cn/cloudfront/features/)在全球分发 Web 应用程序。"
    },
    {
        "query":"如何连接我的自定义域？",
        "intention":"知识问答",
        "reply":"连接自定义域很简单。如果您的域是在 Route53 上注册的，只需从下拉菜单中选择它，AWS Amplify 将自动配置 DNS 记录，以指向您网站的顶点和“www”子域。此外，我们自动为所有连接的分支创建子域。例如，连接“dev”分支将在 https://dev.appname.amplifyapp.com 上创建部署。作为自定义域设置的一部分，我们将生成一个免费的 HTTPS 证书，以确保到站点的流量是安全的。"
    },
    {
        "query":"AWS Amplify 的 Web 托管服务支持哪些域名注册商？",
        "intention":"知识问答",
        "reply":"通过所有域名注册商购买的域可以通过定义自定义域连接到应用程序。对于使用 Amazon Route53 作为注册商的开发人员，AWS Amplify 会自动更新 DNS 记录，以指向他们部署的应用程序。对于第三方注册商，AWS Amplify 提供如何更新 DNS 记录的说明。"
    },
    {
        "query":"所有 Web 流量都通过 HTTPS 提供吗？",
        "intention":"知识问答",
        "reply":"AWS Amplify 的 Web 托管服务在所有站点上生成一个免费的 HTTPS，并在所有 Route53 托管域上自动启用它。SSL 证书由 Amazon Certificate Manager 生成，并具有通配符域支持。ACM 处理为基于 AWS 的网站和应用程序创建和管理公共 SSL/TLS 证书的复杂性。使用通配符选项，主域和所有子域可以由一个证书覆盖。"
    },
    {
        "query":"我的密码可以保护我的 Web 部署吗？",
        "intention":"知识问答",
        "reply":"可以使用基本访问身份验证对所有 Web 部署进行密码保护。开发新功能时，开发人员可以通过为分支部署设置用户名和密码与内部利益相关者共享更新。"
    },
    {
        "query":"什么是重定向和重写？ 如何使用？",
        "intention":"知识问答",
        "reply":"重定向是指客户端请求将 Web 浏览器转到另一个 URL。这意味着您在浏览器中看到的 URL 将更新为新的 URL。重写指的是 URL 的服务器端重写。这不会改变您在浏览器中看到的内容，因为这些更改对用户是隐藏的。反向代理是跨源重写。在 AWS Amplify 控制台设置中，开发人员可以指定重新导向、HTTP 响应代码、自定义 404 和外部服务代理。"
    },
    {
        "query":"什么是 AWS Shield？",
        "intention":"知识问答",
        "reply":"AWS Shield 是一项托管服务，用于保护 AWS 上运行的应用程序免受分布式拒绝服务 (DDoS) 攻击。可自动为所有 AWS 客户启用 AWS Shield Standard，且无需额外付费。AWS Shield Advanced 是一项可选的付费服务。AWS Shield Advanced 能为 Amazon Elastic Compute Cloud（EC2）、Elastic Load Balancing（ELB）、Amazon CloudFront、AWS Global Accelerator 和 Route 53 上运行的应用程序提供额外保护，使其免受更复杂、更大型的攻击。"
    },
    {
        "query":"什么是 AWS Shield Standard？",
        "intention":"知识问答",
        "reply":"AWS Shield Standard 可以提供保护所有 AWS 客户免受常见的、最为频繁的基础设施层（第 3 层和第 4 层）攻击（如 SYN/UDP 洪泛、反射攻击和其他攻击），确保 AWS 上的应用程序具有较高的可用性。"
    },
    {
        "query":"什么是 AWS Shield Advanced？",
        "intention":"知识问答",
        "reply":"AWS Shield Advanced 可以为受保护的 Amazon EC2、Elastic Load Balancing (ELB)、Amazon CloudFront、AWS Global Accelerator 和 Route 53 资源上运行的应用程序提供增强保护，防护更复杂、更大型的攻击。利用 AWS Shield Advanced 提供的保护，您可以实现基于流的持续网络流量监控和主动应用程序监控，并近乎实时地发送可疑 DDoS 事件通知。AWS Shield Advanced 还采用先进的攻击缓解和路由技术来自动缓解攻击。此外，借助业务或企业支持，客户还可以联系提供全天候服务的 Shield 响应团队（SRT）来管理和缓解应用程序层的 DDoS 攻击。适用于扩展的 DDoS 成本保护功能可以在因 DDoS 攻击而出现受保护的 Amazon EC2、Elastic Load Balancing（ELB）、Amazon CloudFront、AWS Global Accelerator 和 Amazon Route 53 使用高峰时防止您的 AWS 费用增加。"
    },
    {
        "query":"是否可以使用 AWS Shield 来保护未在 AWS 上托管的网站？",
        "intention":"知识问答",
        "reply":"可以。AWS Shield 已与 Amazon CloudFront 实现集成，支持为 AWS 外部的自定义来源提供保护。"
    },
    {
        "query":"AWS Shield 的所有功能是否都支持 IPv6？",
        "intention":"知识问答",
        "reply":"是的。AWS Shield 的所有检测和缓解功能都支持 IPv6 和 IPv4，且不会对该服务的性能、可扩展性或可用性产生任何显著的影响。"
    },
    {
        "query":"如何测试 AWS Shield？",
        "intention":"知识问答",
        "reply":"AWS 可接受使用策略描述了 AWS 允许和禁止的行为，还描述了禁止的安全违规和网络滥用行为。但是，因为 DDoS 模拟测试、渗透测试及其他模拟事件常与此类活动混在一起，难以区分，所以我们制订了一项政策，要求客户先申请权限，然后才能执行 DDoS 测试、渗透测试和漏洞扫描。请访问我们的[渗透测试页面](https://aws.amazon.com/cn/security/penetration-testing/)和 [DDoS 模拟测试政策](https://aws.amazon.com/cn/security/ddos-simulation-testing/)以便了解更多详细信息。"
    },
    {
        "query":"目前可在哪些 AWS 区域使用 AWS Shield Standard？",
        "intention":"知识问答",
        "reply":"目前，客户可在全球各个 AWS 区域和 AWS 边缘站点，在各种 AWS 服务上使用 AWS Shield Standard。\n请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，详细了解 AWS Shield Standard 在各区域的可用性。"
    },
    {
        "query":"目前可在哪些 AWS 区域使用 AWS Shield Advanced？",
        "intention":"知识问答",
        "reply":"目前，客户可在全球所有 Amazon CloudFront、AWS Global Accelerator 和 Amazon Route 53 边缘站点使用 AWS Shield Advanced。通过为您的应用程序部署 Amazon CloudFront，您可以保护在全球任意位置托管的 Web 应用程序的安全。您的源服务器可以是 Amazon Simple Storage Service（S3）、Amazon EC2、Elastic Load Balancing 或 AWS 以外的自定义服务器。您还可以在以下 AWS 区域直接在 Elastic Load Balancing 或 Amazon EC2 上启用 AWS Shield Advanced：弗吉尼亚北部、俄亥俄、俄勒冈、加利福尼亚北部、蒙特利尔、圣保罗、爱尔兰、法兰克福、伦敦、巴黎、斯德哥尔摩、新加坡、东京、悉尼、首尔、孟买、米兰和开普敦。\n请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 AWS Shield Advanced 在各个区域的可用性的最新详细信息。"
    },
    {
        "query":"AWS Shield 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"符合，AWS 已对其 HIPAA 合规性计划进行扩展，其中已将 AWS Shield 作为一项符合 HIPAA 要求的服务包括进来。如果您已与 AWS 签订商业合伙协议 (BAA)，则可以使用 AWS Shield 来保护您在 AWS 上运行的 Web 应用程序，使其免受分布式拒绝服务 (DDoS) 攻击。有关更多信息，请参阅 [HIPAA 合规性](https://aws.amazon.com/cn/compliance/hipaa-compliance/)。"
    },
    {
        "query":"AWS Shield Standard 可以针对哪些类型的攻击提供防护？",
        "intention":"知识问答",
        "reply":"AWS Shield Standard 可以自动保护 AWS 上运行的 Web 应用程序，使其免受最常见且频繁发生的基础设施层攻击（如 UDP 洪泛）和状态耗尽攻击（如 TCP SYN 洪泛）。客户也可以使用 AWS WAF 来针对 HTTP POST 或 GET 洪泛等应用程序层攻击提供防护。要详细了解如何部署应用程序层防护，请参阅 [AWS WAF 和 AWS Shield Advanced 开发人员指南](https://aws.amazon.com/cn/documentation/waf/)。"
    },
    {
        "query":"可以使用 AWS Shield Standard 保护多少资源？",
        "intention":"知识问答",
        "reply":"AWS Shield Standard 对于接受保护的资源没有数量限制。您可以遵循 AWS 的 [DDoS 攻击弹性最佳实践](https://d0.awsstatic.com/whitepapers/Security/DDoS_White_Paper.pdf)，以享受 AWS Shield Standard 防护带来的全部好处。"
    },
    {
        "query":"可以使用 AWS Shield Advanced 保护多少资源？",
        "intention":"知识问答",
        "reply":"您可以针对 AWS Shield Advanced 保护为每种受支持的资源类型（Classic/Application Load Balancer、Amazon CloudFront 分配、Amazon Route 53 托管区域、弹性 IP、AWS Global Accelerator 加速器）最多启用 1000 项 AWS 资源。如果您要保护的资源超过 1000 个，您可以[创建 AWS Support 案例来申请提高限额](http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html)。"
    },
    {
        "query":"是否可以使用 API 激活 AWS Shield Advanced 防护？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 API 激活 AWS Shield Advanced，还可以使用 API 添加或删除使用 AWS Shield Advanced 保护的 AWS 资源。"
    },
    {
        "query":"攻击缓解的速度有多快？",
        "intention":"知识问答",
        "reply":"通常情况下，对于 AWS Shield 检测到的基础设施层攻击，若攻击位于 Amazon CloudFront 和 Amazon Route 53 上，其中 99% 的攻击可在 1 秒内缓解，若攻击位于 Elastic Load Balancing 上，则可在 5 秒内缓解。剩余 1% 的基础设施层攻击通常会在 20 分钟内缓解。您可以使用 AWS WAF 编写规则来缓解应用程序层攻击，AWS WAF 会在流量传入过程中检测和缓解这些攻击。"
    },
    {
        "query":"我可以保护 AWS 之外的资源吗？",
        "intention":"知识问答",
        "reply":"可以，我们的一些客户选择在他们的后端实例前面使用 AWS 端点。最常见的情况是，这些端点是全球分布的 CloudFront 和 Route 53 服务。这些服务也是我们针对 DDoS 弹性提出的最佳实践建议。客户可以使用 Shield Advanced 保护这些 CloudFront 分布和 Route 53 托管区域。请注意，您需要锁定后端资源，以便仅接受来自这些 AWS 端点的流量。"
    },
    {
        "query":"AWS Shield Standard 可以提供哪些工具来缓解 DDoS 攻击？",
        "intention":"知识问答",
        "reply":"AWS Shield Standard 可以自动保护在 AWS 上运行的 Web 应用程序，使其免受最常见且频繁发生的 DDoS 攻击。您可以遵循 AWS 的 DDoS 攻击弹性最佳实践，以享受 AWS Shield Standard 防护带来的所有好处。"
    },
    {
        "query":"AWS Shield Advanced 可以提供哪些工具来缓解 DDoS 攻击？",
        "intention":"知识问答",
        "reply":"AWS Shield Advanced 可以管理第 3 层和第 4 层的 DDoS 攻击缓解。这意味着，该服务可以保护您指定的应用程序免受 UDP 洪泛、TCP SYN 洪泛等攻击。此外，对于应用程序层（第 7 层）攻击，AWS Shield Advanced 可以检测 HTTP 洪泛和 DNS 洪泛等攻击。您可以使用 AWS WAF 来应用自身的缓解措施，或者如果您具有业务或企业支持，则可以联系提供全天候服务的 AWS Shield 响应团队 (SRT)，他们可以帮助您编写规则来缓解第 7 层 DDoS 攻击。"
    },
    {
        "query":"我是否需要有特殊的支持计划才能联系 AWS Shield 响应团队？",
        "intention":"知识问答",
        "reply":"是的，您需要有业务或企业支持计划，以便上报或接洽 AWS Shield 响应团队（SRT）。有关 AWS 支持计划的更多详细信息，请访问 [AWS Support 网站](https://aws.amazon.com/cn/premiumsupport/)。"
    },
    {
        "query":"如何联系 AWS Shield 响应团队？",
        "intention":"知识问答",
        "reply":"您可以通过常规的 AWS 支持方式联系 AWS Shield 响应团队 (SRT)，也可以[联系 AWS Support](https://aws.amazon.com/cn/contact-us/)。"
    },
    {
        "query":"可以在多长时间内联系到 AWS Shield 响应团队 (SRT)？",
        "intention":"知识问答",
        "reply":"SRT 的响应时间取决于您订阅的 AWS Support 计划。我们将会尽一切合理努力，在相应时间期限内响应您的初始请求。有关 AWS 支持计划的更多详细信息，请访问 [AWS Support 网站](https://aws.amazon.com/cn/premiumsupport/)。"
    },
    {
        "query":"发生攻击时，AWS Shield 是否会通知我？",
        "intention":"知识问答",
        "reply":"会。使用 AWS Shield Advanced 时，您可以通过 CloudWatch 指标获得 DDoS 攻击通知。"
    },
    {
        "query":"需要多长时间才能收到攻击通知？",
        "intention":"知识问答",
        "reply":"通常情况下，AWS Shield Advanced 在检测到攻击后，会在几分钟内发出攻击通知。"
    },
    {
        "query":"我是否可以获取一份 AWS 资源的所有 DDoS 攻击历史记录？",
        "intention":"知识问答",
        "reply":"可以。使用 AWS Shield Advanced，您可以查看过去 13 个月内发生的所有事件的历史记录。"
    },
    {
        "query":"是否可以通过 AWS 发现攻击？",
        "intention":"知识问答",
        "reply":"可以，AWS Shield Advanced 客户可以访问全球威胁环境控制面板，该控制面板提供过去两周内在 AWS 上发现的所有 DDoS 攻击的匿名和采样视图。"
    },
    {
        "query":"如何了解 AWS WAF 规则是否正常发挥作用？",
        "intention":"知识问答",
        "reply":"AWS WAF 提供两种不同的方式，帮助您确认您的网站受保护情况：您可以在 CloudWatch 获取每分钟的指标，同时您也可以通过 AWS WAF API 或 AWS 管理控制台获取 Web 请求采样。此外，您还可以启用通过 Amazon Kinesis Firehose 发送到您选择的目的地的综合日志。您可以通过查阅这些信息，查阅到所有被阻止、获允许或经计数的请求，同时能看到每个请求是符合哪条规则（例如，此 Web 请求因符合 IP 地址条件而受阻止，等等）。有关详情，请参阅 [AWS WAF 和 AWS Shield Advanced 开发人员指南](https://aws.amazon.com/cn/documentation/waf/)。"
    },
    {
        "query":"我需要进行渗透测试来评估服务和应用程序。经过批准的程序是怎样的？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 上的渗透测试](https://aws.amazon.com/security/penetration-testing/)。但是，这不包括“DDoS 加载测试”，AWS 上没有授权进行这个测试。如果您要进行在线 DDoS 测试，可以通过 AWS Support 发起工单，申请批准进行这项测试。该测试批准需要 AWS、客户和 DDoS 测试供应商就测试条件达成一致。请注意，我们仅与经过批准的 DDoS 测试供应商合作，整个流程大约需要 3-4 周。"
    },
    {
        "query":"是否可以选择仅使用 AWS Shield Advanced 来保护我的一些资源？",
        "intention":"知识问答",
        "reply":"可以，AWS Shield Advanced 允许您灵活选择要保护的资源。您只需为这些受保护资源上的 AWS Shield Advanced 数据传输付费。"
    },
    {
        "query":"如何在多个 AWS 账户中启用 AWS Shield Advanced？",
        "intention":"知识问答",
        "reply":"如果您的企业拥有多个 AWS 账户，您可以使用 AWS 管理控制台或 API 在每个 AWS 账户上单独启用 AWS Shield Advanced，从而使用这些账户来订阅 AWS Shield Advanced。只要这些 AWS 账户均在同一个整合账单下，且您拥有所有这些 AWS 账户及其中的资源，您就可以一次性支付月度费用。\n了解有关 AWS Shield 定价的更多信息"
    },
    {
        "query":"什么是 AWS App Mesh？",
        "intention":"知识问答",
        "reply":"AWS App Mesh 可用于方便地监控、控制和调试服务之间的通信。App Mesh 使用 Envoy，这是一种与微服务容器一起部署的开源服务网格代理。App Mesh 与 AWS 服务集成以进行监控和跟踪，还可以与很多常用的第三方工具结合使用。App Mesh 可以与在 AWS 上运行的 Amazon ECS、Amazon EKS、AWS Fargate、Kubernetes 托管的微服务容器以及在 Amazon EC2 上运行的服务结合使用。"
    },
    {
        "query":"为什么应该使用 App Mesh？",
        "intention":"知识问答",
        "reply":"借助 App Mesh，您可以更加轻松地获得服务之间的通信的可见性、安全性和控制力，而无需编写新代码或运行额外的 AWS 基础设施。使用 App Mesh，您可以标准化服务的通信方式，实现服务之间的通信规则并将指标、日志和跟踪直接捕获到 AWS 服务和您选择的第三方工具中。"
    },
    {
        "query":"App Mesh 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"App Mesh 为您的服务设置和管理服务网格。要实现此操作，您将与每个服务一起运行开源 Envoy 代理，而 App Mesh 配置此代理以处理进出每个容器的通信。App Mesh 收集指标（例如错误率和每秒连接数），这些指标可使用 statsd 收集器导出到 Amazon CloudWatch。使用 App Mesh API，可以基于路径或权重将流量路由到特定服务版本。"
    },
    {
        "query":"什么是服务网格？",
        "intention":"知识问答",
        "reply":"服务网格是处理服务之间所有通信的新软件层。其提供新功能以连接和管理服务之间的连接，且独立于每个服务的代码，这样其可以跨网络边界工作，并用于多个服务管理系统。"
    },
    {
        "query":"App Mesh 如何与 Amazon Elastic Container Services (ECS) 和 AWS Fargate 结合使用？",
        "intention":"知识问答",
        "reply":"App Mesh 为 Amazon ECS 和 AWS Fargate 托管的应用程序提供新通信、观测和管理功能。将 Envoy 代理映像添加到 ECS 任务定义。App Mesh 管理 Envoy 配置以提供服务网格功能。App Mesh 将指标、日志和跟踪导出到所提供的 Envoy 引导程序配置中指定的终端节点。App Mesh 提供一个 API，用于配置已启用网格功能的微服务之间的流量路由及其他控制。"
    },
    {
        "query":"App Mesh 如何与 Amazon Elastic Container Service for Kubernetes (EKS) 结合使用？",
        "intention":"知识问答",
        "reply":"使用开源 AWS App Mesh 控制器和变更 Webhook 准入控制器。这些控制器将 Kubernetes 服务连接到 App Mesh，并确保 Envoy 代理注入到池中。App Mesh 将指标、日志和跟踪导出到所提供的 Envoy 引导程序配置中指定的终端节点。App Mesh 提供一个 API，用于配置已启用网格功能的微服务之间的流量路由及其他控制。"
    },
    {
        "query":"App Mesh 如何与在 Amazon EC2 上运行的服务结合使用？",
        "intention":"知识问答",
        "reply":"将 Envoy 代理作为容器或进程在 EC2 实例上运行。使用 AWS 提供的容器代理 init 容器，或运行您自己的脚本，以通过代理重定向实例上的网络流量。App Mesh 管理 Envoy 配置以提供服务网格功能。App Mesh 将指标、日志和跟踪导出到所提供的 Envoy 引导程序配置中指定的终端节点。App Mesh 提供一个 API，用于配置已启用网格功能的微服务之间的流量路由及其他控制。"
    },
    {
        "query":"为何我应使用 App Mesh 而不是 AWS Elastic Load Balancers？",
        "intention":"知识问答",
        "reply":"我们建议使用 AWS Elastic Load Balancing 处理所有 Internet 流量以及来自信任边界外部的客户端的流量。对于连接到 AWS 区域内的其他服务的内部服务，App Mesh 提供灵活性、一致性和更大的控制程度，并监控服务通信。"
    },
    {
        "query":"App Mesh 提供哪种类型的监控功能？",
        "intention":"知识问答",
        "reply":"通过 App Mesh，您可以为服务之间的每个跃点获得一致的指标和日志。这些日志和指标包括服务名称和请求标识符等元数据。通过这些元数据，您可以使用 Amazon CloudWatch 等工具聚合、筛选并查看服务到服务通信的图形控制面板。常见控制面板可能包括服务和依赖服务之间的错误率和错误代码。App Mesh 自动收集每个服务的跟踪，并使您可以更方便地查看包含所有服务 API 调用的服务映射。这些功能使您可以更方便地调试并确定微服务之间的通信问题的根本原因。"
    },
    {
        "query":"我是否可以使用非 AWS 工具通过 App Mesh 进行监控、日志记录或跟踪？ 可以。",
        "intention":"知识问答",
        "reply":"可以。App Mesh 支持可与 Envoy 结合使用的所有第三方工具。包括 Splunk、Prometheus、Jaeger、Flagger 和 Grafana，以及 Zipkin 和 LightStep 等开放式跟踪解决方案。"
    },
    {
        "query":"App Mesh 提供哪种类型的流量控制？",
        "intention":"知识问答",
        "reply":"App Mesh 提供一组客户端控制用于流量路由。App Mesh 提供 API 以基于服务名称和版本路由应用程序之间的流量。这些功能使您可以更方便地部署微服务的新版本。"
    },
    {
        "query":"App Mesh 如何支持应用程序身份？",
        "intention":"知识问答",
        "reply":"双向 TLS (mTLS) 提供在传输层实施应用程序身份识别并根据客户端提供的证书来允许或拒绝客户端连接的方法。AWS App Mesh 支持使用 X.509 证书（称为双向传输层安全性或 mTLS）实施客户端应用程序身份识别。为了配置 mTLS，您需要将客户端设置为在请求启动期间向服务器服务提供证书，这是 TLS 会话协商的一部分。服务器使用此证书对客户端进行身份识别和身份验证，检查证书是否有效而且是否由受信任的证书颁发机构 (CA) 颁发的，并通过使用证书上的使用者可选名称 (SAN) 来识别客户端的身份。"
    },
    {
        "query":"为什么应将 mTLS 与 AWS App Mesh 配合使用？",
        "intention":"知识问答",
        "reply":"微服务还具有特殊的安全需求，包括端到端流量加密和灵活的服务访问控制，这些需求可以通过服务网格来得到解决。AWS App Mesh mTLS 实施使您的客户端应用程序可以验证服务器并提供流量加密，而双向 TLS 提供用于服务到服务身份验证的对等身份验证。它在 TLS 上增加了一个安全层，使您的服务可以验证建立连接的客户端。通过将整体式应用程序分解为微服务并在服务网格中运行它们会带来各种好处，其中包括更好的可见性和智能流量路由。"
    },
    {
        "query":"Amazon EBS 卷和快照 ID 的长度在 2018 年会变吗？",
        "intention":"知识问答",
        "reply":"会，请访问 [EC2 常见问题](https://aws.amazon.com/cn/ec2/faqs/#longer-ids)页面了解更多详细信息。"
    },
    {
        "query":"Amazon EC2 实例终止时，会对我的数据产生什么影响？",
        "intention":"知识问答",
        "reply":"与保存在本地实例存储的数据（只要实例存在，数据就始终存在）不同，保存在 Amazon EBS 卷中的数据的存续不受实例寿命的影响。因此，我们建议您仅将本地实例存储用于临时数据。至于对存储时间有较高要求的数据，我们建议您使用 Amazon EBS 卷，或将数据备份至 Amazon S3。如果将 Amazon EBS 卷用作根分区，而您希望在实例生命周期外保留 Amazon EBS 卷，请将“Delete On Terminate”标志设置为“No”。"
    },
    {
        "query":"Amazon EBS 卷预计可以给我带来什么样的性能？",
        "intention":"知识问答",
        "reply":"Amazon EBS 提供七种卷类型：预置 IOPS SSD（io2 Block Express、io2 和 io1）、通用型 SSD（gp3 和 gp2）、吞吐量优化型 HDD (st1) 和 Cold HDD (sc1)。这些卷类型的性能特点和价格各不相同，您可根据应用程序要求定制您所需的存储性能和相应费用。EC2 实例与 EBS 之间的平均延迟为几毫秒。有关性能的更多信息，请参阅 [EBS 产品详情页面](https://aws.amazon.com/cn/ebs/)。有关 Amazon EBS 性能指南的更多信息，请参阅[提升 EBS 性能](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html)。"
    },
    {
        "query":"我应该选择哪种卷？",
        "intention":"知识问答",
        "reply":"Amazon EBS 提供两种主要存储类别：适用于交易型工作负载的 SSD 型存储（性能主要取决于 IOPS、延迟和持久性），以及适用于吞吐量密集型工作负载的 HDD 型存储（性能主要取决于吞吐量，以 MB/s 为单位）。SSD 型卷专用于事务型和 IOPS 密集型数据库工作负载、启动卷以及需要高 IOPS 的工作负载。SSD 型卷包括预置 IOPS SSD（io1 和 io2）和通用型 SSD（gp3 和 gp2）。预置 IOPS SSD 卷的 io2 和 io2 Block Express 均设计为提供 100 倍的持久性 (99.999％)，这让它成为需要更高正常运行时间的业务关键型应用程序的理想之选。gp3 是最新一代通用型 SSD 卷，可在不要求最高 IOPS 性能或 99.999% 持久性的大多数应用程序的价格和性能之间达到最佳平衡。HDD 型卷专用于吞吐量密集型和大数据工作负载、大型 I/O 以及连续 I/O 模式。HDD 型卷包括吞吐量优化型 HDD (st1) 和 Cold HDD (sc1)。"
    },
    {
        "query":"由于 io2 可以提供更高的卷持久性，我是否还应拍摄快照并计划跨可用区 (AZ) 复制 io2 卷以实现更高的持久性？",
        "intention":"知识问答",
        "reply":"较高的卷持久性、快照和跨可用区复制卷可防止发生不同类型的故障，客户可以根据其数据持久性要求选择使用其中一种、两种或所有方法。较高的卷持久性可以降低丢失数据主副本的可能性。快照可防止发生意外的卷故障事件。跨可用区复制卷可防止发生可用区级别的故障，并可在发生故障时更快地恢复。"
    },
    {
        "query":"有关 Amazon EBS 高可用性的最佳实践有哪些？",
        "intention":"知识问答",
        "reply":"Amazon EBS 卷具有很高的可用性、可靠性和持久性。Amazon EBS 卷的数据可在可用区内多个服务器间进行复制，以防备在任一组件发生故障时丢失数据，无需额外付费。根据您的应用程序所需的高可用性（HA）程度，我们建议遵循以下准则以实现稳健的高可用性：  \n 1) 设计无单点故障的系统。有关更多详情，请见 [AWS 上的高可用性与扩缩](https://docs.aws.amazon.com/whitepapers/latest/real-time-communication-on-aws/high-availability-and-scalability-on-aws.html)。  \n 2) 采用自动监控、故障检测和失效转移。请查看[监控您的 EBS 卷的状态](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-volume-status.html)和[利用 CloudWatch 监控 EBS 卷](https://aws.amazon.com/cn/blogs/storage/valuable-tips-for-monitoring-and-understanding-amazon-ebs-performance-using-amazon-cloudwatch/)，以了解有关监控您的 EBS 卷性能的更多详情。  \n 3) 制定手动机制的操作程序，以便响应任何故障、降低它们的风险并且从中恢复。这其中包括在发生故障时断开不可用的卷，并连接备份恢复卷。要了解更多详情，请参阅有关[替换 EBS 卷](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-restoring-volume.html)的文档。"
    },
    {
        "query":"如何修改现有 EBS 卷的容量、性能或类型？",
        "intention":"知识问答",
        "reply":"更改卷配置的方法非常简单。借助[弹性卷](https://aws.amazon.com/cn/ebs/features/#Amazon_EBS_Elastic_Volumes)这项功能，您可以通过单个 CLI 调用、API 调用或在控制台中单击几次来增加容量、调整性能或更改卷类型。有关弹性卷的更多信息，请参阅弹性卷文档。"
    },
    {
        "query":"EBS 标准卷是否仍然可用？",
        "intention":"知识问答",
        "reply":"EBS 标准卷已更名为 EBS 磁性介质卷。此次更名对于任何现有卷都不会有影响，并且与 EBS 标准卷相比，EBS 磁性介质卷在功能上也不会有任何区别。给该产品更名的目的是为了避免与我们的通用型 SSD (gp2) 卷类型混淆，后者是我们推荐的默认卷类型。"
    },
    {
        "query":"预调配 IOPS SSD（io2 Block Express、io2 和 io1）卷是否支持所有 Amazon EC2 实例类型？",
        "intention":"知识问答",
        "reply":"预调配 IOPS SSD io2 卷适用于所有 EC2 实例类型，支持 io2 Block Express 的 [EC2 实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html#io2-block-express)除外。io2 Block Express 卷目前在这些 [Amazon EC2 实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html#io2-block-express)上可用。使用 EBS 优化型 EC2 实例可在 io2 和 io1 卷上提供稳定且可预测的 IOPS。[EBS 优化型实例](https://aws.amazon.com/cn/ebs/features/#Amazon_EBS-Optimized_instances)可在 Amazon EC2 和 Amazon EBS 之间提供专用吞吐量，选择范围介于 62.5MB/s 到 7500 MB/s 之间，具体取决于所用实例类型。要达到 64000 IOPS 和 1000 MB/s 吞吐量的限制，必须将此卷挂载到基于 Nitro 系统的 EC2 实例。"
    },
    {
        "query":"io2 与 io2 Block Express 有何区别？",
        "intention":"知识问答",
        "reply":"io2 卷可为所有的 EC2 实例提供高性能块存储。 对于需要更高性能的应用程序，您可以将 io2 卷挂载到上述在 Block Express 上运行的 [Amazon EC2 实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html#io2-block-express)并提供比 io2 高 4 倍的性能。从而可让单个 io2 卷实现高达 64TiB 的容量、256000 IOPS 和 4000MB/s 的吞吐量，并且达到亚毫秒级的平均 IO 延迟。"
    },
    {
        "query":"我的预置 IOPS SSD（io2 和 io1）卷有望达到哪种水平的性能一致性？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例后，预置 IOPS SSD （io2 和 io1）卷可以在指定年份 99.9% 的时间内实现 10% 以内的预置 IOPS 性能。确切性能取决于应用程序的 I/O 要求。"
    },
    {
        "query":"我的预调配 IOPS SSD（io2 和 io1）卷有望达到哪种水平的性能延迟？",
        "intention":"知识问答",
        "reply":"当附加到 EBS 优化实例时，预调配 IOPS（io1 和 io2）卷可以实现个位数毫秒的延迟，而 io2 Block Express 卷可以实现亚毫秒级的延迟。确切性能取决于应用程序的 I/O 要求。"
    },
    {
        "query":"应用程序读写的 I/O 大小是否会影响我从预置 IOPS SSD （io2 和 io1）卷获得 IOPS 的速率？",
        "intention":"知识问答",
        "reply":"会。为 io2 或 io1 卷预置 IOPS 时，您获得的 IOPS 速率取决于您应用程序读取和写入操作的 I/O 大小。预置 IOPS 卷的基本 I/O 大小为 16KB。因此，如果您为 16KB 大小的 I/O 预置了 40000 IOPS 的卷，则在该大小下将达到 40000 IOPS。如果 I/O 大小增加到 32 KB，则将达到 20000 IOPS，依此类推。有关更多详细信息，请访问有关预置 IOPS 卷的技术文档。您可以使用 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/) 监控您的吞吐量和 I/O 大小。"
    },
    {
        "query":"哪些因素会影响预置 IOPS SSD（io2 和 io1）卷的性能一致性？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例的预置 IOPS SSD（io2 和 io1）卷可以提供一致性能，能在指定年度 99.9% 的时间内实现 10% 以内的预置 IOPS 性能。为了与从快照创建的新卷保持最大的性能一致性，我们建议在快照上启用快速快照还原 (FSR)。从启用 FSR 的快照还原的 EBS 卷可立刻达到其完整性能。\n您的应用程序是否并没有发送足够的 I/O 请求，这是影响性能的另一个因素。这可以通过查看卷的队列深度来监控。队列深度是您的应用程序向卷发起的待处理 I/O 请求的数量。为获得最大的一致性，在一分钟内，对于每 1000 个预配置 IOPS，预配置 IOPS 卷队列长度平均值（四舍五入取整数）必须保持为 1。例如，对于预置了 3000 个 IOPS 的卷，队列长度平均值必须为 3。有关确保稳定的卷性能的更多信息，请参阅[提高 EBS 性能](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html)。"
    },
    {
        "query":"我的 HDD 型卷有望达到哪种水平的性能一致性？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例后，吞吐量优化型 HDD (st1) 和 Cold HDD (sc1) 卷均可在指定年度 99% 的时间内实现 10% 以内的预期吞吐量性能。确切性能取决于应用程序的 I/O 要求和 EC2 实例的性能。"
    },
    {
        "query":"应用程序读写的 I/O 大小是否会影响我从 HDD 型卷获得吞吐量的速率？",
        "intention":"知识问答",
        "reply":"是。您获得的吞吐量速率取决于应用程序读写的 I/O 大小。HDD 型卷以 1MB 的 I/O 大小处理读取和写入操作。连续 I/O 会被合并和处理成 1MB 单元，每个非连续 I/O 也会被处理成 1MB，即使实际 I/O 小于 1MB。因此，虽然拥有小型随机 I/O 的事务型工作负载（如数据库）在 HDD 型卷上无法正常运行，但是连续 I/O 和大型 I/O 也会在较长时间后实现 st1 和 sc1 的预期性能。"
    },
    {
        "query":"哪些因素会影响 HDD 型卷的性能一致性？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例的吞吐量优化型 HDD (st1) 和 Cold HDD (sc1) 卷均可提供一致性能，能在指定年度 99% 的时间内实现 10% 以内的预期吞吐量性能。有几个因素可能影响您看到的一致性水平。例如，卷上随机 I/O 和连续 I/O 操作的相对平衡就可能会影响性能。如果小型随机 I/O 操作过多，则会快速耗尽 I/O 点数，并将性能降至基准速率。根据所选实例，您的吞吐量速率也可能会更低。虽然 st1 可将吞吐量增至 500MB/s，但 EBS 流量的不同实例水平限制会限制性能。另一个因素是拍摄快照，该操作会将预期写入性能降至基准速率，直到快照拍摄完成。这只适用于 st1 和 sc1。\n如果您的应用程序没有发送足够的 I/O 请求，性能也会受到影响。这可以通过查看卷的队列深度和 I/O 大小来进行监控。队列深度是您的应用程序向卷发起的待处理 I/O 请求的数量。为获得最大的一致性，对于每 1MB 连续 I/O，HDD 备份卷队列长度平均值（四舍五入取整数）必须保持为 4 或更多。有关确保稳定的卷性能的更多信息，请参阅[提高 EBS 性能](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html)。"
    },
    {
        "query":"我能否将多个卷一起条带化以获得更好性能？",
        "intention":"知识问答",
        "reply":"能。您可以将挂载到较大 EC2 实例的多个卷一起条带化，以达到 260000 IOPS 或 60000 Mbps（或 7500 MB/s）。不过，st1 和 sc1 的性能与卷大小呈线性扩展关系，因此将这些卷一起条带化可能没有多大益处。"
    },
    {
        "query":"Amazon EBS 如何处理存储争用之类的问题？",
        "intention":"知识问答",
        "reply":"EBS 是一种多租户数据块存储服务。我们采用速率限制机制来避免资源争用。首先为卷的定义性能标准（我们的卷类型包括 gp2、PIOPS、st1 和 sc1）定义 IOPS 和吞吐量方面的性能特性。下一步是定义实例级的性能。每个 EBS 优化实例都为附加到实例的 EBS 卷集定义了性能（吞吐量和 IOPS）。因此，客户可以调整实例和卷的大小，以获得所需的性能级别。此外，客户可以使用我们报告的指标来观察实例级和卷级性能。他们可以设置警报来确定他们所看到的是否与预期的性能不匹配——指标还可以帮助确定客户是否在正确的实例类型上进行了配置，且是否具有适当的卷级别性能。在 EBS 端，我们使用配置的性能来通知我们如何分配适当的实例和 EBS 基础设施来支持卷。我们通过适当分配基础设施来避免资源争用。此外，我们还持续监控我们的基础设施。在此监控下，我们可以检测基础设施故障（或即将发生的基础设施故障），因此，主动将卷移动到正常运行的硬件中，同时修复或更换底层基础设施（根据需要）。"
    },
    {
        "query":"我的通用型 SSD（gp3 和 gp2）卷有望达到哪种水平的性能一致性？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例后，通用型 SSD（gp3 和 gp2）卷可以在指定年份 99% 的时间内实现 10% 以内的预置 IOPS 性能。确切性能取决于应用程序的 I/O 要求。"
    },
    {
        "query":"我的通用型 SSD（gp3 和 gp2）卷有望达到哪种水平的性能延迟？",
        "intention":"知识问答",
        "reply":"挂载到 EBS 优化型实例时，通用型 SSD（gp3 和 gp2）卷可以达到个位数毫秒以内的延迟水平。确切性能取决于应用程序的 I/O 要求。"
    },
    {
        "query":"通用型 SSD (gp3) 卷是否有突增？",
        "intention":"知识问答",
        "reply":"没有。所有通用型 SSD (gp3) 卷都包括 3,000 IOPS 和 125 MB/s 的一致性能，无额外收费。卷可以无限期地保持满额 3,000 IOPS 和 125 MB/s。"
    },
    {
        "query":"突增如何应用于通用型 SSD (gp2) 卷？",
        "intention":"知识问答",
        "reply":"低于 1,000 GB 的通用型 SSD (gp2) 卷可获得高达 3,000 IOPS 的突增 IOPS 性能，至少保持 30 分钟。此外，gp2 卷可为预置的每 GB 提供 3 IOPS 的一致性能。例如，500 GB 的卷能够一致地驱动 1500 IOPS，突增到 3000 IOPS 后持续 60 分钟（3000 IOPS \\* 60 秒 \\* 30 分钟 / 1500 IOPS / 60 秒）。"
    },
    {
        "query":"io2 与 io2 Block Express 有何区别？",
        "intention":"知识问答",
        "reply":"io2 卷可为所有的 EC2 实例提供高性能块存储。对于需要更高性能的应用程序，您可以将 io2 卷挂载到上述在 Block Express 上运行的 [Amazon EC2 实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html#io2-block-express)并提供比 io2 高 4 倍的性能。从而可让单个 io2 卷实现高达 64TiB 的容量、256000 IOPS 和 4000MB/s 的吞吐量，并且达到亚毫秒级的平均 IO 延迟。"
    },
    {
        "query":"什么是 EBS Block Express？",
        "intention":"知识问答",
        "reply":"EBS Block Express 是下一代 Amazon EBS 存储服务器架构，专为在亚毫秒级延迟下为云规模的数据块存储提供最高级别的性能而构建。为此，Block Express 使用可扩展可靠数据报 (SRD)，通过这种高性能低延迟网络协议与基于 Nitro 系统的 EC2 实例通信。这是相同的高性能低延迟网络接口，在 Elastic Fabric Adapter (EFA) 的实例间通信中用于高性能计算 (HPC) 和 Machine Learning (ML) 工作负载。此外，Block Express 还提供了模块化软件和硬件构建基块，它们可按不同方式组装，让我们能够灵活地设计并以更快的速度获得更高的性能和新功能。"
    },
    {
        "query":"哪些工作负载适合 io2 Block Express？",
        "intention":"知识问答",
        "reply":"io2 Block Express 适合性能和容量密集型工作负载，单个卷中更低的延迟、更高的 IOPS、更高的吞吐量和更大的容量可使其受益。这些工作负载包括关系和 NoSQL 数据库，例如 SAP HANA、Oracle、MS SQL、PostgreSQL、MySQL、MongoDB、Cassandra；关键业务运行工作负载，例如 SAP Business Suite、NetWeaver、Oracle eBusiness、PeopleSoft、Siebel；以及 ERP 工作负载，例如 Infor LN 和 Infor M3。"
    },
    {
        "query":"如何了解 io2 卷是否在 Block Express 上运行？",
        "intention":"知识问答",
        "reply":"如果一个 io2 卷挂载在上述 [Amazon EC2 实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/provisioned-iops.html#io2-block-express)上，则它在 Block Express 上运行，从而提供亚毫秒级延迟，且最高能够为单个卷驱动 256000 IOPS 以及 4000MB/s 的吞吐量和 64TiB 的大小。挂载到其他所有实例上的 io2 卷不在 Block Express 上运行，该类卷可提供个位数毫秒的延迟且最高能够为单个卷驱动 64K IOPS 以及 1GB/s 的吞吐量和 16TiB 的大小。"
    },
    {
        "query":"如何为快照使用 EBS 直接 API？",
        "intention":"知识问答",
        "reply":"可通过可以使用 AWS CLI 或通过 AWS SDK 调用的以下 API 来使用此功能。"
    },
    {
        "query":"GetSnapshotBlock 和 PutSnapshotBlock API 支持哪些数据块大小？",
        "intention":"知识问答",
        "reply":"GetSnapshotBlock 和 PutSnapshotBlock API 支持大小为 512 KiB 的数据块。"
    },
    {
        "query":"是否可以使用常规 Amazon S3 API 访问我的快照？",
        "intention":"知识问答",
        "reply":"不可以，只能通过 Amazon EC2 API 访问快照。"
    },
    {
        "query":"是否需要卸载卷才能拍摄快照？",
        "intention":"知识问答",
        "reply":"否，可以在卷连接和使用期间实时拍摄快照。不过，快照只能捕获已写入 Amazon EBS 卷的数据，可能不包含应用程序或操作系统已在本地缓存的数据。为了确保能为实例连接的卷获得一致的快照，我们建议先彻底地断开卷连接，再发出快照命令，然后重新连接卷。对于用作根设备的 Amazon EBS 卷，我们建议先关闭机器，以便能拍摄完整的快照。"
    },
    {
        "query":"对 16TB 的卷拍摄完整快照会不会比对 1TB 的卷更花时间？",
        "intention":"知识问答",
        "reply":"按照设计，对整个 16 TB 卷拍摄 EBS 快照所需的时间不会超过对整个 1 TB 卷拍摄快照所需的时间。但是创建快照所需的实际时间取决于多项因素，其中包括在上次拍摄 EBS 卷快照之后发生更改的数据量。"
    },
    {
        "query":"快照是否进行版本控制？ 能否读取旧版的快照来执行时间点恢复？",
        "intention":"知识问答",
        "reply":"每个快照都会获得一个唯一的识别符，客户可以根据任何现有的快照创建卷。"
    },
    {
        "query":"如何发现已与我共享的 Amazon EBS 快照？",
        "intention":"知识问答",
        "reply":"从 AWS 管理控制台“快照”部分的列表中选择“私有快照”，即可找到已与您共享的快照。本部分列出了您拥有的快照和与您共享的快照。"
    },
    {
        "query":"如何了解哪些 Amazon EBS 快照是全局共享的？",
        "intention":"知识问答",
        "reply":"从 AWS 管理控制台“快照”部分的列表中选择“公有快照”，即可找到全局共享的快照。"
    },
    {
        "query":"如何查找 Amazon EBS 快照中存储的 Amazon 公有数据集的列表？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台来查找存储为 Amazon 快照的公有数据集。请登录控制台，选择“Amazon EC2 Service”，再选择“快照”，然后使用[公有快照](https://console.aws.amazon.com/ec2/v2/home#Snapshots:visibility=public;sort=startTime)进行筛选。有关公有数据集的所有信息，请参阅我们的 [AWS 公有数据集](https://aws.amazon.com/public-datasets/)资源中心。"
    },
    {
        "query":"我何时应使用快速快照还原 (FSR)？",
        "intention":"知识问答",
        "reply":"如果您担心将数据从快照还原到卷时存在数据访问延迟，并且希望在初始化过程中避免初始性能下降，则应对快照启用 FSR。FSR 适合在多种使用案例中提供帮助，例如虚拟桌面基础设施 (VDI)、备份和还原、测试/开发卷副本以及从自定义 AMI 启动。通过在您的快照上启用 FSR，当您需要从该快照还原数据时，将会获得提高且可预测的性能。"
    },
    {
        "query":"为我的快照启用 FSR 是否会加速快照创建？",
        "intention":"知识问答",
        "reply":"不会。启用 FSR 的快照可改善备份数据从快照还原到卷的流程。启用 FSR 的快照不会加快创建快照的速度。"
    },
    {
        "query":"如何启用快速快照还原 (FSR)？",
        "intention":"知识问答",
        "reply":"要使用此功能，在将要还原初始化卷的可用区 (AZ) 内的快照上调用新的 enable-fast-snapshot-restores API。\n启用 FSR 的快照可为下面任何一种状态：正在启用、正在优化、已启用、正在禁用、已禁用。状态转换发布为 CloudWatch 事件，FSR 状态可通过 describe-fast-snapshot-restores API 检查。\n在快照上启用 FSR 不会改变任何现有的快照 API 交互，现有的工作流程不需要更改。FSR 只能在账户拥有的快照上启用或禁用。FSR 不能应用于共享快照。您可以通过 API 或控制台查看自己的已启用 FSR 的快照列表。"
    },
    {
        "query":"如何使用快速快照还原 (FSR)？",
        "intention":"知识问答",
        "reply":"从启用 FSR 的快照创建的卷已完全初始化。但是，创建后立即获得完整性能的卷数量有限制。这些限制表示为与指定可用区中启用了 FSR 的快照关联的信用桶。关于信用需要了解的重要信息：\n1.单卷创建操作消耗一个信用积分  \n 2.信用分数是启用了 FSR 的快照大小的函数  \n 3.信用分数过一段时间后可重新恢复  \n 4.最大信用桶为 10\n为了估计您的信用桶大小和填充率，使用 1,024 除以您的快照大小。例如，100 GiB 启用了 FSR 的快照的最大余额为 10 个信用分数，填充率为每小时 10 个信用积分。而 4 TiB 快照的最大余额为 1，填充率为每 4 小时 1 个信用积分。\n请务必注意，信用桶大小是启用了 FSR 的快照大小的函数，而不是所创建的卷的大小的函数。例如，每次可从 100GiB 快照创建最多十个 1TiB 卷。\n最后，快照启用了 FSR 的每个可用区获得各自的信用桶，与其他可用区无关。"
    },
    {
        "query":"可以创建多少个并发卷？如果超过此限制会发生什么情况？",
        "intention":"知识问答",
        "reply":"创建信用桶的大小代表最大数量，而信用桶余额代表可用的创建数量。填充时，每次可以从启用了 FSR 的快照创建最多 10 个已初始化的卷。最大信用桶大小和信用桶余额都作为 CloudWatch 指标发布。超出限制的卷创建将像未在快照上启用 FSR 时那样继续。"
    },
    {
        "query":"我怎样知道何时从启用了 FSR 的快照创建了卷？",
        "intention":"知识问答",
        "reply":"使用 FSR 时，会在 DescribeVolumes API 中添加 EBS 特有的新属性 (fastRestored) 以指示创建时的状态。当从启用了 FSR 的快照创建卷而没有足够的卷创建信用时，创建仍将继续进行，但是卷将不会初始化。"
    },
    {
        "query":"在删除快照时，FSR 会发生什么？",
        "intention":"知识问答",
        "reply":"当您删除快照时，将自动禁用快照的 FSR，并且会终止该快照的 FSR 计费。"
    },
    {
        "query":"我能否为共享给我的公有和私有快照启用 FSR？",
        "intention":"知识问答",
        "reply":"可以，您可以为共享给您的账户的公有快照和所有私有快照启用 FSR。您可以使用为自己的快照启用 FSR 时使用过的相同 API 调用来为共享快照启用 FSR。"
    },
    {
        "query":"在共享给我的快照上启用 FSR 如何计费？",
        "intention":"知识问答",
        "reply":"当您在共享的快照上启用 FSR 时，将按照 FSR 标准费率向您收费（参阅[定价页面](https://aws.amazon.com/cn/ebs/pricing/)）。请注意，仅向您的账户收取该共享快照的 FSR 费用。您在共享的快照上启用 FSR 时，不会向该快照的所有者收费。"
    },
    {
        "query":"当快照的所有者停止分享快照或将其删除时，共享快照的 FSR 会发生什么？",
        "intention":"知识问答",
        "reply":"当共享快照的所有者删除快照，或者通过撤消您为此快照创建卷的权限来停止与您共享快照时，将自动禁用该共享快照的 FSR，并且会终止该快照的 FSR 计费。"
    },
    {
        "query":"什么是 Amazon EBS 加密？",
        "intention":"知识问答",
        "reply":"Amazon EBS 加密提供 EBS 数据卷、引导卷和快照的无缝加密，无需构建和维护安全密钥管理基础设施。EBS 加密可使用 Amazon 托管的密钥或您使用 [AWS Key Management Service (KMS)](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys) 创建和管理的密钥来给您的数据加密，从而保障静态数据的安全性。加密还发生在托管 EC2 实例的服务器上，当数据在 EC2 实例和 EBS 存储之间移动时提供数据加密。有关详细信息，请参阅 [Amazon EC2 用户指南](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html)中的“Amazon EBS”加密。"
    },
    {
        "query":"什么是 AWS Key Management Service (KMS)？",
        "intention":"知识问答",
        "reply":"[AWS KMS](https://aws.amazon.com/kms/) 是一项托管服务，可让您轻松创建和控制加密数据所用的加密密钥。AWS Key Management Service 可与其他 AWS 服务集成，包括 Amazon EBS、Amazon S3 和 Amazon Redshift，可让您轻松使用您管理的加密密钥加密您的数据。AWS Key Management Service 还能与 AWS CloudTrail 集成，从而为您提供所有密钥的使用记录，帮助您满足监管和合规性要求。要了解有关 KMS 的更多信息，请访问 AWS Key Management Service 产品页面。"
    },
    {
        "query":"为什么我应使用 EBS 加密？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon EBS 加密来满足云中静态数据加密的安全性和加密合规性要求。将加密与现有 IAM 访问控制策略配合使用可以提高公司的纵深防御策略。"
    },
    {
        "query":"如何管理我的 Amazon EBS 加密密钥？",
        "intention":"知识问答",
        "reply":"Amazon EBS 加密为您处理密钥管理。每个新创建的卷获取唯一的 256 位 AES 密钥；从加密快照创建的卷将共享该密钥。这些密钥受我们自己的密钥管理基础设施的保护，设施将实施强逻辑和物理安全控制来防止未经授权的访问。使用行业标准 AES-256 算法对数据和关联密钥进行加密。"
    },
    {
        "query":"EBS 加密是否支持启动卷？",
        "intention":"知识问答",
        "reply":"是。"
    },
    {
        "query":"我是否可以在实例启动时创建加密数据卷？",
        "intention":"知识问答",
        "reply":"可以，使用 AWS 进行托管的或客户托管的[客户主密钥 (CMK)](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys) 创建。您可以通过以下两种方式指定卷详细信息和加密：使用 [BlockDeviceMapping](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_BlockDeviceMapping.html) 参数执行 [RunInstances API](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html) 调用或使用 EC2 控制台中的启动向导。"
    },
    {
        "query":"我是否可以在实例启动时创建不属于 AMI 的额外加密数据卷？",
        "intention":"知识问答",
        "reply":"可以，您可以在实例启动时创建采用了默认或自定义 CMK 加密的加密数据卷。您可以通过 [RunInstances API](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html) 调用中的 [BlockDeviceMapping](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_BlockDeviceMapping.html) 对象或使用 EC2 控制台中的启动向导指定卷详细信息和进行加密。"
    },
    {
        "query":"我能否从未加密的 AMI 启动加密的 EBS 实例？",
        "intention":"知识问答",
        "reply":"可以。请参阅[技术文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIEncryption.html)了解详细信息。"
    },
    {
        "query":"我能否与其他账户共享加密的快照和 AMI？",
        "intention":"知识问答",
        "reply":"可以。我可以使用 [客户托管的客户主密钥](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html) (CMK) 与其他 AWS 账户共享加密的快照和 AMI。请参阅[技术文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/sharingamis-explicit.html)了解详细信息。"
    },
    {
        "query":"我能否确保创建的所有新卷始终处于加密状态？",
        "intention":"知识问答",
        "reply":"可以，您可以在每个区域使用单个设置，即可在默认情况下启用 EBS 加密。此操作可确保所有新卷始终处于加密状态。有关更多详细信息，请参阅[技术文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSEncryption.html)。"
    },
    {
        "query":"当预配置 IOPS 卷从实例断开连接时，是否会就预配置的 IOPS 向我计费？",
        "intention":"知识问答",
        "reply":"会，当预配置 IOPS 卷从实例断开连接时，您就会因预配置 IOPS 被计费。当卷断开连接时，我们建议您创建一个快照并删除该卷以减少费用。有关更多信息，请参阅 [Trusted Advisor](http://aws.amazon.com/support/trustedadvisor/) 中的“未充分利用的 Amazon EBS 卷”成本优化检查。该项目检查您的 Amazon Elastic Block Store (Amazon EBS) 卷配置并在卷使用不足时发出警告。"
    },
    {
        "query":"我能否使用启用了多重挂载的卷启动 EC2 实例？",
        "intention":"知识问答",
        "reply":"否。"
    },
    {
        "query":"如果我所有的挂载实例都没有设置“deleteOnTermination”标记，将发生什么？",
        "intention":"知识问答",
        "reply":"卷的 deleteOnTermination 行为由终止的最后一个挂载实例的配置决定。要确保对终止行为进行可预测删除，为卷挂载到的所有实例启用或禁用“deleteOnTermination”。\n如果您想要在挂载的实例终止时删除卷，为卷挂载到的所有实例启用“deleteOnTermination”。如果您想要在挂载的实例终止时保留卷，请为挂载的所有实例禁用“deleteOnTermination”。有关更多信息，请参阅[多重挂载](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volumes-multi.html)技术文档。"
    },
    {
        "query":"我的应用程序能否使用多重挂载？",
        "intention":"知识问答",
        "reply":"如果您的应用程序不需要写操作的存储层协调（如只读应用程序）或强制进行应用程序级 IO 隔离，则您的应用程序可以使用多重挂载。\n了解有关 Amazon EBS 定价的更多信息"
    },
    {
        "query":"什么是 Amazon Omics？",
        "intention":"知识问答",
        "reply":"Amazon Omics 是一项专用服务，可帮助医疗保健和生命科学组织及其软件合作伙伴存储、查询和分析基因组、转录组和其他组学数据，然后从这些数据中产生见解，从而改善健康。它支持大规模分析和协作研究。"
    },
    {
        "query":"Amazon Omics 如何帮助提高效率？",
        "intention":"知识问答",
        "reply":"Amazon Omics 为准备和分析组学数据提供了可扩展的工作流程和集成工具，并自动提供和扩展底层基础设施，以便您可以将更多时间用于研究和创新。Amazon Omics 支持大规模分析和协作研究。"
    },
    {
        "query":"此服务如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"Amazon Omics 可以使用 Amazon Omics 私有和 Ready2Run 工作流程直接从 Amazon Simple Storage Service（S3）或 Amazon Omics 存储处理数据。您可以将原始基因组序列文件、变体调用格式文件和注释数据集等数据从 Amazon S3 导入与生物信息学兼容的 Amazon Omics 存储和分析商店。您可以使用 AWS Lake Formation 控制对 Amazon Omics 变体和注释存储的访问，并使用 Amazon Athena 使数据更易于查询，并与其他形式的数据（例如来自 Amazon HealthLake 的医疗健康记录）相结合。您还可以使用 Amazon Athena 使数据更容易查询并与其他形式的数据相结合，例如来自 Amazon HealthLake 的医疗健康记录。此外，您还可以在 Amazon QuickSight 中使用转换后的数据进行高级分析。您还可以使用 Amazon SageMaker 在您的多组学和多模态数据上构建、训练和部署新型机器学习算法。最后，您还可以使用 [Amazon EventBridge](https://aws.amazon.com/cn/eventbridge/) 将事件作为事件驱动架构的一部分发布。"
    },
    {
        "query":"Amazon Omics 支持哪些数据格式？",
        "intention":"知识问答",
        "reply":"我们有两种类型的数据存储，一种用于原始、生物数据存储，另一种用于变体和注释数据存储。Amazon Omics Storage 可以导入 FASTA 格式的参考基因组和 Gzip 压缩后的 FASTQ、BAM 和 CRAM 格式的原始序列文件。Amazon Omics 分析存储可以为变体数据导入 (g)VCF 格式的文件，为基因组注释导入 VCF、GFF 和 TSV/CSV 文件。Amazon Omics 工作流程可以从 Amazon Omics 存储或 Amazon S3 读取您定义的工作流程定义和工具支持的任何数据。"
    },
    {
        "query":"用 Amazon Omics 工作流程运行 WDL 或 Nextflow 工作流程，与运行它们的开源引擎实施有什么不同？",
        "intention":"知识问答",
        "reply":"Amazon Omics 工作流程支持符合 WDL 1.1 规范或 Nextflow 22.04.0 DSL2 的工作流程定义。目前，工作流程引用的工具必须被封装在符合 OCI 标准的容器中，并存储在 Amazon Elastic Container Registry（ECR）的私有注册表中。工作流程定义必须定义特定的最终输出 — 当工作流程运行完成后，中间结果将被丢弃。目前不支持工作流程运行或任务的缓存。"
    },
    {
        "query":"Ready2Run 和私有工作流程有什么区别？",
        "intention":"知识问答",
        "reply":"私有工作流程使您可以使用两种最常用的工作流程语言（WDL 和 Nextflow）编写自己的生物信息学脚本。您可以通过一次执行来运行这些私有工作流程，这称为运行。对于私有工作流程，您只需按请求量付费，并针对组学实例类型和运行存储单独计费。工作流程中的所有任务都映射到最适合已定义资源的实例。\nReady2Run 工作流程是预先构建的工作流程，由行业领先的第三方软件公司（如 Sentieon, Inc.、NVIDIA 和 Element Biosciences）以及常见的开源管道（如 Broad Institute 的 GATK 最佳实践工作流程和用于蛋白质结构预测的 AlphaFold）设计。Ready2Run 工作流程让您使用最常用的工作流程（比如 Germline 和 Broad Institute 的 GATK-8P）即可轻松处理数据。Ready2Run 工作流程按运行次数付费，价格预先确定。这意味着您为每个工作流程支付的价格相同。"
    },
    {
        "query":"Amazon Omics 提供什么类型的安全？",
        "intention":"知识问答",
        "reply":"Amazon Omics 符合 HIPAA 要求。您可以使用基于属性的访问控制来定义谁可以访问 Amazon Omics 资源。所有持久性存储支持客户管理的密钥。行权限和列权限也可以在 Amazon Omics 分析商店中使用。Amazon Omics API 与 AWS CloudTrail 和 Amazon CloudWatch Logs 集成，允许您生成详细的数据出处并访问审计跟踪记录。"
    },
    {
        "query":"在使用 Amazon Omics 之前，我是否需要一个商业伙伴附录 (BAA)？",
        "intention":"知识问答",
        "reply":"Amazon Omics 是一项符合 HIPAA 要求的服务。如果您在 AWS 上存储受保护的健康信息 (PHI) ，您需要有一个商业伙伴附录。您可以使用 [AWS Artifact](https://aws.amazon.com/artifact/) 在线快速输入一个商业伙伴附录。"
    },
    {
        "query":"什么是 Amazon Elastic Kubernetes Service (Amazon EKS)？",
        "intention":"知识问答",
        "reply":"Amazon EKS 是一项托管服务，借助该服务，您可以轻松在 AWS 上运行 Kubernetes，而无需安装和操作您自己的 Kubernetes 控制面板或工作线程节点。"
    },
    {
        "query":"什么是 Kubernetes？",
        "intention":"知识问答",
        "reply":"Kubernetes 是一款开源容器编排系统，您可以利用它大规模地部署和管理容器化应用程序。Kubernetes 会将容器安排到各个逻辑分组以便进行管理和查找，然后在 Amazon Elastic Compute Cloud (Amazon EC2) 实例集群上启动它们。使用 Kubernetes，您可以使用同一工具集在本地和云中运行容器化应用程序，包括微服务、批处理工作线程和平台即服务 (PaaS)。"
    },
    {
        "query":"为何应该使用 Amazon EKS？",
        "intention":"知识问答",
        "reply":"Amazon EKS 可跨多个 AWS 可用区 (AZ) 预置和扩展 Kubernetes 控制面板（包括应用程序编程接口 (API) 服务器和后端持久层），从而获得高可用性和容错能力。Amazon EKS 可自动检测和替换运行状况不佳的控制面板节点并修补控制面板。您可以使用 AWS Fargate 运行 EKS，前者提供适用于容器的无服务器计算。使用 Fargate，您无需预置和管理服务器，而且可以为每个应用程序指定资源并为其付费，并通过设计隔离应用程序来提高安全性。\nAmazon EKS 可与许多 AWS 服务集成，为应用程序提供可扩展性和安全性。这些产品包括用于分配负载的 Elastic Load Balancing、用于身份验证的 AWS Identity and Access Management (IAM)、用于隔离的 Amazon Virtual Private Cloud (VPC) 和用于日志记录的 AWS CloudTrail。"
    },
    {
        "query":"Amazon EKS 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon EKS 可为您预置（启动）和管理 Kubernetes 控制面板和工作线程节点。总体来说，Kubernetes 由两大组件构成：运行容器的工作线程节点群集和管理容器在集群上的启动时间和位置并监控容器状态的控制面板。\n如果不使用 Amazon EKS，您需要自行运行 Kubernetes 控制面板和工作线程节点群集。使用 Amazon EKS，您可以在 EKS 控制台、命令行界面 (CLI) 或 API 中通过单个命令预置您的工作线程节点。AWS 在高度可用且安全的配置中处理 Kubernetes 控制面板的预置、扩展和管理。这消除了操作重担，让您能够专注于应用程序构建而非 AWS 基础设施管理。"
    },
    {
        "query":"Amazon EKS 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"Amazon EKS 支持与 Kubernetes 兼容的 Linux x86、ARM 和 Windows Server 操作系统发行版本。Amazon EKS 为 Amazon Linux 2 和 Windows Server 2019 提供了优化的 AMI。目前，还没有针对 AL2023 的 Amazon EKS 优化 AMI。针对其他 Linux 发行版本（例如 Ubuntu），可从其各自的供应商处获得 EKS 优化型 AMI。"
    },
    {
        "query":"我该向谁提出功能请求？",
        "intention":"知识问答",
        "reply":"请通过 [AWS 容器服务公共路线图](https://github.com/aws/containers-roadmap)创建功能请求，告诉我们可以添加或改进哪些功能"
    },
    {
        "query":"Amazon EKS 是否可与我现有的 Kubernetes 应用程序和工具搭配使用？",
        "intention":"知识问答",
        "reply":"Amazon EKS 运行开源 Kubernetes 软件，因此您可以使用 Kubernetes 社区中的所有现有插件和工具。无论是在本地数据中心还是在公有云中，在 Amazon EKS 上运行的应用程序都与在任何标准 Kubernetes 环境中运行的应用程序完全兼容。这意味着您可以将任何标准 Kubernetes 应用程序轻松迁移到 Amazon EKS，而无需修改任何代码。"
    },
    {
        "query":"Amazon EKS 是否可与 AWS Fargate 搭配使用？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS Fargate 和 Amazon EKS，将 Kubernetes 应用程序作为无服务器容器运行。"
    },
    {
        "query":"Amazon EKS 附加组件是什么？",
        "intention":"知识问答",
        "reply":"EKS 附加组件可让您启用及管理 Kubernetes 操作软件，这些操作软件提供观测、扩展、联网以及针对您的 EKS 集群进行 AWS 云资源集成等功能。推出后，EKS 附加组件支持通过 EKS API 控制 AWS VPC CNI 插件的发布和版本。"
    },
    {
        "query":"为何应该使用 Amazon EKS 附加组件？",
        "intention":"知识问答",
        "reply":"[Amazon EKS 附加组件](https://aws.amazon.com/blogs/containers/introducing-amazon-eks-add-ons/)可让您一键式安装及管理 Kubernetes 操作软件。只需使用一个命令即可完成从集群创建到运行应用程序的整个过程，同时可以轻松将集群所需的操作软件保持最新。如此就确保了 Kubernetes 集群的安全性和稳定性，并减少了在 AWS 上启动及管理生产就绪的 Kubernetes 集群所需完成的工作量。"
    },
    {
        "query":"Amazon EKS 支持哪些 Kubernetes 版本？",
        "intention":"知识问答",
        "reply":"请参阅 [Amazon EKS 文档](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html)，了解当前受支持的 Kubernetes 版本。Amazon EKS 今后将继续支持更多 Kubernetes 版本。"
    },
    {
        "query":"是否可以将 Kubernetes 集群更新为新版本？",
        "intention":"知识问答",
        "reply":"可以。Amazon EKS 为 Kubernetes 和 Amazon EKS 平台版本执行托管的就地集群升级。这简化了集群操作，使您可以利用最新的 Kubernetes 功能以及 Amazon EKS 配置和安全补丁的更新。\n存在可应用于 Amazon EKS 集群的两种更新，即 Kubernetes 版本更新和 Amazon EKS 平台版本更新。随着新的 Kubernetes 版本的发布和验证（供 Amazon EKS 使用），我们将在任何给定时间支持三个稳定的 Kubernetes 版本作为更新过程的一部分。"
    },
    {
        "query":"什么是 EKS 平台版本？",
        "intention":"知识问答",
        "reply":"Amazon EKS 平台版本代表集群控制平面的功能，例如启用了哪些 Kubernetes API 服务器标记以及当前的 Kubernetes 补丁程序版本。每个 Kubernetes 次要版本都有一个或多个关联的 Amazon EKS 平台版本。不同 Kubernetes 次要版本的平台版本彼此独立。\n当 Amazon EKS 中有新的 Kubernetes 次要版本（例如 1.13）可用时，该 Kubernetes 次要版本的初始 Amazon EKS 平台版本从 eks.1 开始。但是，Amazon EKS 会定期发布新的平台版本，以启用新的 Kubernetes 控制平面设置并提供安全修复程序。"
    },
    {
        "query":"为什么我要手动控制 Kubernetes 版本更新？",
        "intention":"知识问答",
        "reply":"新版本的 Kubernetes 会对 Kubernetes API 进行重大更改，因此会导致应用程序行为发生变化。通过手动控制 Kubernetes 集群版本，您可以在升级生产集群之前针对新版本的 Kubernetes 测试应用程序。Amazon EKS 使您能够选择何时向 EKS 集群引入更改。"
    },
    {
        "query":"如何更新我的工作线程节点？",
        "intention":"知识问答",
        "reply":"AWS 发布包含必要的工作线程节点二进制文件（Docker 和 Kubelet）的 EKS 优化型 Amazon 系统映像 (AMI)。 此 AMI 会定期更新，并包含这些组件的最新版本。您可以在 EKS 控制台、API 或 CLI 中使用单独一条命令将 EKS 托管节点更新为 EKS 优化型 AMI 的最新版本。\n如果您要构建自己的自定义 AMI 以用于 EKS 工作线程节点，AWS 还发布记录我们的构建步骤的 [Packer 脚本](https://github.com/awslabs/amazon-eks-ami)，以允许您识别每个 AMI 版本中包含的二进制文件。"
    },
    {
        "query":"Amazon EKS 在哪些区域可用？",
        "intention":"知识问答",
        "reply":"请访问 [AWS 全球基础设施区域列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解有关 Amazon EKS 区域可用性的最新信息。"
    },
    {
        "query":"什么是 Amazon EKS 服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"可以在[此处](https://aws.amazon.com/eks/sla/)找到 Amazon EKS SLA。\n了解使用 Amazon EKS 的客户"
    },
    {
        "query":"我如何确定为应用程序选择哪种负载均衡器？",
        "intention":"知识问答",
        "reply":"Elastic Load Balancing (ELB) 支持四类负载均衡器。您可以根据应用程序按需选择合适的负载均衡器。如果您需要对 HTTP 请求进行负载均衡，建议您使用 Application Load Balancer (ALB)。如果您需要对网络/传输协议（第 4 层 – TCP、UDP）以及极端性能/低延迟的应用程序进行负载均衡，建议您使用 Network Load Balancer。如果应用程序在 Amazon Elastic Compute Cloud (Amazon EC2) Classic 网络中构建而成，则建议您使用 Classic Load Balancer。如果您需要部署和运行第三方虚拟设备，您可以使用网关负载均衡器。"
    },
    {
        "query":"我可以在不使用公有 IP 的情况下，从 Amazon Virtual Private Cloud (VPC) 对 Elastic Load Balancing API 进行私有访问吗？",
        "intention":"知识问答",
        "reply":"可以，您可以通过创建 [VPC 终端节点](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-endpoints.html)来实现从 Amazon Virtual Private Cloud (VPC) 对 Elastic Load Balancing API 进行私有访问。借助 VPC 终端节点，VPC 和 Elastic Load Balancing API 之间的路由将由 AWS 网络处理，而无需使用 Internet 网关、网络地址转换 (NAT) 网关或虚拟专用网络 (VPN) 连接。Elastic Load Balancing 所使用的最新一代 VPC 终端节点由 AWS PrivateLink 提供支持。AWS PrivateLink 是一种通过使用 VPC 中带有私有 IP 的弹性网络接口来支持各 AWS 服务之间的私有连接的 AWS 技术。要了解有关 [AWS PrivateLink](https://aws.amazon.com/cn/privatelink/) 的更多信息，请访问 AWS PrivateLink [文档](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html#what-is-privatelink.html)。"
    },
    {
        "query":"有没有适用于负载均衡器的 SLA？",
        "intention":"知识问答",
        "reply":"有，Elastic Load Balancing 可保证负载均衡器（传统、应用程序或网络）的每月可用性至少达到 99.99%。如需了解有关 SLA 的更多信息并了解您是否有资格获得额度，[请访问此处](https://aws.amazon.com/cn/elasticloadbalancing/sla/)。"
    },
    {
        "query":"Application Load Balancer 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"Application Load Balancer 支持使用 Amazon EC2 目前所支持的任何操作系统的目标。"
    },
    {
        "query":"Application Load Balancer 支持哪些协议？",
        "intention":"知识问答",
        "reply":"Application Load Balancer 支持对使用 HTTP 和 HTTPS（安全 HTTP）协议的应用程序进行负载均衡。"
    },
    {
        "query":"Application Load Balancer 是否支持 HTTP/2？",
        "intention":"知识问答",
        "reply":"能。Application Load Balancer 内置 HTTP/2 支持。支持 HTTP/2 的客户端可以通过 TLS 连接到 Application Load Balancer。"
    },
    {
        "query":"如何在我的 Application Load Balancer 上使用静态 IP 或 PrivateLink？",
        "intention":"知识问答",
        "reply":"您可以从为每个可用区的 PrivateLink 和静态 IP 地址提供支持的网络负载均衡器中将流量转发至您的 Application Load Balancer。创建一个 Application Load Balancer 型目标组、将 Application Load Balancer 注册到该目标组并将网络负载均衡器配置为将流量转发至 Application Load Balancer 型目标组。"
    },
    {
        "query":"可以对哪些 TCP 端口执行负载均衡？",
        "intention":"知识问答",
        "reply":"您可以为下列 TCP 端口执行负载均衡：1-65535"
    },
    {
        "query":"Application Load Balancer 是否支持 WebSocket？",
        "intention":"知识问答",
        "reply":"能。Application Load Balancer 内置 WebSocket 和 Secure WebSocket 支持，随时可用。"
    },
    {
        "query":"Application Load Balancer 是否支持请求跟踪？",
        "intention":"知识问答",
        "reply":"能。您的 Application Load Balancer 上默认启用了请求跟踪。"
    },
    {
        "query":"Classic Load Balancer 是否具有与 Application Load Balancer 相同的功能和优点？",
        "intention":"知识问答",
        "reply":"虽然存在一些重叠，但两种类型的负载均衡器之间没有同等的功能。Application Load Balancer 是我们面向未来推出的应用程序层负载均衡平台的基础。"
    },
    {
        "query":"可否将 Amazon EC2 实例配置为仅接收来自 Application Load Balancer 的流量？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"我是否可以为 Application Load Balancer 的前端配置安全组？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"可否将用于 Classic Load Balancer 的现有 API 用于 Application Load Balancer？",
        "intention":"知识问答",
        "reply":"不可以。Application Load Balancer 需要一组新的应用程序编程接口 (API)。"
    },
    {
        "query":"如何同时管理 Application Load Balancer 和 Classic Load Balancer？",
        "intention":"知识问答",
        "reply":"借助 ELB 控制台，您可以在同一界面中管理 Application Load Balancer 和 Classic Load Balancer。如果您使用命令行界面 (CLI) 或软件开发工具包 (SDK)，则将针对 Application Load Balancer 使用其他“服务”。例如，在 CLI 中，您可以使用“aws elb describe-load-balancers”描述 Classic Load Balancer，使用“aws elbv2 describe-load-balancers”描述 Application Load Balancer。"
    },
    {
        "query":"可否将 Classic Load Balancer 转换为 Application Load Balancer（或将 Application Load Balancer 转换为 Classic Load Balancer）？",
        "intention":"知识问答",
        "reply":"不可以，您不能将一种负载均衡器类型转换为另一种。"
    },
    {
        "query":"可否从 Classic Load Balancer 迁移到 Application Load Balancer？",
        "intention":"知识问答",
        "reply":"能。您可以使用该[文档](https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/migrate-to-application-load-balancer.html)中所列的方式之一从 Classic Load Balancers 迁移到 Application Load Balancer。"
    },
    {
        "query":"可否将 Application Load Balancer 用作第 4 层负载均衡器？",
        "intention":"知识问答",
        "reply":"不可以。如果您需要第 4 层功能，则应使用 Network Load Balancer。"
    },
    {
        "query":"可否使用单个 Application Load Balancer 处理 HTTP 和 HTTPS 请求？",
        "intention":"知识问答",
        "reply":"可以。您可以将 HTTP 端口 80 和 HTTPS 端口 443 的侦听器添加到单个 Application Load Balancer。"
    },
    {
        "query":"我能否获取从我的账户发起的所有 Application Load Balancer API 调用的历史记录，以便进行安全分析并排除运行故障？",
        "intention":"知识问答",
        "reply":"能。要获取从您的账户发起的 Application Load Balancer API 调用的历史记录，请使用 [AWS CloudTrail](https://aws.amazon.com/cloudtrail/)。"
    },
    {
        "query":"Application Load Balancer 是否支持终止 HTTPS？",
        "intention":"知识问答",
        "reply":"支持。您可以终止 Application Load Balancer 上的 HTTPS 连接。您必须在负载均衡器上安装安全套接字层 (SSL) 证书。负载均衡器先使用此证书终止连接，然后解密来自客户端的请求并将请求发送到目标。"
    },
    {
        "query":"获取 SSL 证书需要哪些步骤？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Certificate Manager](https://aws.amazon.com/certificate-manager/) 预置 SSL/TLS 证书，也可以从其他来源获取证书，具体方法如下：先创建证书请求、获取 CA 签名的证书请求，然后使用 AWS Certification Manager 或 [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam/) 服务上传证书。"
    },
    {
        "query":"Application Load Balancer 如何与 AWS Certificate Manager (ACM) 集成？",
        "intention":"知识问答",
        "reply":"Application Load Balancer 现已与 AWS Certificate Management (ACM) 集成。与 ACM 集成后，可以简化将证书绑定到负载均衡器的过程，从而精简整个 SSL 卸载过程。SSL/TLS 证书的购买、上传和续订是一个复杂且耗时的手动过程。Application Load Balancer 与 ACM 集成后，整个过程便大大简化，只需请求受信任的 SSL/TLS 证书，然后选择 ACM 证书并使用负载均衡器对其进行预置即可。"
    },
    {
        "query":"Application Load Balancer 是否支持后端服务器身份验证？",
        "intention":"知识问答",
        "reply":"不支持。Application Load Balancer 仅支持后端加密。"
    },
    {
        "query":"如何能为 Application Load Balancer 启用服务器名称指示 (SNI)？",
        "intention":"知识问答",
        "reply":"当您将多个 TLS 证书与负载均衡器上的同一个安全侦听器关联时，系统会自动启用 SNI。同样，当您仅将一个证书与一个安全侦听器关联时，系统会自动禁用该安全侦听器的 SNI 模式。"
    },
    {
        "query":"可以将同一个域的多个证书关联到一个安全侦听器吗？",
        "intention":"知识问答",
        "reply":"可以，您可以将同一个域的多个证书关联到一个安全侦听器。例如，您可以指定："
    },
    {
        "query":"Application Load Balancer 是否支持 IPv6？",
        "intention":"知识问答",
        "reply":"支持。Application Load Balancer 支持 IPv6。"
    },
    {
        "query":"如何在 Application Load Balancer 上设置规则？",
        "intention":"知识问答",
        "reply":"您可以针对负载均衡器上的每个侦听器配置规则。规则包括条件以及条件满足时的相应操作。支持的条件为托管标头、路径、HTTP 标头、方法、查询参数和源 IP 无类域间路由 (CIDR)。支持的操作为重定向、固定响应、验证和转发。规则设置成功后，负载均衡器将使用这些规则来确定应路由哪个特定 HTTP 请求。您可以在一个规则中使用多个条件和操作，并可以在每个条件中就多个值指定一个匹配。"
    },
    {
        "query":"Application Load Balancer 是否存在资源限制？",
        "intention":"知识问答",
        "reply":"您的 AWS 账户存在以下关于 Application Load Balancer 的[限制](http://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-limits.html)。"
    },
    {
        "query":"如何保护负载均衡器后的 Web 应用程序免受 Web 攻击？",
        "intention":"知识问答",
        "reply":"您可以将 Application Load Balancer 与 AWS Web Application Firewall (WAF) 集成，后者是一种 Web 应用程序防火墙，让您能够配置基于 IP 地址、HTTP 报头和自定义统一资源标识符 (URI) 字符串的规则，帮助保护 Web 应用程序免受攻击。借助这些规则，AWS WAF 能够阻止、允许或监控（统计）Web 应用程序的 Web 请求。要了解更多信息，请参阅 AWS WAF 开发人员指南。"
    },
    {
        "query":"能否对任意 IP 地址进行负载均衡？",
        "intention":"知识问答",
        "reply":"您可以将负载均衡器 VPC CIDR 中的任意 IP 地址用于负载均衡器 VPC 内的目标，将 RFC 1918 范围（10.0.0.0/8、172.16.0.0/12，以及 192.168.0.0/16）或 RFC 6598 范围 (100.64.0.0/10) 中的任意 IP 地址用于负载均衡器 VPC 外的目标（例如，对等 VPC、Amazon EC2 Classic 和本地位置内可通过 AWS Direct Connect 或 VPN 连接进行访问的目标）。"
    },
    {
        "query":"如何对分布在 VPC 和本地位置的应用程序进行负载均衡？",
        "intention":"知识问答",
        "reply":"有多种方法可实现混合负载均衡。如果应用程序在分布于 VPC 和本地位置之间的多个目标上运行，您可以使用这些目标的 IP 地址将其添加到同一目标组。要在不影响应用程序的情况下迁移到 AWS，请逐步向目标组添加 VPC 目标，并从目标组中删除本地目标。\n如果您有两个不同的应用程序，其中一个应用程序的目标位于 VPC 中，另一应用程序的目标位于本地位置，则您可以将 VPC 目标放入一个目标组，将本地目标放入另一个目标组，然后使用基于内容的路由将流量路由到每个目标组。您还可以分别针对 VPC 目标和本地目标使用不同的负载均衡器，并使用 DNS 加权在 VPC 和本地目标之间进行加权负载均衡。"
    },
    {
        "query":"如何对 EC2-Classic 实例进行负载均衡？",
        "intention":"知识问答",
        "reply":"将 EC2-Classic 实例的 ID 注册为目标时，您无法对其进行负载均衡。但如果您使用 ClassicLink 将这些 EC2-Classic 实例链接到负载均衡器的 VPC，并将这些 EC2-Classic 实例的私有 IP 用作目标，那么您就可以对 EC2-Classic 实例进行负载均衡。如果您目前使用的是带有 Classic Load Balancer 的 EC2 Classic 实例，则可以轻松迁移至 Application Load Balancer。"
    },
    {
        "query":"如何在 Application Load Balancer 中启用跨区域负载均衡？",
        "intention":"知识问答",
        "reply":"在 Application Load Balancer 中，跨区域负载均衡默认已启用。"
    },
    {
        "query":"什么时候应该使用与 Application Load Balancer 集成的 Amazon Cognito 验证用户身份，什么时候应该利用 Application Load Balancer 对 OpenID Connect (IODC) 身份提供程序 (IdP) 的原生支持验证用户身份？",
        "intention":"知识问答",
        "reply":"如果存在以下情况，您应该使用 Amazon Cognito 验证身份：\n另外，如果您已经开发了自定义 IdP 解决方案并希望使用一个与 OpenID Connect 兼容的身份提供程序进行身份验证，那么您最好使用 Application Load Balancer 原生的 OIDC 解决方案。"
    },
    {
        "query":"Application Load Balancer 支持什么类型的重定向？",
        "intention":"知识问答",
        "reply":"支持以下三种类型的重定向。\n| 重定向类型 | 示例 |\n| --- | --- |\n| HTTP 重定向到 HTTP | http://hostA 重定向到 http://hostB |\n| HTTP 重定向到 HTTPS | http://hostA 重定向到 https://hostB https://hostA:portA/pathA 重定向到 https://hostB:portB/pathB |\n| HTTPS 重定向到 HTTPS | https://hostA 重定向到 https://hostB |\nhttp://hostA 重定向到 https://hostB  \n https://hostA:portA/pathA 重定向到 https://hostB:portB/pathB"
    },
    {
        "query":"ALB 支持哪些内容类型作为固定响应操作的消息正文？",
        "intention":"知识问答",
        "reply":"支持以下内容类型：text/plain、text/css、text/html、application/javascript 和 application/json。"
    },
    {
        "query":"通过 Application Load Balancer 进行的 AWS Lambda 调用的机制是什么？",
        "intention":"知识问答",
        "reply":"负载均衡器接收的 HTTP(S) 请求由基于内容的路由规则处理。如果请求内容与具有将 Lambda 函数作为目标转发到目标组的操作的规则匹配，则调用相应的 Lambda 函数。请求的内容（包括标题和正文）以 JavaScript 对象表示法 (JSON) 格式传递给 Lambda 函数。Lambda 函数的响应应采用 JSON 格式。Lambda 函数的响应转换为 HTTP 响应并发送到客户端。负载均衡器使用 AWS Lambda Invoke API 调用您的 Lambda 函数，并要求您将 Lambda 函数的调用权限提供给 Elastic Load Balancing 服务。"
    },
    {
        "query":"通过 Application Load Balancer 调用 Lambda 是否支持 HTTP 和 HTTPS 协议上的请求？",
        "intention":"知识问答",
        "reply":"是。Application Load Balancer 支持通过 HTTP 和 HTTPS 协议进行请求的 Lambda 调用。"
    },
    {
        "query":"我可以在哪些 AWS 区域中使用 Lambda 函数作为 Application Load Balancer 的目标？",
        "intention":"知识问答",
        "reply":"在以下 AWS 区域，您可以将 Lambda 用作 Application Load Balancer 的目标：美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（加利福尼亚北部）、美国西部（俄勒冈）、亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲（法兰克福）、欧洲（爱尔兰）、欧洲（伦敦）、欧洲（巴黎）、南美洲（圣保罗）和 GovCloud（美国西部）。"
    },
    {
        "query":"Application Load Balancer 在 AWS Local Zones 中是否可用？",
        "intention":"知识问答",
        "reply":"是的，Application Load Balancer 可以在洛杉矶本地区域中使用。在洛杉矶本地扩展区内，Application Load Balancer 将在单个子网中运行并自动扩展，以适应不同级别的应用程序负载，而无需人工干预。"
    },
    {
        "query":"Application Load Balancer 的定价机制是什么？",
        "intention":"知识问答",
        "reply":"您需要按 Application Load Balancer 的运行小时数（不足 1 小时按 1 小时算）和每小时使用的负载均衡器容量单位 (LCU) 数付费。"
    },
    {
        "query":"什么是负载均衡器容量单位 (LCU)？",
        "intention":"知识问答",
        "reply":"LCU 是一项新指标，用于确定您如何为 Application Load Balancer 付费。对于 Application Load Balancer 处理流量时涉及的各项指标（新连接数、活跃连接数、带宽和规则评估数），LCU 将确定哪项指标的资源使用量最大。"
    },
    {
        "query":"Classic Load Balancer 是否会按 LCU 计费？",
        "intention":"知识问答",
        "reply":"不会，Classic Load Balancer 将继续按带宽和每小时使用量计费。"
    },
    {
        "query":"如何得知 Application Load Balancer 使用的 LCU 数？",
        "intention":"知识问答",
        "reply":"我们通过 Amazon CloudWatch 公开构成 LCU 的所有四个指标的使用情况。"
    },
    {
        "query":"我是否需要为一个 LCU 中的所有指标付费？",
        "intention":"知识问答",
        "reply":"不需要。每小时所使用的 LCU 数量由组成 LCU 的四个指标中资源使用量最大的指标来决定。"
    },
    {
        "query":"我是否只需为部分 LCU 付费？",
        "intention":"知识问答",
        "reply":"能。"
    },
    {
        "query":"是否会为新 AWS 账户提供 Application Load Balancer 免费套餐？",
        "intention":"知识问答",
        "reply":"是。对于新 AWS 账户，针对 Application Load Balancer 提供包括 750 小时和 15 个 LCU 的免费套餐。此免费套餐仅面向新 AWS 客户提供，自 AWS 注册之日起 12 个月内有效。"
    },
    {
        "query":"能否在免费套餐中同时使用 Application Load Balancer 和 Classic Load Balancer？",
        "intention":"知识问答",
        "reply":"是。您可以同时使用 Classic Load Balancer 和 Application Load Balancer，二者的免费使用量分别为 15GB 和 15 个 LCU。Classic Load Balancer 和 Application Load Balancer 的免费使用时间共计 750 小时。"
    },
    {
        "query":"什么是规则评估数？",
        "intention":"知识问答",
        "reply":"规则评估数是指处理的规则数量与每小时平均请求率的乘积。"
    },
    {
        "query":"如何针对不同的证书类型和密钥长度应用 LCU 账单？",
        "intention":"知识问答",
        "reply":"证书密钥长度只影响 LCU 账单计算中每秒新建立的连接数。下表针对不同密钥长度的 RSA 和 ECDSA 证书列出了此指标的值。\n\n| RSA 证书 |  |  |  |  |\n| --- | --- | --- | --- | --- |\n| 密钥长度 | <=2K  | <=4K  | <=8K  | >8K  |\n| 新建连接数/秒 | 25 | 5 | 1 | 0.25 |\n| ECDSA 证书 |  |  |  |  |\n| --- | --- | --- | --- | --- |\n| 密钥长度 | <=256 | <=384 | <=521 | >521  |\n| 新建连接数/秒 | 25 | 5 | 1 | 0.25 |"
    },
    {
        "query":"当在 Application Load Balancer 中启用跨区域负载均衡时，我是否需要对区域 AWS 数据转移付费？",
        "intention":"知识问答",
        "reply":"不需要。当您在 Application Load Balancer 中启用跨区域负载均衡时，您无需支付此类型的区域数据转移费用。"
    },
    {
        "query":"Application Load Balancer 的用户身份验证是否需要单独付费？",
        "intention":"知识问答",
        "reply":"不需要。启用 Application Load Balancer 中的身份验证功能不需要单独付费。如果同时使用 Amazon Cognito 和 Application Load Balancer，需要按 Amazon Cognito 定价付费。"
    },
    {
        "query":"我如何区分 Lambda 目标处理的字节数与其他目标（Amazon EC2、容器和本地服务器）处理的字节数？",
        "intention":"知识问答",
        "reply":"Application Load Balancer 会发出两个新的 CloudWatch 指标。LambdaTargetProcessedBytes 指标指示 Lambda 目标处理的字节数，StandardProcessedBytes 指标指示由所有其他目标类型处理的字节数。"
    },
    {
        "query":"我能否为 Network Load Balancer 创建 TCP 或 UDP（第 4 层）侦听器？",
        "intention":"知识问答",
        "reply":"能。网络负载均衡器支持 TCP、UDP 和 TCP+UDP（第 4 层）侦听器以及 TLS 侦听器。"
    },
    {
        "query":"Network Load Balancer 提供哪些重要功能？",
        "intention":"知识问答",
        "reply":"Network Load Balancer 提供 TCP 和 UDP（第 4 层）负载均衡功能。网络负载均衡器的设计目的在于处理每秒数百万请求、突变的流量模式以及提供超低延迟。此外，Network Load Balancer 还支持 TLS 终止，保存客户端的源 IP，提供稳定的 IP 支持和区域隔离，以及支持长时间运行的连接（此类连接对 WebSocket 型应用程序非常有用）。"
    },
    {
        "query":"Network Load Balancer 能否在同一端口上处理 TCP 和 UDP 协议流量？",
        "intention":"知识问答",
        "reply":"能。为此，您可以使用 TCP+UDP 侦听器。例如，对于同时使用 TCP 和 UDP 的 DNS 服务，您可以在端口 53 上创建 TCP+UDP 侦听器，然后负载均衡器将在该端口上处理 UDP 和 TCP 请求的流量。您必须将 TCP+UDP 侦听器与 TCP+UDP 目标组关联。"
    },
    {
        "query":"网络负载均衡器与 Classic Load Balancer 上的 TCP 侦听器相比如何？",
        "intention":"知识问答",
        "reply":"Network Load Balancer 会保存客户端的源 IP，Classic Load Balancer 则不会。不过，客户可以使用配备 Classic Load Balancer 的代理协议获取源 IP。Network Load Balancer 会自动按可用区 (AZ) 向相应负载均衡器提供静态 IP，还支持按 AZ 向相应负载均衡器分配弹性 IP。Classic Load Balancer 不提供此项支持，"
    },
    {
        "query":"能否从 Classic Load Balancer 迁移到网络负载均衡器？",
        "intention":"知识问答",
        "reply":"能。您可以使用该文档中所列的方式之一从 Classic Load Balancer 迁移到 Network Load Balancer。"
    },
    {
        "query":"Network Load Balancer 是否存在资源限制？",
        "intention":"知识问答",
        "reply":"是的，有关详细信息，请参阅 Network Load Balancer 限制文档。"
    },
    {
        "query":"我能否使用 AWS 管理控制台设置 Network Load Balancer？",
        "intention":"知识问答",
        "reply":"能，您可以使用 AWS 管理控制台、AWS CLI 或相应 API 创建 Network Load Balancer。"
    },
    {
        "query":"我能否使用 Classic Load Balancer 的现有 API 创建网络负载均衡器？",
        "intention":"知识问答",
        "reply":"不能。要创建 Classic Load Balancer，请使用 2012-06-01 API。要创建网络负载均衡器或 Application Load Balancer，请使用 2015-12-01 API。"
    },
    {
        "query":"我能否在单个可用区内创建 Network Load Balancer？",
        "intention":"知识问答",
        "reply":"能，您可以在单个 AZ 内创建 Network Load Balancer，方法是在创建负载均衡器时提供单个子网。"
    },
    {
        "query":"Network Load Balancer 是否支持 DNS 地区和区域故障转移？",
        "intention":"知识问答",
        "reply":"支持，您可以使用 Amazon Route 53 运行状况检查和 DNS 故障转移功能来增强在 Network Load Balancer 后方运行的应用程序的可用性。使用 Route 53 DNS 故障转移，您可以在多个 AWS 可用区运行应用程序并跨地区指定备用负载均衡器以进行故障转移。\n如果您的 Network Load Balancer 已针对多个可用区进行了配置，那么当该可用区内通过该负载均衡器注册的 Amazon EC2 实例运行状况不佳时，或者当指定可用区内的负载均衡器节点运行状况不佳时，Route 53 将故障转移至其他运行状况良好的可用区内的备用负载均衡器节点。"
    },
    {
        "query":"我的 Network Load Balancer 能否同时具有 ELB 提供的 IP、弹性 IP 和分配的私有 IP？",
        "intention":"知识问答",
        "reply":"不能。Network Load Balancer 的地址必须完全由您或 ELB 控制。这是为了确保当将弹性 IP 用于 Network Load Balancer 时，客户端常用的所有地址均不会改变。"
    },
    {
        "query":"我能否在每个子网中为 Network Load Balancer 分配多个 EIP？",
        "intention":"知识问答",
        "reply":"不能。对于 Network Load Balancer 所在的每个关联子网，该 Network Load Balancer 仅支持单个公有/面向 Internet 的 IP 地址。"
    },
    {
        "query":"如果我移除/删除 Network Load Balancer，其关联的弹性 IP 地址会怎样？",
        "intention":"知识问答",
        "reply":"该负载均衡器关联的弹性 IP 地址将返回已分配的池，以供未来使用。"
    },
    {
        "query":"Network Load Balancer 是否支持内部负载均衡器？",
        "intention":"知识问答",
        "reply":"您可以将 Network Load Balancer 设置为面向 Internet 的负载均衡器或内部负载均衡器，可实现与 Application Load Balancer 和 Classic Load Balancer 类似的功能。"
    },
    {
        "query":"内部 Network Load Balancer 能否在每个子网中支持多个私有 IP？",
        "intention":"知识问答",
        "reply":"不能。对于负载均衡器所在的每个关联子网，该 Network Load Balancer 只能支持一个私有 IP。"
    },
    {
        "query":"我能否使用 Network Load Balancer 设置 Websockets？",
        "intention":"知识问答",
        "reply":"能，您可以配置 TCP 侦听器，用于将流量路由至实施 WebSockets 协议 (https://tools.ietf.org/html/rfc6455) 的目标。由于 WebSockets 是第 7 层协议，而 Network Load Balancer 在第 4 层运行，因此无需针对 WebSockets 或其他更高级别的协议特别处理 Network Load Balancer。"
    },
    {
        "query":"能否对任意 IP 地址进行负载均衡？",
        "intention":"知识问答",
        "reply":"是。您可以将负载均衡器 VPC CIDR 中的任意 IP 地址用于负载均衡器 VPC 内的目标，将 RFC 1918 范围（10.0.0.0/8、172.16.0.0/12，以及 192.168.0.0/16）或 RFC 6598 范围 (100.64.0.0/10) 中的任意 IP 地址用于负载均衡器 VPC 外的目标（可通过 AWS Direct Connect 进行访问的 EC2-Classic 和本地位置）。负载均衡到 IP 地址目标类型仅在 TCP 侦听器上受支持，目前在 UDP 侦听器上不受支持。"
    },
    {
        "query":"能否使用 Network Load Balancer 设置 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"能，带有 TCP 和 TLS 侦听器的网络负载均衡器可以用来设置 AWS PrivateLink。您不能在网络负载均衡器上使用 UDP 侦听器设置 PrivateLink。"
    },
    {
        "query":"什么是 UDP 流？",
        "intention":"知识问答",
        "reply":"用户数据报协议 (UDP) 处于无连接状态，而负载均衡器基于 5 元组哈希维持 UDP 流状态，确保在相同环境中发送的数据包始终被转发到相同目标。只要流量在流动，流就被视为是活跃的，直到达到空闲超时。一旦达到超时阈值，负载均衡器就会忘记关联，传入的 UDP 数据包将被视为新流，并被负载均衡到新目标。"
    },
    {
        "query":"Network Load Balancer 支持的空闲超时是多长时间？",
        "intention":"知识问答",
        "reply":"TCP 连接的 Network Load Balancer 空闲超时为 350 秒。UDP 流的空闲超时为 120 秒。"
    },
    {
        "query":"通过将具有 IP 地址而非实例 ID 的负载均衡器后的容器作为目标，我可以获得哪些益处？",
        "intention":"知识问答",
        "reply":"目前，实例上的每个容器都拥有自己的安全组，不需要与其他容器共享安全规则。您可以将安全组附加到 ENI，以便实例上的每个 ENI 都能拥有不同的安全组。您可以将容器映射到特定 ENI 的 IP 地址，以便关联每个容器的安全组。使用 IP 地址进行负载均衡时，还支持在一个实例上运行的多个容器使用同一端口 (比如说端口 80)。通过让多个容器使用同一端口，实例上的容器能够通过已知端口而非随机端口进行相互通信。"
    },
    {
        "query":"如何对分布在 VPC 和本地位置的应用程序进行负载均衡？",
        "intention":"知识问答",
        "reply":"有多种方法可实现混合负载均衡。如果应用程序在分布于 VPC 和本地位置之间的多个目标上运行，您可以使用这些目标的 IP 地址将其添加到同一目标组。要在不影响应用程序的情况下迁移到 AWS，请逐步向目标组添加 VPC 目标，并从目标组中删除本地目标。您还可以分别针对 VPC 目标和本地目标使用不同的负载均衡器，并使用 DNS 加权在 VPC 和本地目标之间进行加权负载均衡。"
    },
    {
        "query":"如何对 EC2-Classic 实例进行负载均衡？",
        "intention":"知识问答",
        "reply":"将 EC2-Classic 实例的 ID 注册为目标时，您无法对其进行负载均衡。但如果您使用 ClassicLink 将这些 EC2-Classic 实例链接到负载均衡器的 VPC，并将这些 EC2-Classic 实例的私有 IP 用作目标，那么您就可以对 EC2-Classic 实例进行负载均衡。如果您目前使用的是带有 Classic Load Balancer 的 EC2 Classic 实例，则可以轻松迁移至网络负载均衡器。"
    },
    {
        "query":"如何在 Network Load Balancer 中启用跨区域负载均衡？",
        "intention":"知识问答",
        "reply":"您只能在创建您的 Network Load Balancer 之后才可以启用跨区域负载均衡。您可以通过编辑负载均衡器属性，然后勾选跨区域负载均衡支持选框来实现。"
    },
    {
        "query":"当在 Network Load Balancer 中启用跨区域负载均衡时，我是否需要对区域 AWS 数据传输付费？",
        "intention":"知识问答",
        "reply":"需要。当 Network Load Balancer 中启用跨区域负载均衡时，将对可用区之间的区域数据传输进行计费。在 [Amazon EC2 按需定价页面](https://aws.amazon.com/ec2/pricing/on-demand/)的数据传输部分中查看收费信息。"
    },
    {
        "query":"跨区域负载平衡是否对 Network Load Balancer 限制有任何影响？响？",
        "intention":"知识问答",
        "reply":"是。Network Load Balancer 每个可用区目前支持 200 个目标。例如，如果您处于两个可用区内，您可以在 Network Load Balancer 最多注册 400 个目标。如果启用跨区域负载平衡，那么支持的最多目标数将从每个可用区 200 个减少至每个负载平衡器 200 个。因此，在上述例子中，当启用跨区域负载平衡时，即使您的负载平衡器处于两个可用区中，您能在负载平衡器中注册的目标数最多为 200 个。"
    },
    {
        "query":"Network Load Balancer 是否支持 TLS 终止？",
        "intention":"知识问答",
        "reply":"是。您可以终止 Network Load Balancer 上的 TLS 连接。您必须在负载均衡器上安装 SSL 证书。负载均衡器先使用此证书终止连接，然后解密来自客户端的请求并将请求发送到目标。"
    },
    {
        "query":"终止 Network Load Balancer 上的 TLS 时，源 IP 地址会保留吗？",
        "intention":"知识问答",
        "reply":"即使您终止了 Network Load Balancer 上的 TLS，源 IP 地址也会继续保留。"
    },
    {
        "query":"获取 SSL 证书需要哪些步骤？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Certificate Manager](https://aws.amazon.com/cn/certificate-manager/) 预置 SSL/TLS 证书，也可以从其他来源获取证书，具体方法如下：先创建证书请求、获取证书颁发机构 (CA) 签名的证书请求，然后使用 AWS Certification Manager (ACM) 或 [AWS Identity and Access Management](https://aws.amazon.com/cn/iam/) (IAM) 服务上传证书。"
    },
    {
        "query":"如何能为 Network Load Balancer 启用服务器名称指示 (SNI)？",
        "intention":"知识问答",
        "reply":"当您将多个 TLS 证书与负载均衡器上的同一个安全侦听器关联时，系统会自动启用 SNI。同样，当您仅将一个证书与一个安全侦听器关联时，系统会自动禁用该安全侦听器的 SNI 模式。"
    },
    {
        "query":"Network Load Balancer 如何集成 AWS Certificate Manager (ACM) 或 Identity Access Manager (IAM)？",
        "intention":"知识问答",
        "reply":"Network Load Balancer 现已与 AWS Certificate Management (ACM) 集成。与 ACM 集成后，可以很简单地将证书绑定到负载均衡器，从而使整个 SSL 卸载过程变得非常容易。SSL/TLS 证书的购买、上传和续订是一个非常耗时且复杂的手动过程。Network Load Balancer 与 ACM 集成后，整个过程便大大简化，只需请求受信任的 SSL/TLS 证书，然后选择 ACM 证书并使用负载均衡器对其进行预置即可。创建 Network Load Balancer 之后，您现在即可配置 TLS 侦听器，然后您便可以选择从 ACM 或 Identity Access Manager (IAM) 中选择证书。这种经验类似于 Application Load Balancer 或 Classic Load Balancer 提供的体验。"
    },
    {
        "query":"Network Load Balancer 是否支持后端服务器身份验证？",
        "intention":"知识问答",
        "reply":"不支持。Network Load Balancer 仅支持后端加密。"
    },
    {
        "query":"Network Load Balancer 支持哪些类型的证书？",
        "intention":"知识问答",
        "reply":"Network Load Balancer 仅支持 2K 密钥大小的 RSA 证书。我们目前不支持在 Network Load Balancer 上使用密钥大小超过 2K 的 RSA 证书或 ECDSA 证书。"
    },
    {
        "query":"哪些 AWS 区域的 Network Load Balancer 支持 TLS 终止？",
        "intention":"知识问答",
        "reply":"在以下 AWS 区域，您可以在 Network Load Balancer 上使用 TLS 终止：美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（加利福尼亚北部）、美国西部（俄勒冈）、亚太区域（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲（法兰克福）、欧洲（爱尔兰）、欧洲（伦敦）、欧洲（巴黎）、南美洲（圣保罗）和 GovCloud（美国西部）。"
    },
    {
        "query":"Network Load Balancer 的定价机制是什么？",
        "intention":"知识问答",
        "reply":"您需要按 Network Load Balancer 的运行小时数（不足 1 小时按 1 小时算）和每小时使用的负载均衡器容量单位 (LCU) 数付费。"
    },
    {
        "query":"什么是负载均衡器容量单位 (LCU)？",
        "intention":"知识问答",
        "reply":"LCU 是一项新指标，用于确定您如何为 Network Load Balancer 付费。对于 Network Load Balancer 处理流量时涉及的各项指标（新连接/流数、活跃连接/流数和带宽），LCU 可确定哪项指标使用的资源最多。"
    },
    {
        "query":"Network Load Balancer 上 TCP 流量的 LCU 指标有哪些？",
        "intention":"知识问答",
        "reply":"TCP 流量的 LCU 指标如下：\n答：UDP 流量的 LCU 指标如下："
    },
    {
        "query":"Network Load Balancer 上 TLS 流量的 LCU 指标有哪些？",
        "intention":"知识问答",
        "reply":"TLS 流量的 LCU 指标如下："
    },
    {
        "query":"每秒的新连接/流数是否与每秒请求数相同？",
        "intention":"知识问答",
        "reply":"不相同。在一次连接中可以发送多个请求。"
    },
    {
        "query":"Classic Load Balancer 是否会按 LCU 计费？",
        "intention":"知识问答",
        "reply":"不会，Classic Load Balancer 将继续按带宽和小时费用计费。"
    },
    {
        "query":"如何得知 Network Load Balancer 使用的 LCU 数量？",
        "intention":"知识问答",
        "reply":"我们会通过 Amazon CloudWatch 公布组成 LCU 的所有三个指标的使用情况。"
    },
    {
        "query":"我是否需要为一个 LCU 中的所有指标付费？",
        "intention":"知识问答",
        "reply":"不需要。每小时所使用的 LCU 数量由组成 LCU 的三个指标中资源使用量最大的指标来决定。"
    },
    {
        "query":"我是否只需为部分 LCU 付费？",
        "intention":"知识问答",
        "reply":"是。"
    },
    {
        "query":"是否会为新 AWS 账户提供 Network Load Balancer 免费套餐？",
        "intention":"知识问答",
        "reply":"是。对于新 AWS 账户，针对 Network Load Balancer 提供包括 750 小时和 15 个 LCU 的免费套餐。此免费套餐仅面向新 AWS 客户提供，自 AWS 注册之日起 12 个月内有效。"
    },
    {
        "query":"能否在免费套餐中同时使用网络负载均衡器、Application Load Balancer 和 Classic Load Balancer？",
        "intention":"知识问答",
        "reply":"是。您可以同时使用 Application Load Balancer 和网络负载均衡器（每个免费使用量均为 15 个 LCU）以及 Classic Load Balancer（分别为 15GB）。Application Load Balancer、网络负载均衡器和 Classic Load Balancer 的免费使用时间共计 750 小时。"
    },
    {
        "query":"与 Network Load Balancer 或 Application Load Balancer 相反的是，我应该什么时候使用网关负载均衡器？",
        "intention":"知识问答",
        "reply":"您应该在部署网络流量目标不为网关负载均衡器本身的内联虚拟设备时使用网关负载均衡器。网关负载均衡器可以通过第三方虚拟设备以透明方式传递第 3 层的所有流量，并且对流量源和目的地不可见。有关如何比较这些负载均衡器的更多详细信息，请参阅[功能比较](https://aws.amazon.com/cn/elasticloadbalancing/features/#Product_comparisons)页面。"
    },
    {
        "query":"可在哪些区域使用网关负载均衡器？",
        "intention":"知识问答",
        "reply":"网关负载均衡器现已在以下区域提供：AWS GovCloud（美国东部）、AWS GovCloud（美国西部）、美国东部（弗吉尼亚州北部）（除 us1-az3 区域外）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、美国西部（北加利福尼亚）、加拿大（中部）、南美洲（圣保罗）、欧洲地区（爱尔兰）、欧洲地区（法兰克福）、欧洲地区（斯德哥尔摩）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（米兰）、欧洲（西班牙）、欧洲（苏黎世）、非洲（开普敦）、中东（巴林）、中东（阿联酋）、亚太地区（悉尼）、亚太地区（东京）、亚太地区（香港）、亚太地区（新加坡）、亚太地区（孟买）、亚太地区（首尔）、亚太地区（大阪）、亚太地区（海得拉巴）、亚太地区（墨尔本）、中国（北京）和中国（宁夏）。"
    },
    {
        "query":"网关负载均衡器是按区域还是按可用区 (AZ) 部署？",
        "intention":"知识问答",
        "reply":"网关负载均衡器在一个可用区内运行。"
    },
    {
        "query":"网关负载均衡器提供哪些重要功能？",
        "intention":"知识问答",
        "reply":"网关负载均衡器提供第 3 层网关和第 4 层负载均衡功能。它是一种透明的线内缓冲设备，不会改变数据包的任何部分。网络负载均衡器的设计目的在于处理每秒数百万请求、不稳定的流量模式以及带来超低延迟。请参阅[此](https://aws.amazon.com/cn/elasticloadbalancing/features/)表中的网关负载均衡器功能。"
    },
    {
        "query":"网关负载均衡器是否执行 TLS 终止？",
        "intention":"知识问答",
        "reply":"网关负载均衡器不执行 TLS 终止且不会维持任何应用程序状态。这些功能由第三方虚拟设备执行，而网关负载均衡器在其中发送和接收流量。"
    },
    {
        "query":"网关负载均衡器是否会维持应用程序状态？",
        "intention":"知识问答",
        "reply":"网关负载均衡器不维持应用程序状态，但它使用 5 元组（对于 TCP/UDP 流量）或 3 元组（对于非 TCP/UDP 流量）维持流量对特定设备的粘性。"
    },
    {
        "query":"网关负载均衡器如何定义流量？",
        "intention":"知识问答",
        "reply":"默认情况下，网关负载均衡器将流量定义为由源 IP、目标 IP、协议、源端口和目标端口组成的 5 元组的组合。网关负载均衡器使用默认的 5 元组哈希确保该流量的两个方向（即源到目标和目标到源）始终被转发到相同目标。只要流量在流动，流就被视为是活跃的，直到达到空闲超时。一旦达到超时阈值，负载均衡器就会忘记关联，传入的流量数据包将被视为新流，并可能被负载均衡到新目标。\n请注意，默认的 5 元组哈希会影响基于 TCP、为控制和数据使用单独的流式传输或端口号的应用程序，如 FTP、Microsoft RDP、Windows RPC 和 SSL VPN。此类应用程序的控制和数据流可能会落在不同的目标设备上，并可能导致流量中断。如果要支持此类协议，可以使用 3 元组（源 IP、目标 IP、传输协议）或 2 元组（源 IP、目标 IP）启用 GWLB 流粘性。请参阅[流粘性文档](https://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/target-groups.html#flow-stickiness)以了解如何更改流粘性类型。\n问：网关负载均衡器支持的空闲超时是多长时间？\n答：TCP 连接的网关负载均衡器空闲超时为 350 秒。非 TCP 流的空闲超时为 120 秒。这些超时为固定数值，不能更改。\n问：设备可以对数据包进行分段吗？\n答：不可以。在将数据包发回到 Gateway Load Balancer (GWLB) 时，GWLB 的目标设备不应对其进行分段。由设备创建的片段会在 Gateway Load Balancer 中被丢弃，因为 IP 片段中没有第 4 层标头。为防止在设备上发生分段，我们建议在您的设备上启用巨型帧或设置您的设备的网络接口以便使用最大所需 MTU，从而通过使原始数据包内容保持原样来实现透明的转发行为。"
    },
    {
        "query":"Gateway Load Balancer 如何处理单个可用区中一个虚拟设备实例的故障？",
        "intention":"知识问答",
        "reply":"当单个虚拟设备实例发生故障时，网关负载均衡器会将其从路由列表中删除并将流量重新路由至运行状况正常的设备实例中。"
    },
    {
        "query":"网关负载均衡器如何处理单个可用区中所有虚拟设备的故障？",
        "intention":"知识问答",
        "reply":"如果某个可用区的所有虚拟设备都发生故障，网关负载均衡器将删除网络流量。为获得更大的可用性，我们建议将网关负载均衡器部署在多个可用区中。如果一个可用区内的所有设备均发生故障，脚本可用于添加新设备，或将流量导向另一个可用区内的网关负载均衡器。"
    },
    {
        "query":"我能否将设备配置为多个网关负载均衡器的目标？",
        "intention":"知识问答",
        "reply":"能，多个网关负载均衡器可以指向相同的虚拟设备集。"
    },
    {
        "query":"我可以为网关负载均衡器创建哪种类型的侦听器？",
        "intention":"知识问答",
        "reply":"网关负载均衡器是一种透明的线内缓冲设备，可侦听所有类型的 IP 流量（包括 TCP、UDP、ICMP、GRE、ESP 等）。因此只能在网关负载均衡器上创建 IP 侦听器。"
    },
    {
        "query":"网关负载均衡器是否存在资源限制？",
        "intention":"知识问答",
        "reply":"是的，有关详细信息，请参阅 Gateway Load Balancer [限制文档](https://docs.aws.amazon.com/elasticloadbalancing/latest/gateway/quotas-limits.html)。"
    },
    {
        "query":"我能否使用 AWS 管理控制台设置网关负载均衡器？",
        "intention":"知识问答",
        "reply":"能，您可以使用 AWS 管理控制台、AWS CLI 或相应 API 创建网关负载均衡器。"
    },
    {
        "query":"我能否在单个可用区内创建网关负载均衡器？",
        "intention":"知识问答",
        "reply":"能，您可以在单个可用区内创建网关负载均衡器，方法是在创建负载均衡器时提供单个子网。但是，我们建议使用多个可用区来提升可用性。创建网关负载均衡器后，您不能添加或删除可用区。  \n   \n 问：如何在网关负载均衡器中启用跨区域负载均衡？\n答：默认情况下禁用跨区负载均衡。您只能在创建您的网关负载均衡器之后才可以启用跨区域负载均衡。您可以通过编辑负载均衡器属性，然后勾选跨区域负载均衡支持选框来实现。  \n   \n 问：当在网关负载均衡器中启用跨区域负载均衡时，我是否需要对 AWS 数据传输付费？\n答：需要。当网关负载均衡器中启用跨区域负载均衡时，将对可用区之间的数据传输进行计费。在“Amazon EC2 按需定价”页面的数据传输部分中查看收费信息。  \n   \n 问：跨区域负载平衡是否对网关负载均衡器限制有任何影响？\n答：是。网关负载均衡器每个可用区目前支持 300 个目标。例如，如果您在 3 个可用区内创建网关负载均衡器，则可以最多注册 900 个目标。如果启用跨区域负载平衡，那么支持的最多目标数将从每个可用区 300 个减少至每个网关负载均衡器 300 个。"
    },
    {
        "query":"网关负载均衡器的定价机制是什么？",
        "intention":"知识问答",
        "reply":"您需要按网关负载均衡器的运行小时数（不足 1 小时按 1 小时算）和网关负载均衡器每小时使用的负载均衡器容量单位 (LCU) 数付费。"
    },
    {
        "query":"什么是负载均衡器容量单位 (LCU)？",
        "intention":"知识问答",
        "reply":"LCU 是一个 Elastic Load Balancing 指标，用于确定您如何为网关负载均衡器付费。对于网关负载均衡器处理流量时涉及的各项指标（新连接/流数、活跃连接/流数和带宽），LCU 可确定哪项指标使用的资源最多。"
    },
    {
        "query":"用于网关负载均衡器的 LCU 指标有哪些？",
        "intention":"知识问答",
        "reply":"TCP 流量的 LCU 指标如下："
    },
    {
        "query":"我为什么需要网关负载均衡器终端节点？",
        "intention":"知识问答",
        "reply":"为了具有价值，虚拟设备需要尽量少带来额外延迟，且进出虚拟设备的流量必须遵循安全连接。网关负载均衡器终端节点会创建满足这些要求所需的安全低延迟连接。"
    },
    {
        "query":"网关负载均衡器终端节点如何帮助进行集中化？",
        "intention":"知识问答",
        "reply":"使用网关负载均衡器终端节点，设备可以驻留在不同的 AWS 账户和 VPC 中。这样一来，设备可以集中在一个位置，从而更加便于管理和减少运营开销。"
    },
    {
        "query":"网关负载均衡器终端节点的工作原理是什么？",
        "intention":"知识问答",
        "reply":"网关负载均衡器终端节点是采用 PrivateLink 技术的一种新的 VPC 端点类型。当网络流量从一个来源（互联网网关、VPC 等）流向网关负载均衡器，然后返回时，网关负载均衡器终端节点可确保这两者之间的私有连接。所有流量均通过 AWS 网络，且数据永远不会公开到互联网上，从而提高安全性和性能。"
    },
    {
        "query":"PrivateLink 接口终端节点与网关负载均衡器终端节点有何不同？",
        "intention":"知识问答",
        "reply":"PrivateLink 接口终端节点与 Network Load Balancer (NLB) 配对，以分发目标为 Web 应用程序的 TCP 和 UDP 流量。相比之下，网关负载均衡器终端节点可网关负载均衡器结合使用，以连接流量的来源和目的地。流量通过虚拟设备从网关负载均衡器端点流向网关负载均衡器中，然后再通过安全的 PrivateLink 连接返回目的地中。  \n   \n 问：我可以将多少个网关负载均衡器端点连接到一个网关负载均衡器？\n网关负载均衡器端点是一个 VPC 端点，对于可以连接到使用网关负载均衡器的服务的 VPC 端点数量没有限制。但是，我们建议每个网关负载均衡器连接不超过 50 个网关负载均衡器端点，以降低在服务失效时产生更广泛影响的风险。"
    },
    {
        "query":"Classic Load Balancer 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"Classic Load Balancer 支持 Amazon EC2 实例使用 Amazon EC2 服务目前支持的所有操作系统。"
    },
    {
        "query":"Classic Load Balancer 支持哪些协议？",
        "intention":"知识问答",
        "reply":"Classic Load Balancer 支持对使用 HTTP、HTTPS（安全 HTTP）、SSL（安全 TCP）和 TCP 协议的应用程序执行负载均衡。"
    },
    {
        "query":"可以为哪些 TCP 端口执行负载均衡？",
        "intention":"知识问答",
        "reply":"您可以为下列 TCP 端口执行负载均衡："
    },
    {
        "query":"Classic Load Balancer 是否支持 IPv6 流量？",
        "intention":"知识问答",
        "reply":"能。每个 Classic Load Balancer 都关联一个 IPv4、一个 IPv6 和一个双栈（同时支持 IPv4 和 IPv6）DNS 名称。VPC 中不支持 IPv6。您可以在 VPC 中使用 Application Load Balancer 提供原生 IPv6 支持。"
    },
    {
        "query":"可否将 Amazon EC2 实例配置为仅接收来自 Classic Load Balancer 的流量？",
        "intention":"知识问答",
        "reply":"能。"
    },
    {
        "query":"可否为 Classic Load Balancer 的前端配置安全组？",
        "intention":"知识问答",
        "reply":"如果您使用的是 Amazon Virtual Private Cloud，则可以为 Classic Load Balancer 的前端配置安全组。"
    },
    {
        "query":"可否使用单个 Classic Load Balancer 处理 HTTP 和 HTTPS 请求？",
        "intention":"知识问答",
        "reply":"可以。您可以将 HTTP 端口 80 和 HTTPS 端口 443 映射到单个 Classic Load Balancer。"
    },
    {
        "query":"已进行负载均衡的 Amazon EC2 实例需要从每个 Classic Load Balancer 接收多少个连接？",
        "intention":"知识问答",
        "reply":"对于其可以尝试与已执行负载均衡的 Amazon EC2 实例建立的连接数，Classic Load Balancer 并不设置上限。随着 HTTP、HTTPS 或 SSL 并发请求数或 Classic Load Balancer 所接收的并发 TCP 连接数的增多，此数值亦会提高。"
    },
    {
        "query":"是否可以对使用付费 AMI 启动的 Amazon EC2 实例执行负载均衡？",
        "intention":"知识问答",
        "reply":"对于通过从 [AWS Marketplace](https://aws.amazon.com/marketplace) 购买的付费 AMI 启动的 Amazon EC2 实例，您可以对其执行负载均衡。但是，Classic Load Balancer 不支持使用 [Amazon DevPay](http://aws.amazon.com/devpay/) 网站上的付费 AMI 启动的实例。"
    },
    {
        "query":"是否可以在 Amazon Virtual Private Cloud 中使用 Classic Load Balancer？",
        "intention":"知识问答",
        "reply":"能。请参阅 Elastic Load Balancing [网页](https://aws.amazon.com/cn/elasticloadbalancing/)。"
    },
    {
        "query":"我能否获取从我的账户发起的所有 Classic Load Balancer API 调用的历史记录，以便进行安全分析并排除运行故障？",
        "intention":"知识问答",
        "reply":"能。要获取从您的账户发起的 Classic Load Balancer API 调用的历史记录，只需在 AWS 管理控制台打开 CloudTrail 即可。"
    },
    {
        "query":"Classic Load Balancer 是否支持终止 SSL？",
        "intention":"知识问答",
        "reply":"支持。您可以终止 Classic Load Balancer 上的 SSL 连接。您必须在每个负载均衡器上安装 SSL 证书。负载均衡器先使用此证书终止连接，然后解密来自客户端的请求并将请求发送到后端实例。"
    },
    {
        "query":"获取 SSL 证书需要哪些步骤？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Certificate Manager](https://aws.amazon.com/certificate-manager/) 预配置 SSL/TLS 证书，也可以从其他来源获取证书，具体方法如下：先创建证书请求、获取 CA 签名的证书请求，然后使用 AWS Identity and Access Management (IAM) 服务上传证书。"
    },
    {
        "query":"Classic Load Balancer 如何与 AWS Certificate Manager (ACM) 集成？",
        "intention":"知识问答",
        "reply":"Classic Load Balancer 现已与 AWS Certificate Management (ACM) 集成。与 ACM 集成后，可以很简单地将证书绑定到每个负载均衡器，从而使整个 SSL 卸载过程变得非常容易。SSL/TLS 证书的购买、上传和续订通常是一个非常耗时且复杂的手动过程。Classic Load Balancer 与 ACM 集成后，整个过程便大大简化，只需请求受信任的 SSL/TLS 证书，然后选择 ACM 证书并使用负载均衡器对其进行预置即可。"
    },
    {
        "query":"如何在 Classic Load Balancer 中启用跨区负载均衡？",
        "intention":"知识问答",
        "reply":"您可以使用控制台、AWS CLI 或 AWS 开发工具包启用跨区负载均衡。有关更多详细信息，请参阅跨区负载均衡[文档](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/enable-disable-crosszone-lb.html#enable-cross-zone)。"
    },
    {
        "query":"当在 Classic Load Balancer 中启用跨区域负载均衡时，我是否需要对区域 AWS 数据传输付费？",
        "intention":"知识问答",
        "reply":"不需要。当您在 Classic Load Balancer 中启用跨区域负载均衡时，您无需为可用区之间的区域数据传输付费。"
    },
    {
        "query":"AWS DeepRacer 有哪些新功能？ AWS DeepRacer 客户可以在 AWS DeepRacer 控制台中启动多车竞赛和物体躲避功能，使用 AWS DeepRacer 应对未来的机器学习挑战。客户现在可以通过试验多个传感器输入、最新的强化学习算法和神经网络配置，来构建物体躲避和双车正面挑战赛的模型。",
        "intention":"知识问答",
        "reply":"问：AWS DeepRacer 与市场上的其他机器人模型汽车有何不同？\nAWS DeepRacer 是第一款专门为帮助开发人员进行强化学习实践而开发的自动驾驶汽车。AWS DeepRacer 为开发人员提供了一种学习 RL 的简单方法，用新的 RL 算法和模拟到真实域传输方法进行实验，并在现实世界中体验 RL。"
    },
    {
        "query":"什么是 AWS DeepRacer League？ AWS DeepRacer League 是世界上第一个面向开发人员的全球自动驾驶赛车联盟。AWS 客户可以使用其 AWS DeepRacer RL 模型参加全球锦标赛，竞逐奖品、荣誉，并有机会举起冠军奖杯。",
        "intention":"知识问答",
        "reply":"[在以下专用常见问题部分](https://aws.amazon.com/deepracer/faqs/#AWS_DeepRacer_League)了解更多关于联盟的信息"
    },
    {
        "query":"Amazon Lookout for Metrics 有何功能？",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Metrics 使用机器学习 (ML)，使客户能够更轻松、更准确地检测指标异常。客户上传数据后，Lookout for Metrics 会自动检查数据，并使用 ML 创建准确的异常检测模型。当检测到异常时，Lookout for Metrics 会将相关异常分组在一起并提供一个严重性分数，以便客户能够快速诊断问题或最大程度地利用机会。"
    },
    {
        "query":"Amazon Lookout for Metrics 与其他异常检测服务有何不同？",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Metrics 有四个关键的差异化功能。"
    },
    {
        "query":"Amazon Lookout for Metrics 支持哪些关键使用案例？",
        "intention":"知识问答",
        "reply":"Lookout for Metrics 支持与零售、游戏、广告技术和电信等行业的客户参与、运营、销售和营销相关的各种业务指标的异常检测用例。"
    },
    {
        "query":"客户是否需要历史数据才能使用 Amazon Lookout for Metrics？",
        "intention":"知识问答",
        "reply":"客户不需要历史数据即可使用 Lookout for Metrics。客户只需要自己的连续数据就可以开始使用，因为 Lookout for Metrics 会从客户的实时数据中学习，并在初始化时期（模型从数据中学习的时期）过后开始显示结果。初始化时期的长短取决于数据的频率，例如 5 分钟、10 分钟、1 小时、每 24 小时。"
    },
    {
        "query":"要使用 Amazon Lookout for Metrics，我的数据需要采用什么格式？",
        "intention":"知识问答",
        "reply":"Lookout for Metrics 使用 CSV 或 JSON 格式的数据。"
    },
    {
        "query":"Amazon Lookout for Metrics 支持哪些数据源？",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Metrics 可轻松连接热门的数据存储，如 Amazon Simple Storage (S3)、Amazon Redshift、AWS CloudWatch、Amazon RDS（所有受支持的数据库引擎），以及常用的 SaaS 应用程序，包括 Salesforce、Marketo、Zendesk、ServiceNow、Infor Nexus、Google Analytics、Dynatrace、Datadog、Amplitude、Veeva Systems、Singular、Amazon Simple Notification Service (SNS) AWS Lambda、Slack、PagerDuty、Datadog、Webhooks。"
    },
    {
        "query":"哪些区域可以使用 Amazon Lookout for Metrics？",
        "intention":"知识问答",
        "reply":"Lookout for Metrics 现已在以下区域推出：美国东部（弗吉尼亚北部）、美国西部（俄勒冈）、美国东部（俄亥俄）、欧洲（爱尔兰）、欧洲（法兰克福）、欧洲（斯德哥尔摩）、亚太地区（东京）、亚太地区（新加坡）和亚太地区（悉尼）。"
    },
    {
        "query":"Amazon Lookout for Metrics 如何定价？",
        "intention":"知识问答",
        "reply":"使用 Amazon Lookout for Metrics 时，您只需按实际使用量付费。无需预先承诺，没有最低消费限制。Amazon Lookout for Metrics 会自动分析您关心的指标、检测这些指标是否有异常、发送自动警报，并能帮助您确定异常的严重程度及其根本原因。请参阅[定价页面](https://aws.amazon.com/lookout-for-metrics/pricing/)了解更多详细信息和示例。"
    },
    {
        "query":"客户如何开始使用 Amazon Lookout for Metrics？",
        "intention":"知识问答",
        "reply":"单击[此处](https://ap-northeast-1.console.aws.amazon.com/lookoutmetrics/home?region=ap-northeast-1#landing)即可开始使用。"
    },
    {
        "query":"为什么要使用 AWS IoT FleetWise？",
        "intention":"知识问答",
        "reply":"AWS IoT FleetWise 消除了大规模收集车辆数据的复杂性。使用虚拟车辆建模，您可以创建一个不同车辆品牌、型号和组件都通用的数据格式，从而简化在云中分析车队数据的工作。\nAWS IoT FleetWise 还能帮助您更智能地收集车辆数据，让您在云端获得更有用的数据。您可以通过创建基于时间和事件的数据收集活动，将需要的确切数据发送到云中，从而提高数据的相关性。\n问：如何开始使用 AWS IoT FleetWise？\n首先，登录 [AWS 管理控制台](https://console.aws.amazon.com/iotfleetwise/home?region=us-east-1#/)。接下来，查看[资源页面](https://aws.amazon.com/cn/iot-fleetwise/resources/)上的入门文档。最后，通过为车辆建模并定义数据收集活动来开始使用 AWS IoT FleetWise 进行构建。\n问：Edge Agent 与 AWS IoT FleetWise 配合使用的系统要求是什么？\nAWS IoT FleetWise 的 Edge Agent 参考实施可以在大多数基于 Linux 的嵌入式平台上运行。如需查看移植了 Edge Agent 参考实施的参考硬件的示例，请访问[合作伙伴](https://aws.amazon.com/iot-fleetwise/partners/)页面。[开发人员指南](https://github.com/aws/aws-iot-fleetwise-edge/blob/main/docs/dev-guide/edge-agent-dev-guide.md)中包含了使用由 [AWS Graviton2](https://aws.amazon.com/pm/ec2-graviton/) 提供支持的 Amazon Elastic Compute Cloud (EC2) 实例设置虚拟环境的说明，而非采购硬件。\n将 Edge Agent 移至目标硬件的过程很简单。要开始移植，您可以在 Edge Agent [GitHub 页面](https://github.com/aws/aws-iot-fleetwise-edge/blob/main/README.md)上查找移植信息，包括源代码访问、平台支持、版本依赖项信息以及其他资源。要了解更多信息，请参阅[控制台](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fus-east-1.console.aws.amazon.com%2Fiotfleetwise%2Fhome%3Ffromtb%3Dtrue%26hashArgs%3D%2523%252F%26isauthcode%3Dtrue%26region%3Dus-east-1%26state%3DhashArgsFromTB_us-east-1_4e1d7db2f1c98161&client_id=arn%3Aaws%3Asignin%3A%3A%3Aconsole%2Fiotfleetwise&forceMobileApp=0&code_challenge=Ot8xBSBIHmMvDB7stNdA8S2b6ycBj7mIywMjk4gl43I&code_challenge_method=SHA-256)内提供的 Edge Agent 指南。\n问：AWS IoT FleetWise 收集的数据将会发生什么变化？\n通过 AWS IoT FleetWise 收集和摄取的数据将会直接进入您的存储库，如 [Amazon Timestream](https://aws.amazon.com/cn/timestream/) 或 [Amazon Simple Storage Service（Amazon S3）](https://aws.amazon.com/cn/s3/)。您可以拥有并控制 AWS IoT FleetWise 收集的数据。"
    },
    {
        "query":"在哪些情况下，我应该在 Amazon Timestream 而不是 Amazon Simple Storage Service（Amazon S3）中存储数据？",
        "intention":"知识问答",
        "reply":"不能。要更改存储目的地，您必须创建新的活动并选择 Amazon S3。"
    },
    {
        "query":"AWS IoT FleetWise 还可以收集车辆丰富的传感器数据吗？",
        "intention":"知识问答",
        "reply":"AWS IoT FleetWise 将会收集和传输传统的基于 CAN 的汽车传感器数据（例如，发动机温度或燃油压力）。2023 年，我们计划支持从摄像头或雷达等高级传感器收集数据。"
    },
    {
        "query":"AWS IoT FleetWise 车辆建模工作原理是什么？",
        "intention":"知识问答",
        "reply":"车辆模型是车辆传感器和信号的数字表现形式。您可以根据需要让这些模型变得简单或详细。通过将虚拟车辆模型用作 AWS IoT FleetWise 的蓝图，您可以根据通用属性（例如车门数量）将车辆组织到市场活动中，然后在不同的车队中设置统一的收集参数。车辆模型可以帮助您创建传感器和信号定义并在多个提供商中进行共享。有关详细信息，请参阅 [AWS IoT FleetWise 开发人员指南](https://docs.aws.amazon.com/iot-fleetwise/latest/developerguide/what-is-iotfleetwise.html)。"
    },
    {
        "query":"如何选择要收集的数据？",
        "intention":"知识问答",
        "reply":"通过在 AWS IoT FleetWise 控制台中编写基于规则的简单语句来定义想要收集的车辆数据。AWS IoT FleetWise 将这些语句从云中发送到车辆，Edge Agent 将会根据这些语句收集和传输数据。有关详细信息，请参阅 [AWS IoT FleetWise 开发人员指南](https://docs.aws.amazon.com/iot-fleetwise/latest/developerguide/what-is-iotfleetwise.html)。"
    },
    {
        "query":"AWS IoT FleetWise 如何使用我当前的 AWS 架构？",
        "intention":"知识问答",
        "reply":"您可将 AWS IoT FleetWise 与您现有 AWS 服务（如 AWS IoT Core 和 Amazon Timestream）的实施相集成。若要讨论与特定架构的集成或者与 AWS IoT FleetWise 的其他集成选项，[请联系我们的销售团队](https://aws.amazon.com/cn/contact-us/sales-support/)。"
    },
    {
        "query":"What is AWS Microservice Extractor for .NET?",
        "intention":"知识问答",
        "reply":"AWS Microservice Extractor for .NET simplifies the process of refactoring applications into independent services. Modernize and transform your applications with an assistive tool that analyzes source code and runtime metrics to create a visual representation of your application and its dependencies. Microservice Extractor for .NET delivers a holistic visualization of applications, assists in code refactoring and extraction of the codebase into separate code projects that teams can develop, build, and operate independently to improve agility, uptime, and scalability."
    },
    {
        "query":"Who should use AWS Microservice Extractor for .NET?",
        "intention":"知识问答",
        "reply":"AWS Microservice Extractor for .NET is for customers looking to break down ASP.NET monolithic applications into smaller code projects that may be deployed as independent services. It is primarily aimed at developers who make code changes to refactor applications. It also assists software architects and business analysts in identifying the business processes that need to be modeled as separate services."
    },
    {
        "query":"What are the pre-requisites to use Microservice Extractor for .NET? Microservice Extractor for .NET needs to be installed on a Windows system that has access to buildable source code of the application you are looking to refactor. You need to have an AWS account with AWS CLI profile setup to publish metrics. The application source to be analyzed must be built on .NET Framework 4.0 or higher, .NET Core version 3.1, .NET 5.0, or .NET 6.0. The application code must be written in C#.",
        "intention":"知识问答",
        "reply":"Note: Microservice Extractor does not support ASP.NET Web Pages or Razer Pages at this time."
    },
    {
        "query":"什么是 AWS Application Discovery Service？",
        "intention":"知识问答",
        "reply":"AWS Application Discovery Service 可以收集和提供数据，让企业客户能够了解其 IT 环境内的服务器配置、使用情况和行为。服务器数据保留在 Application Discovery Service 中，该服务将按照各个应用程序对数据进行标记和分组，以便安排 AWS 迁移。所收集的数据可以导出到 Excel 或其他云迁移分析工具中进行分析。"
    },
    {
        "query":"Application Discovery Service 如何帮助企业迁移到 AWS？",
        "intention":"知识问答",
        "reply":"Application Discovery Service 可以收集服务器规格信息、硬件配置、性能数据以及正在运行的进程和网络连接的详细信息，从而帮助企业获取其数据中心服务器当前状态的快照。在该服务收集到相关数据后，您可以使用这些数据分析总拥有成本（TCO），然后根据您独特的业务需求制定成本优化的迁移计划。"
    },
    {
        "query":"Application Discovery Service 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"除了基于文件的导入之外，Application Discovery Service 还支持基于代理和无代理的本地工具。通过无代理发现，客户可将工具部署在集中式服务器上，后者随后会利用本地环境中的公有 API 来发现资源并监控利用率。此过程允许一次安装监控多台服务器。对于需要更高分辨率数据（包括正在运行的进程的相关信息）的客户，该收集工具将部署在本地环境中的每台服务器（物理或虚拟）上。"
    },
    {
        "query":"如何开始使用 Application Discovery Service？",
        "intention":"知识问答",
        "reply":"要开始使用 Application Discovery Service，只需访问 [AWS Migration Hub 控制台](https://console.aws.amazon.com/migrationhub/dashboard)。"
    },
    {
        "query":"Application Discovery Service 在何处提供服务？",
        "intention":"知识问答",
        "reply":"Application Discovery Service 在全球均提供服务。这意味着，无论资源在何处，您都可以发现它们。要查看服务托管在哪个区域，请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"什么是 Migration Hub 主区域？",
        "intention":"知识问答",
        "reply":"使用 Migration Hub 和 Application Discovery Service 之前，您需要从 [Migration Hub 设置](https://console.aws.amazon.com/migrationhub/settings)页面中或使用 [Migration Hub Config API](https://docs.aws.amazon.com/migrationhub-home-region/latest/APIReference/Welcome.html) 选择 Migration Hub 主区域。Application Discovery Service 使用 Migration Hub 主区域作为存储您的发现和计划数据的唯一 AWS 区域。Migration Hub 主区域中存储的数据可为您的整个组合资源提供用于发现和迁移计划信息的单一存储库以及关于迁移到多个 AWS 区域的单一视图。请参阅[文档](https://docs.aws.amazon.com/migrationhub/latest/ug/home-region.html)，了解有关 Migration Hub 主区域的更多信息。\n注意：一旦设置，Migration Hub 主区域就不能再更改。"
    },
    {
        "query":"我应该使用哪种本地发现工具？",
        "intention":"知识问答",
        "reply":"对于寻求进程级依赖关系数据的客户，建议使用 AWS Application Discovery Service Discovery Agent。收集的数据可用于 Migration Hub 和 Amazon Athena。\n对于专门寻求有关本地 VMware 基础设施的元数据的客户，应使用 AWS Application Discovery Service Agentless Collector。发现的数据可用于 Migration Hub。基于代理的 Application Discovery 和无代理 Application Discovery 可以同时运行。\n对于寻求引导式迁移评估或无代理服务器依赖关系映射的客户，应通过 Migration Evaluator 来请求评估。此服务提供专门的解决方案架构师来协助数据发现并提供迁移专业知识。Migration Evaluator Agentless Collector 可监控 VMware、Hyper-V、SQL Server、Windows 和 Linux 工作负载。收集的数据可用于 Migration Hub 和 Migration Evaluator。"
    },
    {
        "query":"AWS Application Discovery Service Discovery Agent 可以捕获哪些数据？",
        "intention":"知识问答",
        "reply":"Discovery Agent 可以捕获系统配置、系统性能、正在运行的进程以及系统间网络连接的详细信息。"
    },
    {
        "query":"Application Discovery Service 可以为哪些操作系统提供代理？",
        "intention":"知识问答",
        "reply":"Application Discovery Service 发布了全新的 2.0 版本 Discovery Agent，可提供更好的操作系统支持。2.0 版本 Discovery Agent 可支持 Microsoft Windows Server 2008 R1 SP2、2008 R2 SP1、2012 R1、2012 R2、2016、2019、Amazon Linux 2012.03、2015.03、Amazon Linux 2（2018 年 9 月 25 日更新及更高版本）、Ubuntu 12.04、14.04、16.04、18.04、20.04、Red Hat Enterprise Linux 5.11、6.10、7.3、7.7、8.1、CentOS 5.11、6.9、7.3 和 SUSE 11 SP4、12 SP5。"
    },
    {
        "query":"如何在将数据传输到 AWS 的过程中保护数据？",
        "intention":"知识问答",
        "reply":"Discovery Agent 使用 HTTPS/TLS 将数据传输到 Application Discovery Service。Discovery Agent 可以在离线测试模式下运行，并将数据写入本地文件，这使客户可以在启用在线模式前查看所收集的数据。"
    },
    {
        "query":"如何在我的数据中心安装 Discovery Agent？",
        "intention":"知识问答",
        "reply":"请参阅该[文档](https://aws.amazon.com/cn/documentation/application-discovery/)，了解有关如何安装 Discovery Agent 的详细信息。"
    },
    {
        "query":"Discovery Agent 是否会向 AWS 授予对我的数据中心服务器的远程访问权限？",
        "intention":"知识问答",
        "reply":"不会，部署在您的数据中心服务器上的 Discovery Agent 不会向 AWS 授予远程访问权限。但是，Discovery Agent 需要建立出站 SSL 连接，以将收集到的数据传输到 AWS。"
    },
    {
        "query":"能否在我的 EC2 实例中运行代理？",
        "intention":"知识问答",
        "reply":"是。您可以在 EC2 实例上安装 Discovery Agent，以发现性能信息、网络连接和正在运行的进程并生成相关报告，就像您针对任何其他服务器执行这些操作一样。"
    },
    {
        "query":"“无代理”Application Discovery 是什么意思？",
        "intention":"知识问答",
        "reply":"“无代理”意味着无需在每个主机上安装软件即可使用 Application Discovery。只需将 Agentless Collector 作为 OVA 安装在 VMware vCenter 上。"
    },
    {
        "query":"Agentless Collector 可以捕获哪些数据？",
        "intention":"知识问答",
        "reply":"Agentless Collector 作为一个开放虚拟机 (OVA) 软件包交付，可部署到 VMware 主机上。收集的数据类型将取决于您配置的功能。如果提供了连接到 vCenter 的凭证，则 Agentless Collector 将收集虚拟机清单、配置，以及 CPU、内存和磁盘使用情况等性能历史数据。如果提供连接到 Oracle、SQL Server、MySQL 或 PostgreSQL 等数据库的凭证，则 Agentless Collector 将收集版本、版本和架构数据。服务器和数据库信息将上传到 Application Discovery Service 数据存储。数据库信息可以发送到 AWS DMS Fleet Advisor 进行分析。"
    },
    {
        "query":"无代理发现支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"无代理发现不区分操作系统。无论客户使用什么 VM 操作系统，它都可以收集有关 VMware 虚拟机的信息。"
    },
    {
        "query":"如何在将数据传输到 AWS 的过程中保护数据？",
        "intention":"知识问答",
        "reply":"Agentless Collector 使用 HTTPS/TLS 将数据传输到 Application Discovery Service。"
    },
    {
        "query":"如何在我的数据中心中安装 Agentless Collector？",
        "intention":"知识问答",
        "reply":"请参阅该[文档](https://docs.aws.amazon.com/application-discovery/latest/userguide/agentless-collector.html)，了解有关如何安装 Agentless Collector 的详细信息。"
    },
    {
        "query":"如何开始收集数据？",
        "intention":"知识问答",
        "reply":"可通过本地 Agentless Collector UI 控制数据收集。您需要访问本地环境以开始或停止收集。"
    },
    {
        "query":"Agentless Collector 是否会向 AWS 授予对我的数据中心服务器的远程访问权限？",
        "intention":"知识问答",
        "reply":"不会，部署在您的 VMware 环境中的 Agentless Collector 不会向 AWS 授予对您的数据中心服务器的远程访问权限。但是，该工具需要使用 VMware 凭证才能收集数据。这些凭证保存在本地，绝不会与 AWS 共享。Agentless Collector 会建立出站 SSL 连接，以仅传输其收集到的数据。"
    },
    {
        "query":"能否在我的 EC2 实例中运行无代理发现？",
        "intention":"知识问答",
        "reply":"不能。Agentless Collector 安装在 VMware 上，仅收集来自 VMware vCenter 的信息。"
    },
    {
        "query":"Application Discovery Service 会捕获哪些类型的信息？",
        "intention":"知识问答",
        "reply":"Application Discovery Service 旨在捕获各种数据，其中包括静态配置，例如服务器主机名、IP 地址、MAC 地址、CPU 分配、网络吞吐量、内存分配、磁盘资源分配和 DNS 服务器的相关数据。它还可以捕获资源利用率指标，例如 CPU 使用率和内存使用率。Application Discovery Service 提供两个收集器。除上述信息外，Discovery Agent 还可以通过收集活跃的传输控制协议 (TCP) 连接和进程信息来帮助识别服务器工作负载。此外，Agentless Collector 还可以发现数据库的引擎、版本和版本信息。"
    },
    {
        "query":"该服务是否会捕获任何存储指标？",
        "intention":"知识问答",
        "reply":"是，该服务会捕获磁盘指标，例如读取和写入量、吞吐量、分配的/预置的和已使用的容量。"
    },
    {
        "query":"Application Discovery Service 中的信息多久更新一次？",
        "intention":"知识问答",
        "reply":"该服务只在 Discovery Agent 或 Agentless Collector 在线时收集信息。"
    },
    {
        "query":"能否将数据从现有的配置管理数据库（CMDB）导入 Application Discovery Service？",
        "intention":"知识问答",
        "reply":"是，您可以将有关本地服务器和应用程序的信息导入到 Migration Hub 之中，以便您可以跟踪应用程序迁移的状态。要导入数据，您可以下载并填充 CSV 导入模板，然后使用 Migration Hub 导入控制台或通过调用 Application Discovery Service API 进行上传。"
    },
    {
        "query":"如何访问该服务的数据？",
        "intention":"知识问答",
        "reply":"您可以在 AWS 管理控制台中查看摘要数据。您可以使用 AWS 管理控制台或公有 API 导出 Application Discovery Service 收集到的详细数据。该服务支持以 CSV 格式导出数据。"
    },
    {
        "query":"什么是数据探查功能？",
        "intention":"知识问答",
        "reply":"利用数据探查功能，客户能够从一个地方分析 Application Discovery Service 代理从本地服务器收集的数据。一旦客户启用此功能，代理收集的数据将自动存储至客户账户中创建的 Amazon S3 存储桶。客户可以在 Amazon Athena 中查询所收集的数据，然后在 Amazon QuickSight 中显示查询输出以执行迁移计划。"
    },
    {
        "query":"在启用数据探查功能的 Amazon Athena 中，我能看到什么？",
        "intention":"知识问答",
        "reply":"进入启用数据探查功能的 Amazon Athena 后，您会看到一个称为“application\\_discovery\\_service\\_database”的数据库。在此数据库中，默认为您创建了一列表格。这些表格包括："
    },
    {
        "query":"能否只为部分代理启用数据探查功能？",
        "intention":"知识问答",
        "reply":"否，数据探查功能是针对所有代理的全局设置。全局设置旨在确保所有代理收集的数据是同一时间段的。"
    },
    {
        "query":"使用此功能是否需要创建一个特殊 S3 存储桶？",
        "intention":"知识问答",
        "reply":"否，您不需要自行创建 S3 存储桶。当您初次启用此功能时，系统会自动为您创建一个名为“aws-application-discovery-service-”的 S3 存储桶。默认情况下，此存储桶以及存储至该存储桶中的发现数据都是保密的。只有您账户中具有 Application Discovery Service 和 Migration Hub 访问权限的用户才能访问该存储桶及其中的数据。"
    },
    {
        "query":"在 S3 存储桶中存储发现数据安全吗？",
        "intention":"知识问答",
        "reply":"是的，在经过专门设计的 S3 存储桶中存储的数据都使用[客户主密钥](https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys)加密。您还可以组合使用[存储桶 ACL](https://docs.aws.amazon.com/AmazonS3/latest/dev/acl-overview.html) 和 [IAM 及存储桶策略](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html)来进一步控制对 S3 资源的访问。\n了解有关 AWS Application Discovery Service 定价的更多信息"
    },
    {
        "query":"什么是 AWS Direct Connect",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 是一种联网服务，提供了通过互联网连接到 AWS 的替代方案。使用 AWS Direct Connect ，以前通过 Internet 传输的数据将可以借助您的设施和 AWS 之间的私有网络连接进行传输。在许多情况下，私有网络连接可以降低成本、增加带宽，提供比基于 internet 的连接更为一致的网络体验。所有 AWS 服务都可与 AWS Direct Connect 结合使用，包括 Amazon Elastic Compute Cloud (EC2)、Amazon Virtual Private Cloud (VPC)、Amazon Simple Storage Service (S3) 和 Amazon DynamoDB。"
    },
    {
        "query":"AWS Direct Connect 可在何处使用？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 站点的完整列表详见 AWS Direct Connect [站点](https://aws.amazon.com/cn/directconnect/locations/)页面。使用 AWS Direct Connect 时，您可以连接到在任何 AWS 区域和可用区中部署的 VPC。您还可以连接到 AWS Local Zones。"
    },
    {
        "query":"专用连接和托管连接之间有哪些区别？",
        "intention":"知识问答",
        "reply":"专用连接通过单个客户专用的 1 Gbps、10 Gbps 或 100 Gbps 以太网端口提供。托管连接来自其自身和 AWS 之间具有网络链路的 AWS Direct Connect 合作伙伴。"
    },
    {
        "query":"如何开始使用 AWS Direct Connect？",
        "intention":"知识问答",
        "reply":"使用 AWS 管理控制台中的 [AWS Direct Connect 选项卡](https://console.aws.amazon.com/directconnect/v2/home)，新建一个连接。请求连接时，系统将提示您选择 AWS Direct Connect 站点、端口数量和端口速度。如果需要有关将办公室或数据中心网络扩展到 AWS Direct Connect 站点的帮助，您可以联系 [Direct Connect 合作伙伴](https://aws.amazon.com/cn/directconnect/partners/)。"
    },
    {
        "query":"如果我的网络不在 AWS Direct Connect 站点中，是否可以使用 AWS Direct Connect？",
        "intention":"知识问答",
        "reply":"是。AWS Direct Connect 合作伙伴可以帮助您将先前存在的数据中心或办公室网络扩展到 AWS Direct Connect 站点。有关更多信息，请参阅 [AWS Direct Connect 合作伙伴](https://aws.amazon.com/cn/directconnect/partners/)。 利用 AWS Direct Connect 网关，您可以从任何 AWS Direct Connect 站点（中国除外）访问任何 AWS 区域。"
    },
    {
        "query":"在将我的本地站点连接到 AWS 时，AWS 是否扮演我的“第一英里”或“最后一英里”的角色？",
        "intention":"知识问答",
        "reply":"否，您需要在本地站点所使用的本地服务提供商之间进行连接，或者与 AWS Direct Connect 交付合作伙伴合作，以连接到 AWS Direct Connect 站点。"
    },
    {
        "query":"如何在 AWS Direct Connect 站点请求交叉连接？",
        "intention":"知识问答",
        "reply":"下载授权书和连接设施分配 (LOA-CFA) 后，必须完成交叉网络连接。如果您的设备已经位于 AWS Direct Connect 站点，请联系相应的提供商完成交叉连接。有关每个提供商和交叉连接定价的具体说明，请参阅 AWS Direct Connect 文档：在 [AWS Direct Connect 站点](https://aws.amazon.com/directconnect/locations/)[请求交叉连接](https://docs.aws.amazon.com/directconnect/latest/UserGuide/Colocation.html)。"
    },
    {
        "query":"什么是 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 网关是虚拟私有网关 (VGW) 和私有虚拟接口 (VIF) 的组合。AWS Direct Connect 网关是全球可用的资源。您可以在任何区域中创建 AWS Direct Connect 网关，并从所有其他区域进行访问。"
    },
    {
        "query":"什么是虚拟接口 (VIF)？",
        "intention":"知识问答",
        "reply":"虚拟接口 (VIF) 是访问 AWS 服务的必要条件，它可以是公有，也可以是私有。公有虚拟接口支持访问公有服务，如 Amazon S3。私有虚拟接口支持访问 VPC。有关更多信息，请参阅 [AWS Direct Connect 虚拟接口](https://docs.aws.amazon.com/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html)。"
    },
    {
        "query":"什么是虚拟私有网关 (VGW)？",
        "intention":"知识问答",
        "reply":"虚拟私有网关 (VGW) 是 VPC 的一部分，可为 AWS 托管的 VPN 连接和 AWS Direct Connect 连接提供边缘路由。您可以将 AWS Direct Connect 网关与 VPC 的虚拟私有网关关联。有关更多详细信息，请参阅本[文档](https://docs.aws.amazon.com/directconnect/latest/UserGuide/virtualgateways.html)。"
    },
    {
        "query":"什么是链路汇聚组 (LAG)？",
        "intention":"知识问答",
        "reply":"链路汇聚组 (LAG) 是一种逻辑接口，使用链路汇聚控制协议 (LACP) 在单个 AWS Direct Connect 终端节点汇聚多个专用连接，允许您将其视为单个托管连接。LAG 之所以能够简化配置，原因在于 LAG 配置适用于组中的所有连接。有关创建、更新、关联/解除关联和删除 LAG 的详细信息，请参阅 AWS Direct Connect 文档：[链路汇聚组 - AWS Direct Connect](https://docs.aws.amazon.com/directconnect/latest/UserGuide/lags.html)。"
    },
    {
        "query":"什么是 AWS Direct Connect 弹性工具包？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 弹性工具包提供了一种连接向导，可帮助您在多个弹性模式之间进行选择。这些模式可帮助您确定专用连接的数量，然后下订单，以实现 SLA 目标。选择一个弹性模式，然后 AWS Direct Connect 弹性工具包将引导您完成专用连接订购过程。弹性模式旨在确保您能够在多个站点拥有适当数量的专用连接。"
    },
    {
        "query":"什么是 AWS Direct Connect 失效转移测试功能？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 故障转移测试功能让您可以通过禁用本地网络和 AWS 之间的边界网关协议会话来测试您的 AWS Direct Connect 连接的弹性。您可以使用 AWS 管理控制台或 AWS Direct Connect 应用程序编程接口 (API)。要详细了解此功能，请参阅本[文档](https://docs.aws.amazon.com/directconnect/latest/UserGuide/resilency_failover.html)。所有商用 AWS 区域（GovCloud (US) 除外）都支持这一功能。"
    },
    {
        "query":"什么是针对私有虚拟接口 (VIF) 的本地优先团体？",
        "intention":"知识问答",
        "reply":"私有和中转虚拟接口的站点首选项社区提供了一项功能，可以让您影响源自 VPC 的流量的退回路径。"
    },
    {
        "query":"什么是针对私有和中转虚拟接口 (VIF) 的本地优先团体？",
        "intention":"知识问答",
        "reply":"私有和中转虚拟接口的站点首选项社区为您提供了一项功能，可以让您影响源自 VPC 的流量的退回路径。"
    },
    {
        "query":"什么是 AWS Direct Connect 网关 – 自带私有 ASN？",
        "intention":"知识问答",
        "reply":"借助可配置的私有自治系统编号 (ASN)，您可以在边界网关协议 (BGP) 会话的 AWS 端为任何新创建的 AWS Direct Connect 网关上的私有或中转 VIF 设置 ASN。所有商用 AWS 区域（AWS 中国区域除外）和 AWS GovCloud（美国）区域都提供这一功能。"
    },
    {
        "query":"什么是中转虚拟接口？",
        "intention":"知识问答",
        "reply":"中转虚拟接口指的是可以通过任何 AWS Direct Connect 连接创建的一种虚拟接口。中转虚拟接口只能附加到 AWS Direct Connect 网关。您可以使用附加了一个或多个中转虚拟接口的 AWS Direct Connect 网关来在任何支持的 AWS 区域中最多与三个 AWS Transit Gateway 交互。与私有虚拟接口类似，您可以通过单个中转虚拟接口建立一个 IPv4 BGP 会话和一个 IPv6 BGP 会话。"
    },
    {
        "query":"什么是 AWS Direct Connect 网关的多账户支持？",
        "intention":"知识问答",
        "reply":"提供 AWS Direct Connect 网关的多账户支持功能，您可以将来自多个 AWS 账户的最多 10 个 Amazon Virtual Private Cloud (Amazon VPC) 或三个 AWS Transit Gateway 关联到一个 AWS Direct Connect 网关。"
    },
    {
        "query":"什么是 MACsec？",
        "intention":"知识问答",
        "reply":"802.1AE MAC 安全性 (MACsec) 是一项 [IEEE 标准](https://1.ieee802.org/security/802-1ae/)，用于确保数据保密性、数据完整性和数据源真实性。您可以使用支持 MACsec 的 AWS Direct Connect 连接对从本地网络或托管设备到所选 AWS Direct Connect 存在点的数据进行加密。"
    },
    {
        "query":"什么是 AWS Direct Connect SiteLink？",
        "intention":"知识问答",
        "reply":"当在两个或更多 AWS Direct Connect 站点启用 AWS Direct Connect SiteLink 功能时，您可以在这些站点之间发送数据，而绕过 AWS 区域。AWS Direct Connect SiteLink 兼容托管和专用连接。"
    },
    {
        "query":"在将我的本地站点连接到 AWS 时，AWS 是否扮演我的“第一英里”或“最后一英里”的角色？",
        "intention":"知识问答",
        "reply":"否，您需要在您的本地站点所使用的本地服务提供商之间进行连接，以连接到 AWS。"
    },
    {
        "query":"拥有链路汇聚组 (LAG) 能否提高我的连接的弹性？",
        "intention":"知识问答",
        "reply":"不能，LAG 并不能提高您的 AWS 连接的弹性。如果您的 LAG 中包含多个链路，并将最少链路数设置为 1 时，您的 LAG 可使您不会发生单链路故障。但是，当 LAG 终止时，它不能防止在 AWS 中出现单一设备故障。\n为确保 AWS 连接的高度可用，我们建议您在多个 AWS Direct Connect 站点上建立连接。您可以参阅 [AWS Direct Connect 弹性建议](https://aws.amazon.com/cn/directconnect/resiliency-recommendation/)，详细了解如何实现高度可用的网络连接。"
    },
    {
        "query":"如何订购 AWS Direct Connect 连接以获得高可用性？",
        "intention":"知识问答",
        "reply":"我们建议按照 [AWS Direct Connect 弹性建议](https://aws.amazon.com/cn/directconnect/resiliency-recommendation/)页面详细介绍的弹性最佳实践，来确定适合您的使用场景的最佳弹性模式。选择弹性模型后，[AWS Direct Connect 弹性工具包](https://docs.aws.amazon.com/directconnect/latest/UserGuide/resiliency_toolkit.html)将指导您完成订购冗余连接的过程。此外，AWS 还鼓励您在投入使用之前，使用弹性工具包故障转移测试功能测试您的配置。\n每个专用的 AWS Direct Connect 连接由您的路由器端口和 AWS Direct Connect 设备端口之间的一个专用连接组成。我们建议您建立第二个连接来实现冗余。如果您在同一个 AWS Direct Connect 站点请求多个端口，它们将被预置在冗余的 AWS 路由器上。\n如果您配置了备用 IPsec VPN 连接，则所有的 VPC 流量将自动故障转移到该 VPN 连接。传入/传出 Amazon S3 等公有资源的流量将通过互联网路由。如果您没有备用的 AWS Direct Connect 链路或 IPsec VPN 链路，则出现故障时会丢失 Amazon VPC 流量。传入/传出公有资源的流量将通过互联网路由。"
    },
    {
        "query":"AWS Direct Connect 是否提供服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"是，AWS Direct Connect 提供 SLA。[详细信息请参阅此处](https://aws.amazon.com/cn/directconnect/sla/)。"
    },
    {
        "query":"使用故障转移测试功能时，是否可以配置测试持续时间或在运行时取消测试？",
        "intention":"知识问答",
        "reply":"是，您可以配置测试的持续时间。您可以将测试的最短和最长持续时间分别设为 1 分钟和 180 分钟。  您可以在运行测试过程中取消测试。取消测试时，我们将会恢复边界网关协议会话，并在您的测试历史记录中记录测试已取消。"
    },
    {
        "query":"在使用故障转移测试功能时，是否可以查看我过去的测试历史记录？ 测试历史记录会保留多长时间？",
        "intention":"知识问答",
        "reply":"可以，您可以通过 AWS 管理控制台或 AWS CloudTrail 查看测试历史记录。我们会将测试历史记录保留 365 天。如果删除虚拟接口，测试历史记录也将会删除。"
    },
    {
        "query":"故障转移测试完成之后将会出现什么情况？",
        "intention":"知识问答",
        "reply":"在配置测试持续时间以后，我们将使用测试启动前协商的边界网关协议会话参数，恢复本地网络和 AWS 之间的边界网关协议会话。"
    },
    {
        "query":"谁可以使用 AWS Direct Connect 弹性工具包启动故障转移测试？",
        "intention":"知识问答",
        "reply":"只有包含虚拟接口的 AWS 账户的拥有者可以启动测试。"
    },
    {
        "query":"我可以在虚拟接口的故障转移测试进行过程中删除该虚拟接口吗？",
        "intention":"知识问答",
        "reply":"可以，您可以在虚拟接口测试进行过程中删除该虚拟接口。"
    },
    {
        "query":"我可以为任何类型的虚拟接口运行故障转移测试吗？",
        "intention":"知识问答",
        "reply":"可以，您可以对使用任何类型的虚拟接口建立的边界网关协议会话运行测试。"
    },
    {
        "query":"如果我建立了 IPv4 和 IPv6 边界网关协议会话，可以为每个边界网关协议会话执行此测试吗？",
        "intention":"知识问答",
        "reply":"可以，您可以为其中一个边界网关协议会话或者同时为这两个会话启动测试。\n问：我需要新的 AWS Direct Connect 连接以使用 AWS Direct Connect SiteLink 吗，以及它们需要是相同类型的吗？\n您可以搭配使用 AWS Direct Connect SiteLink 和您的现有 AWS Direct Connect 连接。它与任何类型的 AWS Direct Connect 连接兼容（专用或托管）。"
    },
    {
        "query":"我要在哪里以及如何配置 AWS Direct Connect SiteLink？",
        "intention":"知识问答",
        "reply":"您要在配置虚拟接口 (VIF) 时启用和禁用 AWS Direct Connect SiteLink。要使用 AWS Direct Connect SiteLink 建立连接，您必须在两个或更多 AWS Direct Connect 站点的两个或更多 VIF 上启用 AWS Direct Connect SiteLink。您必须将全部站点附加到相同的 AWS Direct Connect 网关。您可以使用 AWS 管理控制台、AWS 命令行界面或 API 配置您的 VIF，以启用或禁用 AWS Direct Connect SiteLink。AWS Direct Connect SiteLink 与 AWS CloudWatch 集成，因此您可以监控通过此链路发送的流量。"
    },
    {
        "query":"AWS Direct Connect SiteLink 是否需要 AWS Direct Connect 网关连接？",
        "intention":"知识问答",
        "reply":"是。要使用 AWS Direct Connect SiteLink，您必须将启用 AWS Direct Connect SiteLink 的虚拟接口 (VIF) 连接到 AWS Direct Connect 网关。VIF 类型可以是私有或中转的。"
    },
    {
        "query":"我要如何知道自己要为 AWS Direct Connect SiteLink 的哪些服务付费？",
        "intention":"知识问答",
        "reply":"在账单中，与 AWS Direct Connect SiteLink 有关的费用将在有别于其他 AWS Direct Connect 相关费用的独立行上显示。"
    },
    {
        "query":"简单的 AWS Direct Connect SiteLink 双站点网络架构看起来是什么样子的？",
        "intention":"知识问答",
        "reply":"要构建简单的网络，请配置私有虚拟接口 (VIF)，并在每个站点的该 VIF 上启用 AWS Direct Connect SiteLink。然后创建 AWS Direct Connect 网关，将其关联到每个已启用 AWS Direct Connect SiteLink 的 VIF，以便创建一个网络。"
    },
    {
        "query":"我要如何使用 AWS Direct Connect SiteLink 实现辐射状架构？",
        "intention":"知识问答",
        "reply":"要创建辐射状架构，请创建 AWS Direct Connect 网关，并将其关联到全部已启用 AWS Direct Connect SiteLink 的私有 VIF。"
    },
    {
        "query":"我要如何使用 AWS Direct Connect SiteLink 创建分段网络架构？",
        "intention":"知识问答",
        "reply":"启动多个 AWS Direct Connect 网关，将每个关联到已启用 AWS Direct Connect SiteLink 的私有接口 (VIF) 子集。某个 AWS Direct Connect 网关上已启用 AWS Direct Connect SiteLink 的 VIF 无法和另一个 AWS Direct Connect 上已启用 AWS Direct Connect SiteLink 的 VIF 通信，从而形成一个分段网络。"
    },
    {
        "query":"AWS Direct Connect SiteLink 支持哪些类型的虚拟接口 (VIF)？",
        "intention":"知识问答",
        "reply":"私有和中转 VIF 均支持 AWS Direct Connect SiteLink。不过，当 AWS Direct Connect 网关之前和虚拟私有网关关联，或者被附加到私有虚拟接口时，您无法附加 AWS Direct Connect 网关 (DXGW) 到 AWS Transit Gateway。"
    },
    {
        "query":"AWS Direct Connect SiteLink 是否需要 BGP？",
        "intention":"知识问答",
        "reply":"是。AWS Direct Connect SiteLink 需要 BGP。"
    },
    {
        "query":"AWS Direct Connect SiteLink 是否支持 IPv6？",
        "intention":"知识问答",
        "reply":"是。AWS Direct Connect SiteLink 支持 IPv6。"
    },
    {
        "query":"AWS Direct Connect SiteLink 是否支持 MACsec？",
        "intention":"知识问答",
        "reply":"是。只要端口和 PoP 站点支持 MACsec 加密，那么 AWS Direct Connect SiteLink 就支持 MACsec。"
    },
    {
        "query":"已启用 AWS Direct Connect SiteLink 的虚拟接口 (VIF) 支持服务质量 (QoS) 吗？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 不提供托管式 QoS 功能。当您在通过 AWS Direct Connect SiteLink 连接的设备上配置 QoS，DSCP 标记将在转发流量上保留。"
    },
    {
        "query":"AWS Direct Connect SiteLink 是否支持本地首选项 BGP 社区？",
        "intention":"知识问答",
        "reply":"是。您可以搭配使用现有的 AWS Direct Connect 本地首选项标签和 AWS Direct Connect SiteLink。支持以下本地首选项 BGP 社区标签：  \n 7224:7100 - 低首选项  \n 7224:7200 - 中首选项  \n 7224:7300 - 高首选项"
    },
    {
        "query":"我应该在何时使用 AWS Direct Connect SiteLink 以及在何时使用 AWS 云 WAN？",
        "intention":"知识问答",
        "reply":"根据使用场景，您可能会使用其中一种，或同时使用两种。[Cloud WAN](https://aws.amazon.com/cn/cloud-wan/) 目前提供预览版，可以跨多个区域创建与管理 VPC 网络。另一方面，AWS Direct Connect SiteLink 会将 DX 站点连接在一起，绕过 AWS 区域以提高性能。AWS Direct Connect 是未来您将可以与 Cloud WAN 网络搭配使用的多种连接选项之一。"
    },
    {
        "query":"我可以使用 AWS Direct Connect 来连接在 AWS Local Zones 中运行的资源吗？",
        "intention":"知识问答",
        "reply":"可以，当使用 AWS Direct Connect 时，您可以连接到部署在 AWS Local Zones 中的 VPC。您的数据将通过 AWS Direct Connect 连接直接传送到 AWS Local Zones 以及从其中传出，而不会遍历整个 AWS 区域。这将会提高性能并且可以缩短延迟。"
    },
    {
        "query":"如何配置 AWS Local Zones 以便搭配使用 AWS Direct Connect？",
        "intention":"知识问答",
        "reply":"不管是链接到 AWS Local Zones 还是连接到某个区域的 AWS Direct Connect，它们都以相同的方式运行。\n要连接到某个区域，首先您要创建新的子网并将其分配到 AWS 本地扩展区，以便将您的 VPC 从父级区域扩展到 AWS Local Zones。（有关此流程的详细信息，请见我们的文档中的[使用 Local Zones、Wavelength 区域和 AWS Outposts 将 VPC 扩展到其他位置](https://docs.aws.amazon.com/vpc/latest/userguide/Extend_VPCs.html)页面。） 然后，将您的 Virtual Gateway（VGW）关联到 AWS Direct Connect 私有虚拟接口，或 AWS Direct Connect 网关，以进行连接。（如需了解详情，请见我们的文档中的[虚拟私有网关关联](https://docs.aws.amazon.com/directconnect/latest/UserGuide/virtualgateways.html)条目。）\n您还可以通过互联网网关（IGW）连接到采用 AWS Direct Connect 公有虚拟接口的 AWS Local Zones。"
    },
    {
        "query":"AWS Direct Connect 连接到 AWS 本地扩展区的方式和连接到某个区域相比有什么不同吗？",
        "intention":"知识问答",
        "reply":"是的，它们之间存在差异。AWS Local Zones 尚不支持 AWS Transit Gateway。如果通过 AWS Transit Gateway 连接到 AWS 本地扩展区子网，您的流量会传入父级区域，由您的 AWS Transit Gateway 进行处理并被发送到 AWS 本地扩展区，然后从该区域（或发夹弯道）返回。接着，入口路由目标位置不会直接路由到 AWS Local Zones。流量将首先传入父级区域，然后回连到您的 AWS Local Zones。再接下来，有别于最大 MTU 大小为 9001 的区域，连接到 Local Zones 的数据包的最大 MTU 大小是 1468。此时支持并建议使用路径 MTU 发现。最后，与区域的 5 Gbps 相比，连接到 AWS 本地扩展区的单个流的限制（5 个元组）在 MTU 达到最大时（1468）大约为 2.5 Gbps。注：MTU 大小和单个流的限制不适用于 AWS Direct Connect 连接到位于洛杉矶的 AWS 本地扩展区的情况。"
    },
    {
        "query":"我可以使用 AWS Site-to-Site VPN 备份链接到 AWS 本地扩展区的 AWS Direct Connect 吗？",
        "intention":"知识问答",
        "reply":"不可以。与连接到某个区域不同，您不能使用 AWS Site-to-Site VPN 备份与 AWS 本地扩展区的 AWS Direct Connect 连接。对于冗余，您必须使用两个或更多 AWS Direct Connect 连接。"
    },
    {
        "query":"我可以使用当前的 AWS Direct Connect 网关（DXGW）来关联 Virtual Gateway（VGW）吗？",
        "intention":"知识问答",
        "reply":"可以，只要当前的 AWS Direct Connect 网关未与 AWS Transit Gateway 关联。因为 AWS Local Zones 不支持 AWS Transit Gateway，而且与 AWS Transit Gateway 关联的 DXGW 无法与 VGW 关联，因此您不能将 DXGW 关联到 AWS Transit Gateway。您必须创建新的 DXGW 并将它和 VGW 关联。"
    },
    {
        "query":"是否可以将同一私有网络连接同时用于 Amazon Virtual Private Cloud (VPC) 和其他 AWS 服务？",
        "intention":"知识问答",
        "reply":"是。每个 AWS Direct Connect 连接都可以配置一个或多个虚拟接口。虚拟接口可以配置为访问 Amazon EC2 和 Amazon S3 等使用公有 IP 空间的 AWS 产品，或配置为访问使用私有 IP 空间的 VPC 中的资源。"
    },
    {
        "query":"如果我在使用 Amazon CloudFront，并且我的源服务器是自有数据中心，是否可以使用 AWS Direct Connect 传输自有数据中心中存储的对象？",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 支持自定义源服务器，包括您在 AWS 外部运行的源服务器。对 CloudFront 边缘站点的访问将被限制在地理位置最接近的 AWS 区域，但位于北美的 AWS 区域除外，这些区域目前允许对所有北美区域的联网 CloudFront 源的访问。您可以在 AWS Direct Connect 连接上使用公有虚拟接口访问它。使用 AWS Direct Connect 时，您将按照 AWS Direct Connect 数据传输费率支付原始服务器数据传输费。\n通过 Direct Connect 站点进入 AWS 全球网络后，您的流量仍然位于 Amazon 骨干网络内。属于不在 Amazon 骨干网络内的 CloudFront 站点的前缀将不会通过 Direct Connect 公布。 您可以在[此处](https://docs.aws.amazon.com/directconnect/latest/UserGuide/routing-and-bgp.html)找到有关已公布的 IP 前缀和 Direct Connect 路由策略的更多详细信息。"
    },
    {
        "query":"可以在 AWS 管理控制台中订购 AWS GovCloud（美国）端口吗？",
        "intention":"知识问答",
        "reply":"要订购连接到 AWS GovCloud（美国）的端口，必须使用 AWS GovCloud（美国）管理控制台。"
    },
    {
        "query":"AWS Global Accelerator (AGA) 公共端点前缀是否通过 Direct Connect 公有虚拟接口从 AWS 公布到现场？",
        "intention":"知识问答",
        "reply":"是。Direct Connect 公有虚拟接口会公布 AGA 公共端点使用的 AnyCast 前缀。"
    },
    {
        "query":"一个 LAG 组中最多可以拥有几条链路？",
        "intention":"知识问答",
        "reply":"一个 LAG 组中最多可以拥有 4 条链路。"
    },
    {
        "query":"链路汇聚组（LAG）是处于主动/主动还是主动/被动模式？",
        "intention":"知识问答",
        "reply":"它们处于主动/主动模式。换句话说，AWS 端口会持续发送链路汇聚控制协议数据单元 (LACPDU)。"
    },
    {
        "query":"LAG 的最大传输单位可以改变吗？",
        "intention":"知识问答",
        "reply":"LAG 的最大传输单位可被变更。要了解详情，请参阅[此处](https://docs.aws.amazon.com/directconnect/latest/UserGuide/set-jumbo-frames-vif.html)的巨型帧文档。"
    },
    {
        "query":"是否可以将我的端口配置为主动/被动模式，而不是主动/主动模式？",
        "intention":"知识问答",
        "reply":"终端节点处的 LAG 可以配置为 LACP 主动或被动模式。AWS 侧始终配置为主动模式 LACP。"
    },
    {
        "query":"是否可以在同一 LAG 中混合使用接口类型，配置一些 1 G 端口和一些 10 G 端口？",
        "intention":"知识问答",
        "reply":"否，您可以使用同一类型的端口（1 G 或 10 G）创建 LAG。"
    },
    {
        "query":"它适用于哪些类型的端口？",
        "intention":"知识问答",
        "reply":"它适用于 1 G、10 G 和 100 G 的专用连接端口。"
    },
    {
        "query":"是否可以将此项功能用于 LAG 托管连接？",
        "intention":"知识问答",
        "reply":"否。此项功能仅适用于 1 G、10 G 和 100 G 的专用连接，而不适用于托管连接。"
    },
    {
        "query":"是否可以使用现有端口以外的其他端口创建 LAG？",
        "intention":"知识问答",
        "reply":"是，只要您的端口都在同一个 AWS Direct Connect 设备上。请注意，在您的端口重新配置为 LAG 的过程中，它们的运行速度将会下降。直到 LAG 在您所在的一端配置完毕后，它们的运行速度才会恢复正常。"
    },
    {
        "query":"是否可以创建一个跨越多个 AWS Direct Connect 设备的 LAG？",
        "intention":"知识问答",
        "reply":"LAG 将仅包含同一 AWS Direct Connect 设备上的端口。我们不支持多机架 LAG。"
    },
    {
        "query":"在 LAG 设置完毕后，如何向其添加链路？",
        "intention":"知识问答",
        "reply":"您必须为 LAG 请求其他端口。如果同一设备中没有可用的端口，则必须订购新的 LAG 并迁移连接。例如，假设您有 3 条 1 G 的链路，并且希望增加一条，而该设备上没有可用端口，那么您需要订购一个拥有 4 条 1 G 链路的新 LAG。"
    },
    {
        "query":"您没有可用端口，因此我订购了新 LAG，但已经配置了虚拟接口 (VIF)。如何转移这些 VIF？",
        "intention":"知识问答",
        "reply":"您可以一次性将多个 VIF 附加到某个 VGW，还可以在连接上配置 VIF，即使该连接出现故障也是如此。建议您在新 LAG 上创建新的 VIF，并在创建好所有 VIF 后将连接转移到新 LAG。请务必删除旧的连接，以使我们停止计费。"
    },
    {
        "query":"是否可以删除 LAG 的某个端口？",
        "intention":"知识问答",
        "reply":"是，但前提是您设置的最少链路数必须低于剩余的端口数量。例如，假设您有 4 个端口，并将最少链路数设置为 4，那么您将不能删除该 LAG 中的端口。如果将最少链路数设置为 3，那么您就可以删除该 LAG 中的一个端口。我们将返回一条通知和一条提醒，前者将告知您已删除的特定面板/端口，后者将提醒您断开与 AWS 的交叉连接和线路。"
    },
    {
        "query":"是否可以一次性彻底删除我的 LAG？",
        "intention":"知识问答",
        "reply":"是，但与常规连接类似，如果您配置了 VIF，那么您就不能删除 LAG。\n问：如果我的 LAG 中只有 2 个端口，我是否仍然可以删除其中一个端口？\n是，LAG 中可以只有一个端口。"
    },
    {
        "query":"是否可以订购只有一个端口的 LAG？",
        "intention":"知识问答",
        "reply":"是。但请注意，如果未来您需要增加端口，我们将无法承诺会在同一机架上提供端口。"
    },
    {
        "query":"是否可以将一个 LAG 转换回各个端口？",
        "intention":"知识问答",
        "reply":"是。您可以通过 *DisassociateConnectionWithLag* API 调用来执行这一操作。"
    },
    {
        "query":"是否可以为我创建一款用于转移虚拟接口 (VIF) 的工具？",
        "intention":"知识问答",
        "reply":"您可以使用 *AssociateVirtualInterface* API 或控制台来执行这一操作。"
    },
    {
        "query":"LAG 会显示为单个连接还是一组连接？",
        "intention":"知识问答",
        "reply":"它将显示为单个 dxlag，我们将列出它下面的连接 ID。"
    },
    {
        "query":"最少链路数量是什么意思？在订购捆绑包时，为什么会看到最少链路数量复选框？",
        "intention":"知识问答",
        "reply":"最少链路数是 LACP 中的一项功能，您可以借助此功能设置捆绑包中需要处于活动状态的链路的最少数量，以使该捆绑包处于活动状态并能传输流量。例如，假设您有 4 个端口并将最少链路数设置为 3，但您只有 2 个处于活动状态的端口，那么您的捆绑包不会处于活动状态。如果您有 3 个或更多端口处于活动状态，并配置了 VIF，那么您的捆绑包将处于活动状态并能传输流量。\n如果您没有勾选“最少链路数”，则系统会默认将其设置为零。在设置好捆绑包后，您可以通过 AWS 管理控制台或 API 更改最少链路数的值。"
    },
    {
        "query":"将现有的 AWS Direct Connect 连接关联到 LAG 后，已经通过某个连接创建的现有虚拟接口 (VIF) 将会怎么样？",
        "intention":"知识问答",
        "reply":"将具有现有虚拟接口 (VIF) 的 AWS Direct Connect 连接关联到 LAG 后，这些虚拟接口会迁移到该 LAG 中。请注意，与 VIF 关联的某些参数（例如要迁移到 LAG 的 VLAN 编号）也必须唯一。"
    },
    {
        "query":"是否可以在某个特定链路上设置链路优先级？",
        "intention":"知识问答",
        "reply":"我们对所有链路一视同仁，因此不会在任何链路上设置“链路优先级”。"
    },
    {
        "query":"我所在的一端是否可以拥有一个连接至 AWS 一端的 4 个 10 GE 接口的 40 GE 接口？",
        "intention":"知识问答",
        "reply":"要做到这一点，您的路由器上需要有 4 个 10 GE 接口用于连接到 AWS。我们不支持将单个 40 GE 接口连接到具有 4 个 10 GE 接口的 LACP。"
    },
    {
        "query":"区域数据转移是否会按 AWS Direct Connect 费率计费？",
        "intention":"知识问答",
        "reply":"否，同一地区域不同可用区之间的数据传输将按照常规的区域数据转移费率计费，费用计入使用该服务的当月账单中。"
    },
    {
        "query":"决定托管连接的可计费端口小时数的因素有哪些？",
        "intention":"知识问答",
        "reply":"端口小时数将从您接受托管连接之时起计算。只要预置了托管连接以供您使用，都将持续产生端口费。如果您不希望继续支付托管连接费，请联系 AWS Direct Connect 合作伙伴取消托管连接。"
    },
    {
        "query":"托管连接的端口小时费采用什么形式？",
        "intention":"知识问答",
        "reply":"对于一个 AWS Direct Connect 站点的所有托管连接，端口小时费用均按容量分组。\n例如，假设一个客户在某个 AWS Direct Connect 站点有两个独立的 200 Mbps 托管连接，并且在该站点无其他托管连接，则这两个独立 200 Mbps 托管连接的端口小时费将使用以 “HCPortUsage:200M” 结尾的标签，汇总为一个项目。假设一个月总运行时间为 720 小时，则此项目的端口小时数为 1,440，也就是该月的总小时数乘以该站点的 200Mbps 托管连接总数。\n在您的账单中，可能显示如下托管连接容量标识符：\nHCPortUsage:50M  \n HCPortUsage:100M  \n HCPortUsage:200M  \n HCPortUsage:300M  \n HCPortUsage:400M  \n HCPortUsage:500M  \n HCPortUsage:1G  \n HCPortUsage:2G  \n HCPortUsage:5G  \n HCPortUsage:10G\n请注意，这些容量识别符将根据您在各个站点拥有的托管连接容量，按站点分别显示。"
    },
    {
        "query":"哪个 AWS 账户需要为在公有虚拟接口上执行的数据传出付费？",
        "intention":"知识问答",
        "reply":"对于可公开寻址的 AWS 资源（例如，Amazon S3 存储桶、Classic EC2 实例或通过互联网网关的 EC2 流量），如果出站流量的目的地是同一 AWS 付款人账户拥有的公有前缀，并通过 AWS Direct Connect 公有虚拟接口主动发布给 AWS，那么将按照 AWS Direct Connect 数据传输速率向资源拥有者计量数据传出 (DTO) 使用量。\n有关 AWS Direct Connect 定价的信息，请参阅 AWS Direct Connect [定价](https://aws.amazon.com/cn/directconnect/pricing/)页面。如果使用 AWS Direct Connect 合作伙伴来协助建立 AWS Direct Connect 连接，请联系 AWS Direct Connect 合作伙伴了解相关费用。\n问：通过中转/私有虚拟接口执行的数据传出需要向哪个 AWS 账户收费？\n随着精细数据传出分配功能的引入，负责数据传出的 AWS 账户将为通过中转/私有虚拟接口执行的数据传出付费。负责数据传出的 AWS 账户将根据客户对私有/中转虚拟接口的使用情况来确定，如下所示：\n私有虚拟接口用于与具有或不具有 AWS Direct Connect 网关的 Amazon Virtual Private Cloud 交互。对于私有虚拟接口，将由拥有对数据传出负责的 AWS 资源的 AWS 账户付费。\n中转虚拟接口用于与 AWS Transit Gateway 交互。对于中转虚拟接口，将由拥有与附加到该中转虚拟接口的 AWS Direct Connect 网关关联的 AWS Transit Gateway 附加的 Amazon Virtual Private Cloud 的 AWS 账户付费。请注意，所有适用的 AWS Transit Gateway 特定费用（数据处理和附件）都将在 Direct Connect 数据传出费用之外另行收取。\n问：AWS Direct Connect 如何与整合账单结合使用？\nAWS Direct Connect 数据传输使用量将汇总到您的管理账户中。\n问：如何取消 AWS Direct Connect 服务？\n您可以从 AWS 管理控制台删除端口，从而取消 AWS Direct Connect 服务。您还应取消通过第三方购买的所有服务。例如，您应联系主机托管提供商断开与 AWS Direct Connect 的所有交叉连接，以及/或者联系为您的远程站点与 AWS Direct Connect 站点之间提供网络连接的网络服务提供商。\n问：您的价格是否包括税费？\n除非另行说明，否则我们的价格不包括适用的税费和税收 (包括增值税和适用销售税)。使用日本账单地址的客户若要使用 AWS 服务，则需缴纳日本消费税。[了解更多。](https://aws.amazon.com/cn/c-tax-faqs/)"
    },
    {
        "query":"可使用哪些连接速度？",
        "intention":"知识问答",
        "reply":"对于专用连接，可以使用 1 Gbps、10 Gbps 和 100 Gbps 端口。对于托管连接，可以向经批准的 AWS Direct Connect 合作伙伴订购 50 Mbps、100 Mbps、200 Mbps、300 Mbps、400 Mbps、500 Mbps、1 Gbps、2 Gbps、5 Gbps 和 10 Gbps 的连接速度。有关更多信息，请参阅 [AWS Direct Connect 合作伙伴](https://aws.amazon.com/cn/directconnect/partners/)。"
    },
    {
        "query":"使用 AWS Direct Connect 时，数据传输量是否有限制？",
        "intention":"知识问答",
        "reply":"否。您可以传输任意数量的数据，最大传输量为您选用的端口容量。"
    },
    {
        "query":"使用 AWS Direct Connect 时，向 AWS 公布的路由数量是否有限制？",
        "intention":"知识问答",
        "reply":"是，使用 AWS Direct Connect 时，每个边界网关协议会话最多可公布 100 个路由。[了解 AWS Direct Connect 限制的更多信息](https://docs.aws.amazon.com/directconnect/latest/UserGuide/limits.html)。"
    },
    {
        "query":"如果针对一个边界网关协议会话，我公布了超过 100 个路由，会发生什么？",
        "intention":"知识问答",
        "reply":"如果针对一个边界网关协议会话，您公布了超过 100 个路由，则您的边界网关协议会话将关闭。如此一来，将会阻止所有网络流量流经虚拟接口，直至您将路由数量降至 100 以下。"
    },
    {
        "query":"连接有什么技术要求？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 支持在使用以太网传输的单模光纤上进行 1000BASE-LX、10GBASE-LR 或 100GBASE-LR4 连接。您的设备必须支持 802.1Q VLAN。有关详细的要求信息，请参阅 [AWS Direct Connect 用户指南](https://docs.aws.amazon.com/directconnect/latest/UserGuide/Welcome.html)。"
    },
    {
        "query":"能否通过 AWS Direct Connect 将我的一个 VLAN 扩展到 AWS 云？",
        "intention":"知识问答",
        "reply":"不能。在 AWS Direct Connect 中，VLAN 仅用于在虚拟接口之间分隔流量。"
    },
    {
        "query":"应向虚拟接口的两端指定什么 IP 地址？",
        "intention":"知识问答",
        "reply":"如果要连接公有 AWS 云的虚拟接口，则必须从您所拥有的公有 IP 空间向该连接的两端分配 IP 地址。如果该虚拟接口将连接到某个 VPC，且您选择让 AWS 自动生成对等 IP CIDR，则该连接两端的 IP 地址空间将由 AWS 分配，其范围为 169.254.0.0/16。"
    },
    {
        "query":"能否将我的硬件部署在支持 AWS Direct Connect 的设备附近？",
        "intention":"知识问答",
        "reply":"您可以购买 AWS Direct Connect 站点所在场址中的机架空间，并在附近部署您的设备。但是，出于安全考虑，您的设备不能放置在 AWS Direct Connect 机架或机笼区域内。有关更多信息，请联系负责相关设施的运营方。部署后，您可以通过交叉连接将此设备连接到 AWS Direct Connect。"
    },
    {
        "query":"如何为 AWS Direct Connect 连接启用 BFD？",
        "intention":"知识问答",
        "reply":"AWS 会为每个 AWS Direct Connect 虚拟接口自动启用异步 BFD，但要等到在您的路由器上对其进行配置之后才会生效。AWS 已将 BFD 连线检测最小间隔设置为 300，并将 BFD 连线检测乘数设置为 3。"
    },
    {
        "query":"如何为 AWS GovCloud（美国）区域设置 AWS Direct Connect？",
        "intention":"知识问答",
        "reply":"有关如何设置 AWS Direct Connect 以在 [AWS GovCloud（美国）区域](https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-dc.html)使用的详细说明，请参阅 AWS GovCloud（美国）用户指南。"
    },
    {
        "query":"虚拟接口 (VIF) 连接 VPC 有什么技术要求？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 需要使用边界网关协议 (BGP)。要完成连接，您需要具备下列信息：\n• 公有或私有 ASN。如果使用公有 ASN，您必须具有其所有权。如果使用私有 ASN，它必须在 64512 至 65535 的范围内。  \n • 您所选用的未使用的新 VLAN 标签。  \n • VPC 虚拟私有网关 (VGW) ID  \n • AWS 将在 169.x.x.x 范围内为 BGP 会话分配私有 IP (/30)，并将通过 BGP 公布 VPC CIDR 数据块。您可以通过 BGP 公布默认路由。"
    },
    {
        "query":"能否在 VPC 和我的网络之间建立 Layer 2 连接？",
        "intention":"知识问答",
        "reply":"不能。Layer 2 连接不受支持。"
    },
    {
        "query":"AWS Direct Connect 与 IPsec VPN 连接有什么区别？",
        "intention":"知识问答",
        "reply":"VPC VPN 连接通过公共互联网，利用 IPsec 在您的内网与 Amazon VPC 之间建立加密网络连接。VPN 连接可在几分钟内完成配置。如果您急需连接、带宽要求不高且可以承受互联网连接固有的易变性，则这种连接是不错的解决方案。相反，AWS Direct Connect 不涉及互联网；它在您的网络和 AWS 之间使用专用的私有网络连接。"
    },
    {
        "query":"是否可以同时使用 AWS Direct Connect 和 VPN 连接与同一 VPC 连接？",
        "intention":"知识问答",
        "reply":"是，但仅限用于故障转移。AWS Direct Connect 路径一旦建立，就始终是首选路径，且与追加的 AS 路径无关。请确保您的 VPN 连接能够处理来自 AWS Direct Connect 的故障转移流量。"
    },
    {
        "query":"为 AWS Direct Connect 列出的 BGP 配置/设置详细信息是否有任何不同？",
        "intention":"知识问答",
        "reply":"VPN BGP 的运行方式与 AWS Direct Connect 相同。"
    },
    {
        "query":"哪些 AWS 区域为 AWS Transit Gateway 提供 AWS Direct Connect 支持？",
        "intention":"知识问答",
        "reply":"所有商业 AWS 区域均为 AWS Transit Gateway 提供支持。"
    },
    {
        "query":"如何创建中转虚拟接口？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台或 API 操作来创建中转虚拟接口。"
    },
    {
        "query":"能否分配其他 AWS 账户中的中转虚拟接口？",
        "intention":"知识问答",
        "reply":"是，我可以将中转虚拟接口分配到任何 AWS 账户中。"
    },
    {
        "query":"能否将中转虚拟接口附加到我的虚拟私有网关？",
        "intention":"知识问答",
        "reply":"不能，您不能将中转虚拟接口附加到您的虚拟私有网关。"
    },
    {
        "query":"能否将私有虚拟接口附加到我的 AWS Transit Gateway？",
        "intention":"知识问答",
        "reply":"不能，您不能将虚拟私有接口附加到您的 AWS Transit Gateway。"
    },
    {
        "query":"中转虚拟接口有哪些相关限制？",
        "intention":"知识问答",
        "reply":"要详细了解与中转虚拟接口有关的限制，请参阅 [AWS Direct Connect 配额页面](https://docs.aws.amazon.com/directconnect/latest/UserGuide/limits.html)。"
    },
    {
        "query":"能否在连接中添加更多中转虚拟接口？",
        "intention":"知识问答",
        "reply":"不，您只能为任何 AWS Direct Connect 连接创建一个中转虚拟接口。"
    },
    {
        "query":"我有一个现有 AWS Direct Connect 网关附加在私有虚拟接口上，能否附加一个中转虚拟接口到此 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"不能，AWS Direct Connect 网关只能附加一种类型的虚拟接口。"
    },
    {
        "query":"我能否将我的 AWS Transit Gateway 与附加在私有虚拟接口上的 AWS Direct Connect 网关关联？",
        "intention":"知识问答",
        "reply":"不能，AWS Transit Gateway 只能与附加在中转虚拟接口上的 AWS Direct Connect 网关关联。"
    },
    {
        "query":"在 AWS Transit Gateway 和 AWS Direct Connect 网关之间建立关联需要多久？",
        "intention":"知识问答",
        "reply":"在 AWS Transit Gateway 和 AWS Direct Connect 网关之间建立关联最多需要 40 分钟。"
    },
    {
        "query":"对于每个 1Gbps、10Gbps 或 100Gbps 专用连接，我总共可以创建多少个虚拟接口？",
        "intention":"知识问答",
        "reply":"对于每个 1Gbps、10Gbps 或 100Gbps 专用连接，您最多可以创建 51 个虚拟接口，包括中转虚拟接口。"
    },
    {
        "query":"能否在任何速度的托管连接上创建中转虚拟接口？",
        "intention":"知识问答",
        "reply":"是。"
    },
    {
        "query":"我有 4x10 Gbps LAG，我可以在此链路汇聚组 (LAG) 上创建多少中转虚拟接口？",
        "intention":"知识问答",
        "reply":"您可以在 4x10G LAG 上创建一个中转虚拟接口。"
    },
    {
        "query":"中转虚拟接口是否支持巨型帧？",
        "intention":"知识问答",
        "reply":"是，中转虚拟接口将支持巨型帧。最大传输单位（MTU）大小限制为 8,500。"
    },
    {
        "query":"对于中转虚拟接口，是否支持在私有虚拟接口上支持的所有边界网关协议（BGP）属性？",
        "intention":"知识问答",
        "reply":"支持，您可以在中转虚拟接口上继续使用支持的 BGP 属性（AS\\_PATH、Local Pref、NO\\_EXPORT）。"
    },
    {
        "query":"为什么需要使用 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"AWS Direct Connect 网关具有多个功能："
    },
    {
        "query":"能否将多个 AWS Transit Gateway 关联到一个 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"一个 AWS Direct Connect 网关最多可以关联三个 Transit Gateway，但前提是 Transit Gateway 发布的 IP CIDR 块不重叠。"
    },
    {
        "query":"是否可以将任何 AWS 账户拥有的 VPC 关联到任何 AWS 账户拥有的 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"是，您可以将任何 AWS 账户拥有的 VPC 关联到任何 AWS 账户拥有的 AWS Direct Connect 网关。"
    },
    {
        "query":"是否可以将任何 AWS 账户拥有的 AWS Transit Gateway 关联到任何 AWS 账户拥有的 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"是，您可以将任何 AWS 账户拥有的 Transit Gateway 关联到任何 AWS 账户拥有的 AWS Direct Connect 网关。"
    },
    {
        "query":"如果使用 AWS Direct Connect 网关，传输到所需 AWS 区域的流量是否会通过关联的主 AWS 区域？",
        "intention":"知识问答",
        "reply":"否，使用 AWS Direct Connect 网关时，无论您连接的 AWS Direct Connect 站点关联哪个主 AWS 区域，您的流量将通过最短路径从您的 AWS Direct Connect 站点到达目标 AWS 区域。"
    },
    {
        "query":"使用 AWS Direct Connect 网关连接远程 AWS 区域是否需要额外付费？",
        "intention":"知识问答",
        "reply":"使用 AWS Direct Connect 网关不会产生任何费用。您需要根据源远程 AWS 区域支付适当的数据传出费，此外还需支付端口小时费。请参阅 [AWS Direct Connect 定价页面，以了解详细信息](https://aws.amazon.com/cn/directconnect/pricing/)。"
    },
    {
        "query":"为了使用 AWS Direct Connect 网关，我的私有/中转虚拟接口、AWS Direct Connect 网关、虚拟私有网关或 AWS Transit Gateway 是否需要来自同一 AWS 账户？",
        "intention":"知识问答",
        "reply":"私有虚拟接口和 AWS Direct Connect 网关必须来自同一 AWS 账户。同样，中转虚拟接口和 AWS Direct Connect 网关也必须来自同一 AWS 账户。拥有虚拟私有网关和 AWS Transit Gateway 的账户可以与拥有 AWS Direct Connect 网关的 AWS 账户不同。"
    },
    {
        "query":"如果我将虚拟私有网关 (VGW) 关联到某个 AWS Direct Connect 网关，能否继续使用所有 VPC 功能？",
        "intention":"知识问答",
        "reply":"Elastic File System、Elastic Load Balancing、Application Load Balancer、安全组、访问控制列表和 AWS PrivateLink 等联网功能仍受 AWS Direct Connect 网关支持。AWS Direct Connect 网关不支持 AWS VPN CloudHub 功能。.但如果使用 AWS Site-to-Site VPN 来连接与您的 AWS Direct Connect 网关关联的虚拟网关 (VGW)，那么您将可以使用 VPN 连接进行故障转移。\n目前 AWS Direct Connect 不支持的功能包括：AWS Classic VPN、AWS VPN（例如边缘到边缘路由）、VPC 对等连接和 VPC 终端节点。"
    },
    {
        "query":"我请一家 AWS Direct Connect 合作伙伴为我的账户预置了私有虚拟接口 (VIF)，我是否可以使用 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"是。当您在 AWS 账户中确认预置的私有虚拟接口 (VIF) 后，即可以将预置的私有虚拟接口关联到您的 AWS Direct Connect 网关。"
    },
    {
        "query":"是否可以连接到我本地区域中的 VPC？",
        "intention":"知识问答",
        "reply":"您可以继续将虚拟接口 (VIF) 连接到虚拟私有网关 (VGW)。您仍将拥有区域内 VPC 连接，并将收取相关地理区域的出口费用。"
    },
    {
        "query":"与 AWS Direct Connect 网关有关的配额有哪些？",
        "intention":"知识问答",
        "reply":"要了解这方面的信息，请参阅 [AWS Direct Connect 配额](https://docs.aws.amazon.com/directconnect/latest/UserGuide/limits.html)。"
    },
    {
        "query":"虚拟私有网关（VGW，与 VPC 关联）是否可以成为多个 AWS Direct Connect 网关的一部分？",
        "intention":"知识问答",
        "reply":"否，一个 VGW-VPC 对不能属于多个 AWS Direct Connect 网关。"
    },
    {
        "query":"是否可以将一个私有虚拟接口 (VIF) 附加到多个 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"否，一个私有虚拟接口只能附加到一个 AWS Direct Connect 网关或一个虚拟私有网关。我们建议您遵循 [AWS Direct Connect 弹性建议](https://aws.amazon.com/cn/directconnect/resiliency-recommendation/)并附加多个私有虚拟接口。"
    },
    {
        "query":"AWS Direct Connect 网关是否会破坏已有的 AWS VPN CloudHub 功能？",
        "intention":"知识问答",
        "reply":"否，AWS Direct Connect 网关不会破坏已有的 AWS VPN CloudHub。AWS Direct Connect 网关支持本地网络与任何 AWS 区域的 VPC 之间的连接。AWS VPN CloudHub 支持同一区域内使用 AWS Direct Connect 或 VPN 的本地网络之间的连接。VIF 与 VGW 直接关联。已有的 AWS VPN CloudHub 功能不受影响。您可以将 AWS Direct Connect 虚拟接口 (VIF) 直接附加到虚拟私有网关 (VGW)，以支持区域内的 AWS VPN CloudHub。"
    },
    {
        "query":"AWS Direct Connect 网关支持哪种类型的流量？不支持哪种类型的流量？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS Direct Connect 用户指南](https://docs.aws.amazon.com/directconnect/latest/UserGuide/dc-ug.pdf)，查看受支持和不受支持的流量模式。"
    },
    {
        "query":"我目前在 us-east-1 区域有一个 VPN 已附加到某个虚拟私有网关 (VGW)。我想在 us-east-1 区域在该 VPN 和某个新的 VIF 之间使用 AWS VPN CloudHub。能否用 AWS Direct Connect 网关来实现这一点？",
        "intention":"知识问答",
        "reply":"不能。您不能通过 AWS Direct Connect 网关来实现这一点，但可以选择将一个 VIF 直接附加到一个 VGW 以使用该 VPN <-> AWS Direct Connect AWS VPN CloudHub 使用场景。"
    },
    {
        "query":"我有一个与虚拟私有网关（VGW）关联的现有私有虚拟接口，是否可以将我现有的私有虚拟接口关联到 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"否，与 VGW 关联的现有私有虚拟接口不能与 AWS Direct Connect 网关关联。要做到这一点，您必须创建一个新的私有虚拟接口，并在创建时将其关联到您的 AWS Direct Connect 网关。"
    },
    {
        "query":"如果我有一个附加到某个 VPN 和某个 AWS Direct Connect 网关的虚拟私有网关（VGW），当我的 AWS Direct Connect 线路断开时，VPC 流量是否会被路由到该 VPN 之外？",
        "intention":"知识问答",
        "reply":"是，但前提是 VPC 路由表中具有指向该 VPN 的虚拟私有网关（VGW）路由。"
    },
    {
        "query":"是否可以将未附加到 VPC 的虚拟私有网关（VGW）附加到某个 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"否，您不能将未附加到 VPC 的 VGW 关联到 AWS Direct Connect 网关。"
    },
    {
        "query":"我创建了一个 AWS Direct Connect 网关，它具有一个 AWS Direct Connect 私有 VIF 和三个不重叠的虚拟私有网关（VGW，每个 VGW 都关联一个 VPC）。如果我将一个 VGW 与 VPC 分离，会发生什么情况？",
        "intention":"知识问答",
        "reply":"从您的本地网络传输到分离的 VPC 的流量会停止，并且 VGW 与 AWS Direct Connect 网关之间的关联会被删除。"
    },
    {
        "query":"我创建了一个 AWS Direct Connect 网关，它具有一个 AWS Direct Connect VIF 和三个不重叠的 VGW-VPC 对，如果我将一个虚拟私有网关 (VGW) 与 AWS Direct Connect 网关分离，会发生什么情况？",
        "intention":"知识问答",
        "reply":"从您的本地网络传输到分离的 VGW（关联一个 VPC）的流量会停止。"
    },
    {
        "query":"是否可以将流量从关联到某个 AWS Direct Connect 网关的一个 VPC 发送到与同一 AWS Direct Connect 网关关联的另一个 VPC？",
        "intention":"知识问答",
        "reply":"否，AWS Direct Connect 网关仅支持从 AWS Direct Connect VIF 路由到 VGW（与 VPC 关联）的流量。要在 2 个 VPC 之间发送流量，您必须配置一个 VPC 对等连接。"
    },
    {
        "query":"我目前在 us-east-1 区域有一个附加到某个虚拟私有网关（VGW）的 VPN。如果将此 VGW 关联到一个 AWS Direct Connect 网关，是否能够将来自我的 VPN 的流量发送到其他 AWS 区域中附加到该 AWS Direct Connect 网关的 VIF？",
        "intention":"知识问答",
        "reply":"否，AWS Direct Connect 网关不支持在 VPN 和 AWS Direct Connect VIF 之间路由流量。要支持这一使用场景，您需要在该 VIF 所在的 AWS 区域创建一个 VPN，并将该 VIF 和该 VPN 附加到同一 VGW。"
    },
    {
        "query":"是否可以调整关联到 AWS Direct Connect 网关的 VPC 的大小？",
        "intention":"知识问答",
        "reply":"是，您可以调整 VPC 的大小。如果您调整了 VPC 的大小，则必须将包含调整大小后 VPC 的 CIDR 的提案重新发送给 AWS Direct Connect 网关拥有者。AWS Direct Connect 网关拥有者批准新提案后，将向本地网络公开调整大小后的 VPC CIDR。"
    },
    {
        "query":"有没有一种方法可以配置 AWS Direct Connect 网关，从而有选择地向/从 VPC 公布前缀？",
        "intention":"知识问答",
        "reply":"有，AWS Direct Connect 网关提供了有选择地向本地网络公布前缀的方法。对于从您的本地网络公布的前缀，关联到 AWS Direct Connect 网关的每个 VPC 都将收到您的本地网络公布的所有前缀。要限制进出任何特定 Amazon VPC 的流量，则应考虑为每个 VPC 使用访问控制列表 (ACL)。"
    },
    {
        "query":"是否可以将这一功能用于我现有的 EBGP 会话？",
        "intention":"知识问答",
        "reply":"是，私有虚拟接口上的所有现有 BGP 会话都支持使用本地优先团体。"
    },
    {
        "query":"这一功能是否同时适用于公有虚拟接口和私有虚拟接口？",
        "intention":"知识问答",
        "reply":"否，这一功能目前只适用于私有和中转虚拟接口。"
    },
    {
        "query":"此功能是否支持 AWS Direct Connect 网关？",
        "intention":"知识问答",
        "reply":"是，此功能支持附加到 AWS Direct Connect 网关的私有虚拟接口。"
    },
    {
        "query":"我是否可以验证 AWS 收到的社区？",
        "intention":"知识问答",
        "reply":"否，目前我们不提供此类监控功能。"
    },
    {
        "query":"AWS Direct Connect 私有虚拟接口支持哪些本地优先社区？",
        "intention":"知识问答",
        "reply":"私有虚拟接口支持以下社区，其优先级按从低到高的顺序排列。不同团体互相排斥。标有同一团体并且带有相同的 MED\\*, AS\\_PATH 属性的前缀适合多路径传输。"
    },
    {
        "query":"如果我不使用支持的社区，默认会出现什么情况？",
        "intention":"知识问答",
        "reply":"如果您没有为私有 VIF 指定本地优先社区，则默认本地首选项将根据从本地区域到 AWS Direct Connect 站点的距离而定。在这种情况下，跨来自多个 AWS Direct Connect 站点的多个 VIF 的出口行为可能是随机的。"
    },
    {
        "query":"我在位于某个 AWS Direct Connect 站点的一个物理连接上有两个私有 VIF，是否可以使用支持的社区来影响通过这两个私有 VIF 的出口行为？",
        "intention":"知识问答",
        "reply":"是，您可以使用此项功能来影响同一物理连接上的两个 VIF 之间的出口流量行为。"
    },
    {
        "query":"本地优先社区功能是否支持故障转移？",
        "intention":"知识问答",
        "reply":"是。要实现这一目的，您可以通过使用具有更高本地优先级的社群的主要/主动虚拟接口来公布前缀，而非通过辅助/被动虚拟接口公布前缀；此项功能可向后兼容用于实现故障转移的既有方法；如果您的连接当前已配置为可用于故障转移，则不需要进行其他更改。"
    },
    {
        "query":"我已经将路由器属性配置为 AS_PATH，我是否需要更改配置才能使用社区标签？是否需要中断我的网络？",
        "intention":"知识问答",
        "reply":"不需要，我们会继续支持 AS\\_PATH 属性。这一功能可以为您提供额外的帮助，让您更好地控制来自 AWS 的传入流量。AWS Direct Connect 采用标准方法进行路径选择。请注意，本地优先级先于 AS\\_PATH 属性接受评估。"
    },
    {
        "query":"我有两个 AWS Direct Connect 连接，一个为 1 Gbps，另一个为 10 Gbps，都公布相同的前缀。我想通过 10 Gbps AWS Direct Connect 连接来接收此目标的所有流量，但同时仍希望能够故障转移至 1 Gbps 连接；在这种情况下，本地优先社区是否可用于均衡流量？",
        "intention":"知识问答",
        "reply":"是。您可以将通过 10 Gbps AWS Direct Connect 连接公布的前缀标记为使用具有更高本地优先级的社区，则该连接将成为首选路径，如果 10 Gbps 接口出现故障或者前缀被取消，那么 1 Gbps 接口将成为退回路径。"
    },
    {
        "query":"传输到我的网络的流量的 AWS 多路径宽度是多少？",
        "intention":"知识问答",
        "reply":"每个前缀的多路径宽度最大为 16 个下一跳，而每个下一跳都是一个唯一的 AWS 终端节点。"
    },
    {
        "query":"我可以在单个 VPN 隧道上运行 v4 和 v6 BGP 会话吗？",
        "intention":"知识问答",
        "reply":"目前，我们仅允许在具有 IPv4 地址的单个 VPN 隧道上运行 v4 BGP 会话。"
    },
    {
        "query":"为 AWS Direct Connect 列出的 BGP 配置/设置详细信息是否有任何不同？",
        "intention":"知识问答",
        "reply":"VPN BGP 的运行方式与 AWS Direct Connect 相同。"
    },
    {
        "query":"我可以在具有 IPv6 地址的终结点终止我的隧道吗？",
        "intention":"知识问答",
        "reply":"目前，我们仅支持具有 IPv4 终端节点地址的 VPN。"
    },
    {
        "query":"我是否可以在 IPv4 地址上终止我的隧道并在该隧道上运行 IPv6 BGP 会话？",
        "intention":"知识问答",
        "reply":"目前，我们仅允许在具有 IPv4 地址的单个 VPN 隧道上运行 v4 BGP 会话。"
    },
    {
        "query":"这是什么功能？",
        "intention":"知识问答",
        "reply":"可配置的私有自治系统编号 (ASN)。利用这一功能，客户可以针对任何新创建的 AWS Direct Connect 网关上的私有 VIF，在 BGP 会话的 AWS 端设置 ASN。"
    },
    {
        "query":"可以在哪里使用这些功能？",
        "intention":"知识问答",
        "reply":"所有商用 AWS 区域（AWS 中国区域除外）和 AWS GovCloud（美国）区域都支持这些功能。"
    },
    {
        "query":"如何将要公布的 ASN 配置/分配为 AWS 端 ASN？",
        "intention":"知识问答",
        "reply":"您可以在创建新的 AWS Direct Connect 网关期间将某个要公布的 ASN 配置/分配为 AWS 端 ASN。您可以通过 AWS 管理控制台或 CreateDirectConnectGateway API 操作来创建 AWS Direct Connect 网关。"
    },
    {
        "query":"能否使用任何 ASN – 公有和私有？",
        "intention":"知识问答",
        "reply":"您可以将任何私有 ASN 分配到 AWS 端。您无法分配任何其他公有 ASN。"
    },
    {
        "query":"为什么不能为 BGP 会话的 AWS 端分配公有 ASN？",
        "intention":"知识问答",
        "reply":"AWS 不会验证 ASN 的所有权，因此我们将 AWS 端 ASN 限定为私有 ASN。我们要保护客户免受 BGP 欺诈。"
    },
    {
        "query":"我可以选择什么 ASN？",
        "intention":"知识问答",
        "reply":"您可以选择任何私有 ASN。16 位私有 ASN 的范围是从 64512 到 65534。您还可以提供介于 4200000000 与 4294967294 之间的 32 位 ASN。"
    },
    {
        "query":"如果我尝试为 BGP 会话的 AWS 端分配某个公有 ASN，会出现什么情况？",
        "intention":"知识问答",
        "reply":"我们会在您尝试创建 AWS Direct Connect 网关时要求您重新输入一个私有 ASN。"
    },
    {
        "query":"如果我没有为 BGP 会话的 AWS 端提供 ASN，AWS 会如何分配该 ASN？",
        "intention":"知识问答",
        "reply":"如果您没有提供 ASN，AWS 会为该 AWS Direct Connect 网关提供编号为 64512 的 ASN。"
    },
    {
        "query":"我可以在哪里查看 AWS 端 ASN？",
        "intention":"知识问答",
        "reply":"您可以在 AWS Direct Connect 控制台以及 DescribeDirectConnectGateways 或 DescribeVirtualInterfaces API 操作的响应中查看 AWS 端 ASN。"
    },
    {
        "query":"如果我有公有 ASN，它是否会与 AWS 端的私有 ASN 搭配使用？",
        "intention":"知识问答",
        "reply":"是，您可以为 BGP 会话的 AWS 端配置一个私有 ASN，并为您所在端配置一个公有 ASN。"
    },
    {
        "query":"我已经配置了私有 VIF，并且想要为现有 VIF 上的 BGP 会话设置一个不同的 AWS 端 ASN。如何进行此项更改？",
        "intention":"知识问答",
        "reply":"您需要使用所需 ASN 创建一个新的 AWS Direct Connect 网关，然后使用新建的 AWS Direct Connect 网关创建一个新的 VIF。您的设备配置也必须相应更改。"
    },
    {
        "query":"我要将多个私有 VIF 附加到单个 AWS Direct Connect 网关。每个 VIF 是否可以具有单独的 AWS 端 ASN？",
        "intention":"知识问答",
        "reply":"不可以，您可以为每个 AWS Direct Connect 网关分配/配置单独的 AWS 端 ASN，但不能为每个 VIF 这样做。VIF 的 AWS 端 ASN 将会集成所附加的 AWS Direct Connect 网关的 AWS 端 ASN。"
    },
    {
        "query":"AWS Direct Connect 网关和虚拟私有网关是否可以使用不同的私有 ASN？",
        "intention":"知识问答",
        "reply":"是，AWS Direct Connect 网关和虚拟私有网关可以使用不同的私有 ASN。您收到的 AWS 端 ASN 取决于您的私有虚拟接口关联。"
    },
    {
        "query":"AWS Direct Connect 网关和虚拟私有网关是否可以使用相同的私有 ASN？",
        "intention":"知识问答",
        "reply":"可以，AWS Direct Connect 网关和虚拟私有网关可以使用相同的私有 ASN。您收到的 AWS 端 ASN 取决于您的私有虚拟接口关联。"
    },
    {
        "query":"我要将多个虚拟私有网关附加到一个 AWS Direct Connect 网关，并且这些网关都具有/配置了自己的私有 ASN。系统会优先使用哪个私有 ASN？是 VGW 的还是 AWS Direct Connect 网关的私有 ASN？",
        "intention":"知识问答",
        "reply":"对于您的网络与 AWS 之间的边界网关协议 (BGP) 会话，AWS 端 ASN 将会使用 AWS Direct Connect 网关的私有 ASN。"
    },
    {
        "query":"我可以在哪里选择自己的私有 ASN？",
        "intention":"知识问答",
        "reply":"您可以在 AWS Direct Connect 网关控制台中选择自己的私有 ASN。为 AWS Direct Connect 网关配置好 AWS 端 ASN 之后，关联到该 AWS Direct Connect 网关的私有虚拟接口会将您配置的 ASN 用作 AWS 端 ASN。"
    },
    {
        "query":"我今天使用了 AWS VPN CloudHub，以后是否必须要调整配置？",
        "intention":"知识问答",
        "reply":"您不需要进行任何更改。"
    },
    {
        "query":"我想选择 32 位 ASN。32 位私有 ASN 的范围是什么？",
        "intention":"知识问答",
        "reply":"我们支持从 4200000000 到 4294967294 的 32 位 ASN。"
    },
    {
        "query":"创建 AWS Direct Connect 网关后，是否可以更改或修改 AWS 端 ASN？",
        "intention":"知识问答",
        "reply":"不可以，AWS 端 ASN 创建后将不能修改。但您可以删除该 AWS Direct Connect 网关，然后重新创建一个具有所需私有 ASN 的新 AWS Direct Connect 网关。"
    },
    {
        "query":"MACsec 是否取代了我目前在网络中使用的其他加密技术？",
        "intention":"知识问答",
        "reply":"MACsec 并非旨在取代任何特定的加密技术。为了简单起见，也为了加深防御，您应该继续使用您已经使用的任何加密技术。除了您当前使用的其他加密技术之外，我们提供的 MACsec 作为一种加密选项，您也可以将其集成到您的网络中。"
    },
    {
        "query":"哪些类型的 AWS Direct Connect 连接支持 MACsec？",
        "intention":"知识问答",
        "reply":"选定[入网点](https://aws.amazon.com/cn/directconnect/locations/)的 10 Gbps 和 100 Gbps 专用 AWS Direct Connect 连接支持 MACsec。要使 MACsec 正常工作，您的专用连接必须对第 2 层流量透明，且终止第 2 层邻接的设备必须支持 MACsec。如果您使用的是最后一英里连接合作伙伴，请检查您的最后一英里连接是否支持 MACsec。1 Gbps 专用连接和所有托管连接都不支持 MACsec。"
    },
    {
        "query":"我是否需要任何特殊硬件才能使用 MACsec？",
        "intention":"知识问答",
        "reply":"是。对于到 AWS Direct Connect 站点的以太网连接，您所在一端的设备需要支持 MACsec。请参阅我们用户指南的 [MAC 安全性](https://docs.aws.amazon.com/directconnect/latest/UserGuide/MACsec.html)部分，以确定支持的运行模式和需要的 MACsec 功能。"
    },
    {
        "query":"是否需要新的 AWS Direct Connect 连接才能将 MACsec 用于支持 MACsec 的设备？",
        "intention":"知识问答",
        "reply":"MACsec 要求您的连接在连接的 AWS Direct Connect 端上支持 MACsec 的设备上终止。您可以通过 AWS 管理控制台或 *[DescribeConnections](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_DescribeConnections.html)* AWS Direct Connect API 来检查现有的连接是否支持 MACsec。如果现有的 MACsec 连接未连接到支持 MACsec 的设备上，则可以使用 AWS 管理控制台或 *[CreateConnection](https://docs.aws.amazon.com/directconnect/latest/APIReference/API_CreateConnection.html)* API 来请求新的支持 MACsec 的连接。"
    },
    {
        "query":"您支持哪些 MACsec 密码套件？",
        "intention":"知识问答",
        "reply":"对于 100Gbps 连接，我们支持 GCM-AES-XPN-256 密码套件。 对于 10Gbps 连接，我们支持 GCM-AES-256 和 GCM-AES-XPN-256。"
    },
    {
        "query":"为何仅支持 256 位密钥？",
        "intention":"知识问答",
        "reply":"我们仅支持 256 位 MACsec 密钥是为了提供最先进的数据保护。"
    },
    {
        "query":"您要求使用扩展包编号（XPN）吗？",
        "intention":"知识问答",
        "reply":"我们要求使用 XPN 进行 100Gbps 连接。对于 10Gbps 连接，我们支持 GCM-AES-256 和 GCM-AES-XPN-256。高速连接（如 100Gbps 专用连接）会很快耗尽 MACsec 原来的 32 位数据包编号空间，这需要您每隔几分钟轮换一次加密密钥，以建立新的连接关联。为了避免这种情况，IEEE Std 802.1AEbw-2013 修正案引入了扩展数据包编号，将编号空间增加到 64 位，从而缓解了密钥轮换的及时性要求。"
    },
    {
        "query":"您是否支持使用安全通道标识符 (SCI)？",
        "intention":"知识问答",
        "reply":"是。我们要求 SCI 必须打开。此设置无法更改。"
    },
    {
        "query":"您是否支持 IEEE 802.1Q (Dot1q/VLAN) 标签偏移/dot1q-in-clear？",
        "intention":"知识问答",
        "reply":"否，我们不支持将 VLAN 标签移到加密负载之外。"
    },
    {
        "query":"什么是 AWS Database Migration Service？",
        "intention":"知识问答",
        "reply":"AWS Database Migration Service (AWS DMS) 是一项托管迁移和复制服务，可帮助您将数据库和分析工作负载快速、安全地迁移到 AWS。源数据库可在迁移过程中保持全面运行，从而最大程度地减少依赖该数据库的应用程序的停机时间。\nAWS Database Migration Service 可以在广泛使用的开源商业数据库之间评估、转换和迁移您的数据。AWS Database Migration Service 支持同构迁移（例如从 Oracle 迁移至 Oracle），以及不同数据库之间的异构迁移（例如从 Oracle 或 Microsoft SQL Server 迁移至 Amazon Aurora）。\n使用 AWS Database Migration Service，您还可以从支持的源中将数据低延迟、持续地复制到支持的目标。 例如，您可以从多个源复制到 Amazon Simple Storage Service（Amazon S3），以构建高度可用且可扩展的数据湖解决方案。\n您还可以通过将数据流传输到 Amazon Redshift 来将数据库整合到 PB 级数据仓库中。了解更多有关受支持的源和目标数据库的信息。"
    },
    {
        "query":"如何开始使用 AWS Database Migration Service？",
        "intention":"知识问答",
        "reply":"您可以快速而轻松地[开始使用 AWS Database Migration Service](https://aws.amazon.com/cn/dms/getting-started/)。大多数数据复制任务可在 10 分钟内设置完毕。\n请访问 [AWS 管理控制台](https://aws.amazon.com/cn/console/)的 AWS Database Migration Service 部分，然后进入“Start Migration”（开始迁移）向导。指定来源和目标端点，选择现有复制实例或新建一个，然后接受默认的架构映射规则或定义您自己的转换。完成该向导后，系统会立即开始数据复制。"
    },
    {
        "query":"使用 AWS Database Migration Service 的数据库迁移步骤有哪些？",
        "intention":"知识问答",
        "reply":"在典型的简单数据库迁移过程中，您需要创建目标数据库、迁移数据库架构、设置数据复制处理操作、启动完整负载和后续变更数据捕获并应用，最后，在目标数据库可替代来源数据库后，将生产环境切换到新的数据库。"
    },
    {
        "query":"使用 AWS DMS 的数据库迁移流程与连续数据复制有何不同？",
        "intention":"知识问答",
        "reply":"唯一的区别是最后一步（生产环境切换），持续数据复制不需要执行这一步。数据复制任务将一直运行，直到您更改或终止它。"
    },
    {
        "query":"我能监控数据库迁移任务的进度吗？",
        "intention":"知识问答",
        "reply":"能。AWS 管理控制台中显示了各种各样的 AWS Database Migration Service 指标。它提供了数据复制进程的端到端视图，包括复制管道中各个节点的诊断和性能数据。\nAWS Database Migration Service 还与 [CloudTrail](https://aws.amazon.com/cn/cloudtrail/) 和 [CloudWatch](https://aws.amazon.com/cn/cloudwatch/) Logs 等其他 AWS 产品集成。您可以借助 [AWS Database Migration Service API](https://docs.aws.amazon.com/dms/latest/APIReference/Welcome.html) 和 [AWS 命令行界面](https://aws.amazon.com/cn/cli/)（AWS CLI）与现有的工具集成或构建自定义监控工具，以契合自己的独特需求。"
    },
    {
        "query":"如何将 AWS Database Migration Service 与其他应用程序集成？",
        "intention":"知识问答",
        "reply":"AWS Database Migration Service 提供了一种调配 API，让您能够从开发环境直接创建复制任务，或编写脚本以在一天中的预定时间创建。\n服务 API 和 CLI 使开发人员和数据库管理员能够实现自动创建、重启、管理和终止复制任务。"
    },
    {
        "query":"AWS Database Migration Service 支持哪些源数据库和目标数据库？ AWS Database Migration Service (DMS) 支持一系列同构和异构数据复制。",
        "intention":"知识问答",
        "reply":"来源或目标数据库（或两者）需要位于 RDS 中或 EC2 上。不支持在两个本地数据库之间复制。"
    },
    {
        "query":"AWS DMS 无服务器支持哪些源和目标引擎？",
        "intention":"知识问答",
        "reply":"AWS DMS Serverless 支持热门的数据库和分析服务，例如 Oracle、Microsoft SQL Server、PostgreSQL、MySQL、Amazon Redshift、Amazon RDS、Amazon Aurora 等。查看[受支持引擎的完整列表](https://docs.aws.amazon.com/dms/latest/userguide/data-migrations.html)。"
    },
    {
        "query":"AWS Database Migration Service 可以帮助我将 Oracle PL/SQL 和 SQL Server T-SQL 代码转换为 Amazon RDS for MySQL 和 Amazon RDS for PostgreSQL 存储过程吗？",
        "intention":"知识问答",
        "reply":"可以。AWS Database Migration Service 包含 [AWS DMS Schema Conversion (DMS SC)](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_SchemaConversion.html)，可以自动将 Oracle PL/SQL 和 SQL Server T-SQL 代码转换为使用 SQL 的 Amazon RDS for MySQL 语法的等效代码，或者转换为 PostgreSQL 中的等效 PL/pgSQL 代码。  \n   \n 如果遇到无法自动转换为目标语言的代码段，DMS SC 会明确记录需要应用程序开发人员手动输入的位置。 此外，还可提供可下载版本，即 [AWS Schema Conversion Tool (AWS SCT)](https://aws.amazon.com/dms/schema-conversion-tool/)。"
    },
    {
        "query":"AWS Database Migration Service 会替我迁移数据库架构吗？",
        "intention":"知识问答",
        "reply":"会，当您需要使用可自定义程度更高的架构迁移流程（例如，迁移生产数据库并且需要迁移存储的程序和二级数据库对象时）时，您可以使用 AWS DMS 的内置架构转换功能，以实现异构迁移。如果您进行的是同构迁移，则还可以下载 AWS Schema Conversion Tool 或者使用源引擎的原生架构导出工具，例如："
    },
    {
        "query":"AWS Database Migration Service (AWS DMS) 与 AWS Schema Conversion Tool (AWS SCT) 有什么关系？",
        "intention":"知识问答",
        "reply":"AWS DMS 和 AWS SCT 协同工作，可以迁移数据库并支持持续复制，适用于填充数据湖和仓库、同步系统等多种用途。AWS SCT 可以复制数据库架构以便进行同构迁移，还可以转换数据库架构以便进行异构迁移。架构可以在数据库之间迁移（例如 Oracle 到 PostgreSQL），也可以在数据仓库之间迁移（例如 Netezza 到 Amazon Redshift）。\n在空目标上创建架构之后，可以根据数据量和/或支持的引擎选用 AWS DMS 或 AWS SCT 来移动数据。AWS DMS 常用于移动较小的关系工作负载（<10 TB），而 AWS SCT 主要用于迁移大型数据仓库工作负载。AWS DMS 支持持续复制，可以让目标与来源保持同步，AWS SCT 则不能。"
    },
    {
        "query":"除了一次性数据迁移外，我可以使用 AWS Database Migration Service 进行持续的数据复制吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS Database Migration Service 将数据一次性迁移到基于 RDS 和 EC2 的数据库，也可以进行持续的数据复制。AWS Database Migration Service 会捕获来源数据库的变更，并将它们以事务一致的方式应用到目标。\n您可以从数据中心向 AWS 数据库进行持续复制，或者反过来，从 AWS 数据库向数据中心的数据库进行持续复制。此外，您也可以在同构或异构数据库之间进行持续复制。对于持续复制，建议使用多可用区，以实现高可用性。"
    },
    {
        "query":"我为什么要使用 AWS Database Migration Service 而不是我自己的自主管理复制解决方案？",
        "intention":"知识问答",
        "reply":"AWS Database Migration Service 非常简单易用。与必须进行安装和配置的自主管理复制解决方案相比，AWS Database Migration Service 的复制任务只需几分钟就能设置完毕，而不是几小时乃至几天。AWS Database Migration Service 监测复制任务、网络或主机故障，如果无法修复故障，将自动更换主机。AWS Database Migration Service 用户无需像通常的自行管理解决方案一样过度预置容量，投入昂贵的硬件和复制软件。\n借助 AWS Database Migration Service，用户能够享受按需定价的好处，并可根据负载来扩展或缩小复制基础设施的规模。AWS Database Migration Service 数据复制与 AWS Schema Conversion Tool 紧密集成，简化了异构数据库迁移项目。"
    },
    {
        "query":"我能从加密数据来源复制数据吗？",
        "intention":"知识问答",
        "reply":"能。AWS Database Migration Service 能够读写加密数据库。AWS Database Migration Service 在 SQL 接口层连接数据库终端节点。如果您使用了 Oracle 或 SQL Server 的“透明数据加密”功能，则 AWS Database Migration Service 可从此类来源提取加密数据并复制到目标。\n这同样适用于存储级加密。只要 AWS Database Migration Service 拥有数据库来源的正确凭证，它就能连接来源并将数据传送（以加密形式）到目标。\n我们建议在模板上使用静态加密，以维护信息的机密性。如果您使用应用级加密，则数据将通过 AWS Database Migration Service 按原样（加密格式）传输，然后插入到目标数据库中。"
    },
    {
        "query":"什么是 AWS DMS Serverless？",
        "intention":"知识问答",
        "reply":"AWS Database Migration Service（AWS DMS）Serverless 可自动预置、监控和扩展资源，使您能够以更简单、更具成本效益的方式完成向 AWS 的数据库和分析迁移。使用 AWS DMS Serverless，您不再需要过度预置迁移资源或手动监控和扩展资源即可实现持续数据复制。AWS DMS Serverless 会优化资源以满足需求，因此您只需为使用的资源付费。这使其对持续数据复制以及不同源和目标引擎之间的复杂异构迁移等常见应用场景很有帮助。"
    },
    {
        "query":"我能否使用 AWS DMS Serverless 进行持续复制？",
        "intention":"知识问答",
        "reply":"是的，AWS DMS Serverless 可用于持续复制。DMS Serverless 支持单可用区和多可用区部署选项。"
    },
    {
        "query":"我应该使用哪个 DMS 功能进行同构数据库迁移？",
        "intention":"知识问答",
        "reply":"对于同构迁移，我们建议对支持的引擎使用 DMS 内置原生工具，因为该工具对用户来说非常熟悉，而且可以无缝迁移。您无需预置或监控迁移，只需按迁移期间的使用时间付费。要查看支持的引擎，请转到 [DMS 文档页面](https://docs.aws.amazon.com/dms/latest/userguide/data-migrations.html)。\n对于具有数据波动的异构迁移或持续数据复制，我们建议使用 AWS DMS Serverless，因为它可以自动监控和扩展资源以满足需求，无需手动干预或过度预置资源，从而为您节省时间和成本。相对而言，按需型实例有利于可预测的、稳定的数据传输，因为它们可以调整大小以改善性能和成本。有关支持的引擎，请参阅 [AWS DMS Serverless 文档](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Serverless.html)。"
    },
    {
        "query":"AWS DMS 同构数据迁移是无服务器的吗？",
        "intention":"知识问答",
        "reply":"是的，用于同构数据迁移的 AWS DMS 内置原生工具是无服务器的。它不使用复制实例，将根据需要自动监控和扩展迁移资源以实现无缝迁移。\n什么是 AWS DMS Fleet Advisor？\n[AWS DMS Fleet Advisor](https://aws.amazon.com/cn/dms/fleet-advisor/) 是 AWS Database Migration Service (AWS DMS) 的一项完全托管式免费功能。它可以自动执行迁移计划，并帮助您轻松大规模地将数据库和分析机群迁移到云。 要发现本地数据库，您可以使用独立的 AWS DMS Fleet Advisor 收集器或 [AWS Application Discovery Service (ADS) Agentless Collector](https://docs.aws.amazon.com/application-discovery/latest/userguide/agentless-collector.htm) 的数据库和分析收集模块。"
    },
    {
        "query":"何时应使用 AWS DMS Fleet Advisor 以及 AWS Application Discovery Service 和 Migration Evaluator？",
        "intention":"知识问答",
        "reply":"[AWS DMS Fleet Advisor](https://aws.amazon.com/cn/dms/fleet-advisor/) 面向希望将大量数据库和分析服务器迁移到 AWS 的用户。准备好将数据库和分析工作负载迁移到 AWS 的目标服务后，应[使用 AWS DMS Fleet Advisor 发现和分析](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_FleetAdvisor.html) Online Transaction Processing (OLTP) 和联机分析处理 (OLAP) 系统数据库工作负载。Fleet Advisor 允许您通过确定将源数据库迁移到 AWS 中的目标服务的复杂性来构建定制的迁移计划。\n[AWS Application Discovery Service](https://aws.amazon.com/cn/application-discovery/) (ADS) 和 [Migration Evaluator](https://aws.amazon.com/migration-evaluator/) 针对广泛计算和连接的数据块存储发现。Migration Evaluator 供开始迁移，希望找到 AWS 的数据驱动业务场景的客户使用。ADS 用于向 [AWS Migration Hub](https://aws.amazon.com/migration-hub/) 提供数据，可视化服务器之间的依赖项，创建应用程序组，跟踪迁移进度。"
    },
    {
        "query":"何时应使用 AWS DMS Fleet Advisor 收集器以及 AWS Application Discovery Service？",
        "intention":"知识问答",
        "reply":"对于大多数客户，我们建议在[可用区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)使用 [AWS Application Discovery Service (ADS) Agentless Collector](https://docs.aws.amazon.com/application-discovery/latest/userguide/agentless-collector.html)，因为它支持通过 AWS Migration Hub 进行服务器迁移，并允许您发现本地数据库。对于所有其他区域，我们建议使用 AWS DMS Fleet Advisor 收集器。从独立的 AWS DMS Fleet Advisor 收集器和 AWS ADS Agentless Collector 收集的数据库元数据和利用率指标将在 [AWS DMS Fleet Advisor](https://aws.amazon.com/cn/dms/fleet-advisor/) 中提供。\n如果您有 [VMware vCenter Server 环境](https://docs.aws.amazon.com/application-discovery/latest/userguide/agentless-collector.html)，请使用 AWS ADS Agentless Collector，否则可以在 [Microsoft Windows Server 2012 或更高版本](https://docs.aws.amazon.com/dms/latest/userguide/fa-data-collectors-install.html)上安装 AWS DMS Fleet Advisor 收集器。"
    },
    {
        "query":"什么是 AWS DMS 支持生命周期策略？",
        "intention":"知识问答",
        "reply":"AWS DMS 支持生命周期策略指定了每个 DMS 版本的支持期，即从版本发布到不再受支持的时长。"
    },
    {
        "query":"支持生命周期政策的目的是什么？",
        "intention":"知识问答",
        "reply":"支持生命周期策略旨在为每个 AWS DMS 版本发布提供可预测且一致的支持指南。该指南将有利于客户战略性地规划他们的迁移和升级。"
    },
    {
        "query":"AWS DMS 版本的支持时间表是什么？",
        "intention":"知识问答",
        "reply":"以下是所有 AWS DMS 版本的支持时间表摘要。此表将随着我们发布新的 DMS 版本而更新。支持终止日期将从每个版本发布后的 18 个月开始，但 2022 年之前发布的版本的支持期更长。\n|  |  |  |\n| --- | --- | --- |\n| 版本 | 发布日期 | 支持终止起始日期 |\n| 3.3.3 | 6/2020 | 02/2023 |\n| 3.3.4 | 8/2020 | 02/2023 |\n| 3.4.2 | 11/2020 | 02/2023 |\n| 3.4.3 | 12/2020 | 02/2023 |\n| 3.4.4 | 5/2021 | 02/2023 |\n| 3.4.5 | 9/2021 | 5/2023 |\n| 3.4.6 | 12/2021 | 12/2023 |\n| 3.4.7 | 6/2022 | 12/2023 |\n发布日期\n支持终止起始日期\n3.3.3\n6/2020\n02/2023\n3.3.4\n8/2020\n02/2023\n3.4.2\n11/2020\n02/2023\n3.4.3\n12/2020\n02/2023\n3.4.4\n5/2021\n02/2023\n3.4.5\n9/2021\n5/2023\n3.4.6\n12/2021\n12/2023\n3.4.7\n6/2022\n12/2023"
    },
    {
        "query":"什么是 AWS DMS 支持生命周期策略？",
        "intention":"知识问答",
        "reply":"AWS DMS 支持生命周期策略指定了每个 DMS 版本的支持期，即从版本发布到不再受支持的时长。"
    },
    {
        "query":"支持生命周期政策的目的是什么？",
        "intention":"知识问答",
        "reply":"支持生命周期策略旨在为每个 AWS DMS 版本发布提供可预测且一致的支持指南。该指南将有利于客户战略性地规划他们的迁移和升级。"
    },
    {
        "query":"AWS DMS 版本的支持时间表是什么？",
        "intention":"知识问答",
        "reply":"以下是所有 AWS DMS 版本的支持时间表摘要。此表将随着我们发布新的 DMS 版本而更新。支持终止日期将从每个版本发布后的 18 个月开始，但版本 3.3.3、3.3.4、3.4.2、3.4.3 和 3.4.4 的支持期更长。"
    },
    {
        "query":"时间表是如何传达的？",
        "intention":"知识问答",
        "reply":"每个 AWS DMS 版本发布的支持时间表将包含在相关的 [DMS 发布说明](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReleaseNotes.html)中。 此外，AWS 每季度会向 DMS 实例所有者发送一次提醒，提醒他们正在运行的版本下一季度将不再受支持。"
    },
    {
        "query":"AWS DMS 发布支持生命周期策略何时生效？",
        "intention":"知识问答",
        "reply":"该策略将于 2023 年 1 月 1 日起生效。所有在发布后 18 个月终止支持的实例都将自动升级到最新的首选 DMS 版本，不受自动升级设置影响。"
    },
    {
        "query":"首选 DMS 版本是什么？",
        "intention":"知识问答",
        "reply":"DMS 服务将 DMS 的最新版本之一指定为首选版本。此首选版本是将用于自动升级的版本，是客户创建新 DMS 实例的默认选择。"
    },
    {
        "query":"您如何定义最新的首选 AWS DMS 版本？",
        "intention":"知识问答",
        "reply":"新的 DMS 版本仅在广泛测试后发布。新版本发布后，DMS 服务团队会密切监控可靠性指标和客户反馈。若我们确信新版本没有重大问题，则会将该版本标记为新的首选版本，您可以在创建复制实例时看到该版本作为可选项。"
    },
    {
        "query":"DMS 主要版本和次要版本的支持策略期限是否相同？",
        "intention":"知识问答",
        "reply":"AWS DMS 不区分主要版本和次要版本，也不打算采用不同的支持策略。"
    },
    {
        "query":"AWS DMS 会自动将我的实例更新到最新的首选版本吗？",
        "intention":"知识问答",
        "reply":"如果您启用了自动升级，您的复制实例将在最新的首选版本可用时自动更新到该版本。如果您选择退出自动升级，一旦生命周期终止，AWS DMS 就会将您的实例更新到最新的首选版本，并在升级前通过电子邮件和控制台通知传达该信息。您可以在本 [DMS 用户指南](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.EngineVersions.html)中了解有关如何使用 AWS 管理控制台或 AWS CLI 升级 DMS 引擎版本的更多信息。"
    },
    {
        "query":"如何启用自动升级？",
        "intention":"知识问答",
        "reply":"默认情况下，复制实例中的自动升级设置处于打开状态。要使用 AWS CLI、DMS API 或控制台检查此设置或对其进行任何修改，可以使用此[修改复制实例指南](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.Modifying.html)。"
    },
    {
        "query":"升级期间，您的任务会发生什么变化？",
        "intention":"知识问答",
        "reply":"如果迁移任务中的表处于复制持续更改阶段（CDC），则 AWS DMS 会在应用补丁时暂停该任务。在应用补丁后，再从中止的位置继续迁移。  \n 如果应用补丁时，AWS DMS 正在运行满负载操作，则 AWS DMS 会重新启动表的迁移。这些升级将在为复制实例指定的维护时段内进行。您可以在[使用 AWS DMS 维护时段指南](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_ReplicationInstance.MaintenanceWindow.html#CHAP_ReplicationInstance.MaintenanceWindow.Effect)中找到更多详细信息。"
    },
    {
        "query":"我有一个不在支持范围内的版本实例。这对我现有的实例和作业有何影响？ 您对接下来的操作有什么建议？",
        "intention":"知识问答",
        "reply":"在复制实例版本的生命周期终止后，AWS DMS 可能会从控制台中删除发布版本并将您的复制实例升级到最新的首选版本，以便继续提供支持。我们建议您尽快升级到最新的 AWS DMS 版本。"
    },
    {
        "query":"如果我需要更多信息，可以联系谁？",
        "intention":"知识问答",
        "reply":"您可以[联系 AWS 开发人员支持](https://console.aws.amazon.com/support/home)以获取更多信息。"
    },
    {
        "query":"AWS CloudFormation 是什么？",
        "intention":"知识问答",
        "reply":"AWS CloudFormation 是一种可让开发人员和企业轻松创建一系列相关的 AWS 和第三方资源，并以有序且可预测的方式进行预置和管理的服务。"
    },
    {
        "query":"开发人员可以使用 AWS CloudFormation 做什么？",
        "intention":"知识问答",
        "reply":"开发人员可以采用简单的声明式风格来部署和更新计算、数据库以及许多其他资源，从而消除特定资源 API 的复杂性。AWS CloudFormation 旨在允许重复、可预测和安全地管理资源生命周期，同时支持自动回滚、自动状态管理以及跨账户和跨区域管理资源。最新的增强功能和选项允许使用多种方法来创建资源，包括使用 AWS CDK 进行高级语言编码、导入现有资源、检测配置偏差以及新的 Registry，该 Registry 可让您更轻松地创建继承 CloudFormation 许多核心优势的自定义类型。"
    },
    {
        "query":"CloudFormation 与 AWS Elastic Beanstalk 有什么区别？",
        "intention":"知识问答",
        "reply":"这些服务的设计目的是使二者相辅相成。[AWS Elastic Beanstalk](https://aws.amazon.com/cn/elasticbeanstalk/) 提供了一个可在云中轻松部署和运行应用程序的环境。它与开发人员工具相集成，为您提供“一站式”的应用程序生命周期管理体验。如果应用程序工作负载可以作为 Elastic Beanstalk 工作负载进行管理，则您可以在创建和更新应用程序时享受更完善的一体化体验。Elastic Beanstalk 可以在后台使用 CloudFormation 创建和维护资源。如果您的应用程序要求获得更多的自定义权限，那么您可以根据CloudFormation 提供的其他功能来控制您的工作负载。\nAWS CloudFormation 是一种便捷的预置机制，支持种类广泛的 [AWS](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-supported-resources.html) 和第三方资源。它支持不同类型的应用程序的基础需求，如现有的企业级应用程序、旧式应用程序、使用各种 AWS 资源构建的应用程序，以及基于容器的解决方案（包括使用 AWS Elastic Beanstalk 构建而成的解决方案）。\nAWS CloudFormation 支持 Elastic Beanstalk 应用程序环境，将其作为其中一种 AWS 资源类型。例如，这可使您创建和管理 AWS Elastic Beanstalk 托管的应用程序，以及用于存储应用程序数据的 RDS 数据库。还可向该组添加任何其他受支持的 AWS 资源。"
    },
    {
        "query":"AWS CloudFormation 引入了哪些新概念？",
        "intention":"知识问答",
        "reply":"CloudFormation 引入了四个新概念：模板是 JSON 或 YAML 声明性代码文件，其中介绍了部署应用程序需要的所有资源的预期状态。堆栈，运行管理模板中概述的资源组，并允许一起管理这些资源的状态和依赖关系。更改集，指由创建、更新或删除资源的堆栈操作执行的更改的预览。堆栈集，指的是由您一起管理的、可以对组进行复制的一组堆栈。"
    },
    {
        "query":"AWS CloudFormation 支持哪些资源？",
        "intention":"知识问答",
        "reply":"要查看[受支持的 AWS 资源](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-supported-resources.html)及其功能的完整列表，请访问文档发布历史记录中的“受支持的 AWS 服务”页面。\n通过 [AWS CloudFormation Registry](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/registry.html) 和 AWS CloudFormation [自定义资源](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/crpg-walkthrough.html)能够管理其他 AWS 和第三方资源。"
    },
    {
        "query":"我能否管理属于 AWS CloudFormation 堆栈的个体 AWS 资源？",
        "intention":"知识问答",
        "reply":"可以。CloudFormation 并不会阻碍您完全控制基础设施中的所有元素，您仍可以继续使用现有的任何 AWS 和第三方工具来管理您的 AWS 资源。但是，由于 CloudFormation 支持您使用其他规则、最佳实践和合规控制，我们建议您允许 CloudFormation 管理对资源的更改。这种可预测、可控的方法有助于您管理整个应用程序组合中成百上千的资源。"
    },
    {
        "query":"AWS CloudFormation 模板有什么元素？",
        "intention":"知识问答",
        "reply":"CloudFormation 模板是 JSON 或 YAML 格式的文本文件，由以下五种元素组成：\n1.可选的模板参数列表（堆栈创建时提供的输入值）  \n 2.可选的输出值列表（如指向 Web 应用程序的完整 URL）  \n 3.可选的数据表列表，用于查询静态配置值（如 AMI 名称）  \n 4.AWS 资源及其配置值的列表  \n 5.模板文件格式版本号\n创建堆栈时，模板参数可用于在运行时自定义模板的各个方面。例如，创建堆栈时，您可以将 Amazon RDS 数据库大小、Amazon EC2 实例类型、数据库和 Web 服务器端口号传输到 AWS CloudFormation。各个参数可以具有默认值和描述，也可标记为“NoEcho”，以便隐藏您在屏幕上以及 AWS CloudFormation 事件日志中输入的实际值。在创建 AWS CloudFormation 堆栈时，AWS 管理控制台将自动合成并显示一个弹出式对话表单，供您编辑参数值。\n输出值可以非常方便地通过 AWS 管理控制台或命令行工具向用户显示堆栈的重要资源（如 Elastic Load Balancing 负载均衡器或 Amazon RDS 数据库的地址）。您可以通过简单函数来串接字符串参数以及与实际 AWS 资源关联的属性值。模板还可以利用 Registry 资源类型、您自己的自定义私有类型、您自己的宏以及从 AWS Secrets Manager 和AWS System Manager 参数存储中检索配置参数。"
    },
    {
        "query":"AWS CloudFormation 如何选择实际的资源名称？",
        "intention":"知识问答",
        "reply":"您可以在模板中为 AWS 资源分配逻辑名称。创建堆栈时，AWS CloudFormation 会将逻辑名称与对应的实际 AWS 资源的名称绑定。实际资源名称是堆栈和逻辑资源名称的组合。这样就可以从一个模板创建多个堆栈，而不必担心 AWS 资源名称冲突。"
    },
    {
        "query":"我为什么不能命名全部资源？",
        "intention":"知识问答",
        "reply":"虽然 AWS CloudFormation 允许您命名一些资源（如 Amazon S3 存储桶），但是它并不允许您命名全部资源。命名资源限制了模板的重复使用，并会引起资源因更新迭代产生的命名冲突。为了最大限度地减少这些问题的发生，CloudFormation 会根据每个案例的具体情况决定是否支持资源命名。"
    },
    {
        "query":"可否在堆栈创建时使用 AWS CloudFormation 安装软件？",
        "intention":"知识问答",
        "reply":"可以。AWS CloudFormation 提供了一组应用程序引导脚本，您只需在 CloudFormation 模板中进行描述，即可在 EC2 实例上安装资源包、文件和服务。有关详细信息和关于如何操作的说明，请参阅[通过 AWS CloudFormation 引导应用程序](https://s3.amazonaws.com/cloudformation-examples/BoostrappingApplicationsWithAWSCloudFormation.pdf)。\nCloudFormation 也可以与 Systems Manager 相集成，以使用 Systems Manager 自动化文档来驱动和维护软件安装。"
    },
    {
        "query":"AWS CloudFormation 可否与 Chef 一起使用？",
        "intention":"知识问答",
        "reply":"可以。AWS CloudFormation 可用于在 EC2 实例中引导 Chef Server 和 Chef Client 软件。有关详细信息和关于如何操作的说明，请参阅[将 AWS CloudFormation 与 Chef 集成](https://s3.amazonaws.com/cloudformation-examples/IntegratingAWSCloudFormationWithOpscodeChef.pdf)。"
    },
    {
        "query":"AWS CloudFormation 可否与 Puppet 一起使用？",
        "intention":"知识问答",
        "reply":"可以。AWS CloudFormation 可用于在 EC2 实例中引导 Puppet Master 和 Puppet Client 软件。有关详细信息和关于如何操作的说明，请参阅“将 AWS CloudFormation 与 Puppet 集成”。"
    },
    {
        "query":"AWS CloudFormation 可否与 Terraform 一起使用？",
        "intention":"知识问答",
        "reply":"可以。CloudFormation 可以在 EC2 实例上引导 Terraform 引擎，您可以通过 Terraform 资源提供程序在堆栈中创建资源，从而利用堆栈状态管理、依赖关系、稳定和回滚。"
    },
    {
        "query":"AWS CloudFormation 是否支持 Amazon EC2 标记功能？",
        "intention":"知识问答",
        "reply":"可以。支持标记功能的 Amazon EC2 资源也可在 AWS 模板中进行标记。标记值可以引用模板参数、其他资源名称、资源属性值（如地址），或者由简单函数（如串接的字符串列表）计算而得到的值。CloudFormation 使用所属 CloudFormation 堆栈的名称自动标记 Amazon EBS 卷和 Amazon EC2 实例。"
    },
    {
        "query":"能否访问 Amazon EC2 实例，或 Auto Scaling 启动配置用户数据字段？",
        "intention":"知识问答",
        "reply":"可以。您可以使用简单函数来串接字符串参数和 AWS 资源的属性值，并将它们传递到模板中的用户数据字段。请参阅我们的示例模板，进一步了解这些简易函数。"
    },
    {
        "query":"堆栈中某个资源无法成功创建时会发生什么情形？",
        "intention":"知识问答",
        "reply":"默认情况下，启用“错误时自动回滚”功能。如果各项操作均成功，将指示 CloudFormation 创建或更新堆栈中的所有资源。如果任一操作有误，那么 CloudFormation 会将堆栈恢复到最后一个已知的稳定配置。例如，当您意外超过了 Elastic IP 地址的默认限值，或者无权访问要尝试运行的 EC2 AMI 时，就可以使用此功能。这一功能可以完全创建堆栈，或者使其恢复到完全未建状态，从而简化系统管理以及基于 CloudFormation 构建的分层式解决方案。"
    },
    {
        "query":"堆栈创建能否等待我的应用程序完成启动？",
        "intention":"知识问答",
        "reply":"可以。CloudFormation 提供了 *WaitCondition* 资源，它可以起到屏障作用，在从您的应用程序或管理系统等外部资源收到完成信号前，阻止其他资源的创建。其他选项包括使用 AWS Lambda 函数创建自定义逻辑。"
    },
    {
        "query":"堆栈删除后，能否保存我的数据？",
        "intention":"知识问答",
        "reply":"可以。CloudFormation 允许您在模板中定义资源的删除策略。您可以指定在删除 Amazon EBS 卷或 Amazon RDS 数据库实例前为它们创建快照。也可以指定在删除堆栈时应当保留某个资源，而不将其删除。如果要在删除堆栈时保留 Amazon S3 存储桶，可以使用此功能。"
    },
    {
        "query":"创建堆栈后，能否对其进行更新？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 CloudFormation，以可控且可预测的方式修改和更新现有堆栈中的资源。通过使用模板来管理堆栈更改，您就可以对 AWS 基础设施应用版本控制，方法与对其中运行的软件应用版本控制一样。"
    },
    {
        "query":"能否在 Virtual Private Cloud (VPC) 中创建堆栈？",
        "intention":"知识问答",
        "reply":"可以。CloudFormation 支持创建 VPC、子网、网关、路由表和网络 ACL，还支持在 VPC 中创建弹性 IP、Amazon EC2 实例、EC2 安全组、Auto Scaling 组、Elastic Load Balancer、Amazon RDS 数据库实例和 Amazon RDS 安全组等资源。"
    },
    {
        "query":"如何加入 CloudFormation 社区？",
        "intention":"知识问答",
        "reply":"请加入 [AWS CloudFormation GitHub 社区](https://github.com/aws-cloudformation)。"
    },
    {
        "query":"是否能管理在 CloudFormation 外部创建的资源？",
        "intention":"知识问答",
        "reply":"能！ 借助资源导入功能，您可以使用[资源导入](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resource-import.html)功能将现有资源引入 AWS CloudFormation 管理中。"
    },
    {
        "query":"如何注册 AWS CloudFormation？",
        "intention":"知识问答",
        "reply":"若要注册 CloudFormation，请单击 [CloudFormation 产品页面](https://aws.amazon.com/cn/cloudformation/)上的创建免费账户。注册后，请参阅 CloudFormation [文档](https://aws-cms.aka.amazon.com/documentation/cloudformation/)，其中包含了入门指南。"
    },
    {
        "query":"注册 AWS CloudFormation 时为什么需要验证我的电话号码？",
        "intention":"知识问答",
        "reply":"注册 CloudFormation 要求您在 AWS 上登记您的有效电话号码和电子邮件地址，以便我们在需要时联系您。验证您的电话号码只需要几分钟时间。注册过程中您会接到一个自动电话，然后您需要使用电话键盘输入 PIN 码。"
    },
    {
        "query":"注册后，如何开始使用？",
        "intention":"知识问答",
        "reply":"了解如何启动 CloudFormation 最好的方法是仔细阅读技术文档中提供的入门指南。只需短短几分钟，您就能部署和使用我们提供的某个示例模板，这些模板演示如何创建运行 WordPress 等应用程序时所需的基础设施。还有其他各种来源的 CloudFormation 培训，包括第三方课程提供程序、网络教程和文章等。有关更多信息，请参阅 [CloudFormation 资源](https://aws.amazon.com/cn/cloudformation/resources/)。"
    },
    {
        "query":"是否有示例模板可用来检验 AWS CloudFormation？",
        "intention":"知识问答",
        "reply":"有。CloudFormation 提供了[示例模板](https://aws.amazon.com/cn/cloudformation/resources/templates/)，您可以使用这些示例模板来试运行相关服务，并了解其功能。我们的示例模板演示了在遵循可用区冗余、扩展和警报最佳实践的基础上，互连和协同使用多种 AWS 资源的方法。您只需打开 AWS 管理控制台，单击“创建堆栈”，然后按照步骤选择和启动其中的一个示例即可使用我们的示例模板。模板创建后，您可以在控制台中选择堆栈并检查“模板”和“参数”选项卡，以查看用于创建各个堆栈的模板文件的详细信息。GitHub 上也提供了一些示例模板。"
    },
    {
        "query":"AWS CloudFormation Registry 是什么？",
        "intention":"知识问答",
        "reply":"AWS CloudFormation Registry 是一种托管服务，帮助您注册、使用和发现 AWS 和第三方资源类型。第三方资源类型在使用前必须注册，然后才能利用它们通过 AWS CloudFormation 模板预置资源。有关详细信息，请参阅我们文档中的[使用 AWS CloudFormation 注册表](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/registry.html)。"
    },
    {
        "query":"AWS CloudFormation 中的资源类型是什么？",
        "intention":"知识问答",
        "reply":"资源提供程序是一组资源类型，具有通过创建、读取、更新、删除和列出操作控制底层资源的规格和处理程序。您可以使用资源提供商通过 CloudFormation 对资源进行建模和预置。例如，AWS::EC2::Instance 就是一种来自 Amazon EC2 提供商的资源类型。您可以使用此类型，通过 CloudFormation 对 Amazon EC2 实例进行建模和预置。您可以使用 CloudFormation Registry 构建和使用资源提供程序，对第三方资源进行建模和预置，例如 SaaS 监控、团队生产力或资源代码管理资源。"
    },
    {
        "query":"AWS 与第三方资源提供商之间有什么差别？",
        "intention":"知识问答",
        "reply":"AWS 与第三方资源提供商之间的差别是其来源。AWS 资源提供商由 Amazon 和 AWS 构建和维护，用于管理 AWS 资源和服务。例如，有三种 AWS 资源提供商可帮助您管理 Amazon DynamoDB、AWS Lambda 和 Amazon EC2 资源。这些提供商包含多种资源类型，例如 AWS::DynamoDB::Table、AWS::Lambda::Function 和 AWS::EC2::Instance。如需完整参考，请转到我们的文档。\n第三方资源提供商由其他公司、组织或开发人员社区构建。它们可帮助您管理 AWS 和非 AWS 资源，例如 AWS 应用程序资源，以及非 AWS SaaS 软件服务，例如监控、团队生产力、事故管理或版本控制管理工具。"
    },
    {
        "query":"什么是资源架构？",
        "intention":"知识问答",
        "reply":"资源架构以结构化且一致的格式定义资源类型。此架构还用于使资源类型的定义生效。此架构包括给定资源类型的所有受支持的参数和属性，以及使用尽可能低的权限创建资源所需的权限。"
    },
    {
        "query":"如何开发资源类型？",
        "intention":"知识问答",
        "reply":"使用 [AWS CloudFormation CLI](https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/what-is-cloudformation-cli.html) 构建资源提供商。首先，您可以为资源定义简单的声明性架构，其中包括所需的权限以及与其他资源的关系。然后，使用 CloudFormation CLI 为资源生命周期处理程序（创建、读取、更新、删除和列出）生成支架以及用于单元和集成测试的测试桩。"
    },
    {
        "query":"如何注册资源提供商？",
        "intention":"知识问答",
        "reply":"您可以使用开源的 [AWS CloudFormation CLI](https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/what-is-cloudformation-cli.html) 或者直接调用 RegisterType 及相关的 Registry API，它们可通过 AWS SDK 和 AWS CLI 获得。有关详细信息，请参阅我们文档中的[使用 AWS CloudFormation 注册表](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/registry.html)。AWS 资源提供商可以直接使用，无需任何注册步骤。"
    },
    {
        "query":"AWS CloudFormation Public Registry 是什么",
        "intention":"知识问答",
        "reply":"CloudFormation Public Registry 是扩展工具的新型可搜索托管目录，这些扩展工具包含 AWS 合作伙伴网络 (APN) 合作伙伴和开发人员社区发布的资源类型（预置逻辑）和[模块](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/modules.html)。通过 CloudFormation Public Registry，现在任何人都可以在 Registry 上发布资源类型和模块。客户可以轻松地发现和使用这些已发布的资源类型和模块，无需自行构建和维护。"
    },
    {
        "query":"资源和模块有什么不同？",
        "intention":"知识问答",
        "reply":"资源类型是包含预置逻辑的代码包，可供您管理资源（例如，Amazon EC2 实例或 Amazon DynamoDB 表）从创建到删除的生命周期，简化了复杂的 API 交互。资源类型包含架构，它定义资源的形状和属性，以及预置、更新、删除和描述资源所需的逻辑。CloudFormation Public Registry 中的第三方资源类型示例包括 Datadog 监视器、MongoDB 地图集项目或 Atlassian Opsgenie 用户以及其他。  \n   \n 模块是可在多个 CloudFormation 模板之间重复使用的构建块，就像原生 CloudFormation 资源那样使用。这些构建块可用于单个资源，例如定义 Amazon Elastic Compute Cloud (Amazon EC2) 实例的最佳实践，也可以用于多个资源，以定义应用程序架构的常见模式。"
    },
    {
        "query":"如何开发自己的资源或模块并添加到 AWS CloudFormation Registry？",
        "intention":"知识问答",
        "reply":"您可以参阅此[链接](https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-types.html)开发自己的资源或模块并添加到 AWS CloudFormation Registry。您可以选择以私有方式发布，也可将其发布到 Public Registry。"
    },
    {
        "query":"对于创建堆栈失败期间回滚的资源，我是否需要付费？",
        "intention":"知识问答",
        "reply":"是的。无论整个堆栈能否创建成功，模板实例化期间创建的 AWS 资源均需收费。"
    },
    {
        "query":"模板或堆栈的数量是否有限制？",
        "intention":"知识问答",
        "reply":"有关您可以创建的 AWS CloudFormation 堆栈最大数的更多信息，请参阅 [AWS CloudFormation 配额](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html?pg=fq&sec=lr)中的堆栈。请在[此处](https://aws.amazon.com/cn/contact-us/cloudformation-request/)填写增加限制的申请表，我们将在两个工作日内答复您的请求。"
    },
    {
        "query":"描述字段的长度是否有限制？",
        "intention":"知识问答",
        "reply":"有关更多信息，请参阅 AWS 文档中的 [AWS CloudFormation 配额](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html?pg=fq&sec=lr)和[参数](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html?pg=fq&sec=lr)、[资源](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/resources-section-structure.html?pg=fq&sec=lr)和[输出](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/outputs-section-structure.html?pg=fq&sec=lr)中的模板说明。"
    },
    {
        "query":"模板中参数或输出的数量是否有限制？",
        "intention":"知识问答",
        "reply":"有关您可以在模板中指定的参数和输出数量的更多信息，请参阅 [AWS CloudFormation 配额](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html?pg=fq&sec=lr)中的参数和输出部分。"
    },
    {
        "query":"堆栈中可以创建的资源数量是否受限？",
        "intention":"知识问答",
        "reply":"有关您可以在模板中声明的资源数量的更多信息，请参阅 [AWS CloudFormation 配额](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cloudformation-limits.html?pg=fq&sec=lr)中的资源。最佳做法是创建较小的模板和堆栈，并跨多个堆栈对应用程序进行模块化，这是为了最大程度地减小资源更改的影响半径，并更快地解决存在多个资源依赖关系的问题，因为与大型资源组相比，较小的资源组具有更少的依赖关系。"
    },
    {
        "query":"各个区域的 AWS CloudFormation 服务的接入点有哪些？",
        "intention":"知识问答",
        "reply":"有关各个区域的终端节点，请参阅技术[文档](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-endpoints.html)中的 [AWS CloudFormation 终端节点](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/using-cfn-endpoints.html)。"
    },
    {
        "query":"目前有哪些 AWS 区域支持 AWS CloudFormation？",
        "intention":"知识问答",
        "reply":"请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 CloudFormation 在不同区域的具体提供情况。\n了解更多有关 AWS CloudFormation 定价的信息"
    },
    {
        "query":"什么是 AWS OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"AWS OpsWorks for Chef Automate 可以提供一个完全托管的 Chef 服务器和全套自动化工具，让您可以通过工作流自动化来实现连续部署以及合规性与安全性的自动测试，并能通过一个用户界面查看各种节点及其状态。Chef 服务器可以处理软件与操作系统配置、软件包安装和数据库设置等多种操作任务，让您实现全栈自动化。Chef 服务器可以集中存储您的配置任务，并将其提供给任意规模的计算环境中的每个节点，节点数量既可以是几个也可以是数千个。OpsWorks for Chef Automate 与 Chef 社区中提供的各种工具和说明书完全兼容，并会将新的节点自动注册到您的 Chef 服务器。"
    },
    {
        "query":"OpsWorks for Chef Automate 与 OpsWorks Stacks 有什么区别？",
        "intention":"知识问答",
        "reply":"OpsWorks for Chef Automate 是一种配置管理服务，可以帮助您即时预置 Chef 服务器，并让该服务运行此服务器，包括执行备份和软件升级。该服务与 Chef 的 Supermarket 说明书和配方完全兼容。可以支持 TestKitchen 和 Knife 等本机 Chef 工具。OpsWorks Stacks 服务可以帮助您使用安装在 Amazon EC2 实例上的嵌入式 Chef Solo 客户端在 AWS 上对应用程序进行建模、预置和管理。要了解更多信息，请参阅 [OpsWorks Stacks](https://aws.amazon.com/cn/opsworks/stacks/)。"
    },
    {
        "query":"哪些人应该使用 OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"如果客户希望自己的配置管理工作与 Chef（包括所有社区脚本和工具）完全兼容并且不会产生运营开销，则应该采用 OpsWorks for Chef Automate。"
    },
    {
        "query":"如何访问 OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"OpsWorks for Chef Automate 服务可以通过 AWS 管理控制台、AWS 软件开发工具包和 AWS 命令行界面 (CLI) 访问。设置完 Chef 服务器后，您还可以通过 Knife 等与 Chef 兼容的工具对其进行管理。"
    },
    {
        "query":"OpsWorks for Chef Automate 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)了解详细信息。"
    },
    {
        "query":"OpsWorks for Chef Automate 是否存在任何限制？",
        "intention":"知识问答",
        "reply":"默认服务限制为：\n如果您想更改这些限制，请联系 AWS Support。"
    },
    {
        "query":"服务器必须满足哪些网络要求才能与 OpsWorks for Chef Automate 配合使用？",
        "intention":"知识问答",
        "reply":"您的服务器必须能够连接到 AWS 公共终端节点。请参阅[文档](https://docs.aws.amazon.com/general/latest/gr/rande.html#opsworks_region)了解详细信息。"
    },
    {
        "query":"什么是 Chef？OpsWorks for Chef Automate 如何使用 Chef？",
        "intention":"知识问答",
        "reply":"Chef Automate 是 [Chef Software, Inc.](https://www.chef.io/automate/) 的软件服务包，可以通过代码自动配置、部署和管理应用程序。OpsWorks for Chef Automate 使用 Chef 配方在 Amazon EC2 实例和本地服务器上部署和配置软件组件。Chef 拥有一个丰富的生态系统，带有上百种可以在 AWS 中使用的说明书，例如用于管理 PostgreSQL、Nginx、Solr 等的说明书。"
    },
    {
        "query":"什么是 Chef Automate？",
        "intention":"知识问答",
        "reply":"Chef Automate 可以为您提供一个全堆栈式持续部署管道，支持自动测试合规性和安全性，并能让您全面了解各种情况。其通过 Chef 实现基础设施自动化、通过 InSpec 实现合规性自动化，并通过 Habitat 实现应用程序自动化。在 Chef Automate 的助力下，您可以将自己的公司转型成一个由软件驱动并且高度协作的组织。要了解更多信息，请参阅 [Chef Automate 产品详细信息页面](https://www.chef.io/automate/)。"
    },
    {
        "query":"如何使用 Chef Automate 控制台？",
        "intention":"知识问答",
        "reply":"Chef Automate 附带自己的控制台。Chef Automate 控制台可以通过 AWS 管理控制台上的 OpsWorks 链接访问。单击该链接后，系统会提示您提供在设置 Chef Automate 服务器时分配到的凭证。"
    },
    {
        "query":"我是一名 AWS OpsWorks Stacks 客户。我是否应该迁移到 OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"对于希望实现与 Chef 服务器的全面兼容性的 OpsWorks Stacks 客户，我们鼓励其使用 OpsWorks for Chef Automate。要了解有关 OpsWorks Stacks 的更多信息，请参阅 [OpsWorks Stacks 产品详细信息页面](https://aws.amazon.com/cn/opsworks/stacks/)。"
    },
    {
        "query":"如何从 OpsWorks Stacks 迁移到 OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"迁移之前，您必须先修改 OpsWorks 说明书，然后才能在 Chef 服务器上使用。但是有些说明书无需修改也能使用。如果您在使用 OpsWorks 实例扩展 (基于时间或基于负载)，则必须改为使用 EC2 Auto Scaling 组和 OpsWork Chef 的节点注册功能。之后，您就可以通过 Chef 的可见性控制台或 Knife 来使用 Chef 服务器和节点。"
    },
    {
        "query":"支持哪些版本的 Chef？",
        "intention":"知识问答",
        "reply":"OpsWorks for Chef Automate 服务会定期将您的 Chef 服务器升级到推荐的最新版本。请参阅我们的[文档](https://docs.aws.amazon.com/opsworks/latest/userguide/welcome_opscm.html)，了解支持的最新版本。建议您在与 AWS OpsWorks for Chef Automate 服务器关联的节点上运行最新的稳定版 [chef 客户端版本](https://downloads.chef.io/chef/stable)。"
    },
    {
        "query":"哪些云资源能够为 AWS OpsWorks for Chef Automate 服务器提供支持？",
        "intention":"知识问答",
        "reply":"AWS OpsWorks for Chef Automate 可以使用 Amazon EC2、Amazon EBS、Amazon S3 和 Amazon CloudWatch 等多种成熟的 AWS 功能和服务，用于创建构成托管 Chef 服务器的组件。OpsWorks for Chef Automate 可以使用 Amazon Linux Amazon Machine Image (AMI)。"
    },
    {
        "query":"如何备份 Chef 服务器？",
        "intention":"知识问答",
        "reply":"您可以设定周期性备份 Chef 服务器，频率为每日一次或每周一次。服务会将备份存储在 Amazon S3 中。另外，您也可以根据需要选择创建手动备份。"
    },
    {
        "query":"我能够针对每台 Chef 服务器保存多少个备份？",
        "intention":"知识问答",
        "reply":"备份存储在 Amazon S3 中，并会产生额外费用。您最多可以将备份的保留数量设定为 30 个。您可以使用 AWS Support 渠道提交服务请求，以便更改这一限制。"
    },
    {
        "query":"如何将 Chef 服务器恢复到之前的时间点？",
        "intention":"知识问答",
        "reply":"您可以浏览可用的备份，然后从中选择一个要将 Chef 服务器恢复到的时间点。服务器备份只包含 Chef 软件持久性数据，例如说明书和已注册的节点。"
    },
    {
        "query":"可以将哪些资源连接到 Chef 服务器？",
        "intention":"知识问答",
        "reply":"您可以连接运行着受支持的操作系统并能通过 Internet 访问 OpsWorks for Chef Automate 服务器的任何 EC2 实例或本地服务器。您需要为连接的各项资源按小时支付费用。"
    },
    {
        "query":"如何将节点注册到 Chef 服务器？",
        "intention":"知识问答",
        "reply":"您将通过控制台获得用户数据代码段。您可以将这些代码段放置到一个 EC2 Auto Scaling 组中。这些代码段可以确保您的实例作为 Chef 节点注册到 Chef 服务器中，并运行相应的 Chef 配方。本地服务器需要您安装 Chef 客户端代理软件，然后才能将服务器注册到 Chef 服务器。"
    },
    {
        "query":"如何获得 Chef 的相关培训？",
        "intention":"知识问答",
        "reply":"您可以从 Chef 的[网站](https://training.chef.io/)选择您首选的 Chef Automate 培训方式。"
    },
    {
        "query":"如何让底层 Chef 服务器保持运行并处于最新状态？",
        "intention":"知识问答",
        "reply":"您的托管配置管理服务器会在您设置的维护时段内更新到最新版本的 Chef Automate。OpsWorks for Chef Automate 还会定期运行安全更新和操作系统软件包更新。"
    },
    {
        "query":"什么是 OpsWorks for Chef Automate 维护时段？",
        "intention":"知识问答",
        "reply":"维护时段是每日或每周内为期一小时的时间段，OpsWorks for Chef Automate 在这一时间段内进行没有重大更改的 Chef 版本更新、安全更新和操作系统软件包更新。例如，如果您选择的维护时段始于每周日凌晨 2 点，则 OpsWorks for Chef Automate 会在每周日凌晨 2 点到 3 点之间进行平台更新。\n维护时段针对单独的 Chef 服务器，因此您可以为不同的 Chef 服务器设置不同的维护时段。您可以使用 OpsWorks for Chef Automate 控制台、AWS CLI 或 API 来更改执行维护的时间。"
    },
    {
        "query":"如何设置维护时段？",
        "intention":"知识问答",
        "reply":"维护时段默认处于启用状态，可以在 Chef 服务器设置阶段进行设置。您可以使用 AWS 管理控制台、CLI 或 API 在之后更改设置。"
    },
    {
        "query":"OpsWorks for Chef Automate 会执行哪些类型的版本更新？",
        "intention":"知识问答",
        "reply":"只要更新包括向后兼容的改变，OpsWorks for Chef Automate 就会自动执行版本更新。当有新版本的 Chef 软件时，只要版本更新通过了 AWS 测试，系统维护便会自动在服务器上更新 Chef Automate 和 Chef Server 的版本。AWS 会执行广泛的测试来验证 Chef 升级是否可直接用于生产且不会中断客户现有的环境，因此在 Chef 软件发布后，需要过一段时间才可将其用于现有的 OpsWorks for Chef Automate 服务器。"
    },
    {
        "query":"在什么时候执行主要版本更新？如何更新？",
        "intention":"知识问答",
        "reply":"您可以随时使用 AWS OpsWorks for Chef Automate 控制台、API 或 CLI 执行主要版本更新。"
    },
    {
        "query":"AWS OpsWorks for Chef Automate 如何应用更新内容？",
        "intention":"知识问答",
        "reply":"更新内容直接应用到 Chef 服务器运行时所在的托管 EC2 实例上。如果 OpsWorks for Chef Automate 运行状况系统在更新期间检测到任何问题，则 OpsWorks for Chef Automate 将回滚变更，并在下一个维护时段重试。"
    },
    {
        "query":"Chef 服务器在维护时段内是否可用？",
        "intention":"知识问答",
        "reply":"在应用维护更新时，Chef 服务器不可用。您连接的节点会进入等待服务器状态，直到维护完成为止。连接的节点将继续正常运行。"
    },
    {
        "query":"我将如何收到 OpsWorks for Chef Automate 新版本可用的通知？",
        "intention":"知识问答",
        "reply":"您会通过 OpsWorks for Chef Automate 控制台收到有关 Chef 新版本的通知。如果您的 Chef 服务器在维护时段内更新，则服务控制台会通知您这一消息。"
    },
    {
        "query":"在哪里可以找到平台版本间变更的详细信息？",
        "intention":"知识问答",
        "reply":"Chef Automate 版本间变更的详细信息位于 [Chef Automate 发布说明](https://docs.chef.io/release_notes_automate/)页面上。"
    },
    {
        "query":"平台版本更新多久发布一次？",
        "intention":"知识问答",
        "reply":"每年的版本发布次数不固定，具体取决于 Chef 发布 Chef Automate 补丁的频率和 AWS 进行的验收测试。"
    },
    {
        "query":"如何开始使用 OpsWorks for Chef Automate？",
        "intention":"知识问答",
        "reply":"开始使用 OpsWorks for Chef Automate 的最佳方式是查看技术[文档](http://docs.aws.amazon.com/opsworks/latest/userguide/gettingstarted-opscm.html)的“AWS OpsWorks for Chef Automate 入门”一章。"
    },
    {
        "query":"如何创建 Chef 说明书和配方？",
        "intention":"知识问答",
        "reply":"最简单的方法是从使用现有 Chef 配方入手。许多公共存储库都包含 Chef 说明书，其附带的配方只需少量修改或无需修改即可运行。OpsWorks for Chef Automate 入门套件还包含一个示例 Chef 配方并介绍了其工作原理。"
    },
    {
        "query":"是否可以使用 Chef Supermarket 中的社区说明书？",
        "intention":"知识问答",
        "reply":"支持。OpsWorks for Chef Automate 可以让您实现与 Chef Automate 完全兼容的配置管理。您可以使用[社区编写的说明书](https://supermarket.chef.io/)，无需进行任何特定于 AWS 的修改。"
    },
    {
        "query":"如何将 Chef 节点升级到新版本？",
        "intention":"知识问答",
        "reply":"您可以使用 [Chef 混合配方](https://github.com/hw-cookbooks/omnibus_updater)在方便的时候进行 Chef 节点升级。虽然 OpsWorks 会为您定期执行 Chef 服务器版本升级，但旧版 Chef 节点仍然能够继续运行。"
    },
    {
        "query":"OpsWorks for Chef Automate 服务器是否支持 Knife 和 Test Kitchen 等社区工具？",
        "intention":"知识问答",
        "reply":"支持。OpsWorks for Chef Automate 可以让您实现与 Chef Automate 完全兼容的配置管理。您可以将相同的工具生态系统用作本地 Chef Automate 服务器。"
    },
    {
        "query":"是否有能够用来检查 OpsWorks for Chef Automate 的示例说明书？",
        "intention":"知识问答",
        "reply":"有。OpsWorks for Chef Automate 入门套件包含一个示例说明书，您可以使用该说明书来试用产品并了解其功能。"
    },
    {
        "query":"是否能将 AWS Identity and Access Management (IAM) 与 OpsWorks for Chef Automate 配合使用？",
        "intention":"知识问答",
        "reply":"能。具有相应权限的 IAM 用户可以使用 AWS OpsWorks for Chef Automate。Chef 用户不受 IAM 管理，必须在 Chef Automate 中预置。"
    },
    {
        "query":"如何创建 IAM 用户？",
        "intention":"知识问答",
        "reply":"您可以使用 [IAM 控制台](https://console.aws.amazon.com/iam/)、IAM 命令行界面 (CLI) 或 IAM API 来预置 IAM 用户。默认情况下，IAM 用户在获得权限前不能访问 AWS 服务。"
    },
    {
        "query":"我是否具有 OpsWorks for Chef Automate 服务器 EC2 实例的根访问权限？",
        "intention":"知识问答",
        "reply":"具有。您可以提供一个 SSH 密钥对，以便启用对 OpsWorks for Chef Automate 服务器 EC2 实例的根访问权限。OpsWorks for Chef Automate 可以为您提供用于执行常见操作任务的工具，因此我们建议您禁用 SSH 访问。"
    },
    {
        "query":"在哪里可以找到有关 AWS 安全性和在 AWS 上运行应用程序的更多信息？",
        "intention":"知识问答",
        "reply":"请参阅 Amazon Web Services：安全过程概述和 [AWS 安全中心](https://aws.amazon.com/cn/security/)。"
    },
    {
        "query":"我是否能获取从我的账户发起的 OpsWorks for Chef Automate API 调用的历史记录，以便进行安全分析并排除故障？",
        "intention":"知识问答",
        "reply":"能。要获取从您的账户发起的 OpsWorks for Chef Automate API 调用的历史记录，您只需在 AWS 管理控制台中打开 AWS CloudTrail 即可。"
    },
    {
        "query":"我是否需要为连接到 OpsWorks for Chef Automate 服务器的 EC2 实例和本地服务器付费？",
        "intention":"知识问答",
        "reply":"您需要为连接到 AWS OpsWorks for Chef Automate 服务器的每个 EC2 实例和本地服务器按小时支付费用。既没有最低费用，也无需预先承诺。有关更多信息，请参阅我们的[定价页面](https://aws.amazon.com/cn/opsworks/chefautomate/pricing/)。"
    },
    {
        "query":"AWS Support 是否可以为 OpsWorks for Chef Automate 提供支持？",
        "intention":"知识问答",
        "reply":"可以。[AWS Support](https://aws.amazon.com/cn/premiumsupport/) 可以帮助您解决与使用 OpsWorks for Chef Automate 相关的问题。请参阅 [AWS 支持计划比较页面](https://aws.amazon.com/cn/premiumsupport/compare-plans/)了解详细信息。"
    },
    {
        "query":"还有哪些支持选项可用？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS OpsWorks 开发论坛来了解 AWS 社区中的现有知识，从而促进自身的发展。请参阅 [AWS OpsWorks 论坛页面](https://forums.aws.amazon.com/forum.jspa?forumID=153)了解详细信息。\n开始使用 AWS OpsWorks for Chef Automate 构建"
    },
    {
        "query":"什么是 AWS CloudTrail？",
        "intention":"知识问答",
        "reply":"CloudTrail 通过跟踪用户活动和 API 使用，支持审计、安全监控和操作故障排除。CloudTrail 记录、持续监控和保留与您的 AWS 基础设施中操作相关的账户活动，让您能够控制存储、分析和修复操作。"
    },
    {
        "query":"CloudTrail 有哪些优势？",
        "intention":"知识问答",
        "reply":"CloudTrail 可以帮助您证明合规性、改善安保状况，并跨区域和账户整合活动记录。CloudTrail 可通过记录账户上执行的操作来让您深入了解用户活动。CloudTrail 可记录每个操作的重要信息，包括请求的发出方、使用的服务、执行的操作、操作的参数，以及 AWS 服务返回的响应元素。这些信息能够帮助您跟踪 AWS 资源的变更情况，帮助您解决操作性问题。CloudTrail 可使您更轻松地确保符合内部策略和监管标准。有关更多详细信息，请参阅 AWS 合规性白皮书 [Security at Scale: Logging in AWS](https://d1.awsstatic.com/whitepapers/compliance/AWS_Security_at_Scale_Logging_in_AWS_Whitepaper.pdf)。"
    },
    {
        "query":"哪些人应该使用 CloudTrail？",
        "intention":"知识问答",
        "reply":"如果您需要审计活动、监控安全状况或对操作问题进行故障排查，请使用 CloudTrail。"
    },
    {
        "query":"如果我是 AWS 的新客户或现有客户，且没有设置 CloudTrail，我是否需要启用或设置某些选项才能查看我的账户活动？",
        "intention":"知识问答",
        "reply":"不需要。您无需进行任何操作即可查看账户活动。您可以访问 [AWS CloudTrail 控制台](https://console.aws.amazon.com/cloudtrail/)或使用 AWS CLI 查看过去 90 天的账户活动。"
    },
    {
        "query":"CloudTrail 事件历史记录是否展示了账户内的所有账户活动？",
        "intention":"知识问答",
        "reply":"AWS CloudTrail 将仅显示您正在查看的当前区域在过去 90 天的 CloudTrail 事件历史记录结果，并支持一系列 [AWS 服务](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/view-cloudtrail-events-supported-services.html)。这些事件仅限于创建、修改和删除 API 调用和账户活动的管理事件。要获取账户活动（包括所有管理事件、数据事件和只读活动）的完整记录，您必须配置 CloudTrail 跟踪。"
    },
    {
        "query":"我可以使用哪些搜索筛选条件来查看账户活动？",
        "intention":"知识问答",
        "reply":"您可以指定时间范围和以下任一属性：事件名称、用户名称、资源名称、事件源、事件 ID 和资源类型。"
    },
    {
        "query":"如果没有配置跟踪，我是否可以使用 lookup-events CLI 命令？",
        "intention":"知识问答",
        "reply":"可以。您可以访问 [CloudTrail 控制台](https://console.aws.amazon.com/cloudtrail/)或使用 CloudTrail API/CLI 查看过去 90 天的账户活动。"
    },
    {
        "query":"创建跟踪后，我可以获得哪些额外的 CloudTrail 功能？",
        "intention":"知识问答",
        "reply":"设置 CloudTrail 跟踪，将 CloudTrail 事件传送至 Amazon Simple Storage Service（S3）、Amazon CloudWatch Logs 和 Amazon CloudWatch Events。这有助于您使用多种功能来存档、分析和响应 AWS 资源中发生的更改。"
    },
    {
        "query":"我能否限制用户访问 CloudTrail 事件历史记录？",
        "intention":"知识问答",
        "reply":"可以。CloudTrail 与 [AWS Identity and Access Management](https://aws.amazon.com/cn/iam/)（IAM）相集成，帮助您控制对 CloudTrail 和 CloudTrail 所需的其他 AWS 资源的访问。这包括限制查看和搜索账户活动的权限。从用户 IAM policy 中删除“cloudtrail:LookupEvents”，以阻止 IAM 用户查看账户活动。"
    },
    {
        "query":"在账户创建时启用 CloudTrail 事件历史记录是否会产生相关成本？",
        "intention":"知识问答",
        "reply":"使用 CloudTrail 事件历史记录查看或搜索账户活动不会产生任何相关成本。"
    },
    {
        "query":"是否可以关闭账户的 CloudTrail 事件历史记录功能？",
        "intention":"知识问答",
        "reply":"对于创建的任何 CloudTrail 跟踪，您可以停止记录或删除这些跟踪。这也将停止将账户活动传输到您指定为跟踪配置的一部分的 Amazon S3 存储桶，并停止传输 CloudWatch Logs（如果已配置）。过去 90 天的账户活动仍将收集并显示在 CloudTrail 控制台中，您可以通过 AWS 命令行界面（CLI）进行查看。"
    },
    {
        "query":"CloudTrail 支持哪些服务？",
        "intention":"知识问答",
        "reply":"CloudTrail 可记录来自大多数 AWS 服务的账户活动和服务事件。有关支持的服务列表，请参阅 CloudTrail 用户指南中的 [CloudTrail 支持的服务](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-supported-services.html)。"
    },
    {
        "query":"是否能够记录从 AWS 管理控制台进行的 API 调用？",
        "intention":"知识问答",
        "reply":"可以。CloudTrail 会记录从任何客户端进行的 API 调用。AWS 管理控制台、AWS 软件开发工具包（SDK）、命令行工具和更高级别的 AWS 服务都会调用 AWS API 操作，因此上述调用均会予以记录。"
    },
    {
        "query":"日志文件在被传送到我的 S3 存储桶之前，会在哪里进行存储和处理？",
        "intention":"知识问答",
        "reply":"具有区域端点的服务（如 Amazon Elastic Compute Cloud [EC2] 或 Amazon Relational Database Service [RDS]）的活动信息将在执行操作的同一区域进行捕获和处理。然后会将其传送到与您的 S3 存储桶相关联的区域。具有单一端点的服务（如 IAM 和 AWS Security Token Service（STS））的活动信息将在端点所在的区域进行捕获。然后会在配置 CloudTrail 跟踪的地区进行处理，并传送到与您的 S3 存储桶相关联的地区。"
    },
    {
        "query":"将一个跟踪应用到所有 AWS 区域意味着什么？",
        "intention":"知识问答",
        "reply":"将一个跟踪到所有 AWS 区域是指创建一个可记录存储您的数据的所有区域内 AWS 账户活动的跟踪。此设置还将应用于添加的所有新区域。有关区域和分区的更多详细信息，请参阅 [Amazon 资源名称和 AWS 服务命名空间页面](http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html)。"
    },
    {
        "query":"将一个跟踪应用到所有区域有什么好处？",
        "intention":"知识问答",
        "reply":"您只需调用一次 API 或进行几次选择，即可在分区内的所有区域创建和管理跟踪。您将在一个 S3 存储桶或 CloudWatch Logs 组中收到在您的 AWS 账户中跨所有区域进行的账户活动的记录。当 AWS 发布新区域时，您无需执行任何操作即可收到包含该新区域的事件历史记录的日志文件。"
    },
    {
        "query":"如何将一个跟踪应用到所有区域？",
        "intention":"知识问答",
        "reply":"在 CloudTrail 控制台中，在跟踪配置页面选择“是”以将其应用到所有区域。如果您使用的是软件开发工具包或 AWS CLI，请将“IsMultiRegionTrail”设为“true”。"
    },
    {
        "query":"将一个跟踪应用到所有区域后会出现什么情况？",
        "intention":"知识问答",
        "reply":"将一个跟踪应用到所有区域之后，CloudTrail 会通过复制相关跟踪配置创建一个新跟踪。CloudTrail 将记录并处理每个区域中的日志文件，并会将包含所有区域的账户活动的日志文件传送至一个 S3 存储桶和一个 CloudWatch Logs 日志组。如果您指定了一个可选 Amazon Simple Notification Service（SNS）主题，CloudTrail 会将针对所有已发送日志文件的 Amazon SNS 通知发送到一个 SNS 主题中。"
    },
    {
        "query":"是否可以将一个现有跟踪应用到所有区域？",
        "intention":"知识问答",
        "reply":"可以。您可以将一个现有跟踪应用到所有区域。在您将一个现有跟踪应用到所有区域后，CloudTrail 会在所有区域为您创建一个新跟踪。如果您之前已在其他区域创建跟踪，则可通过 [CloudTrail 控制台](https://console.aws.amazon.com/cloudtrail/home)查看、编辑和删除这些跟踪。"
    },
    {
        "query":"CloudTrail 将相关跟踪配置复制到所有区域需要多长时间？",
        "intention":"知识问答",
        "reply":"通常情况下，将相关跟踪配置复制到所有区域只需不到 30 秒。"
    },
    {
        "query":"在一个区域中可以创建多少个跟踪？",
        "intention":"知识问答",
        "reply":"在一个区域中，您最多可以创建五个跟踪。应用到所有区域的跟踪会出现在每个区域中，并算作每个区域的一个跟踪。"
    },
    {
        "query":"在一个区域中创建多个跟踪有什么好处？",
        "intention":"知识问答",
        "reply":"有了多个跟踪，安全管理员、软件开发人员和 IT 审计人员等不同利益相关者就可以创建并管理他们自己的跟踪。例如，安全管理员可以创建一个应用到所有区域的跟踪，并使用一个 Amazon Key Management Service（KMS）密钥来配置加密。开发人员可以创建一个应用到一个区域的跟踪，以便排查操作问题。"
    },
    {
        "query":"CloudTrail 是否支持资源级权限？",
        "intention":"知识问答",
        "reply":"是。使用资源级权限，您可以编写精细访问控制策略，以允许或拒绝特定用户访问特定跟踪。有关更多详细信息，请访问 CloudTrail [文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/grant-custom-permissions-for-cloudtrail-users.html#grant-custom-permissions-for-cloudtrail-users-resource-level%C2%A0)。"
    },
    {
        "query":"如何保护 CloudTrail 日志文件的安全？",
        "intention":"知识问答",
        "reply":"默认情况下，CloudTrail 会通过 S3 服务器端加密（SSE）对 CloudTrail 日志文件进行加密，并将其放在您的 S3 存储桶中。您可以通过应用 IAM 或 S3 存储桶策略，控制对日志文件的访问。您可以通过在 S3 存储桶上启用 S3 [多重身份验证（MFA）Delete](http://docs.aws.amazon.com/AmazonS3/latest/dev/MultiFactorAuthenticationDelete.html) 来添加额外的安全层。有关创建和更新跟踪的更多详细信息，请参阅 [CloudTrail 文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/setupyourtrail.html)。"
    },
    {
        "query":"在何处下载 S3 存储桶策略和 SNS 主题策略的示例？",
        "intention":"知识问答",
        "reply":"您可以从 CloudTrail S3 存储桶下载 [S3 存储桶策略](https://awscloudtrail.s3.amazonaws.com/policy/S3/AWSCloudTrail-S3BucketPolicy-2013-11-01.json)和 [SNS 主题策略](https://awscloudtrail.s3.amazonaws.com/policy/SNS/AWSCloudTrail-SnsTopicPolicy-2013-11-01.json)的示例。在将示例策略应用于您的 S3 存储桶或 SNS 主题之前，必须先根据您的信息更新示例策略。"
    },
    {
        "query":"活动日志文件可以存储多长时间？",
        "intention":"知识问答",
        "reply":"您可以对应用于 CloudTrail 日志文件的保留策略进行控制。默认情况下，您可以无限期存储这些日志文件。您可以使用 [S3 对象生命周期管理规则](http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)来定义您自己的保留策略。例如，您可能希望删除旧日志文件或将这些文件存档至 Amazon Simple Storage Service Glacier（S3 Glacier）。"
    },
    {
        "query":"一个事件中包含了哪些信息？",
        "intention":"知识问答",
        "reply":"一个事件中包含相关活动的信息：请求的发出方、使用的服务、执行的操作、操作的参数，以及 AWS 服务返回的响应元素。有关更多详细信息，请参阅用户指南中的 [CloudTrail 事件参考](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/eventreference.html)部分。"
    },
    {
        "query":"CloudTrail 传送一个 API 调用事件需要多长时间？",
        "intention":"知识问答",
        "reply":"一般情况下，CloudTrail 会在 API 调用后 5 分钟内传送事件。有关 CloudTrail 工作原理的更多信息，请参见[此处](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/how-cloudtrail-works.html)。"
    },
    {
        "query":"CloudTrail 每隔多久会向我的 S3 存储桶传送一次日志文件？",
        "intention":"知识问答",
        "reply":"CloudTrail 大约每隔五分钟会向您的 S3 存储桶传送日志文件。如果您的账户上没有进行 API 调用，则 CloudTrail 不会传送日志文件。"
    },
    {
        "query":"在 CloudTrail 向我的 S3 存储桶传送新的日志文件时，是否会向我发送通知？",
        "intention":"知识问答",
        "reply":"是。您可以启用 Amazon SNS 通知，以便在送达新日志文件时立即采取行动。"
    },
    {
        "query":"我认为我的一个日志文件包含多个重复事件。我怎么知道哪些事件是唯一的？",
        "intention":"知识问答",
        "reply":"尽管这种情况并不常见，但您可能会收到包含一个或多个重复事件的日志文件。重复的事件将具有相同的 eventID。有关 eventID 字段的更多信息，请参阅 [CloudTrail 记录内容](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-event-reference-record-contents.html)。"
    },
    {
        "query":"如果我的账户已启用 CloudTrail，但我的 S3 存储桶未配置正确的策略，会怎样？",
        "intention":"知识问答",
        "reply":"CloudTrail 会根据既有的 S3 存储桶策略来传送日志文件。如果存储桶策略配置错误，那么 CloudTrail 将无法传送日志文件。"
    },
    {
        "query":"可以接收重复的事件吗？",
        "intention":"知识问答",
        "reply":"CloudTrail 旨在支持向客户 S3 存储桶交付至少一次订阅事件。在某些情况下，CloudTrail 可能会多次发送同一事件。因此，客户可能会看到重复的事件。"
    },
    {
        "query":"什么是数据事件？",
        "intention":"知识问答",
        "reply":"通过数据事件，您可以了解对资源本身或在资源内部执行的资源（数据面板）操作。数据事件通常是高频率活动，包括诸如 S3 对象级 API 操作和 AWS Lambda 函数调用 API 等操作。配置跟踪时，数据事件默认处于停用状态。若要记录 CloudTrail 数据事件，您必须明确添加您想对其收集活动的受支持的资源或资源类型。与管理事件不同，数据事件会产生额外的成本。有关更多信息，请参阅 [CloudTrail 定价](https://aws.amazon.com/cn/cloudtrail/pricing/)。"
    },
    {
        "query":"如何使用数据事件？",
        "intention":"知识问答",
        "reply":"与管理事件类似，由 CloudTrail 记录的数据事件会被传送到 S3 中。启用后，也可以在 Amazon CloudWatch Events 中使用这些事件。"
    },
    {
        "query":"什么是 S3 数据事件？ 如何记录？",
        "intention":"知识问答",
        "reply":"S3 数据事件表示对 S3 对象执行的 API 活动。若要让 CloudTrail 记录这些操作，请在创建新跟踪或修改现有跟踪时，在数据事件部分指定一个 S3 存储桶。对指定 S3 存储桶中的对象执行的任何 API 操作都会由 CloudTrail 记录下来。"
    },
    {
        "query":"什么是 Lambda 数据事件？ 如何记录？",
        "intention":"知识问答",
        "reply":"Lambda 数据事件用于记录 Lambda 函数的运行时活动。使用 Lambda 数据事件，您可以获得有关 Lambda 函数运行时的详细信息。Lambda 函数运行时的示例包括哪个 IAM 用户或服务进行了 Invoke API 调用、调用的时间以及应用了哪个函数。所有的 Lambda 数据事件都提供给 S3 存储桶和 CloudWatch Events。您可以使用 CLI 或 CloudTrail 控制台为 Lambda 数据事件启用日志记录，并通过创建新的跟踪或编辑现有跟踪来选择记录哪些 Lambda 函数。"
    },
    {
        "query":"我可以向我的组织添加委派管理员吗？",
        "intention":"知识问答",
        "reply":"可以，CloudTrail 现在支持为每个组织添加最多三个委派管理员。"
    },
    {
        "query":"谁是由委派管理员创建的组织级别的组织跟踪或事件数据存储的所有者？",
        "intention":"知识问答",
        "reply":"主账户将仍然是在组织级别创建的任何组织跟踪或事件数据存储的所有者，无论它是由委派管理员账户还是主账户创建。"
    },
    {
        "query":"哪些区域提供委派管理员支持？",
        "intention":"知识问答",
        "reply":"目前，CloudTrail 的委派管理员支持在所有提供 AWS CloudTrail 的区域推出，中国（北京，由光环新网运营）和中国（宁夏，由西云数据运营）除外。"
    },
    {
        "query":"什么是 CloudTrail Insights 事件？",
        "intention":"知识问答",
        "reply":"CloudTrail Insights 事件可帮助您识别 AWS 账户中的异常活动，例如资源预置突增、AWS Identity and Access Management（IAM）操作突增或例行维护活动缺口等。CloudTrail Insights 使用机器学习（ML）模型持续监控 CloudTrail 写入管理事件，从而发现异常活动。\n检测到异常活动时，CloudTrail Insights 事件将会在控制台中显示，并发送到 CloudWatch Events、您的 S3 存储桶，并且还可以发送到 CloudWatch Logs 组。这可以更方便您创建提示并与现有的事件管理和工作流系统集成。"
    },
    {
        "query":"CloudTrail Insights 可帮助识别哪些类型的活动？",
        "intention":"知识问答",
        "reply":"CloudTrail Insights 会通过分析 AWS 账户和区域内的 CloudTrail 写入管理事件来检测异常活动。异常活动是指 AWS API 调用的数量偏离既定操作模式或基线的预期的情形。CloudTrail Insights 会考虑基于时间的 API 调用趋势并随着工作负载的变化执行自适应的基线，从而适应正常运行模式的变化。\nCloudTrail Insights 可以帮助您检测行为有误的脚本或应用程序。有时，开发人员会对脚本或应用程序做出启动无限循环的更改，或者对数据库、数据存储或其他函数等非计划资源进行大量调用。经常，除非月末结账时成本意外增加或者发生实际的停机或中断，否则这种行为不会有人注意。CloudTrail Insights 事件可帮助您了解 AWS 账户中的这些变化，从而让您可以快速采取纠正措施。"
    },
    {
        "query":"CloudTrail Insights 如何与使用异常检测功能的其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"CloudTrail Insights 可识别 AWS 账户中的异常操作活动，从而帮助您解决运营问题，减轻对运营和业务的影响。Amazon GuardDuty 关注提高账户的安全性，通过监控账户活动来提供威胁检测功能。Amazon Macie 旨在通过发现、分类和保护敏感数据，增强账户中的数据保护。这些服务针对账户中可能出现的不同类型的问题，提供了补充的保护功能。"
    },
    {
        "query":"我是否需要设置 CloudTrail 才能使用 CloudTrail Insights？",
        "intention":"知识问答",
        "reply":"是。CloudTrail Insights 事件是针对单个跟踪配置的，因此您必须至少设置一个跟踪。当您为某个跟踪启用 CloudTrail Insights 事件后，CloudTrail 将会开始监控该跟踪捕获的写入管理事件，从而发现异常模式。如果 CloudTrail Insights 检测到异常活动，将会在跟踪定义中指定的传输目标位置记录一个 CloudTrail Insights 事件。"
    },
    {
        "query":"CloudTrail Insights 会监控哪些种类的事件？",
        "intention":"知识问答",
        "reply":"CloudTrail Insights 会跟踪写入管理 API 操作的异常活动。"
    },
    {
        "query":"如何开始使用？",
        "intention":"知识问答",
        "reply":"您可以通过控制台、CLI 或软件开发工具包在账户中的具体跟踪上启用 CloudTrail Insights 事件。您还可以使用在您的 AWS Organizations 管理账户中配置的组织跟踪，为整个组织启用 CloudTrail Insights 事件。您可以通过选择跟踪定义中的雷达按钮，从而启用 CloudTrail Insights 事件。"
    },
    {
        "query":"为什么应该使用 CloudTrail Lake？",
        "intention":"知识问答",
        "reply":"CloudTrail Lake 通过查询 CloudTrail 记录的所有操作、AWS Conﬁg 记录的配置项、来自审计管理器的证据或来自非 AWS 来源的事件来帮助您检查事件。它通过帮助消除操作依赖关系来简化事件日志记录，并提供相关工具来帮助您减少对跨团队的复杂数据处理管道的依赖。CloudTrail Lake 不要求您在其他位置移动和提取 CloudTrail 日志，这有助于保持数据保真度并减少限制日志的低速率限制。它还提供近乎实时的延迟，因为它专为处理大量结构化日志进行了微调，这使得它们可用于事件调查。此外，CloudTrail Lake 提供了熟悉的 SQL 多属性查询体验，并且能够调度和处理多个并发查询。"
    },
    {
        "query":"这项功能与其他 AWS 服务有什么关系？如何配合使用这些服务？",
        "intention":"知识问答",
        "reply":"CloudTrail 是 AWS 服务中用户活动和 API 使用情况的规范日志来源。一旦 CloudTrail 中有日志，您就可以使用 CloudTrail Lake 来检查 AWS 服务中的活动。您可以查询和分析用户活动以及受影响的资源，并使用这些数据来解决相关问题，例如识别不法分子和执行权限基准测试。"
    },
    {
        "query":"如何从 AWS 以外的来源（例如自定义应用程序、第三方应用程序或其他公有云）提取事件？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudTrail 控制台，通过几个步骤查找并添加合作伙伴集成以开始从这些应用程序接收活动事件，而无需构建和维护自定义集成。对于可用合作伙伴集成以外的来源，您可以使用新的 CloudTrail Lake API 设置您自己的集成并将事件推送到 CloudTrail Lake。要开始使用，请参阅 [CloudTrail 用户指南中的使用 CloudTrail Lake](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-lake.html)。"
    },
    {
        "query":"您建议何时使用 AWS Conﬁg 高级查询而不是 CloudTrail Lake 来从 AWS Conﬁg 中查询配置项？",
        "intention":"知识问答",
        "reply":"对于希望聚合和查询当前状态 AWS Conﬁg 配置项（CI）的客户，建议使用 AWS Conﬁg 高级查询。这有助于客户实现库存管理、安全和运营智能、成本优化和合规性数据。如果您是 AWS Conﬁg 客户，可以免费使用 AWS Conﬁg 高级查询。\nCloudTrail Lake 支持 AWS Conﬁg 配置项的查询范围，包括资源配置和合规历史记录。使用相关 CloudTrail 事件分析资源的配置和合规性历史记录，有助于推断这些资源的更改者、更改时间和更改内容。这有助于分析与安全暴露或不合规相关的事件的根本原因。如果您必须在 CloudTrail 事件和历史配置项之间聚合和查询数据，建议使用 CloudTrail Lake。"
    },
    {
        "query":"如果我今天启用将 AWS Conﬁg 中的配置项摄取到 CloudTrail Lake 中，Lake 会摄取我的历史配置项（在创建 Lake 之前生成）还是仅收集新记录的配置项？",
        "intention":"知识问答",
        "reply":"CloudTrail Lake 不会摄取在配置 CloudTrail Lake 之前生成的 AWS Conﬁg 配置项。AWS Conﬁg 中帐户级别或组织级别的新记录的配置项将传输到指定的 CloudTrail Lake 事件数据存储。在指定的保留期内，这些配置项将可在 Lake 中查询，并可用于历史数据分析。"
    },
    {
        "query":"我通过查询 CloudTrail Lake 是否总能知道哪个用户进行了特定的配置更改？",
        "intention":"知识问答",
        "reply":"如果多个用户连续快速尝试对单个资源进行多次配置更改，则只会创建一个配置项，映射到资源的最终状态配置。在这种场景和类似的场景中，通过查询 CloudTrail 和特定时间范围和资源 id 的配置项，可能无法 100% 准确地提供哪个用户进行了哪些配置更改。"
    },
    {
        "query":"如果我以前使用过跟踪，是否可以将现有的 CloudTrail 日志导入现有或新的 CloudTrail Lake 事件数据存储？",
        "intention":"知识问答",
        "reply":"可以。CloudTrail Lake 导入功能支持从 S3 存储桶复制 CloudTrail 日志，该存储桶存储来自多个账户（来自组织跟踪）和多个 AWS 区域的日志。您也可以从个别账户和单个区域跟踪导入日志。此外，使用导入功能时，您还可以指定导入的日期范围，以便仅导入需要在 CloudTrail Lake 中长期存储和进行分析的部分日志。合并日志后，您可以对日志运行查询，范围从启用 CloudTrail Lake 后收集的最新事件，到您的跟踪带来的历史事件。"
    },
    {
        "query":"这一导入功能是否会影响 S3 中的原始跟踪？",
        "intention":"知识问答",
        "reply":"导入功能将日志信息从 S3 复制到 CloudTrail Lake，并将原始副本原样保存在 S3 中。"
    },
    {
        "query":"启用 CloudTrail Lake 功能后，我可以查询哪些 CloudTrail 事件？",
        "intention":"知识问答",
        "reply":"您可以为 CloudTrail 收集的任何事件类别启用 CloudTrail Lake，具体取决于您的内部故障排除需求。事件类别包括用于捕获控制面板活动（如 CreateBucket 和 TerminateInstances）的管理事件，以及用于捕获数据面板活动（如 GetObject 和 PutObject）的数据事件。您不需要为任何这些事件单独订阅试用版。您可以选择长达七年的事件保留期限，并且可以随时查询该数据。 在 CloudTrail Lake 控制面板中，我们支持查询 CloudTrail 事件。"
    },
    {
        "query":"启用 CloudTrail Lake 功能后，我需要等待多长时间才能开始编写查询？",
        "intention":"知识问答",
        "reply":"您几乎可以立即开始查询启用该功能后发生的活动。"
    },
    {
        "query":"我可以使用 CloudTrail Lake 解决哪些常见的安全和运营使用案例？",
        "intention":"知识问答",
        "reply":"常见使用案例包括调查安全事件（例如未经授权的访问或泄露的用户凭证），以及通过执行审计以定期对用户权限执行基准测试来增强您的安全状况。您可以执行必要的审计，以确保允许合适的用户组对资源（例如安全组）进行更改，并跟踪任何不符合组织最佳实践的更改。此外，您还可以跟踪对资源执行的操作并评测修改或删除，并深入了解您的 AWS 服务账单，包括订阅服务的 IAM 用户。"
    },
    {
        "query":"如何开始使用 CloudTrail Lake？",
        "intention":"知识问答",
        "reply":"如果您是现有和新的 CloudTrail 客户，您可以立即开始使用 CloudTrail Lake 功能来运行查询，方法是通过 API 或 CloudTrail 控制台启用此功能。选择 CloudTrail 控制台左侧面板上的 CloudTrail Lake 选项卡，然后选择创建事件数据存储按钮以选择事件保留期限（最多七年）。然后，从 CloudTrail 记录的所有事件类别（管理和数据事件）中进行事件选择，即可开始使用。\n此外，为了帮助您可视化热门 CloudTrail Lake 事件，您可以开始使用 CloudTrail Lake 控制面板。CloudTrail Lake 控制面板是预先构建的，可直接在 CloudTrail 控制台中提供开箱即用的可见性以及从您的审计和安全数据中获得的重要见解。"
    },
    {
        "query":"我现在可以在控制面板上可视化来自 CloudTrail Lake 的哪种类型的事件？",
        "intention":"知识问答",
        "reply":"现在，CloudTrail Lake 控制面板支持 CloudTrail 管理和数据事件。"
    },
    {
        "query":"控制面板是在账户级别还是事件数据存储级别启用？",
        "intention":"知识问答",
        "reply":"控制面板目前在账户级别启用，并将应用于该账户中启用了 CloudTrail 管理或数据事件的所有活动数据存储。"
    },
    {
        "query":"我目前可以创建自定义控制面板吗？",
        "intention":"知识问答",
        "reply":"不可以。目前所有 CloudTrail Lake 控制面板都是经过精心设计和预定义的，无法自定义。"
    },
    {
        "query":"CloudTrail Lake 控制面板支持哪些应用场景？",
        "intention":"知识问答",
        "reply":"审计和合规工程师可以使用 CloudTrail Lake 控制面板来跟踪合规性规定的进度，例如迁移到 TLS 1.2 及更高版本。CloudTrail Lake 控制面板将帮助安全工程师密切跟踪敏感的用户活动，例如删除跟踪或重复出现访问被拒绝错误。云运营工程师可以从精心设计的控制面板上查看诸如主要服务限制错误之类的问题。"
    },
    {
        "query":"我有多个 AWS 账户。但我希望所有账户的日志文件传送到单个 S3 存储桶中。这能实现吗？",
        "intention":"知识问答",
        "reply":"能。您可以配置一个 S3 存储桶作为多个账户的目标存储桶。有关详细说明，请参阅 CloudTrail 用户指南中的[将日志文件聚合到单个 S3 存储桶中](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/aggregatinglogs.html)一节。"
    },
    {
        "query":"什么是 CloudTrail 与 CloudWatch Logs 的集成？",
        "intention":"知识问答",
        "reply":"CloudTrail 与 CloudWatch Logs 集成，让您可以将 CloudTrail 捕获的管理事件和数据事件传送到您指定的 CloudWatch Logs 日志组中的 CloudWatch Logs 日志流。"
    },
    {
        "query":"CloudTrail 与 CloudWatch Logs 集成有哪些优势？",
        "intention":"知识问答",
        "reply":"这一集成可帮助您接收 CloudTrail 所捕获的账户活动的 SNS 通知。例如，您可以创建 CloudWatch 警报以监控创建、修改和删除安全组及网络访问控制列表（ACL）的 API 调用。"
    },
    {
        "query":"如何启用 CloudTrail 与 CloudWatch Logs 的集成？",
        "intention":"知识问答",
        "reply":"您可以通过指定 CloudWatch Logs 日志组和 IAM 角色从 CloudTrail 控制台启用 CloudTrail 与 CloudWatch Logs 的集成。您还可以使用 AWS 软件开发工具包或 AWS CLI 来启用此集成。"
    },
    {
        "query":"启用 CloudTrail 与 CloudWatch Logs 的集成后会出现什么情况？",
        "intention":"知识问答",
        "reply":"启用该集成后，CloudTrail 会持续向您指定的 CloudWatch Logs 日志组中的 CloudWatch Logs 日志流传送账户活动。CloudTrail 还会像以前一样继续向您的 S3 存储桶传送日志。"
    },
    {
        "query":"哪些 AWS 区域支持 CloudTrail 与 CloudWatch Logs 的集成？",
        "intention":"知识问答",
        "reply":"支持 CloudWatch Logs 的区域均支持该集成。有关更多信息，请参阅 AWS 一般参考中的[区域和端点](http://docs.aws.amazon.com/general/latest/gr/rande.html#cwl_region)。\n问：CloudTrail 如何将包含账户活动的事件传送至 CloudWatch Logs？\n为了将账户活动传送至 CloudWatch Logs，CloudTrail 会承担您指定的 IAM 角色。您可以对 IAM 角色加以限制，使其仅具有其所需要的将事件传送至您的 CloudWatch Logs 日志流的权限。要查看 IAM 角色策略，请前往 CloudTrail 文档的[用户指南](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cw_role_policy.html)。"
    },
    {
        "query":"当我开始将 CloudTrail 与 CloudWatch Logs 集成后，要如何付费？",
        "intention":"知识问答",
        "reply":"当您启用 CloudTrail 与 CloudWatch Logs 的集成之后，您要支付 CloudWatch Logs 和 CloudWatch 的标准费用。有关详细信息，请前往 CloudWatch [定价页面](https://aws.amazon.com/cn/cloudwatch/pricing/)。"
    },
    {
        "query":"使用 AWS KMS 的服务器端加密对 CloudTrail 日志文件进行加密有哪些好处？",
        "intention":"知识问答",
        "reply":"使用 [SSE-KMS](http://docs.aws.amazon.com/AmazonS3/latest/dev/UsingKMSEncryption.html) 进行 CloudTrail 日志文件加密可通过 KMS 密钥加密日志文件，从而帮助您为交付到 S3 存储桶的 CloudTrail 日志文件添加一个额外的安全层。默认情况下，CloudTrail 会使用 S3 服务器端加密加密交付到 S3 存储桶的日志文件。"
    },
    {
        "query":"我有一个接收并处理 CloudTrail 日志文件的应用程序。我需要对该应用程序进行任何更改吗？",
        "intention":"知识问答",
        "reply":"借助 SSE-KMS，S3 会自动加密日志文件，因此，您无需对自己的应用程序进行任何更改。与往常一样，您必须确保应用程序拥有相应的权限，如 S3 GetObject 和 AWS KMS Decrypt 权限。"
    },
    {
        "query":"如何配置 CloudTrail 日志文件加密？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台、AWS CLI 或 AWS 软件开发工具包配置日志文件加密。有关详细说明，请参阅[文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/encrypting-cloudtrail-log-files-with-aws-kms.html)。"
    },
    {
        "query":"什么是 CloudTrail 日志文件完整性验证？",
        "intention":"知识问答",
        "reply":"CloudTrail 日志文件完整性验证功能可帮助您确定 CloudTrail 日志文件在被 CloudTrail 传送到特定的 S3 存储桶后是否发生过更改、删除或修改。"
    },
    {
        "query":"使用 CloudTrail 日志文件完整性验证有哪些好处？",
        "intention":"知识问答",
        "reply":"您可以将日志文件完整性验证用作 IT 安全和审核流程中的一个辅助手段。"
    },
    {
        "query":"如何启用 CloudTrail 日志文件完整性验证？",
        "intention":"知识问答",
        "reply":"您可以通过控制台、AWS CLI 或 AWS 软件开发工具包启用 CloudTrail 日志文件完整性验证功能。"
    },
    {
        "query":"打开日志文件完整性验证功能后会怎样？",
        "intention":"知识问答",
        "reply":"打开日志文件完整性验证功能后，CloudTrail 会每小时交付一次摘要文件。摘要文件包含有关传递到 S3 存储桶的日志文件的信息以及这些日志文件的哈希值。它们还包含 S3 元数据部分中先前摘要文件的数字签名和当前摘要文件的签名。有关摘要文件、数字签名和哈希值的更多信息，请参阅 [CloudTrail 文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-intro.html)。"
    },
    {
        "query":"摘要文件会传送到什么位置？",
        "intention":"知识问答",
        "reply":"摘要文件交付到日志文件交付到的 S3 存储桶。但是，它们会交付到不同的文件夹，以便您实施精细的访问控制策略。有关详细信息，请参阅 [CloudTrail 文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-digest-file-structure.html)的摘要文件结构部分。"
    },
    {
        "query":"如何验证 CloudTrail 传送的日志文件或摘要文件的完整性？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CLI 验证日志文件或摘要文件的完整性。您也可以构建自己的工具来进行验证。有关使用 AWS CLI 验证日志文件完整性的更多信息，请参阅 [CloudTrail 文档](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-log-file-validation-cli.html)。"
    },
    {
        "query":"我将所有区域和多个账户的所有日志文件集中到了一个 S3 存储桶中。摘要文件是否也会传送到该 S3 存储桶中？",
        "intention":"知识问答",
        "reply":"是。CloudTrail 会将所有区域和多个账户的摘要文件传送到该 S3 存储桶。"
    },
    {
        "query":"什么是 AWS CloudTrail 处理库？",
        "intention":"知识问答",
        "reply":"AWS CloudTrail 处理库是一个 Java 库，可以帮助您更轻松地构建读取和处理 CloudTrail 日志文件的应用程序。您可以从 [GitHub](https://github.com/aws/aws-cloudtrail-processing-library) 下载 CloudTrail 处理库。"
    },
    {
        "query":"CloudTrail 处理库可提供哪些功能？",
        "intention":"知识问答",
        "reply":"CloudTrail 处理库可提供处理以下任务的功能，如不断轮询 SQS 队列，读取和解析 Amazon Simple Queue Service（SQS）消息。它还可以下载 S3 中存储的日志文件，并以容错方式解析和序列化日志文件事件。有关更多信息，请前往 CloudTrail 文档中的[用户指南](http://docs.aws.amazon.com/awscloudtrail/latest/userguide/using_processing_lib.html)。"
    },
    {
        "query":"要开始使用 CloudTrail 处理库，我需要什么软件？",
        "intention":"知识问答",
        "reply":"您需要 aws-java-sdk 版本 1.9.3 和 Java 1.7 或更高版本。"
    },
    {
        "query":"如果我只有一个跟踪包含管理事件并应用于所有区域，我是否需要付费？",
        "intention":"知识问答",
        "reply":"不需要。管理事件的第一个副本在每个区域中都是免费提供的。"
    },
    {
        "query":"如果对包含免费管理事件的现有跟踪启用数据事件，我是否需要付费？",
        "intention":"知识问答",
        "reply":"是。您仅需为数据事件付费。管理事件的第一个副本是免费提供的。"
    },
    {
        "query":"AWS 合作伙伴解决方案如何帮助我分析 CloudTrail 记录的事件？",
        "intention":"知识问答",
        "reply":"有多个合作伙伴提供了集成解决方案，用于分析 CloudTrail 日志文件。这些解决方案包括变更追踪、故障排查和安全分析等功能。有关更多信息，请参阅 [CloudTrail 合作伙伴部分](https://aws.amazon.com/cn/cloudtrail/partners/)。"
    },
    {
        "query":"如何将 CloudTrail Lake 集成作为可用来源？",
        "intention":"知识问答",
        "reply":"要开始集成，您可以查看[合作伙伴入门指南](https://docs.aws.amazon.com/awscloudtrail/latest/partner-onboarding/cloudtrail-lake-partner-onboarding.html)。与您的合作伙伴开发团队或合作伙伴解决方案架构师接洽，与 CloudTrail Lake 团队联系，以进行更深入的研究或提出更多问题。"
    },
    {
        "query":"启用 CloudTrail 是否会影响 AWS 资源的性能或增加 API 调用的延迟？",
        "intention":"知识问答",
        "reply":"不会。启用 CloudTrail 既不会影响 AWS 资源的性能，也不会增加 API 调用的延时。\n了解有关 AWS CloudTrail 合作伙伴的更多信息。\n在 AWS 管理控制台中，使用 AWS CloudTrail 开始构建。\n了解 AWS CloudTrail 支持选项。"
    },
    {
        "query":"What is AWS Fault Injection Simulator (FIS)?",
        "intention":"知识问答",
        "reply":"AWS Fault Injection Simulator is a fully managed service for running fault injection experiments on AWS that makes it easier to improve an application’s performance, observability, and resiliency. Fault injection experiments are used in chaos engineering, which is the practice of stressing an application in testing or production environments by creating disruptive events, such as sudden increase in CPU or memory consumption, observing how the system responds, and implementing improvements."
    },
    {
        "query":"What is Chaos Engineering?",
        "intention":"知识问答",
        "reply":"Chaos engineering is the process of stressing an application in testing or production environments by creating disruptive events, such as server outages or API throttling, observing how the system responds, and implementing improvements. Chaos engineering helps teams create the real-world conditions needed to uncover the hidden issues, monitoring blind spots, and performance bottlenecks that are difficult to find in distributed systems. It starts with analyzing the steady-state behavior, building an experiment hypothesis (e.g., terminating x number of instances will lead to x% more retries), executing the experiment by injecting fault actions, monitoring roll back conditions, and addressing the weaknesses."
    },
    {
        "query":"Does AWS FIS require an agent?",
        "intention":"知识问答",
        "reply":"Many action types do not require any agents to be installed in your resources. However, instance level faults including increased CPU utilization and memory utilization, require the SSM agent."
    },
    {
        "query":"Why should I use AWS FIS?",
        "intention":"知识问答",
        "reply":"You should use FIS to discover an application’s weaknesses at scale in order to improve performance, observability, and resiliency. FIS delivers real-world fault injection experience from a centralized console, eliminating the need for you to manage complex tooling. FIS’s flexible experiment template allows you to incorporate various fault types into a single experiment and to design custom experiments to simulate complex outage scenarios. FIS provides built-in safety mechanisms in the form of stop conditions, which stop an experiment before it runs out of control."
    },
    {
        "query":"Can I use AWS FIS as part of my CD pipeline?",
        "intention":"知识问答",
        "reply":"Yes, you can integrate FIS into your continuous delivery pipeline. This will enable you to repeatedly test the impact of fault actions as part of your software delivery process"
    },
    {
        "query":"How do the faults injected by AWS FIS compare to real world conditions?",
        "intention":"知识问答",
        "reply":"FIS fault inject actions create conditions which are nearly identical to what happens in the real world. For example, the action to increase CPU utilization actually consumes CPU resources. The action to throttle API requests throttles those requests at the control plane level so the experience is the same as any other throttling. Unlike the real world, with FIS you have the control to stop an experiment at any time and, where possible, specify roll back actions that execute once an action duration is complete."
    },
    {
        "query":"What are the core concepts of running an experiment?",
        "intention":"知识问答",
        "reply":"FIS experiment contains one or more sets of Target, Fault Injection Actions, Post Action, and Stop Condition. You start the FIS experiment with fault injection action(s) and AWS target(s). As your application resiliency improves, you expand the scope of the experiment to include additional AWS resources and fault injection actions. Once you have defined the experiment, you can schedule it to run at specific times."
    },
    {
        "query":"What are the core concepts of target resources?",
        "intention":"知识问答",
        "reply":"Targets are AWS resources that are selected for the specific fault injection experiment. For example, tags, instance-id, cluster-id, VPC, etc. Targets can be specific AWS resource or random AWS resource(s)."
    },
    {
        "query":"What are the core concepts of fault injection actions?",
        "intention":"知识问答",
        "reply":"One example of fault injection action in FIS is generating a high CPU load on an EC2 instance. Each FIS action accepts a unique set of properties. This example of CPU load on EC2 instance, the property would be the % value of the load. Different FIS actions have different property values. FIS actions also helps you control the timeline and duration of the experiment. For each action, you can specify the StartTime and duration of the experiment. For example, you can design your experiment to include CPULoad action that increases the CPU load to 75% to start at StartTime of 0 seconds and run for 60 seconds.\nQ: Is there anything I need to do before using AWS FIS?\nThere are several things you need to think about before using FIS. First, you need to identify the target deployment for the experiment. If this is your first experiment, you should consider starting in a pre-production or test environment. As your fault injection experiment matures, you can introduce fault injection to continuously assess resilience in the production environment. Second, you need to define the steady-state behavior and identify important technical (e.g., latency, CPU load) and business metrics (e.g., failed logins per minute, number of retries, page load speed). Next, you need to form a hypothesis of what you expect from the experiment. Your hypothesis is defined as “if is performed <business or technical metric impact should not exceed >.” For example, your hypothesis for an authentication service could say, “if, network latency increases by 10%, there would be less than 1% increase in login failures”. After the experiment, you evaluate if the application resiliency is in line with your business and technical expectation."
    },
    {
        "query":"How do I start using AWS FIS?",
        "intention":"知识问答",
        "reply":"You can use the FIS console or AWS CLI to define, manage and control the experiment. You start by creating an experiment that includes one or more actions that you want to execute on one or more targets. You can define everything through the experiment template, including targets, actions, alarm and stop conditions. Then, you can start the experiment. Each start-experiment returns a unique execution-id. You can use the execution-id parameter to track the status of a specific run."
    },
    {
        "query":"How do I check the status of AWS FIS experiment?",
        "intention":"知识问答",
        "reply":"You can use the management console or AWS CLI to check the status of the experiment. With list-experiment-executions, you list all experiment executions. With get-experiment-execution, you get the details of a specific execution. When you query the details of a specific run, you get the specific actions and their respective result. With CloudTrail, you can log and continuously monitor the executed actions."
    },
    {
        "query":"How can I stop the experiment?",
        "intention":"知识问答",
        "reply":"You execute stop-experiment in the FIS console, or through CLI via stop-experiment. Additionally, you can leverage CloudWatch enable-alarm-actions to stop an experiment."
    },
    {
        "query":"What type of faults can I inject using AWS FIS?",
        "intention":"知识问答",
        "reply":"FIS enables you to execute pre-defined fault injection experiments across compute, database, network, and more. You can find the full list of [fault injections here](https://docs.aws.amazon.com/fis/latest/userguide/fis-actions-reference.html#fis-actions-reference-fis)."
    },
    {
        "query":"How can I monitor the impact of a AWS FIS experiment?",
        "intention":"知识问答",
        "reply":"The FIS console enables you to monitor the progress of an experiment, and retrieve the status of each executed actions. Additionally, you can use CloudWatch monitoring and dashboards to monitor the state of your AWS resources. FIS generates CloudTrail logs for all actions that it takes on your AWS resources during an experiment, providing you full visibility and auditing on actions taken in your account."
    },
    {
        "query":"什么是 AWS IoT ExpressLink？",
        "intention":"知识问答",
        "reply":"AWS IoT ExpressLink 是连接软件，支持 AWS 合作伙伴开发和提供的一系列硬件模块。这些模块提供云连接并实施 AWS 强制安全性要求。将这些无线模块集成到您设备的硬件设计之后，您可以更快速、更轻松地构建可安全与 AWS 服务连接的物联网（IoT）产品。"
    },
    {
        "query":"为什么要使用 AWS IoT ExpressLink？",
        "intention":"知识问答",
        "reply":"您可以将合作伙伴提供的模块与 AWS IoT ExpressLink 结合使用，通过极少的设计工作，快速将嵌入式设备转变为连接了 IoT 的设备。您不必再亲自处理集成所需网络和安全库方面的复杂工作，而可以将这项无差别工作交给模块。这可以降低开发成本、加快上市速度，并可以集中工程资源来打造优势产品体验。AWS IoT ExpressLink 兼容各种规模的设备和资源限制，让您可以自由灵活地保留现有处理器，而无需将其替换为更大或更新的处理器。免去了从头开始重新编写应用程序带来的成本高昂的重新设计工作，从而确保兼容性。此外，使用 AWS IoT ExpressLink 的模块预置了符合条件的 AWS 合作伙伴设置的安全凭证，有助于您快速建立安全连接并实现无线（OTA）更新，大规模确保设备队列运行状况。"
    },
    {
        "query":"AWS IoT ExpressLink 与其余 AWS IoT 服务之间有什么联系？",
        "intention":"知识问答",
        "reply":"AWS IoT ExpressLink 提供开箱即用的解决方案，可快速轻松地与一系列 AWS 服务集成，包括用于安排和执行更新的 IoT 任务和 IoT 无线下载（OTA）服务，以及用于管理和监控设备队列状态的 IoT Device Management。您还可以利用云存储服务（如 Amazon Simple Storage Service（Amazon S3））、计算服务（如 Amazon Elastic Compute Cloud（Amazon EC2））、人工智能和机器学习（AI/ML）以及建模和分析服务（如 Amazon SageMaker）。"
    },
    {
        "query":"如何开始使用？",
        "intention":"知识问答",
        "reply":"通过 [AWS 合作伙伴设备目录页面](https://devices.amazonaws.com/search?page=1&sv=iotxplnk)向参与计划的合作伙伴购买开发套件，评估 AWS IoT ExpressLink 是否适合您。该套件将会包含应用程序处理器，或会连接到 Arduino 等兼容的开发平台。 然后，您可以立即开始通过简单的 AWS IoT ExpressLink 序列接口将遥测数据发送到云中。"
    },
    {
        "query":"Amazon SES 提供哪些电子邮件工具？",
        "intention":"知识问答",
        "reply":"Amazon SES 提供许多电子邮件工具，包括：电子邮件发件人配置选项、电子邮件送达率工具、灵活的电子邮件部署选项、发件人和身份管理、电子邮件安全、电子邮件发送统计数据、电子邮件声誉控制面板和入站电子邮件服务。"
    },
    {
        "query":"测试 Amazon SES 有何简单方法？",
        "intention":"知识问答",
        "reply":"Amazon SES 沙盒是新用户可以从中测试 Amazon SES 功能的区域。当您的账户处于沙盒中时，您只能将电子邮件发送到已验证身份。经验证身份是您已证明您拥有的电子邮件地址或域。\n另外，当您的账户在沙盒中时，您每天可发送的电子邮件数量和您每秒可发送的邮件数量都存在限制。"
    },
    {
        "query":"我是否可以立即开始发送大量电子邮件？",
        "intention":"知识问答",
        "reply":"当您准备好开始向未经验证的收件人发送电子邮件时，请通过 AWS Support Center 提交 Amazon SES 发送限制提高请求。有关更多信息，请参阅*《Amazon SES 开发人员指南》*中的[移出 Amazon SES 沙盒](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/request-production-access.html)。"
    },
    {
        "query":"SES 如何帮助我提高电子邮件送达率？",
        "intention":"知识问答",
        "reply":"SES 提供了一套名为虚拟可交付性管理器的电子邮件送达率工具。借助虚拟可交付性管理器，电子邮件发件人能够通过送达率数据分析来跟踪其电子邮件送达率，并通过虚拟可交付性管理器的送达率建议来改善电子邮件收件箱的位置。电子邮件发件人还可以启用虚拟可交付性管理器来自动实施建议，从而立即提高其电子邮件送达率。"
    },
    {
        "query":"如何跟踪我的 Amazon SES 使用情况？",
        "intention":"知识问答",
        "reply":"您可以通过访问 AWS 管理控制台中的[账单控制面板](https://console.aws.amazon.com/billing/home)，随时查看当前计费周期内的费用。"
    },
    {
        "query":"我可以将 Amazon SES 用作免费电子邮件服务吗？",
        "intention":"知识问答",
        "reply":"新客户可以使用 AWS Free Tier 通过 Amazon SES 免费发送电子邮件。 SES 灵活的免费套餐使新发件人能够试用您需要的 SES 功能。在开始使用 SES 后的前 12 个月内，每月最多可免费接收 3000 条消息。免费套餐可用于免费试用以下电子邮件服务：出站电子邮件、入站电子邮件、虚拟可交付性管理器出站电子邮件处理。\n如需了解更多详情，请参阅 [定价页面](https://aws.amazon.com/ses/pricing/#:~:text=custom%20estimate%20now%C2%A0%C2%BB-,AWS%20Free%20Tier,-As%20part%20of \"AWS 上的免费电子邮件发送服务\")。"
    },
    {
        "query":"我可以从任何电子邮件地址发送电子邮件吗？",
        "intention":"知识问答",
        "reply":"不。您只能使用 Amazon SES 从您拥有的地址或域发送电子邮件。\n要证明您拥有电子邮件地址或域，您必须验证它。在每个 AWS 区域中，您最多可以验证 10000 个电子邮件地址和域的任意组合。有关验证电子邮件地址和域的更多信息，请参阅 Amazon SES 开发人员指南中的[在 Amazon SES 中验证身份](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/verify-addresses-and-domains.html)。"
    },
    {
        "query":"Amazon SES 传输的电子邮件的大小是否受到限制？",
        "intention":"知识问答",
        "reply":"Amazon SES v2 API 和 SMTP 接受大小最大 40MB 的电子邮件消息，包括属于消息一部分的任何图片和附件。大于 10MB 的消息受带宽限制，根据您的发送速率，您可能会被限制到低至 40MB/s。例如，您可以以每秒 1 条消息或每秒 2 条 20MB 消息的速率发送一条 40MB 的消息。\nAmazon SES API v1 接受大小最大 10MB 的消息，包括属于消息一部分的任何图片和附件。"
    },
    {
        "query":"我可以发送的电子邮件数量是否受到限制？",
        "intention":"知识问答",
        "reply":"每个 Amazon SES 账户都对电子邮件批量发送功能有自己的限制。这些限制包括：\n发送限制基于收件人而不是电子邮件。您可以随时使用 Amazon SES 控制台检查这些发送限制。\n注意：如果我们确定您发送的电子邮件的质量不佳或有问题（例如，如果它具有高退回率或投诉率，或者它包含未经请求的或恶意的内容），我们保留暂停您发送电子邮件的能力的权利。"
    },
    {
        "query":"Amazon SES 是否支持发件人策略框架 (SPF)？",
        "intention":"知识问答",
        "reply":"支持，Amazon SES 支持 SPF。您可能需要发布 SPF 记录，具体取决于您如何使用 Amazon SES 发送电子邮件。如果您无需通过 SPF 遵循基于域的邮件身份验证、报告和一致性 (DMARC)，则无需发布 SPF 记录，因为在默认情况下，Amazon SES 会从 Amazon Web Services 拥有的发件人域发送您的电子邮件。如果您希望通过 SPF 遵循 DMARC，则必须将 Amazon SES 设置为使用您自己的发件人域并发布 SPF 记录。"
    },
    {
        "query":"Amazon SES 是否支持域名密钥识别邮件 (DKIM)？",
        "intention":"知识问答",
        "reply":"支持，Amazon SES 支持 DKIM。如果您已经启用并配置 Easy DKIM，则 Amazon SES 将代表您使用 DKIM 对传出邮件进行签名。如果您愿意，也可以手动对电子邮件进行签名。为确保最高送达率，有几个 DKIM 标头不能进行签名。有关更多信息，请参阅 Amazon SES 开发人员指南中的[在 Amazon SES 中手动进行 DKIM 签名](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/manual-dkim.html)。"
    },
    {
        "query":"发自 Amazon SES 的电子邮件是否可以遵循 DMARC？",
        "intention":"知识问答",
        "reply":"通过 Amazon SES，您的电子邮件可以通过 SPF 和/或 DKIM 遵循 DMARC。\n有关更多信息，请参阅 Amazon SES 开发人员指南中的 [Amazon SES 与安全协议](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/security.html#security-ses-to-receiver)。"
    },
    {
        "query":"在发送某些类型的电子邮件时，是否可以指定专用 IP 地址？",
        "intention":"知识问答",
        "reply":"如果您租赁了几个专用 IP 地址以使用 Amazon SES 账户，则可以使用专用 IP 池功能来创建这些 IP 地址的组（池）。然后，您可以将每个池与配置集相关联；当您使用该配置集发送电子邮件时，这些电子邮件将只会从相关池中的 IP 地址发出。有关更多信息，请参阅 *Amazon SES 开发人员指南*中的[创建专用 IP 池](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/dedicated-ip-pools.html)。"
    },
    {
        "query":"专用 IP 地址（标准）和（托管）有什么区别？",
        "intention":"知识问答",
        "reply":"这两个专用 IP 选项都可以帮助您通过保留的 IP 地址来管理发送信誉。专用 IP 地址（标准）要求您手动设置和管理您的 IP 地址。专用 IP 地址（托管）减少了手动监控或扩展专用 IP 池的需要。它还可以帮助您更准确地模拟预热状态并防止可能影响交付能力的过度发送。有关更详细的优势比较，请参阅 *[Amazon SES 开发人员指南](https://docs.aws.amazon.com/ses/latest/dg/dedicated-ip.html)*中的专用 IP 地址。"
    },
    {
        "query":"Amazon SES 是否提供 SMTP 终端节点？",
        "intention":"知识问答",
        "reply":"Amazon SES 提供 SMTP 接口，以实现与能够通过 SMTP 发送电子邮件的应用程序的无缝集成。您可从应用程序直接连接至此 SMTP 接口，或将现有电子邮件服务器配置为使用此接口作为 SMTP 中继。\n要连接到 Amazon SES SMTP 接口，必须创建 SMTP 凭证。有关创建 SMTP 凭证的更多信息，请参阅 *Amazon SES 开发人员指南*中的[获取 Amazon SES SMTP 凭证](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/smtp-credentials.html)。"
    },
    {
        "query":"可以使用 Amazon SES 从我的现有应用程序发送电子邮件吗？",
        "intention":"知识问答",
        "reply":"Amazon SES 允许您创建一个专用 SMTP 中继，以便与任何现有 SMTP 客户端软件配合使用，其中包括您自己开发的软件或可以使用 SMTP 协议发送电子邮件的任何第三方软件。\n有关更多信息，请参阅 *Amazon SES 开发人员指南*中的[使用 Amazon SES SMTP 接口发送电子邮件](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/send-email-smtp.html)。"
    },
    {
        "query":"Amazon SES 是否能够发送带附件的电子邮件？",
        "intention":"知识问答",
        "reply":"Amazon SES 支持很多常见内容格式，包括文档、图像、音频和视频。\n注意：为了您自己和客户的安全考虑，Amazon SES 会对您发送的每封电子邮件的附件进行病毒和恶意软件扫描。\n您可以使用支持 SMTP 的电子邮件客户端发送带附件的电子邮件。在将这些客户端配置为通过 Amazon SES 发送传出电子邮件时，客户端将在发送邮件之前生成相应的 MIME 部分和电子邮件标头。\n您还可以通过编程方式发送带附件的电子邮件。要在电子邮件中包括附件，生成一封新的多部分电子邮件。在此邮件中，包含一个具有合适的 Content-Type 标头以及 MIME 编码内容的 MIME 部分。接下来，使用 Content-Disposition 标头来指定该内容是嵌入显示，还是作为附件处理。\n在您撰写完邮件后，可以使用 SendRawEmail API 操作来发送它。"
    },
    {
        "query":"是否可以在不向真实的收件人发送电子邮件的情况下测试 Amazon SES 响应情况？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon SES 邮箱模拟器来测试发送率，并测试您处理事件（例如退回邮件和投诉）的能力，而无需向真实收件人发送电子邮件。您发送到邮箱模拟器的邮件不会计入您的退回邮件和投诉指标或您的每日发送配额。不过，我们会对您发送到邮箱模拟器的每封邮件收费，就好像它们是您发送给真实客户的邮件。\n有关 Amazon SES 邮箱模拟器的更多信息，请参阅 Amazon SES 开发人员指南中的[测试 Amazon SES 电子邮件发送](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/mailbox-simulator.html)。"
    },
    {
        "query":"Amazon SES 如何确保可靠的电子邮件传输？",
        "intention":"知识问答",
        "reply":"Amazon SES 使用内容筛选技术来扫描传出电子邮件。这些内容筛选条件有助于确保通过 Amazon SES 发送的内容符合 ISP 标准。为了帮助您进一步提高电子邮件的送达率，Amazon SES 提供包含退回邮件、投诉和送达通知的反馈循环。"
    },
    {
        "query":"Amazon SES 是否会保证收到我的电子邮件？",
        "intention":"知识问答",
        "reply":"Amazon SES 密切监控 ISP 指导原则，帮助确保合法的高质量电子邮件能够可靠地送达收件人收件箱。但是，无论是 Amazon SES 还是其他任何电子邮件发送服务，都无法保证每一封电子邮件的送达。ISP 可能会丢弃或丢失电子邮件，收件人可能会疏忽大意提供错误电子邮件地址，如果收件人不希望接收您的电子邮件，ISP 会选择拒绝或静默丢弃这些邮件。"
    },
    {
        "query":"使用 Amazon SES 发送的电子邮件多长时间可以送达收件人的收件箱？",
        "intention":"知识问答",
        "reply":"Amazon SES 在收到每个请求后几秒之内尝试将电子邮件传送到 Internet。但是，因为受到众多因素的影响和 Internet 的固有不确定性，我们无法准确估计电子邮件的送达时间以及邮件在到达目的地前经过的确切路线。\n例如，ISP 可能因为临时状况 (例如邮箱已满) 而无法将电子邮件交给收件人。 在这些情况下，Amazon 会尝试重新传送邮件。如果错误是永久的（例如“邮箱不存在”），则 Amazon SES 不会再次尝试传送邮件，您将收到查无此人的邮件通知。您可以设置送达通知，在 Amazon SES 成功将电子邮件送达收件人邮件服务器后提醒您。  \n   \n 问：其他 Amazon SES 用户导致的退回邮件或投诉是否会影响我的电子邮件送达率？\n通常，在其他 Amazon SES 用户发送了导致退回邮件或投诉的邮件时，不会对您发送电子邮件产生什么影响。\n此规则有一个例外情况，即收件人电子邮件地址出现了查无此人的邮件。当收件人的电子邮件地址出现查无此人的邮件时，Amazon SES 将把此地址添加至全局黑名单。如果您试图向位于全局黑名单中的地址发送电子邮件，则可以成功调用 Amazon SES，但 Amazon SES 会将该邮件视为查无此人的邮件，而不会尝试将其发送出去。\n向位于全局黑名单中的地址发送的电子邮件会计入您的发送配额和退回率。电子邮件地址可在黑名单上保留最多 14 天。\n有关全局黑名单的更多信息，请参阅 *Amazon SES* 中的 [Amazon SES 和送达率](https://docs.aws.amazon.com/ses/latest/DeveloperGuide/deliverability-and-ses.html#suppression-list)。"
    },
    {
        "query":"Amazon 可以访问我发送和接收的电子邮件吗？",
        "intention":"知识问答",
        "reply":"我们使用内部反垃圾邮件技术来筛选包含质量不佳的内容的邮件。另外，我们扫描所有包含附件的邮件来检查是否存在病毒及其他恶意内容。"
    },
    {
        "query":"我可以对我收到的电子邮件进行加密吗？",
        "intention":"知识问答",
        "reply":"Amazon SES 与 AWS Key Management Service (KMS) 集成，后者可以对前者写入到 Amazon S3 存储桶的邮件进行加密。Amazon SES 先使用客户端加密对邮件进行加密，然后再将电子邮件发送到 Amazon S3。这表示在检索来自 Amazon S3 的邮件之后，您必须在您那一端解密内容。AWS Java 开发工具包和 AWS Ruby 开发工具包提供能够为您处理解密事项的客户端。"
    },
    {
        "query":"Amazon SES 是否使用传输层安全性 (TLS) 通过加密连接发送电子邮件？",
        "intention":"知识问答",
        "reply":"Amazon SES 支持为 TLS 连接使用 TLS 1.2、TLS 1.1 和 TLS 1.0。\n默认情况下，Amazon SES 使用*机会性 TLS*。这意味着 Amazon SES 始终会尝试与接收方邮件服务器建立安全连接。如果 Amazon SES 无法建立安全连接，则会以未加密的方式发送邮件。\n您可以更改此行为，以便 Amazon SES 仅在可以建立安全连接时将消息发送到接收方电子邮件服务器"
    },
    {
        "query":"Amazon SES 如何确保传入邮件不是垃圾邮件且不含病毒？",
        "intention":"知识问答",
        "reply":"Amazon SES 采用了许多垃圾邮件和病毒防护措施。首先使用黑名单来防止已知垃圾邮件发送者的邮件进入系统。还对包含附件的每封传入电子邮件执行病毒扫描。Amazon SES 为您提供垃圾邮件检测结果，让您决定是否信任每封邮件。除了垃圾邮件和病毒扫描结果之外，Amazon SES 还提供 DKIM 和 SPF 检查结果。"
    },
    {
        "query":"哪些技术可以防止 Amazon SES 用户发送垃圾邮件？",
        "intention":"知识问答",
        "reply":"Amazon SES 使用内部的内容筛选技术来扫描电子邮件内容，以检查其是否为垃圾邮件和恶意软件。\n如果我们确定一个账户正在发送垃圾邮件或恶意内容，我们会暂停该账户发送其他电子邮件的能力。"
    },
    {
        "query":"Amazon SES 与 Amazon SNS 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon SES 适用于需要通过电子邮件发送通信内容的应用程序。Amazon SES 支持自定义的电子邮件标头字段，以及很多 MIME 类型。\n相反，Amazon Simple Notification Service (Amazon SNS) 适用于消息收发导向的应用程序，有多个订户通过选择的传输协议（包括 HTTP、Amazon SQS 和电子邮件），请求和接受时间关键型消息的“推送”通知。Amazon SNS 通知的正文不得超过 8192 个 UTF-8 字符串字符，不支持多媒体内容。"
    },
    {
        "query":"是否必须注册 Amazon EC2 或其他任何 AWS 服务方可使用 Amazon SES？",
        "intention":"知识问答",
        "reply":"Amazon SES 用户无须注册其他任何 AWS 服务。可访问互联网的任何应用程序均可使用 Amazon SES 来传输电子邮件，无论该应用程序是在自已的数据中心运行，还是在 Amazon EC2 中运行，抑或是作为客户端软件解决方案运行。"
    },
    {
        "query":"我收到了 Amazon SES 用户发送的垃圾邮件或其他未经请求的电子邮件。如何举报这些邮件？",
        "intention":"知识问答",
        "reply":"您可以通过向 [email-abuse@amazon.com](mailto:mailto:email-abuse@amazon.com) 发送电子邮件来举报滥用电子邮件的情况。  \n 为了帮助我们尽快有效地处理问题，请附上原始电子邮件的完整标头。有关获取多个常见电子邮件客户端的电子邮件标头的过程，请参阅 MxToolbox.com 网站上的[如何获取电子邮件标头](https://mxtoolbox.com/public/content/emailheaders/)。"
    },
    {
        "query":"如何提交功能请求或发送有关 Amazon SES 的其他产品反馈？",
        "intention":"知识问答",
        "reply":"您的 AWS 客户经理可以将您的功能请求和反馈直接发送给相应的团队。如果您目前没有 AWS 客户经理，也可以在 [Amazon SES 论坛](http://forums.aws.amazon.com/forum.jspa?forumID=90)上提供反馈。"
    },
    {
        "query":"如何获得 Amazon SES 的技术支持？",
        "intention":"知识问答",
        "reply":"如果您有 AWS Support 计划，可以直接通过基于 Web 的 AWS 管理控制台创建新的支持案例。AWS Support 计划的起价为每月 29 USD。有关 AWS Support 计划的更多信息，请访问 [https://aws.amazon.com/premiumsupport/](https://aws.amazon.com/cn/premiumsupport/)。\n打开新的技术支持案例\n如果您没有 AWS Support 计划，也可以在 [Amazon SES 论坛](http://forums.aws.amazon.com/forum.jspa?forumID=90)上提出问题并获得答案。"
    },
    {
        "query":"什么是数字孪生？",
        "intention":"知识问答",
        "reply":"数字孪生是单个真实系统的生动数字表示，通过动态更新数据来模拟真实系统的真实结构、状态和行为，以推动实现业务成果。"
    },
    {
        "query":"为什么要使用数字孪生？",
        "intention":"知识问答",
        "reply":"数字孪生通过加速对系统和流程的理解来改进运营决策，并推进更有效的行动，从而超越现有的建模方法来改善业务成果。数字孪生可应用于横跨系统或资产整个生命周期的各种用例，例如建筑、工厂、工业设备和生产线。对于工业运营，通过将物联网（IoT）数据与来自企业摄像头和数据库的数据连接和组合，并在 3D 可视化中呈现相应数据以便于理解，数字孪生可用于优化工厂运营、增加产量和提高设备性能。"
    },
    {
        "query":"什么是 AWS IoT TwinMaker？",
        "intention":"知识问答",
        "reply":"AWS IoT TwinMaker 作为一项服务，可以更快、更轻松地创建真实系统的数字孪生，并将其应用于改进运营领域。 创建数字孪生是一个复杂的过程，需要横跨运营技术（OT）系统、图形数据库、IoT 技术、用户界面和 3D Web 开发等领域的开发人员专业知识。要构建数字孪生，您必须手动连接不同来源的各种数据（例如，来自设备的时间序列传感器数据、来自摄像头的视频源，以及来自业务应用程序的维护记录），并将它们建模成一个图形，该图形可呈现真实环境中数据来源之间的关系。然后，您必须构建真实系统（例如，建筑、工厂、设备和生产线）的 3D 虚拟表示形式，并将真实世界的数据覆盖到 3D 可视化视图上。之后，开发人员必须为最终用户（例如工厂操作员和维护工程师）创建应用程序，以使用他们的数字孪生进行日常操作。AWS IoT TwinMaker 通过以下方式简化了这一流程：提供连接到多个来源的各种数据的服务；自动创建并管理数字孪生图形，该图形可整合并说明所连接的数据来源之间的关系；此外，提供一个简单的基于 Web 的工具来创建可显示数据和见解的 3D 可视化视图，从而创建数字孪生。"
    },
    {
        "query":"如何开始使用 AWS IoT TwinMaker？",
        "intention":"知识问答",
        "reply":"首先，登录 [AWS 管理控制台](https://console.aws.amazon.com/console/home)，然后导航到 AWS IoT TwinMaker。要了解详情，请参阅 AWS IoT TwinMaker [文档](https://docs.aws.amazon.com/iot-twinmaker/latest/guide/what-is-twinmaker.html)。要了解服务功能和示例数字孪生应用程序，请访问 AWS IoT TwinMaker [GitHub 存储库](https://github.com/aws-samples/aws-iot-twinmaker-samples)。\n问：如何使用 AWS IoT TwinMaker 创建数字孪生？\n首先，创建一个工作区，其中包含创建数字孪生所需的所有资源（例如模型和可视化资产）。\n在工作区内，创建代表设备数字副本的实体（例如，混合器或泵）。然后，将实体与连接器关联到数据存储（例如 [AWS IoT SiteWise](https://aws.amazon.com/cn/iot-sitewise/)），从而将来自不同数据存储的数据汇集在一起，并为所存储的数据添加设备背景。AWS IoT TwinMaker 会在您指定实体之间的关系时自动创建实体的数字孪生图形。\n接下来，使用基于 AWS IoT TwinMaker 控制台的场景编辑器，导入 3D 模型（例如 CAD 文件和点云扫描）来编辑场景，并定位 3D 资产以正确匹配和呈现您的真实环境和系统。您可以使用场景编辑器添加锚点，以添加将特定 3D 位置与该实体的数据流或用户操作连接起来的数据覆层。\n最后，使用适用于 [Amazon Managed Grafana](https://aws.amazon.com/cn/grafana/) 的 AWS IoT TwinMaker 插件创建基于 Web 的数字孪生应用程序，以构建嵌入 3D 场景的控制面板，并显示与来自数字孪生的真实系统运行状态有关的数据和见解。这些应用程序使用 AWS IoT TwinMaker 统一数据访问 API，以便在控制面板中填充数据。"
    },
    {
        "query":"AWS IoT TwinMaker 如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"AWS IoT TwinMaker 为各种数据存储提供内置连接器，包括用于时间序列传感器数据的 AWS IoT SiteWise、用于视频数据的 [Amazon Kinesis Video Streams](https://aws.amazon.com/cn/kinesis/video-streams/)，以及用于文档数据的 [Amazon Simple Storage Service（S3）](https://aws.amazon.com/cn/s3/)。AWS IoT TwinMaker 可连接到 AWS IoT SiteWise 以获取资产模型数据，还可连接到 Amazon S3 以获取可视资产文件和设备文档等资源。AWS IoT TwinMaker 可为 Grafana 和 Amazon Managed Grafana 提供插件，因此您可以创建基于 Web 的数字孪生应用程序，供最终用户监控和优化其运营。"
    },
    {
        "query":"如何在 AWS IoT TwinMaker 中为我的真实系统建模？",
        "intention":"知识问答",
        "reply":"要构建数字孪生，您首先需要一个呈现单个工作场所的工作区。工作区包含创建数字孪生所需的所有资源（例如模型和可视化资产）。在工作区内，您可以创建可呈现其真实系统的数字副本的实体。您还可以指定能形成数字孪生图形的实体之间的自定义关系。然后，连接到来自各种数据存储的数据，并为所存储的数据添加设备背景。借助 AWS IoT TwinMaker，您可以轻松地将这些数据汇集在一起，而无需创建其他数据存储，也不需要重新输入数据存储中已经存在的模式信息。要为数据存储中存在的数据提供上下文，您可以将实体与内置连接器关联到这些不同的数据存储，例如 AWS IoT SiteWise 中的时间序列传感器数据、Amazon Kinesis Video Streams 中的视频数据或 Amazon S3 中的文档数据，"
    },
    {
        "query":"什么是数字孪生图形？",
        "intention":"知识问答",
        "reply":"数字孪生图形是一种知识图形，用于构建和整理有关数字孪生的信息，从而更轻松地进行访问和理解。如果您创建的是呈现真实系统的数字副本的实体、指定实体之间的关系，并将这些实体连接到不同的数据来源，AWS IoT TwinMaker 会自动创建数字孪生图形，用于在图形数据库中整理关系信息。"
    },
    {
        "query":"AWS IoT TwinMaker 支持哪些数据存储？",
        "intention":"知识问答",
        "reply":"AWS IoT TwinMaker 支持内置连接器连接到 AWS IoT SiteWise 中的时间序列数据存储、Amazon Kinesis Video Streams 中的视频数据存储以及 Amazon S3 中的文档数据存储。您还可以编写自己的自定义数据连接器，以连接到 AWS 中的数据或第三方数据存储。"
    },
    {
        "query":"如何创建自定义数据连接器？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Lambda 服务为数据存储编写自定义连接器。利用 AWS Lambda，您可以运行连接到数据存储所需的自定义代码和逻辑，同时整合安全凭证、自定义查询以及原始数据的筛选和处理。您将使用由 AWS IoT TwinMaker 定义的标准接口创建 AWS Lambda 函数，它允许您仅使用 AWS IoT TwinMaker 统一数据访问 API 来读取和写入不同的数据存储，而无需使用各自的 API 查询每个数据来源。"
    },
    {
        "query":"如何为数字孪生添加视频数据？",
        "intention":"知识问答",
        "reply":"首先，您在 AWS IoT SiteWise 中创建资产模型和资产，用于呈现视频数据的来源，例如摄像头。然后，配置和部署 AWS IoT Greengrass 组件，即 [Greengrass Edge Connector for KVS](https://docs.aws.amazon.com/greengrass/v2/developerguide/kvs-edge-connector-component.html)，用于连接到摄像头，并将其视频数据上传到 Amazon Kinesis Video Streams。最后，利用 AWS IoT TwinMaker 将摄像头和视频数据与呈现真实系统数字副本的实体相关联。然后，您可以将此视频数据集成到真实系统和环境的 3D 可视化中，以显示实时视频或来自摄像机的特定视频片段的回放。\n问：如何在 AWS IoT TwinMaker 中编辑 3D 场景？\n您将之前构建的 3D 模型 [例如 CAD 和 Building Information Modeling（BIM）文件或点云扫描（针对 Web 优化并转换为 glTF 格式）] 导入到您在 Amazon S3 中的资源库中。利用 AWS IoT TwinMaker 场景编辑器，您可以将这些可视化资产融入场景中，并正确定位 3D 资产以匹配您的真实环境。此外，借助 AWS IoT TwinMaker，您还可以轻松地将实体中建模的数据（例如，泵或混合器）与您的 3D 可视化绑定。然后，您可以在场景编辑器中添加视觉组件，从而将特定 3D 位置与该实体的数据流或用户操作连接起来。例如，可以为 3D 场景中的混合器添加标签，然后将其连接到报告混合器当前状态的底层时间序列数据。添加此绑定后，您还可以配置规则（例如，温度大于 50 度），以更改混合器的视觉表示形式，以及用户单击它时的交互（例如，更新时间序列图表，仅关注选定的混合器）。\n问：支持哪些 3D 格式？\nAWS IoT TwinMaker 支持 [glTF](https://www.khronos.org/gltf/)（图形语言传输格式）格式的 3D 资产，该格式是一种 3D 文件格式，以 JSON 格式存储 3D 模型信息，可在应用程序中高效传输和加载 3D 模型。[glTF 格式](https://github.com/KhronosGroup/glTF)可最大限度地减少 3D 资产大小，减少解压缩和使用资产所需的运行时处理工作。使用 AWS 合作伙伴解决方案（例如，来自 [Pixyz](https://aws.amazon.com/marketplace/pp/prodview-6jfxsmawl75hw?ref_=srh_res_product_title) 的解决方案），可以轻松地将来自传统 CAD 应用程序的 3D 模型以及点云扫描转换为 glTF。\n问：如何为最终用户创建数字孪生应用程序？\nAWS IoT TwinMaker 可为 [Grafana](https://grafana.com/) 提供应用程序插件，作为创建最终用户应用程序的低代码选项。该插件提供自定义可视化面板，包括 3D 场景查看器和控制面板模板，以及用于连接到数字孪生数据并为最终用户快速创建交互式应用程序的数据源组件。Grafana 是一个热门的开源分析平台，使您能够查询、可视化、提醒和理解您的指标，无论这些指标存储在何处。AWS IoT TwinMaker 插件支持客户托管的 Grafana 部署以及 Amazon Managed Grafana，这是与 Grafana Labs 合作开发的开源 Grafana 的完全托管式 AWS 服务。\n问：AWS IoT TwinMaker 如何与 AWS 合作伙伴配合使用？\n您可以与 AWS 合作伙伴网络（APN）合作，这有助于您利用 AWS IoT TwinMaker 的功能，实现业务的数字孪生潜力。APN 包括可提供托管在 AWS 平台上或与 AWS 平台集成的数字孪生软件解决方案的合作伙伴，以及有助于您在 AWS 上设计、架构、迁移或构建新的数字孪生应用程序的合作伙伴。我们还有提供软件工具和系统的合作伙伴，这些软件工具和系统提供数据、模拟和可视化服务，用于通过 AWS IoT TwinMaker 创建数字孪生。有关更多信息，请访问[合作伙伴](https://aws.amazon.com/cn/iot-twinmaker/partners/)页面。"
    },
    {
        "query":"什么是 AWS CodeBuild？",
        "intention":"知识问答",
        "reply":"AWS CodeBuild 是一项在云中完全托管的持续集成服务。CodeBuild 可编译源代码、运行测试，并生成可供部署的软件包。使用 CodeBuild，您无需预置、管理和扩展自己的构建服务器。CodeBuild 可自动扩展和缩减以及并发处理多项构建任务，因此您的构建任务不必在队列中等待。您可以使用 CodeBuild 预先打包的构建环境快速开始，也可以使用自定义构建环境来使用自己的构建工具。使用 CodeBuild，您只需按分钟付费。"
    },
    {
        "query":"为什么应该使用 CodeBuild？",
        "intention":"知识问答",
        "reply":"您不必自行安装、修补和维护构建服务器软件，可以享受 CodeBuild 的完全托管体验。您将构建任务提交给 CodeBuild 后，它会为每个构建任务创建临时计算容器，在容器中运行构建任务，完成后丢弃容器。您无需管理构建服务器硬件或软件。CodeBuild 还会根据您的构建任务量自动进行扩展。它会立即处理您提交的每个构建任务，可以并发运行各个构建任务，也就是说，您的构建任务永远不会在队列中等待。"
    },
    {
        "query":"CodeBuild 如何定价？",
        "intention":"知识问答",
        "reply":"有关详细信息，请参阅 [AWS CodeBuild 定价页面](https://aws.amazon.com/codebuild/pricing/)。"
    },
    {
        "query":"我可以用 CodeBuild 自动执行发布过程吗？",
        "intention":"知识问答",
        "reply":"可以。CodeBuild 与 AWS CodePipeline 集成。您可以添加构建操作，设置在云中运行的持续集成和持续交付过程。您可以在[此处](https://docs.aws.amazon.com/codebuild/latest/userguide/how-to-create-pipeline.html)了解如何从 CodePipeline 控制台设置和监控您的构建任务。"
    },
    {
        "query":"什么是构建项目？",
        "intention":"知识问答",
        "reply":"构建项目用于定义 CodeBuild 运行构建任务的方式。它包括的信息有源代码获取位置、使用的构建环境、运行的构建命令和存储构建输出的位置等。构建环境是由操作系统、编程语言运行时和 CodeBuild 用于运行构建任务的工具组成的。"
    },
    {
        "query":"如何配置构建项目？",
        "intention":"知识问答",
        "reply":"可以通过控制台或 AWS CLI 配置构建项目。您指定源存储库位置、运行时环境、构建命令、容器担任的 IAM 角色和运行构建任务所需的计算类。您也可以选择在 buildspec.yml 文件中指定构建命令。"
    },
    {
        "query":"CodeBuild 支持哪些源存储库？",
        "intention":"知识问答",
        "reply":"CodeBuild 可以连接到 AWS CodeCommit、S3、GitHub 和 GitHub Enterprise 为构建任务拉取源代码。"
    },
    {
        "query":"CodeBuild 支持哪些编程框架？",
        "intention":"知识问答",
        "reply":"CodeBuild 为支持的 Java、Ruby、Python、Go、Node.js、Android、.NET Core、PHP 和 Docker 版本提供预配置环境。您也可以自定义自己的环境，方法是创建 Docker 镜像并将其上传到 Amazon EC2 Container Registry 或 Docker Hub 注册表。然后您就可以在自己的构建项目中引用此自定义镜像。"
    },
    {
        "query":"CodeBuild 提供了哪些预配置的 Windows 构建运行时？",
        "intention":"知识问答",
        "reply":"CodeBuild 为 .NET Core 2.0 提供预配置的 Windows 构建环境。我们也希望为 Microsoft .NET Framework 客户（许多客户已拥有使用 Microsoft 专有库的许可证）提供预配置的构建环境，但 Microsoft 目前并不愿意与我们合作满足这些客户的要求。通过创建 Docker 镜像并将其上传到 Amazon EC2 Container Registry 或 Docker Hub 注册表，您可以自定义您的环境，以支持 .NET Framework 等其他构建目标。然后您就可以在自己的构建项目中引用此自定义镜像。"
    },
    {
        "query":"构建任务运行时会发生什么？",
        "intention":"知识问答",
        "reply":"CodeBuild 为构建项目中定义的类创建一个临时计算容器，用指定的运行时环境加载它，下载源代码，执行项目中配置的命令，将生成的项目上传到 S3 存储桶后销毁该计算容器。在构建期间，CodeBuild 会将构建输出流式传输到服务控制台和 Amazon CloudWatch。"
    },
    {
        "query":"如何设置第一个构建程序？",
        "intention":"知识问答",
        "reply":"登录 [AWS 管理控制台](https://console.aws.amazon.com/codebuild/)，创建一个构建项目，然后运行构建任务。有关 CodeBuild 的介绍，请参阅[入门](https://docs.aws.amazon.com/codebuild/latest/userguide/getting-started.html)了解分步教程。您也可以使用 [CodeBuild Local](https://aws.amazon.com/blogs/devops/announcing-local-build-support-for-aws-codebuild/) 在本地测试和调试您的构建。"
    },
    {
        "query":"我可以配合使用 CodeBuild 和 Jenkins 吗？",
        "intention":"知识问答",
        "reply":"可以。可以使用 [CodeBuild Plugin for Jenkins](https://github.com/awslabs/aws-codebuild-jenkins-plugin) 将 CodeBuild 集成到 Jenkins 任务中。构建任务会发送到 CodeBuild，无需配置和管理 Jenkins 工作程序节点。"
    },
    {
        "query":"我该如何查看过去的构建结果？",
        "intention":"知识问答",
        "reply":"您可以通过控制台、CloudWatch 或 API 获取过去的构建任务结果。构建结果包括结果（成功或失败）、构建持续时间、输出项目位置和日志位置。借助 CodeBuild 控制面板，您可以查看各项指标来了解一段时间内的构建行为。该控制面板会显示已尝试执行、成功和失败的构建任务数量以及构建任务持续时间。您还可以访问 CloudWatch 控制台查看更详细的构建任务指标。要了解有关使用 CloudWatch 监控 CodeBuild 的更多信息，请访问我们的文档。"
    },
    {
        "query":"如何调试过去失败的构建任务？",
        "intention":"知识问答",
        "reply":"您可以通过检查构建任务运行期间生成的详细日志来调试构建任务，也可以使用 [CodeBuild Local](https://aws.amazon.com/blogs/devops/announcing-local-build-support-for-aws-codebuild/) 在本地测试和调试构建任务。"
    },
    {
        "query":"为什么 build.general1.small 不支持适用于 Windows 的 .NET Core 构建环境？",
        "intention":"知识问答",
        "reply":"由于 Windows Docker 基本容器和其他库的大小，适用于 Windows 的 .NET Core 构建环境所需的内存和处理能力超出了 build.general1.small 计算实例类型的承受范围。基于这一限制，适用于 Windows 的 .NET Core 构建环境没有免费套餐。"
    },
    {
        "query":"如何接收 AWS CodeBuild 中各种事件的通知或警报？",
        "intention":"知识问答",
        "reply":"您可以针对影响您部署的事件创建通知。通知将以 [Amazon SNS](https://aws.amazon.com/sns/) 通知的形式出现。每个通知将包括状态消息以及指向其事件生成该通知的资源的链接。 通知没有额外成本；但您可能需要为通知使用的其他 AWS 服务付费，例如 Amazon SNS。要了解如何开始使用通知，请参阅[通知用户指南](https://docs.aws.amazon.com/codestar-notifications/latest/userguide/welcome.html)。此外，使用 [AWS Chatbot](https://aws.amazon.com/chatbot/) 的客户可以将通知配置为发送到其 Slack 通道或 Amazon Chime 聊天室。有关更多详情，请单击[此处](https://docs.aws.amazon.com/codestar-notifications/latest/userguide/notifications-chatbot.html)。"
    },
    {
        "query":"我可以加密 CodeBuild 存储的构建项目吗？",
        "intention":"知识问答",
        "reply":"可以。您可以指定存储在 AWS Key Management Service (AWS KMS) 中的密钥，从而加密您的项目。"
    },
    {
        "query":"CodeBuild 如何隔离属于其他客户的构建任务？",
        "intention":"知识问答",
        "reply":"CodeBuild 在与其他用户隔离的新环境中运行您的构建任务，并在完成后丢弃每个构建环境。CodeBuild 在基础设施和执行级别提供安全性和隔离。"
    },
    {
        "query":"我是否可以使用 AWS Identity and Access Management (IAM) 管理对 CodeBuild 的访问？",
        "intention":"知识问答",
        "reply":"可以。您可以通过 IAM 策略中的资源级权限控制对构建项目的访问。"
    },
    {
        "query":"CodeBuild 支持哪些区域？",
        "intention":"知识问答",
        "reply":"有关详细信息，请参阅[区域性产品和服务](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。\n了解有关 AWS CodeBuild 定价的更多信息"
    },
    {
        "query":"什么是 Amazon Inspector？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 是一项自动化漏洞管理服务，持续扫描 Amazon Elastic Compute Cloud (EC2)、AWS Lambda 函数和容器工作负载，从而发现软件漏洞和意外网络暴露。"
    },
    {
        "query":"Amazon Inspector 有哪些主要优势？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 允许您一步跨所有账户部署 Amazon Inspector，从而消除了与部署和配置漏洞管理解决方案相关的运营开销。其他优势包括："
    },
    {
        "query":"Amazon Inspector 与 Amazon Inspector Classic 有何区别？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 已重新架构并重建，以创建一项新的漏洞管理服务。以下是 Amazon Inspector Classic 的重要改进："
    },
    {
        "query":"我可以在同一个账户中同时使用 Amazon Inspector 和 Amazon Inspector Classic 吗？",
        "intention":"知识问答",
        "reply":"是的，您可以在同一个账户中同时使用这两种服务。"
    },
    {
        "query":"我如何从 Amazon Inspector Classic 迁移至新 Amazon Inspector？",
        "intention":"知识问答",
        "reply":"您只需删除账户中的所有评估模板即可停用 Amazon Inspector Classic。要访问现有评估运行结果，您可以下载这些结果作为报告或使用 Amazon Inspector API 导出这些结果。您可以通过在 AWS 管理控制台中单击几下或通过使用新 Amazon Inspector API 来激活新的 Amazon Inspector。您可以在 [Amazon Inspector Classic 用户指南](https://docs.aws.amazon.com/inspector/v1/userguide/index.html)中找到详细的迁移步骤。"
    },
    {
        "query":"Amazon ECR 的 Amazon Inspector 容器镜像扫描服务与 Amazon ECR 基于 Clair 的解决方案有何区别？",
        "intention":"知识问答",
        "reply":"|  | Amazon Inspector 容器镜像扫描 | Amazon ECR 基于 Clair 的解决方案 |\n| --- | --- | --- |\n| 扫描引擎 | Amazon Inspector 是 AWS 开发的一项漏洞管理服务，内置对 Amazon ECR 中的容器镜像的支持 | Amazon ECR 提供了一个托管式[开源 Clair 项目](https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html)作为基本的扫描解决方案 |\n| 资源包覆盖范围 | 识别操作系统（OS）资源包和编程语言（如 Python、Java 和 Ruby）资源包中的漏洞 | 仅识别 OS 资源包中的软件漏洞 |\n| 扫描频率 | 提供连续扫描和推送时扫描 | 仅提供推送时扫描 |\n| 漏洞情报 | 提供增强的漏洞情报，例如漏洞是否可用于 CVE 并在资源包版本修复指导中修复 | 仅提供有关软件漏洞的基本信息 |\n| 结果 | 可在 Amazon Inspector 和 ECR 控制台以及 Amazon Inspector 和 Amazon ECR 应用程序编程接口（API）和软件开发工具包（SDK）中查看结果 | 可在 Amazon ECR 控制台和 Amazon ECR API 和 SDK 中查看结果 |\n| 漏洞评分 | 提供情境化 Inspector 评分以及美国国家漏洞数据库 (NVD) 和供应商的通用漏洞评分系统 (CVSS) v2 和 v3 评分 | 仅 CVSS v2 评分 |\n| AWS 服务集成 | 已与 AWS Security Hub、AWS Organizations 和 AWS EventBridge 集成 | 没有与其他 AWS 服务的内置集成 |\n扫描引擎\nAmazon Inspector 是 AWS 开发的一项漏洞管理服务，内置对 Amazon ECR 中的容器镜像的支持\nAmazon ECR 提供了一个托管式[开源 Clair 项目](https://docs.aws.amazon.com/AmazonECR/latest/userguide/image-scanning.html)作为基本的扫描解决方案\n资源包覆盖范围\n识别操作系统（OS）资源包和编程语言（如 Python、Java 和 Ruby）资源包中的漏洞\n仅识别 OS 资源包中的软件漏洞\n扫描频率\n提供连续扫描和推送时扫描\n仅提供推送时扫描\n提供增强的漏洞情报，例如漏洞是否可用于 CVE 并在资源包版本修复指导中修复\n仅提供有关软件漏洞的基本信息\n结果\n可在 Amazon Inspector 和 ECR 控制台以及 Amazon Inspector 和 Amazon ECR 应用程序编程接口（API）和软件开发工具包（SDK）中查看结果\n可在 Amazon ECR 控制台和 Amazon ECR API 和 SDK 中查看结果\n漏洞评分\n提供情境化 Inspector 评分以及美国国家漏洞数据库 (NVD) 和供应商的通用漏洞评分系统 (CVSS) v2 和 v3 评分\nAWS 服务集成\n已与 AWS Security Hub、AWS Organizations 和 AWS EventBridge 集成\n没有与其他 AWS 服务的内置集成"
    },
    {
        "query":"Amazon Inspector 如何定价？",
        "intention":"知识问答",
        "reply":"如需了解完整的定价详情，请参阅 [Amazon Inspector 定价](https://aws.amazon.com/inspector/pricing/)页面。"
    },
    {
        "query":"Amazon Inspector 是否提供免费试用版？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 的所有新账户均有资格获得 [15 天的免费试用](https://console.aws.amazon.com/inspector/v2/home)，用于评估服务及估计成本。 试用期间，可免费持续扫描推送到 ECR 的所有合格的 Amazon EC2 实例、AWS Lambda 函数和容器镜像。您也可以在 Amazon Inspector 控制台查看预计的花费。"
    },
    {
        "query":"在哪些区域可以使用 Amazon Inspector？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 现已在全球推出。[此处](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)按区域列出了具体可用性。"
    },
    {
        "query":"如何开始使用？",
        "intention":"知识问答",
        "reply":"您只需在 AWS 管理控制台中点击几下，即可为您的整个企业或个人账户激活 Amazon Inspector。激活后，Amazon Inspector 自动发现正在运行的 Amazon EC2 实例、Lambda 函数和 Amazon ECR 存储库，并立即开始持续扫描工作负载，以发现软件漏洞和意外网络暴露。如果您是第一次使用 Amazon Inspector，将获得 [15 天免费试用](https://console.aws.amazon.com/inspector/v2/home)。"
    },
    {
        "query":"Amazon Inspector 结果是什么？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 结果是潜在的安全漏洞。例如，Amazon Inspector 检测软件漏洞或开放至计算资源的网络路径时，Amazon Inspector 会创建安全结果。"
    },
    {
        "query":"我能使用 AWS Organizations 结构管理 Amazon Inspector 吗？",
        "intention":"知识问答",
        "reply":"是。Amazon Inspector 已与 AWS Organizations 集成。您可以为 Amazon Inspector 配置 DA 账户，该帐户作为 Amazon Inspector 的主管理员账户，可用于对其进行集中管理和配置。DA 账户可以集中查看并管理 AWS 企业的所有账户的结果。"
    },
    {
        "query":"我如何委派 Amazon Inspector 服务的管理员？",
        "intention":"知识问答",
        "reply":"AWS Organizations 管理账户可在 Amazon Inspector 控制台中或通过使用 Amazon Inspector API 为 Amazon Inspector 分配 DA 账户。"
    },
    {
        "query":"我是否必须激活特定的扫描类型（即 Amazon EC2 扫描、Lambda 函数扫描或 Amazon ECR 容器镜像扫描）？",
        "intention":"知识问答",
        "reply":"如果您是第一次启动 Amazon Inspector，则默认会激活所有扫描类型，包括 EC2 扫描、Lambda 扫描和 ECR 容器镜像扫描。但是，您可以在组织的所有账户中停用其中任何一个或所有这些类型。现有用户可以在 Amazon Inspector 控制台中或使用 Amazon Inspector API 激活新功能。"
    },
    {
        "query":"我是否需要代理来使用 Amazon Inspector？",
        "intention":"知识问答",
        "reply":"这取决于您正在扫描的资源。对 Amazon EC2 实例进行漏洞扫描需要 AWS Systems Manager Agent (SSM Agent)。Amazon EC2 实例的网络可达性和容器镜像的漏洞扫描，或 Lambda 函数的漏洞扫描不需要代理。"
    },
    {
        "query":"如何安装并配置 Amazon Systems Manager Agent？",
        "intention":"知识问答",
        "reply":"要成功扫描 Amazon EC2 实例的软件漏洞，Amazon Inspector 要求用 [AWS Systems Manager](https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html) 和 [SSM Agent](https://docs.aws.amazon.com/systems-manager/latest/userguide/prereqs-ssm-agent.html) 管理这些实例。请参阅 AWS Systems Manager 用户指南中的 [Systems Manager 先决条件](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-prereqs.html)，了解如何激活和配置 AWS Systems Manager。有关托管式实例的信息，请参阅 AWS Systems Manager 用户指南中的托管式实例部分。"
    },
    {
        "query":"如何知道哪些 Amazon ECR 存储库配置了扫描？ 如何管理应配置哪些存储库进行扫描？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 支持配置包含规则，以选择扫描哪些 ECR 存储库。可在 ECR 控制台中的注册设置页面或使用 ECR API 创建并管理包含规则。匹配包含规则的 ECR 存储库配置了扫描。存储库的详细扫描状态在 ECR 和 Amazon Inspector 控制台中可见。"
    },
    {
        "query":"我如何知道我的资源是否正在被主动扫描？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 控制面板中的环境覆盖范围面板显示 Amazon Inspector 正在主动扫描的账户指标、Amazon EC2 实例、Lambda 函数和 ECR 存储库。每个实例和镜像的扫描状态：扫描或未扫描。扫描状态表示近乎实时地持续扫描资源。未扫描状态表示尚未执行初始扫描，操作系统不受支持，或扫描受阻。"
    },
    {
        "query":"多久执行一次自动化重新扫描？",
        "intention":"知识问答",
        "reply":"所有扫描都会根据事件自动执行。对于所有工作负载，在发现时，先进行初始扫描，然后进行重新扫描。"
    },
    {
        "query":"如何使用 Amazon Inspector 评测我的 Lambda 函数是否存在安全漏洞？",
        "intention":"知识问答",
        "reply":"在多账户结构中，您可以通过委派管理员（DA）账户从 Amazon Inspector 控制台或 API 为您在 AWS 组织内的所有账户激活 Amazon Inspector for Lambda 漏洞评估，其他成员账户则可以在中央安全团队尚未为他们激活 Amazon Inspector 时为各自的账户执行此操作。不属于 AWS 组织的账户可以通过 Amazon Inspector 控制台或 API 为其个人账户激活 Amazon Inspector。"
    },
    {
        "query":"如果 Lambda 函数有多个版本，Amazon Inspector 将评估哪个版本？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 将仅持续监控和评估 $LATEST 版本。自动重新扫描将仅针对最新版本继续进行，因此只会为最新版本生成新发现。在控制台中，您可以通过从下拉列表中选择版本来查看任何版本的结果。"
    },
    {
        "query":"我能否在不激活 Lambda 标准扫描的情况下激活 Lambda 代码扫描？",
        "intention":"知识问答",
        "reply":"不能。您有两种选择：要么单独激活 Lambda 标准扫描，要么同时启用 Lambda 标准扫描和代码扫描。Lambda 标准扫描为作为 Lambda 函数和关联层部署的应用程序中使用的易受攻击的依赖项提供基本的安全保护。Lambda 代码扫描可以在 Lambda 函数中扫描您的自定义专有应用程序代码以查找代码安全漏洞（例如注入缺陷、数据泄漏、弱加密或嵌入式机密），从而进一步提高安全价值。"
    },
    {
        "query":"将 SSM 目录收集频率从默认的 30 分钟更改为 12 小时对 Amazon Inspector 的连续扫描有何影响？",
        "intention":"知识问答",
        "reply":"更改 SSM 目录收集频率的原定设置可能会影响扫描的连续性。Amazon Inspector 依靠 SSM Agent 收集应用程序目录来生成结果。如果延长应用程序目录持续时间的原定设置 30 分钟，这将延迟对应用程序目录变更的检测，并延迟新结果。"
    },
    {
        "query":"Amazon Inspector 的风险评分是多少？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 风险评分是一个高度情境化的评分，系统通过将通用漏洞和暴露（CVE）信息与网络可达性结果、可利用性数据和社交媒体趋势关联，对每个结果生成该评分。这使您更容易对结果进行优先排序，并专注于最重要的结果和有漏洞的资源。您可以查看如何计算 Inspector 风险评分，以及哪些因素影响了结果详细信息侧面板中 Inspector 评分选项中的评分。\n示例：在您的 Amazon EC2 实例中存在已识别的新 CVE， 该 CVE 只能远程使用。如果 Amazon Inspector 持续网络可达性扫描还发现无法通过网络访问该实例，Amazon Inspector 就会发现漏洞的利用性太低。因此，Amazon Inspector 将扫描结果与 CVE 相关联，以向下调整风险评分，更准确地反映 CVE 对该特定实例的影响。"
    },
    {
        "query":"如何确定结果的严重性？",
        "intention":"知识问答",
        "reply":"| Inspector 评分 | 严重性 |\n| --- | --- |\n| 0 | 信息性 |\n| 0.2–3.9 | 低 |\n| 4.0–6.9 | 中 |\n| 7.0–8.9 | 高 |\n| 9.0–10.0 | 严重 |"
    },
    {
        "query":"如何使用禁止规则？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 允许您根据您设定的自定义标准禁止结果。您可以为您的企业认为可接受的结果创建禁止规则。"
    },
    {
        "query":"如何导出结果，包括哪些结果？",
        "intention":"知识问答",
        "reply":"您只需在 Amazon Inspector 控制台单击几下或使用 Amazon Inspector API，即可生成多种格式（CSV 或 JSON）的报告。您可以下载包含所有结果的完整报告，或者根据控制台中设置的视图筛选器生成并下载自定义报告。"
    },
    {
        "query":"如何为我的资源导出 SBOM，其中包含哪些内容？",
        "intention":"知识问答",
        "reply":"只需在 Amazon Inspector 控制台中或通过 Amazon Inspector API 执行几个步骤，就能以多种格式（CyclonedX 或 SPDX）为使用 Amazon Inspector 监控的所有资源生成和导出 SBOM。您可以使用 SBOM 下载所有资源的完整报告，也可以根据设置的视图筛选条件有选择地生成和下载一些选定资源的 sBOM。"
    },
    {
        "query":"我可以通过将 Amazon Inspector 设置为 VPC 来扫描我的私有 Amazon EC2 实例吗？",
        "intention":"知识问答",
        "reply":"可以。Amazon Inspector 使用 SSM Agent 收集应用程序目录，可以将其设置为 [Amazon Virtual Private Cloud (VPC) 端点](https://docs.aws.amazon.com/systems-manager/latest/userguide/setup-create-vpc.html)，避免在互联网上发送信息。"
    },
    {
        "query":"Amazon Inspector 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/inspector/latest/user/supported.html)找到支持的操作系统 (OS) 列表。"
    },
    {
        "query":"Amazon Inspector 支持哪些编程语言资源包进行容器镜像扫描？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/inspector/latest/user/supported.html)找到支持的编程语言资源包列表。"
    },
    {
        "query":"Amazon Inspector 可以与使用网络地址转换（NAT）的实例配合使用吗？",
        "intention":"知识问答",
        "reply":"可以。Amazon Inspector 自动支持使用 NAT 的实例。"
    },
    {
        "query":"我的实例使用代理。Amazon Inspector 会与这些实例配合使用吗？",
        "intention":"知识问答",
        "reply":"是。有关更多信息，请参阅[如何配置 SSM Agent 以使用代理](https://docs.aws.amazon.com/systems-manager/latest/userguide/sysman-proxy-with-ssm-agent.html)。"
    },
    {
        "query":"Amazon Inspector 可以与其他 AWS 服务集成来进行日志记录和提供通知吗？",
        "intention":"知识问答",
        "reply":"Amazon Inspector 与 Amazon EventBridge 集成提供事件通知，例如新结果、结果状态变更、或禁止规则创建。Amazon Inspector 还与 [AWS CloudTrail](https://aws.amazon.com/cloudtrail/) 集成，用于调用日志记录。"
    },
    {
        "query":"Amazon Inspector 提供“CIS 操作系统安全配置基准测试”扫描吗？",
        "intention":"知识问答",
        "reply":"不提供。目前 Amazon Inspector 不支持 CIS 扫描，但在未来将添加该功能。但是，您可以继续使用 Amazon Inspector Classic 提供的 CIS 扫描规则包。"
    },
    {
        "query":"Amazon Inspector 可与 AWS 合作伙伴解决方案搭配使用吗？",
        "intention":"知识问答",
        "reply":"可以。有关更多信息，请参阅 [Amazon Inspector 合作伙伴](https://aws.amazon.com/inspector/partners/)。"
    },
    {
        "query":"我可以停用 Amazon Inspector 吗？",
        "intention":"知识问答",
        "reply":"可以。您可以通过停用 Amazon Inspector 服务来停用所有扫描类型（Amazon EC2 扫描、Amazon ECR 容器镜像扫描和 Lambda 函数扫描），也可以单独为一个账户停用每种扫描类型。"
    },
    {
        "query":"我可以暂停 Amazon Inspector 吗？",
        "intention":"知识问答",
        "reply":"不可以。Amazon Inspector 不支持暂停状态。\n了解 Amazon Inspector 客户"
    },
    {
        "query":"什么是 Amazon EventBridge？",
        "intention":"知识问答",
        "reply":"Amazon EventBridge 是一项服务，让用户无需编写代码即可[实时访问](https://aws.amazon.com/eventbridge/integrations/) AWS 服务、用户自己的应用程序以及软件即服务 (SaaS) 应用程序中的数据变化。\n在开始使用之前，您可以在 EventBridge 控制台上选择事件源。然后，您可以从 AWS 服务中选择目标，包括 [AWS Lambda](https://aws.amazon.com/lambda/)、[Amazon Simple Notification Service (SNS)](https://aws.amazon.com/sns/) 和 [Amazon Kinesis Data Firehose](https://aws.amazon.com/kinesis/data-firehose/)。EventBridge 会近乎实时地自动传输事件。"
    },
    {
        "query":"如何开启使用 EventBridge？",
        "intention":"知识问答",
        "reply":"要开始使用 Amazon EventBridge，请按照以下六个步骤操作："
    },
    {
        "query":"能否将自己的事件推送到 EventBridge？",
        "intention":"知识问答",
        "reply":"可以。您可以生成应用程序级别的自定义事件，并通过 API 操作将其发送到 EventBridge。您还可以设置定期生成的计划事件，并在 EventBridge 支持的任何目标中处理这些事件。"
    },
    {
        "query":"事件采用什么格式？",
        "intention":"知识问答",
        "reply":"事件采用特定的 JSON 结构。每个事件都有相同的顶级信封字段，其中包含事件源、时间戳和区域等项目。这一字段的后面是详情字段，详情字段是事件的正文。\n例如，当 Amazon Elastic Compute Cloud（EC2）自动扩缩组创建新的 Amazon EC2 实例时，其发送的事件的事件源为“aws.autoscaling”，详情为“成功创建 EC2 实例”。"
    },
    {
        "query":"如何筛选传输到目标的事件？",
        "intention":"知识问答",
        "reply":"您可以使用规则来筛选事件。规则会针对给定的事件总线匹配传入的事件，然后将其路由到目标进行处理。一项规则可以将事件路由到多个目标进行并行处理。规则可以帮助不同的应用程序组件查找和处理自己想要处理的事件。\n规则可以对事件进行自定义（例如只传输特定部分或者使用常量覆盖事件），然后再将其发送到目标。以上一个问题中的示例为例，您可以创建一项事件规则，使其匹配事件源“aws.autoscaling”和详情“成功创建 EC2 实例”，这样您就可以在自动扩缩组成功创建 EC2 实例时收到通知。"
    },
    {
        "query":"如何保证对 EventBridge 的访问的安全性？",
        "intention":"知识问答",
        "reply":"EventBridge 集成了 [AWS Identity and Access Management (IAM)](https://aws.amazon.com/iam/)，因此您可以指定自己的 AWS 账户中的用户可以执行哪些操作。例如，您可以创建一项 IAM policy，只向企业中的特定用户授予创建事件总线或附上事件目标的权限。"
    },
    {
        "query":"EventBridge 与 Amazon CloudWatch Events 有什么关系？",
        "intention":"知识问答",
        "reply":"EventBridge 以 [Amazon CloudWatch Events](https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/WhatIsCloudWatchEvents.html) 为基础构建，是对 Amazon CloudWatch Events 的扩充。二者使用相同的服务 API 和端点，使用相同的底层服务基础设施。对于现有的 CloudWatch Events 客户，不会有任何变化。您可以继续使用相同的 API、AWS CloudFormation 模板和控制台。\nCloudWatch Events 是构建事件驱动型架构的理想服务，因此我们开发了一些新功能，帮助您从自己的应用程序和第三方 SaaS 应用程序连接数据。我们没有将这一功能保留在 CloudWatch 服务中，而是使用 Amazon EventBridge 这个新名称来发布这一功能，用于体现我们在 CloudWatch Events 的监控使用场景的基础上进行的扩充。"
    },
    {
        "query":"我现在使用 CloudWatch Events，想要试用 EventBridge 的功能。我是否需要把 CloudWatch Events 规则和权限转移到 EventBridge？",
        "intention":"知识问答",
        "reply":"不需要。现有的 CloudWatch Events 用户可以在新的 EventBridge 控制台和 API 或者 CloudWatch Events 控制台和 API 中访问其现有原定设置总线、规则和事件。"
    },
    {
        "query":"我已经在使用 CloudWatch Events，不需要 EventBridge 的功能。对我来说会有什么改变？",
        "intention":"知识问答",
        "reply":"没有改变。EventBridge 使用与 CloudWatch Events 相同的 API，因此对现有 CloudWatch Events API 的所有使用方式均保持不变。"
    },
    {
        "query":"亚马逊是否会逐步淘汰 CloudWatch Events？",
        "intention":"知识问答",
        "reply":"不会。我们不会弃用该服务或其 API。EventBridge 使用相同的 API 并具有额外的功能。随着时间的推移，Amazon CloudWatch Events 的名称将会被替换为 Amazon EventBridge。"
    },
    {
        "query":"哪些 AWS 服务被集成为 Amazon EventBridge 的事件源？",
        "intention":"知识问答",
        "reply":"有 90 多项 AWS 服务可以用作 EventBridge 的事件源，其中包括 [AWS Lambda](https://aws.amazon.com/lambda/)、[Amazon Kinesis](https://aws.amazon.com/kinesis/)、[AWS Fargate](https://aws.amazon.com/fargate/) 和 [Amazon Simple Storage Service (S3)](https://aws.amazon.com/s3/)。要查看 AWS 服务集成的完整列表，请参阅 [EventBridge 文档](https://docs.aws.amazon.com/eventbridge/latest/userguide/event-types.html)。"
    },
    {
        "query":"哪些 AWS 服务被集成为 EventBridge 的事件目标？",
        "intention":"知识问答",
        "reply":"有超过 15 项 AWS 服务可以用作 EventBridge 的事件目标，其中包括 [Lambda](https://aws.amazon.com/lambda/)、[Amazon Simple Queue Service (SQS)](https://aws.amazon.com/sqs/)、[Amazon SNS](https://aws.amazon.com/sns/)、[Amazon Kinesis Streams](https://aws.amazon.com/kinesis/data-streams/) 和 [Kinesis Data Firehose](https://aws.amazon.com/kinesis/data-firehose/)。要查看 AWS 服务集成的完整列表，请参阅 [EventBridge 文档](https://docs.aws.amazon.com/eventbridge/latest/userguide/what-is-amazon-eventbridge.html)。"
    },
    {
        "query":"什么是 EventBridge 存档和重播事件？",
        "intention":"知识问答",
        "reply":"事件重播是 EventBridge 的一项新功能，该功能可帮助您重新处理既往事件，将其再次放回到事件总线或特定的 EventBridge 规则中。这项功能可帮助开发人员更轻松地调试其应用程序，通过将历史事件与目标合成来扩展应用程序，并从错误中恢复。通过事件重播，开发人员将始终能访问发布到 EventBridge 的任何事件，从而保证其安心无虞。"
    },
    {
        "query":"什么是 EventBridge API 目标？",
        "intention":"知识问答",
        "reply":"API 目标可帮助开发人员将事件发回任何本地部署或 SaaS 应用程序，并且可以控制吞吐量和身份验证。您可以使用输入转换功能来配置规则，输入转换功能会将事件的格式映射到接收方服务的格式，EventBridge 则保证安全性和交付。\n启动规则时，EventBridge 将根据指定的条件转换事件。然后会使用设置规则时提供的身份验证信息将其发送到已配置的 Web 服务。由于内置安全机制，开发人员无需为其要使用的服务编写身份验证组件。"
    },
    {
        "query":"对于 API 目标来说，“连接”是什么意思？ 我该如何设置 API 目标？",
        "intention":"知识问答",
        "reply":"每个 [API 目标都使用一个“连接”，这个“连接”定义了用于连接到 HTTP 端点的授权方法和凭证](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-api-destinations.html)。配置授权设置并创建连接时，系统会在 AWS Secrets Manager 上创建一个密钥以安全地存储授权信息。您还可以根据自己的应用程序适当地添加更多参数，以包含连接。\n要设置 API 目标，您需要提供 API 目标端点，也就是事件的 HTTP 调用端点目标。您需要创建一个连接，以对此端点进行授权。您还可以选择定义调用速率限制，即每秒发送到 API 目标端点的调用次数上限。[详细了解连接和 API 目标](https://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/)。"
    },
    {
        "query":"有哪些服务限制？",
        "intention":"知识问答",
        "reply":"EventBridge 对发布事件的速率、可以在事件总线上创建的规则数量以及可以调用目标的速率有默认配额。有关配额的完整列表以及如何增加配额，请参阅[服务限额页面](https://docs.aws.amazon.com/eventbridge/latest/userguide/cloudwatch-limits-eventbridge.html)。"
    },
    {
        "query":"发送与接收事件之间的延迟有多长？",
        "intention":"知识问答",
        "reply":"典型延迟约为半秒。但要视具体情况而定。"
    },
    {
        "query":"EventBridge 是否支持资源标记？",
        "intention":"知识问答",
        "reply":"是的，您可以标记规则和事件总线。"
    },
    {
        "query":"EventBridge 的吞吐量有多大？",
        "intention":"知识问答",
        "reply":"可以增加 EventBridge 的默认限额，使其每秒处理数十万个事件。[AWS 服务限额页面给出了事件总线的吞吐量限额](https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-quota.html)。如果您需要更高的吞吐量，请在 [AWS Support Center](https://console.aws.amazon.com/support/) 选择“创建问题”，然后选择“放宽服务限制”，申请放宽服务限制。"
    },
    {
        "query":"EventBridge 是否有服务等级协议？",
        "intention":"知识问答",
        "reply":"是。AWS 将采取商业上合理的措施，确保在每个 AWS 区域，EventBridge 在任何月度结算周期的月度正常运行时间百分比至少达到 99.99%。有关详细信息，请查看完整的 [EventBridge 服务等级协议](https://aws.amazon.com/eventbridge/sla/)。"
    },
    {
        "query":"什么是 Schema？",
        "intention":"知识问答",
        "reply":"Schema 表示事件的结构，通常包括事件中所包含的各种数据的标题和格式等信息。\n例如，Schema 可能包括名称和电话号码等字段，而名称其实为文本串，电话号码为整数。Schema 还可能包括模式信息，例如要求电话号码的长度为 10 位数。事件的 Schema 非常重要，因为它显示了事件中包含了哪些信息，并帮助您根据这些数据类编写代码。"
    },
    {
        "query":"什么是 Schema 注册表？",
        "intention":"知识问答",
        "reply":"Schema 注册表存储了一个可搜索的 Schema 集合，因此组织中的任何开发人员都可以更容易地访问应用程序生成的 Schema。这与查看文档或查找 Schema 作者以获取此信息的方式不同。您可以手动将 Schema 添加到注册表中，或者通过启用 EventBridge Schema 发现功能自动执行该过程。"
    },
    {
        "query":"什么是 Schema 发现功能？",
        "intention":"知识问答",
        "reply":"Schema 发现功能可自动执行查找 Schema 并将其添加至注册表的过程。启用 EventBridge 事件总线的 Schema 发现功能后，系统会将发送至事件总线的每个事件的 Schema 自动添加至注册表。如果事件的 Schema 发生更改，Schema 发现会在注册表中自动创建新版本的 Schema。\n将 Schema 添加到注册表后，您可以在 EventBridge 控制台中或直接在集成式开发环境（IDE）中为该 Schema 生成代码绑定。这有助于将事件表示为代码中的强类型对象。然后，您可以利用 IDE 功能，如验证和自动完成。"
    },
    {
        "query":"我是否可以发现其他账户中所传输事件的 Schema？",
        "intention":"知识问答",
        "reply":"是的，在 [Schema 发现](https://aws.amazon.com/about-aws/whats-new/2021/09/cross-account-discovery-amazon-eventbridge-schema/)中，您可以发现跨账户的事件，这样您就可以全面了解发布到事件总线的事件架构。"
    },
    {
        "query":"Schema 注册表如何减少所需编写的代码数量？",
        "intention":"知识问答",
        "reply":"Schema 注册表允许您执行以下操作，从而减少代码量："
    },
    {
        "query":"为何应该使用 Schema 注册表？",
        "intention":"知识问答",
        "reply":"您应该使用 Schema 注册表来更快地构建事件驱动型应用程序。Schema 注册表可以自动从任何支持的事件源（包括 AWS 服务、第三方和自定义应用程序）查找可用事件并检测其 Schema，从而省去在开发团队之间进行协调所花费的时间。它旨在让开发人员能够专注于他们的应用程序代码，而不是将宝贵的时间浪费在搜索可用事件、它们的结构，以及编写代码来解释和翻译事件上。"
    },
    {
        "query":"Schema 注册表支持哪些 IDE？",
        "intention":"知识问答",
        "reply":"Schema 注册表可通过 AWS Toolkit for JetBrains（IntelliJ IDEA、PyCharm、WebStorm、Rider）和 [Visual Studio Code](https://aws.amazon.com/visualstudiocode/) 以及 EventBridge 控制台和 API 获得。了解有关[使用 IDE 中 EventBridge Schema 注册表](https://docs.aws.amazon.com/eventbridge/latest/userguide/eventbridge-schemas.html#eventbridge-schemas-toolkits)的更多信息。"
    },
    {
        "query":"Schema 是否可以与 AWS Serverless Application Model (SAM) 一起使用？",
        "intention":"知识问答",
        "reply":"可以，最新版本的 [AWS SAM CLI](https://aws.amazon.com/serverless/aws-sam/) 包含交互模式，可帮助您在 EventBridge 中为任何 Schema 以事件类型创建新的无服务器应用程序。\n选择 EventBridge Starter App 模板和您的事件的 Schema，SAM 将使用 EventBridge 所调用的 Lambda 函数自动生成应用程序，其中包含该事件的处理代码。这意味着您可以将事件触发视为代码中的一般对象，并使用 IDE 中的验证和自动完成等功能。\n[AWS Toolkit for Jetbrains](https://docs.aws.amazon.com/toolkit-for-jetbrains/latest/userguide/welcome.html)（Intellij IDEA、PyCharm、Webstorm、Rider）插件和 [AWS Toolkit for Visual Studio Code](https://aws.amazon.com/visualstudiocode/) 还提供将 Schema 作为触发器，通过这些 IDE 中的模板直接生成无服务器应用程序的功能。"
    },
    {
        "query":"我可以使用哪些语言从我的 Schema 生成代码？",
        "intention":"知识问答",
        "reply":"EventBridge 支持以 Java (8+)、Python (3.6+)、TypeScript (3.0+) 和 Go (1+) 语言生成代码。"
    },
    {
        "query":"Schema 注册表在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"EventBridge 架构注册表可在以下区域使用："
    },
    {
        "query":"什么是 Amazon EventBridge Pipes？",
        "intention":"知识问答",
        "reply":"EventBridge Pipes 提供了一种更简单、具有成本效益的一致方式，以在事件产生器和使用者之间创建点对点集成。创建管道就像选择来源和目标一样简单，可以自定义批处理、起始位置、并发等。可选的筛选步骤仅允许特定源事件流入管道，使用 AWS Lambda、AWS Step Functions、API Destinations 或 Amazon API Gateway 的可选扩充步骤可用于在事件到达目标之前扩充或转换事件。通过消除写入、管理和扩展无差别集成代码的必要性，EventBridge Pipes 允许您花费时间来构建应用程序而不是连接应用程序。"
    },
    {
        "query":"如何开始使用 EventBridge Pipes？",
        "intention":"知识问答",
        "reply":"您可以首先访问 EventBridge 控制台，选择管道选项卡，然后选择创建管道。在那里，您可以从可用源列表中进行选择，并提供一个可选的筛选模式，用于仅传输所需的事件。对于管道的可选转换和丰富步骤，可以提供 API 端点，例如 SaaS 应用程序 API 或容器集群、Lambda 函数或 AWS Step Function。处理完成后，管道将发出 API 请求并捕获响应。最后，设置事件传递到的目标服务，并指定是否需要在管道上启用归档或 DLQ 功能。您还可以使用 AWS 命令行界面（AWS CLI）、CloudFormation 或 AWS Cloud Development Kit（AWS CDK）创建管道。"
    },
    {
        "query":"EventBridge Pipes 可用的事件源有哪些？",
        "intention":"知识问答",
        "reply":"EventBridge Pipes 将 Amazon SQS、Amazon Kinesis、Amazon DynamoDB、Amazon Managed Streaming Kafka、自我管理型 Kafka 和 Amazon MQ 作为 EventBridge 产品套件的来源。EventBridge Pipes 支持与事件总线相同的目标服务（如 Amazon SQS、AWS Step Functions、Amazon Kinesis Data Streams、Amazon Kinesis Data Firehose、Amazon SNS、Amazon ECS）和事件总线本身。"
    },
    {
        "query":"转换和丰富如何运作？",
        "intention":"知识问答",
        "reply":"EventBridge Pipes 支持使用 Velocity 模板语言（VTL）的基本转换。对于更强大的转换，EventBridge Pipes 可帮助您指定 Lambda 函数或 Step Functions 工作流来转换事件。如果您希望使用容器服务，例如 Amazon Elastic Container Service（ECS）或 Amazon Elastic Kubernetes Service（EKS），可以为容器集群指定 API 端点和身份验证 Scheme。然后 EventBridge 将负责交付事件进行转换。"
    },
    {
        "query":"我是否需要使用 EventBridge 事件总线才能使用 EventBridge Pipes？",
        "intention":"知识问答",
        "reply":"不需要，EventBridge Pipes 可以独立于现有的 EventBridge 功能使用，帮助您从其他事件产生器（如 Kinesis、SQS 或 Amazon MSK）接收事件，而无需使用 EventBridge 事件总线。它还可以用于点对点集成，而事件总线用于多对多集成。如果您已经使用 EventBridge 事件总线来路由事件，则可以使用 EventBridge Pipes 连接到受支持的源，并将事件总线设置为管道的源。"
    },
    {
        "query":"EventBridge 事件总线和 EventBridge Pipes 之间的区别有哪些？",
        "intention":"知识问答",
        "reply":"EventBridge 事件总线非常适合事件驱动服务之间的多对多事件路由。EventBridge Pipes 旨在用于事件发布者和消费者之间的点对点集成，支持高级转换和丰富。EventBridge Pipes 可以使用 EventBridge 事件总线作为目标。从 EventBridge 事件总线规则迁移到管道更容易，因为两个资源之间的筛选和目标保持不变。"
    },
    {
        "query":"EventBridge Pipes 与 AWS Lambda 的事件源映射（ESM）有哪些不同？",
        "intention":"知识问答",
        "reply":"AWS Lambda 的事件源映射（ESM）和 Amazon EventBridge Pipes 使用相同的轮询基础设施来选择和发送事件。ESM 非常适合希望使用 Lambda 作为处理接收事件的目标的客户。Pipes 非常适合不担心创建、维护和扩展 Lambda 代码，而是希望使用一个简单的、受管理的资源将其源代码连接到超过 14 个目标之一的客户。"
    },
    {
        "query":"EventBridge Pipes 是否提供顺序保证？",
        "intention":"知识问答",
        "reply":"是的，当将事件发送到目标服务时，EventBridge Pipes 将保持从事件源接收的事件的顺序。"
    },
    {
        "query":"EventBridge Pipes 是否支持批处理事件？",
        "intention":"知识问答",
        "reply":"是的，对于支持批处理事件的服务，可以在创建管道时配置所需的批处理大小。对于不支持批处理的源和目标，您仍然可以选择为丰富和转换步骤批处理事件。这有助于您节省计算成本，同时也有助于将事件单独交付给您选择的目标。"
    },
    {
        "query":"我能否获得从我的账户发起的所有 EventBridge Pipes API 调用的历史记录，以便用于安全分析和运营方面的故障排除？",
        "intention":"知识问答",
        "reply":"可以。要获取从您的账户发起的 EventBridge Pipes API 调用的历史记录，您需要在 AWS 管理控制台中打开 CloudTrail 即可。"
    },
    {
        "query":"什么是 Amazon EventBridge 调度器？",
        "intention":"知识问答",
        "reply":"Amazon EventBridge 调度器是一种无服务器任务计划程序，可简化跨 AWS 服务的数百万个计划的创建、执行和管理，而无需预置或管理底层基础设施。"
    },
    {
        "query":"如何开始使用 EventBridge 调度器？",
        "intention":"知识问答",
        "reply":"登录您的 AWS 账户，导航到 EventBridge 控制台，然后选择创建计划按钮。按照分步工作流程操作并填写必填字段。选择一种计划格式，包括执行任务的时间窗口、固定速率、cron 或特定日期和时间。从 AWS 服务列表中选择您的目标并配置重试策略以最大限度地控制您的计划实施。查看您的计划，然后选择创建。"
    },
    {
        "query":"EventBridge 调度器 和 Scheduled Rules 有什么区别？",
        "intention":"知识问答",
        "reply":"EventBridge 调度器基于 Scheduled Rules 中提供的计划功能构建。EventBridge 调度器包括对时区的支持、增加的规模、自定义的目标负载、添加的时间表达式以及用于监控计划的仪表板。可以独立创建计划，而无需创建具有计划规则的事件总线。"
    },
    {
        "query":"应该何时使用 EventBridge Scheduled Rules 或 EventBridge Scheduler？",
        "intention":"知识问答",
        "reply":"Scheduled Rules 将继续可用，但 EventBridge Scheduler 提供了更丰富的功能集，在创建、执行和管理您的计划时提供更大的灵活性。您也可以免费开始使用，请参阅[定价页面](https://aws.amazon.com/cn/eventbridge/pricing/)以了解更多详情。"
    },
    {
        "query":"此功能如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"EventBridge 调度器与 AWS 服务深度集成，可以使用 AWS API 操作为任何服务创建计划。时间模式和重试的配置在 AWS 中是统一的，以提供一致的计划体验。借助 EventBridge 调度器控制台，您可以在仪表板中或通过“ListSchedule”API 请求获得计划视图，从而更轻松地监控计划。您将能够查看有关您的计划的关键信息，例如开始时间、上次运行和分配的 AWS 目标。有关更详细的信息，您可以查看 CloudWatch 日志中的执行日志，也可以将其发送到 S3 或 Kinesis Firehose。"
    },
    {
        "query":"如何更新我的计划？",
        "intention":"知识问答",
        "reply":"您可以通过选择要修改的计划在 EventBridge 调度器控制台中更新您的计划。此时将出现一个新的面板，其中显示了您的选项。"
    },
    {
        "query":"EventBridge 调度器是否支持所有时区？",
        "intention":"知识问答",
        "reply":"是的，使用 EventBridge 调度器，您可以选择计划将采用的时区。这些计划将自动调整为夏令时（DST）并返回标准时间。"
    },
    {
        "query":"EventBridge 调度器如何验证按时交付？",
        "intention":"知识问答",
        "reply":"EventBridge 调度器向目标提供至少一次事件传递，这意味着至少一次传递成功并得到目标的响应。可以使用设置重试、时间窗口和超时的选项来满足您的业务需求。"
    },
    {
        "query":"我如何监控计划的状态？",
        "intention":"知识问答",
        "reply":"EventBridge 调度器在 EventBridge 调度器控制台中为所有创建的计划提供了一个监控页面，您可以在其中查看计划及其实施的详细信息。这包括计划开始的时间、实施时间模式和目标交付状态，以及能够看到成功、失败或重试尝试的响应代码。"
    },
    {
        "query":"我可以为 AWS 之外的服务（例如我的本地服务器或外部 SaaS 产品）安排任务吗？",
        "intention":"知识问答",
        "reply":"EventBridge 调度器不直接支持非 AWS 目标。但是，您可以使用 [Lambda](https://aws.amazon.com/cn/lambda/)、[ECS](https://aws.amazon.com/cn/ecs/) 和 [Fargate](https://aws.amazon.com/cn/fargate/) 调用非 AWS 目标，或者[通过 API 目标功能使用 EventBridge 调用](https://aws.amazon.com/cn/eventbridge/features/)。"
    },
    {
        "query":"EventBridge 调度器的成本是多少？",
        "intention":"知识问答",
        "reply":"要查看 Amazon EventBridge 调度器定价的完整详细信息，请访问[定价页面](https://aws.amazon.com/cn/eventbridge/pricing/)。"
    },
    {
        "query":"什么是全局端点？",
        "intention":"知识问答",
        "reply":"[全局端点](https://aws.amazon.com/about-aws/whats-new/2022/04/amazon-eventbridge-global-endpoints-automatic-failover-recovery/)使您可以更轻松地使用 AWS 构建高度可用的事件驱动型应用程序。您可以跨主区域和次区域复制事件，以实现失效转移，同时将数据丢失降至最低。您还可以实现在任何服务中断时自动失效转移到备份区域的功能。这简化了多区域架构的采用，并帮助您将弹性整合到事件驱动型应用程序中。"
    },
    {
        "query":"为什么应该使用全局端点？",
        "intention":"知识问答",
        "reply":"全局端点通过最大程序减少服务中断期间面临风险的数据量，帮助为最终客户提供更好的体验。\n通过将事件接收自动失效转移到次要区域，而不需要人工干预，可以使事件驱动型应用程序更加可靠和有弹性。您可以灵活地使用 Amazon CloudWatch 警报（通过 Amazon Route 53 运行状况检查）来配置失效转移标准，从而确定何时进行故障转移以及何时将事件路由返回到主区域。"
    },
    {
        "query":"全局端点如何提高应用程序的可用性？",
        "intention":"知识问答",
        "reply":"一旦您在全局端点中发布事件，这些事件会被路由到主区域内的事件总线。如果在主区域中检测到错误，您的运行状况检查会被标记为不正常，且传入事件将被路由到次区域。使用您指定的 CloudWatch 警报（通过 Route 53 运行状况检查）可以更轻松地检测错误。当缓解问题后，我们会将新事件路由回主区域并继续处理事件。"
    },
    {
        "query":"什么类型的应用程序适合全局端点？",
        "intention":"知识问答",
        "reply":"全局端点非常适合不需要幂等性，或者可以处理跨区域的幂等性的应用程序。它们也非常适合于允许多达 420 秒的事件不被复制的应用程序。因此，在服务或区域恢复之前（称为恢复点目标），它们将一直停留在主区域。"
    },
    {
        "query":"我应该使用什么指标对我的全局端点进行失效转移？",
        "intention":"知识问答",
        "reply":"我们已经添加了一个新的指标，报告 EventBridge 的整个延迟，这可以帮助您更轻松地确定 EventBridge 内是否有错误，需要您的事件摄入失效转移到次区域。\n通过提供一个预填充的 CloudFormation 堆栈（如果您选择的话，可以对其进行自定义）来创建一个 CloudWatch 警报和 Route 53 运行状况检查，您可以更容易地开始使用控制台。有关如何设置警报和运行状况检查的更多详细信息，请查看我们的启动博客和文档。"
    },
    {
        "query":"我是否应该使用订阅者的指标来对我们的全局端点进行失效转移？",
        "intention":"知识问答",
        "reply":"我们建议不要在运行状况检查中包含订阅者指标。如果单个订阅者遇到问题，尽管主区域中的所有其他订阅者都处于正常状态，这样做还是可能会导致发布者失效转移到备份区域。\n如果您的其中一个订阅者无法处理主区域中的事件，您应该开启复制，以验证次区域中的订阅者是否能够成功地处理事件。"
    },
    {
        "query":"预期的恢复时间目标 (RTO) 和恢复点目标 (RPO) 是什么？",
        "intention":"知识问答",
        "reply":"[恢复时间目标 (RTO)](https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/disaster-recovery-dr-objectives.html) 是备份区域或目标在故障后开始接收新事件的时间。恢复点目标 (RPO) 是对故障期间未处理的数据的度量。使用全局端点时，如果您按照我们的规定指导进行警报配置，RTO 和 RPO 将为 360 秒（最大 420 秒）。对于 RTO，该时间包括启动 [CloudWatch 警报](https://aws.amazon.com/cloudwatch/)和更新 Route 53 运行状况检查的状态的时间段。对于 RPO，该时间包括未复制到次区域的事件，在业务或区域恢复之前，这些事件仍停留在主区域。"
    },
    {
        "query":"我是否应该开启复制？",
        "intention":"知识问答",
        "reply":"是。开启复制，以在服务中断时将数据风险最小化。一旦您在两个区域设置了自定义总线并创建了全局端点后，您就可以更新应用程序以将事件发布到全局端点。这样做以后，一旦问题得到缓解，传入的事件将被复制回主区域。您可以在次区域中对您的事件进行归档，以验证您的任何事件都不会在中断期间丢失。为了快速从中断恢复，您可以在次区域中复制您的架构，以继续处理您的事件。您还必须开启复制，以验证在问题得到缓解后自动恢复。"
    },
    {
        "query":"管理我的两个区域中的配额的最佳实践是什么？",
        "intention":"知识问答",
        "reply":"您应验证是否在主区域和次区域中设置了相同的配额。您应该打开复制并处理次区域中的事件，因为这不仅可以确保您拥有正确的配额，而且还可以验证次区域中的应用程序是否得到正确配置。"
    },
    {
        "query":"是否有一种更简单的方法来复制我的次区域中的架构？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS CloudFormation StackSets](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/what-is-cfnstacksets.html) 跨 AWS 区域更轻松地复制您的架构。关于示例，请参阅我们的文档。"
    },
    {
        "query":"我是否可以将任何账户、任何区域和任何总线用于我的次要架构？",
        "intention":"知识问答",
        "reply":"在启动的第一次迭代中，不支持选择加入、中国或 GovCloud 区域。有关本次发布中支持的区域列表，请参阅下面的问题。我们还支持跨区域的具有相同名称的相同账户和总线之间的失效转移和恢复。"
    },
    {
        "query":"全局端点是否与 CloudTrail、S3 和其他 AWS 服务中的 AWS 事件结合使用？",
        "intention":"知识问答",
        "reply":"全局端点仅可用于自定义事件。我们将在未来增加对 AWS 服务事件、S3 的选择加入事件（[Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)）和第三方事件的支持。"
    },
    {
        "query":"您是否支持基于延迟的路由？",
        "intention":"知识问答",
        "reply":"否，我们在启动的第一次迭代中，不支持基于延迟的路由。"
    },
    {
        "query":"全局端点可在哪些区域提供？",
        "intention":"知识问答",
        "reply":"全局端点在以下区域可用："
    },
    {
        "query":"能否让目标把事件发送到另一个账户？",
        "intention":"知识问答",
        "reply":"可以。这种事件称为跨账户事件，您可以将一个目标用作其他账户的原定设置事件总线或任何其他事件总线。这可用于将来自多个账户的事件集中到单个事件总线中，以便更轻松地监控和审核您的事件，并保持账户之间的数据同步。"
    },
    {
        "query":"CloudFormation 可否与 EventBridge 一起使用？",
        "intention":"知识问答",
        "reply":"可以。[所有推出 Amazon EventBridge 的区域](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)均提供 CloudFormation 支持。要了解有关如何使用 CloudFormation 预置和管理 EventBridge 资源的更多信息，请访问我们的[文档](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_Events.html)。"
    },
    {
        "query":"什么时候应该使用 EventBridge？什么时候应该使用 SNS？",
        "intention":"知识问答",
        "reply":"EventBridge 和 SNS 都可以用于开发事件驱动型应用程序，您可以根据自己的具体需求做出选择。\n如果您想要构建的应用程序需要对来自您自己的应用程序、SaaS 应用程序和 AWS 服务的事件做出反应，建议您使用 Amazon EventBridge。EventBridge 是直接与第三方 SaaS 合作伙伴集成的唯一一种基于事件的服务。EventBridge 还可以自动接收来自 200 多种 AWS 服务的事件，不需要开发人员在账户中创建任何资源。\nEventBridge 使用基于 JSON 并且明确的事件结构，帮助您创建应用于整个事件正文的规则，以便选择要发送到目标的事件。EventBridge 目前支持用作目标的 AWS 服务超过 20 种，其中包括 Lambda、SQS、SNS 以及 Amazon Kinesis Data Streams 和 Data Firehose。\n建议需要高扇出（数千或数百万个端点）的应用程序使用 Amazon SNS。我们看到的一种常见模式是，客户使用 SNS 作为其规则的目标，以筛选他们需要的事件并将其扇出到多个端点。\n消息为非结构化消息，可以采用任何格式。SNS 支持将消息发送到六种不同类型的目标，包括 Lambda、SQS、HTTP/S 端点、SMS、移动推送和电子邮件。[Amazon SNS 的典型延迟不超过 30 毫秒](https://aws.amazon.com/sns/faqs/)。您可以对包括 [Amazon EC2](https://aws.amazon.com/ec2/)、[Amazon S3](https://aws.amazon.com/s3/) 和 [Amazon RDS](https://aws.amazon.com/rds/) 在内的 30 多种 AWS 服务进行配置，使其发送 SNS 消息。"
    },
    {
        "query":"我为什么要将 SaaS 应用程序与 EventBridge 集成？",
        "intention":"知识问答",
        "reply":"Amazon EventBridge 可以让 SaaS 供应商将其服务更轻松地集成到客户构建在 AWS 上的事件驱动型架构中。\nEventBridge 让数百万 AWS 开发人员能够直接使用您的产品，并创造出各种新的使用场景。这一服务可以提供可审计、安全并且可扩展的事件发送通道，无需 SaaS 供应商管理任何事件基础设施。"
    },
    {
        "query":"我想让自己的 SaaS 公司成为事件源。应该怎样操作？",
        "intention":"知识问答",
        "reply":"想要成为 EventBridge 合作伙伴的 SaaS 供应商应该在 [Amazon EventBridge 集成页面](https://aws.amazon.com/eventbridge/integrations/)按照自助说明进行操作，然后才能在 EventBridge 中发布事件。"
    },
    {
        "query":"SaaS 供应商需要进行多少工作才能与 EventBridge 集成？",
        "intention":"知识问答",
        "reply":"对于已经支持 Webhook 或其他基于推送的集成模式的 SaaS 供应商，与 EventBridge 集成可能需要不到五天的时间。"
    },
    {
        "query":"支持哪些 SaaS 集成？",
        "intention":"知识问答",
        "reply":"我们支持超过 45 个 SaaS 集成，请参阅 [Amazon EventBridge 支持的 SaaS 集成](https://aws.amazon.com/eventbridge/integrations/)的完整列表。"
    },
    {
        "query":"如何通过互联网连接到我的 Amazon MSK 集群？ 最简单的方法是通过互联网开启至运行 Apache Kafka 2.6.0 或更高版本的 MSK 集群代理的公有连接。出于安全原因，您不能在创建 MSK 集群时开启公共访问。但是，您可以更新现有集群使其可公开访问。您还可以创建新的集群，然后将其更新为可公开访问。要了解有关开启公开访问的更多信息，请参阅公开访问文档。",
        "intention":"知识问答",
        "reply":"问：如何从 AWS 网络内部但在集群的 Amazon VPC 外部连接到我的 Amazon MSK 集群？  \n 您可以通过为运行 Apache Kafka 2.7.1 或更高版本的 MSK 集群开启多 VPC 私有连接，从与 MSK 集群不同的任何 VPC 或 AWS 账户连接您的 MSK 集群。您只能在为任何支持的身份验证方案（IAM 身份验证、SASL SCRAM 和 mTLS 身份验证）创建集群后开启私有连接。您应将客户端配置为使用 Amazon MSK 托管 VPC 连接私有连接到集群，该连接使用 AWS PrivateLink 技术启用私有连接。要了解有关设置私有连接的更多信息，请参阅[从 AWS 文档中访问。](https://docs.aws.amazon.com/msk/latest/developerguide/aws-access-mult-vpc.html)"
    },
    {
        "query":"What features does AWS Control Tower provide? AWS Control Tower automates the creation of a landing zone with best-practices blueprints that configure AWS Organizations for a multi-account structure, provide identity management using AWS IAM Identity Center (successor to AWS SSO), provide federated access using IAM Identity Center console, create a central log archive using AWS CloudTrail and AWS Config, enable security audits across accounts using IAM Identity Center, implement network configurations using Amazon Virtual Private Cloud (Amazon VPC), and define workflows for provisioning accounts using AWS Service Catalog and associated Control Tower solutions.",
        "intention":"知识问答",
        "reply":"AWS Control Tower offers “guardrails” for ongoing governance of your AWS environment. Guardrails provide governance controls by preventing deployment of resources that don’t conform to selected policies or detecting non-conformance of provisioned resources. AWS Control Tower automatically implements guardrails using multiple building blocks such as AWS CloudFormation to establish a baseline, AWS Organizations service control policies (SCPs) to prevent configuration changes, and AWS Config rules to continuously detect non-conformance.\nAWS Control Tower offers a dashboard for continuous oversight of your multi-account environment. You get visibility into provisioned accounts across your organization. Dashboards provide reports on detective and preventive guardrails you have enabled on your accounts, and they give you the status of resources that don’t comply with policies you have enabled through guardrails."
    },
    {
        "query":"Can I use AWS Control Tower to meet my data residency requirements? AWS Control Tower offers a set of preventive and detective guardrails to help with data residency. Data residency gives you control over where you host your customer content. It allows you to choose whether it’s hosted in multiple regions or held in place in a defined region.",
        "intention":"知识问答",
        "reply":"If you work in a regulated industry like finance, government, or healthcare, data residency may be a necessity for operating in a cloud environment. More generally, it can also help you meet company data management requirements."
    },
    {
        "query":"Is there an API available for AWS Control Tower? No. You can use AWS Control Tower through the AWS Management Console to perform all necessary operations.",
        "intention":"知识问答",
        "reply":"Q: How is AWS Control Tower different from the AWS Landing Zone solution?  \n AWS Control Tower is an AWS native service providing a pre-defined set of blueprints and guardrails to help you implement a landing zone for AWS accounts. [AWS Landing Zone](https://aws.amazon.com/solutions/implementations/aws-landing-zone/) is an AWS solution offered through AWS Solution Architect, Professional Services, or AWS Partner Network (APN) Partners that provides a fully configurable, customer-managed landing zone implementation. You can use either AWS Control Tower or the Landing Zone solution to create a foundational AWS environment based on best-practices blueprints implemented through AWS Service Catalog. AWS Control Tower is designed to provide an easy, self-service setup experience and an interactive user interface for ongoing governance with guardrails. While AWS Control Tower automates creation of a new landing zone with predefined blueprints (e.g., IAM Identity Center for directory and access), the AWS Landing Zone solution provides a configurable setup of a landing zone with rich customization options through custom add-ons (such as Active Directory- or Okta Directory) and ongoing modifications through a code deployment and configuration pipeline."
    },
    {
        "query":"什么是 AWS RoboMaker 模拟？",
        "intention":"知识问答",
        "reply":"AWS RoboMaker 模拟是一项完全托管式服务，可让您轻松创建模拟世界并运行模拟作业，而无需预置或管理任何基础设施。"
    },
    {
        "query":"RoboMaker 模拟有哪些作用？",
        "intention":"知识问答",
        "reply":"RoboMaker 模拟有多种使用案例。您可以使用 RoboMaker 模拟以自动化方式测试机器人应用程序并加速迭代开发。您可以使用它来生成合成图片或激光雷达数据以便开发算法。您还可以使用 RoboMaker 模拟通过强化学习来训练机器学习模型。"
    },
    {
        "query":"RoboMaker 模拟有哪些主要功能？",
        "intention":"知识问答",
        "reply":"RoboMaker 模拟提供完全托管式计算基础设施，可运行任何规模的模拟。借助 RoboMaker 模拟 WorldForge，可以自动创建数百个预定义的随机模拟世界，通过这些世界复制实际条件，而无需工程投入或管理世界生成基础设施。"
    },
    {
        "query":"RoboMaker 模拟运行支持哪些模拟引擎？",
        "intention":"知识问答",
        "reply":"RoboMaker 模拟支持您选择的任何模拟引擎。您可以将基于容器的模拟应用程序连接到 Robomaker，且无需预置、配置或管理任何基础设施即可运行模拟。该服务支持在 WorldForge 中创建兼容 Gazebo 的世界格式的模拟世界。"
    },
    {
        "query":"什么是 RoboMaker 中的机器人应用程序？",
        "intention":"知识问答",
        "reply":"RoboMaker 中的机器人应用程序是指要在实体机器人上运行的、基于机器人中间件（例如 ROS）的应用程序。您需要将机器人应用程序源代码构建到 X86 架构中，才能使用 RoboMaker 模拟。"
    },
    {
        "query":"什么是 RoboMaker 中的模拟应用程序？",
        "intention":"知识问答",
        "reply":"模拟应用程序中包含一个 3D 模拟世界和多种模拟器插件，这些插件可以控制机器人在模拟世界中的运动。与机器人应用程序一样，您需要将模拟应用程序源代码构建到 X86 架构中，才能使用 RoboMaker 模拟。"
    },
    {
        "query":"如何开始使用 RoboMaker 模拟运行？",
        "intention":"知识问答",
        "reply":"您可以通过创建机器人应用程序和/或模拟应用程序来开始使用 RoboMaker 模拟运行。这些应用程序关联到存储在 Amazon S3 存储桶中的代码。然后，您可以创建一个模拟作业，以在 RoboMaker 的完全托管的基础设施上执行模拟应用程序和机器人应用程序。"
    },
    {
        "query":"什么是模拟作业？",
        "intention":"知识问答",
        "reply":"模拟作业是 RoboMaker 模拟运行中的主要服务资源。您通过创建模拟作业在 RoboMaker 上运行模拟工作负载，模拟作业将自动为您预置和管理计算基础设施。[在我们的文档中了解有关创建模拟作业的更多信息](https://docs.aws.amazon.com/robomaker/latest/dg/application-create-simjob.html)。"
    },
    {
        "query":"什么是批量模拟作业？",
        "intention":"知识问答",
        "reply":"批量模拟作业是模拟作业请求的集合。您可以使用 AWS RoboMaker 的 API 创建新的批量模拟作业。使用批量模拟作业功能，您可以通过一次 API 调用提交多个模拟作业请求，并为提交的所有请求提供排队功能。"
    },
    {
        "query":"我可以使用哪些工具来构建机器人应用程序和模拟应用程序？",
        "intention":"知识问答",
        "reply":"您可以使用您已经熟悉的容器工具构建并将您的代码打包到兼容 Open Container Initiative（OCI）的镜像中，并将其存储在 Amazon Elastic Conatiner Registry（ECR）中。您可以使用这些镜像创建 RoboMaker 机器人应用程序和模拟应用程序。"
    },
    {
        "query":"什么是应用程序版本控制？",
        "intention":"知识问答",
        "reply":"RoboMaker 支持机器人应用程序和模拟应用程序的版本控制，因此您可以控制机器人和模拟使用的程序版本。版本是带有编号的机器人应用程序或模拟应用程序快照，您可以在开发工作流程的不同环节（例如开发、测试部署和生产）创建版本以便使用。"
    },
    {
        "query":"能否删除机器人应用程序或模拟应用程序的特定版本？",
        "intention":"知识问答",
        "reply":"可以，您可以删除某个应用程序的特定版本或所有版本。"
    },
    {
        "query":"RoboMaker 是否会存储我的机器人应用程序和模拟应用程序？",
        "intention":"知识问答",
        "reply":"否，RoboMaker 不会在服务中存储您的机器人应用程序或模拟应用程序。您自己将应用程序上传到 S3 存储桶中，然后在机器人应用程序和模拟应用程序创建过程中使用 S3 对象路径。"
    },
    {
        "query":"模拟作业的故障行为是什么？",
        "intention":"知识问答",
        "reply":"您可以将模拟作业的故障行为配置为失败或继续。在失败模式下，如果在模拟作业运行过程中发生故障，模拟作业会失败，并且底层基础设施会被释放。在继续模式下，如果在模拟作业运行过程中发生故障，模拟作业会失败，但底层基础设施会被保留。利用继续模式，您可以使用命令行工具进一步排除模拟作业的故障。在继续模式下，RoboMaker 模拟会继续产生费用，直到您终止作业为止。"
    },
    {
        "query":"在什么时候重启模拟作业？",
        "intention":"知识问答",
        "reply":"重启模拟作业可以用于快速迭代开发。重启模拟作业的速度比创建新模拟作业的速度要快，因为其不需要在后台预置和配置资源。在机器人应用程序开发期间，您可以使用重启模拟作业功能在迭代代码更改时快速测试代码。"
    },
    {
        "query":"重启模拟作业与克隆模拟作业有什么不同？",
        "intention":"知识问答",
        "reply":"重启模拟作业用于快速迭代测试，更新后的模拟作业在 RoboMaker 预置和管理的相同基础设施资源上运行。克隆模拟作业使用与现有作业相同的配置来创建新作业。其会在后台触发基础设施资源预置和配置，这可能需要几分钟时间。"
    },
    {
        "query":"为什么我需要在模拟作业中提供 AWS Identity and Access Management (IAM) 角色？",
        "intention":"知识问答",
        "reply":"IAM 角色让 RoboMaker 模拟能够访问您在模拟作业中指定的资源。例如，RoboMaker 可以将模拟日志写入您的 S3 存储桶。"
    },
    {
        "query":"什么是模拟持续时间？",
        "intention":"知识问答",
        "reply":"模拟持续时间定义了模拟作业在终止之前应该运行多长时间。持续时间取决于时钟时间和模拟时间。"
    },
    {
        "query":"模拟作业是否实时运行？",
        "intention":"知识问答",
        "reply":"RoboMaker 模拟会尝试尽快运行您的模拟作业。您也可以使用 Gazebo 世界配置中的“实时更新速度”和“最大步长”设置来控制模拟作业的运行速度。请参阅[定价页面](https://aws.amazon.com/cn/robomaker/pricing/)了解详细信息。"
    },
    {
        "query":"什么是模拟世界？",
        "intention":"知识问答",
        "reply":"模拟世界是房屋等环境的虚拟模型。在运行模拟时需要使用模拟世界，它包括建模环境的几何、视觉和物理信息。"
    },
    {
        "query":"为何需要使用 WorldForge？",
        "intention":"知识问答",
        "reply":"构建模拟世界可能非常困难、成本高昂且耗时，而且还需要具有 3D 建模和模拟引擎方面的专业技能。尽管有些公司具有创建一个模拟世界的时间和资源，但要想创建足够的世界来有效地针对回归测试和强化学习等工作负载扩展模拟却是极其困难且成本高昂的。\n借助 RoboMaker WordForge，可以自动创建数百个预定义的随机模拟世界，通过这些世界复制实际条件，而无需工程投入、专业的设计技能或管理世界生成基础设施。"
    },
    {
        "query":"我如何开始使用模拟 WorldForge？",
        "intention":"知识问答",
        "reply":"您可以通过创建一个世界模板来开始使用 WorldForge，在创建世界模板时可以从头开始，也可以使用 RoboMaker 提供的某个示例模板。然后，您可以借助世界模板，通过创建世界生成作业来生成一个或多个模拟世界。 如果您要在 RoboMaker Simulation 作业或本地环境中使用生成的世界，则可以通过创建世界导出作业来完成，该导出作业会将制定的世界作为 ROS 包以 .zip 格式导出到您的 Amazon S3 存储桶中。"
    },
    {
        "query":"什么是模拟世界模板？",
        "intention":"知识问答",
        "reply":"模拟世界模板用于定义模拟世界的规范。例如，您可以在世界模板中定义平面图、房间和装饰，以生成一组室内居住世界。世界模板不是用来精确定义一个模拟世界。相反，世界模板可以生成具有一定随机性的多个模拟世界，例如随机的房间大小和家具。世界模板的规范定义这种随机性的范围。"
    },
    {
        "query":"什么是世界生成作业？",
        "intention":"知识问答",
        "reply":"世界生成作业用于通过世界模板生成一个或多个模拟世界。在创建世界生成作业时，您可以通过两个维度（平面图和室内设计）指定世界版本数量。例如，如果有 2 个平面图，每个平面图有 2 种室内设计，则会形成 4 (2\\*2) 个独特世界。"
    },
    {
        "query":"什么是世界导出作业？",
        "intention":"知识问答",
        "reply":"世界导出作业可以将生成的世界作为 ROS 包以 .zip 格式导出到您的 Amazon S3 存储桶。需要在本地环境使用生成的世界或在运行 RoboMaker Simulation 时使用生成的世界，可以创建世界导出作业。"
    },
    {
        "query":"什么是域名系统 (DNS) 服务？",
        "intention":"知识问答",
        "reply":"[DNS](https://aws.amazon.com/cn/route53/what-is-dns/) 是一种全球分布式服务，可以将 www.example.com 等人类可读的名称转换为 192.0.2.1 等数字 IP 地址，供计算机用于互相连接。Internet 的 DNS 系统的工作原理和电话簿相似，都是管理名称和数字之间的映射关系。对于 DNS 而言，名称为方便人们记忆的域名 (www.example.com)，数字为指定计算机在 Internet 上位置的 IP 地址 (192.0.2.1)。DNS 服务器将名称请求转换为 IP 地址，对最终用户在 Web 浏览器中输入域名时所访问的服务器进行控制。这些请求称为“查询”。"
    },
    {
        "query":"什么是 Amazon Route 53？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 提供高度可用且可扩展的域名系统 (DNS)、域名注册和运行状况检查 Web 服务。设计用于为开发人员和企业提供一种非常可靠且经济高效的方式，把名称（如 example.com）转换为计算机用于互相连接的数字 IP 地址（如 192.0.2.1），从而将最终用户路由到 Internet 应用程序。您可以将 DNS 与运行状况检查服务组合使用，路由流量到运行正常的终端节点，或者独立监控终端节点和/或对其提供警报。您还可以购买和管理域名（例如 example.com），并自动为域配置 DNS 设置。Route 53 高效地将用户请求连接到 AWS 中运行的基础设施，例如 Amazon EC2 实例、Elastic Load Balancing 负载均衡器或 Amazon S3 存储桶，还可以将用户转接到 AWS 外部的基础设施。"
    },
    {
        "query":"Amazon Route 53 可以用来做什么？",
        "intention":"知识问答",
        "reply":"借助 Amazon Route 53，您可以创建和管理公有 DNS 记录。与电话簿相似，Route 53 可让您管理 Internet 的 DNS 电话簿中为您的域名所列的 IP 地址。Route 53 也应答将此类特定域名转换为对应的 IP 地址（如 192.0.2.1）的请求。您可以使用 Route 53 创建新域的 DNS 记录，或转换现有域的 DNS 记录。Route 53 具有简单的标准型 REST API，可让您轻松创建、更新和管理 DNS 记录。Route 53 还额外提供运行状况检查，可以监控应用程序的运行状况和性能，还能监控 Web 服务器和其他资源。您还可以注册新的域名或者将现有域名转移到 Route 53 中进行管理。"
    },
    {
        "query":"如何开始使用 Amazon Route 53？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 具有简单易用的 Web 服务接口，短短几分钟便可开始使用。您的 DNS 记录将组织为“托管区域”，您可以使用 AWS 管理控制台或 Route 53 的 API 进行配置。要使用 Route 53，您只需："
    },
    {
        "query":"Amazon Route 53 如何提供高可用性和低延迟性？",
        "intention":"知识问答",
        "reply":"Route 53 使用 AWS 的高度可用且可靠的基础设施进行构建。我们的 DNS 服务器具有全球分布的特点，确保您可以规避任何 Internet 或网络相关的问题，始终如一地将最终用户路由到您的应用程序。Route 53 的宗旨是提供重要应用程序所需的依赖级别。Route 53 设计为通过分布于世界各地的 DNS 服务器任播网络，为根据网络条件自动从最优的节点回答查询。因此，该服务可为您的最终用户提供低查询延迟性。"
    },
    {
        "query":"Amazon Route 53 服务的 DNS 服务器名称是什么？",
        "intention":"知识问答",
        "reply":"为了向您提供高度可用的服务，每个 Amazon Route 53 托管区域都由其自己的一组虚拟 DNS 服务器提供服务。因此，在创建托管区域时，系统会分配各个托管区域的 DNS 服务器名称。"
    },
    {
        "query":"域和托管区域有什么区别？",
        "intention":"知识问答",
        "reply":"域是一般的 DNS 概念。域名是采用数字地址的 Internet 资源的易于识别的名称。例如，amazon.com 是域。托管区域是一种 Amazon Route 53 概念。托管区域和传统的 DNS 区域文件类似；它代表一组可以一起管理的记录，属于单个父域名。托管区域中的所有资源记录集合必须将该托管区域的域名作为后缀。例如，amazon.com 托管区域可能包含名为 www.amazon.com 和 www.aws.amazon.com 的记录，而不含名为 www.amazon.ca 的记录。您可以使用 Route 53 管理控制台或 API 创建、检查、修改和删除托管区域。您还可以使用管理控制台或 API 来注册新的域名，并将现有域名转移到 Route 53 中进行管理。"
    },
    {
        "query":"可以为 Amazon Route 53 上管理域名设置什么类型的访问控制？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Identity and Access Management（IAM）服务，控制对 Amazon Route 53 托管区域和单个资源记录集的管理访问。AWS IAM 可让您控制组织中的哪些人可以管理您的 DNS 记录的更改，具体方式为在您的 AWS 账户下创建多个用户，并管理各个用户的权限。 您可在[此处](https://aws.amazon.com/iam/)了解 AWS IAM 的更多信息。"
    },
    {
        "query":"我已订阅了 Amazon Route 53，但在尝试使用该服务时，它显示“AWS 访问密钥 ID 需要订阅服务。”",
        "intention":"知识问答",
        "reply":"在您注册新的 AWS 服务时，有时可能需要最多 24 小时才能激活，这一期间中您无法再次注册该服务。如果在等待了 24 小时以上还没收到确认激活的电子邮件，这可能表示您的账户或者付款详细信息授权存在问题。请联系 [AWS 客户服务](https://aws.amazon.com/contact-us/)以获取帮助。"
    },
    {
        "query":"Amazon Route 53 是否提供查询日志记录功能？",
        "intention":"知识问答",
        "reply":"您可以配置 Amazon Route 53 来记录与 Amazon Route 53 收到的查询相关的信息，包括日期时间戳、域名、查询类型和位置等。  当您配置查询日志记录后，Amazon Route 53 会开始将日志发送到 CloudWatch Logs。您可以使用 CloudWatch Logs 工具访问查询日志。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/query-logs.html)。"
    },
    {
        "query":"Amazon Route 53 是否提供服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"是。如果客户的月度正常运行时间百分比在任何账单周期内低于我们的服务承诺，Amazon Route 53 授权服务和 Amazon Route 53 Resolver Endpoints 服务都将提供服务补偿。可从 [Amazon Route 53 服务等级协议](https://aws.amazon.com/cn/route53/sla/)和 [Amazon Route 53 Resolver Endpoints 服务等级协议](https://aws.amazon.com/cn/route53/resolver/sla/)了解更多信息。"
    },
    {
        "query":"Amazon Route 53 是否使用任播网络？",
        "intention":"知识问答",
        "reply":"是。任播是一种联网和路由技术，可帮助最终用户的 DNS 查询从给定网络条件中最佳的 Route 53 节点获得回答。您的用户因此就能通过 Route 53 获得高可用性和改进的性能。"
    },
    {
        "query":"使用 Amazon Route 53 管理的托管区域是否有数量限制？",
        "intention":"知识问答",
        "reply":"每个 Amazon Route 53 账户的托管区域上限为 500 个，每个托管区域的资源记录集最多 10000 条。请填写[提高上限申请表](https://aws.amazon.com/route53-request/)，我们将在两个工作日之内答复您的请求。"
    },
    {
        "query":"怎样将区域导入到 Route 53 中？",
        "intention":"知识问答",
        "reply":"Route 53 支持导入标准 DNS 区域文件，此类文件可以从众多 DNS 提供商处导出得到，也可以从 BIND 等标准 DNS 服务器软件导出得到。对于新创建的托管区域，以及除默认 NS 和 SOA 记录之外皆为空的现有托管区域，可以将您的区域文件直接粘贴到 Route 53 控制台中，Route 53 会自动在您的托管区域中创建记录。要开始导入区域文件，请阅读 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/rrs-changes-import-console.html)中的演示。"
    },
    {
        "query":"是否可以为同一域名设置多个托管区域？",
        "intention":"知识问答",
        "reply":"是。您可以通过创建多个托管区域，在“测试”环境中验证您的 DNS 设置，而后在“生产”托管区域中复制这些设置。例如，托管区域 Z1234 可能是您的 example.com 的测试版本，托管在名称服务器 ns-1, ns-2、ns-3 和 ns-4 上。类似地，托管区域 Z5678 可能是您的 example.com 的生产版本，托管在名称服务器 ns-5, ns-6、ns-7 和 ns-8 上。由于每个托管区域是与该区域关联的名称服务器虚拟集合， Route 53 将根据您向其发送 DNS 查询的名称服务器为 example.com 的 DNS 查询提供不同的回答。"
    },
    {
        "query":"Amazon Route 53 是否也提供网站托管？",
        "intention":"知识问答",
        "reply":"否。Amazon Route 53 属于授权型 DNS 服务，不提供[网站托管](https://aws.amazon.com/websites/)。不过，您可以使用 Amazon Simple Storage Service（Amazon S3）来托管静态网站。要托管动态网站或其他 Web 应用程序，您可以使用 Amazon Elastic Compute Cloud (Amazon EC2)；与传统[网站托管](https://aws.amazon.com/websites/)解决方案相比，它不仅能提供灵活性和控制，还可大幅节省开支。在[此处](https://aws.amazon.com/ec2/)了解有关 Amazon EC2 的更多信息。对于静态和动态网站，您都可以使用 Amazon CloudFront 为您的全球最终用户提供低延迟的传输。您可在[此处](https://aws.amazon.com/cloudfront/)了解 Amazon CloudFront 的更多信息。"
    },
    {
        "query":"Amazon Route 53 支持哪些 DNS 记录类型？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 目前支持下列 DNS 记录类型：\n我们预计在未来增加其他的记录类型。"
    },
    {
        "query":"Amazon Route 53 是否支持通配符条目？ 如果支持，支持的类型是什么？",
        "intention":"知识问答",
        "reply":"是。为了让您更加方便地为域配置 DNS 设置，Amazon Route 53 针对除 NS 记录以外的所有记录类型支持通配符条目。通配符条目是 DNS 区域中的记录，可以根据您设置的配置匹配任何域名。例如，通配符 DNS 记录 \\*.example.com 将匹配对 www.example.com 和 subdomain.example.com 的查询。"
    },
    {
        "query":"各种记录类型的默认 TTL 是多少？是否可以更改这些值？",
        "intention":"知识问答",
        "reply":"DNS 解析器用于缓存回复的时间是通过与各条记录关联的一个值设置的，它称为存活期 (TTL)。Amazon Route 53 没有任何记录类型的默认 TTL。您始终都必须为各种记录指定 TTL，以便缓存 DNS 解析器能够在通过 TTL 指定的时间长度内缓存您的 DNS 记录。"
    },
    {
        "query":"是否可以将“别名”记录用于子域？",
        "intention":"知识问答",
        "reply":"是。您还可以使用别名记录将子域（www.example.com、pictures.example.com 等）映射到 ELB 负载平衡器、CloudFront 分配或 S3 网站存储桶。"
    },
    {
        "query":"对资源记录集的更改是否是事务性的？",
        "intention":"知识问答",
        "reply":"是。事务性更改有助于确保更改是一致、可靠的，并且与其他更改独立。Amazon Route 53 已经过了设计，使得更改可在任何个体 DNS 服务器上彻底完成，或者完全不更改。这有助于确保 DNS 查询始终都能获得一致的回答，这在进行目标服务器之间翻转等更改时非常重要。在使用 API 时，对 ChangeResourceRecordSets 的每个调用将返回一个能跟踪相关更改的状态的识别符。一旦状态报告为 INSYNC 时，您的更改就已在所有 Route 53 DNS 服务器上执行完毕。"
    },
    {
        "query":"是否可以将多个 IP 地址与一条记录关联？",
        "intention":"知识问答",
        "reply":"是将多个 IP 地址与一条记录关联，常常用于平衡地理位置上分散的 Web 服务器的负载。Amazon Route 53 允许您为一条 A 记录列举多个 IP 地址，并使用包含所有配置的 IP 地址的列表回复 DNS 请求。"
    },
    {
        "query":"Amazon Route 53 上 DNS 设置更改的全球传播速度有多快？",
        "intention":"知识问答",
        "reply":"正常情况下，Amazon Route 53 的设计可以在 60 秒内将您对 DNS 记录的更新传播到其授权 DNS 服务器的全球网络中。当 API 调用返回 INSYNC 状态列表时，即表示更改已成功完成全球传播。\n请注意，缓存 DNS 解析器不在 Amazon Route 53 服务的控制范围内，它们将根据其生存时间 (TTL) 缓存您的资源记录集。更改的 INSYNC 或 PENDING 状态仅指示 Route 53 的授权 DNS 服务器的状态。"
    },
    {
        "query":"是否可以查看我所做更改以及对我的 Route 53 资源所做其他操作的历史记录？",
        "intention":"知识问答",
        "reply":"可以，通过 AWS CloudTrail，您可以记录 Route 53 的 API 调用历史记录。请参阅 [CloudTrail 产品页](https://aws.amazon.com/cloudtrail/)开始使用。"
    },
    {
        "query":"是否可以使用 AWS CloudTrail 日志来恢复对我的托管区域所做的更改？",
        "intention":"知识问答",
        "reply":"否。我们建议您不要使用 CloudTrail 来恢复对您的托管区域的更改，因为使用 CloudTrail 日志重建的托管区域更改历史记录可能不完整。\n您的 AWS CloudTrail 日志可用于安全分析、资源更改跟踪以及合规性审核等目的。"
    },
    {
        "query":"Amazon Route 53 是否支持 DNSSEC？",
        "intention":"知识问答",
        "reply":"是的。您可以为现有的和新的公有托管区域启用 DNSSEC 签名，并为 Amazon Route 53 Resolver 启用 DNSSEC 验证。此外，Amazon Route 53 支持在域注册时使用 DNSSEC。"
    },
    {
        "query":"Amazon Route 53 是否支持 IPv6？",
        "intention":"知识问答",
        "reply":"是。Amazon Route 53 支持正向 (AAAA) 和反向 (PTR) IPv6 记录。Amazon Route 53 服务本身也可通过 IPv6 使用。IPv6 网络上的递归 DNS 解析器可以使用 IPv4 或 IPv6 传输，以便向 Amazon Route 53 提交 DNS 查询。Amazon Route 53 运行状况检查也支持使用 IPv6 协议来监控终端节点。"
    },
    {
        "query":"是否可以将我的顶级域名（example.com 与 www.example.com 相比）指向我的 Elastic Load Balancer？",
        "intention":"知识问答",
        "reply":"可以。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将顶级域名 (example.com) DNS 名称映射到 ELB 负载均衡器的 DNS 名称（例如 my-loadbalancer-1234567890.us-west-2.elb.amazonaws.com）。与负载均衡器关联的 IP 地址随时会由于大小扩展或软件更新而改变。Route 53 使用负载均衡器的一个或多个 IP 地址来响应别名记录的每个请求。Route 53 支持三类负载均衡器的别名记录：Application Load Balancer、网络负载均衡器和 Classic Load Balancer。对映射到 AWS ELB 负载均衡器的别名记录的查询不收取额外费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"是否可以将我的顶级域名（example.com 与 www.example.com 对比）指向我托管在 Amazon S3 上的网站？",
        "intention":"知识问答",
        "reply":"是。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将域顶点 (example.com) DNS 名称映射到 Amazon S3 网站存储段（如 example.com.s3-website-us-west-2.amazonaws.com）。与 Amazon S3 网站终端节点关联的 IP 地址随时会由于大小扩展或软件更新而改变。Route 53 使用存储段的一个 IP 地址来回复别名记录的各个请求。Route 53 对映射到 S3 存储段且配置为网站的别名记录的查询不收取费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"是否可以将我的域顶点（example.com 与 www.example.com 相比）指向我的 Amazon CloudFront 分配？",
        "intention":"知识问答",
        "reply":"是。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将域顶点 (example.com) DNS 名称映射到您的 Amazon CloudFront 分配（如 d123.cloudfront.net）。与 Amazon CloudFront 终端节点相关联的 IP 地址会根据您的最终用户的位置而有所不同（目的是将最终用户定向至最近的 CloudFront 节点），会随时因为扩大规模、缩小规模或软件更新而改变。Route 53 使用分配的一个或多个 IP 地址来回复别名记录的各个请求。Route 53 对映射到 CloudFront 分配的别名记录的查询不收取费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"是否可以将我的顶级域名（example.com 对应 www.example.com）指向我的 AWS Elastic Beanstalk 环境？",
        "intention":"知识问答",
        "reply":"是。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将顶级域名 (example.com) DNS 名称映射到 AWS Elastic Beanstalk DNS 名称（即 example.elasticbeanstalk.com）。与 AWS Elastic Beanstalk 关联的 IP 地址随时可能由于大小扩展或软件更新而改变。Route 53 使用环境的一个或多个 IP 地址来响应针对别名记录的每个请求。对映射到 AWS Elastic Beanstalk 环境的别名记录的查询不收取费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"是否可以将我的顶级域名（example.com 与 www.example.com 对比）指向我的 Amazon API Gateway？",
        "intention":"知识问答",
        "reply":"可以。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将顶级域名 (example.com) DNS 名称映射到 Amazon API Gateway DNS 名称（如 api-id.execute-api.region.amazonaws.com/stage）。与 Amazon API Gateway 关联的 IP 地址随时会由于大小扩展或软件更新而改变。Route 53 使用 API Gateway 的一个或多个 IP 地址来响应针对别名记录的每个请求。对映射到 Amazon API Gateway 的别名记录的查询不收取额外费用。这些查询在 Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"是否可以将我的顶级域名（example.com 与 www.example.com 对比）指向我的 Amazon VPC 终端节点？",
        "intention":"知识问答",
        "reply":"可以。Amazon Route 53 提供一种称为“别名”记录的特殊记录类型，供您将顶级域名 (example.com) DNS 名称映射到 Amazon VPC 终端节点 DNS 名称（如 vpce-svc-03d5ebb7d9579a2b3.us-east-1.vpce.amazonaws.com）。与 Amazon VPC 终端节点关联的 IP 地址随时会由于大小扩展或软件更新而改变。Route 53 使用 VPC 终端节点的一个或多个 IP 地址来响应针对别名记录的每个请求。对映射到 Amazon VPC 终端节点的别名记录的查询不收取额外费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"如何将 Amazon Route 53 与 Amazon Simple Storage Service (Amazon S3) 和 Amazon CloudFront 协作？",
        "intention":"知识问答",
        "reply":"针对通过 Amazon CloudFront 传输的网站或托管于 Amazon S3 的静态网站，您可以使用 Amazon Route 53 服务为指向 CloudFront 分配或 S3 网站存储段的域创建别名记录。针对未配置托管静态网站的 S3 存储段，您可以为您的域和 S3 存储段名创建 CNAME。无论哪种情况，请注意，您也需要相应地使用备用域名条目配置 S3 存储段或 CloudFront 分配，以便在域名和存储段或分配的 AWS 域名之间建立完整的别名关系。\n针对 CloudFront 分配和配置托管静态网站的 S3 存储段，我们建议您创建映射到 CloudFront 分配或 S3 网站存储段的别名记录，而非使用 CNAME。别名记录有两种优势：首先，与 CNAME 不同，您可以针对域顶点（如 example.com，而不是 www.example.com）创建别名记录，其次，对别名记录的查询不收取费用。"
    },
    {
        "query":"DNS 查询测试工具为何会返回一个不同于 dig 或 nslookup 命令的响应？",
        "intention":"知识问答",
        "reply":"当 Amazon Route 53 中的资源记录集发生更改时，该服务会将您对 DNS 记录进行的更新传播到其权威 DNS 服务器在世界范围内的网络中。如果在传播完成之前测试记录，那么在使用 dig 或 nslookup 实用程序时看到的可能是一个旧值。此外，Internet 上的 DNS 解析程序不受 Amazon Route 53 服务的控制并且可根据生存时间 (TTL) 缓存资源记录集，这表示一个 dig/nslookup 命令可返回一个缓存值。您还应该确保您的域名注册商正在使用您 Amazon Route 53 托管区域中的名称服务器。如果不使用名称服务器，Amazon Route 53 将不会获得授权对您的域进行查询。"
    },
    {
        "query":"Amazon Route 53 是否支持加权轮询 (WRR)？",
        "intention":"知识问答",
        "reply":"是。加权轮询可让您为资源记录集合分配权重，以便指定不同回复所服务的频率。您可能希望使用此功能来执行 A/B 测试，发送一小部分流量到进行了软件更改的服务器。例如，假设您向一个 DNS 名称关联了两个记录集合，其中一个的权重为 3，另一个的权重为 1。此情形中，75% 时间内 Route 53 将返回权重为 3 的记录集合，25% 时间内 Route 53 将返回权重为 1 的记录集合。权重可以是 0 到 255 范围内的任意数字。"
    },
    {
        "query":"什么是 Amazon Route 53 的基于延迟的路由 (LBR) 功能？",
        "intention":"知识问答",
        "reply":"LBR（基于延迟的路由）是 Amazon Route 53 的一项新功能，有助于您提高应用程序对全球受众的性能。您可以在多个 AWS 地区运行应用程序，Amazon Route 53 则通过其遍布全球的节点将最终用户路由到可提供最低延迟性的 AWS 地区。"
    },
    {
        "query":"如何开始使用 Amazon Route 53 的基于延迟的路由 (LBR) 功能？",
        "intention":"知识问答",
        "reply":"只需通过 AWS 管理控制台或简单的 API，就能快速而轻松地使用 Amazon Route 53 的全新 LBR 功能。只需创建包含 IP 地址或各个 AWS 终端节点的 ELB 名称的记录集合，再将该集合标记为支持 LBR 的记录集合，这与将记录集合标记为加权记录集合非常相似。Amazon Route 53 将负责其余的工作 – 为各个请求确定最佳的终端节点并相应地路由最终用户，与 Amazon CloudFront 这一 Amazon 全球内容传输服务非常相似。有关如何使用基于延迟的路由的更多信息，请参阅 [Amazon Route 53 开发人员指南](http://docs.amazonwebservices.com/Route53/latest/DeveloperGuide/CreatingLatencyRRSets.html)。"
    },
    {
        "query":"Amazon Route 53 的 Geo DNS 功能是什么？",
        "intention":"知识问答",
        "reply":"Route 53 Geo DNS 会根据请求发出的地理位置将其送至特定的终端节点，以此帮助调整负载平衡。Geo DNS 可以自定义本地化的内容，例如以正确的语言展示详情页面或限制将内容分配到已授权的市场。Geo DNS 通过一种可以预见而又易于管理的方式让您实现负载平衡，确保每一个终端用户地点始终路由到相同的终端节点。Geo DNS 提供三种地理粒度级别：洲、国家/地区和州/省，Geo DNS 还提供全球记录，当终端用户的地点与您创建的特定 Geo DNS 记录不匹配时，全球记录可在这种情况下发挥作用。您还可以将 Geo DNS 与其他路由类型（例如基于延迟的路由和 DNS 故障转移）进行组合，以实现多种低延迟的容错架构。关于如何配置各种路由类型的信息，请参阅 [Amazon Route 53 文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html)。"
    },
    {
        "query":"如何开始使用 Amazon Route 53 的 Geo DNS 功能？",
        "intention":"知识问答",
        "reply":"只需通过 AWS 管理控制台或 Route 53 API，就能快速而轻松地使用 Amazon Route 53 的 Geo DNS 功能。只需创建记录集并对记录集的类型指定适用的值，将该记录集标记为启用了 Geo DNS 的记录集，然后选择想要记录生效的地理位置（全球、洲、国家/地区或州/省）。有关如何使用 Geo DNS 的详细信息，请参阅 Amazon Route 53 Developer Guide。"
    },
    {
        "query":"问：使用 Geo DNS 时，我是否必须拥有一份“全球”记录？ Route 53 何时会返回此记录？",
        "intention":"知识问答",
        "reply":"是，强烈建议您配置全球记录，以确保 Route 53 可以从所有可能的位置对 DNS 请求提供响应，即使您对期望终端用户所在的每一个洲、国家/地区或州/省创建了特定的记录也应该如此。Route 53 将返回以下案例中全球记录所包含的数值：\nDNS 查询来自 Route 53 的 Geo IP 数据库无法识别的 IP 地址。\nDNS 查询来自您创建的所有特定 Geo DNS 记录都不包含的位置。"
    },
    {
        "query":"我可以对一个大洲采用一份 Geo DNS 记录，而该大洲中不同国家/地区采用不同的 Geo DNS 记录吗？ 或者一个国家/地区采用一份 Geo DNS 记录，该国家/地区中的各州/省采用不同 Geo DNS 记录？",
        "intention":"知识问答",
        "reply":"可以，您可以对重叠的地理区域配置 Geo DNS 记录（例如洲和这个洲中的国家/地区，或者国家/地区和这个国家/地区中的州/省）。对于每个终端用户地点，Route 53 返回的大多数特定 Geo DNS 记录包含该地点。换言之，对于给定的终端用户地点，Route 53 会首先返回州/省记录。如果未找到任何州/省记录，则 Route 53 会返回国家/地区记录。如果未找到任何国家/地区记录，则 Route 53 会返回洲记录。最后，如果未找到任何洲记录，则 Route 53 会返回全球记录。"
    },
    {
        "query":"Route 53 的 Geo DNS 功能如何定价？",
        "intention":"知识问答",
        "reply":"与所有 AWS 服务一样，Amazon Route 53 和 Geo DNS 的使用没有前期费用或长期使用期限合约。客户只需按照实际的用量支付托管区域和查询的费用。有关 Geo DNS 查询的定价详细信息，请访问 [Amazon Route 53 定价页面](https://aws.amazon.com/route53/pricing/)。"
    },
    {
        "query":"基于延迟的路由和 Geo DNS 有何区别？",
        "intention":"知识问答",
        "reply":"Geo DNS 根据请求的地理位置制定路由决策。某些情况下，地理位置是很好的延迟代理；但是某些情况下则不然。基于延迟的路由利用查看者网络和 AWS 数据中心之间的延迟测量值。这些测量值用于确定引导用户到达了哪个终端节点。\n如果您的目标是尽量减少最终用户延迟，我们建议使用基于延迟的路由。如果您有合规性、本地化方面的要求，或者有需要从特定地理位置稳定路由至特定终端节点的其他使用案例，我们建议使用 Geo DNS。"
    },
    {
        "query":"Amazon Route 53 是否支持使用多个值响应 DNS 查询？",
        "intention":"知识问答",
        "reply":"Route 53 现在支持使用多值回答响应 DNS 查询。在 DNS 查询响应中返回多个可检查运行状况的 IP 地址这一功能并非负载均衡器的替代，这是使用 DNS 提高可用性和负载均衡能力的一种方式。如果您希望将流量随机路由到多个资源 (如 Web 服务器)，您可以为每个资源创建一条多值回答记录，然后选择性地将 Amazon Route 53 运行状况检查与每条记录关联。Amazon Route 53 最多支持使用八条正常记录响应每条 DNS 查询。"
    },
    {
        "query":"什么是 Amazon Route 53 Traffic Flow？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 Traffic Flow 是一项易于使用且经济实惠的全球流量管理服务。借助 Amazon Route 53 Traffic Flow，您可以运行全球的多个终端节点，并基于延迟、地理位置和终端节点的运行状况使用 Amazon Route 53 Traffic Flow 将您的终端用户连接到最佳终端节点，从而帮助用户提高应用程序的性能和可用性。Amazon Route 53 Traffic Flow 使开发人员可根据他们最关心的约束条件（包括延迟、终端节点的运行状况、负载、临近地理位置和地理位置）来轻松创建流量路由策略。客户可以使用一个简单的可视化策略生成器，在 AWS 管理控制台中自定义这些模板或者从头开始构建策略。"
    },
    {
        "query":"流量策略和策略记录有何区别？",
        "intention":"知识问答",
        "reply":"流量策略是指您为了将终端用户的请求路由到应用程序的一个终端节点而定义的规则集。您可以使用 Amazon Route 53 控制台中 Amazon Route 53 Traffic Flow 部分的可视化策略生成器来创建一个流量策略。您还可以将流量策略创建为 JSON 格式的文本文件，并利用 Route 53 API、AWS CLI 或多种 AWS 软件开发工具包上传这些策略。\n就其本身而言，流量策略不会影响将最终用户路由到应用程序的方式，因为它尚没有与应用程序的 DNS 名称（如 www.example.com）关联。要开始通过您创建的流量策略使用 Amazon Route 53 Traffic Flow 将流量路由到您的应用程序，您可以创建一个可将流量策略与您拥有的 Amazon Route 53 托管区域内的相应 DNS 名称关联的策略记录。例如，如果您希望使用已命名为 my-first-traffic-policy 的流量策略来管理 www.example.com 上应用程序的流量，您需要在托管区域 example.com 中为 www.example.com 创建一个策略记录，并选择将 my-first-traffic-policy 作为流量策略。\n策略记录在 Amazon Route 53 控制台的 Amazon Route 53 Traffic Flow 和 Amazon Route 53 托管区域部分均可见。"
    },
    {
        "query":"我是否可以使用相同的策略来管理多个 DNS 名称的路由？",
        "intention":"知识问答",
        "reply":"是。您可以重复使用一个策略来以两种方式之一管理多个 DNS 名称。首先，您可以利用该策略来创建更多策略。请注意，使用这种方法需要另外付费，因为我们会根据您创建的每条策略记录进行收费。\n第二种方法是利用策略创建一条策略记录，然后为您希望借助策略来管理的每一个附加 DNS 名称创建一个标准别名记录，它们均指向已创建策略记录的 DNS 名称。例如，如果您为 example.com 创建一条策略记录，您就可以为 www.example.com、blog.example.com 和 www.example.net 创建 DNS 记录，且每条记录都带有 example.com 的 CNAME 值。请注意，这种方法不适用于域名前无 www 或另一子域名的顶级域名（如 example.net、example.org 或 example.co.uk）中的记录。对于顶级域名中的记录，您必须使用您的流量策略创建一条策略记录。"
    },
    {
        "query":"我可以创建一个指向由流量策略管理的 DNS 名称的别名记录吗？",
        "intention":"知识问答",
        "reply":"可以，可以创建指向由一个流量策略管理的 DNS 名称的别名记录。"
    },
    {
        "query":"没有策略记录的流量策略需要付费吗？",
        "intention":"知识问答",
        "reply":"没有。我们只对策略记录进行收费，不对创建流量策略本身进行收费。"
    },
    {
        "query":"Amazon Route 53 Traffic Flow 的使用如何计费？",
        "intention":"知识问答",
        "reply":"根据每条策略记录计费。一条策略记录代表着一个 Traffic Flow 策略应用于特定 DNS 名称（如 www.example.com），以使用流量策略来管理如何对该 DNS 名称的请求作出应答的过程。将按月计费，并分摊到部分月份中。与策略记录中的 DNS 名称不相关的流量策略无需任何费用。有关定价的详细信息，请参阅 [Amazon Route 53 定价页面](https://aws.amazon.com/route53/pricing/)。"
    },
    {
        "query":"Amazon Route 53 Traffic Flow 支持哪些高级查询类型？",
        "intention":"知识问答",
        "reply":"Traffic Flow 支持所有 Amazon Route 53 DNS 路由策略，包括延迟、终端节点的运行状况、多值答案、加权轮询和地理位置。除此之外，Traffic Flow 还支持通过流量偏置实现基于临近地理位置的路由。"
    },
    {
        "query":"采用临近地理位置规则的流量策略是如何路由 DNS 流量的？",
        "intention":"知识问答",
        "reply":"创建流量的流动策略时，可指定 AWS 地区 (如果使用 AWS 资源的话) 或每个终端节点的经度和纬度。例如，假设您在 AWS 美国东部 (俄亥俄) 区域和美国西部 (俄勒冈) 区域均拥有 EC2 实例。当西雅图的用户访问您的网站时，临近地理位置路由会将 DNS 查询路由至美国西部（俄勒冈）区域的 EC2 实例，因为它的地理位置较为临近。有关更多信息，请参阅关于[临近地理位置路由](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-geoproximity)的文档。"
    },
    {
        "query":"某个终端节点的临近地理位置偏差值如何影响路由到其他终端节点的 DNS 流量？",
        "intention":"知识问答",
        "reply":"更改终端节点上的临近地理位置偏置值可以扩展或收缩 Route 53 将流量路由到资源的区域。不过，临近地理位置偏置无法准确预测负载因子，因为地理区域大小的微小变化可能会包括或排除产生大量查询的主要大城市区域。有关更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy.html#routing-policy-geoproximity)。"
    },
    {
        "query":"我可以对其他 Traffic Flow 规则应用偏置吗？",
        "intention":"知识问答",
        "reply":"截至目前，偏置仅适用于临近地理位置规则。"
    },
    {
        "query":"什么是私有 DNS？",
        "intention":"知识问答",
        "reply":"私有 DNS 是 Route 53 的一项功能，可以让您在 VPC 中拥有权威的 DNS 而不会将您的 DNS 记录（包括资源名称及其 IP 地址）暴露给互联网。"
    },
    {
        "query":"是否可以使用 Amazon Route 53 管理组织的专用 IP 地址？",
        "intention":"知识问答",
        "reply":"可以，您可以使用 Amazon Route 53 的私有 DNS 功能在 Virtual Private Clouds (VPCs) 中管理私有 IP 地址。通过私有 DNS，您可以创建私有的托管区域，当查询来自您与私有托管区域关联的 VPC 内部时，Route 53 将只返回这些记录。有关更多详细信息，请参阅 [Amazon Route 53 文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html)。"
    },
    {
        "query":"如何设置私有 DNS？",
        "intention":"知识问答",
        "reply":"您可以设置私有 DNS，方法是在 Route 53 中创建托管区域，选择选项让托管区域变成“私有”，再将托管区域与一个您的 VPC 进行关联。创建托管区域后，您可以将其与其他 VPC 进行关联。查看 [Amazon Route 53 文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-private.html)，了解私有 DNS 配置方法的完整介绍。"
    },
    {
        "query":"使用私有 DNS 是否需要连接到外部 Internet？",
        "intention":"知识问答",
        "reply":"您可以使用不连接互联网的 VPC 中的资源来解析内部 DNS 名称。但是，如果要更新私有 DNS 托管区域的配置，您需要互联网连接来访问 Route 53 API 终端节点，这个终端节点在 VPC 的外部。"
    },
    {
        "query":"如果不使用 VPC，能否使用私有 DNS？",
        "intention":"知识问答",
        "reply":"否。Route 53 私有 DNS 使用 VPC 来管理可见性并为私有 DNS 托管区域提供 DNS 解析。为了利用 Route 53 私有 DNS，您必须配置一个 VPC 并将资源迁移到其中。"
    },
    {
        "query":"能否为多个 VPC 使用同一个私有 Route 53 托管区域？",
        "intention":"知识问答",
        "reply":"能，您可以将多个 VPC 关联到一个托管区域。"
    },
    {
        "query":"是否能将由不同 AWS 账户创建的 VPC 和私有托管区域相关联？",
        "intention":"知识问答",
        "reply":"可以，您可以将从属于不同账户的 VPC 关联到同一个托管区域。有关更多详细信息，请参阅[此处](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zone-private-associate-vpcs-different-accounts.html)。"
    },
    {
        "query":"私有 DNS 能不能在所有 AWS 区域中使用？",
        "intention":"知识问答",
        "reply":"能。DNS 应答可以在与私有托管区域关联的每一个 VPC 中使用。注意，您需要保证每个区域中的所有 VPC 彼此相连，以便一个区域中的资源可以触及另一个区域中的资源。以下区域现已支持 Route 53 私有 DNS：美国东部（弗吉尼亚北部）、美国西部（加利福尼亚北部）、美国西部（俄勒冈）、亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲（法兰克福）、欧洲（爱尔兰）和南美洲（圣保罗）。"
    },
    {
        "query":"是否可以为私有 DNS 托管区域配置 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"可以，可以通过将运行状况检查与私有 DNS 托管区域中的资源记录集相关联来配置 DNS 故障转移。如果您的终端节点位于 Virtual Private Cloud (VPC) 中，那么您可以使用多种选项来配置针对这些终端节点的运行状况检查。如果终端节点具有公有 IP 地址，那么您可以针对每个终端节点的公有 IP 地址创建标准的运行状况检查。如果您的终端节点只有私有 IP 地址，那么您无法针对这些终端节点创建标准的运行状况检查。但是，您可以创建基于指标的运行状况检查，其运行方式类似于标准的 Amazon Route 53 运行状况检查，但使用现有 Amazon CloudWatch 指标作为终端节点运行状况信息的来源（而不是针对外部位置的终端节点进行请求）。"
    },
    {
        "query":"能否使用私有 DNS 在 VPC 中阻止不希望访问的域名和 DNS 名称？",
        "intention":"知识问答",
        "reply":"能，您可以阻止域和特定的 DNS 名称，方法是在一个或多个私有 DNS 托管区域中创建这些名称，然后将这些名称指派到您自己的服务器（或您管理的其他位置）。"
    },
    {
        "query":"什么是 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"DNS 故障转移包含两个组件，即：运行状况检查和故障转移。运行状况检查是通过 Internet 发送到您的应用程序的自动请求，目的是验证您的应用程序是否可获得、可用且功能正常。您可以配置与用户提交的一般请求相似的运行状况检查，例如从特定 URL 请求网页。利用 DNS 故障转移，Route 53 仅返回运行状态良好且可从外部访问的资源的响应，因此您的最终用户可以绕开出现故障或运行状态不佳的应用程序部分。"
    },
    {
        "query":"如何开始使用 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"请访问 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks.html)，了解有关入门的详细信息。您还可以从 Route 53 控制台配置 DNS 故障转移。"
    },
    {
        "query":"DNS 故障转移是否支持将 Elastic Load Balancer (ELB) 用作终端节点？",
        "intention":"知识问答",
        "reply":"可以，您可以为 Elastic Load Balancers (ELB) 配置 DNS 故障转移。若要启用一个 ELB 终端节点的 DNS 故障转移，请创建一个指向 ELB 的别名记录并将“Evaluate Target Health”参数设置为真。Route 53 会自动创建和管理您的 ELB 的运行状况检查。您无需创建您自己的 ELB Route 53 运行状况检查。您也不需要将您为 ELB 设置的资源记录与您自己的运行状况检查关联在一起，因为 Route 53 会代表您将它与 Route 53 管理的运行状况检查关联在一起。ELB 运行状况检查还会继承该 ELB 的后端实例的运行状况。要了解有关使用 ELB 终端节点进行 DNS 故障转移的更多详细信息，请参阅 [Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html)。"
    },
    {
        "query":"我是否可以配置仅在运行状况检查失败时使用的备份站点？",
        "intention":"知识问答",
        "reply":"可以，您可以使用 DNS 故障转移来维护备份站点（例如，Amazon S3 网站存储段上运行的静态站点）并在您的主要站点无法访问时转移到该站点。"
    },
    {
        "query":"可以将什么类型的 DNS 记录与 Route 53 运行状况检查相关联？",
        "intention":"知识问答",
        "reply":"您可以关联任何受 Route 53 支持的记录类型，除了 SOA 和 NS 记录。"
    },
    {
        "query":"如果我不知道终端节点的 IP 地址，是否可以检查其运行状况？",
        "intention":"知识问答",
        "reply":"是。您可以通过 Amazon Route 53 控制台配置 Elastic Load Balancer 和 Amazon S3 网站存储桶的 DNS 故障转移，这种方法无需创建您自己的运行状况检查。对于这些终端节点类型，Route 53 会代表您自动创建和管理运行状况检查，而这些运行状况检查会在您创建指向 ELB 或 S3 网站存储桶的别名记录和在该别名记录上启用“Evaluate Target Health”参数时使用。\n对于所有其他终端节点，当您为该终端节点创建运行状况检查时，您可以指定 DNS 名称（例如 www.example.com）或该终端节点的 IP 地址。"
    },
    {
        "query":"我的其中一个终端节点在 AWS 外部。是否能在此终端节点上设置 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"是。就像可以创建指向 AWS 外的地址的 Route 53 资源记录一样，您可以为在 AWS 外部运行的应用程序部分设置运行状况检查，并且可以转移到您选择的任何终端节点，无需理会位置。例如，您可以有一个在 AWS 外部的数据中心运行的历史应用程序和一个在 AWS 内运行的该应用程序的备份实例。您可以为在 AWS 外部运行的遗留应用程序设置运行状况检查，并且如果该应用程序未能通过运行状况检查，可以自动切换到 AWS 中的备份实例。"
    },
    {
        "query":"如果发生故障转移并且我拥有多个运行正常的终端节点，那么 Route 53 在决定从故障终端节点发送流量时，是否会考虑运行正常的终端节点上的负载情况呢？",
        "intention":"知识问答",
        "reply":"不会，Route 53 不会根据终端节点的负载或可用流量来决定路由目标。您将需要确保您的终端节点有可用容量，或这些终端节点具有扩展能力，以处理流向故障终端节点的流量。"
    },
    {
        "query":"终端节点需要未通过多少次连续运行状况检验观察才能视为“失败”？",
        "intention":"知识问答",
        "reply":"默认阈值为三次运行状况检验观察：当终端节点未通过三次连续的观察时，Route 53 将其视为失败。但是，Route 53 会继续对此终端节点执行运行状况检验观察，并在它通过三次连续的运行状况检验观察后重新向其发送流量。您可以将此阈值更改为 1 到 10 次观察之间的任何值。有关更多详细信息，请参阅 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html)。"
    },
    {
        "query":"当我的故障终端节点再次正常运行后，DNS 故障转移如何进行逆向转移呢？",
        "intention":"知识问答",
        "reply":"在失败的终端节点通过您在创建运行状况检查时指定的连续运行状况检验观察的次数后（默认阈值为三次观察），Route 53 将自动恢复其 DNS 记录，并且流向该终端节点的流量将在无需您操作的情况下恢复。"
    },
    {
        "query":"运行状况检验观察之间的间隔是多长时间？",
        "intention":"知识问答",
        "reply":"默认情况下，运行状况检验观察每隔 30 秒执行一次。您可以选择快速观察间隔时间，如 10 秒。\n通过以高出三倍的频率执行检查，快速运行状况检查间隔允许 Route 53 更快地确认发生故障的终端节点，从而缩短 DNS 故障转移重定向流量以响应终端节点故障所需的时间。\n快速运行状况检查间隔还会向您的终端节点生成三倍数量的请求，如果您的终端节点用于支持 Web 流量的容量有限，可能需要考虑此因素。访问 [Route 53 定价页面](http://aws.amazon.com/route53/pricing/)，获取关于快速间隔运行状况检查和其他可选运行状况检查功能定价的详细信息。有关更多详细信息，请参阅 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html)。"
    },
    {
        "query":"预计运行状况检查会在终端节点（例如，Web 服务器）上生成多少负载？",
        "intention":"知识问答",
        "reply":"每次运行状况检查都是从全球多个位置执行的。数量和位置集都是可配置的，对于使用 Amazon Route 53 控制台或 API 从多少个位置执行每个运行状况检查，是可以修改的。每个位置都将以您所选的间隔单独检查终端节点：默认间隔（30 秒）或可选的快速间隔（10 秒）。基于当前默认的运行状况检查位置数量，执行标准间隔运行状况检查时，您的终端节点平均每 2-3 秒收到一个请求，而执行快速间隔运行状况检查时，您会每秒收到一个或多个请求。"
    },
    {
        "query":"Route 53 运行状况检查是否会跟踪 HTTP 重定向？",
        "intention":"知识问答",
        "reply":"否。Route 53 运行状况检查将 HTTP 3xx 代码视为成功的响应，因此不会跟踪重定向。这可能会导致字符串匹配运行状况检查出现异常结果。运行状况检查将在重定向的正文中搜索指定的字符串。由于运行状况检查不遵循重定向，它永远不会将请求发送到重定向所指向的位置，因此也永远不会从该位置获得响应。对于字符串匹配运行状况检查，我们建议您不要使用把运行状况检查指向某个将返回 HTTP 重定向的位置。"
    },
    {
        "query":"进行故障转移时，将发生哪些事件？",
        "intention":"知识问答",
        "reply":"在最简单的条件中，如果运行状况检查未能通过需要进行转移，将发生以下事件：\nRoute 53 对您的应用程序执行运行状况检查。在这个示例中，您的应用程序连续三次未能通过运行状况检查，从而触发以下事件。\nRoute 53 禁用故障终端节点的资源记录并且不再服务于这些记录。这是故障转移步骤，它使流量路由到运行良好的终端节点，而不是故障终端节点。"
    },
    {
        "query":"我是否需要调整我的 TTL 记录以便使用 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"DNS 解析器用于缓存回复的时间是通过与各条记录关联的一个值设置的，它称为存活期 (TTL)。我们建议在使用 DNS 故障转移时，TTL 为 60 秒或更少，以尽量缩短使流量停止路由到故障终端节点所需的时间。为了配置 ELB 和 S3 网站终端节点的 DNS 故障转移，您需要使用 TTL 固定为 60 秒的别名记录；对于这些终端节点类型，您不需要调整 TTL 来使用 DNS 故障转移。"
    },
    {
        "query":"如果我所有的终端节点都无法正常运行，将会怎样？",
        "intention":"知识问答",
        "reply":"Route 53 只能转移到运行良好的终端节点。如果资源记录集中没有运行良好的终端节点，Route 53 将当所有运行状况检查都通过进行处理。"
    },
    {
        "query":"我是否能在不使用基于延迟的路由 (LBR) 的情况下使用 DNS 故障转移功能？",
        "intention":"知识问答",
        "reply":"是。您可以在不使用 LBR 的情况下配置 DNS 故障转移。尤其是，您可以使用 DNS 故障转移来配置简单的故障转移方案，其中 Route 53 监视您的主要网站并在您的主站点不可用时转移到备份站点。"
    },
    {
        "query":"我是否能在仅可通过 HTTPS 访问的站点上配置运行状况检查？",
        "intention":"知识问答",
        "reply":"是。Route 53 支持通过 HTTPS、HTTP 或 TCP 的运行状况检查。"
    },
    {
        "query":"HTTPS 运行状况检查是否会验证终端节点的 SSL 证书？",
        "intention":"知识问答",
        "reply":"不会，HTTPS 运行状况检查将测试是否能够通过 SSL 连接终端节点，以及终端节点是否会返回有效的 HTTP 响应代码。但是，它们不会验证终端节点返回的 SSL 证书。"
    },
    {
        "query":"HTTPS 运行状况检查是否支持服务器名称指示 (SNI)？",
        "intention":"知识问答",
        "reply":"是的，HTTPS 健康检查支持 SNI。"
    },
    {
        "query":"如何使用运行状况检查来验证我的 Web 服务器正在返回正确内容？",
        "intention":"知识问答",
        "reply":"您可以通过选择“启用字符串匹配”的选项来使用 Route 53 运行状况检查查看指定字符串是否存在于服务器响应中。此选项可用于检查 Web 服务器，验证其所服务的 HTML 包含预期字符串。或者您可以建立一个专用状态页面，使用它从内部或操作角度来检查服务器的运行状况。有关更多详细信息，请参阅 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-creating-deleting.html)。"
    },
    {
        "query":"如何查看我已创建的运行状况检查的状态？",
        "intention":"知识问答",
        "reply":"您可以在 Amazon Route 53 控制台中或通过 Route 53 API 查看运行状况检查的当前状态以及失败原因的详细信息。\n此外，每个运行状况检查的结果将作为 Amazon CloudWatch 指标进行发布，以显示终端节点的运行状况，也可选择性显示终端节点响应的延迟。您可以在 Amazon Route 53 控制台的运行状况检查选项卡中查看 Amazon CloudWatch 指标的图形，以查看运行状况检查的当前状态和历史状态。您也可为该指标创建 Amazon CloudWatch 警报，它将在运行状况检查的状态发生变化时发送通知。\n所有 Amazon Route 53 运行状况检查的 Amazon CloudWatch 指标也可以在 Amazon CloudWatch 控制台中查看。每个 Amazon CloudWatch 指标包含运行状况检查 ID（如 01beb6a3-e1c2-4a2b-a0b7-7031e9060a6a），您可使用它来识别该指标正在跟踪哪一个运行状况检查。"
    },
    {
        "query":"如何使用 Amazon Route 53 评估应用程序终端节点的性能？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 运行状况检查包含可选的延迟测量功能，它会就终端节点响应请求所花的时间提供相关数据。当您启用延迟测量功能后，Amazon Route 53 运行状况检查将生成额外的 Amazon CloudWatch 指标，以显示 Amazon Route 53 运行状况检查程序建立连接并开始接收数据所需的时间。Amazon Route 53 将为执行 Amazon Route 53 运行状况检查的每个 AWS 区域提供一组单独的延迟指标。"
    },
    {
        "query":"如何收到某个终端节点运行状况不良的通知？",
        "intention":"知识问答",
        "reply":"因为每个 Route 53 运行状况检查的结果都作为 CloudWatch 指标来发布，所以您可以配置全范围的 CloudWatch 通知和自动操作（会在运行状况检查值变化到您指定的阈值以外时触发）。首先，在 Route 53 或 CloudWatch 控制台中，为运行状况检查指标配置一个 CloudWatch 警报。然后添加一个通知操作，指定您想要发布通知的电子邮件或 SNS 主题。请参阅 [Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/monitoring-health-checks.html)以了解完整详情。"
    },
    {
        "query":"我已经为运行状况检查创建了警报，但需要重新发送该警报的 SNS 主题的确认电子邮件。如何重新发送此电子邮件？",
        "intention":"知识问答",
        "reply":"可以从 SNS 控制台重新发送确认电子邮件。要找到与该警报相关的 SNS 主题的名称，请单击 Route 53 控制台内的警报名称，然后在带有“发送通知到”标签的框中查找。\n在 SNS 控制台中，展开主题的列表，然后从警报中选择主题。打开“Create Subscription”框并为协议选择电子邮件，然后输入所需的电子邮件地址。点击“Subscribe”将重新发送确认电子邮件。"
    },
    {
        "query":"我正在使用 DNS 故障转移，同时将 Elastic Load Balancer (ELB) 用作终端节点。如何查看这些终端节点的状态？",
        "intention":"知识问答",
        "reply":"设置带有 ELB 终端节点的 DNS 故障转移的推荐方法是使用带有“Evaluate Target Health”选项的别名记录。因为您并未在使用此选项时针对 ELB 终端节点创建您自己的运行状况检查，所以这些终端节点并没有由 Route 53 生成的特定 CloudWatch 指标。\n您可以以两种方式获取有关负载均衡器的运行状况的指标。第一，Elastic Load Balancing 会发布负载均衡器的运行状况的指标，以及在负载均衡器上运行良好的实例数量的指标。有关配置针对 ELB 的 CloudWatch 指标的详细信息，请参阅 [ELB 开发人员指南](http://docs.aws.amazon.com/ElasticLoadBalancing/latest/DeveloperGuide/US_MonitoringLoadBalancerWithCW.html)。第二，您可以对照由 ELB 提供的别名记录（例如 elb-example-123456678.us-west-2.elb.amazonaws.com）创建您自己的运行状况检查。您不可将此运行状况检查用于 DNS 故障转移本身（因为“Evaluate Target Health”选项为您提供 DNS 故障转移），但是您可以查看此运行状况检查的 CloudWatch 指标，并创建在运行状况检查失败时通知您的警报。\n有关使用 ELB 终端节点进行 DNS 故障转移的完整的详细信息，请参阅 [Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover.html)。"
    },
    {
        "query":"对于指向 Amazon S3 网站存储桶的别名记录，当我将“Evaluate Target Health (评估目标运行状况)”设置为“true”时，将会检查哪些项目的运行状况？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 在每个 AWS 区域执行 Amazon S3 服务本身的运行状况检查。当您在指向 Amazon S3 网站存储段的别名记录上启用“Evaluate Target Health”时，Amazon Route 53 会考虑存储段所处的 AWS 区域中的 Amazon S3 服务的运行状况。Amazon Route 53 不会检查特定的存储段是否存在或者是否包含有效网站内容；仅在存储段所处的 AWS 区域中没有可用的 Amazon S3 服务时，Amazon Route 53 才会故障转移至另一位置。"
    },
    {
        "query":"我是否可以基于 CPU 负载、网络或内存等内部运行状况指标配置 DNS 故障转移？",
        "intention":"知识问答",
        "reply":"是。通过 Amazon Route 53 的基于指标的运行状况检查，您可以基于 Amazon CloudWatch 中提供的任何指标执行 DNS 故障转移，包括 AWS 提供的指标以及您的应用程序中的自定义指标。在 Amazon Route 53 中创建基于指标的运行状况检查时，只要相关 Amazon CloudWatch 指标进入警报状态，运行状况检查就会无法正常运行。\n基于指标的运行状况检查有助于对标准 Amazon Route 53 运行状况检查无法到达的终端节点（如 Virtual Private Cloud (VPC) 中只具有私有 IP 地址的实例）启用 DNS 故障转移。通过使用 Amazon Route 53 的计算运行状况检查功能，您还可以将基于指标的运行状况检查的结果与标准 Amazon Route 53 运行状况检查的结果结合起来，针对全球检查程序网络中的终端节点提出运行状况检查请求，从而完成更加高级的故障转移方案。例如，您可以创建这样一种配置：如果终端节点面向公众的网页无法访问或者 CPU 负载、网络输入/输出或磁盘读取次数等内部指标显示服务器本身运行不正常，该配置可使终端节点避免故障。"
    },
    {
        "query":"我的 Web 服务器从 Route 53 健康检查收到了我没有创建的请求。我如何停止这些请求？",
        "intention":"知识问答",
        "reply":"有些时候，Amazon Route 53 客户会创建健康检查，其中指定了不属于他们的 IP 地址或域名。如果您的 Web 服务器收到了不需要的 HTTP(s) 请求，并且您跟踪到了 Amazon Route 53 运行状况检查，请[使用此表单](https://aws.amazon.com/forms/route53-unwanted-healthchecks)来提供有关不需要的健康检查的信息，然后我们将与客户协作来更正此问题。"
    },
    {
        "query":"如果指定域名作为我的运行状况检查目标，Amazon Route 53 是通过 IPv4 还是通过 IPv6 进行检查？",
        "intention":"知识问答",
        "reply":"如果您指定域名作为 Amazon Route 53 运行状况检查的终端节点，Amazon Route 53 将查找该域名的 IPv4 地址并使用 IPv4 连接至该终端节点。Amazon Route 53 不会尝试查找由域名指定的终端节点的 IPv6 地址。如果您想要通过 IPv6 而不是 IPv4 进行运行状况检查，请选择“IP 地址”而不是“域名”作为您的终端节点类型，然后在“IP 地址”字段中输入 IPv6 地址。"
    },
    {
        "query":"哪里能找到由 Amazon Route 53 的 DNS 服务器和运行状况检查程序所使用的 IPv6 地址范围？",
        "intention":"知识问答",
        "reply":"AWS 现在以 JSON 格式发布其当前的 IP 地址范围。要查看当前范围，请使用以下链接下载该 .json 文件。如果您通过编程方式访问此文件，请确保应用程序仅在成功验证 AWS 服务器所返回的 TLS 证书后才下载该文件。\n下载 [ip-ranges.json](https://ip-ranges.amazonaws.com/ip-ranges.json)。\n要找到 Route 53 服务器的 IP 范围，请在“服务”字段中搜索以下值：\nRoute 53 DNS 服务器：搜索“ROUTE53”\nRoute 53 运行状况检查程序：搜索“ROUTE53\\_HEALTHCHECKS”\n有关更多信息，请参阅《Amazon Web Services 一般参考》中的 [AWS IP 地址范围](http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html)。\n请注意，IPv6 地址范围可能尚未显示在此文件中。仅供参考，Amazon Route 53 运行状况检查程序的 IPv6 地址范围如下所示：\n2600:1f1c:7ff:f800::/53  \n 2a05:d018:fff:f800::/53  \n 2600:1f1e:7ff:f800::/53  \n 2600:1f1c:fff:f800::/53  \n 2600:1f18:3fff:f800::/53  \n 2600:1f14:7ff:f800::/53  \n 2600:1f14:fff:f800::/53  \n 2406:da14:7ff:f800::/53  \n 2406:da14:fff:f800::/53  \n 2406:da18:7ff:f800::/53  \n 2406:da1c:7ff:f800::/53  \n 2406:da1c:fff:f800::/53  \n 2406:da18:fff:f800::/53  \n 2600:1f18:7fff:f800::/53  \n 2a05:d018:7ff:f800::/53  \n 2600:1f1e:fff:f800::/53  \n 2620:107:300f::36b7:ff80/122  \n 2a01:578:3::36e4:1000/122  \n 2804:800:ff00::36e8:2840/122  \n 2620:107:300f::36f1:2040/122  \n 2406:da00:ff00::36f3:1fc0/122  \n 2620:108:700f::36f4:34c0/122  \n 2620:108:700f::36f5:a800/122  \n 2400:6700:ff00::36f8:dc00/122  \n 2400:6700:ff00::36fa:fdc0/122  \n 2400:6500:ff00::36fb:1f80/122  \n 2403:b300:ff00::36fc:4f80/122  \n 2403:b300:ff00::36fc:fec0/122  \n 2400:6500:ff00::36ff:fec0/122  \n 2406:da00:ff00::6b17:ff00/122  \n 2a01:578:3::b022:9fc0/122  \n 2804:800:ff00::b147:cf80/122"
    },
    {
        "query":"是否可以在 Amazon Route 53 注册域名？",
        "intention":"知识问答",
        "reply":"是。您可以使用 AWS 管理控制台或 API 通过 Route 53 注册新域名。您还可以请求将现有域名从其他注册机构转移到 Route 53 中进行管理。我们提供的域名注册服务遵循我们的[域名注册协议](https://aws.amazon.com/route53/domain-registration-agreement/)。"
    },
    {
        "query":"你们提供哪些顶级域名 (TLD)？",
        "intention":"知识问答",
        "reply":"Route 53 提供一般顶级域（“gTLD”：例如 .com 和 .net）和国家级顶级域（“ccTLD”：例如 .de 和 .fr）。有关完整列表，请参阅 [Route 53 域注册价格列表](https://d32ze2gidvkk54.cloudfront.net/Amazon_Route_53_Domain_Registration_Pricing_20140731.pdf)。"
    },
    {
        "query":"如何通过 Route 53 注册域名？",
        "intention":"知识问答",
        "reply":"要开始使用，请用您的账户登录并单击“域”。然后，单击蓝色的“注册域”大按钮并完成注册流程。"
    },
    {
        "query":"注册一个域名要花多长时间？",
        "intention":"知识问答",
        "reply":"根据所选择的 TLD 的不同，注册可能需要几分钟到几小时不等的时间。成功注册域后，其会显示在您的账户中。"
    },
    {
        "query":"注册域名要花多长时间？",
        "intention":"知识问答",
        "reply":"第一个注册期通常是一年，但有些顶级域名 (TLD) 的注册期会更长。如果您通过 Amazon Route 53 注册域名，或将域名注册工作转交给 Amazon Route 53，我们会将域名配置为自动续订。有关更多信息，请参阅《Amazon Route 53 开发人员指南》中的[续订域注册](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-renew.html)。"
    },
    {
        "query":"注册域名需要提供哪些信息？",
        "intention":"知识问答",
        "reply":"要注册域名，您需要提供域的注册申请人的联系信息，包括姓名、地址、电话和电子邮件地址。如果管理员和技术联系人不是同一人，您还需要提供他们的联系信息。"
    },
    {
        "query":"注册域名为什么还要提供个人信息？",
        "intention":"知识问答",
        "reply":"作为域名注册管理主体的 ICANN 要求注册机构对每一条域名注册提供联系信息，包括姓名、地址和电话，且注册机构应该通过 Whois 数据库公布此信息。对于以个人（即非公司或组织）名义注册的域名，Route 53 提供免费的隐私保护，将您的个人电话、电子邮件地址和实际地址隐藏起来。作为替代，Whois 包含注册机构的名称和收信地址，以及注册机构生成的转发电子邮件地址，第三方可能根据需要使用该地址联系您。"
    },
    {
        "query":"Route 53 对我已注册的域名是否提供隐私保护？",
        "intention":"知识问答",
        "reply":"是的，Route 53 免费提供隐私保护。隐私保护会隐藏您的电话号码、电子邮件地址和实际地址。如果 TLD 注册处和注册商允许，将会对您的姓名进行隐藏。您启用隐私保护后，针对域的 Whois 查询将分别用注册商的邮寄地址和名称替代您的实际地址和姓名（如果允许）。您的电子邮件地址将是由注册商生成的转发电子邮件地址，如有需要，第三方将使用这一地址与您联系。如果 TLD 注册处和注册商允许，由公司或组织注册的域名可享受隐私保护服务。"
    },
    {
        "query":"哪里可以找到特定 TLD 的要求？",
        "intention":"知识问答",
        "reply":"有关 TLD 列表，请参阅[价目表](https://d32ze2gidvkk54.cloudfront.net/Amazon_Route_53_Domain_Registration_Pricing_20140731.pdf)。如需每一条的特定注册要求，请参阅 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar-tld-list.html)和[域名注册协议](https://aws.amazon.com/route53/domain-registration-agreement/)。"
    },
    {
        "query":"注册域名用到的名称服务器有哪些？",
        "intention":"知识问答",
        "reply":"当域名创建完成后，我们会自动将您的域与四个唯一的 Route 53 名称服务器（也称为委派集）进行关联。您可以在 Amazon Route 53 控制台中查看域的委派集。委派集列于注册域时我们为您自动创建的托管区域中。\n根据默认，Route 53 将为每一个您创建的托管区域指派一个唯一的新委派。但是，您还可以使用 Route 53 API 来创建“可重复使用的委派集”，该委派集可于之后应用到多个您创建的托管区域。多于拥有大量域名的客户，可重复使用的委派集让迁移到 Route 53 变得简单，因为您可以通知您的域名服务公司对 Route 53 中托管的所有域名使用相同的委派集。此功能还可以让您创建“白标签”名称服务器地址，例如 ns1.example.com、ns2.example.com 等，并且可以将这些地址指派给您的 Route 53 名称服务器。然后可以使用“白标签”名称服务器地址作为任意数量域名的权威名称服务器。有关更多详细信息，请参阅 [Amazon Route 53 文档](http://docs.aws.amazon.com/Route53/latest/APIReference/actions-on-reusable-delegation-sets.html)。"
    },
    {
        "query":"什么是 Amazon Registrar, Inc.？什么是备案注册机构？",
        "intention":"知识问答",
        "reply":"AWS 转售通过 ICANN 认可的注册机构注册的域名。Amazon Registrar, Inc. 是一家获得 ICANN 认可的 Amazon 公司，提供域名注册服务。备案注册机构是您域名的 WHOIS 记录中列出的“注册商”，以指示您的域名是在哪家注册机构注册的。"
    },
    {
        "query":"Gandi 是怎样的一家公司？",
        "intention":"知识问答",
        "reply":"Gandi 是一家注册机构，Amazon 是其经销商。作为记录在案的注册机构，Gandi 在 ICANN 的要求下会在注册的开始阶段联系注册人以验证其联系信息。如果 Gandi 提出要求，您必须在起初的 15 天内验证您的联系信息，以免域名被终止。在域名需要续期前，Gandi 还会发出提醒通知。"
    },
    {
        "query":"Amazon Route 53 通过 Amazon Registrar 注册了哪些顶级域名？哪些是通过 Gandi 注册的？",
        "intention":"知识问答",
        "reply":"有关您当前可以使用 Amazon Route 53 注册的域名列表，请参阅[文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/registrar-tld-list.html)。该列表包含以下信息：对于我们销售的每个 TLD，哪家注册机构是当前备案的注册机构。"
    },
    {
        "query":"我能否将 .com 和 .net 域名注册从 Gandi 转移到 Amazon？",
        "intention":"知识问答",
        "reply":"不能。我们计划不久后增加该功能。"
    },
    {
        "query":"什么是 Whois？ 为什么我的信息出现在 Whois 中？",
        "intention":"知识问答",
        "reply":"Whois 是一个公开开放的域名数据库，其中列出了与域名相关的联系信息和名称服务器。所有人均可使用常见的 Whois 指令来访问 Whois 数据库。许多操作系统中都包含了该指令，并且该指令也以网页应用程序的方式存在于许多网站中。Internet Corporation for Assigned Names and Numbers (ICANN) 要求所有域名要配有公开开放的联系信息，以保证万一有人需要联系域名主人时可以联系得上。"
    },
    {
        "query":"如何将我的域名转移到 Route 53？",
        "intention":"知识问答",
        "reply":"要开始使用，请用您的账户登录并单击“域”。然后单击屏幕上方的“转移域”按钮并完成转移步骤。请在转移步骤开始前，确保以下各项：(1) 您的域名在您的当前注册机构处不是锁定状态；(2) 您已禁用域名的隐私保护（如果适用）；(3) 您已经获得当前注册机构的有效授权代码或“authcode”，该代码将用在转移步骤中输入。"
    },
    {
        "query":"如何将现有的域名注册转移到 Amazon Route 53，而不干扰我现有的 Web 流量？",
        "intention":"知识问答",
        "reply":"首先，您需要获取您的域名的 DNS 记录数据列表，通常以“区域文件”的形式提供，您可以从现有的 DNS 提供商处获得。如果您已经得到了 DNS 记录数据，则可以使用 Route 53 的管理控制台或简单的 Web 服务界面来创建可以为您的域名储存 DNS 记录的托管区域，然后遵循其转移步骤操作，其中的步骤包括将域名的名称服务器更新为与托管区域关联的新的名称服务器。要完成域名转移步骤，请联系为您提供域名注册服务的注册机构，然后遵循其转移步骤操作，其中的步骤包括将域名的名称服务器更新为与托管区域关联的新的名称服务器。一旦注册商传播了新的名称服务器指派，来自您的最终用户的 DNS 查询将从 Route 53 DNS 服务器获得回答。"
    },
    {
        "query":"如何查看转移请求的状态？",
        "intention":"知识问答",
        "reply":"您可以在 Route 53 控制台主页的“警报”部分中查看域名转移的状态。"
    },
    {
        "query":"如果转移没有成功，我该怎么办？",
        "intention":"知识问答",
        "reply":"您应该与您的当前注册机构取得联系，确定转移失败的原因。只有在他们将问题解决后，您才可以重新提交您的转移请求。"
    },
    {
        "query":"如何将我的域名转移到其他注册机构？",
        "intention":"知识问答",
        "reply":"为了将域名从 Route 53 移出，您需要向注册机构发起转移请求。他们会请求将域名移动到其管理范围内。"
    },
    {
        "query":"使用 Amazon Route 53 管理域名是否有域名数量限制？",
        "intention":"知识问答",
        "reply":"每个新 Amazon Route 53 账户最多只能管理 50 个域。请填写[提高上限申请表](https://aws.amazon.com/route53-request/)，我们将在两个工作日之内答复您的请求。"
    },
    {
        "query":"Amazon Route 53 DNS 是否支持 DNSSEC？",
        "intention":"知识问答",
        "reply":"是的。您可以为现有的和新的公有托管区域启用 DNSSEC 签名。"
    },
    {
        "query":"如何将已启用 DNSSEC 的域名注册转移到 Amazon Route 53？",
        "intention":"知识问答",
        "reply":"请参阅我们的[文档](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-configure-dnssec.html)，获取有关将已启用 DNSSEC 的域名转移到 Amazon Route 53 的分步指南。"
    },
    {
        "query":"什么是 Amazon Route 53 解析程序？",
        "intention":"知识问答",
        "reply":"Route 53 解析程序是一种区域 DNS 服务，为 EC2 中托管的名称以及 Internet 上的公有名称提供递归 DNS 查找。默认情况下，此功能在每个 Amazon Virtual Private Cloud (VPC) 中都可用。对于混合云方案，您可以配置条件转发规则和 DNS 终端节点，在 AWS Direct Connect 和 AWS 托管 VPN 之间启用 DNS 解析。"
    },
    {
        "query":"什么是递归 DNS？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 既是权威 DNS 服务又是递归 DNS 服务。权威 DNS 包含 DNS 查询的最终答案，通常是 IP 地址。客户端（例如移动设备、在云中运行的应用程序或数据中心中的服务器）实际上并不直接与权威 DNS 服务通信，但极少数情况例外。相反，客户端与递归 DNS 服务（也称为 DNS 解析程序）通信，后者为任何 DNS 查询查找正确的权威答案。Route 53 解析程序是一种递归 DNS 服务。\n收到查询时，Route 53 解析程序等递归 DNS 服务可能会配置为自动将查询直接转发到特定的递归 DNS 服务器，也可能从域的根开始递归搜索并继续，直至找到最终答案。无论是哪种情况，一旦找到答案，递归 DNS 服务器就会将答案缓存一段时间，这样它可以在将来更快地回答对相同名称的后续查询。"
    },
    {
        "query":"什么是条件转发规则？",
        "intention":"知识问答",
        "reply":"条件转发规则允许解析器将指定域的查询转发到您选择的目标 IP 地址，通常是本地 DNS 解析程序。规则在 VPC 级别应用，可以从一个账户进行管理，并在多个账户之间共享。"
    },
    {
        "query":"什么是 DNS 终端节点？",
        "intention":"知识问答",
        "reply":"DNS 终端节点包括一个或多个连接到您的 Amazon Virtual Private Cloud (VPC) 的弹性网络接口 (ENI)。系统会为每个 ENI 分配其所在的 VPC 的子网空间中的 IP 地址。然后，此 IP 地址可用作本地 DNS 服务器的转发目标以转发查询。您要从 VPC 转发到网络的 DNS 查询流量以及通过 AWS Direct Connect 和托管 VPN 从网络转发到 VPC 的 DNS 查询流量都需要终端节点。"
    },
    {
        "query":"如何跨账户共享规则？",
        "intention":"知识问答",
        "reply":"Route 53 解析程序与 AWS Resource Access Manager (RAM) 集成，为客户提供了一种在 AWS 账户或 AWS 组织内共享资源的简单方法。可以在一个主账户中创建规则，然后使用 RAM 在多个账户之间共享。共享后，规则仍需要应用于这些账户中的 VPC 才能生效。有关更多信息，请参阅 AWS RAM [文档](https://docs.aws.amazon.com/ram/index.html#lang/en_us)。"
    },
    {
        "query":"如果我决定停止与其他账户共享规则会怎么样？",
        "intention":"知识问答",
        "reply":"您以前与之共享的账户将不再使用这些规则。这意味着，如果这些规则与这些账户中的 VPC 相关联，则它们将与这些 VPC 取消关联。"
    },
    {
        "query":"哪些区域对 Route 53 解析程序可用？",
        "intention":"知识问答",
        "reply":"访问我们的 [AWS 区域表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)，查看已推出 Route 53 解析程序的区域。"
    },
    {
        "query":"Route 53 解析程序的区域性支持是否意味着所有 Amazon Route 53 现在都是区域性的？",
        "intention":"知识问答",
        "reply":"否。Amazon Route 53 公有和私有 DNS、流量、运行状况检查以及域名注册都是全球服务。"
    },
    {
        "query":"如何开始使用 Route 53 解析程序？",
        "intention":"知识问答",
        "reply":"请访问 [Amazon Route 53 开发人员指南](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resolver.html)，了解有关入门的详细信息。您还可以从 Amazon Route 53 控制台配置解析程序。"
    },
    {
        "query":"什么是 Amazon Route 53 Resolver DNS Firewall？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 Resolver DNS Firewall 是一项功能，允许您在所有 Amazon Virtual Private Cloud (VPC) 中快速部署 DNS 保护。Route 53 Resolver DNS Firewall 允许您在使用 Route 53 Resolver 递归 DNS 解析时，阻止对已知的恶意域进行查询（即创建“拒绝名单”），并允许对可信域进行查询（创建“允许名单”）。您还可以使用 AWS 托管域列表快速开始针对常见 DNS 威胁进行保护。Amazon Route 53 Resolver DNS Firewall 与 AWS Firewall Manager 协同工作，因此您可以构建基于 DNS Firewall 规则的策略，然后跨多个 VPC 和账户集中应用这些策略。"
    },
    {
        "query":"我何时应该使用 Route 53 Resolver DNS Firewall？",
        "intention":"知识问答",
        "reply":"如果您想过滤哪些域名可以在 VPC 中通过 DNS 查询，那么 DNS Firewall 就非常适合您。其从以下两个方面为您选择最适合您组织安全状况的配置提供了灵活性：(1) 如果您对 DNS 泄露有严格要求，想要拒绝对已批准域列表之外的域的所有出站 DNS 查询，您就可以为 DNS 安全性创建这种“围墙花园”式的规则。(2) 如果您的组织首选在默认情况下允许您账户内进行的所有出站 DNS 查找，只需要能够阻止对已知的恶意域进行 DNS 请求，您就可以使用 DNS Firewall 创建拒绝名单，包含您的组织已知的所有恶意域名。DNS Firewall 还带有 AWS 托管域列表，可帮助您防范可疑域和命令与控制 (C&C) 机器人程序。"
    },
    {
        "query":"Amazon Route 53 Resolver DNS Firewall 与 AWS 和 AWS Marketplace 上的其他防火墙产品有何不同？",
        "intention":"知识问答",
        "reply":"Route 53 Resolver DNS Firewall 能够为整个 VPC 提供对 Route 53 Resolver DNS 流量（如 AmazonProvidedDNS）的控制性和可见性，可作为 AWS 上现有网络和应用程序安全服务的补充。根据您用例的不同，您可以选择在现有安全控件（如 AWS Network Firewall、Amazon VPC 安全组、AWS Web 应用程序防火墙规则或 AWS Marketplace 设备）上实施 DNS Firewall。"
    },
    {
        "query":"Amazon Route 53 Resolver DNS Firewall 能否管理多个 AWS 账户的安全性？",
        "intention":"知识问答",
        "reply":"可以。Route 53 Resolver DNS Firewall 是一种区域功能，可从组织和账户层面保护 Route 53 Resolver DNS 网络流量。如需维护多个账户的策略和治理，您应该使用 [AWS Firewall Manager](https://aws.amazon.com/cn/firewall-manager/)。"
    },
    {
        "query":"我可以使用哪些 AWS 工具来记录和监控我的 Amazon Route 53 Resolver DNS Firewall 活动？",
        "intention":"知识问答",
        "reply":"您可以将 DNS Firewall 活动记录到 Amazon S3 存储桶或 Amazon CloudWatch 日志组中，供进一步分析和调查。您还可以使用 Amazon Kinesis Firehose 将日志发送给第三方提供商。"
    },
    {
        "query":"在防御恶意 DNS 查询威胁方面，Amazon Route 53 Resolver 53 DNS Firewall 与 AWS Network Firewall 有何区别？",
        "intention":"知识问答",
        "reply":"Amazon Route 53 Resolver DNS Firewall 与 AWS Network Firewall 都能够防御出站 DNS 查询威胁，但它们适用于不同的部署模型。Amazon Route 53 Resolver DNS Firewall 专门提供精细控制，如果您正在使用 Amazon Route 53 Resolver 进行 DNS 解析，它将阻止向恶意或受到威胁的域发出 DNS 请求。AWS Network Firewall 提供了类似的功能，如果您正在使用外部 DNS 服务来解析 DNS 请求，它将筛选/阻止向已知的恶意域发送的出站 DNS 查询。\n定价简单，仅按所需量付费。\n立即享受 AWS 免费套餐。\n在 AWS 控制台中开始使用 Amazon Route 53。"
    },
    {
        "query":"Why do I see another account as ‘sharing’ my datastore in AWS Lakeformation? The reason resources are shared between customer accounts and the service accounts is because Amazon Healthlake is a fully managed service. The service account does not have access to the data in your account and is only orchestrating the resources behind Amazon Healthlake including Glue, Lambda, and Lake Formation among others. Amazon Healthlake uses Lake formation in conjunction with Glue and Resource Access Manager (RAM) to provide a managed experience where the customer’s Glue catalog is shared with the customer’s account. However, the Glue catalog is a logical view, and not where the data resides.",
        "intention":"知识问答",
        "reply":"This enables Amazon HealthLake to transform your HealthLake datastore FHIR data into a format that can be queried using Athena. Amazon HealthLake creates tables as FHIR resource types in Amazon HealthLake owned service accounts and shares them with customer accounts using LakeFormation named resource share method. The “another account” is essentially the Amazon HealthLake service account where customer data is encrypted at rest within Amazon HealthLake service boundary to ensure security and HIPAA-eligible requirements are met."
    },
    {
        "query":"什么是 Amazon SageMaker？",
        "intention":"知识问答",
        "reply":"SageMaker 是一项完全托管的服务，可通过完全托管的基础设施、工具和工作流程为任何应用场景准备数据并构建、训练和部署机器学习（ML）模型。"
    },
    {
        "query":"SageMaker 在哪些 AWS 区域提供？",
        "intention":"知识问答",
        "reply":"有关受支持的 SageMaker 区域的列表，请访问 [AWS 区域服务页面](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。此外，有关更多信息，请参阅 AWS 一般参考指南中的[区域端点](https://docs.aws.amazon.com/general/latest/gr/rande.html#machinelearning_region)。"
    },
    {
        "query":"SageMaker 的服务可用性水平如何？",
        "intention":"知识问答",
        "reply":"SageMaker 旨在提供高可用性。没有维护时段或计划停机时间。SageMaker API 在 Amazon 稳定可靠且具有高可用性的数据中心中运行，相关的服务堆栈会在每个区域中的三处数据中心进行复制配置，以实现容错，防止服务器故障或可用区中断等事故导致的损失。"
    },
    {
        "query":"SageMaker 如何保护我的代码安全？",
        "intention":"知识问答",
        "reply":"SageMaker 将代码存储在 ML 存储卷上，通过安全组保证安全，并可以选择在静态时加密。"
    },
    {
        "query":"SageMaker 有哪些安全防护保障？",
        "intention":"知识问答",
        "reply":"SageMaker 可以确保机器学习模型构件和其他系统构件在传输中和静态下全部经过加密。对 SageMaker API 和控制台发出的请求全部通过安全（SSL）连接进行。您可以为 SageMaker 传递 [AWS Identity and Access Management 角色](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html)，为其提供资源访问权限以便进行训练和部署。您可以将加密的 Amazon Simple Storage Service（Amazon S3）存储桶用于模型构件和数据，并为 SageMaker 笔记本、训练任务和端点传递 AWS Key Management Service（AWS KMS）密钥来加密挂载的 ML 存储卷。SageMaker 还支持 Amazon Virtual Private Cloud（Amazon VPC）和 AWS PrivateLink 支持。"
    },
    {
        "query":"SageMaker 是否会使用或共享模型、训练数据或算法？",
        "intention":"知识问答",
        "reply":"SageMaker 不使用或共享模型、训练数据或算法。我们知道，客户十分注重隐私和数据安全。因此，AWS 通过简单而强大的工具让您拥有和控制自己的内容，这些工具可以让您确定内容的存储位置、保护动态和静态内容，并为用户管理对 AWS 服务和资源的访问权限。我们还采取了技术和物理控制措施，防止您的内容被非法访问或披露。作为客户，您对自己的内容拥有所有权，并且您可以选择使用哪项 AWS 服务来处理、存储和托管您的内容。未经您同意，我们不会出于任何目的而访问您的内容。"
    },
    {
        "query":"如果我有自己的笔记本以及训练或托管环境，会怎么样？",
        "intention":"知识问答",
        "reply":"SageMaker 提供完整的工作流，但您可以继续将现有工具与 SageMaker 结合使用。您可以根据业务需求将每个阶段的结果轻松传入和传出 SageMaker。"
    },
    {
        "query":"SageMaker 是否支持 R？",
        "intention":"知识问答",
        "reply":"是。您可以在 SageMaker 笔记本实例中使用 R，该实例包括预装的 R 内核和 [reticulate](https://rstudio.github.io/reticulate/) 库。Reticulate 为 Amazon SageMaker Python SDK 提供了 R 接口，可帮助机器学习从业人员构建、训练、调整和部署 R 模型。"
    },
    {
        "query":"如何检查模型中的不平衡？",
        "intention":"知识问答",
        "reply":"[Amazon SageMaker Clarify](https://aws.amazon.com/cn/sagemaker/clarify/) 通过检测整个 ML 工作流中的统计偏差来帮助提高模型的透明度。SageMaker Clarify 在数据准备期间、训练之后以及随时间推移检查是否存在不平衡，同时包括有助于解释 ML 模型及其预测的工具。可通过可解释性报告共享调查发现。"
    },
    {
        "query":"什么是 Amazon SageMaker Studio？",
        "intention":"知识问答",
        "reply":"SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习（ML）开发步骤。借助 SageMaker Studio，您可以全面访问、控制和查看准备数据以及构建、训练和部署模型所需的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。您可以在统一的 SageMaker Studio 可视化界面中执行所有 ML 开发活动，包括笔记本、实验管理、自动创建模型、调试和分析以及模型偏差检测。"
    },
    {
        "query":"什么是 RStudio on Amazon SageMaker？",
        "intention":"知识问答",
        "reply":"RStudio on SageMaker 是云中第一个完全托管的 RStudio Workbench。您可以快速启动熟悉的 RStudio 集成式开发环境（IDE），并在不中断工作的情况下上拨和下拨底层计算资源，从而更轻松地在 R 中大规模构建 ML 和分析解决方案。您可以在 RStudio IDE 和 SageMaker Studio 笔记本之间无缝切换以进行 R 和 Python 开发。 您的所有工作，包括代码、数据集、存储库和其他构件，都会在两个环境之间自动同步，以减少上下文切换并提高工作效率。"
    },
    {
        "query":"SageMaker Studio 如何定价？",
        "intention":"知识问答",
        "reply":"使用 SageMaker Studio 不收取额外费用。您只需为在 SageMaker Studio 中使用的服务支付基础计算和存储费用。"
    },
    {
        "query":"哪些区域支持 SageMaker Studio？",
        "intention":"知识问答",
        "reply":"您可以在[《Amazon SageMaker 开发人员指南》](https://docs.aws.amazon.com/sagemaker/latest/dg/regions-quotas.html)中找到支持 SageMaker Studio 的区域。"
    },
    {
        "query":"SageMaker 提供哪些 ML 治理工具？",
        "intention":"知识问答",
        "reply":"SageMaker 在整个 ML 生命周期中提供专门构建的 ML 治理工具。借助 Amazon SageMaker 角色管理器，管理员可以在几分钟内定义最低权限。Amazon SageMaker 模型卡让您可以更轻松地捕获、检索和共享从概念到部署的基本模型信息，而 Amazon SageMaker 模型总览板则可以让您在一个位置了解生产模型的行为。有关  \n 更多详情，请参阅[使用 Amazon SageMaker 进行机器学习治理](https://aws.amazon.com/sagemaker/ml-governance \"机器学习治理\")。"
    },
    {
        "query":"SageMaker Role Manager 有什么作用？",
        "intention":"知识问答",
        "reply":"您可以使用 SageMaker Role Manager 在几分钟内定义最低权限。该服务通过预构建的 IAM policy 目录为 ML 活动和角色提供一组基线权限。您可以保留基线权限，或根据您的特定需求进一步自定义它们。通过一些自助提示，您可以快速输入常见的治理结构，例如网络访问边界和加密密钥。然后，SageMaker Role Manager 将自动生成 IAM policy。您可以通过 AWS IAM 控制台发现生成的角色和关联的策略。要进一步针对您的用例定制权限，请将您的托管 IAM 策略附加到您使用 SageMaker Role Manager 创建的 IAM 角色。您还可以添加标签以帮助跨 AWS 服务识别和组织角色。"
    },
    {
        "query":"SageMaker 模型卡有什么作用？",
        "intention":"知识问答",
        "reply":"SageMaker 模型卡通过为模型信息创建单一信任源，帮助您在整个 ML 生命周期中集中和标准化模型文档。SageMaker 模型卡可以自动填充训练详细信息以加速文档编制过程。您还可以添加详细信息，例如模型的目的和性能目标。您可以将模型评估结果附加到您的模型卡并提供可视化效果，以获得对模型性能的关键洞察。SageMaker 模型卡可以通过导出为 PDF 格式轻松地与他人共享。"
    },
    {
        "query":"SageMaker 模型总览板有什么作用？",
        "intention":"知识问答",
        "reply":"SageMaker 模型总览板为您提供已部署模型和端点的全面概览，让您可以通过一个窗格跟踪资源和模型行为违规。它让您可以通过与 SageMaker Model Monitor 和 SageMaker Clarify 的集成，从四个维度监控模型行为，包括数据和模型质量，以及偏差和特征归因漂移。SageMaker 模型总览板还提供了一种集成体验，可以针对缺失和不活动的模型监控作业以及模型质量、数据质量、偏差漂移和特征归因漂移的模型行为偏差设置和接收警报。您可以进一步检查各个模型并分析随时间推移影响模型性能的因素。然后，您可以跟进 ML 从业者以采取纠正措施。"
    },
    {
        "query":"如何快速开始使用 SageMaker？",
        "intention":"知识问答",
        "reply":"SageMaker JumpStart 可帮助您快速轻松地开始 ML。SageMaker JumpStart 为最常见的应用场景提供了一套解决方案，只需几个步骤即可轻松部署。这些解决方案是完全可定制的，并展示了 AWS CloudFormation 模板和参考架构的使用，因此可以加快您的 ML 进程。SageMaker JumpStart 还提供根基模型并支持一步式部署和 150 多种流行的开源模型的微调，例如转换器、对象检测和图像分类模型。"
    },
    {
        "query":"SageMaker JumpStart 中提供哪些根基模型？",
        "intention":"知识问答",
        "reply":"SageMaker JumpStart 提供专有和公共模型。有关可用根基模型的列表，请参阅 [Amazon SageMaker JumpStart 入门](https://aws.amazon.com/sagemaker/jumpstart/getting-started/?sagemaker-jumpstart-cards.sort-by=item.additionalFields.priority&sagemaker-jumpstart-cards.sort-order=asc&awsf.sagemaker-jumpstart-filter-product-type=*all&awsf.sagemaker-jumpstart-filter-text=*all&awsf.sagemaker-jumpstart-filter-vision=*all&awsf.sagemaker-jumpstart-filter-tabular=*all&awsf.sagemaker-jumpstart-filter-audio-tasks=*all&awsf.sagemaker-jumpstart-filter-multimodal=*all&awsf.sagemaker-jumpstart-filter-RL=*all)。"
    },
    {
        "query":"如何通过 SageMaker JumpStart 开始使用根基模型？",
        "intention":"知识问答",
        "reply":"您可以通过 SageMaker Studio、SageMaker SDK 和 AWS 管理控制台访问根基模型。要开始使用专有根基模型，您必须接受 [AWS Marketplace](https://aws.amazon.com/marketplace) 中的销售条款。"
    },
    {
        "query":"是否会使用或共享我的数据来更新向使用 SageMaker JumpStart 的客户提供的基本模型？",
        "intention":"知识问答",
        "reply":"不会。不会使用或共享您的推理和训练数据来更新或训练 SageMaker JumpStart 向客户展示的基本模型。"
    },
    {
        "query":"能否使用 SageMaker JumpStart 查看专有模型的模型权重和脚本？",
        "intention":"知识问答",
        "reply":"不能。专有模型不允许客户查看模型权重和脚本。"
    },
    {
        "query":"SageMaker JumpStart 根基模型在哪些地区提供？",
        "intention":"知识问答",
        "reply":"在提供 SageMaker Studio 的所有[区域](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)都可以发现根基模型，但部署模型的能力因所需实例类型的型号和实例可用性而异。您可以从 [AWS Marketplace](https://aws.amazon.com/cn/marketplace/) 的模型详细信息页面查看 AWS 区域的可用性和所需实例。\n问：SageMaker JumpStart 根基模型如何定价？\n对于专有模型，您需要按模型提供商确定的软件定价付费，并根据使用的实例支付 SageMaker 基础设施费用。对于公开可用的模型，您需要根据使用的实例支付 SageMaker 基础设施费用。有关更多信息，请参阅 [Amazon SageMaker 定价](https://aws.amazon.com/sagemaker/pricing/)和 [AWS Marketplace](https://aws.amazon.com/marketplace)。"
    },
    {
        "query":"SageMaker JumpStart 如何帮助保护我的数据的安全？",
        "intention":"知识问答",
        "reply":"安全是 AWS 的重中之重，SageMaker JumpStart 旨在确保安全。因此，SageMaker 通过简单而强大的工具让您拥有和控制自己的内容，这些工具可以帮助您确定内容的存储位置、保护动态和静态内容，并为用户管理对 AWS 服务和资源的访问权限。\n使用 AWS Marketplace 或 SageMaker JumpStart 中的模型，即表示用户承担模型输出质量的责任并承认已知悉单个模型描述中所述的功能和限制。"
    },
    {
        "query":"SageMaker JumpStart 支持哪些开源模型？",
        "intention":"知识问答",
        "reply":"SageMaker JumpStart 包括来自 PyTorch Hub 和 TensorFlow Hub 的 150 多种经过预先训练的开源模型。对于图像分类和对象检测等视觉任务，您可以利用 RESNET、MobileNet 和 Single-Shot Detector（SSD）等模型。对于句子分类、文本分类和问题回答等文本任务，您可以使用 BERT、RoBERTa 和 DistilBERT 等模型。"
    },
    {
        "query":"如何与组织内的其他人共享 ML 构件？",
        "intention":"知识问答",
        "reply":"借助 SageMaker JumpStart，数据科学家和 ML 开发人员可以在其组织内轻松共享 ML 构件，包括笔记本和模型。管理员可以设置一个存储库，可供定义的一组用户访问。所有有权访问存储库的用户都可以浏览、搜索和使用模型和笔记本以及 SageMaker JumpStart 中的公共内容。用户可以选择构件，以在 SageMaker JumpStart 中训练模型、部署端点和执行笔记本。"
    },
    {
        "query":"为什么我应该使用 SageMaker JumpStart 与组织内的其他人共享 ML 构件？",
        "intention":"知识问答",
        "reply":"借助 SageMaker JumpStart，您可以在构建 ML 应用程序时加快上市速度。只需几个步骤，就可以将组织内一个团队构建的模型和笔记本轻松地与组织内的其他团队共享。内部知识共享和资产重用可以显著提高组织的生产力。"
    },
    {
        "query":"什么是 Amazon SageMaker Autopilot？",
        "intention":"知识问答",
        "reply":"[SageMaker Autopilot](https://aws.amazon.com/cn/sagemaker/autopilot/) 是业内首个自动化机器学习功能，可让您完全掌控 ML 模型。只需单击几下，SageMaker Autopilot 即可自动检查原始数据、应用功能处理器、选择最佳算法集、训练和调优多个模型、跟踪模型性能以及根据性能对模型进行排名。如此一来，您无需像通常情况下训练模型那样耗费时间，只需很少的时间即可部署性能最佳的模型。您可以全面了解模型的创建方式以及模型内容，此外，SageMaker Autopilot 已与 SageMaker Studio 集成。您可以深入了解 SageMaker Autopilot 在 SageMaker Studio 中生成的 50 余种不同模型，轻松为您的使用案例选择最佳模型。SageMaker Autopilot 适用于各类人群，不具备机器学习经验的人员可以使用它轻松生成模型，经验丰富的开发人员可以使用它快速开发基准模型，供团队进一步迭代。"
    },
    {
        "query":"SageMaker Autopilot 支持哪些内置算法？",
        "intention":"知识问答",
        "reply":"SageMaker Autopilot 支持 2 种内置算法：XGBoost 和 Linear Learner。"
    },
    {
        "query":"能否手动停止 SageMaker Autopilot 作业？",
        "intention":"知识问答",
        "reply":"是。您可以随时停止某项作业。停止一项 SageMaker Autopilot 作业时，所有正在进行的试验都将停止，也不会开始新的试验。"
    },
    {
        "query":"什么是 Amazon SageMaker Canvas？",
        "intention":"知识问答",
        "reply":"SageMaker Canvas 是一项无代码服务，具有一个直观的点击式界面，使您能够根据数据创建高度准确的基于机器学习的预测。SageMaker Canvas 让您可以使用拖放式用户界面访问和组合来自各种来源的数据，自动清理和准备数据以最大限度地减少手动清理工作。SageMaker Canvas 应用各种最先进的 ML 算法来寻找高度准确的预测模型，并提供直观的界面来进行预测。您可以使用 SageMaker Canvas 在各种业务应用程序中进行更精确的预测，并通过共享模型、数据和报告轻松与企业中的数据科学家和分析师协作。要了解有关 SageMaker Canvas 的更多信息，请参阅 [Amazon SageMaker Canvas 常见问题](https://aws.amazon.com/sagemaker/canvas/faqs/)。"
    },
    {
        "query":"SageMaker Canvas 如何定价？",
        "intention":"知识问答",
        "reply":"SageMaker Canvas 根据使用量付费。SageMaker Canvas 使您能够以交互方式摄取、探索和准备来自多个来源的数据、使用您的数据训练高度准确的 ML 模型并生成预测。您的账单由两个部分决定：基于使用或登录 SageMaker Canvas 的小时数的会话费用，以及基于用于构建模型的数据集大小的模型训练费用。有关更多信息，请参阅 [Amazon SageMaker Canvas 定价](https://aws.amazon.com/cn/sagemaker/canvas/pricing/)。"
    },
    {
        "query":"如何使用 SageMaker 构建连续集成和交付（CI/CD）管道？",
        "intention":"知识问答",
        "reply":"[Amazon SageMaker Pipelines](https://aws.amazon.com/cn/sagemaker/pipelines/) 帮助您创建从数据准备到模型部署的全自动 ML 工作流，让您可以在生产中扩展到数千个 ML 模型。SageMaker Pipelines 附带一个连接到 SageMaker Studio 的 Python 开发工具包，因此您可以利用可视界面来构建工作流的每个步骤。然后，使用单个 API，您可以连接每个步骤以创建完整的工作流。SageMaker Pipelines 管理步骤之间的数据、打包代码配方并编排其执行，从而将数月的编码工作缩短至几个小时。每次执行工作流时，都会保存已处理数据和所采取措施的完整记录，以便数据科学家和 ML 开发人员可以快速调试问题。  \n   \n 问：如何查看所有经训练模型，以选择最佳模型投入生产？  \n   \n SageMaker Pipelines 提供了一个经培训模型的中央存储库，称为模型注册表。您可以通过 SageMaker Studio 找到模型，并通过 Python SDK 以编程方式访问模型注册表，从而更轻松选择部署到生产中所需的模型。  \n   \n 问：可以将 SageMaker 的哪些组件添加到 SageMaker 管道中？  \n   \n 可以将通过 SageMaker Studio 可用的组件（包括 SageMaker Clarify、Amazon SageMaker Data Wrangler、Amazon SageMaker Feature Store、Amazon SageMaker Experiments、Amazon SageMaker Debugger 和 Amazon SageMaker Model Monitor）添加到 SageMaker Pipelines。  \n   \n 问：如何在整个 ML 工作流中跟踪模型组件？  \n   \n SageMaker Pipelines 自动跟踪所有模型构成部分，并跟踪所有更改的审核记录，从而消除手动跟踪，并可以帮助您实现合规性目标。您可以使用 SageMaker Pipelines 跟踪数据、代码、经训练的模型等。  \n   \n 问：SageMaker Pipelines 如何定价？   \n   \n 使用 SageMaker Pipelines 不收取额外费用。您只需为 SageMaker Pipelines 中使用的基础计算或任何单独 AWS 服务支付费用。"
    },
    {
        "query":"如何使用在 SageMaker Data Wrangler 中准备的数据训练机器学习模型？",
        "intention":"知识问答",
        "reply":"SageMaker Data Wrangler 提供了统一的体验，使您能够在 [SageMaker Autopilot](https://aws.amazon.com/sagemaker/autopilot/) 中准备数据并无缝训练机器学习模型。SageMaker Autopilot 可根据您的数据自动构建、训练和调整最佳 ML 模型。利用 SageMaker Autopilot，您仍然可以拥有数据和模型的完全控制性和可见性。您还可以将 SageMaker Data Wrangler 中准备的功能与现有模型结合使用。您可以通过在用户界面（UI）中配置作业或使用编排代码导出笔记本，将 SageMaker Data Wrangler 处理作业配置为作为 SageMaker 训练管道的一部分运行。"
    },
    {
        "query":"当我在历史数据上准备好特征后，SageMaker Data Wrangler 会如何处理新数据？",
        "intention":"知识问答",
        "reply":"您可以直接从 SageMaker Data Wrangler UI 配置和启动 SageMaker 处理作业，包括安排数据处理作业和参数化数据来源，以轻松地大规模转换新的数据批次。"
    },
    {
        "query":"SageMaker Data Wrangler 如何与我的 CI/CD 流程配合使用？",
        "intention":"知识问答",
        "reply":"准备好数据后，SageMaker Data Wrangler 会提供不同的选项来将您的 SageMaker Data Wrangler 流程推广到生产环境，并与 MLOps 和 CI/CD 功能无缝集成。您可以直接从 SageMaker Data Wrangler UI 配置和启动 SageMaker 处理作业，包括安排数据处理作业和参数化数据来源，以轻松地大规模转换新的数据批次。或者，SageMaker Data Wrangler 与 SageMaker 处理和 SageMaker Spark 容器无缝集成，让您可以轻松使用 SageMaker SDK 将 SageMaker Data Wrangler 集成到您的生产工作流程中。"
    },
    {
        "query":"SageMaker Data Wrangler Quick Model 使用哪种模型？",
        "intention":"知识问答",
        "reply":"只需几个步骤，SageMaker Data Wrangler 就会使用默认超参数拆分和训练 XGBoost 模型。根据问题类型，SageMaker Data Wrangler 提供模型摘要、特征摘要和混淆矩阵，以快速为您提供见解，让您可以迭代数据准备流程。"
    },
    {
        "query":"SageMaker Data Wrangler 支持多大的数据？",
        "intention":"知识问答",
        "reply":"SageMaker Data Wrangler 支持各种采样技术，例如用于导入数据的 top-K、随机和分层采样，因此您可以使用 SageMaker Data Wrangler 的 UI 快速转换数据。如果您使用的是大型或宽数据集，则可以增加 SageMaker Data Wrangler 实例大小以提高性能。创建流程后，您可以使用 SageMaker Data Wrangler 处理作业处理完整的数据集。"
    },
    {
        "query":"SageMaker Data Wrangler 是否可以与 SageMaker Feature Store 一起使用？",
        "intention":"知识问答",
        "reply":"您可以将 SageMaker Feature Store 配置为在 SageMaker Data Wrangler 中准备的特征的目标。这可以直接在 UI 中完成，或者您可以导出专门为处理数据而生成的笔记本，并将 SageMaker Feature Store 作为目标。"
    },
    {
        "query":"如何存储 ML 模型的功能？  SageMaker Feature Store 提供具有低延迟（毫秒）读写数据功能的中央存储库。可以通过 SageMaker Feature Store 存储、检索、发现和共享这些功能，以便在具有安全访问和控制权限的模型和团队之间轻松重复使用。SageMaker Feature Store 支持通过批处理或流传输管道生成的在线和离线功能。它支持回填功能，并提供在线和离线库，以维持模型训练和推理中所使用功能的均等性。  问：如何保持在线和离线功能之间的一致性？  SageMaker Feature Store 自动维护在线和离线功能之间的一致性，无需其他管理或代码。SageMaker Feature Store 完全托管，并保持训练和推理环境之间一致性。  问：如何从给定时间点重现功能？  SageMaker Feature Store 在每个时间实例为所有功能维护时间戳。这可帮助您在任何时间段检索符合业务或合规性要求的功能。通过从给定时间点重现模型，您可以轻松解释从创建之初到当前时间的模型特征及其数值。  问：什么是离线功能？  离线功能用于训练，因为您需要长时间访问大量数据。通过高吞吐量、高带宽的存储库提供这些功能。  问：什么是在线功能？",
        "intention":"知识问答",
        "reply":"在线功能用于进行实时预测所需的应用程序。在线功能通过高吞吐量的存储库提供，延迟时间仅几毫秒，可进行快速预测。"
    },
    {
        "query":"SageMaker Feature Store 如何定价？",
        "intention":"知识问答",
        "reply":"作为 [AWS Free Tier](https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc) 的一部分，您可以免费开始使用 SageMaker Feature Store。使用 SageMaker Feature Store 时，您需要支付写入功能库以及从在线功能库读取和存储的费用。有关定价详情，请参阅 [Amazon SageMaker 定价](https://aws.amazon.com/sagemaker/pricing/)。  \n   \n 问：SageMaker 为数据标注提供什么产品？\nSageMaker 提供两种数据标注产品：Amazon SageMaker Ground Truth Plus 和 Amazon SageMaker Ground Truth。这两个选项都允许您识别原始数据，例如图像、文本文件和视频，并添加信息标签来为您的机器学习模型创建高质量的训练数据集。要了解更多信息，请参阅 [Amazon SageMaker 数据标注](https://aws.amazon.com/cn/sagemaker/data-labeling/)。"
    },
    {
        "query":"什么是地理空间数据？",
        "intention":"知识问答",
        "reply":"地理空间数据表示地球表面的特征或对象。第一类地理空间数据是矢量数据，它使用点、线或多边形等二维几何图形来表示道路和陆地边界等对象。第二种地理空间数据是栅格数据，例如卫星、航空平台或遥感平台收集的图像。此数据类型使用像素矩阵来定义特征所在的位置。您可以使用栅格格式来存储变化的数据。第三种地理空间数据是地理标记位置数据。它包括兴趣点（例如埃菲尔铁塔）、带有位置标记的社交媒体帖子、经纬度坐标或不同风格和格式的街道地址。"
    },
    {
        "query":"SageMaker 地理空间功能有哪些？",
        "intention":"知识问答",
        "reply":"SageMaker 地理空间功能使数据科学家和 ML 工程师可以更轻松地构建、训练和部署 ML 模型，以使用地理空间数据进行预测。您可以自带数据，例如来自 Amazon S3 的 Planet Labs 卫星数据，或从 AWS 上的开放数据、Amazon Location Service 和其他 SageMaker 地理空间数据来源获取数据。"
    },
    {
        "query":"为什么我应该在 SageMaker 上使用地理空间 ML？",
        "intention":"知识问答",
        "reply":"您可以使用 SageMaker 地理空间功能比自己动手的解决方案更快地对地理空间数据进行预测。SageMaker 地理空间功能使您可以更轻松地从现有客户数据湖、开源数据集和其他 SageMaker 地理空间数据来源访问地理空间数据。SageMaker 地理空间功能通过提供用于高效数据准备、模型训练和推理的专用算法，最大限度地减少了构建自定义基础设施和数据预处理功能的需求。您还可以从 SageMaker Studio 创建自定义可视化和数据并与您的组织共享。SageMaker 地理空间功能包括用于农业、房地产、保险和金融服务的常见用途的预训练模型。"
    },
    {
        "query":"什么是 Amazon SageMaker Studio 笔记本？",
        "intention":"知识问答",
        "reply":"SageMaker Studio 笔记本电脑是快速启动、协作、托管的 Jupyter notebook。SageMaker Studio 笔记本与 SageMaker 中的专用 ML 工具和其他 AWS 服务集成，用于在 SageMaker Studio（完整的 ML 集成式开发环境）中完成 ML 开发。"
    },
    {
        "query":"SageMaker Studio 笔记本与基于实例的笔记本服务有何不同？",
        "intention":"知识问答",
        "reply":"SageMaker Studio Notebooks 提供了几项重要的功能，从而将它们与基于实例的笔记本区分开来。借助这些 Studio 笔记本，您可以快速启动笔记本，而无需手动预置实例并等待其运行。启动 UI 来读取和执行笔记本的启动时间比基于实例的笔记本快。\n您还可以随时灵活地在 UI 内从大量实例类型中进行选择。您不需要转至 AWS 管理控制台即可通过笔记本启动新实例和进行移植。\n每个用户都有一个独立于特定实例的隔离主目录。该目录在启动时便自动挂载在所有的笔记本服务器和内核中，因此，即使您切换实例以查看和运行笔记本，您仍可以访问笔记本和其他文件。\nSageMaker Studio 笔记本集成了 AWS IAM Identity Center（AWS SSO 的后继者），使您可以更轻松地使用组织凭证来访问笔记本。笔记本共享是 SageMaker Studio 笔记本中的集成功能。只需一个步骤，您就可以与同事共享笔记本，甚至可以同时共同编辑一个笔记本。"
    },
    {
        "query":"SageMaker Studio 笔记本是如何运作的？",
        "intention":"知识问答",
        "reply":"SageMaker Studio Notebooks 是一步式 Jupyter notebook，可以快速启动。底层计算资源极具弹性，让您可以轻松启用或关闭可用资源，并且更改将在后台自动进行，不会干扰您的工作。SageMaker 还支持一步共享笔记本。您可以与他人轻松共享笔记本，他们将获得保存在同一位置的完全相同的笔记本。\n使用 SageMaker Studio Notebooks 时，您可以通过 IAM Identity Center 使用您的企业凭证登录。在团队内和团队间共享笔记本非常简单，因为系统会在工作映像中自动跟踪运行笔记本所需的依赖关系，并在共享笔记本时将其封装在笔记本内。"
    },
    {
        "query":"SageMaker 中的共享空间有哪些？",
        "intention":"知识问答",
        "reply":"ML 从业者可以创建一个共享工作区，团队成员可以在其中一起阅读和编辑 SageMaker Studio 笔记本。通过使用共享步调，团队成员可以共同编辑同一个笔记本文件，同时运行笔记本代码，并一起查看结果，以消除来回和简化协作。在共享空间中，ML 团队将内置对 BitBucket 和 AWS CodeCommit 等服务的支持，因此他们可以轻松管理笔记本的不同版本并比较随时间变化的变化。从笔记本中创建的任何资源（例如实验和 ML 模型）都会自动保存并与创建它们的特定工作区相关联，因此团队可以更轻松地保持井井有条并加速 ML 模型开发。"
    },
    {
        "query":"SageMaker Studio 笔记本如何与其他 AWS 服务协同工作？",
        "intention":"知识问答",
        "reply":"SageMaker Studio 笔记本让您能够使用 SageMaker 的所有功能，例如分布式训练、批量转换、托管和试验管理。您可以从 SageMaker 笔记本中使用 Amazon S3、Amazon Redshift、AWS Glue、Amazon EMR 或 AWS Lake Formation 中的数据集等其他服务。"
    },
    {
        "query":"SageMaker Studio Notebooks 如何定价？",
        "intention":"知识问答",
        "reply":"使用 SageMaker Studio Notebooks 时，您需要支付计算和存储费用。有关按计算实例类型收费的信息，请参阅 [Amazon SageMaker 定价](https://aws.amazon.com/cn/sagemaker/pricing/)。您的笔记本以及相关构件（例如数据文件和脚本）将保留在 Amazon Elastic File System（Amazon EFS）上。有关存储费用，请参阅 [Amazon EFS 定价](https://aws.amazon.com/efs/pricing/)。作为 [AWS Free Tier](https://aws.amazon.com/free/) 的一部分，您可以免费开始使用 SageMaker Studio 笔记本。"
    },
    {
        "query":"我是否需要为在 SageMaker Studio 中创建和运行的每个笔记本单独付费？",
        "intention":"知识问答",
        "reply":"不需要。您可以在同一计算实例上创建并运行多个笔记本。您只需为使用的计算付费，不需要为各个项目付费。您可以在我们的[计量指南](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-usage-metering.html)中了解更多相关信息。\n除了笔记本之外，您还可以在 SageMaker Studio 中启动和运行终端和交互式 Shell，一切操作均在同一计算实例上执行。每个应用程序都在容器或映像内运行。SageMaker Studio 提供了多个内置映像，这些映像是为数据科学和机器学习专门构建和预先配置的。您可以在[使用 SageMaker Studio 笔记本](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html)的指南中，阅读有关 SageMaker Studio 开发人员环境的更多信息。"
    },
    {
        "query":"如何监视和关闭我的笔记本所使用的资源？",
        "intention":"知识问答",
        "reply":"您可以通过 SageMaker Studio 可视化界面和 AWS 管理控制台来监视和[关闭](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-run-and-manage-shut-down.html) SageMaker Studio Notebooks 所使用的资源。 有关详细信息，请参阅[文档](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html#studio-ui-nav-bar)。"
    },
    {
        "query":"我正在运行 SageMaker Studio Notebook。如果关闭浏览器，关闭笔记本选项卡，或者只是保持浏览器打开，我仍需要付费吗？",
        "intention":"知识问答",
        "reply":"需要，您将继续为计算付费。这类似于在 AWS 管理控制台中启动 Amazon EC2 实例，然后关闭浏览器。除非您明确关闭 Amazon EC2 实例，否则该实例仍在运行，并且仍会产生费用。"
    },
    {
        "query":"创建和设置 SageMaker Studio 域是否需要付费？",
        "intention":"知识问答",
        "reply":"否，您无需为创建或配置 SageMaker Studio 域（包括添加、更新和删除用户资料）付费。"
    },
    {
        "query":"什么是 Amazon SageMaker Studio Lab？",
        "intention":"知识问答",
        "reply":"SageMaker Studio Lab 是一个免费的机器学习开发环境，它免费提供计算、存储（高达 15GB）和安全性，供任何人学习和试验 ML。您只需一个有效的电子邮件 ID 即可开始使用；无需配置基础设施或管理身份和访问权限，甚至无需注册 AWS 账户。SageMaker Studio Lab 通过 GitHub 集成加速模型构建，它预配置了最流行的 ML 工具、框架和库，可让您立即开始使用。SageMaker Studio Lab 会自动保存您的工作，因此您无需在会话之间重新启动。就像合上笔记本电脑然后再回来一样简单。"
    },
    {
        "query":"为什么要使用 SageMaker Studio Lab？",
        "intention":"知识问答",
        "reply":"SageMaker Studio Lab 适用于需要免费笔记本开发环境且无需设置机器学习课程和实验的学生、研究人员和数据科学家。SageMaker Studio Lab 非常适合不需要生产环境但仍希望使用 SageMaker 功能的子集来提高机器学习技能的用户。SageMaker 会话会自动保存，可帮助用户从每个用户会话的中断处继续。"
    },
    {
        "query":"SageMaker Studio Lab 与其他 AWS 服务如何协同工作？",
        "intention":"知识问答",
        "reply":"SageMaker Studio Lab 是一项基于 AWS 构建的服务，它利用了许多与 Amazon SageMaker Studio 相同的核心服务，例如 Amazon S3 和 Amazon EC2。与其他服务不同，客户不需要 AWS 账户。他们将使用电子邮件地址创建一个 SageMaker Studio Lab 特定账户。这将使用户能够访问一个有限的环境（15GB 的存储空间和 12 小时的会话），以便他们运行机器学习笔记本。"
    },
    {
        "query":"什么是 SageMaker Canvas？",
        "intention":"知识问答",
        "reply":"SageMaker Canvas 是一种可视化、拖放式服务，允许业务分析师构建 ML 模型并生成准确的预测，而无需编写任何代码，也无需 ML 专业知识。SageMaker Canvas 让您可以更轻松地访问和组合来自各种来源的数据，自动清理数据并应用各种数据调整，以及构建 ML 模型以通过单个步骤生成准确的预测。您还可以轻松发布结果、解释和解读模型，以及与企业内的其他人共享模型以进行审查。"
    },
    {
        "query":"SageMaker Canvas 支持哪些数据来源？",
        "intention":"知识问答",
        "reply":"SageMaker Canvas 有助于您无缝发现账户有权访问的 AWS 数据来源，包括 Amazon S3 和 Amazon Redshift。您可以使用 SageMaker Canvas 可视化拖放界面浏览和导入数据。此外，您还可以从本地磁盘拖放文件，并使用预构建的连接器从第三方源（如 Snowflake）导入数据。"
    },
    {
        "query":"如何在 SageMaker Canvas 中构建 ML 模型以生成准确的预测？",
        "intention":"知识问答",
        "reply":"连接源、选择数据集并准备好数据后，您可以选择要预测的目标列以启动模型创建任务。SageMaker Canvas 将自动识别问题类型，生成新的相关特征，使用 ML 技术（例如线性回归、逻辑回归、深度学习、时间序列预测和梯度提升）测试一组全面的预测模型，并构建基于您的数据集进行准确预测的模型。"
    },
    {
        "query":"在 SageMaker Canvas 中构建模型需要多长时间？ 如何在模型创建过程中监控进度？",
        "intention":"知识问答",
        "reply":"构建模型所需的时间取决于数据集的大小。小型数据集可能需要不到 30 分钟，大型数据集可能需要几个小时。随着模型创建作业的进行，SageMaker Canvas 会提供详细的视觉更新，包括作业完成百分比和完成作业剩余的时间。"
    },
    {
        "query":"什么是 Amazon SageMaker Experiments？",
        "intention":"知识问答",
        "reply":"SageMaker Experiments 可帮助您组织和跟踪机器学习模型的迭代。SageMaker Experiments 通过自动捕获输入参数、配置和结果并将其存储为“实验”来帮助您管理迭代。您可以使用 SageMaker Studio 的可视化界面来浏览进行中的实验，根据实验特征搜索先前的实验、查看先前的实验及结果，以及直观比较实验结果。"
    },
    {
        "query":"什么是 Amazon SageMaker Debugger？",
        "intention":"知识问答",
        "reply":"SageMaker Debugger 能够在训练期间自动捕获实时指标（例如，混淆矩阵和学习梯度），帮助提高模型精度。SageMaker Studio 中会直观呈现来自 SageMaker 调试程序的指标，以便您理解。检测到常见的训练问题时，SageMaker 调试程序还会生成警告及提供修复建议。SageMaker Debugger 还可以自动实时监控和分析系统资源，例如 CPU、GPU、网络和内存，并提供有关重新分配这些资源的建议。这有助于您在训练期间有效使用资源，并有助于降低成本和资源。"
    },
    {
        "query":"什么是 Amazon SageMaker Training Compiler？",
        "intention":"知识问答",
        "reply":"SageMaker Training Compiler 是一种深度学习（DL）编译器，可通过图形和内核级优化将 DL 模型训练速度提高多达 50%，从而更有效地使用 GPU。SageMaker Training Compiler 与 SageMaker 中的 TensorFlow 和 PyTorch 版本集成，因此您可以在这些流行框架中以最少的代码更改加速训练。"
    },
    {
        "query":"SageMaker Training Compiler 如何运行？",
        "intention":"知识问答",
        "reply":"SageMaker Training Compiler 通过将 DL 模型从其高级语言表示转换为硬件优化指令来加速训练任务，这些指令比使用本机框架的任务训练速度更快。更具体地说，SageMaker Training Compiler 使用图形级优化（运算符融合、内存规划和代数简化）、数据流级优化（布局转换、公共子表达式消除）和后端优化（内存延迟隐藏、面向循环的优化）来生成优化的模型训练任务，更有效地使用硬件资源，进而更快地训练。\n问：如何使用 SageMaker Training Compiler？\nSageMaker Training Compiler 内置于 SageMaker Python SDK 和 SageMaker Hugging Face 的深度学习容器中。您无需更改工作流程即可获得其加速优势。您可以采用与之前相同的方式使用任何 SageMaker 界面来运行训练任务：SageMaker Notebook 实例、SageMaker Studio、适用于 Python 的 Amazon SDK（Boto3）和 AWS 命令行界面（AWS CLI）。您可以在创建框架估算器对象时通过添加 TrainingCompilerConfig 类作为参数来启用 SageMaker Training Compiler。实际上，这意味着将几行代码添加到单个 GPU 实例的现有训练任务脚本中。[文档](https://docs.aws.amazon.com/sagemaker/latest/dg/training-compiler.html)中提供了最新的详细文档、示例笔记本和示例。"
    },
    {
        "query":"SageMaker Training Compiler 如何定价？",
        "intention":"知识问答",
        "reply":"SageMaker Training Compiler 是 SageMaker Training 的一项功能，专为 SageMaker 客户免费提供。随着训练时间的减少，客户实际上可以通过 SageMaker Training Compiler 降低成本。"
    },
    {
        "query":"什么是托管型 Spot 训练？",
        "intention":"知识问答",
        "reply":"借助 SageMaker 的托管型 Spot 训练功能，您可以使用 Amazon EC2 竞价型实例来训练您的机器学习模型，同时降低最高 90% 的训练模型成本。"
    },
    {
        "query":"我如何使用托管型 Spot 训练？",
        "intention":"知识问答",
        "reply":"您可以在提交训练作业时启用托管型 Spot 训练选项，同时您还可以指定希望等待 Spot 容量多长时间。然后，SageMaker 将使用 Amazon EC2 竞价型实例运行您的任务并管理 Spot 容量。您可以在训练任务运行及等待容量时全面了解其状态。"
    },
    {
        "query":"我应该在何时使用托管型 Spot 训练？",
        "intention":"知识问答",
        "reply":"当您能灵活运行您的训练且您想最大限度降低训练任务成本时，托管型 Spot 训练适用。托管型 Spot 训练可帮助您将训练机器学习模型的成本最高降低 90%。"
    },
    {
        "query":"托管型 Spot 训练的工作原理是什么？",
        "intention":"知识问答",
        "reply":"托管型 Spot 训练使用 Amazon EC2 竞价型实例进行训练，并且当 AWS 需要容量时可以先获得这些实例。因此，当容量可用时，托管型 Spot 训练任务可以以小的增量运行。当出现中断时，不需要从头开始重启训练任务，因为 SageMaker 可以使用最新的模型检查点恢复训练任务。SageMaker 的内置框架和内置计算机视觉算法支持定期检查点，并且您可以启用带有自定义模型的检查点。"
    },
    {
        "query":"使用托管型 Spot 训练时，我是否需要定期检查？",
        "intention":"知识问答",
        "reply":"对于长期运行的训练任务，我们建议将定期检查点作为一般最佳实践。这将阻止您的托管型 Spot 训练任务在先取得容量时重新启动。当您启用检查点时，SageMaker 会从最近的检查点恢复您的托管型 Spot 训练作业。"
    },
    {
        "query":"如何计算使用托管型 Spot 训练任务节省的成本？",
        "intention":"知识问答",
        "reply":"当托管的 Spot 训练任务完成后，您可以在 AWS 管理控制台中查看节省情况，并且还能通过训练任务运行持续时间与计费持续时间之间的百分比差异来计算成本节省。\n无论您的托管型 Spot 训练任务中断了多少次，都只会根据下载数据的持续时间向您收取一次费用。"
    },
    {
        "query":"我可以将哪些实例用于托管型 Spot 训练？",
        "intention":"知识问答",
        "reply":"可以将托管型 Spot 训练用于 SageMaker 中支持的所有实例。"
    },
    {
        "query":"哪些区域支持托管型 Spot 训练？",
        "intention":"知识问答",
        "reply":"目前[提供](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/) SageMaker 的所有区域都支持托管型 Spot 训练。"
    },
    {
        "query":"对于可用于训练的数据集，有没有大小限制？",
        "intention":"知识问答",
        "reply":"SageMaker 训练模型可以使用的数据集没有固定的大小限制。"
    },
    {
        "query":"SageMaker 使用哪些算法来生成模型？",
        "intention":"知识问答",
        "reply":"SageMaker 包含一些内置算法，例如线性回归算法、逻辑回归算法、k-means 集群算法、主成分分析算法、因式分解机算法、神经主题建模算法、潜在狄利克雷分配算法、梯度提高树算法、序列到序列算法、预测时间序列 word2vec 和映像分类算法等。SageMaker 还提供经过优化的 Apache MXNet、Tensorflow、Chainer、PyTorch、Gluon、Keras、Horovod、Scikit-learn 和 Deep Graph Library 容器。此外，SageMaker 还支持通过符合成文规格的 Docker 映像提供的自定义训练算法。"
    },
    {
        "query":"什么是 Automatic Model Tuning？",
        "intention":"知识问答",
        "reply":"大多数机器学习算法都提供了各种各样的参数，这些参数控制了底层算法的运算方式。这些参数通常被称为超参数，它们的值会影响经过训练的模型的质量。Automatic Model Tuning 是为能够生成最优模型的算法寻找超参数组合的过程。"
    },
    {
        "query":"Automatic Model Tuning 可用来优化哪些模型？",
        "intention":"知识问答",
        "reply":"只要在科学上可行，您就可以在 SageMaker 中基于任何算法运行自动模型调优，包括内置的 SageMaker 算法、深度神经网络算法或您通过 Docker 映像引入 SageMaker 的任意算法。"
    },
    {
        "query":"可以在 SageMaker 之外使用 Automatic Model Tuning 吗？",
        "intention":"知识问答",
        "reply":"目前不可以。只有在 SageMaker 内部使用它，才能获得最佳的模型优化性能和体验。"
    },
    {
        "query":"Automatic Model Tuning 的底层优化算法是什么？",
        "intention":"知识问答",
        "reply":"目前，用于优化超参数的算法是对贝叶斯算法的自定义实现。其目的是在优化过程中优化客户指定的目标参数。具体来说，它检查已完成训练任务的目标参数，然后利用这一信息推断下一个训练任务的超参数组合。"
    },
    {
        "query":"Automatic Model Tuning 是否推荐特定的超参数进行优化？",
        "intention":"知识问答",
        "reply":"不推荐。某些超参数对模型性能的影响取决于各种各样的因素，很难肯定地说一个超参数比其他超参数更重要，因此需要对它进行优化。对于 SageMaker 的内置算法，我们会提示每个超参数是否可进行优化。"
    },
    {
        "query":"每个超参数优化任务用时多久？",
        "intention":"知识问答",
        "reply":"超参数优化任务的用时长短取决于多种因素，包括数据的大小、底层算法和超参数的值。此外，客户可以选择同时执行的训练任务的数量和训练任务的总数量。所有这些选择都会影响超参数优化任务的用时。"
    },
    {
        "query":"能否像优化模型一样既快速又准确地同时优化多个目标？",
        "intention":"知识问答",
        "reply":"目前不可以。目前，您需要指定一个目标参数来优化或更改您的算法代码，以生成一个新指标（该指标是两个或更多有用指标之间的加强平均值），并在优化过程中对该目标指标进行优化。"
    },
    {
        "query":"怎样判断是应该使用 SageMaker Autopilot 还是 Automatic Model Tuning？",
        "intention":"知识问答",
        "reply":"SageMaker Autopilot 可以自动处理典型的机器学习工作流程中的所有工作，包括特征预处理、算法选择和超参数优化，同时特别关注分类和回归使用场景。而 Automatic Model Tuning 用于优化任何模型，无论其是基于内置算法、深度学习框架还是自定义容器。为了获得灵活性，您必须手动选择具体算法、要优化的超参数和相应的搜索范围。"
    },
    {
        "query":"什么是强化学习？",
        "intention":"知识问答",
        "reply":"强化学习是一项机器学习技术，可帮助代理运用从其自己的行为和经验中得到的反馈，通过反复试验在交互式环境中学习。"
    },
    {
        "query":"我是否可以在 SageMaker 中训练强化学习模型？",
        "intention":"知识问答",
        "reply":"可以，除了监督学习和无监督学习训练模型之外，您还可以在 SageMaker 中训练强化学习模型。"
    },
    {
        "query":"强化学习与有监督学习有何不同？",
        "intention":"知识问答",
        "reply":"虽然监督学习与强化学习均使用输入和输出之间的映射，但强化学习使用延迟反馈，它对奖励信号进行了优化，以确保通过一系列操作实现长期目标，而不像监督学习那样，提供给代理的反馈是一组用于执行任务的正确操作。"
    },
    {
        "query":"什么时候应该使用强化学习？",
        "intention":"知识问答",
        "reply":"监督学习技术的目标是根据训练数据中的模式找到正确的答案，无监督学习技术的目标是发现数据点之间的相同之处和不同之处。相比之下，强化学习 (RL) 技术的目标是学习如何实现预期结果，即使不清楚如何实现该结果。因此，RL 更适合实现智能应用，其中代理可以自主决策，例如机器人、无人驾驶车辆、暖通空调和工业控制等等。"
    },
    {
        "query":"我可以使用什么类型的环境训练 RL 模型？",
        "intention":"知识问答",
        "reply":"Amazon SageMaker RL 支持许多不同的环境来训练 RL 模型。您可以使用 AWS 服务（如 AWS RoboMaker）、开源环境或自定义环境（使用 Open AI Gym 接口开发），或者使用商业模拟环境（如 MATLAB 和 SimuLink）。"
    },
    {
        "query":"我是否需要编写自己的 RL 代理算法来训练 RL 模型？",
        "intention":"知识问答",
        "reply":"不需要，SageMaker RL 包含 RL 工具包（如 Coach 和 Ray RLLib），这些工具包提供 RL 代理算法的实现，如 DQN、PPO、A3C 等等。"
    },
    {
        "query":"我能否自带 RL 库和算法实现并在 SageMaker RL 中运行它们？",
        "intention":"知识问答",
        "reply":"能，您可以将您自己的 RL 库和算法实现引入 Docker 容器并在 SageMaker RL 中运行这些实现。"
    },
    {
        "query":"我是否可以使用 SageMaker RL 执行分布式部署？",
        "intention":"知识问答",
        "reply":"是。您甚至可以选择一个异构集群，其中训练可以在 GPU 实例上运行，而模拟可以在多个 CPU 实例上运行。"
    },
    {
        "query":"SageMaker 提供哪些部署选项？",
        "intention":"知识问答",
        "reply":"在您构建和训练模型以后，SageMaker 提供三种选项来部署它们，让您可以开始进行预测。实时推理适用于有毫秒级延迟要求的工作负载，它的负载最大为 6MB，处理时间最长为 60 秒。批量转换适用于对预付费用的大批量数据的离线预测。异步推理专门为没有亚秒级延迟要求，负载最大为 1GB，处理时间最长为 15 分钟的工作负载而设计。"
    },
    {
        "query":"什么是 Amazon SageMaker 异步推理？",
        "intention":"知识问答",
        "reply":"SageMaker 异步推理可异步对传入请求进行排列与处理。此选项适用于需要在到达时进行处理的负载大小较大和/或处理时间较长的请求。您还可以选择配置自动扩展设置，以便在未积极处理请求时缩减实例数量到零，从而节省成本。"
    },
    {
        "query":"我该如何配置自动扩展设置，以便在未积极处理请求时缩减实例数量到零？",
        "intention":"知识问答",
        "reply":"您可以缩减 SageMaker 异步推理端点实例数量到零，以便在您未积极处理请求时节省成本。您需要定义根据“ApproximateBacklogPerInstance”自定义指标进行扩展的扩展策略，并且将“MinCapacity”值设置为零。如需了解分步说明，请查看《开发人员指南》的[自动扩展异步终端节点](http://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-autoscale.html)部分。"
    },
    {
        "query":"什么是 Amazon SageMaker 无服务器推理功能？",
        "intention":"知识问答",
        "reply":"[SageMaker 无服务器推理功能](https://aws.amazon.com/cn/sagemaker/deploy/#Serverless_inference_for_intermittent_usage_patterns)是一个专门构建的无服务器模型服务选项，可让您轻松部署和扩展 ML 模型。SageMaker 无服务器推理端点会自动启动计算资源并根据流量扩大和缩小它们，让您无需选择实例类型、运行预置容量或管理扩展。您可以选择为无服务器推理端点指定内存要求。您只需为运行推理代码的持续时间和处理的数据量付费，而无需为空闲时间付费。"
    },
    {
        "query":"为什么要使用 SageMaker 无服务器推理功能？",
        "intention":"知识问答",
        "reply":"SageMaker 无服务器推理功能无需预先配置容量和管理扩展策略，从而简化了开发人员的体验。SageMaker 无服务器推理功能可以根据使用模式在几秒钟内立即从数十个推理扩展到数千个推理，使其成为具有间歇性或不可预测流量的 ML 应用程序的理想选择。例如，一家工资单处理公司使用的 Chatbot 服务在月底会遇到查询增加的情况，而在该月的其余时间，流量是间歇性的。在这种情况下，为整个月调配实例的成本效益不高，因为您最终要为闲置期付费。SageMaker 无服务器推理通过为您提供开箱即用的自动和快速扩展，而无需您预先预测流量或管理扩展策略，从而帮助解决这些类型的用例。此外，您只需为运行推理代码的计算时间（以毫秒计费）和数据处理支付费用，因此对于具有间歇流量的工作负载，这是一个经济有效的选择。"
    },
    {
        "query":"什么是 SageMaker 无服务器推理的预置并发？",
        "intention":"知识问答",
        "reply":"预置并发可让您在无服务器端点上部署模型，这些模型具有可预测的性能，并且通过让端点为指定数量的并发请求保持预热来实现高可扩展性。"
    },
    {
        "query":"为什么应使用预置并发？",
        "intention":"知识问答",
        "reply":"使用按需无服务器端点，如果您的端点有一段时间没有收到流量，然后突然收到新的请求，则您的端点可能需要一些时间才能启动计算资源来处理请求。这称为冷启动。如果您的并发请求超过当前的并发请求使用量，也可能发生冷启动。冷启动时间取决于您的模型大小、下载模型所需的时间以及容器的启动时间。\n为了减少不断变化的延迟，您可以选择为无服务器端点启用预置并发。使用预置并发功能，您的无服务器端点随时准备就绪，可以即时应对突发流量，并且不会出现冷启动。"
    },
    {
        "query":"什么是 Amazon SageMaker Inference Recommender？",
        "intention":"知识问答",
        "reply":"[SageMaker Inference Recommender](https://aws.amazon.com/cn/sagemaker/deploy/#Automatic_inference_instance_selection_and_load_testing) 通过跨 SageMaker ML 实例自动执行性能基准测试和优化模型性能，减少了将 ML 模型投入生产所需的时间。您现在可以使用 SageMaker Inference Recommender 将您的模型部署到提供最佳性能和最小成本的端点。您可以在几分钟内开始使用 SageMaker Inference Recommender，同时选择实例类型并在数小时内获得最佳端点配置的建议，从而消除数周的手动测试和调整时间。使用 SageMaker Inference Recommender，您只需为负载测试期间使用的 SageMaker ML 实例付费，无需额外费用。  \n   \n 问：为什么要使用 SageMaker Inference Recommender？\n如果您需要有关正确端点配置的建议以提高性能并降低成本，则应使用 SageMaker Inference Recommender。以前，想要部署模型的数据科学家必须运行手动基准测试来选择正确的端点配置。他们必须首先根据模型的资源需求和样本有效负载，从 70 多种可用实例类型中选择正确的 ML 实例类型，然后优化模型以适应不同的硬件。接下来，他们必须进行广泛的负载测试，以验证是否满足延迟和吞吐量要求并且成本很低。SageMaker Inference Recommender 消除了这种复杂性，让您可以轻松地：1) 通过实例推荐在几分钟内开始使用；2) 跨实例类型进行负载测试，以在数小时内获得有关您的端点配置的建议；3) 自动调整容器和模型服务器参数，并为给定的实例类型执行模型优化。  \n   \n 问：SageMaker Inference Recommender 如何与其他 AWS 服务配合使用？\n数据科学家可以从 SageMaker Studio、AWS SDK for Python (Boto3) 或 AWS CLI 访问 SageMaker Inference Recommender。他们可以在 SageMaker Studio 中的 SageMaker 模型注册表中为已注册模型版本获取部署建议。数据科学家可以通过 SageMaker Studio、AWS 开发工具包或 AWS CLI 搜索和筛选建议。"
    },
    {
        "query":"SageMaker Inference Recommender 能否支持多模型端点或多容器端点？",
        "intention":"知识问答",
        "reply":"不，我们目前仅支持每个终端节点一个模型。"
    },
    {
        "query":"SageMaker Inference Recommender 支持哪些类型的终端节点？",
        "intention":"知识问答",
        "reply":"目前我们只支持实时终端节点。"
    },
    {
        "query":"我可以在一个区域使用 SageMaker Inference Recommender 并在不同区域进行基准测试吗？",
        "intention":"知识问答",
        "reply":"我们支持 Amazon SageMaker 支持的所有区域，AWS 中国区域除外。"
    },
    {
        "query":"SageMaker Inference Recommender 是否支持 Amazon EC2 Inf1 实例？",
        "intention":"知识问答",
        "reply":"是的，我们支持所有类型的容器。Amazon EC2 Inf1 基于 AWS Inferentia 芯片，需要使用 Neuron 编译器或 Amazon SageMaker Neo 编译的模型构件。一旦您拥有 Inferentia 目标的编译模型和关联的容器映像 URI，您就可以使用 SageMaker Inference Recommender 对不同的 Inferentia 实例类型进行基准测试。"
    },
    {
        "query":"什么是 Amazon SageMaker Model Monitor？",
        "intention":"知识问答",
        "reply":"开发人员能够使用 SageMaker Model Monitor 来检测和修复概念偏差。SageMaker Model Monitor 会自动检测已部署模型中的概念偏差，并提供详细的警报，帮助确定问题的根源。通过 SageMaker 训练的所有模型都会自动发送关键指标，这些指标可以在 SageMaker Studio 中收集和查看。从 SageMaker Studio 内部，您可以配置要收集的数据、查看方式以及提示的接收时间。"
    },
    {
        "query":"我能否访问运行 SageMaker 的基础设施？",
        "intention":"知识问答",
        "reply":"否。SageMaker 会代您运行计算基础设施，从而执行运行状况检查、应用安全补丁和执行其他例行维护。您也可以通过在自己托管的环境中训练自定义推理代码来部署模型项目。"
    },
    {
        "query":"如何在投产后扩展 SageMaker 模型的大小和性能？",
        "intention":"知识问答",
        "reply":"SageMaker 托管使用 Application Auto Scaling 自动扩展到您的应用程序所需的性能。此外，您可以通过修改端点配置，在不停机的情况下手动更改实例的数量和类型。"
    },
    {
        "query":"如何监控我的 SageMaker 生产环境？",
        "intention":"知识问答",
        "reply":"SageMaker 将性能指标发到 Amazon CloudWatch Metrics，这样您可以跟踪指标、设置警报，并自动响应生产流量变化。此外，SageMaker 还会将日志写入 Amazon CloudWatch Logs，让您能够监控生产环境并对其进行故障排除。"
    },
    {
        "query":"哪种模型能够通过 SageMaker 进行托管？",
        "intention":"知识问答",
        "reply":"SageMaker 可托管符合推理 Docker 映像的记录规格的任何模型，其中包括利用 SageMaker 模型构件和推理代码创建的模型。"
    },
    {
        "query":"SageMaker 支持的并发实时 API 请求的数量是多少？",
        "intention":"知识问答",
        "reply":"SageMaker 旨在将每秒完成的事务量扩展到一个更大值。精确的数量因部署的模型以及部署模型的目标实例的数量和类型而有所不同。"
    },
    {
        "query":"什么是批量转换？",
        "intention":"知识问答",
        "reply":"通过批量转换，您可以针对大批量或小批量数据运行预测。无需将数据集拆分为多个区块，也无需管理实时终端节点。使用一个简单的 API，您可以轻松快速地请求对大量数据记录进行预测并转换数据。"
    },
    {
        "query":"SageMaker Edge Manager 与 AWS Panorama 有何关系？ 何时应使用 SageMaker Edge Manager 与 AWS Panorama？  AWS 提供在边缘设备上运行模型的最大广度和最大深度功能。我们提供的服务可支持各种使用案例，包括计算机视觉、语音识别和预测性维护。",
        "intention":"知识问答",
        "reply":"对于希望在摄像机和家电等边缘设备上运行计算机视觉的公司，您可以使用 AWS Panorama。AWS Panorama 可随时为边缘设备部署计算机视觉应用程序。登录云控制台，指定要在 Amazon S3 或 SageMaker 中使用的模型，然后将业务逻辑作为 Python 脚本编写，即可轻松开始使用 AWS Panorama。AWS Panorama 会为目标设备编译模型并创建一个应用程序包，因此只需单击几下即可将其部署到您的设备上。此外，想要构建自己的自定义应用程序的独立软件提供商可以使用 AWS Panorama 开发工具包，并且设备制造商可使用 Device SDK 认证其设备以使用 AWS Panorama。\n想要构建自己的模型并对模型功能进行更精细控制的客户，可以使用 SageMaker Edge Manager。SageMaker Edge Manager 是一项托管服务，用于跨各种边缘设备（如智能摄像机、智能扬声器和机器人）准备、运行、监控和更新机器学习模型，以用于自然语言处理、欺诈检测和预测性维护等使用案例。SageMaker Edge Manager 适用于希望控制其模型（包括设计不同的模型功能并监控模型漂移）的 ML 边缘开发人员。任何 ML Edge 开发人员都可以通过 SageMaker 控制台和 SageMaker API 使用 SageMaker Edge Manager。SageMaker Edge Manager 提供 SageMaker 的功能，可将云中的模型构建、训练和部署到边缘设备。"
    },
    {
        "query":"什么是 Amazon SageMaker Neo？",
        "intention":"知识问答",
        "reply":"SageMaker Neo 让机器学习模型训练一次即可在云和边缘站点中的任何位置运行。SageMaker Neo 可以自动优化使用常用的深度学习框架构建的模型，这些框架可用于在多个硬件平台上部署。优化的模型运行速度最多可提高 25 倍，并且所消耗的资源不到典型机器学习模型的十分之一。"
    },
    {
        "query":"如何开始使用 SageMaker Neo？",
        "intention":"知识问答",
        "reply":"要开始使用 SageMaker Neo，请登录 SageMaker 控制台，选择经过训练的模型，根据示例编译模型，然后将生成的模型部署到目标硬件平台上。"
    },
    {
        "query":"SageMaker Neo 有哪些主要组件？",
        "intention":"知识问答",
        "reply":"SageMaker Neo 包含两个主要组件：编译器和运行时系统。首先，SageMaker Neo 编译器会读取由不同框架导出的模型。然后，它将框架特定的功能和操作转换为与框架无关的中间表示形式。接着，它会执行一系列优化。最后，编译器会为优化的操作生成二进制代码，并将其写入一个共享对象库。此外，编译器还会将模型定义和参数保存到各个文件中。在执行期间，SageMaker Neo 运行时系统会加载编译器生成的构件（模型定义、参数和共享对象库）以运行模型。"
    },
    {
        "query":"我是否需要使用 SageMaker 训练我的模型才能使用 SageMaker Neo 转换模型？",
        "intention":"知识问答",
        "reply":"不需要。您可以在其他位置训练模型，然后使用 SageMaker Neo 为 SageMaker ML 实例或 AWS IoT Greengrass 支持的设备优化这些模型。"
    },
    {
        "query":"SageMaker Neo 支持哪些模型？",
        "intention":"知识问答",
        "reply":"目前，SageMaker Neo 支持最常用的深度学习模型（此类模型支持计算机视觉应用程序），以及当今 SageMaker 中最常用的决策树模型。SageMaker Neo 可以优化 MXNet 和 TensorFlow 中训练的 AlexNet、ResNet、VGG、Inception、MobileNet、SqueezeNet 和 DenseNet 模型的性能，以及 XGBoost 中训练的分类和随机砍伐森林（Random Cut Forest）模型的性能。"
    },
    {
        "query":"SageMaker Neo 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"要查看支持区域的列表，请参阅 [AWS 区域性服务列表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"什么是 Amazon SageMaker 实惠配套？",
        "intention":"知识问答",
        "reply":"SageMaker 实惠配套是一种面向 Amazon SageMaker 的基于用量的灵活定价模式，您需要在一年或三年的期限内达到稳定的承诺用量（以 USD/小时为单位衡量）。SageMaker 实惠配套的灵活性最高，最高可帮助您节省 64% 的费用。这些计划会自动应用于符合条件的 SageMaker ML 实例用量，包括 SageMaker Studio Notebooks、SageMaker 按需笔记本、SageMaker 处理、SageMaker Data Wrangler、SageMaker 训练、SageMaker 实时推理和 SageMaker 批量转换，无论实例系列、大小或区域如何。例如，您可以随时将在美国东部（俄亥俄州）运行的 CPU 实例 ml.c5.xlarge 用量更改为在美国西部（俄勒冈州）运行的 ml.Inf1 实例用量以用于推理工作负载，并自动继续支付实惠配套价格。  \n   \n 问：为什么要使用 SageMaker 实惠配套？\n如果您具有稳定的 SageMaker 实例用量（以 USD/小时为单位衡量）并且使用多个 SageMaker 组件，或者期望您的技术配置（例如实例系列、区域）随时间推移而变化，SageMaker 实惠配套会帮助您更加轻松地实现最大程度的费用节省，与此同时，它还会根据应用程序需求或新创新来灵活更改基础技术配置。实惠配套费率会自动应用于所有符合条件的 ML 实例，无需进行手动修改。"
    },
    {
        "query":"如何开始使用 SageMaker 实惠配套？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 管理控制台中的 AWS Cost Explorer 成本管理服务或者通过 API/CLI 开始使用实惠配套。您可以按照 AWS Cost Explorer 中提供的建议，轻松承诺使用某个 Savings Plans 并实现最大的成本节省。建议的小时承付额基于您的历史按需使用量以及您选择的计划类型、期限长度和付款选项。注册 Savings Plans 后，您的计算用量将自动按 Savings Plan 折扣价格计费，超过承付额的任何用量都将按正常按需价格计费。  \n   \n 问：SageMaker 实惠配套与 Amazon EC2 计算实惠配套有何不同？\nSageMaker 实惠配套和 Amazon EC2 实惠配套的不同之处在于它们所提供的服务不同。SageMaker 实惠配套仅适用于 SageMaker ML 实例用量。  \n   \n 问：Savings Plans 如何使用 AWS Organizations/整合账单？\n可通过 AWS Organizations/整合账单系列中的任何账户购买 Savings Plans。默认情况下，Savings Plans 提供的优惠适用于 AWS Organization/整合账单系列中的所有账户的用量。不过，您也可以选择将 Savings Plans 的权益限定到仅购买过 Savings Plans 的账户。\n了解有关 Amazon SageMaker 定价的更多信息"
    },
    {
        "query":"如何为指定的主节点部署只读副本节点？ 使用 CreateReplicationGroup API 或在 Amazon ElastiCache 管理控制台中单击几下鼠标，即可很快创建一个只读副本。创建复制组时，您要指定 MasterCacheClusterIdentifier。MasterCacheClusterIdentifier 是您想从中进行复制的“主”缓存集群的缓存集群标识符。然后，您可以通过调用 CreateCacheCluster API 指定主要集群的 ReplicationGroupIdentifier 和 CacheClusterIdentifier，以在复制组中创建只读副本集群。与标准缓存集群一样，您也可以指定可用区。开始创建只读副本时，Amazon ElastiCache 将对主缓存集群拍摄快照，并开始复制。因此，在拍摄快照时，您的主缓存集群上的 I/O 可能会短暂性停止。I/O 停止一般大约会持续一分钟。",
        "intention":"知识问答",
        "reply":"删除只读副本同创建一样简单；只需使用 Amazon ElastiCache 管理控制台或调用 DeleteCacheCluster API 即可（为您要删除的只读副本指定 CacheClusterIdentifier）。  \n   \n 问：我能否同时创建主节点和只读副本？  \n 可以。使用 CreateReplicationGroup API，或使用 Amazon ElastiCache 管理控制台中的“Create”（创建）向导并选择“Multi-AZ Replication”（多可用区复制），在几分钟内即可创建一个新的缓存集群及其只读副本。创建集群时，请指定标识符、集群内所需分区的总数量、每个分区的只读副本数量以及创建参数，如节点类型、引擎版本等。您还可以为该集群中的每个分区指定可用区。"
    },
    {
        "query":"如果发生失效转移，只读副本会怎么样？ 如果发生失效转移，所有关联和可用的只读副本在失效转移完成后将自动恢复复制（获取最新提升的只读副本的更新）。  问：是否可以为其他只读副本创建只读副本？ 不支持为其他只读副本创建只读副本。  问：是否可以将我的只读副本提升为“独立”主节点？ 不可以，不支持此操作。但是，您可以为您的 Amazon ElastiCache for Redis 节点创建快照（可以选择主节点或任何只读副本）。然后，您可使用快照生成新的 Amazon ElastiCache for Redis 主节点。",
        "intention":"知识问答",
        "reply":"只读副本受 Redis 复制的优点和缺点影响。如果使用只读副本，您应了解只读副本与其主缓存节点之间可能存在滞后或“不一致”。 Amazon ElastiCache [会发出指标](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheMetrics.Redis.html)以帮助您了解不一致性。\n问：如何查看有效的只读副本？  \n 您可以使用标准的 DescribeCacheClusters API 返回已部署的所有缓存集群列表（包括只读副本），或者直接单击 Amazon ElastiCache 管理控制台的“缓存集群”选项卡进行查看。\nAmazon ElastiCache 监控您的只读副本的复制状态，并在因任何原因停止复制时将“副本状态”字段更新为“错误”。您可以通过查看 Replication Error（复制错误）字段来查看 Redis 引擎产生的相关错误的详细信息，然后进行适当操作以从中恢复。您可以在 Amazon ElastiCache 用户指南的“排除只读副本问题”部分了解有关排除复制问题的更多信息。如果复制错误得到修复，“副本状态”将更改为“正在复制”。  \n   \n Amazon ElastiCache 允许您利用 AWS 管理控制台或 Amazon CloudWatch API 通过 Amazon CloudWatch 指标（“副本滞后”）查看只读副本滞后于其主节点的程度。  \n   \n 问：我的只读副本已远远落后于其主节点。我应该怎么办？  \n 如前述问题中所述，使用 Redis 异步复制时，只读副本与其主缓存节点之间的“不一致”或滞后非常常见。如果现有只读副本已远远落后，不能满足您的要求，您可以重启该副本。请注意，副本滞后可能会随时间推移而加剧或减缓，具体取决于主节点的稳定状态使用模式。  \n   \n 问：如何删除只读副本？ 主节点删除后，它是否会自动随之删除？  \n 您在 AWS 管理控制台中单击几下鼠标或者使用 DeleteCacheCluster 或 DecreaseReplicaCount API，即可轻松地删除只读副本。如果除了主缓存节点之外您还想删除只读副本，您必须使用 DeleteReplicationGroup API 或 AWS 管理控制台。  \n   \n 问：只读副本的费用如何？ 如何计算记账周期？  \n 只读副本按标准的缓存节点进行计费，且费率相同。和标准的缓存节点一样，只读副本的每“缓存节点小时”费率取决于只读副本的缓存节点类 – 有关最新的定价信息，请参阅 Amazon ElastiCache 详细信息页面。在主缓存节点和只读副本之间复制数据，产生的数据传输不收取费用。只读副本的账单周期从成功创建只读副本后开始（即当列出的状态为“有效”时）。只读副本将一直按标准的 Amazon ElastiCache 缓存节点小时费用计费，直到您发布命令将其删除为止。\n问：执行失效转移时会发生什么状况？这种情况会持续多长时间？  \n Amazon ElastiCache 支持启动失效转移，这样您可以尽快恢复缓存操作。失效转移后，Amazon ElastiCache 会让缓存节点的 DNS 记录指向只读副本，只读副本转而成为新的主节点。我们建议您遵循最佳实践，在应用程序层实施缓存节点连接重试。通常，以下从开始到结束的第 1 到第 5 步在 6 分钟内完成。  \n   \n 这些是自动失效转移事件，按发生的顺序列出："
    },
    {
        "query":"是否可以在另一个区域创建只读副本作为主节点？ 不可以，您只可以在相同区域的同一可用区或不同可用区内预置只读副本作为您的主缓存节点。",
        "intention":"知识问答",
        "reply":"然而，您可以[使用](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/Redis-Global-Datastore.html)适用于 Redis 的 Global Datastore 在 AWS 区域间进行快速、可靠、安全的完全托管型复制。使用此功能，您可以为 ElastiCache for Redis 创建跨区域只读副本集群，以实现跨 AWS 区域的低延迟读取和灾难恢复。"
    },
    {
        "query":"如何为我的应用程序选择合适的节点类型？ 虽然此问题没有明确的答案，但使用 Amazon ElastiCache 时，您无需担心节点数量是否恰当，因为日后您可以轻松添加或删除节点。在选择初始配置时，您可以考虑以下两个互为关联的因素：",
        "intention":"知识问答",
        "reply":"所需的内存量取决于您的数据集的大小，以及应用程序的访问模式。要提高容错能力，请在大体了解所需的内存总量后，将该内存量分配到足够数量的节点，以便您的应用程序在一两个节点出现故障时依然可以运行。例如，如果您的内存要求为 13 GB，则您可能需要使用两个 cache.m4.large 节点，而不是一个 cache.m4.xlarge 节点。请务必确保在一个或多个节点的故障恢复期间，当缓存命中率暂时降低时，数据库等其他系统不会过载。有关详细信息，请参阅 [Amazon ElastiCache 用户指南](http://docs.amazonwebservices.com/AmazonElastiCache/latest/mem-ug/ChooseACacheNodeType.html)。  \n   \n 问：一个集群是否可以跨越多个可用区？  \n 可以。创建集群或向现有集群添加节点时，可以为新节点选择可用区。可以在每个可用区中指定请求的节点数量，也可以选择“spread nodes across zones”。如果集群位于 VPC 中，则节点只可以放置在属于所选缓存子网组的可用区中。有关其他详细信息，请参阅 [ElastiCache VPC 文档](https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/VPCs.CreatingCacheCluster.html)。  \n   \n 问：对于一个区域，我可以在 Amazon ElastiCache Memcached 中运行多少个节点？  \n 您最多可以在每个区域运行 300 个节点。如果需要运行更多节点，请填写 [ElastiCache 上限提高申请表](http://aws.amazon.com/contact-us/elasticache-node-limit-request/)。"
    },
    {
        "query":"我可以控制是否以及何时将支持 Amazon ElastiCache 集群的引擎版本升级到受支持的新版本吗？ 使用 Amazon ElastiCache 时，您可以控制是否以及何时将为集群提供技术支持且符合 Memcached 协议规范的软件升级到 Amazon ElastiCache 支持的新版本。这使您能够灵活地保持与特定 Memcached 版本兼容，在生产中部署应用程序前针对新版本进行测试，以及根据自己的要求和时间执行版本升级。由于版本升级涉及一定的兼容性风险，因此这些升级不会自行启动，必须由您启动。这种软件修补方式让您能够主导版本升级，但仍然可以将应用程序修补工作移交给 Amazon ElastiCache。阅读后面的常见问题，可以了解有关版本管理的更多相关信息。此外，您也可以参阅 Amazon ElastiCache 用户指南。虽然引擎版本管理功能旨在让您尽可能多地控制执行修补的方式，但我们保留在系统或缓存软件存在任何安全漏洞时代表您修补集群的权利。  问：如何指定集群应运行哪个受支持的 Memcached 版本？ 您可以在创建新集群时指定当前受支持的任何版本（次要和/或主要版本）。如果您要升级受支持的引擎版本，您可以使用集群的“修改”选项执行此操作。只需通过“Cache Engine Version”字段指定您希望升级到的版本即可。然后，Amazon ElastiCache 将立即（如果已选中“Applied Immediately”选项）或在集群的下一个计划维护窗口代表您执行升级。  问：升级前，是否可以针对新版本测试集群？ 可以。要进行测试，您可以使用新引擎版本创建一个新集群。您可以将开发/暂存应用程序指向此集群并进行测试，而后再决定是否升级您的初始集群。  问：Amazon ElastiCache 是否提供支持新 Memcached 发行版本和/或淘汰当前支持的版本的指导准则？ 随时间推移，我们计划为 Amazon ElastiCache 支持更多 Memcached 的主要和次要版本。特定年度支持的新发布版本数量因 Memcached 发布版本的频率和内容而异，由工程团队负责版本全面审查的最终结果。  问：Amazon ElastiCache 支持哪个版本的 Memcached 线路协议？ Amazon ElastiCache 支持 Memcached 版本 1.6.17、1.6.12、1.6.6、1.5.16、1.5.10、1.4.34、1.4.33、1.4.24、1.4.14 和 1.4.5 的 Memcached 文本和二进制协议。  问：如何升级到最新版 Memcached？ 您可以通过“修改”过程来升级现有 Memcached 集群。从旧版 Memcached 升级到 Memcached 1.4.33 或更高版本时，请确保您的现有参数 max_chunk_size 的值满足 slab_chunk_max 参数需要的条件。请查看此处的升级先决条件。",
        "intention":"知识问答",
        "reply":"详细了解 Amazon ElastiCache for Redis 的定价"
    },
    {
        "query":"什么是 AWS Global Accelerator？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 是一种联网服务，可以帮助您提高为全球用户提供的应用程序的可用性和性能。AWS Global Accelerator 可以轻松设置、配置和管理。它可以提供静态 IP 地址，从而为您的应用程序提供固定的入口点，并消除了为不同 AWS 区域和可用区管理特定 IP 地址的复杂性。AWS Global Accelerator 始终根据性能将用户流量路由到最佳终端节点，即时针对应用程序运行状况、用户位置和您配置的策略的变化做出反应。您可以从自己的位置使用[速度比较工具](https://speedtest.globalaccelerator.aws/#/)测试性能优势。与其他 AWS 服务一样，AWS Global Accelerator 也是一种按用量付费的自助服务，无需长期承诺或最低费用。"
    },
    {
        "query":"AWS Global Accelerator 可以用来做什么？",
        "intention":"知识问答",
        "reply":"借助 AWS Global Accelerator，您可以："
    },
    {
        "query":"如何开始使用 AWS Global Accelerator？",
        "intention":"知识问答",
        "reply":"您可以使用 API 或通过 AWS 管理控制台开始设置 AWS Global Accelerator，也可以使用 AWS CloudFormation 模板进行设置。AWS Global Accelerator 是一项全球服务，因此它不与任何特定 AWS 区域绑定。以下是为您的应用程序设置 AWS Global Accelerator 的三个简单步骤："
    },
    {
        "query":"AWS Global Accelerator 与 Elastic Load Balancing (ELB) 如何配合使用？",
        "intention":"知识问答",
        "reply":"这两种服务都可以解决将用户请求路由到运行状况良好的应用程序终端节点的难题。AWS Global Accelerator 依靠 ELB 提供传统的负载均衡功能，比如支持内部终端节点和非 AWS 终端节点、预热和第 7 层路由。不过，ELB 在一个区域内提供负载均衡，AWS Global Accelerator 却可以跨多个区域提供流量管理。\n区域 ELB 负载均衡器是 AWS Global Accelerator 的理想目标。通过使用区域 ELB 负载均衡器，您可以在 AWS 区域内跨后端（比如 Amazon EC2 实例或 Amazon ECS 任务）精确分配传入应用程序流量。AWS Global Accelerator 将这些功能扩展至超越单个 AWS 区域，对 ELB 起到了补充作用，让您可以为任意数量区域中的应用程序预置全球接口。如果您的工作负载需要满足全球客户群的要求，我们建议您使用 AWS Global Accelerator。如果您将工作负载托管在单个 AWS 区域中并由同一区域内和周围的客户端使用，则可以使用 Application Load Balancer 或网络负载均衡器来管理资源。"
    },
    {
        "query":"AWS Global Accelerator 与 Amazon CloudFront 有何不同？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 和 Amazon CloudFront 是相互独立的服务，都使用 AWS 全球网络及其遍布世界各地的边缘站点。CloudFront 能提高可缓存内容（如图像和视频）和动态内容（如 API 加速和动态站点交付）的性能。Global Accelerator 可通过在一个或多个 AWS 区域中运行的应用程序的边缘为数据包提供代理，提高 TCP 或 UDP 上的各种应用程序的性能。Global Accelerator 非常适合非 HTTP 使用案例，例如游戏 (UDP)、IoT (MQTT) 或 IP 语音，也非常适合特别要求静态 IP 地址或决定性的快速区域故障转移的 HTTP 使用案例。两种服务均与 AWS Shield 集成以提供 DDoS 保护。"
    },
    {
        "query":"可以将 AWS Global Accelerator 用于我的本地服务吗？",
        "intention":"知识问答",
        "reply":"您无法直接将本地资源配置为静态 IP 地址的终端节点，但可以在每个 AWS 区域中配置 Network Load Balancer (NLB) 来寻址您的本地终端节点。然后，您可以将这些 NLB 注册为您的 AWS Global Accelerator 配置中的终端节点。"
    },
    {
        "query":"我可以确切地将多个用户路由到加速器后面的特定终端节点 IP 和端口吗？",
        "intention":"知识问答",
        "reply":"可以。通过使用自定义路由加速器，您可以使用自己的应用程序逻辑将用户流量路由到单个或多个 AWS 区域中的特定 Amazon EC2 IP 和端口。比如多玩家游戏，您希望根据地理位置、玩家技能和游戏配置等因素将多个玩家分配到游戏服务器上的一个会话中。其他示例还包括 VoIP、EdTech 和社交媒体应用程序，这些应用程序将多个用户分配到特定的媒体服务器，以启动语音、视频和消息传递会话。"
    },
    {
        "query":"我是否可通过 Amazon S3 将 AWS Global Accelerator 用于对象存储？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon S3 多区域访问点](https://aws.amazon.com/cn/s3/features/multi-region-access-points/)以获得将 Global Accelerator 用于对象存储的优势。S3 多区域访问点以透明方式使用 Global Accelerator 以提供单个全局终端节点来访问跨越不同 AWS 区域中多个 S3 存储桶的数据集。这可让您使用在单个区域中采用的相同简单架构来构建多区域应用程序，然后在全球任意区域运行这些应用程序。对 S3 多区域访问点的全球终端节点发出的应用程序请求会自动通过 AWS 全球网络路由到网络延迟最低的 S3 存储桶。这可让应用程序自动避开公共互联网上拥塞的网段，从而提高应用程序的性能和可靠性。"
    },
    {
        "query":"AWS Global Accelerator 可提供哪些优势？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 包括以下优势：\n即时区域故障转移：AWS Global Accelerator 会自动检查应用程序的运行状况，并仅将用户流量路由到运行状况良好的应用程序终端节点。如果运行状况发生变化或您进行配置更新，AWS Global Accelerator 会立即做出反应，将您的用户路由到下一个可用终端节点。\n高可用性：AWS Global Accelerator 采用故障隔离设计，可提高应用程序的可用性。您创建加速器时，将为您分配两个由独立网络区域提供服务的 IPv4 静态 IP 地址。类似于可用区，这些网络区域是隔离的单元，具有自己的物理基础设施和来自唯一 IP 子网的服务静态 IP 地址。如果由于 IP 地址封锁或无法访问的网络而导致一个静态 IP 地址变得不可用，AWS Global Accelerator 会重新路由到其他隔离网络区域内运行状况良好的静态 IP 地址，以此为客户端应用程序提供容错功能。\n缓存 IP 地址的客户端周围无变量：部分客户端设备和互联网解析程序会将 DNS 回答缓存较长时间。因此，在您进行配置更新时，或者发生应用程序故障或您的路由首选项发生变化时，您不知道需要花费多长时间才能让所有用户收到更新后的 IP 地址。使用 AWS Global Accelerator，您无需依赖客户端设备的 IP 地址缓存设置。更改传播只需要几秒钟，这缩短了应用程序停机时间。\n经过提升的性能：AWS Global Accelerator 通过任播静态 IP 地址从最靠近终端客户端的边缘站点中获取流量。这些流量流经无封锁且冗余的 AWS 全球网络，从而能优化通向您在 AWS 区域中运行的应用程序的路径。AWS Global Accelerator 根据终端客户端的地理位置选择最佳 AWS 区域，从而能减少首字节延迟并将性能提升高达 60%。\n易管理性：AWS Global Accelerator 提供的静态 IP 地址是固定的，为您的应用程序提供单一入口点。这让您可以轻松在可用区或 AWS 区域之间移动终端节点，而不必更新 DNS 配置或面向客户端的应用程序。使用案例包括 A/B 测试、应用程序更新和故障转移模拟。企业代理还可以将您应用程序的静态 IP 地址列入他们防火墙中的白名单。\n精细控制：AWS Global Accelerator 允许您为区域终端节点组设置流量调配，让您在执行性能测试或应用程序更新时为特定 AWS 区域调高或调低流量。此外，如果您使用有状态应用程序，您可以选择将来自用户的所有请求定向到同一终端节点，而不考虑源端口和协议，从而保持客户端关联。这些功能可以让您实现精细控制。"
    },
    {
        "query":"我只在单一 AWS 区域内运营。我能从 AWS Global Accelerator 获得任何优势吗？",
        "intention":"知识问答",
        "reply":"能。虽然您可能不想使用 AWS Global Accelerator 的智能流量路由功能，但使用静态 IP 地址也有众多好处。首先，通过使用这些地址，您可以将用户流量载入尽可能靠近该用户的 AWS 全球网络，从而提高面向用户的服务质量 (QoS)。通常来讲，流量必须在公共互联网中进行多次跳跃，经过可能堵塞且无冗余的网络路径，然后才能抵达目标 AWS 区域。借助 AWS Global Accelerator，您可以利用 AWS 全球冗余网络帮助提高应用程序可用性和性能。其次，您可以自由地在 AWS 区域之间轻松移动应用程序，而无需更改公共接口。这意味着您可以安心计划未来，因为您知道如果需求发生变化，您可以轻松迁移或添加其他 AWS 区域，而无需担心用户将如何连接到您的应用程序。"
    },
    {
        "query":"AWS Global Accelerator 如何让我轻松迁移到多区域设置？",
        "intention":"知识问答",
        "reply":"您希望在多个 AWS 区域中运行应用程序，可能是为了实现区域冗余，并通过在更靠近用户的位置运行应用程序来提高性能。通过在应用程序与客户端之间提供网络层，AWS Global Accelerator 可执行运行状况检查，然后自动绕过故障终端节点路由流量，而无需中断客户端。这样可以平稳关闭和启动新终端节点，在确保将互联网流量路由到最近的可用终端节点的同时，为用户提供更高的可用性和性能。"
    },
    {
        "query":"AWS Global Accelerator 如何帮助支持多区域故障转移？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 为您提供一组静态 IP 地址，这些地址可以映射到 AWS 区域中的多个应用程序终端节点，从而能提高冗余。如果特定 AWS 区域中的应用程序发生故障，AWS Global Accelerator 会自动检测运行状况不佳的终端节点并将流量重定向到下一个最佳 AWS 区域，从而确保高可用性和灾难恢复。"
    },
    {
        "query":"我的应用程序能够以多快的速度在 AWS 区域之间进行故障转移？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 可以检测到运行状况不佳的终端节点，并在不到 1 分钟的时间内将其暂停。"
    },
    {
        "query":"AWS Global Accelerator 支持哪些合规性认证？",
        "intention":"知识问答",
        "reply":"借助 AWS Global Accelerator 认证，您可以更轻松地验证我们的高安全标准并履行您自己的法规和合规性义务。AWS Global Accelerator 已经过评估，除了符合 [HIPAA](https://aws.amazon.com/compliance/hipaa-compliance/) 以外，它还符合 [PCI DSS](https://aws.amazon.com/compliance/pci-dss-level-1-faqs/)、ISO [9001](https://aws.amazon.com/compliance/iso-9001-faqs/)、[27001](https://aws.amazon.com/compliance/iso-27001-faqs/)、[27017](https://aws.amazon.com/compliance/iso-27017-faqs/)、[27018](https://aws.amazon.com/compliance/iso-27018-faqs/)、[27018](https://aws.amazon.com/compliance/iso-27018-faqs/) 和 [SOC](https://aws.amazon.com/compliance/soc-faqs/)（系统和组织控制）。"
    },
    {
        "query":"我可以对 Global Accelerator 使用自己的 IP 地址吗？",
        "intention":"知识问答",
        "reply":"您可以对 AWS Global Accelerator 使用自己的 IP 地址 (BYOIP)，这使您能够将自己的 IP 地址用作应用程序终端节点的固定入口点。这允许您将已硬编码 IP 地址依赖项的本地应用程序迁移到 AWS，而无需进行任何面向客户端的更改。例如，在要求允许列出 IP 地址范围的监管环境中，这是很有帮助的。使用您自己的 IP 地址的加速器与使用 Amazon 提供的 IP 地址的加速器的工作方式完全相同。有关更多详细信息，请阅读[文档](https://docs.aws.amazon.com/global-accelerator/latest/dg/using-byoip.html)。"
    },
    {
        "query":"我是否既可以通过 Global Accelerator，也可以通过 Amazon EC2 从 AWS 区域公布 IPv4 池？",
        "intention":"知识问答",
        "reply":"不可以，您只可以从其中一项服务公布 IPv4 池。"
    },
    {
        "query":"Global Accelerator 的静态 IP 地址与 EC2 Elastic IP 地址有何不同？",
        "intention":"知识问答",
        "reply":"尽管 Global Accelerator 的 IP 地址和 EC2 Elastic IP 地址都是静态地址，但是两者间还是存在一些区别。第一点区别，Global Accelerator 的 IP 地址可与任意数量的 AWS 区域中的一个或多个终端节点（Application Load Balancer、Network Load Balancer 或 EC2 实例）关联。这支持您轻松地将应用程序扩展到多个可用区或 AWS 区域。另一方面，弹性 IP 绑定到单个 AWS 区域中的单个 AWS 资源，如负载均衡器或 EC2 实例。第二点区别，Global Accelerator 的 IP 地址仅支持客户端生成的连接，而弹性 IP 同时支持客户端生成的连接和服务器生成的连接。第三点区别，Global Accelerator 的 IP 地址是从边缘站点的 AWS 的广泛网络公布的。流量进入尽可能靠近用户的高性能且可用的 AWS 网络。弹性 IP一次只能从单个 AWS 区域发布。"
    },
    {
        "query":"我可以通过 BYOIP 引入多少个 IP 范围？",
        "intention":"知识问答",
        "reply":"您最多可以将两个 IP 范围引入您的账户。"
    },
    {
        "query":"我可以通过 BYOIP 引入的最具体的前缀是什么？",
        "intention":"知识问答",
        "reply":"通过 BYOIP，您能引入的最具体的地址范围为 /24。IP 地址的前 24 位指定了网络编号。例如，198.51.100 是 IP 地址 198.51.100.0 的网络编号。"
    },
    {
        "query":"我可以将哪些 RIR 前缀用于 BYOIP？",
        "intention":"知识问答",
        "reply":"您可以使用 ARIN、RIPE 和 APNIC 注册的前缀。"
    },
    {
        "query":"我是否可将 Amazon 提供的弹性 IP 地址范围转换为 Global Accelerator IP 地址，然后在全球范围内公布？",
        "intention":"知识问答",
        "reply":"不可以，您只能将自己拥有的 IP 地址范围引入 AWS Global Accelerator。这些范围将是您从互联网注册机构处购买的范围。"
    },
    {
        "query":"什么是自定义路由加速器？",
        "intention":"知识问答",
        "reply":"自定义路由加速器是 Global Accelerator 中的一种新型加速器。它可让您使用自己的应用程序逻辑将一个或多个用户确切地路由到单个或多个 AWS 区域中的特定 Amazon EC2 实例目标。这对于要控制将用户流量发送到 EC2 实例上的哪个会话的用例很有用。比如多玩家游戏应用程序，您希望根据地理位置、玩家技能和游戏配置等因素将多个玩家分配到游戏服务器上的一个会话中。其他示例还包括 VoIP、EdTech 和社交媒体应用程序，这些应用程序将多个用户分配到特定的媒体服务器，以启动语音、视频和消息传递会话。您可以使用自定义路由加速器，将多个用户定向到加速器上的唯一端口，并且将他们的流量路由到正在运行您的应用程序会话的特定目标 IP 地址和端口。"
    },
    {
        "query":"自定义路由加速器与标准加速器有何不同？",
        "intention":"知识问答",
        "reply":"标准加速器会自动将流量路由到距离您用户最近的、运行状况良好的终端节点。由于标准加速器旨在实现流量的负载均衡，因此不能确切地将多个用户路由到加速器后面的特定 EC2 目标。自定义路由加速器可让您做到这一点。另一个区别是标准路由加速器支持 Network Load Balancer、Application Load Balancer，EC2 实例和弹性 IP 作为终端节点。自定义路由加速器仅支持 VPC 子网终端节点，每个终端节点都包含一个或多个运行您的应用程序的 EC2 实例。"
    },
    {
        "query":"自定义路由的工作原理是什么？",
        "intention":"知识问答",
        "reply":"借助自定义路由加速器，您可以确定地将多个用户路由到运行应用程序会话的特定目标 IP 地址和端口。您只需将用户定向到 Global Accelerator 上的特定端口即可。用户可以连接到分配给您的加速器的两个静态任播 IP 地址之一。当用户使用加速器 IP 地址和端口连接到您的终端节点时，您的流量将在最近的边缘站点进入 AWS 全局网络。您的自定义路由加速器已将此加速器端口映射到 VPC 子网中的特定 EC2 实例和端口，并在其中路由用户流量。从加速器端口到每个 VPC 子网内的 EC2 实例的映射是预先配置的，并且是静态的。这意味着您的应用程序可以使用 API 查询映射，进行存储，然后使用它来控制 Global Accelerator 如何路由客户端流量。如果在创建加速器后添加或删除终端节点，则现有终端节点的映射不会更改。"
    },
    {
        "query":"什么是 VPC 子网终端节点？",
        "intention":"知识问答",
        "reply":"VPC 子网终端节点是此功能引入的新型终端节点。每个 VPC 子网终端节点可以在单个或多个区域中，包含托管应用程序的 EC2 实例的 IP 地址。使用自定义路由加速器，您可以将加速器置于在单个或多个 VPC 中运行的多达数千个 EC2 实例的前面。自定义路由加速器支持最大大小为 /17 的 VPC 子网终端节点，并且仅将流量路由到每个子网内的 EC2 实例。"
    },
    {
        "query":"如何监控客户端是否可以通过 Global Accelerator 到达我的 VPC 子网终端节点？",
        "intention":"知识问答",
        "reply":"自定义路由加速器不会为您的 VPC 子网终端节点或其中的 EC2 实例提供外部运行状况检查。在这种情况下，每个加速器端口都会映射到特定的 EC2 实例私有 IP 地址和端口。因此，您的应用程序可以监控 EC2 实例的运行状况，然后如果一个实例运行不正常，则可以将用户流量定向到其他加速器 IP 地址和端口组合，从而控制将流量故障转移到另一个特定的正常实例。"
    },
    {
        "query":"如果我需要路由到超过 64,000 个目的地怎么办？",
        "intention":"知识问答",
        "reply":"如果您预计需要更多的目的地，则可以简单地设置更多的自定义路由加速器，并在其他子网中设置额外的终端节点。然后更新您的自定义应用程序逻辑，以使用新加速器的 IP 地址和新端口映射到达每个实例和端口。"
    },
    {
        "query":"AWS Global Accelerator 是否支持 IPv4 和 IPv6？",
        "intention":"知识问答",
        "reply":"Global Accelerator 支持流向所有端点的 IPv4 流量，以及流向应用程序负载均衡器端点的 IPv6 流量。"
    },
    {
        "query":"AWS Global Accelerator 支持哪些协议？",
        "intention":"知识问答",
        "reply":"AWS Global Accelerator 支持 TCP 和 UDP 协议。"
    },
    {
        "query":"AWS Global Accelerator 与基于 DNS 的流量管理解决方案有何不同？",
        "intention":"知识问答",
        "reply":"首先，一些客户端设备和互联网解析程序会将 DNS 回答缓存较长时间。因此，在您进行配置更新时，或者发生应用程序故障或您的路由首选项发生变化时，您不知道需要花费多长时间才能让所有用户收到更新后的 IP 地址。使用 AWS Global Accelerator，您无需依赖客户端设备的 IP 地址缓存设置。更改传播只需要几秒钟，这缩短了应用程序停机时间。其次，使用 Global Accelerator，您可以获得静态 IP 地址，为您的应用程序提供固定的入口点。这让您可以轻松在可用区或 AWS 区域之间移动端点，而不必更新 DNS 配置或面向客户端的应用程序。"
    },
    {
        "query":"What is Amazon Corretto?",
        "intention":"知识问答",
        "reply":"A: Corretto is a build of the Open Java Development Kit (OpenJDK) with long-term support from Amazon. Corretto is certified using the Java Technical Compatibility Kit (TCK) to ensure it meets the Java SE standard and is available on Linux, Windows, and macOS."
    },
    {
        "query":"Why should I use Corretto?",
        "intention":"知识问答",
        "reply":"A: Corretto is a reliable build of OpenJDK with the assurance of long-term support provided at no cost to you. Amazon runs Corretto internally on thousands of production services. Every modification we make to Corretto fixes or mitigates a problem we found running OpenJDK. Amazon also plans to apply urgent fixes (including security) when they are available and ready to use, outside of the regular quarterly cycle."
    },
    {
        "query":"How is Corretto different from OpenJDK?",
        "intention":"知识问答",
        "reply":"A: Corretto is a distribution of Open JDK with patches included by Amazon that are not yet integrated in the corresponding OpenJDK update projects. We focus on patches that improve performance or stability in OpenJDK, chosen based on Amazon's observations running large services."
    },
    {
        "query":"What kinds of patches does Amazon intend to include in Corretto?",
        "intention":"知识问答",
        "reply":"A: Patches will include security fixes, performance enhancements (e.g., speeding up frequently-used functions), garbage collection scheduling, and preventing out-of-memory situations, as well as improved monitoring, reporting, and thread management."
    },
    {
        "query":"Is there any cost associated with using Corretto?",
        "intention":"知识问答",
        "reply":"A: Corretto is distributed by Amazon under an Open Source license at no cost to you. It is licensed under the terms of the GNU Public License version 2 with the Class Path Exception ([GPLv2 with CPE](https://openjdk.java.net/legal/gplv2+ce.html)). Amazon does not charge for its use or distribution."
    },
    {
        "query":"What does long-term support (LTS) mean for Corretto?",
        "intention":"知识问答",
        "reply":"A: Amazon Corretto is a no-cost, multiplatform, production-ready distribution of the Open Java Development Kit (OpenJDK) that comes with long-term support (LTS). LTS includes Amazon’s commitment to provide performance enhancements and security updates at no cost until at least the specified date for the relevant release version (e.g. May 2026 for Corretto 8). Updates are planned to be released quarterly. Amazon also plans to apply urgent fixes (including security) outside of the regular quarterly cycle when they are available and ready to use."
    },
    {
        "query":"What is included in Corretto's long-term support?",
        "intention":"知识问答",
        "reply":"A: Long-term support (LTS) for Corretto includes performance enhancements and security updates for Corretto 8 until at least May 2026 and for Corretto 11 until at least September 2027 at no cost. Updates are planned to be released quarterly.\nLTS for Corretto is unrelated to [AWS Support Plans](https://aws.amazon.com/premiumsupport/), which provide expert guidance and assistance for achieving your objectives on AWS. If you already have an AWS Support Plan, Corretto is covered on the same basis as all other supported AWS Services and software. For those who do not have a plan, it may or may not make sense for you to purchase a plan if your only intention is to receive assistance with Corretto. Please [visit the website](https://aws.amazon.com/premiumsupport/) to determine if it is right for you. There are currently no plans to launch Corretto-specific assistance plans. As always, our roadmaps are a reflection of our customer feedback and we welcome your feature requests at the [Corretto GitHub repository](https://github.com/corretto)."
    },
    {
        "query":"What is Corretto's support calendar?",
        "intention":"知识问答",
        "reply":"|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n|  |  |  |  |  |\n| Coretto Release | Release Type | GA Date | Last Planned Update | End of Life |\n| 20 | FR | March 21st 2023 | July 2023 | October 2023 |\n| 17 | LTS | September 16th 2021 | July 2029 | October 2028 |\n| 11 | LTS | March 15th 2019 | July 2027 | October 2027 |\n| 8 | LTD | January 31st 2019 | April 2026 | July 2026 |"
    },
    {
        "query":"What should I do if I need help with Corretto?",
        "intention":"知识问答",
        "reply":"A: For general questions about installing or running Corretto, please see our [documentation](https://docs.aws.amazon.com/corretto/). If you have an issue related to OpenJDK, please open an issue with the upstream OpenJDK project. If you have a specific issue with Corretto or feature request that is not applicable to OpenJDK, please open an issue or a feature request in the [Corretto GitHub repository](https://github.com/corretto). If you already have an AWS Support Plan you can reach out for assistance with Corretto through your plan."
    },
    {
        "query":"Can I use Corretto as a drop-in replacement for other JDKs?",
        "intention":"知识问答",
        "reply":"A: Corretto is designed as a drop-in replacement for all Java SE distributions unless you are using features not available in OpenJDK. Once Corretto binaries are installed on a host and correctly invoked to run your Java applications (e.g., using the alternatives command on Linux), existing command-line options, tuning parameters, monitoring, and anything else in place will continue to work as before."
    },
    {
        "query":"What operating systems does Corretto 8 support?",
        "intention":"知识问答",
        "reply":"A: Corretto 8 installation packages are distributed by Amazon for Linux (glibc), Linux (musl-libc), Windows, and macOS.\nWindows builds are supported on versions 10 or later, Server 2012, Server 2016, and Server 2019.\nmacOS builds are supported on all versions of macOS still receiving security patches from Apple. Currently supported versions are 11 (Big Sur) and later on x64 (Intel), and 11.0 (Big Sur) and later on aarch64 (M1) architecture.\nLinux (glibc) builds are supported on Red Hat Enterprise Linux 6+, CentOS 6+, Ubuntu Linux 14+, Debian Linux 8+, Amazon Linux AMI, and SuSE 12+.\nLinux (musl-libc) builds are supported on Alpine Linux 3.15+."
    },
    {
        "query":"What operating systems does Corretto 11 support?",
        "intention":"知识问答",
        "reply":"A: Corretto 11 installation packages are distributed by Amazon for Linux (glibc), Linux (musl-libc), Windows, and macOS.\nWindows builds are supported on versions 10 or later, Server 2012, Server 2016, and Server 2019.\nmacOS builds are supported on all versions of macOS still receiving security patches from Apple. Currently supported versions are 11 (Big Sur) and later on x64 (Intel), and 11.0 (Big Sur) and later on aarch64 (M1) architecture.\nLinux (glibc) builds are supported on Red Hat Enterprise Linux 6+, CentOS 6+, Ubuntu Linux 14+, Debian Linux 8+, Amazon Linux AMI, and SuSE 12+.\nLinux (musl-libc) builds are supported on Alpine Linux 3.15+."
    },
    {
        "query":"What operating systems does Corretto 17 support?",
        "intention":"知识问答",
        "reply":"A: Corretto 17 installation packages are distributed by Amazon for Linux (glibc), Linux (musl-libc), Windows, and macOS.\nWindows builds are supported on versions 7, 8, 10, Server 2008 R2, Server 2012, Server 2016, and Server 2019.\nmacOS builds are supported on all versions of macOS still receiving security patches from Apple. Currently supported versions are 11 (Big Sur) and later on x64 (Intel), and 11.0 (Big Sur) and later on aarch64 (M1) architecture.\nLinux (glibc) builds are supported on Red Hat Enterprise Linux 6+, CentOS 6+, Ubuntu Linux 14+, Debian Linux 8+, Amazon Linux AMI, and SuSE 12+.\nLinux (musl-libc) builds are supported on Alpine Linux 3.15+."
    },
    {
        "query":"What operating systems does Corretto 20 support?",
        "intention":"知识问答",
        "reply":"A: Corretto 20 installation packages are distributed by Amazon for Linux (glibc), Linux (musl-libc), Windows, and macOS.\nWindows builds are supported on versions 10 or later, Server 2012, Server 2016, and Server 2019.\nmacOS builds are supported on all versions of macOS still receiving security patches from Apple. Currently supported versions are 11 (Big Sur) and later on x64 (Intel), and 11.0 (Big Sur) and later on aarch64 (M1) architecture.\nLinux (glibc) builds are supported on Red Hat Enterprise Linux 6+, CentOS 6+, Ubuntu Linux 14+, Debian Linux 8+, Amazon Linux AMI, and SuSE 12+.\nLinux (musl-libc) builds are supported on Alpine Linux 3.15+."
    },
    {
        "query":"Why does security scanner show that a docker image has a CVE?",
        "intention":"知识问答",
        "reply":"A: If a security scanner reports that a Corretto-Docker image includes a CVE, the first recommended action is to seek an updated version of this image. Updated Corretto-Docker images are available at this [site](https://hub.docker.com/_/amazoncorretto).\nIf no updated image is available, run the appropriate command to update packages for the platform, e.g. run \"yum update -y --security\" for AmazonLinux or \"apk -U upgrade\" for Alpine Linux in your Dockerfiles or systems to resolve the issue immediately.\nIf no updated package is available, please treat this as a potential security issue and follow the [[AWS vulnerability reporting instructions]](https://aws.amazon.com/security/vulnerability-reporting/) or email AWS security directly at aws-security@amazon.com.\nIt is the responsibility of the base docker image supplier to provide timely security updates to images and packages. AWS only supplies base docker images for Amazon Linux, which are available from the [Docker Hub Amazon Linux 2](https://hub.docker.com/_/amazonlinux) page and the [Amazon Linux 2 ECR Public Gallery](https://gallery.ecr.aws/amazonlinux/amazonlinux). Alpine-based docker images are available from the [Docker Hub Alpine Linux](https://hub.docker.com/_/alpine) page.\nDocker Hub automatically rebuilds Docker images when a new base image is made available, but the Corretto team does not make changes to our Dockerfiles to pull in one-off package updates. If a new base image has not yet been made generally available by a base docker image supplier, please contact that supplier to request that the fix be addressed in a new base docker image distribution.\nNote that there are multiple reasons why a CVE may appear to be present in a docker image, as explained [here](https://github.com/docker-library/faq/tree/73f10b0daf2fb8e7b38efaccc0e90b3510919d51#why-does-my-security-scanner-show-that-an-image-has-cves).\nQ: Is JavaFX included with Corretto? If so, which versions of Corretto have it bundled?\nA: Before OpenJDK 11, JavaFX was included in OpenJDK. However, in 2018, [Oracle decoupled JavaFX from OpenJDK](https://blogs.oracle.com/java-platform-group/the-future-of-javafx-and-other-java-client-roadmap-updates), removing it from OpenJDK distributions. Corretto 8 does include JavaFX for the following platforms:\nAL2 x64  \n Generic Linux x64  \n Windows x86 JDK  \n Windoes x64 JDK  \n Windows x86 JRE  \n Window x64 JRE\nWe do not include it on other platforms, regardless of version. For example, JavaFX is not supported in Corretto 8 for Mac M1.\nWe recommend that you upgrade to Corretto 17+, preferably Corretto 17, since this release will have more up-to-date code and generally perform better than its predecessors. In some instances you may wish to be on the latest JDK, which could be a short term support release with near [EOL date](https://aws.amazon.com/cn/corretto/faqs#support_calendar) (https://aws.amazon.com/corretto/faqs/#support\\_calendar). You can find and download the JFX releases from thee [JavaFX](https://openjfx.io/) website."
    },
    {
        "query":"What are Corretto's license terms?",
        "intention":"知识问答",
        "reply":"A: Corretto is released under the same open source license as OpenJDK, which is licensed under the GNU Public License version 2 with the Class Path Exception ([GPLv2 with CPE](https://openjdk.java.net/legal/gplv2+ce.html)). You can use Corretto as you would use OpenJDK."
    },
    {
        "query":"How does Amazon contribute to OpenJDK?",
        "intention":"知识问答",
        "reply":"A: Amazon started contributing to OpenJDK in 2017 and we plan to increase contributions in both number and complexity."
    },
    {
        "query":"How can I contribute to Corretto?",
        "intention":"知识问答",
        "reply":"A: Amazon encourages contributions to the OpenJDK project as the way to get code into Corretto. This way the whole OpenJDK community benefits from your changes. If your contribution is specific to Corretto, such as to the build logic, the code is available on [GitHub](https://github.com/corretto), where we will evaluate issues and pull requests.\n|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n| Corretto Release | Release Type | GA Date | Last Planned Update | End of Life |\n| 15 | FR | September 24th 2020 | January 19th 2021 | April 20th 2021 |\n| 16 | FR | March 16th 2021  | July 20th 2021 | October 19th 2021  |\n| 18 | FR | March 22nd 2022 | July 19th 2022 | October 18th 2022 |\n| 19 | FR | September 20th 2022 | January 17th 2023 | April 19th 2023 |\nFR: Feature Release"
    },
    {
        "query":"如何指定 AWS 资源供 DevOps Guru 分析？ 答：您可以选择您的分析覆盖界限作为您的整个 AWS 账户，或者可以指定您希望 DevOps Guru 分析的特定 AWS CloudFormation 堆栈，或者使用 AWS 标签创建您希望 DevOps Guru 分析的资源组。DevOps Guru 将根据您的选择，在选定的覆盖界限内为所有支持的 AWS 资源分析操作数据。",
        "intention":"知识问答",
        "reply":"当您添加新资源到您的覆盖界限选择时，DevOps Guru 自动开始分析附加资源。同样地，当您将任何资源从账户或 CloudFormation 堆栈中删除时，DevOps Guru 将停止对它们分析和计费。"
    },
    {
        "query":"什么是 Amazon Elastic Compute Cloud（Amazon EC2）？",
        "intention":"知识问答",
        "reply":"Amazon EC2 是一种 Web 服务，可以在[云](https://aws.amazon.com/cn/what-is-cloud-computing/)中提供可调整大小的计算容量。该服务旨在让开发人员能更轻松地进行 Web 级的计算。"
    },
    {
        "query":"Amazon EC2 可以用来做什么？",
        "intention":"知识问答",
        "reply":"正如 Amazon Simple Storage Service（Amazon S3）实现云中的存储一样，Amazon EC2 可以实现云中的“计算”。  Amazon EC2 云服务器的 Web 云服务接口非常简单，您可以最小的阻力轻松获取容量，随之配置容量。使用该服务，您将能完全控制您的计算资源，并可在成熟的 Amazon 计算环境中运行。Amazon EC2 将获取并启动新服务器实例所需要的时间缩短至几分钟，这样一来，在您的计算要求发生变化时，您便可以快速扩展或缩减计算容量。Amazon EC2 按您实际使用的容量收费，改变了计算的成本结算方式。"
    },
    {
        "query":"如何开始使用 Amazon EC2？",
        "intention":"知识问答",
        "reply":"如需注册 Amazon EC2，请选择 Amazon EC2 详细信息页面上的“注册此 Web 服务”按钮。您必须拥有 AWS 账户才能访问此服务；如果您还没有账户，系统将在您开始 Amazon EC2 注册过程时提示您创建账户。注册后，请参阅 [Amazon EC2 文档](https://docs.aws.amazon.com/ec2/index.html)，其中包含入门指南。"
    },
    {
        "query":"注册 Amazon EC2 时为什么需要验证我的电话号码？",
        "intention":"知识问答",
        "reply":"注册 Amazon EC2 时，您需要在 AWS 上登记您的有效电话号码和电子邮件地址，以便我们在需要联系您时使用。验证您的电话号码只需要几分钟时间。注册过程中您会接到一个电话，然后需要您使用电话键盘输入 PIN 码。"
    },
    {
        "query":"开发人员现在可以实现哪些以前无法做到的事情？",
        "intention":"知识问答",
        "reply":"以前，小规模开发人员没有资本购置大量的计算资源，确保拥有所需的容量来应对意外的负载峰值。Amazon EC2 有助于开发人员利用 Amazon 自身的大规模优势，不需要预先投入，也无需牺牲性能。现在，开发人员知道无论其业务变得多么成功，都可以通过经济而简单的方式来确保具有满足业务需求的计算容量，因此他们可以尽情创新。\n此服务的“弹性”本质可以让开发人员即时进行扩展，满足其流量或需求峰值。当计算需求意外改变时 (增加或缩小)，Amazon EC2 可以即时作出响应，这意味着开发人员可以在任意给定时间点上对使用多少资源进行控制。相比之下，传统的托管服务通常在固定的时间段内提供固定数量的资源，这就意味着当用量快速变化、不可预测或已知会在不同的时间间隔遭遇大峰值时，用户轻松响应的能力会受到限制。"
    },
    {
        "query":"如何在 Amazon EC2 环境中运行系统？",
        "intention":"知识问答",
        "reply":"在您设置账户并选择或创建 AMI 之后，便可启动实例。您可以通过调用 RunInstances API，在任意数量的按需实例上启动 AMI。您只需要说明您想要启动多少个实例。 如果想要运行的实例数量超出您的按需型实例配额，请填写 [Amazon EC2 实例申请表](https://aws.amazon.com/cn/contact-us/ec2-request/)。\n如果 Amazon EC2 能够满足您的请求，RunInstances 将返回成功值，我们将开始启动您的实例。您可以通过调用 DescribeInstances API，查看实例的状态，也可以通过调用 TerminateInstances API，以编程方式终止任意数量的实例。\n如果有一个运行中的实例在使用 Amazon EBS 引导分区，您也可以调用 StopInstances API 释放计算资源，但将数据保留在引导分区中。在准备重新启动与 Amazon EBS 引导分区相关的实例时，您可以使用 StartInstances API。\n此外，如果您可以灵活掌握应用程序的运行时间，您也可以选择使用 Spot 实例，从而降低计算成本。有关 [Spot 实例](https://aws.amazon.com/cn/ec2/spot/)工作原理的详细说明，请参阅更多关于 Spot 实例的信息。\n您也可以根据需要，从 [AWS 管理控制台](https://aws.amazon.com/cn/console/)执行所有这些操作，或者使用我们的命令行工具通过命令行来执行，这些工具已实现了此 Web 服务 API。"
    },
    {
        "query":"对于根设备，使用本地实例存储与使用 Amazon Elastic Block Store (Amazon EBS) 有什么区别？",
        "intention":"知识问答",
        "reply":"启动 Amazon EC2 实例时，您可以将根设备数据存储在 Amazon EBS 或者本地实例存储上。使用 Amazon EBS 时，根设备中的数据将独立于实例的生命周期保留下来。这可让您停止实例并在以后重新启动，这类似于您将笔记本电脑关机并在需要时重新启动。\n另一方面，本地实例存储仅在实例的生命周期内保留。这是启动实例的一种经济方式，因为数据没有存储到根设备中。例如，某些客户使用这一选项来运行其中每个实例都是克隆的大型网站，以便应对 Web 流量。"
    },
    {
        "query":"系统可以多快开始运行？",
        "intention":"知识问答",
        "reply":"从发出 RunInstances 调用到所有请求的实例按顺序启动，用时通常不到 10 分钟。这一时间由多个因素决定，包括：AMI 的大小、启动的实例数量，以及多久前您启动过该 AMI。首次启动的映像可能需要稍长时间才能启动。"
    },
    {
        "query":"如何使用 Amazon EC2 加载和存储我的系统？",
        "intention":"知识问答",
        "reply":"借助 Amazon EC2，您可以设置和配置关于实例的一切，从操作系统到应用程序，不一而足。Amazon Machine Image (AMI) 是一种打包环境，包含了设置并启动实例所必需的所有数据。您的 AMI 是您的部署单元。您可能只有一个 AMI，或您的系统中只有几个构建基块 AMI (例如 webserver、appserver 和数据库)。Amazon EC2 提供了多种工具，让您轻松创建 AMI。在创建自定义 AMI 后，您需要对其进行捆绑。如果要将映像与 Amazon EBS 提供支持的根设备捆绑，您只需使用 AWS 管理控制台中的捆绑命令。如果要将映像与实例存储中的引导分区捆绑，则需要使用 AMI 工具将其上传到 Amazon S3。Amazon EC2 使用 Amazon EBS 和 Amazon S3 为您的 AMI 提供可靠且可扩展的存储，以便我们可在您要求时启动它们。\n或者，如果您需要的话，也不必从头设置您自己的 AMI。您可以从面向全球使用的大量 AMI 中选择，这些 AMI 可提供有用的实例。例如，如果您只想要一个简单的 Linux 服务器，则可以选择一个标准的 Linux 发行版 AMI。"
    },
    {
        "query":"如何访问我的系统？",
        "intention":"知识问答",
        "reply":"发起应用程序堆栈执行操作的 RunInstances 调用会返回一组 DNS 名称，每个名称对应一个要启动的系统。您可以使用此名称来访问系统，就如在自己的数据中心一样。当您在某台机器上执行操作系统堆栈时，这台机器完全由您掌控。"
    },
    {
        "query":"Amazon EC2 是否与 Amazon S3 结合使用？",
        "intention":"知识问答",
        "reply":"是的，对于其根设备采用本地实例存储的实例，我们将 Amazon EC2 与 Amazon S3 结合使用。借助 Amazon S3，开发人员可以使用 Amazon 用于运行其全球网站网络的数据存储基础设施，它不仅具备高度的可扩展性和可靠性，而且速度快速、经济实惠。要在 Amazon EC2 环境中执行系统，开发人员可以使用提供的工具将 AMI 加载到 Amazon S3 中，也可以将其在 Amazon S3 和 Amazon EC2 之间移动。有关 AMI 的更多信息，请参阅[如何使用 Amazon EC2 加载和存储我的系统？](https://aws.amazon.com/cn/ec2/faqs#load-and-store-systems)。\n我们预计开发人员会认为 Amazon EC2 与 Amazon S3 的结合非常有用。Amazon EC2 在云中提供经济、可扩展的计算，而 Amazon S3 则可让用户可靠地存储其数据。"
    },
    {
        "query":"我可以在 Amazon EC2 中运行多少个实例？",
        "intention":"知识问答",
        "reply":"您只能根据您的基于 vCPU 的[按需型实例限制](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html#ec2-on-demand-instances-limits)运行按需型实例、购买 20 个预留实例，并根据每个区域的[动态竞价型实例限制](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html)请求竞价型实例。对于新创建的 AWS 账户，一开始的限制数量可能比此处所述的更低。\n如果需要更多实例，请填写 [Amazon EC2 实例限制提高申请表](https://aws.amazon.com/cn/contact-us/ec2-request/)和您的使用案例，我们将考虑提高您的限制。实例上限的提高与请求所针对的区域有关。"
    },
    {
        "query":"从 Amazon EC2 实例发送电子邮件是否有任何限制？",
        "intention":"知识问答",
        "reply":"是的。为了保持用于发送电子邮件的 Amazon EC2 地址的质量，我们对可以从 EC2 账户发送的电子邮件数量设置了默认限制。如果希望从 EC2 发送更多电子邮件，您可以通过[填写此表](https://portal.aws.amazon.com/gp/aws/html-forms-controller/contactus/ec2-email-limit-rdns-request)申请从您的账户中取消这些限制。"
    },
    {
        "query":"扩展和缩减容量需要多长时间？",
        "intention":"知识问答",
        "reply":"Amazon EC2 提供真正的弹性计算环境。借助 Amazon EC2，您可以在几分钟（而不是几小时或几天）内增加或减少容量。您可以同时管理一个、数百个，甚至数千个服务器实例。需要更多实例时，您只需要调用 RunInstances，Amazon EC2 通常将在几分钟内设置您的新实例。当然，因为这全是通过 Web 服务 API 控制，所以您的应用程序可根据其自身需要自动扩展和缩减。"
    },
    {
        "query":"支持哪些操作系统环境？",
        "intention":"知识问答",
        "reply":"Amazon EC2 目前支持各种操作系统，包括：Amazon Linux、Ubuntu、Windows Server、Red Hat Enterprise Linux、SUSE Linux Enterprise Server、openSUSE Leap、Fedora、Fedora CoreOS、Debian、CentOS、Gentoo Linux、Oracle Linux 和 FreeBSD。我们正在设法扩展到其他平台。"
    },
    {
        "query":"Amazon EC2 是否使用 ECC 内存？",
        "intention":"知识问答",
        "reply":"根据我们的经验，服务器基础设施需要使用 ECC 内存，而且为 Amazon EC2 提供支持的所有硬件也使用 ECC 内存。"
    },
    {
        "query":"此服务与普通托管服务有何不同？",
        "intention":"知识问答",
        "reply":"传统托管服务通常针对固定的时间段提供预先配置的资源，成本也是预先确定的。Amazon EC2 与其他产品截然不同，它给开发人员带来了灵活性、控制力和大幅成本节约，可以让他们将 Amazon EC2 视作其个人的数据中心，同时充分享受 Amazon.com 强大基础设施的优势。\n当计算需求意外改变时 (增加或缩小)，Amazon EC2 可以即时作出响应，这意味着开发人员可以在任意给定时间点上对使用多少资源进行控制。相比之下，传统的托管服务通常在固定的时间段内提供固定数量的资源，这就意味着当用量快速变化、不可预测或已知会在不同的时间间隔遭遇大峰值时，用户轻松响应的能力会受到限制。\n其次，许多托管服务无法让用户完全控制所提供的计算资源。使用 Amazon EC2 时，开发人员不仅可以选择随时启动或关闭实例，而且还能根据其需求对实例配置进行全面自定义，并随时进行更改。许多托管服务更适合于具有相似系统要求的用户组，因而只提供有限的更改能力。\n最后，使用 Amazon EC2 时，开发人员仅需支付其实际资源消耗的费用，而且费率极低。大多数托管服务都要求用户预先支付固定费用，而不管其计算能力的实际用量，这样一来，用户会冒险超额购买资源，以弥补在短时间内无法迅速增加资源的不足。"
    },
    {
        "query":"ID 格式会发生怎样的变化？",
        "intention":"知识问答",
        "reply":"Amazon EC2 的按需实例限制将从当前基于实例数量的限制转变为全新基于 vCPU 的限制，以简化 AWS 客户的限制管理体验。基于 vCPU 限制的使用量按 [Amazon EC2 实例类型](https://aws.amazon.com/cn/ec2/instance-types/)的 vCPU（虚拟中央处理单元）数量计算，以启动满足应用程序需求的任何实例类型组合。"
    },
    {
        "query":"什么是基于 vCPU 的限制？",
        "intention":"知识问答",
        "reply":"您只能在 AWS 账户中运行一个或多个按需实例，Amazon EC2 将根据分配给 AWS 账户中正在运行的按需实例的 vCPU（虚拟中央处理单元）总数来计算每种限制的使用量。下表显示了每种实例大小的 vCPU 数量。某些实例类型的 vCPU 映射可能有所不同；有关详细信息，请参阅 [Amazon EC2 实例类型](https://aws.amazon.com/cn/ec2/instance-types/)。\n|  |  |\n| --- | --- |\n| 实例大小 | vCPU |\n| nano | 1 |\n| 微型 | 1 |\n| small | 1 |\n| medium | 1 |\n| large | 2 |\n| xlarge | 4 |\n| 2xlarge | 8 |\n| 3xlarge | 12 |\n| 4xlarge | 16 |\n| 8xlarge | 32 |\n| 9xlarge | 36 |\n| 10xlarge | 40 |\n| 12xlarge | 48 |\n| 16xlarge | 64 |\n| 18xlarge | 72 |\n| 24xlarge | 96 |\n| 32xlarge | 128 |"
    },
    {
        "query":"我可以在 Amazon EC2 中运行多少按需型实例？",
        "intention":"知识问答",
        "reply":"基于 vCPU 的实例限制有五种；每种限制都定义了给定实例系列可以使用的容量。无论哪一代、大小或配置变量（例如磁盘、处理器类型）如何，给定系列实例的所有使用量都将计入该系列的 vCPU 限制总量，如下表所示。对于新创建的 AWS 账户，一开始的限制数量可能比此处所述的更低。\n|  |  |\n| --- | --- |\n| 按需实例限制名称 | 默认 vCPU 限制 |\n| 正在运行的按需标准（A、C、D、H、I、M、R、T、Z）实例 | 1152 个 vCPU |\n| 正在运行的按需 F 实例 | 128 个 vCPU |\n| 正在运行的按需 G 实例 | 128 个 vCPU |\n| 正在运行的按需 Inf 实例 | 128 个 vCPU |\n| 正在运行的按需 P 实例 | 128 个 vCPU |\n| 正在运行的按需 X 实例 | 128 个 vCPU |"
    },
    {
        "query":"这些基于 vCPU 的按需实例限制是区域性的吗？",
        "intention":"知识问答",
        "reply":"是的，AWS 账户的按需实例限制是按区域设置的。"
    },
    {
        "query":"这些限制会随着时间而改变吗？",
        "intention":"知识问答",
        "reply":"是的，限制会随着时间而改变。Amazon EC2 一直在监控您在每个区域内的使用量，您的限制将会根据您的 EC2 使用量自动提高。"
    },
    {
        "query":"如何才能请求提高限制？",
        "intention":"知识问答",
        "reply":"虽然 EC2 会根据您的使用量自动提高按需实例限制，但如果需要，您可以通过 [Amazon EC2 控制台](https://console.aws.amazon.com/ec2/)中的限制页面、[Service Quotas 控制台](https://console.aws.amazon.com/servicequotas)中的 Amazon EC2 服务页面或 Service Quotas API/CLI 请求提高限制。"
    },
    {
        "query":"如何计算新的 vCPU 限制？",
        "intention":"知识问答",
        "reply":"您可以查找每种 [Amazon EC2 实例类型](https://aws.amazon.com/cn/ec2/instance-types/)的 vCPU 映射，也可以使用[经过简化的 vCPU 计算器](https://console.aws.amazon.com/ec2/home?#LimitsCalculator)计算您的 AWS 账户的 vCPU 限制需求总量。"
    },
    {
        "query":"购买预留实例或请求 Spot 实例时，vCPU 限制是否适用？",
        "intention":"知识问答",
        "reply":"不适用，基于 vCPU 的限制只适用于正在运行的按需实例和 Spot 实例。"
    },
    {
        "query":"如何查看当前按需实例限制？",
        "intention":"知识问答",
        "reply":"您可以在 [Amazon EC2 控制台](https://console.aws.amazon.com/ec2/)中的 EC2 Service Limits 页面或从 [Service Quotas 控制台](https://console.aws.amazon.com/servicequotas)和 API 查找您的当前按需实例限制。"
    },
    {
        "query":"这会影响正在运行的实例吗？",
        "intention":"知识问答",
        "reply":"不会，选择使用基于 vCPU 的限制不会影响任何正在运行的实例。"
    },
    {
        "query":"我还能启动相同数量的实例吗？",
        "intention":"知识问答",
        "reply":"能，基于 vCPU 的实例限制可让您启动至少与基于数量的实例限制相同数量的实例。"
    },
    {
        "query":"我能否根据这些限制查看实例使用量？",
        "intention":"知识问答",
        "reply":"借助 Amazon CloudWatch 指标集成，您可以在 [Service Quotas 控制台](https://console.aws.amazon.com/servicequotas)中根据限制查看 EC2 的使用量。Service Quotas 还使客户能够使用 CloudWatch 的配置警报来提醒客户即将达到限制数量。此外，您还可以在 Trusted Advisor 和限制监控程序中继续跟踪和检查实例的使用量。"
    },
    {
        "query":"我还能使用 DescribeAccountAttributes API 吗？",
        "intention":"知识问答",
        "reply":"使用 vCPU 限制时，我们不再拥有控制使用量的实例限制总量。因此，[DescribeAccountAttributes](https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeAccountAttributes.html) API 将不再返回 max-instances 值。相反，您现在可以使用 Service Quotas API 来检索关于 EC2 限制的信息。您可以在 [AWS 文档](https://docs.aws.amazon.com/servicequotas/2019-06-24/apireference/Welcome.html)中查找关于 Service Quotas API 的更多信息。"
    },
    {
        "query":"vCPU 限制是否会影响我每月的账单？",
        "intention":"知识问答",
        "reply":"不会，EC2 的使用量还是按小时或秒计算，[具体取决于您正在运行的 AMI](https://aws.amazon.com/cn/ec2/pricing/) 以及您启动的实例类型和大小。"
    },
    {
        "query":"vCPU 限制是否在所有区域适用？",
        "intention":"知识问答",
        "reply":"基于 vCPU 的实例限制在所有商业 AWS 区域提供。"
    },
    {
        "query":"ID 格式会发生怎样的变化？",
        "intention":"知识问答",
        "reply":"自 2020 年 1 月 7 日起，Amazon EC2 开始推出一项变化来限制默认情况下通过端口 25 的电子邮件流量，从而防止客户和其他收件人收到垃圾邮件和电子邮件滥用。端口 25 通常用作发送电子邮件的默认 SMTP 端口。在过去请求并取消了端口 25 限制的 AWS 账户将不受此变化影响。"
    },
    {
        "query":"我有一个从 EC2 向端口 25 发送电子邮件的有效用例。我该如何取消这些端口 25 限制？",
        "intention":"知识问答",
        "reply":"如果您有从 EC2 向端口 25（SMTP）发送电子邮件的有效使用案例，请提交[取消电子邮件发送限制的请求](https://aws.amazon.com/cn/premiumsupport/knowledge-center/ec2-port-25-throttle/)以解除这些限制。或者，您也可以使用不同的端口发送电子邮件，或者利用现有的经过身份验证的电子邮件中转服务，例如 [Amazon Simple Email Service](https://aws.amazon.com/cn/ses/)（Amazon SES）。"
    },
    {
        "query":"Amazon EC2 服务等级协议有什么保证？",
        "intention":"知识问答",
        "reply":"我们的 SLA 保证在一个区域内，Amazon EC2 和 Amazon EBS 的月度正常运行时间百分比至少达到 99.99%。"
    },
    {
        "query":"怎样确定我是否有资格获得 SLA 服务抵扣？",
        "intention":"知识问答",
        "reply":"如果在一个月度计费周期内，您所在区域的月度正常运行时间百分比低于 99.99%，您就有资格申请 SLA 针对不可用的 Amazon EC2 和/或 Amazon EBS 提供的抵扣。如需 SLA 所有条款与条件的完整详细信息，以及如何提交索赔的详细信息，请参阅 [Amazon 计算服务等级协议](http://aws.amazon.com/ec2/sla/)。"
    },
    {
        "query":"什么是加速型计算实例？",
        "intention":"知识问答",
        "reply":"加速型计算实例类别包括一系列使用硬件加速器或协同处理器来执行浮点数计算和图形处理等功能的实例，比使用在 CPU 上运行的软件更高效。Amazon EC2 提供三种类型的加速型计算实例 - 用于通用计算的 GPU 计算实例、用于图形密集型应用程序的 GPU 图形实例和用于高级科学工作负载的 FPGA 可编程硬件计算实例。"
    },
    {
        "query":"何时应使用 GPU 图形和计算实例？",
        "intention":"知识问答",
        "reply":"GPU 实例最适合用于并行度极高的应用程序（例如使用数千个线程的工作负载）。例如，图形处理有大量的计算要求，其中的每个任务都相对较小，执行的一组操作形成了一个管道，而此管道的吞吐量要比单个操作的延迟更为重要。要构建能充分利用这种并行度的应用程序，用户需要掌握 GPU 设备的专项知识，了解如何针对各种图形 API (DirectX、OpenGL) 或 GPU 计算编程模型 (CUDA、OpenCL) 进行编程。"
    },
    {
        "query":"什么样的应用程序可以从 P4d 中获益？",
        "intention":"知识问答",
        "reply":"我们期望客户为之使用 P4d 的一些应用程序包括机器学习 (ML) 工作负载，如自然语言理解、自动驾驶汽车的感知模型训练、图像分类、对象检测和推荐引擎。提升的 GPU 性能可以显著减少训练时间，而额外的 GPU 内存将帮助客户训练更大、更复杂的模型。HPC 客户可以使用 P4 增强的处理性能和 GPU 内存进行地震分析、药物发现、DNA 测序和保险风险建模。"
    },
    {
        "query":"P4d 实例与 P3 实例相比如何？",
        "intention":"知识问答",
        "reply":"P4 实例采用 NVIDIA 最新一代的 A100 Tensor Core GPU，与上一代 V100 相比，平均 TFLOP 性能提高 2.5 倍，GPU 内存提高 2.5 倍。P4 实例采用 Cascade Lake Intel CPU，它的每个插槽有 24C 和用于向量神经网络指令的额外指令集。与 P3.16xl 相比，P4 实例将拥有 1.5 倍的系统总内存和 4 倍的 P3dn 或 16x 的网络吞吐量。另一个主要区别是 NVSwitch GPU 互连吞吐量将是 P3 的两倍，这样每个 GPU 可以在相同的 600GB/s 双向吞吐量和单跳延迟的情况下与其他 GPU 通信。如此应用程序开发便能将多个 GPU 和内存视为单个大型 GPU 和统一的内存池。P4d 实例也部署在紧密耦合的超大规模集群（称为 EC2 超级集群）中，使您能够运行最复杂的多节点机器学习训练和 HPC 应用程序。"
    },
    {
        "query":"EC2 UltraCluster 是什么，我如何可以访问？",
        "intention":"知识问答",
        "reply":"P4d 实例部署在称为 EC2 UltraCluster 的超大规模集群中。每个 EC2 UltraCluster 都由超过 4000 个 NVIDIA A100 Tensor Core GPU、PB 级网络和包含 FSx for Lustre 的可扩展低延迟存储组成。每个 EC2 UltraCluster 都是世界上最顶尖的超级计算机。任何人都可以在 EC2 SuperCluster 中轻松启动 P4d 实例。如需更多帮助，请[联系我们](https://pages.awscloud.com/p4d-ultracluster-contactus.html)。"
    },
    {
        "query":"我在 P3 和 P3dn 上使用的 AMI 可否在 P4 上使用？",
        "intention":"知识问答",
        "reply":"P4 AMIs 将需要为 A100 GPU 使用新的 NVIDIA 驱动程序，并安装 ENA 驱动程序的更新版本。P4 实例由 Nitro System 提供支持，这需要安装了 NVMe 和 ENA 驱动程序的 AMI。P4 还附带新的 Intel Cascade Lake CPU，其包含更新的指令集，因此我们建议使用 ML 框架的最新发行版本，它们利用这些新的指令集进行数据预处理。"
    },
    {
        "query":"P3 实例与 G3 实例有何不同？",
        "intention":"知识问答",
        "reply":"P3 实例是新一代 EC2 通用 GPU 计算实例，最多可配备 8 个最新一代 NVIDIA Tesla V100 GPU。这些新实例可显著提高性能和可扩展性，并且增加了多种新功能，包括可实现 Machine Learning (ML)/深度学习 (DL) 性能优化的全新流式多处理器 (SM) 架构、第二代 NVIDIA NVLink 高速 GPU 互连，以及可提高效率的高度优化的 HBM2 内存。\nG3 实例使用 NVIDIA Tesla M60 GPU，可为使用 DirectX 或 OpenGL 的图形应用程序提供高性能平台。NVIDIA Tesla M60 GPU 支持 NVIDIA GRID 虚拟工作站功能，以及 H.265 (HEVC) 硬件编码。G3 实例中的每个 M60 GPU 支持分辨率高达 4096x2160 的 4 台监控器，且获准将 NVIDIA GRID 虚拟工作站用于一位并行连接用户。例如，使用 G3 实例的应用程序包括 3D 可视化、图形密集型远程工作站、3D 渲染、应用程序流式处理、视频编码以及其他服务器端图形工作负载。"
    },
    {
        "query":"使用 NVIDIA Volta GV100 GPU 的优势有哪些？",
        "intention":"知识问答",
        "reply":"新的 NVIDIA Tesla V100 加速器采用了强大的全新 Volta GV100 GPU。GV100 不仅保留了其前任 Pascal GP100 GPU 的优势，还大大提升了性能和可扩展性，并增加了多种提高编程性能的新功能。这些优势将为 HPC、数据中心、超级计算机和深度学习系统及应用程序带来极大益处。"
    },
    {
        "query":"哪些人将通过 P3 实例获益？",
        "intention":"知识问答",
        "reply":"P3 实例具有高计算性能，可使人工智能 (AI)、机器学习 (ML)、深度学习 (DL) 和高性能计算 (HPC) 应用程序的用户获得诸多益处。受益的用户包括数据科学家、数据架构师、数据分析师、科学研究人员、ML 工程师、IT 经理和软件开发人员。受益的主要行业包括交通运输、能源/石油和天然气、金融服务（银行、保险）、医疗保健、制药、科学、IT、零售、制造、高科技、政府机构、学术研究等等。"
    },
    {
        "query":"P3 实例的主要使用案例有哪些？",
        "intention":"知识问答",
        "reply":"P3 实例使用 GPU 为多种深度学习系统和应用程序加速，其中包括无人驾驶汽车平台、语音/图像/文字识别系统、智能视频分析、分子模拟、药物发现、疾病诊断、天气预测、大数据分析、财务建模、机器人学、工厂自动化、实时语言翻译、在线搜索优化和个性化用户推荐，等等。"
    },
    {
        "query":"客户为何应将采用 GPU 的 Amazon P3 实例用于 AI/ML 和 HPC 应用程序？",
        "intention":"知识问答",
        "reply":"基于 GPU 的计算实例可提供更高的吞吐量和性能，因为它们可以使用每个 GPU 数以千计的专用核心进行大量并行处理，而不像采用只有几个核心的 CPU 的实例只能进行顺序处理。此外，开发人员还构建了数百种经过 GPU 优化的科学 HPC 应用程序，例如量子化学、分子动力学、气象学等。研究表明，最热门的 HPC 应用程序中有 70% 以上都提供内部 GPU 支持。"
    },
    {
        "query":"P3 实例是否会支持 EC2 Classic 联网和 Amazon VPC？",
        "intention":"知识问答",
        "reply":"P3 实例将仅支持 VPC。"
    },
    {
        "query":"G3 实例与 P2 实例有何不同？",
        "intention":"知识问答",
        "reply":"G3 实例使用 NVIDIA Tesla M60 GPU，可为使用 DirectX 或 OpenGL 的图形应用程序提供高性能平台。NVIDIA Tesla M60 GPU 支持 NVIDIA GRID 虚拟工作站功能，以及 H.265 (HEVC) 硬件编码。G3 实例中的每个 M60 GPU 支持分辨率高达 4096x2160 的 4 台监控器，且获准将 NVIDIA GRID 虚拟工作站用于一位并行连接用户。例如，使用 G3 实例的应用程序包括 3D 可视化、图形密集型远程工作站、3D 渲染、应用程序流式处理、视频编码以及其他服务器端图形工作负载。\nP2 实例使用 NVIDIA Tesla K80 GPU，是专门为使用 CUDA 或 OpenCL 编程模型进行通用 GPU 计算设计的。P2 实例为客户提供了 25Gbps 高带宽联网、强大的单精度和双精度浮点运算功能以及纠错代码 (ECC) 内存，非常适用于深入学习、高性能数据库、计算流体动力学、计算金融学、地震分析、分子建模、基因组学、渲染以及其他服务器端 GPU 计算工作负载。"
    },
    {
        "query":"P3 实例与 P2 实例有何不同？",
        "intention":"知识问答",
        "reply":"P3 实例是新一代 EC2 通用 GPU 计算实例，最多可配备 8 个最新一代 NVIDIA Volta GV100 GPU。这些新实例可显著提高性能和可扩展性，并且增加了多种新功能，包括可实现 Machine Learning (ML)/深度学习 (DL) 性能优化的全新流式多处理器 (SM) 架构、第二代 NVIDIA NVLink 高速 GPU 互连，以及可提高效率的高度优化的 HBM2 内存。\nP2 实例使用 NVIDIA Tesla K80 GPU，是专门为使用 CUDA 或 OpenCL 编程模型进行通用 GPU 计算设计的。P2 实例可为客户提供高带宽 25Gbps 联网、强大的单精度和双精度浮点计算能力，以及纠错代码 (ECC) 内存。"
    },
    {
        "query":"GPU 图形和计算实例支持哪些 API 和编程模型？",
        "intention":"知识问答",
        "reply":"P3 实例支持 CUDA 9 和 OpenCL，P2 实例支持 CUDA 8 和 OpenCL 1.2，G3 实例支持 DirectX 12、OpenGL 4.5、CUDA 8 和 OpenCL 1.2。"
    },
    {
        "query":"在哪里可以获取适用于 P3 和 G3 实例的 NVIDIA 驱动程序？",
        "intention":"知识问答",
        "reply":"获取 NVIDIA 驱动程序的方式有两种。[AWS Marketplace](https://aws.amazon.com/marketplace/search/results/?searchTerms=GPU) 上提供的商品列表包括已预装 NVIDIA 驱动程序的 Amazon Linux AMI 和 Windows Server AMI。您也可以启动 64 位 HVM AMI，自行安装这些驱动程序。但您必须访问 NVIDIA 驱动程序网站，并搜索 NVIDIA Tesla V100（用于 P3 实例）、NVIDIA Tesla K80（用于 P2 实例）或 NVIDIA Tesla M60（用于 G3 实例）。"
    },
    {
        "query":"哪些 AMI 可以与 P3、P2 和 G3 实例搭配使用？",
        "intention":"知识问答",
        "reply":"目前，您可以在 P2 和 G3 实例上使用 Windows Server、SUSE Enterprise Linux、Ubuntu 和 Amazon Linux AMI。P3 实例仅支持 HVM AMI。如果您要使用此处未列出的操作系统启动 AMI，请联系 AWS [客户支持](https://aws.amazon.com/cn/contact-us/)提出请求或通过 [EC2 论坛](https://forums.aws.amazon.com/forum.jspa?forumID=30#)寻求帮助。"
    },
    {
        "query":"使用 G2 和 G3 实例是否需要第三方许可证？",
        "intention":"知识问答",
        "reply":"除了 NVIDIA 驱动程序和 GRID SDK 之外，使用 G2 和 G3 实例并不一定需要第三方许可证。但是，您需要确定在 G2 和 G3 实例上使用的内容或技术是否需要任何其他许可。例如，如果对内容进行流式处理，则部分或全部内容可能需要许可证。如果您使用的是第三方技术 (例如 Microsoft、Thomson、Fraunhofer IIS、Sisvel S.p.A.、MPEG-LA 和 Coding Technologies 的操作系统、音频和/或视频编码器和解码器)，请咨询这些提供商来确定是否需要许可证。例如，如果您使用 NVIDIA GRID GPU 上的板载 h.264 视频编码器，则应联系 MPEG-LA 寻求指导，如果使用 mp3 技术，则应联系 Thomson 寻求指导。"
    },
    {
        "query":"为什么使用从 NVIDIA 网站下载的驱动程序无法在 G3 实例上获得 NVIDIA GRID 功能？",
        "intention":"知识问答",
        "reply":"G3 实例中使用的 NVIDIA Tesla M60 GPU 需要使用特殊的 NVIDIA GRID 驱动程序才能启用所有高级图形功能，以及分辨率高达 4096x2160 的 4 台监控器。您需要使用已预装 NVIDIA GRID 驱动程序的 AMI，或根据 AWS 文档下载并安装 NVIDIA GRID 驱动程序。"
    },
    {
        "query":"使用 Microsoft 远程桌面时，为什么看不到 GPU？",
        "intention":"知识问答",
        "reply":"在使用远程桌面时，使用 WDDM 驱动程序模型的 GPU 将被替换为非加速的远程桌面显示驱动程序。要访问 GPU 硬件，需要使用其他远程访问工具，如 VNC。"
    },
    {
        "query":"什么是 Amazon EC2 F1？",
        "intention":"知识问答",
        "reply":"Amazon EC2 F1 是一种计算实例，能够通过可编程的硬件实现应用程序加速。新的 F1 实例类型提供较高的性能，可以方便地访问 FPGA 以便开发和部署自定义硬件加速。"
    },
    {
        "query":"什么是 FPGA，我为什么需要它？",
        "intention":"知识问答",
        "reply":"FPGA 是可编程的集成电路，您可以使用软件进行配置。与只使用 CPU 的服务器相比，通过使用 FPGA，您可以将应用程序加速 30 倍。此外，FPGA 可重编程，因此您可以灵活地更新和优化硬件加速，而无需重新设计硬件。"
    },
    {
        "query":"F1 与传统 FPGA 解决方案相比如何？",
        "intention":"知识问答",
        "reply":"F1 是一种 AWS 实例，能够通过可编程的硬件实现应用程序加速。通过 F1，您只需单击几下即可访问 FPGA 硬件，从而节约全 FPGA 开发周期的时间和成本，并将部署时间从数年或数月缩减到数天。尽管 FPGA 技术已出现数十年，但是由于开发基础设施、硬件设计和大规模部署所需的时间和成本等因素，在加速器的开发和向传统企业销售自定义硬件的业务模式方面，导致应用程序加速的采用很难取得成功。通过此服务，客户可避免在本地数据中心开发 FPGA 的无差别的繁重工作。"
    },
    {
        "query":"什么是 Amazon FPGA 映像 (AFI)？",
        "intention":"知识问答",
        "reply":"您创建的用于对 FPGA 进行编程的设计称为 Amazon FPGA 映像 (AFI)。AWS 提供一项用于注册、管理、复制、查询和删除 AFI 的服务。AFI 在创建之后可以加载到正在运行的 F1 实例上。您可以将多个 AFI 加载到同一个 F1 实例上，并可以在运行时在多个 AFI 之间切换，无需重新启动。这让您能够快速地连续测试和运行多个硬件加速。您也可以在 AWS Marketplace 上为其他客户同时提供 FPGA 加速和带有自定义软件或 AFI 驱动程序的 AMI。"
    },
    {
        "query":"怎样在 AWS Marketplace 上发布硬件加速服务？",
        "intention":"知识问答",
        "reply":"您需要先开发自己的 AFI 和使用该 AFI 所需的软件驱动程序/工具。然后，您需要将这些软件工具/驱动程序以加密格式打包到一个 Amazon Machine Image (AMI) 中。AWS 会管理采用您提供的加密格式的所有 AFI，保证您的代码的安全性。要在 AWS Marketplace 上销售产品，您或您的公司必须注册成为 AWS Marketplace 经销商，然后再提交准备打包到单个产品中的 AMI ID 和 AFI ID。AWS Marketplace 会克隆该 AMI 与 AFI 以便创建一个产品，并将一个产品代码与这些构件关联，这样一来，购买了该产品的所有最终用户就能够访问该 AMI 和 AFI。"
    },
    {
        "query":"F1 实例附带哪些内容？",
        "intention":"知识问答",
        "reply":"AWS 为开发人员提供有助于缩短开发周期的硬件开发工具包 (HDK)、用于在云中开发的 FPGA 开发人员 AMI、运行 F1 实例的 AMI 需要的 SDK 以及用于注册、管理、复制、查询和删除 AFI 的一系列 API。开发人员和客户都可以访问 AWS Marketplace 并购买其中发布的 AFI，用于应用程序加速。"
    },
    {
        "query":"我是否需要成为 FPGA 专家才能使用 F1 实例？",
        "intention":"知识问答",
        "reply":"从 AWS Marketplace 订阅 F1 优化 AMI 的 AWS 客户无需了解有关 FPGA 的任何内容，即可使用 F1 实例和 AWS Marketplace 提供的加速。只需从 AWS Marketplace 购买加速功能与工作负载匹配的 F1 优化型 AMI 即可。AMI 包含使用 FPGA 加速所需的所有软件。客户仅需将软件写入针对该加速器的特定 API，并开始使用加速器。"
    },
    {
        "query":"我是 FPGA 开发人员，如何开始使用 F1 实例？",
        "intention":"知识问答",
        "reply":"开发人员可以通过创建 AWS 账户并下载 AWS 硬件开发工具包（HDK）开始使用 F1 实例。HDK 包括 F1 相关文档、内部 FPGA 接口以及用于生成 AFI 的编译器脚本。开发人员可以开始将 FPGA 代码写入 HDK 中包含的已编档的接口，以创建加速函数。开发人员可以使用 FPGA 开发人员 AMI 启动 AWS 实例。该 AMI 包含编译和模拟 FPGA 代码所需的开发工具。开发人员 AMI 在最新的 C5、M5 或 R4 实例上的运行效果最好。开发人员应具备用于创建 FPGA 代码（即 Verilog 或 VHDL）的编程语言的经验，并了解要加速的操作。"
    },
    {
        "query":"我不是 FPGA 开发人员，如何开始使用 F1 实例？",
        "intention":"知识问答",
        "reply":"客户可以通过从 AWS Marketplace 选择 AWS Marketplace 卖家提供的加速器并使用该 AMI 启动 F1 实例，开始使用 F1 实例。AMI 包括适用于该加速器的所有软件和 API。AWS 管理通过适用于该加速器的 AFI 对 FPGA 进行编程。客户无需任何 FPGA 经验或了解如何使用这些加速器。他们可以完全在适用于该加速器的软件 API 级别工作。"
    },
    {
        "query":"AWS 是否提供开发人员工具包？",
        "intention":"知识问答",
        "reply":"是的。硬件开发工具包 (HDK) 包括开发人员可以用来模拟、调试、构建和注册加速代码的模拟工具和模拟模型。HDK 包括代码示例、编译脚本、调试接口和开发适用于 F1 实例的 FPGA 代码所需的很多其他工具。您可以在 AWS 提供的 AMI 或本地开发环境中使用 HDK。可以使用 AWS 账户公开使用这些模型和脚本。"
    },
    {
        "query":"我是否可以在本地开发环境中使用 HDK？",
        "intention":"知识问答",
        "reply":"可以。您可以在 AWS 提供的 AMI 或您的本地开发环境中使用硬件开发工具包 (HDK)。"
    },
    {
        "query":"我是否可以向任何 EC2 实例类型中添加 FPGA？",
        "intention":"知识问答",
        "reply":"不可以。F1 实例有 f1.2xlarge、f1.4xlarge 和 f1.16 xlarge 三种大小。"
    },
    {
        "query":"如何在 Inf1 实例中使用 Inferentia 芯片？",
        "intention":"知识问答",
        "reply":"您可以使用诸如 P4、P3 或 P3dn 之类的 GPU 实例在一种流行的机器学习框架（例如 TensorFlow、PyTorch 或 MXNet）中构建模型，以此开始您的工作流程。将模型训练到所需的精度后，您可以使用机器学习框架的 API 调用 Neuron（用于 Inferentia 的软件开发工具包），以编译将在 Inferentia 芯片上执行的模型，将其加载到 Inferentia 的内存中，然后执行推理调用 。为了快速开始，您可以使用预安装有机器学习框架和 Neuron 开发工具包的 [AWS 深度学习 AMI](https://aws.amazon.com/cn/machine-learning/amis/)。在完全托管的体验中，您将能够使用 Amazon SageMaker，从而在 Inf1 实例上无缝部署经过训练的模型。"
    },
    {
        "query":"Inf1 与C6i 或 C5 与G4 实例分别应于何时用于推理？",
        "intention":"知识问答",
        "reply":"如果客户运行对推理延迟和吞吐量敏感的机器学习模型，可以使用 Inf1 实例进行高性能且经济高效的推理。对于那些对推理延迟和吞吐量不太敏感的机器学习模型，客户可以使用 EC2 C6i 或 C5 实例并使用 AVX-512/VNNI 指令集。对于需要访问 NVIDIA 的 CUDA、CuDNN 或 TensorRT 库的机器学习模型，我们建议使用 G4 实例。\n| 模型特点和使用的库 | EC2 Inf1 | EC2 C6i 或 C5 | EC2 G4 |\n| --- | --- | --- | --- |\n| 受益于以低成本实现低延迟和高吞吐量的模型 | X |  |  |\n| 对延迟和吞吐量不敏感的模型 | X |  |\n| 需要 NVIDIA 开发人员库的模型 | X |"
    },
    {
        "query":"什么时候应选择 Elastic Inference (EI) 而非 Amazon EC2 Inf1 实例进行推理？",
        "intention":"知识问答",
        "reply":"在两种情况下，开发人员应该选择 EI 而非 Inf1 实例：(1) 如果您需要的 CPU 和内存大小与 Inf1 所提供的大小不同，则可使用 EI 为您的应用程序提供适当的 CPU 和内存组合，从而加速 EC2 实例；(2) 如果您的性能要求大大低于最小的 Inf1 实例提供的性能，则使用 EI 可能是更加经济高效的选择。例如，如果您只需要 5 TOPS（足以处理多达 6 个并发视频流），则相较于使用最小 Inf1 实例，使用最小 EI 切片搭配 C5.large 实例最多可节省 50%。"
    },
    {
        "query":"使用 Inferentia 芯片的 EC2 Inf1 实例支持哪些机器学习模型类型和运算符？",
        "intention":"知识问答",
        "reply":"Inferentia 芯片支持多种常用机器学习模型，例如用于图像识别/分类的单帧检测器 (SSD) 和 ResNet，用于自然语言处理和翻译的 Transformer 和 BERT 以及许多其他模型。在 GitHub 上可以找到受支持的运算符列表。\n如何利用 AWS Inferentia 的 NeuronCore Pipeline 功能来降低延迟？\n具有多个 Inferentia 芯片的 Inf1 实例（例如 Inf1.6xlarge 或 Inf1.24xlarge）支持芯片之间的快速互连。使用 Neuron Processing Pipeline 功能，您可以对模型进行拆分并将其加载到多个芯片上的本地缓存内存。Neuron 编译器使用提前 (AOT) 编译技术来分析输入模型并进行编译，使其适合单个或多个 Inferentia 芯片的片内内存。这样做可使 Neuron Core 高速访问模型而无需访问片外内存，从而可以在增加整体推理吞吐量的同时有效限制延迟。"
    },
    {
        "query":"AWS Neuron 与 Amazon SageMaker Neo 有何区别？",
        "intention":"知识问答",
        "reply":"AWS Neuron 是用于 AWS Inferentia 芯片的专用开发工具包，可优化 Inferentia 芯片的机器学习推理性能。它由用于 AWS Inferentia 的编译器、运行时和分析工具组成，并且是在 EC2 Inf1 实例上运行推理工作负载所必需的。相比较而言，Amazon SageMaker Neo 是与硬件无关的服务，由编译器和运行时组成，使开发人员能够一次性训练机器学习模型，然后在许多不同的硬件平台上运行它们。"
    },
    {
        "query":"如何在 Trn1 实例中使用 Trainium 芯片？",
        "intention":"知识问答",
        "reply":"Trainium 软件堆栈 AWS Neuron SDK 与领先的 ML 框架（例如 PyTorch 和 TensorFlow）集成，因此您只需对代码进行极少更改即可开始使用。要快速开始，您可以使用预配置了 AWS Neuron 的 [AWS Deep Learning AMI](https://aws.amazon.com/cn/machine-learning/amis/) 和 [AWS Deep Learning Containers](https://aws.amazon.com/cn/machine-learning/containers/)。如果您使用的是容器化应用程序，则可以使用 [Amazon Elastic Container Service (Amazon ECS)](https://aws.amazon.com/cn/ecs/)、[Amazon Elastic Kubernetes Service (Amazon EKS)](https://aws.amazon.com/cn/eks/) 或您首选的本机容器引擎来部署 AWS Neuron。AWS Neuron 还支持 [Amazon SageMaker](https://aws.amazon.com/cn/sagemaker/)，您可以使用它来构建、训练和部署机器学习模型。"
    },
    {
        "query":"我可以在哪里部署在 Trn1 上训练的深度学习模型？",
        "intention":"知识问答",
        "reply":"您可以在任何其他支持深度学习用例的 Amazon EC2 实例上部署在 Trn1 实例上训练的深度学习模型，包括基于 CPU、GPU 或其他加速器的实例。您还可以部署在 AWS 之外的 Trn1 实例（例如本地数据中心或边缘的嵌入式设备）上训练的模型。例如，您可以在 Trn1 实例上训练模型并将它们部署在 Inf1 实例、G5 实例、G4 实例或边缘计算设备上。"
    },
    {
        "query":"什么时候可以使用 Trn1 实例而不是基于 GPU 的实例来训练 ML 模型？",
        "intention":"知识问答",
        "reply":"Trn1 实例非常适合您的自然语言处理（NLP）、大型语言模型（LLM）和计算机视觉（CV）模型训练用例。Trn1 实例专注于加速模型训练，以提供高性能同时降低模型训练成本。如果您的机器学习模型需要第三方专有库或语言，例如 NVIDIA CUDA、CUDA 深度神经网络（CuDNN）或 TensorRT 库，我们建议使用基于 NVIDIA GPU 的实例（P4、P3）。"
    },
    {
        "query":"突发性能实例有哪些与众不同之处？",
        "intention":"知识问答",
        "reply":"Amazon EC2 允许在固定性能实例（如 C、M 和 R 实例系列）和[突发性能实例](https://aws.amazon.com/cn/ec2/instance-types/#Burstable_Performance_Instances)（如 T2）之间进行选择。突发性能实例可以保证基本 CPU 性能水平并将其突增至更高水平。\nT2 实例的基本性能和突发能力受到 CPU 积分的制约。每个 T2 实例都会持续收到 CPU 积分，其频率取决于实例大小。T2 实例会在其空闲时累计 CPU 积分，然后在活跃时使用 CPU 积分。一个 CPU 积分可以在一分钟内提供完整的 CPU 核心性能。\n|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n| 型号 | vCPU | CPU 积分/小时 | 最大 CPU 积分余额 | 基准 CPU 性能 |\n| t2.nano | 1 | 3 | 72 | 一个内核的 5% |\n| t2.micro | 1 | 6 | 144 | 一个内核的 10% |\n| t2.small | 1 | 12 | 288 | 一个内核的 20% |\n| t2.medium | 2 | 24 | 576 | 一个内核的 40%\\* |\n| t2.large | 2 | 36 | 864 | 一个内核的 60%\\*\\* |\n| t2.xlarge | 4 | 54 | 1,296 | 一个内核的 90%\\*\\*\\* |\n| t2.2xlarge | 8 | 81 | 1,944 | 一个内核的 135%\\*\\*\\*\\* |\n型号\nvCPU\nCPU 积分/小时\n最大 CPU 积分余额\n基准 CPU 性能\nt2.micro\n1\n6\n144\n一个内核的 10%\nt2.small\n1\n12\n288\n一个内核的 20%\nt2.medium\n2\n24\n576\n一个内核的 40%\\*\nt2.xlarge\n4\n54\n1,296\n一个内核的 90%\\*\\*\\*\nt2.2xlarge\n8\n81\n1,944\n一个内核的 135%\\*\\*\\*\\*\n*\\* 对于 t2.medium，单线程应用程序可以使用 1 个内核的 40%；如果需要，多线程应用程序可以使用 2 个内核，各用 20%。*\n*\\*\\* 对于 t2.large，单线程应用程序可以使用 1 个内核的 60%；如果需要，多线程应用程序可以使用 2 个内核，各用 30%。*\n*\\*\\*\\* 对于 t2.xlarge，单线程应用程序可以使用 1 个内核的 90%；如果需要，多线程应用程序可以使用 2 个内核，各用 45%，或者使用全部 4 个内核，各用 22.5%。*\n*\\*\\*\\*\\* 对于 t2.2xlarge，单线程应用程序可以使用 1 个内核的全部；如果需要，多线程应用程序可以使用 2 个内核，各用 67.5%，或者使用全部 8 个内核，各用 16.875%。*"
    },
    {
        "query":"如何为我的 T2 实例选择正确的 Amazon Machine Image (AMI)？",
        "intention":"知识问答",
        "reply":"您将需要验证操作系统和应用程序的最小内存需求是否在为每个 T2 实例大小分配的内存中 (例如，t2.nano 是 512MiB)。采用图形用户界面 (GUI) 的操作系统需要占用极大的内存和 CPU (如 Microsoft Windows)，因此在大多数使用案例中，它们可能需要使用 t2.micro 或更大的实例。您可以在 [AWS Marketplace](https://aws.amazon.com/marketplace/search?page=1&instance_types=t2.nano&filters=instance_types) 上找到适用于 t2.nano 实例类型的 AMI。对于不需要使用 GUI 的 Windows 客户，可以使用 [Microsoft Windows Server 2012 R2 Core AMI](https://aws.amazon.com/marketplace/pp/B00KQOWEPO/ref=srh_res_product_title?ie=UTF8&sr=0-2&qid=1448487264646)。"
    },
    {
        "query":"何时应该选用突发性能实例（如 T2）？",
        "intention":"知识问答",
        "reply":"T2 实例为各种通用型生产工作负载提供了一个经济高效的平台。T2 Unlimited 实例可以按需保持高 CPU 性能。 如果您的工作负载始终要求 CPU 使用率高于基本水平，请考虑专用 CPU 实例，如 M 或 C。"
    },
    {
        "query":"如何查看每个 T2 实例的 CPU 积分余额？",
        "intention":"知识问答",
        "reply":"您可以在 Amazon CloudWatch 中每个实例的 EC2 指标参数中查看各 T2 实例的 CPU 积分余额。T2 实例有四个指标：CPUCreditUsage、CPUCreditBalance、CPUSurplusCreditBalance 和 CPUSurplusCreditsCharged。CPUCreditUsage 是指所使用的 CPU 积分量。CPUCreditBalance 是指 CPU 积分余额。CPUSurplusCredit Balance 是指在没有获得积分时用于突发的积分。CPUSurplusCreditsCharged 是指在平均用量超过基本水平时收取的积分。"
    },
    {
        "query":"如果我的 T2 实例积分不足（CPU 积分余额接近于零），这对 CPU 的性能有什么影响？",
        "intention":"知识问答",
        "reply":"如果您的 T2 实例的 CPU 积分余额为零，则性能将维持在基本 CPU 性能。例如，t2.micro 提供的基本 CPU 性能为物理 CPU 内核的 10%。如果实例的 CPU 积分余额接近零，则每隔 15 分钟 CPU 性能将被降至基本性能。"
    },
    {
        "query":"当实例停止/启动时，我的 T2 实例抵扣金额余额是否保留？",
        "intention":"知识问答",
        "reply":"不会，停止运行的实例不会保留之前获取的积分余额。"
    },
    {
        "query":"T2 实例是否能作为预留实例或 Spot 实例购买？",
        "intention":"知识问答",
        "reply":"T2 实例可以作为按需型实例、预留实例或竞价型实例进行购买。"
    },
    {
        "query":"什么是 Amazon EC2 T4g 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 T4g 实例是由基于 Arm 的 AWS Graviton2 处理器提供支持的下一代通用型突增实例。与 T3 实例相比，T4g 实例的性价比最多可提高 40%。它们在将专用硬件与 Nitro 管理程序集于一体的 [AWS Nitro 系统](https://aws.amazon.com/cn/ec2/nitro/)上构建。"
    },
    {
        "query":"T4g 实例有哪些理想的使用案例？",
        "intention":"知识问答",
        "reply":"与 T3 实例相比，T4g 实例可为广泛的通用型突增工作负载实现 40% 的性价比提升，这些工作负载包括微服务、低延迟交互应用程序、中小型数据库、虚拟桌面、开发环境、代码库和业务关键型应用程序。客户如果在整个 T 实例系列中部署依托开源软件构建的应用程序，就会发现 T4g 实例是一种颇具吸引力的选择，可以实现最佳性价比。此外，Arm 开发人员还能直接依托原生 Arm 硬件（而不是交叉编译或仿真）构建应用程序。"
    },
    {
        "query":"客户如何获取 T4g 免费试用？",
        "intention":"知识问答",
        "reply":"在 2023 年 12 月 31 日之前，所有 AWS 客户都将自动注册 T4g 免费试用，详见 [AWS Free Tier](https://aws.amazon.com/cn/free/)。在免费试用期内，运行 t4g.small 实例的客户，每月将自动从其账单中抵扣 750 个免费小时。750 小时是指 t4g.small 实例在所有区域中的运行时长的总和。如果客户在 T4g 免费试用计划的 750 个免费小时内超过了为实例分配的积分，则必须为超出的 CPU 积分付费。要详细了解 CPU 积分的运行机制，请参阅《适用于 Linux 实例的 Amazon EC2 用户指南》中的[具有可爆发性能实例的关键概念和定义](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/burstable-credits-baseline-concepts.html)。"
    },
    {
        "query":"T4g 免费试用在哪些区域可用？  T4g 免费试用目前已在下列 AWS 区域开放：美国东部（俄亥俄州）、美国东部（弗吉尼亚州北部）、美国西部（加利福尼亚州北部）、美国西部（俄勒冈州）、南美洲（圣保罗）、亚太地区（香港）、亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）。目前中国（北京）和中国（宁夏）区域尚未开放此免费试用。",
        "intention":"知识问答",
        "reply":"作为免费试用的一部分，在 2023 年 12 月 31 日之前，客户在一个或多个区域运行 t4g.small 实例时，每月可累计免费运行 750 个小时。例如，客户可以在俄勒冈州区域免费运行 t4g.small 实例 300 个小时，并在同一个月内在东京区域免费运行另一个 t4g.small 实例 450 个小时。两者相加即为每月 750 小时的免费试用上限。"
    },
    {
        "query":"何时应使用计算优化型实例？",
        "intention":"知识问答",
        "reply":"计算优化型实例适用于需要高计算能力的应用场景。此类应用场景包括各种计算密集型应用场景，例如高性能 Web 服务器、高性能计算（HPC）、科学建模、分布式分析和机器学习推理。"
    },
    {
        "query":"什么是 Amazon EC2 C6g 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 C6g 实例是由基于 Arm 的 AWS Graviton2 处理器提供支持的下一代计算优化型实例。与 C5 实例相比，C6g 实例的性价比最多可提高 40%。它们在将专用硬件与 Nitro 虚拟机监控器集于一体的 [AWS Nitro System](https://aws.amazon.com/cn/ec2/nitro/) 上构建。"
    },
    {
        "query":"C6g 实例有哪些理想的使用案例？",
        "intention":"知识问答",
        "reply":"C6g 实例为计算优化型工作负载提供超高性价比优势，此类工作负载包括高性能计算 (HPC)、批处理、广告服务、视频编码、游戏、科学建模、分布式分析以及基于 CPU 的机器学习推理等。 客户如果在整个 C 实例系列中部署依托开源软件构建的应用程序，就会发现 C6g 实例是一种颇具吸引力的选择，可以实现最佳性价比。此外，Arm 开发人员还能直接依托原生 Arm 硬件（而不是交叉编译或仿真）构建应用程序。"
    },
    {
        "query":"C6g 实例上提供了哪些不同的存储选项？",
        "intention":"知识问答",
        "reply":"C6g 实例默认针对 EBS 进行了优化，可以为加密和未加密 EBS 卷提供高达 19000Mbps 的专用 EBS 带宽。C6g 实例仅支持通过 Non-Volatile Memory Express (NVMe) 接口访问 EBS 存储卷。 此外，还可通过 C6gd 实例类型提供具有本地 NVMe 实例存储的选项。"
    },
    {
        "query":"C6g 实例支持哪种网络接口？",
        "intention":"知识问答",
        "reply":"C6g 实例支持基于 ENA 的增强型联网。借助 ENA，C6g 实例可以在一个置放群组内启动的实例之间实现高达 25Gbps 的网络带宽。"
    },
    {
        "query":"为了在 C6g 实例上运行，客户是否需要修改其应用程序和工作负载？",
        "intention":"知识问答",
        "reply":"所需的更改因应用程序而定。客户如果运行依托开源软件构建的应用程序，就会发现 Arm 生态系统高度发达，很可能已经能够支持他们的应用程序。大多数 Linux 发行版以及容器（Docker、Kubernetes、Amazon ECS、Amazon EKS、Amazon ECR）都支持 Arm 架构。客户可以找到常用软件包的 Arm 版本，通过与目前所用相同的机制进行安装。基于不依赖原生 CPU 指令集的解释语言（例如 Java、Node、Python）的应用程序在运行时应该几乎没有变化。采用编译语言（C、C++、GoLang）开发的应用程序将需要重新编译以生成 Arm 二进制文件。这些主流编程语言可出色支持 Arm 架构，而现代代码则通常需要执行简单的 “Make” 命令。参阅 [GitHub 上的入门指南](https://github.com/aws/aws-graviton-gettting-started)以了解更多详细信息。"
    },
    {
        "query":"C6 实例系列是否会提供更多计算选择？",
        "intention":"知识问答",
        "reply":"会，我们计划在未来增加由 Intel 和 AMD CPU 提供支持的实例，并将其作为 C6 实例系列的一部分。"
    },
    {
        "query":"能否将 C4 实例作为 Amazon EBS 优化实例启动？",
        "intention":"知识问答",
        "reply":"所有 C4 实例类型默认皆为 EBS 优化型。C4 实例拥有的 500 Mbps 到 4000 Mbps EBS 连接能力超过了提供给实例的一般用途网络吞吐量。由于这是 C4 实例与生俱来的能力，因此将 C4 实例专门以 EBS 优化型实例的方式启动对于实例的行为并不会产生任何影响。"
    },
    {
        "query":"如何使用 c4.8xlarge 实例中的处理器状态控制功能？",
        "intention":"知识问答",
        "reply":"c4.8xlarge 实例类型为操作系统提供了控制处理器 C-state 和 P-state 的能力。目前这项功能仅限 Linux 实例。改变 C-state 或 P-state 设置可以增加处理器性能一致性，减少延迟，还可以针对特定工作负载对实例进行调校。默认情况下，Amazon Linux 提供适合多数客户工作负载的最高性能配置。但是，如果您的应用程序需要以较高的单核心或双核心频率来获得较低的延迟，或者需要低频持续性能，而不是突发高性能，则您应该考虑对 C-state 或 P-state 配置选项进行试验，以找到最适合您的实例的设置方法。有关这项功能的更多信息，请参阅《Amazon EC2 用户指南》中关于[处理器状态控制](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/processor_state_control.html)的部分。"
    },
    {
        "query":"计算优化型实例具体包含哪些实例？",
        "intention":"知识问答",
        "reply":"C6g 实例：Amazon EC2 C6g 实例由基于 Arm 的 AWS Graviton2 处理器提供支持。它们所提供的性价比最多比 C5 实例高 40%，是运行高级计算密集型工作负载的理想选择。其中包括例如高性能计算（HPC）、批处理、广告投放、视频编码、游戏、科学建模、分布式分析和基于 CPU 的机器学习推理等在内的工作负载。\nC6a 实例：C6a 实例采用全核睿频高达 3.6GHz 的第 3 代 AMD EPYC 可扩展处理器，与 C5a 实例相比性价比提高多达 15%，适用于各种工作负载，并使用 AMD [Transparent Single Key Memory Encryption](https://developer.amd.com/sev/)（单个密钥透明内存加密，TSME）支持全天候运行的内存中加密。C6a 实例提供最高可达 192 vCPU 和 384 GiB 内存的新实例大小，是最大 C5a 实例的两倍。C6a 还为客户提供最高 50Gbps 的联网速度和 40Gbps 的 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/) 带宽，超过 C5a 实例的两倍。\nC6i 实例：C6i 实例采用全核睿频高达 3.5GHz 的第 3 代英特尔至强可扩展处理器，与 C5 实例相比性价比提高多达 15%，适用于各种工作负载，并使用 Intel Total Memory encryption（TME）实现全天候运行的内存中加密。C6i 实例提供了新的实例大小 (c6i.32xlarge)，它包含 128 个 vCPUs 和 256 GiB 内存，比最大的 C5 实例还多 33%。与 C5 实例相比，它们的每个 vCPU 的内存带宽也要高出多达 9%。C6i 还可为客户提供高达 50Gbps 的联网速度和 40Gbps 的带宽以连接 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/)，是 C5 实例的两倍。对于需要高速度、低延迟本地存储的应用，C6i 还将提供基于 NVMe 的本地 SSD 块级别存储（C6id 实例）。与上一代 C5d 实例相比，C6id 实例中每个 vCPU 的存储量（TB）增加了 138%，并且每 TB 的成本降低了 56%。\nC5 实例：C5 实例基于英特尔至强可扩展处理器（代号为 Skylake-SP 或 Cascade Lake）系列中的英特尔至强 Platinum 处理器，有 9 种大小，提供多达 96 个 vCPU 和 192 GiB 的内存。与 C4 实例相比，C5 实例的性价比提高了 25%。C5d 实例拥有本地 NVMe 存储，用于要求非常低的延迟和具有高随机读写 IOPS 能力的存储访问的工作负载。\nC5a 实例：C5a 实例为包括批处理、分布式分析、数据转换、日志分析和 Web 应用程序在内的广泛的计算密集型工作负载提供领先的 x86 性价比。C5a 实例采用第二代 3.3GHz AMD EPYC 处理器，该处理器最高拥有 96 个 vCPU 和 192 GiB 内存。C5ad 实例拥有本地 NVMe 存储，用于要求非常低的延迟和具有高随机读写 IOPS 能力的存储访问的工作负载。\nC5n 实例：C5n 实例适用于需要高网络带宽和数据包速率的应用程序。C5n 实例适用于 HPC、数据湖、网络设备之类的应用程序以及需要节点间通信和消息传递接口 (MPI) 的应用程序。C5n 提供 Intel Xeon Platinum 3.0 GHz 处理器选择，该处理器最高拥有 72 个 vCPU 和 192GiB 内存。\nC4 实例：C4 实例基于 Intel Xeon E5-2666 v3（代号为 Haswell）处理器。C4 实例有 5 种大小，提供多达 36 个 vCPU 和 60 GiB 的内存。"
    },
    {
        "query":"为什么客户应该选择 C6i 实例而不是 C5 实例？",
        "intention":"知识问答",
        "reply":"C6i 实例提供与 C5 实例相比多达 15% 的性价比，其全天候运行的内存加密使用 Intel Total Memory Encryption (TME)。C6i 实例提供了新的实例大小 (c6i.32xlarge)，它包含 128 个 vCPUs 和 256 GiB 内存，比最大的 C5 实例还多 33%。与 C5 实例相比，它们的每个 vCPU 的内存带宽也要高出多达 9%。C6i 还可为客户提供高达 50 Gbps 的联网速度和 40 Gbps 的带宽以连接 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/)，是 C5 实例的两倍。"
    },
    {
        "query":"为什么客户应该选择 C5 实例而不是 C4 实例？",
        "intention":"知识问答",
        "reply":"C5 实例是 CPU 性能更高、价格更低的新一代产品，比 C4 实例的价格低 25%、性能高 25%，可以支持当前在 C3 或 C4 实例上运行的大量工作负载。对于浮点密集型应用场景，Intel AVX-512 可以有效提取数据级并行，从而大幅度提高 TFLOPS。对于可以通过 GPU 或 FPGA 来加速的图形渲染和 HPC 工作负载，如果客户想要为其寻求绝对性能，则还应该评估包含此类资源的 Amazon EC2 产品组合中的其他实例系列，以便为其工作负载找到理想的实例。"
    },
    {
        "query":"C5 实例支持哪种存储接口？",
        "intention":"知识问答",
        "reply":"C5 实例只支持 NVMe EBS 设备模式。连接到 C5 实例的 EBS 卷会显示为 NVMe 设备。NVMe 是一种最新存储接口，可以降低延迟并提高磁盘 I/O 和吞吐量。"
    },
    {
        "query":"为什么操作系统报告的内存总量与宣传的实例类型内存量不完全一致？",
        "intention":"知识问答",
        "reply":"虚拟 BIOS 会将部分 EC2 实例内存预留并用于视频 RAM、DMI 和 ACPI。此外，对于由 AWS Nitro 管理程序提供支持的实例，Amazon EC2 Nitro 虚拟机监控器会预留一小部分实例内存用来管理虚拟化。"
    },
    {
        "query":"高性能计算（HPC）实例类别中有哪些可用实例？",
        "intention":"知识问答",
        "reply":"Hpc6a 实例：Hpc6a 实例采用具有 96 个内核的第 3 代 AMD EPYC 处理器，具有高达 3.6GHz 的全核睿频率和 384GiB RAM。Hpc6a 实例提供支持高吞吐量节点间通信的 100 Gbps EFA 网络，可帮助您大规模运行 HPC 工作负载。与同等基于 x86 的计算优化型实例相比，Hpc6a 实例的性价比最高提高了 65%。\nHpc6id 实例：Hpc6id 实例由 64 个英特尔第三代至强可扩展处理器内核提供支持，运行频率高达 3.5 GHz，可提高效率。这些实例通过为每个 vCPU 提供 5 GB/s 的内存带宽来提高内存受限型工作负载的性能。Hpc6id 实例提供 200 Gbps EFA 网络以实现高吞吐量节点间通信，可帮助您大规模运行 HPC 工作负载。\nHpc7g 实例：Amazon Elastic Compute Cloud（Amazon EC2）Hpc7g 为 AWS 上的 HPC 工作负载提供最佳性价比。较于上一代基于 Graviton 的实例，这些实例的性能最多可提高 60%，适用于天气和计算流体动力学（CFD）等计算密集型工作负载。Hpc7g 由 AWS Graviton3E 处理器提供支持，与 AWS Graviton3 实例相比，Hpc7g 实例的向量指令性能最多可提高 35%。 与由 Graviton2 处理器提供支持的实例相比，这些实例的浮点性能最多可提高 2 倍。 Hpc7g 实例基于 [AWS Nitro System](https://aws.amazon.com/cn/ec2/nitro/) 构建，并提供 200 Gbps 的网络带宽，适用于需要高度并行集群计算资源的紧密耦合工作负载的低延迟节点间通信。"
    },
    {
        "query":"Hpc6a 实例的区域可用性如何？",
        "intention":"知识问答",
        "reply":"Hpc6a 实例在美国东部（俄亥俄州）、欧洲地区（斯德哥尔摩）和 AWS GovCloud（美国西部）可用。要针对紧密耦合的工作负载优化网络，您可以在每个可用区域的单个可用区访问 Hpc6a 实例。"
    },
    {
        "query":"Hpc6a 实例支持哪些 AMI？",
        "intention":"知识问答",
        "reply":"Hpc6a 实例支持 Amazon Linux 2、Amazon Linux、Ubuntu 18.04 或更新版本、Red Hat Enterprise Linux 7.4 或更新版本、SUSE Linux Enterprise Server 12 SP2 或更新版本、CentOS 7 或更新版本以及 FreeBSD 11.1 或更新版本。这些实例还支持 Windows Server 2012、2012 R2、2016 和 2019。"
    },
    {
        "query":"Hpc6a 实例支持哪些定价模型？",
        "intention":"知识问答",
        "reply":"Hpc6a 实例可通过 1 年和 3 年标准预留实例、可转换预留实例、Savings Plans 和按需型实例购买。"
    },
    {
        "query":"问：Hpc6id 实例与其他 EC2 实例有何不同？",
        "intention":"知识问答",
        "reply":"Hpc6id 实例经过优化，可提供适合内存受限、数据密集型 HPC 工作负载的功能。禁用超线程以增加每个 vCPU 的 CPU 吞吐量，并为每个 vCPU 增加高达 5 GB/s 的内存带宽。这些实例提供针对同一虚拟私有云（VPC）中实例之间的流量进行了优化的 200 Gbps 网络带宽，并支持 EFA 以提高网络性能。要针对紧密耦合的工作负载优化 Hpc6id 实例网络，您可以在每个区域的单个可用区访问 EC2 Hpc6id 实例。"
    },
    {
        "query":"Hpc6id 实例的区域可用性如何？",
        "intention":"知识问答",
        "reply":"Hpc6id 实例在美国东部（俄亥俄州）和 AWS GovCloud（美国西部）每个区域的单个可用区中可用。"
    },
    {
        "query":"Hpc6id 实例支持哪些 AMI？",
        "intention":"知识问答",
        "reply":"Hpc6id 支持 Amazon Linux 2、Amazon Linux、Ubuntu 18.04 或更新版本、Red Hat Enterprise Linux 7.4 或更新版本、SUSE Linux Enterprise Server 12 SP2 或更新版本、CentOS 7 或更新版本、Windows Server 2008 R2 或更早版本以及 FreeBSD 11.1 或更新版本。"
    },
    {
        "query":"Hpc6id 实例支持哪些定价模型？",
        "intention":"知识问答",
        "reply":"Hpc6id 实例可通过 1 年和 3 年 [Amazon EC2 实例实惠配套](https://docs.aws.amazon.com/savingsplans/latest/userguide/what-is-savings-plans.html#plan-types)、[计算实惠配套](https://aws.amazon.com/cn/savingsplans/compute-pricing/)、[EC2 按需型实例](https://aws.amazon.com/cn/ec2/pricing/?trk=36c6da98-7b20-48fa-8225-4784bced9843&sc_channel=ps&s_kwcid=AL!4422!3!536392643179!p!!g!!ec2%20instance&ef_id=CjwKCAjwtp2bBhAGEiwAOZZTuDDvKIFdih0TBaDh3s5RU8-y5_hO4rd8f21Dd29kjqtgL6yQWcP2XxoCcDcQAvD_BwE:G:s&s_kwcid=AL!4422!3!536392643179!p!!g!!ec2%20instance)和 [EC2 预留实例](https://aws.amazon.com/cn/ec2/pricing/reserved-instances/)购买。"
    },
    {
        "query":"Hpc7g 实例与其他 EC2 实例有何不同？",
        "intention":"知识问答",
        "reply":"Hpc7g 实例经过优化，可提供适合计算密集型 HPC 工作负载的功能。Hpc7g 实例以基于 ARM 的 Graviton3E 处理器为基础构建，与基于 Graviton3 处理器的现有实例相比，其向量指令性能最多可提高 35%。这些实例提供 64 个物理内核、128 GiB 内存和 200 Gbps 网络带宽，该带宽针对同一 VPC 中实例之间的流量进行了优化，并支持 EFA 以提高网络性能。Hpc7g 实例通过单个可用区部署提供，让工作负载能够实现 HPC 应用程序紧密耦合的节点间通信所需的低延迟网络性能。"
    },
    {
        "query":"什么是 Amazon EC2 M6g 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 M6g 实例是由基于 Arm 的 AWS Graviton2 处理器提供支持的下一代通用型实例。与 M5 实例相比，M6g 实例的性价比提高了 40%。它们在将专用硬件与 Nitro 管理程序集于一体的 [AWS Nitro 系统](https://aws.amazon.com/cn/ec2/nitro/)上构建。"
    },
    {
        "query":"新 AWS Graviton2 处理器的规格是怎样的？",
        "intention":"知识问答",
        "reply":"与第一代 AWS Graviton 处理器相比，AWS Graviton2 处理器的性能提高了 7 倍，计算内核数量增加了 4 倍，缓存增加了 2 倍，内存速度提升了 5 倍，每个内核的加密性能提速了 50%。AWS Graviton2 处理器的每个内核都是一个单线程 vCPU。这些处理器还提供了全天候运行的全加密 DRAM 内存、用于压缩工作负载的硬件加速、每个 vCPU 的专用引擎（可使视频编码等工作负载的浮点运算性能翻倍），以及基于 int8/fp16 CPU 的机器学习推理加速的指令。这些 CPU 采用 64 位 Arm Neoverse 内核和 AWS 设计的定制硅片，依托先进的 7 纳米制造技术构建。"
    },
    {
        "query":"AWS Graviton2 处理器是否支持内存加密？",
        "intention":"知识问答",
        "reply":"AWS Graviton2 处理器支持全天候运行的 256 位加密，可进一步提升安全性。加密密钥在主机系统内安全地生成，不会离开主机系统，并且在重启或关机后将被销毁，不可恢复。内存加密不支持与 AWS Key Management Service（AWS KMS）集成，客户也不能使用自己的密钥。"
    },
    {
        "query":"M6g 实例有哪些理想的使用案例？",
        "intention":"知识问答",
        "reply":"M6g 实例可为各种通用型工作负载（例如应用程序服务器、游戏服务器、微服务、中型数据库和缓存实例集）带来显著的性能和性价比优势。 客户如果在整个 M 实例系列中部署依托开源软件构建的应用程序，就会发现 M6g 实例是一种颇具吸引力的选择，可以实现最佳性价比。此外，Arm 开发人员还能直接依托原生 Arm 硬件（而不是交叉编译或仿真）构建应用程序。"
    },
    {
        "query":"M6g 实例上提供了哪些不同的存储选项？",
        "intention":"知识问答",
        "reply":"M6g 实例默认针对 EBS 进行了优化，可以为加密和未加密 EBS 卷提供高达 19000Mbps 的专用 EBS 带宽。M6g 实例仅支持通过 Non-Volatile Memory Express (NVMe) 接口访问 EBS 存储卷。 此外，还可通过 M6gd 实例类型提供具有本地 NVMe 实例存储的选项。"
    },
    {
        "query":"M6g 实例支持哪种网络接口？",
        "intention":"知识问答",
        "reply":"M6g 实例支持基于 ENA 的增强型联网。借助 ENA，M6g 实例可以在一个置放群组内启动的实例之间实现高达 25Gbps 的网络带宽。"
    },
    {
        "query":"为了在 M6g 实例上运行，客户是否需要修改其应用程序和工作负载？",
        "intention":"知识问答",
        "reply":"所需的更改因应用程序而定。客户如果运行依托开源软件构建的应用程序，就会发现 Arm 生态系统高度发达，很可能已经能够支持他们的应用程序。大多数 Linux 发行版以及容器（Docker、Kubernetes、Amazon ECS、Amazon EKS、Amazon ECR）都支持 Arm 架构。客户可以找到常用软件包的 Arm 版本，通过与目前所用相同的机制进行安装。基于不依赖原生 CPU 指令集的解释语言（例如 Java、Node、Python）的应用程序在运行时应该几乎没有变化。采用编译语言（C、C++、GoLang）开发的应用程序将需要重新编译以生成 Arm 二进制文件。这些主流编程语言可出色支持 Arm 架构，而现代代码则通常需要执行简单的 “Make” 命令。参阅 [GitHub 上的入门指南](https://github.com/aws/aws-graviton-gettting-started)以了解更多详细信息。"
    },
    {
        "query":"什么是 Amazon EC2 A1 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 A1 实例是一种通用型实例，由 AWS 定制设计的第一代 AWS Graviton 处理器提供支持。"
    },
    {
        "query":"第一代 AWS Graviton 处理器的规格是怎样的？",
        "intention":"知识问答",
        "reply":"AWS Graviton 处理器由 AWS 利用 Amazon 在为大规模运行的云应用程序构建平台解决方案方面的丰富专业知识定制设计而成。这些处理器基于 64 位 Arm 指令集，采用了 Arm Neoverse 内核和由 AWS 定制设计的硅芯片。这些内核的运行频率为 2.3 GHz。"
    },
    {
        "query":"何时应使用 A1 实例？",
        "intention":"知识问答",
        "reply":"A1 实例可以大幅节省符合可用内存占用的扩展型工作负载的成本。A1 实例适合用于 Web 服务器、容器化微服务以及数据/日志处理等扩展型应用程序。这些实例对 Arm 开发人员社区中的开发人员、爱好者和教育工作者也非常具有吸引力。"
    },
    {
        "query":"为了在 A1 实例上运行，客户是否需要修改应用程序和工作负载？",
        "intention":"知识问答",
        "reply":"所需的更改因应用程序而定。基于解析或运行时编译语言（例如 Python、Java、PHP、Node.js）的应用程序无需更改。其他应用程序可能需要重新编译，而那些不依赖 x86 指令的应用程序通常只需要很少甚至不需要修改。"
    },
    {
        "query":"A1 实例支持哪些操作系统/AMI？",
        "intention":"知识问答",
        "reply":"A1 实例支持下列 AMI：Amazon Linux 2、Ubuntu 16.04.4 或更新版本、Red Hat Enterprise Linux (RHEL) 7.6 或更新版本、SUSE Linux Enterprise Server 15 或更新版本。对于 Fedora、Debian 和 NGINX Plus，也可通过社区 AMI 和 AWS Marketplace 获得更多 AMI 支持。在 A1 实例上启动的受 EBS 支持的 HVM AMI 需要在实例启动时安装 NVMe 和 ENA 驱动程序。"
    },
    {
        "query":"在 M6g 和 A1 实例上运行有哪些具体的 AMI 要求？",
        "intention":"知识问答",
        "reply":"您需要将“arm64”AMI 与 M6g 和 A1 实例配合使用。x86 AMI 与 M6g 和 A1 实例不兼容。"
    },
    {
        "query":"A1 实例与新型 M6g 实例分别应于何时使用？",
        "intention":"知识问答",
        "reply":"A1 实例可以继续为可在多个较小内核上运行并符合可用内存占用的扩展型工作负载带来可观的成本优势。新的 M6g 实例非常适合需要更多计算、内存、网络资源和/或可以受益于跨平台功能纵向扩展的各种应用程序。对于这些应用程序，M6g 实例可实现该实例系列中的最佳性价比。M6g 支持最大 16xlarge 的实例大小（A1 最大支持 4xlarge）、每 vCPU 4GB 内存（A1 支持每 vCPU 2GB 内存），以及最高 25 Gbps 的网络带宽（A1 最高支持 10 Gbps）。"
    },
    {
        "query":"使用 A1 实例的客户拥有哪些不同的存储选项？",
        "intention":"知识问答",
        "reply":"A1 实例默认针对 EBS 进行过优化，可以为加密和未加密 EBS 卷提供高达 3,500 Mbps 的专用 EBS 带宽。A1 实例仅支持 Non-Volatile Memory Express (NVMe) 接口访问 EBS 存储卷。A1 实例不支持 blkfront 接口。"
    },
    {
        "query":"A1 实例支持哪种网络接口？",
        "intention":"知识问答",
        "reply":"A1 实例支持基于 ENA 的增强型联网。借助 ENA，A1 实例可以在一个置放群组内启动的实例之间交付高达 10Gbps 的网络带宽。"
    },
    {
        "query":"A1 实例是否支持 AWS Nitro 系统？",
        "intention":"知识问答",
        "reply":"是的，A1 实例由 [AWS Nitro System](https://aws.amazon.com/cn/ec2/nitro/)（专用硬件和 Nitro 虚拟机监控器的组合）提供支持。"
    },
    {
        "query":"客户为何应选择 EC2 M5 实例而非 EC2 M4 实例？",
        "intention":"知识问答",
        "reply":"与 EC2 M4 实例相比，新的 EC2 M5 实例实现了一致性和安全性，能够为客户提供更高的计算和存储性能、更大的实例大小以及更低的成本。EC2 M5 实例的最大优势在于采用了最新一代 Intel Xeon Scalable 处理器（Skylake-SP 或 Cascade Lake），其性价比相较 M4 最高提高了 20%。M5 内置 AVX-512 支持而 M4 配备的是旧版 AVX2，因此在需要浮点运算的工作负载中，客户能够将性能提高两倍。M5 实例提供了高达 25Gbps 的网络带宽和高达 10Gbps 的专用 Amazon EBS 带宽。借助 EBS 突发功能，M5 实例在较小实例上的联网和 Amazon EBS 性能明显更高。"
    },
    {
        "query":"客户为何应选择 M6i 实例而非 M5 实例？",
        "intention":"知识问答",
        "reply":"Amazon [M6i 实例](https://aws.amazon.com/cn/ec2/instance-types/m6i/)由全核睿频为 3.5 GHz 的第 3 代英特尔至强可扩展处理器（代号 Ice Lake）提供支持，与 M5 实例相比计算性价比提高多达 15%，其全天候运行的内存加密使用 Intel Total Memory Encryption (TME)。Amazon EC2 M6i 实例最先使用小写 “i” 来表示它们是由英特尔提供支持的实例。M6i 实例提供了新的实例大小 (m6i.32xlarge)，它包含 128 个 vCPUs 和 512 GiB 内存，比最大的 M5 实例还多 33%。相对于 M5 实例，它们的每个 vCPU 的内存带宽也要高出多达 20%，使客户能够为数据密集型 AI/ML、游戏、高性能计算 (HPC) 应用程序高效执行实时分析。 M6i 还可为客户提供高达 50 Gbps 的联网速度和 40 Gbps 的带宽以连接 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/)，是 M5 实例的两倍。 M6i 还让客户能够在 32xlarge 大小的实例上使用 [Elastic Fabric Adapter](https://aws.amazon.com/cn/hpc/efa/)，从而在节点间通信中实现低延迟和高扩展。 为了在这些新实例上达到最佳联网性能，可能需要更新 Elastic Network Adapter (ENA) 驱动程序。有关 M6i 的最佳 ENA 驱动程序的更多信息，请参阅[此文章](https://aws.amazon.com/cn/premiumsupport/knowledge-center/migrate-to-gen6-ec2-instance/)。"
    },
    {
        "query":"对 Intel AVX-512 的支持如何为使用 EC2 M5 系列或 M6i 系列的客户带来好处？",
        "intention":"知识问答",
        "reply":"Intel Advanced Vector Extensions 512 (AVX-512) 是适用于最新 Intel Xeon 可扩展处理器的一套新 CPU 指令，可以提高各种工作负载和使用案例（如科学模拟、财务分析、人工智能、机器学习/深度学习、3D 建模和分析、图像和视频处理、加密和数据压缩等）的性能。 Intel AVX-512 能够特殊处理加密算法，从而帮助削减用于加密的性能开销，这意味着使用 EC2 M5 系列或 M6i 系列的客户可以在分布式环境中部署更安全的数据和服务，而不会影响性能。\nM5zn 实例是 M5 通用型实例的一种变体，它由云中最快的 Intel Xeon 可扩展处理器提供支持，具有高达 4.5GHz 的全核 Turbo 频率以及 100Gbps 的联网速度，同时还支持 Amazon EFA。M5zn 实例非常适合游戏、金融应用程序、模拟建模应用程序（例如在汽车、航空、能源和电信行业中使用的应用程序）以及其他高性能计算应用程序等工作负载。\nz1d 实例是内存优化型实例，采用 Intel Xeon 可扩展处理器的高频版本（最高 4.0GHz）以及本地 NVMe 存储。M5zn 实例是通用型实例，采用第二代 Intel Xeon 可扩展处理器的高频版本（高达 4.5GHz）以及高达 100Gbps 的联网速度，同时还支持 EFA。与 z1d 相比，M5zn 实例的性价比更高。"
    },
    {
        "query":"EC2 内存增强型实例有哪些？",
        "intention":"知识问答",
        "reply":"Amazon EC2 内存增强型实例有 3 TiB、6 TiB、9 TiB、12 TiB、18 TiB 或 24 TiB 六种单实例内存规格。这些实例用于运行大型内存数据库，包括 SAP HANA 在云中的生产部署安装。\n具有 3 TiB、6 TiB、9 TiB 和 12 TiB 内存的 EC2 内存增强型实例由配备英特尔 ® 至强 ® Platinum 8176M (Skylake) 处理器的 8 插槽平台提供支持。具有 18 TiB 和 24 TiB 内存的 EC2 内存增强型实例是首款由配备针对任务关键型企业工作负载优化的第二代英特尔 ® 至强 ® 可扩展 (Cascade Lake) 处理器的 8 插槽平台提供支持的 Amazon EC2 实例。EC2 内存增强型实例使用基于 Amazon Elastic Network Adapter (ENA) 的增强型联网，提供最高 100Gbps 的聚合网络带宽，可以实现高网络吞吐量和低延迟。EC2 内存增强型实例默认针对 EBS 进行过优化，支持加密和未加密 EBS 卷。"
    },
    {
        "query":"内存增强型实例是否经过 SAP 认证，可以运行 SAP HANA 工作负载？",
        "intention":"知识问答",
        "reply":"内存增强型实例经过 SAP 认证，可以在生产环境中运行 Business Suite on HANA、下一代 Business Suite S/4HANA、Data Mart Solutions on HANA、Business Warehouse on HANA 和 SAP BW/4HANA。 有关详情，请参阅 [SAP 认证和支持的 SAP HANA 硬件目录](https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN/#/solutions?filters=v:deCertified)。"
    },
    {
        "query":"哪些实例类型可用于内存增强型实例？",
        "intention":"知识问答",
        "reply":"内存增强型实例以裸机实例和虚拟化实例形式提供，这让客户可以选择直接访问底层硬件资源，或者利用虚拟化实例提供的额外灵活性，包括按需和 1 年和 3 年 Savings Plan 购买选项。请在 [EC2 实例类型页面](https://aws.amazon.com/cn/ec2/instance-types/)的“内存优化”部分中查看内存增强型实例的可用选项。"
    },
    {
        "query":"与内存增强型裸机实例相比，使用内存增强型虚拟化实例有哪些好处？",
        "intention":"知识问答",
        "reply":"与内存增强型裸机实例相比，内存增强型虚拟化实例的优势包括：启动/重启时间明显缩短，购买选项灵活（按需、Savings Plan、预留实例、专用主机），可选择租赁类型，提供自助服务选项以及支持更多数量 EBS 卷（27 对 19）。"
    },
    {
        "query":"何时应使用内存增强型裸机实例，何时应使用内存增强型虚拟化实例？",
        "intention":"知识问答",
        "reply":"尽管通常建议使用内存增强型虚拟化实例，但在某些特定情况下，只有内存增强型裸机实例才能运行。这些情况包括 – 使用内存增强型虚拟化实例不支持的操作系统版本时，使用需要在非虚拟化模式下运行以满足许可/支持要求的应用程序时，在使用需要访问硬件功能集的应用程序（例如 Intel VT-x）时，或者在使用自定义虚拟机管理程序（例如 ESXi）时。"
    },
    {
        "query":"如何从内存增强型裸机实例迁移到内存增强型虚拟化实例？",
        "intention":"知识问答",
        "reply":"只需执行几个步骤，您就可以将内存增强型裸机实例迁移到虚拟化实例。1/停止您的实例，2/通过 EC2 API 更改实例和租赁类型，3/启动实例备份。如果您使用 Red Hat Enterprise Linux for SAP 或 SUSE Linux Enterprise Server for SAP，则需要确保您的操作系统和内核版本与内存增强型虚拟化实例兼容。有关更多详细信息，请参阅[将 SAP HANA on AWS 迁移到 EC2 内存增强型实例](https://docs.aws.amazon.com/sap/latest/sap-hana/migrating-hana-to-hm.html)文档。"
    },
    {
        "query":"内存增强型实例提供哪些存储选项？",
        "intention":"知识问答",
        "reply":"内存增强型实例支持使用 Amazon EBS 卷进行存储。内存增强型实例默认经过 EBS 优化，并提供高达 38 Gbps 的存储带宽。"
    },
    {
        "query":"内存增强型实例支持哪种存储接口？",
        "intention":"知识问答",
        "reply":"内存增强型实例通过 [PCI 连接的 NVM Express (NVMe) 接口](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/nvme-ebs-volumes.html)访问 EBS 卷。连接到内存增强型实例的 EBS 卷显示为 NVMe 设备。NVMe 是一种高效的可扩展存储接口，通常用于闪存型 SSD，可以缩短延迟时间，产生更高的磁盘 I/O 和吞吐量。EBS 卷通过 PCI 热插拔安装和卸载。"
    },
    {
        "query":"内存增强型实例支持哪些网络性能？",
        "intention":"知识问答",
        "reply":"内存增强型实例使用弹性网络适配器（ENA）进行联网，默认启用[增强型联网](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/enhanced-networking.html)功能。借助 ENA，内存增强型实例可以使用高达 100Gbps 的网络带宽。"
    },
    {
        "query":"我能否在现有的 Amazon Virtual Private Cloud（Amazon VPC）上运行内存增强型实例？",
        "intention":"知识问答",
        "reply":"您可以在现有的和新的 Amazon VPC 上运行内存增强型实例。\n内存增强型实例使用什么底层管理程序？\n内存增强型实例使用基于核心 KVM 技术的轻量级 Nitro 虚拟机监控器。"
    },
    {
        "query":"内存增强型实例是否启用 CPU 电源管理状态控制？",
        "intention":"知识问答",
        "reply":"是的。您可以在内存增强型实例上配置 C 状态和 P 状态。您可以使用 C 状态来实现较高的睿频频率（高达 4.0Ghz）。您还可以使用 P 状态来减少性能变化，具体方法是固定处于 P1 或更高 P 状态的所有核心（与禁用睿频相似）并始终以基本 CPU 时钟速度运行。"
    },
    {
        "query":"内存增强型实例有哪些购买选项？",
        "intention":"知识问答",
        "reply":"EC2 内存增强型虚拟化实例（例如 u-6tb1.112xlarge）可通过按需、1 年和 3 年 Savings Plan 以及 1 年和 3 年预留实例购买。EC2 内存增强型裸机实例（例如 u-6tb1.metal）仅在 1 年和 3 年预留中作为 EC2 专属主机可供购买。"
    },
    {
        "query":"专属主机的生命周期是多长？",
        "intention":"知识问答",
        "reply":"在您的账户中分配专属主机后，它将做好准备供您随时使用。然后，您可以使用 RunInstances API 按“主机”延迟启动实例，也可通过 API 停止/开始/中断该实例。您可以使用 AWS 管理控制台管理专属主机和实例。"
    },
    {
        "query":"我能否使用 AWS CLI/SDK 启动、停止/开始和终止内存增强型实例？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CLI/开发工具包启动、停止/开始和终止实例。"
    },
    {
        "query":"内存增强型实例支持哪些 AMI？",
        "intention":"知识问答",
        "reply":"支持 ENA 联网的 EBS-backed HVM AMI 可用于内存增强型实例。支持最新的 Amazon Linux、Red Hat Enterprise Linux、SUSE Enterprise Linux Server 和 Windows Server AMI。内存增强型实例上的 SAP HANA 工作负载的操作系统支持包括：SUSE Linux Enterprise Server 12 SP3 for SAP、Red Hat Enterprise Linux 7.4 for SAP、Red Hat Enterprise Linux 7.5 for SAP、SUSE Linux Enterprise Server 12 SP4 for SAP、SUSE Linux Enterprise Server 15 for SAP、Red Had Enterprise Linux 7.6 for SAP。请参阅 [SAP 认证和支持的 SAP HANA 硬件目录](https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN/iaas.html#categories=Amazon%20Web%20Services)，了解有关支持的操作系统的最新详细信息。"
    },
    {
        "query":"是否提供适用于内存增强型实例和 AWS Cloud 的标准 SAP HANA 参考部署框架？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Quick Start 参考 SAP HANA](https://docs.aws.amazon.com/quickstart/latest/sap-hana/welcome.html) 部署并遵循 SAP 的建议，在内存增强型实例上快速部署所有必要的 SAP HANA 构建块，从而实现出色的性能和可靠性。AWS 快速入门采用模块化结构，并且可自定义，使您能够针对自己的实施添加更多功能或进行修改。"
    },
    {
        "query":"何时应使用内存优化型实例？",
        "intention":"知识问答",
        "reply":"内存优化型实例可为内存密集型应用程序（包括内存应用程序、内存数据库、内存分析解决方案、HPC、科学计算以及其他内存密集型应用程序）提供大容量内存。"
    },
    {
        "query":"什么是 Amazon EC2 R6g 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 R6g 实例是由基于 Arm 的 AWS Graviton2 处理器提供支持的下一代内存优化型实例。与 R5 实例相比，R6g 实例的性价比最多可提高 40%。它们在将专用硬件与 Nitro 管理程序集于一体的 [AWS Nitro 系统](https://aws.amazon.com/cn/ec2/nitro/)上构建。"
    },
    {
        "query":"R6g 实例有哪些理想的使用案例？",
        "intention":"知识问答",
        "reply":"R6g 实例为内存优化型工作负载（如实例）提供超高性价比优势，是运行内存优化型工作负载（如开放源数据库、内存缓存和实时大数据分析）的理想选择。客户如果在整个 R 实例系列中部署依托开源软件构建的应用程序，就会发现 R6g 实例是一种颇具吸引力的选择，可以实现该实例系列中的最佳性价比。此外，Arm 开发人员还能直接依托原生 Arm 硬件（而不是交叉编译或仿真）构建应用程序。"
    },
    {
        "query":"R6g 实例上提供了哪些不同的存储选项？",
        "intention":"知识问答",
        "reply":"R6g 实例默认针对 EBS 进行了优化，可以为加密和未加密 EBS 卷提供高达 19000Mbps 的专用 EBS 带宽。R6g 实例仅支持通过 Non-Volatile Memory Express (NVMe) 接口访问 EBS 存储卷。 此外，还可通过 R6gd 实例类型提供具有本地 NVMe 实例存储的选项。"
    },
    {
        "query":"R6g 实例支持哪种网络接口？",
        "intention":"知识问答",
        "reply":"R6g 实例支持基于 ENA 的增强型联网。借助 ENA，R6g 实例可以在一个置放群组内启动的实例之间实现高达 25Gbps 的网络带宽。"
    },
    {
        "query":"为了在 R6g 实例上运行，客户是否需要修改其应用程序和工作负载？",
        "intention":"知识问答",
        "reply":"所需的更改因应用程序而定。客户如果运行依托开源软件构建的应用程序，就会发现 Arm 生态系统高度发达，很可能已经能够支持他们的应用程序。大多数 Linux 发行版以及容器（Docker、Kubernetes、Amazon ECS、Amazon EKS、Amazon ECR）都支持 Arm 架构。客户可以找到常用软件包的 Arm 版本，通过与目前所用相同的机制进行安装。基于不依赖原生 CPU 指令集的解释语言（例如 Java、Node、Python）的应用程序在运行时应该几乎没有变化。采用编译语言（C、C++、GoLang）开发的应用程序将需要重新编译以生成 Arm 二进制文件。这些主流编程语言可出色支持 Arm 架构，而现代代码则通常需要执行简单的 “Make” 命令。参阅 [GitHub 上的入门指南](https://github.com/aws/aws-graviton-gettting-started)以了解更多详细信息。"
    },
    {
        "query":"您为何应选择 R6i 实例而非 R5 实例？",
        "intention":"知识问答",
        "reply":"[Amazon R6i 实例](https://aws.amazon.com/cn/ec2/instance-types/r6i/)由全核睿频为 3.5 GHz 的第 3 代英特尔至强可扩展处理器（Ice Lake）提供支持，与 R5 实例相比计算性价比提高多达 15%，其全天候运行的内存加密使用 Intel Total Memory Encryption (TME)。Amazon EC2 R6i 实例使用小写“i”来表示它们是由英特尔提供支持的实例。R6i 实例提供了新的实例大小（r6i.32xlarge），它包含 128 个 vCPUs 和 1024 GiB 内存，比最大的 R5 实例还多 33%。相对于 R5 实例，它们的每个 vCPU 的内存带宽也要高出多达 20%，使您能够为数据密集型 AI/ML、游戏、高性能计算（HPC）应用程序高效执行实时分析。 R6i 实例还可为您提供高达 50Gbps 的联网速度和 40Gbps 的带宽以连接 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/)，是 R5 实例的两倍。 借助 R6i 实例，您还可以使用 Elastic Fabric Adapter，让客户能够在 32xlarge 和裸机大小的实例上使用 [Elastic Fabric Adapter (EFA)](https://aws.amazon.com/cn/hpc/efa/)，从而在节点间通信中实现低延迟和高扩展。为了在这些新实例上达到最佳联网性能，可能需要更新 Elastic Network Adapter (ENA) 驱动程序。有关适用于 R6i 的最佳 ENA 驱动程序的更多信息，请参阅知识中心上的[“在将我的 EC2 实例迁移到第六代实例之前需要进行哪些操作？”](https://aws.amazon.com/cn/premiumsupport/knowledge-center/migrate-to-gen6-ec2-instance/)。"
    },
    {
        "query":"什么是 Amazon EC2 R5b 实例？",
        "intention":"知识问答",
        "reply":"R5b 实例是内存优化型 R5 实例针对 EBS 进行优化的变体，与相同大小的 R5 实例相比，其 EBS 性能提高了 3 倍。R5b 实例可提供高达 60Gbps 的带宽和 26 万 IOPS 的 EBS 性能，这是 EC2 上最快的数据块存储性能。它们依托将专用硬件与 Nitro 管理程序集于一体的 AWS Nitro 系统构建。"
    },
    {
        "query":"R5b 实例有哪些理想的使用案例？",
        "intention":"知识问答",
        "reply":"R5b 实例非常适合大型关系数据库工作负载，包括 Microsoft SQL Server、SAP HANA、IBM DB2 和 Oracle，它们运行性能密集型应用程序，例如商务平台、ERP 系统和健康记录系统。如果客户希望将对存储性能要求较高的大型本地工作负载迁移到 AWS，会发现 R5b 实例非常适合。"
    },
    {
        "query":"R5b 实例上提供了哪些不同的存储选项？",
        "intention":"知识问答",
        "reply":"R5b 实例默认针对 EBS 进行了优化，可以为加密和未加密 EBS 卷提供高达 6 万 Mbps 的专用 EBS 带宽和 26 万 IOPS。R5b 实例仅支持通过 Non-Volatile Memory Express (NVMe) 接口访问 EBS 存储卷。除 io2 卷之外，其他所有卷类型均支持 R5b。"
    },
    {
        "query":"何时应使用 R5b 实例？",
        "intention":"知识问答",
        "reply":"如果客户运行大型关系数据库和数据分析等工作负载，同时希望利用更高的 EBS 存储网络性能，则可以使用 R5b 实例来提供更高的性能和带宽。通过将工作负载迁移到较小的 R5b 实例，或合并工作负载，减少 R5b 实例数量，客户还可以降低成本。"
    },
    {
        "query":"内存增强型实例提供哪些存储选项？",
        "intention":"知识问答",
        "reply":"内存增强型实例支持使用 Amazon EBS 卷进行存储。内存增强型实例默认针对 EBS 进行过优化，可以为加密和未加密 EBS 卷提供高达 38Gbps 的存储带宽。"
    },
    {
        "query":"什么是 Amazon EC2 X2gd 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 X2gd 实例是由 AWS 设计的基于 Arm 的 AWS Graviton2 处理器提供支持的下一代内存优化型实例。与基于 x86 的 X1 实例相比，X2gd 实例的性价比实现了高达 55% 的提升，并且在 Amazon EC2 中提供最低的每 GiB 内存成本。 它们是依托将专用硬件与 Nitro 虚拟机监控器集于一体的 AWS Nitro System 构建的首个 X 系列实例。"
    },
    {
        "query":"哪些工作负载适合 X2gd 实例？",
        "intention":"知识问答",
        "reply":"X2gd 适合具有兼容 Arm 的内存绑定扩展工作负载（例如 Redis 和 Memcached 内存中数据库）的客户，它们需要低延迟的内存访问，且每个 vCPU 更多的内存也会让它们受益。X2gd 还非常适合 PostgreSQL、MariaDB、MySQL 和 RDS Aurora 等关系数据库。运行 Apache Hadoop、实时分析和实施缓存服务器等内存密集型工作负载的客户将从 X2gd 1:16 的 vCPU 内存比中获益。EDA 后端验证作业等单线程工作负载将从 X2gd 实例的物理内核和更多内存中获益，从而使它们可以将更多工作负载合并到单个实例中。X2gd 实例还具有本地 NVMe SSD 数据块存储，可以通过充当缓存层来提高响应时间。"
    },
    {
        "query":"与 X1、X2i 或 R 系列实例相比，我应该在什么时候使用 X2gd 实例？",
        "intention":"知识问答",
        "reply":"X2gd 实例适用于与 Arm 兼容的内存绑定扩展工作负载，例如内存数据库、内存分析应用程序、开源关系数据库工作负载、EDA 工作负载和大型缓存服务器。X2gd 实例为客户提供 EC2 内每 GB 内存的最低成本，大小最高为 1TiB。X2iezn、X2idn、X2iedn、X1 和 X1e 实例使用 x86 处理器，并适用于内存密集型的企业级扩展工作负载，如 Windows 工作负载、内存数据库（例如 SAP HANA）和关系数据库（例如 OracleDB）。客户可以使用基于 x86 的 X 系列实例获得更大的内存大小，最高可达 4 TiB。R6g 和 R6gd 实例适用于 Web 应用程序、数据库和搜索索引查询等工作负载，这些工作负载在处理大量数据时需要更多的 vCPU。运行内存绑定工作负载（需要小于 1TiB 的内存且依赖 Windows 应用程序等 x86 指令集）及 Oracle 或 SAP 之类应用程序的客户可以利用 R5 和 R6 实例。"
    },
    {
        "query":"何时应使用 X2idn 和 X2iedn 实例？",
        "intention":"知识问答",
        "reply":"X2idn 和 X2iedn 实例由全核睿频高达 3.5 GHz 的第 3 代英特尔至强可扩展处理器驱动，可提供高于同等 X1 实例 50% 的计算性价比。X2idn 和 X2iedn 实例都包括高达 3.8 TB 的本地 NVMe SSD 存储和高达 100 Gbps 的网络带宽，而 X2idn 可提供高达 2 TiB 的内存，X2iedn 可提供高达 4 TiB 的内存。X2idn 和 X2iedn 实例通过了 SAP 认证，非常适合小型到大型传统和内存数据库以及分析之类的工作负载。"
    },
    {
        "query":"何时应使用 X2iezn 实例？",
        "intention":"知识问答",
        "reply":"[X2iezn 实例](https://aws.amazon.com/cn/ec2/instance-types/x2i/)配备了云中最快的英特尔至强可扩展处理器，非常适合需要高单线程性能、高内存 vCPU 比和高速网络的工作负载。X2iezn 实例具有高达 4.5 GHz 的全核睿频，内存与 vCPU 的比为 32:1，与 X1e 实例相比，提供最高 55% 的更高计算性能。X2iezn 实例非常适合 Electronic Design Automation (EDA) 工作负载，如实物验证、静态时序分析、功耗签核和全芯片门级仿真。"
    },
    {
        "query":"X2gd 实例支持哪些操作系统/AMI？",
        "intention":"知识问答",
        "reply":"支持下列 AMI：Amazon Linux 2、Ubuntu 18.04 或更新版本、Red Hat Enterprise Linux 8.2 或更新版本以及 SUSE Enterprise Server 15 或更新版本。客户可以找到通过社区 AMI 和 AWS Marketplace 提供的 Fedora、Debian、NetBSD 和 CentOS 等其他 AMI。对于容器化应用程序，也会提供 Amazon ECS 和 EKS 优化型 AMI。"
    },
    {
        "query":"何时应使用 X1 实例？",
        "intention":"知识问答",
        "reply":"X1 实例适合用于运行内存数据库 (如 SAP HANA) 、大数据处理引擎（如 Apache Spark 或 Presto）以及高性能计算（HPC）应用程序。X1 实例已经过 SAP 认证，可在 AWS Cloud 中运行新一代 Business Suite S/4HANA、Business Suite on HANA (SoH)、Business Warehouse on HANA (BW) 以及 Data Mart Solutions on HANA 的生产环境。"
    },
    {
        "query":"X1 及 X1e 实例是否支持 CPU 电源管理状态控制？",
        "intention":"知识问答",
        "reply":"是的。您可以为 x1e.32xlarge、x1e.16xlarge、x1e.8xlarge、x1.32xlarge 及 x1.16xlarge 实例配置 C 状态和 P 状态。您可以使用 C 状态来实现较高的睿频频率 (使用单核或双核睿频处理后频率最高可达 3.1Ghz)。您还可以使用 P 状态来减少性能变化，具体方法是固定处于 P1 或更高 P 状态的所有核心（与禁用睿频相似）并始终以基本 CPU 时钟速度运行。\nx1e.32xlarge 还支持 Windows Server 2012 R2 和 2012 RTM。此外，x1e.xlarge、x1e.2xlarge、x1e.4xlarge、x1e.8xlarge、x1e.16xlarge 和 x1.32xlarge 还支持 Windows Server 2012 R2、2012 RTM 和 64 位 2008 R2（不支持 Windows Server 2008 SP2 及更早版本），并且 x1.16xlarge 将支持 Windows Server 2012 R2、2012 RTM、64 位 2008 R2、64 位 2008 SP2 和 64 位 2003 R2（不支持 32 位版本的 Windows Server）。"
    },
    {
        "query":"是否提供适用于内存增强型实例和 AWS 的标准 SAP HANA 参考部署框架？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Launch Wizard for SAP](https://docs.aws.amazon.com/launchwizard/latest/userguide/what-is-launch-wizard-sap.html) 或 [AWS Quick Start 参考 SAP HANA](https://docs.aws.amazon.com/quickstart/latest/sap-hana/welcome.html) 部署，并遵循 AWS 和 SAP 的建议在内存增强型实例上快速部署所有必要的 SAP HANA 构建块，从而实现出色的性能和可靠性。"
    },
    {
        "query":"为什么定价页面上不再显示 M1、C1、CC2 和 HS1 实例？",
        "intention":"知识问答",
        "reply":"这些实例已被移至[上一代实例](https://aws.amazon.com/cn/ec2/previous-generation/)页面。"
    },
    {
        "query":"这些上一代实例是否仍受支持？",
        "intention":"知识问答",
        "reply":"是的。上一代实例仍被完全支持。"
    },
    {
        "query":"是否仍然能使用/增加更多上一代实例？",
        "intention":"知识问答",
        "reply":"是的。上一代实例仍然可通过我们的 API、CLI 和 EC2 管理控制台界面提供，有按需实例、预留实例和 Spot 实例等类型。"
    },
    {
        "query":"上一代实例是否要被删除？",
        "intention":"知识问答",
        "reply":"不会。您的 C1、C3、CC2、CR1、G2、HS1、M1、M2、M3、R3 和 T1 实例仍然功能完备，不会因为此更改而被删除。"
    },
    {
        "query":"上一代实例是否将很快被中止使用？",
        "intention":"知识问答",
        "reply":"目前尚无终止上一代实例的计划。然而，随着技术的快速发展，最新一代的实例一般会提供最佳价格性能，我们鼓励客户利用技术进步。"
    },
    {
        "query":"我购买的用作预留实例的上一代实例是否会受到影响或改变？",
        "intention":"知识问答",
        "reply":"不会。您的预留实例不会发生改变，且上一代实例未停止使用。"
    },
    {
        "query":"什么是密集存储实例？",
        "intention":"知识问答",
        "reply":"密集存储实例专用于需要对超大型数据集合进行高速的连续读写访问的工作负载，例如 Hadoop 分布式计算、大规模并行处理数据仓库以及日志处理应用程序。与其他 EC2 实例相比，密集存储实例提供了最佳的 GB 存储价格比和磁盘吞吐量价格比。"
    },
    {
        "query":"密集存储实例与高 I/O 实例相比如何？",
        "intention":"知识问答",
        "reply":"高 I/O 实例（Im4gn、Is4gen、I4i、I3、I3en）专用于除要求中等存储密度外还要求低延迟和高随机 I/O 的工作负载，与其他 EC2 实例类型相比，还提供最优 IOPS 性价比。密集存储实例（D3、D3en、D2）和 HDD 存储实例（H1）针对以下应用程序进行过优化：需要对超大型数据集进行高速的连续读/写访问以及与之相应的低成本存储；与其他 EC2 实例相比，提供了最优 GB 存储性价比和磁盘吞吐量性价比。"
    },
    {
        "query":"密集存储实例和 HDD 存储实例可以提供多少磁盘吞吐量？",
        "intention":"知识问答",
        "reply":"当前这一代最大的密集 HDD 存储实例 d3en.12xlarge 可以提供高达 6.2GiB/s 的读取磁盘吞吐量和 6.2GiB/s 的写入磁盘吞吐量（数据块大小为 128k）。请参阅产品详细信息页面，了解其他性能信息。为了确保您的 D2、D3 和 D3en 实例可以在 Linux 上提供最佳磁盘吞吐量性能，我们建议您使用最新版 Amazon Linux AMI，或者内核版本为 3.8 或更高版本的支持永久授权（Xen 数据块环协议的扩展，可显著提高磁盘吞吐量和可扩展性）的其他 Linux AMI。"
    },
    {
        "query":"密集存储实例和 HDD 存储实例是否提供任何失效转移机制或冗余能力？",
        "intention":"知识问答",
        "reply":"D2 和 H1 实例提供硬件故障通知。与所有实例存储一样，密集 HDD 存储卷只在实例生命周期内存在。因此，我们建议您构建冗余度（如 RAID 1/5/6）或使用支持冗余和容错的文件系统（如 HDFS 和 MapR-FS）。您还可以定期将数据备份到更多数据存储解决方案，例如 Amazon EBS 或 Amazon S3。"
    },
    {
        "query":"密集 HDD 存储实例与 Amazon EBS 有什么区别？",
        "intention":"知识问答",
        "reply":"Amazon EBS 为 Amazon EC2 提供简单、弹性、可靠（重复）和永久的数据块级别的存储，同时提取使用中的底层存储介质的详细信息。具有本地 HDD 或 NVMe 存储的 Amazon EC2 实例提供直接附加、高性能的存储构建数据块，可用于多种存储应用程序。密集存储实例专用于希望对本地存储上的大型数据集合进行高速的连续读/写访问的客户，如用于 Hadoop 分布式计算和大规模并行处理数据仓库。"
    },
    {
        "query":"能否将密集 HDD 存储实例作为 Amazon EBS 优化实例启动？",
        "intention":"知识问答",
        "reply":"默认情况下，每种 HDD 存储实例类型（H1、D2、D3 和 D3en）都针对 EBS 进行了优化。因为此功能始终处于启用状态，因此将其中某个实例作为 EBS 优化实例显式启动不会对实例的行为产生任何影响。有关更多信息，请参阅 [Amazon EBS 优化实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSOptimized.html)。"
    },
    {
        "query":"能否将 D2 实例作为 Amazon EBS 优化实例启动？",
        "intention":"知识问答",
        "reply":"默认情况下，每种 D2 实例类型都针对 EBS 进行了优化。D2 实例所拥有的 500 Mbps 到 4000 Mbps EBS 连接能力超过了提供给实例的一般用途网络吞吐量。因为这是 D2 实例与生俱来的能力，因此将 D2 实例作为 EBS 优化实例显式启动不会对实例的行为产生任何影响。"
    },
    {
        "query":"EC2 Classic 中是否提供了密集存储实例？",
        "intention":"知识问答",
        "reply":"当前这一代密集存储实例（D2 实例）既可使用 EC2 Classic 启动，也可使用 Amazon VPC 启动。但是，通过将密集存储实例启动到 VPC 中，您可以利用一些只能在 Amazon VPC 平台上使用的功能，例如，启用增强联网功能、向您的实例分配多个私有 IP 地址，或更改您的实例的安全组。有关使用 VPC 的优势的更多信息，请参阅 [Amazon EC2 和 Amazon Virtual Private Cloud](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html) (Amazon VPC)。您可以执行迁移步骤来将资源从 EC2-Classic 迁移到 Amazon VPC。有关更多信息，请参阅[将 Linux 实例从 EC2-Classic 迁移到 VPC](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html)。"
    },
    {
        "query":"什么是高 I/O 实例？",
        "intention":"知识问答",
        "reply":"高 I/O 实例使用 NVMe 本地实例存储，为应用程序提供性能极高、延迟极低的 I/O 能力，最适合需要数百万 IOPS 的应用程序。与集群实例相似，高 I/O 实例可以通过集群放置组进行集群化，来实现低延迟联网功能。"
    },
    {
        "query":"Amazon EC2 的所有功能是否都可用于高 I/O 实例？",
        "intention":"知识问答",
        "reply":"高 I/O 实例支持 Amazon EC2 的所有功能。Im4gn、Is4gen、I4i、I3 和 I3en 实例提供仅限 NVMe 的存储，上一代 I2 实例则允许传统的 blkfront 存储访问。"
    },
    {
        "query":"AWS 有其他数据库和大数据服务。何时或者为什么要使用高 I/O 实例？",
        "intention":"知识问答",
        "reply":"高 I/O 实例是需要访问数百万低延迟 IOPS 的应用程序的理想选择，并能够利用管理数据冗余与可用性的数据存储和架构。示例应用程序包括：:"
    },
    {
        "query":"高 I/O 实例是否提供任何失效转移机制或冗余能力？",
        "intention":"知识问答",
        "reply":"与其他 Amazon EC2 实例类型相似，Im4gn、Is4gen、I4i、I3 和 I3en 实例上的实例存储在实例的生命周期内均保留。客户应当在其应用程序内构建恢复能力。我们建议使用支持冗余和容错功能的数据库和文件系统。客户应当定期将数据备份到 Amazon S3，以提高数据持久性。"
    },
    {
        "query":"高 I/O 实例是否支持 TRIM？",
        "intention":"知识问答",
        "reply":"TRIM 命令可以让操作系统告知 SSD 哪些数据块已不再被视为正在使用，而可以在内部被擦除。如果没有 TRIM，以后对受影响数据块的写入操作会显著变慢。Im4gn、Is4gen、I4i、I3 和 I3en 实例支持 TRIM。"
    },
    {
        "query":"D3 和 D3en 实例与 D2 实例相比如何？",
        "intention":"知识问答",
        "reply":"D3 和 D3en 实例在以下计算、存储和网络属性方面提供优于 D2 的规格："
    },
    {
        "query":"D3 和 D3en 实例是否会加密存储卷和网络流量？",
        "intention":"知识问答",
        "reply":"会；写入存储卷的数据将使用 AES-256-XTS 进行静态加密。默认情况下，使用 256 位密钥对同一 VPC 或对等 VPC 中 D3 和 D3en 实例之间的网络流量进行加密。"
    },
    {
        "query":"系统终止时我的数据会发生什么情况？",
        "intention":"知识问答",
        "reply":"存储于本地实例存储中的数据仅在实例有效期间保留。不过，存储在 Amazon EBS 卷上的数据将独立于实例的生命周期保留下来。因此，我们建议您将本地实例存储用于临时数据，而对于需要保存较长时间的数据，我们建议您使用 Amazon EBS 卷，或将数据备份到 Amazon S3。如果将 Amazon EBS 卷用作根分区，而您希望在实例生命周期外保留 Amazon EBS 卷，则需要将 Delete On Terminate 旗标设为“N”。"
    },
    {
        "query":"Amazon EBS 卷预计可以给我带来什么样的性能？",
        "intention":"知识问答",
        "reply":"Amazon EBS 提供当前一代的四种卷类型，且被分为两大类：适用于交易型工作负载的 SSD 型存储和适用于吞吐量密集型工作负载的 HDD 型存储。这些卷类型的性能特点和价格各不相同，您可根据应用程序要求定制您所需的存储性能和相应费用。有关更多信息，请参阅 [Amazon EBS 概述](https://aws.amazon.com/cn/ebs/details/)。有关性能的更多信息，请参阅[“Amazon EC2 用户指南”中的“EBS 性能”部分](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSPerformance.html)。"
    },
    {
        "query":"什么是吞吐量优化型 HDD（st1）和 Cold HDD（sc1）卷类型？",
        "intention":"知识问答",
        "reply":"ST1 卷由普通硬盘 (HDD) 提供支持，非常适用于频繁访问且拥有大型数据集和 I/O 的吞吐量密集型工作负载，例如 MapReduce、Kafka、日志处理、数据仓库以及 ETL 工作负载。这些卷提供吞吐量方面的性能 (以 MB/s 为单位)，能够突增至每 TB 250MB/s，其中基准吞吐量为每 TB 40MB/s，最大吞吐量为每卷 500MB/s。ST1 的设计目的是在 99% 的时间内提供预期的吞吐量性能，且拥有的 I/O 点数足以支持以突增速率进行全卷扫描。\nSC1 卷由普通硬盘（HDD）提供支持，能为所有 EBS 卷类型提供最低的每 GB 成本。它非常适用于非频繁访问且拥有大型冷数据集的工作负载。与 st1 类似，sc1 也提供突增模型：这些卷能突增至每 TB 80MB/s，其中基准吞吐量为每 TB 12MB/s，最大吞吐量为每卷 250MB/s。对于非频繁访问的数据，sc1 提供极其经济实惠的存储。SC1 的设计目的是在 99% 的时间内提供预期的吞吐量性能，且拥有的 I/O 点数足以支持以突增速率进行全卷扫描。\n为了最大限度地提高 st1 和 sc1 的性能，我们推荐您使用 [EBS 优化型 EC2 实例](https://aws.amazon.com/cn/ebs/features/#Amazon_EBS-Optimized_instances)。"
    },
    {
        "query":"我应该选择哪种卷？",
        "intention":"知识问答",
        "reply":"Amazon EBS 提供两种主要存储类别：适用于交易型工作负载的 SSD 型存储（性能主要取决于 IOPS），以及适用于吞吐量密集型工作负载的 HDD 型存储（性能主要取决于吞吐量，以 MB/s 为单位）。SSD 型卷专用于事务型和 IOPS 密集型数据库工作负载、启动卷以及需要高 IOPS 的工作负载。SSD 型卷包括预置 IOPS SSD（io1 和 io2）和通用型 SSD（gp2 和 gp3）。HDD 型卷专用于吞吐量密集型和大数据工作负载、大型 I/O 以及连续 I/O 模式。HDD 型卷包括吞吐量优化型 HDD（st1）和 Cold HDD（sc1）。有关更多信息，请参阅 [Amazon EBS 概述](https://aws.amazon.com/cn/ebs/details/)。"
    },
    {
        "query":"是否支持多个实例访问一个卷？",
        "intention":"知识问答",
        "reply":"是的，您可以在 EBS 预置 IOPS io1 卷上启用多重挂载功能，从而可以将卷同时挂载到同一可用区内最多 16 个基于 Nitro 的 EC2 实例。有关 Amazon EBS 多重挂载的更多信息，请参阅 [EBS 产品页面](https://aws.amazon.com/cn/ebs/)。"
    },
    {
        "query":"是否可以使用常规的 Amazon S3 API 访问我的 EBS 快照？",
        "intention":"知识问答",
        "reply":"不能，只能通过 Amazon EC2 API 访问 EBS 快照。"
    },
    {
        "query":"是否需要卸载卷才能拍摄快照？ 是否需要完成快照的拍摄才能重新使用卷？",
        "intention":"知识问答",
        "reply":"否，可以在卷挂载和使用期间实时拍摄快照。不过，快照只能捕获已写入 Amazon EBS 卷的数据，可能不包含应用程序或操作系统已在本地缓存的数据。为了确保能为实例连接的卷获得一致的快照，我们建议先彻底地断开卷连接，再发出快照命令，然后重新连接卷。对于用作根设备的 Amazon EBS 卷，我们建议先关闭机器，以便能拍摄完整的快照。"
    },
    {
        "query":"快照是否进行版本控制？ 能否读取旧版的快照来执行时间点恢复？",
        "intention":"知识问答",
        "reply":"每个快照都会获得一个唯一的识别符，客户可以根据任何现有的快照创建卷。"
    },
    {
        "query":"我的 Amazon EBS 共享快照的用户是否可以更改我的数据？",
        "intention":"知识问答",
        "reply":"有权根据您的共享快照创建卷的用户首先会将该快照复制到其账户中。用户可以修改自己的数据副本，但您原始快照中的数据，以及由其他用户从您原始快照创建的任何其他卷中的数据将保持不变。"
    },
    {
        "query":"如何发现已与我共享的 Amazon EBS 快照？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 管理控制台“快照”部分的查看下拉列表中选择“私有快照”来查找已与您共享的快照。此部分将列出您自己的快照，以及他人与您共享的快照。"
    },
    {
        "query":"如何了解哪些 Amazon EBS 快照是全局共享的？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 管理控制台“快照”部分的查看下拉列表中选择“公有快照”来查找全局共享的快照。"
    },
    {
        "query":"是否为 Amazon EBS 卷和快照提供加密？",
        "intention":"知识问答",
        "reply":"是的。EBS 提供无缝的数据卷和快照加密。EBS 加密使您能够更好地满足安全性和加密合规性要求。"
    },
    {
        "query":"如何找到 Amazon 公用数据集列表？",
        "intention":"知识问答",
        "reply":"我们的[公用数据集资源中心](https://registry.opendata.aws/)提供有关公用数据集的所有信息。您也可以在 AWS 管理控制台中，从 Snapshots 部分的查看下拉列表中选择 Amazon Snapshots 来获取公有数据列表。"
    },
    {
        "query":"哪里有 EBS 的详细介绍？",
        "intention":"知识问答",
        "reply":"请参阅 [Amazon EBS 常见问题](https://aws.amazon.com/cn/ebs/faqs/)。"
    },
    {
        "query":"如何从 Amazon EC2 实例访问文件系统？",
        "intention":"知识问答",
        "reply":"要访问您的文件系统，您需要使用标准 Linux 挂载命令和文件系统的 DNS 名称将文件系统挂载到基于 Linux 的 Amazon EC2 实例上。挂载完成后，您就可以像使用本地文件系统一样，使用您的文件系统中的文件和目录。\nAmazon EFS 使用 NFSv4.1 协议。有关从 Amazon EC2 实例访问文件系统的方法，请参阅 [Amazon EFS 入门指南](http://docs.aws.amazon.com/efs/latest/ug/gs-mount-fs-on-ec2instance-and-test.html)中的分步示例。"
    },
    {
        "query":"Amazon EFS 支持哪些类型的 Amazon EC2 实例和 AMI？",
        "intention":"知识问答",
        "reply":"Amazon EFS 兼容所有类型的 Amazon EC2 实例，且可以从基于 Linux 的 AMI 进行访问。您可以将不同类型的实例关联到一个文件系统。有关从 Amazon EC2 实例访问文件系统的方法，请参阅 [Amazon EFS 入门指南](http://docs.aws.amazon.com/efs/latest/ug/gs-mount-fs-on-ec2instance-and-test.html)中的分步示例。"
    },
    {
        "query":"如何将数据加载到文件系统？",
        "intention":"知识问答",
        "reply":"您可以从您的 Amazon EC2 实例或本地数据中心服务器将数据加载到 Amazon EFS 文件系统。\nAmazon EFS 文件系统可以挂载在 Amazon EC2 实例上，因此，您也可以从 Amazon EFS 读取和写入 Amazon EC2 实例能够访问的所有数据。要加载当前未存储在 Amazon 云中的数据，您可以使用目前用于向 Amazon EC2 传输文件的方式，例如 Secure Copy (SCP)。\n此外，Amazon EFS 文件系统还可以挂载在本地服务器上，因此，您可以使用标准 Linux 工具从 Amazon EFS 读取和写入本地服务器能够访问的所有数据。有关从本地服务器访问文件系统的更多信息，请参阅“Amazon EFS 常见问题”页面的[本地访问](https://aws.amazon.com/cn/efs/faq/#On-premises_Access)部分。\n有关将数据迁移到 Amazon 云的更多信息，请参阅[云数据迁移](https://aws.amazon.com/cn/cloud-data-migration/)页面。"
    },
    {
        "query":"如何从 VPC 外访问文件系统？",
        "intention":"知识问答",
        "reply":"您 VPC 内的 Amazon EC2 实例可以直接访问您的文件系统，而 VPC 外的 Amazon EC2 Classic 实例可以通过 [ClassicLink](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-classiclink.html) 挂载文件系统。本地服务器可以通过 [AWS Direct Connect](https://aws.amazon.com/cn/directconnect/) 连接将文件系统挂载到 VPC。"
    },
    {
        "query":"一个文件系统可以连接多少个 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"Amazon EFS 支持一个到数千个 Amazon EC2 实例同时连接一个文件系统。"
    },
    {
        "query":"哪里有 EFS 的详细介绍？",
        "intention":"知识问答",
        "reply":"您可以访问 [Amazon EFS 常见问题](https://aws.amazon.com/cn/efs/faq/)页面。"
    },
    {
        "query":"Amazon EC2 NVMe 实例存储上保存的数据是否经过加密？",
        "intention":"知识问答",
        "reply":"是的，存储到 [AWS Nitro](https://aws.amazon.com/cn/ec2/nitro/) 硬件模块上的所有数据均经过加密，然后才会被写入到通过 NVMe 实例存储提供的本地连接 SSD 上。"
    },
    {
        "query":"加密 Amazon EC2 NVMe 实例存储时采取何种加密算法？",
        "intention":"知识问答",
        "reply":"Amazon EC2 NVMe 实例存储采用 XTS-AES-256 块密码算法。"
    },
    {
        "query":"加密密钥对于每个实例是唯一的，还是对于特定 NVMe 实例存储设备是唯一的？",
        "intention":"知识问答",
        "reply":"加密密钥是在 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 硬件模块中安全生成的，对于每个获得 EC2 实例的 NVMe 实例存储设备是唯一的。"
    },
    {
        "query":"NVMe 实例存储的加密密钥的有效期是多久？",
        "intention":"知识问答",
        "reply":"每当对存储进行重新分配，包括执行停止和终止实例操作时，所有密钥都将被销毁，不可恢复。"
    },
    {
        "query":"可以禁用 NVMe 实例存储加密吗？",
        "intention":"知识问答",
        "reply":"不可以，NVMe 实例存储加密始终开启，无法禁用。"
    },
    {
        "query":"I3 和 I3en 的公开 IOPS 性能数据包括数据加密吗？",
        "intention":"知识问答",
        "reply":"是的，Im4gn、Is4gen、I4i、I3 和 I3en NVMe 实例存储的 [IOPS 数据记录](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/storage-optimized-instances.html)中包括加密。"
    },
    {
        "query":"Amazon EC2 NVMe 实例存储是否支持 AWS Key Management Service (KMS)？",
        "intention":"知识问答",
        "reply":"不支持，NVMe 实例存储上的磁盘加密不支持和 AWS KMS 系统集成。客户不能将自己的密钥用于 NVMe 实例存储。"
    },
    {
        "query":"什么是 ENA Express？",
        "intention":"知识问答",
        "reply":"ENA Express 是 Elastic Network Adapter 的增强功能，它将可扩展可靠数据报（SRD）协议引入了传统的 TCP 和 UDP 网络。ENA Express 对应用程序透明，提高了单流带宽并减少了吞吐量密集型工作负载的尾延迟。  \n   \n 问：ENA Express 的工作原理是什么？  \n   \n 配置后，ENA Express 在可用区（AZ）中的任意两个受支持实例之间工作。ENA Express 检测到 EC2 实例之间的兼容性，并在两个通信实例均启用 ENA Express 后建立 SRD 连接。建立连接后，流量可以利用 SRD 及其性能优势。"
    },
    {
        "query":"应该在何时使用 ENA Express？",
        "intention":"知识问答",
        "reply":"ENA Express 最适合需要高单流吞吐量的应用程序，例如分布式存储系统和实时媒体编码。这些工作负载需要较高的单流带宽和较低的尾延迟。"
    },
    {
        "query":"如何启用 ENA Express？",
        "intention":"知识问答",
        "reply":"可以在每个 ENI 的基础上启用 ENA Express。将网卡连接到实例或运行修改命令时，可以启用 ENA Express。必须在两个通信 ENI 上启用 ENA Express 才能与其建立点对点通信。此外，如果您使用巨型帧，则必须将最大 MTU 调整为 8900 才能使用 ENA Express。  \n   \n 问：ENA Express 支持哪些协议？\nENA Express 默认支持 TCP。可以选择通过 API 参数或在管理控制台中启用 UDP。"
    },
    {
        "query":"支持哪些实例？",
        "intention":"知识问答",
        "reply":"C6gn.16xl 支持 ENA Express。接下来几个月将会陆续添加更多受支持的实例类型和大小。  \n    \n 问：Elastic Fabric Adapter (EFA) 和 ENA Express 有什么区别？\nEFA 是为 HPC 和 ML 应用程序构建的网络接口，它还可以利用 SRD 协议。EFA 需要不同的网络编程模型，它使用 LibFabric 接口将通信传递给 ENI。与 EFA 不同，ENA Express 可以帮助您在 TCP 和 UDP 上透明地运行应用程序。此外，ENA Express 允许可用区（AZ）内通信，而 EFA 目前仅限于同一子网内的通信。\n问：如果我在一个实例上运行 ENA Express，而它正在与另一个不支持 ENA Express 或未在 ENI 上启用它的实例通信，会发生什么情况？\nENA Express 将检测另一个实例上是否已启用 ENA Express。如果该实例不支持或未启用 ENA Express，您的实例将回退到正常的 ENA 操作。在这种情况下，您将无法获得任何 SRD 性能优势，但也不会受到不良影响。\n问：支持哪些操作系统？\nSRD 功能将在所有操作系统上受支持，但请注意，ENA Express 监控指标将仅在最新的 Amazon Linux AMI 中的 EthTool 上可用，或者通过从 GitHub 安装 ENA 驱动程序版本 2.8.0 或更高版本可用，所有操作系统将来都支持这些指标。\n问：有哪些监控工具可用于跟踪此情况？  \n   \n 除了使用 SRD 实际发送和接收的数据包之外，ENA Express 还提供 EthTool 计数器来跟踪符合 SRD 传输条件的数据包。此外，EthTool 将支持基于百分比的 SRD 资源利用率指标，让您深入了解何时应该考虑扩展您的架构。最后，布尔值将指示 ENA Express 和 UDP 协议的开启和关闭状态。\n问：ENA Express 在哪里可用？  \n   \n ENA Express 可在所有商业区域使用。它可用于在同一可用区内的任意两个已启用实例之间建立通信。\n问：运行 ENA Express 是否需要支付额外费用？\n不需要，ENA Express 是免费使用的。"
    },
    {
        "query":"为什么应该使用 EFA？",
        "intention":"知识问答",
        "reply":"EFA 让紧密耦合的 HPC 应用程序具备云的可扩展性、灵活性和弹性。使用 EFA 之后，紧密耦合的 HPC 应用程序可以获得比传统 TCP 通道更低、更一致的延迟和更高的吞吐量，因此能更好地进行扩展。EFA 支持可以动态、按照需要在任何受支持的 EC2 实例上启动，无需进行预留，因此能够灵活地响应不断变化的业务/工作负载优先级。"
    },
    {
        "query":"使用 EFA 能够让哪些类型的应用程序获益？",
        "intention":"知识问答",
        "reply":"HPC 应用程序将计算工作负载分布在一组实例中以进行并行处理。HPC 应用程序示例包括计算流体动力学（CFD）、坠毁模拟和天气模拟。HPC 应用程序通常使用消息传递接口 (MPI) 编写，对于实例间通信的延迟和带宽具有严格的要求。EFA 有益于使用 MPI 的应用程序和其他支持 libfabric 通信堆栈的 HPC 中间件。"
    },
    {
        "query":"EFA 通信的原理是什么？",
        "intention":"知识问答",
        "reply":"EFA 设备提供所有 ENA 设备功能，以及一个新的 OS 绕过硬件接口，允许用户空间应用程序直接与硬件提供的可靠传输功能通信。大部分应用程序都会使用现有中间件（例如 MPI）与 EFA 连接。AWS 与多家中间件提供商合作，确保支持 EFA 的 OS 绕过功能。请注意，使用 OS 绕过功能的通信仅限于虚拟私有云（VPC）的单个子网中的实例。"
    },
    {
        "query":"哪些实例类型支持 EFA？",
        "intention":"知识问答",
        "reply":"EFA 目前支持以下实例大小：m7g.16xlarge、m7g.metal、m6a.48xlarge、m6i.32xlarge、m6i.metal、m6id.32xlarge、m6id.metal、m6idn.32xlarge、m6idn.metal、m6in.32xlarge、m6in.metal、m5n.24xlarge、m5dn.24xlarge、m5n.metal、m5dn.metal、r7g.16xlarge、r7g.metal、r6idn.32xlarge、r6idn.metal、r6in.32xlarge、r6in.metal、r6a.48xlarge、r6a.metal、r6i.32xlarge、r6i.metal、r6id.32xlarge、r6id.metal、r5n.24xlarge、r5dn.24xlarge、r5n.metal、r5dn.metal、x2idn.32xlarge、x2iedn.32xlarge、c7g.16xlarge、c7g.metal、c7gn.16xlarge、c6a.48xlarge、c6i.32xlarge、c6i.metal、c6id.32xlarge、c6id.metal、c6in.32xlarge、c6in.metal、c5n.18xlarge、c5n.metal、p3dn.24xlarge、i3en.24xlarge、i3en.metal、hpc6a.48xlarge、hpc6i.32xlarge、hpc7g.4xlarge、hpc7g.8xlarge 和 hpc7g.16xlarge。"
    },
    {
        "query":"EFA ENI 和 ENA ENI 有什么区别？",
        "intention":"知识问答",
        "reply":"ENA ENI 提供支持 VPC 网络所需的传统 IP 网络功能。EFA ENI 提供 ENA ENI 的所有功能，并为应用程序直接与 EFA ENI 通信提供硬件支持，而不需要使用扩展编程接口的实例内核（OS 绕过通信）。由于 EFA ENI 具备这些高级功能，所以只能在启动时或在停止的实例上进行连接。"
    },
    {
        "query":"在实例上启用 EFA 需要满足哪些先决条件？",
        "intention":"知识问答",
        "reply":"EFA 支持可以在启动实例时启用，或者添加至已停止的实例。EFA 设备无法添加至正在运行的实例。"
    },
    {
        "query":"此功能包含哪些联网功能？",
        "intention":"知识问答",
        "reply":"目前，我们使用 SR-IOV（单一根 I/O 虚拟化）支持增强型联网功能。SR-IOV 是一种设备虚拟化方法，与传统实现相比，它不仅能提更高的 I/O 性能，同时还能降低 CPU 利用率。对于受支持的 Amazon EC2 实例，此功能可提高每秒数据包数 (PPS) 性能、缩短实例间的延迟，并大大降低网络抖动。"
    },
    {
        "query":"为什么应该使用增强型联网？",
        "intention":"知识问答",
        "reply":"如果您的应用程序可从高每秒数据包性能和/或低延迟联网中受益，增强型联网将显著提高性能、性能一致性以及可扩展性。"
    },
    {
        "query":"如何在受支持的实例上启用增强型联网？",
        "intention":"知识问答",
        "reply":"要启用此功能，您必须使用合适的驱动程序来启动 HVM AMI。作为[最新一代](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#AvailableInstanceTypes)列出的实例使用 ENA 来增强联网功能。默认情况下，Amazon Linux AMI 同时包括这两种驱动程序。对于不包括这两种驱动程序的 AMI，您需要根据计划使用的实例类型下载并安装相应的驱动程序。可以按照 Linux 或 Windows 说明在默认不包含 SR-IOV 驱动程序的 AMI 中启用 Enhanced Networking。仅 Amazon VPC 支持增强型联网。"
    },
    {
        "query":"为什么只有 Amazon VPC 支持增强型联网？",
        "intention":"知识问答",
        "reply":"通过 Amazon VPC，我们可以为您提供许多无法在 EC2-Classic 中实现的高级联网功能。增强型联网是可通过 Amazon VPC 实现的另一项功能。"
    },
    {
        "query":"哪些实例类型支持增强型联网？",
        "intention":"知识问答",
        "reply":"根据您的实例类型，您可以使用以下机制之一来启用增强型联网：\nIntel 82599 虚拟功能（VF）接口 – 对于受支持的实例类型，Intel 82599 虚拟功能接口支持高达 10 Gbps 的网络速度。C3、C4、D2、I2、M4（m4.16xlarge 除外）和 R3 实例使用 Intel 82599 VF 接口实现增强联网。\nElastic Network Adapter (ENA) – 对于支持的实例类型，Elastic Network Adapter (ENA) 最多支持 200 Gbps 的网络速度。列为[最新一代](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-types.html#current-gen-instances)的实例使用 ENA 实现增强的联网，小于 m4.16xlarge 的 C4、D2 和 M4 实例除外。  \n   \n 问：多网卡 EC2 实例是什么意思？ 为什么需要它们？  \n   \n 新一代 EC2 实例使用 Nitro 网卡进行 VPC 数据平面卸载。为了提供更高的网络带宽和改进的数据包速率性能，您可以将特定 EC2 实例配置为使用多个网卡进行数据包处理，最终提高整体系统性能。  \n   \n 问：哪些实例类型支持多个网卡？  \n   \n 加速型实例（例如 p4d.24xlarge）和网络优化型实例（例如 c6in.32xlarge）支持多个网卡。有关支持多个网卡的实例的完整列表，请参阅[弹性网络接口](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html)。  \n   \n 问：多网卡实例可以启动的默认网络接口数量是多少？  \n   \n 这取决于实例类型。p4 等加速型实例可以扩展到每个网卡 15 个网络接口。高网络实例（例如最近推出的 c6in 实例）支持在两个网卡上平均分配的 14 个网络接口（每个网卡各 7 个）。有关每个网卡的网络接口规模的信息，请参阅[网卡](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#network-cards)。"
    },
    {
        "query":"Elastic Load Balancing 服务提供了哪些负载均衡选项？",
        "intention":"知识问答",
        "reply":"Elastic Load Balancing 现有两种负载均衡器，这两种负载均衡器均具备高可用性、自动扩展功能和可靠的安全性。其中一种是 [Classic Load Balancer](https://aws.amazon.com/cn/elasticloadbalancing/classicloadbalancer/)，可基于应用程序或网络级信息路由流量；另一种是 [Application Load Balancer](https://aws.amazon.com/cn/elasticloadbalancing/applicationloadbalancer/)，可基于包括请求内容的高级应用程序级信息路由流量。"
    },
    {
        "query":"何时应使用 Classic Load Balancer，何时应使用 Application Load Balancer？",
        "intention":"知识问答",
        "reply":"Classic Load Balancer 适用于在多个 EC2 实例之间进行简单的流量负载均衡，而 Application Load Balancer 则适用于需要高级路由功能、微服务和基于容器的架构的应用程序。有关更多信息，请访问 [Elastic Load Balancing](https://aws.amazon.com/cn/elasticloadbalancing/)。"
    },
    {
        "query":"为什么每个区域限制使用 5 个弹性 IP 地址？",
        "intention":"知识问答",
        "reply":"公有 (IPV4) Internet 地址是稀缺的资源。可用的公有 IP 空间数量有限，Amazon EC2 也致力于帮助高效地使用该空间。\n默认情况下，所有账户均在每个区域限制使用 5 个弹性 IP 地址。如果您需要 5 个以上弹性 IP 地址，我们要求您申请提高您的限制。我们会请您全面考虑您的使用情况后再下结论，帮助我们了解您对额外地址的需求。您可以[在此处申请增加弹性 IP 地址数量](https://aws.amazon.com/cn/contact-us/eip_limit_request/)。任何增加都仅适用于请求所针对的区域。"
    },
    {
        "query":"是否每个运行的实例都需要一个弹性 IP 地址？",
        "intention":"知识问答",
        "reply":"不是。并非所有实例都需要弹性 IP 地址。默认情况下，每个实例都附带一个私有 IP 地址和一个 Internet 可路由公有 IP 地址。实例停止并重启后，私有 IP 地址仍与网络接口相关联，并会在实例终止后得以释放。此公有地址唯一关联至该实例，直到实例停止或终止，或者替换为弹性 IP 地址。对于许多不需要长期 Internet 可路由终端节点的应用程序来说，这些 IP 地址应当足够。例如，计算集群、Web 网络爬取和后端服务等应用程序通常都不需要弹性 IP 地址。"
    },
    {
        "query":"重新映射弹性 IP 地址需要多长时间？",
        "intention":"知识问答",
        "reply":"目前，从您指示我们重新映射弹性 IP 到其完全传播到我们的系统中，重新映射过程需要几分钟时间。"
    },
    {
        "query":"是否可以为弹性 IP 地址配置反向 DNS 记录？",
        "intention":"知识问答",
        "reply":"所有弹性 IP 地址都带有反向 DNS，格式的标准模板为 ec2-1-2-3-4.region.compute.amazonaws.com。对于要求为面向互联网的应用程序（使用基于 IP 的相互身份验证，例如从 EC2 实例发送电子邮件）自定义反向 DNS 设置的客户，您可以通过填写[此表](https://portal.aws.amazon.com/gp/aws/html-forms-controller/contactus/ec2-email-limit-rdns-request)来配置弹性 IP 地址的反向 DNS 记录。或者，如果您想要 AWS 将弹性 IP 的反向 DNS 管理委派给权威性的 DNS 名称服务器（如 Amazon Route 53），请联系 AWS 客户支持，以便您可以管理自己的反向 DNS PTR 记录来支持这些使用案例。请注意，在我们能够创建反向 DNS 记录前，必须存在指向该弹性 IP 地址的对应正向 DNS 记录。"
    },
    {
        "query":"如何防止他人查看我的系统？",
        "intention":"知识问答",
        "reply":"您可以完全掌控您的系统的可见性。Amazon EC2 安全系统允许您将运行的实例放入您选择的任意的组中。借助 Web 服务界面，您可以指定哪些组能够与哪些其他组通信，以及 Internet 上的哪些 IP 子网可以和哪些组通信。这可让您在我们高度动态的环境中控制对您的实例的访问。当然，您也应当像对待其他任何服务器一样为您的实例提供安全保护。"
    },
    {
        "query":"我能否获得从我的账户发起的所有 EC2 API 调用的历史记录，以便用于安全分析和运营方面的故障排除？",
        "intention":"知识问答",
        "reply":"是的。要获得从您的账户发起的所有 EC2 API 调用（包括 VPC 和 EBS）的历史记录，您只需在 [AWS 管理控制台](https://console.aws.amazon.com/cloudtrail/home)中打开 CloudTrail。有关更多信息，请访问 [CloudTrail](https://aws.amazon.com/cn/cloudtrail/) 主页。"
    },
    {
        "query":"在何处可以找到有关 AWS 安全性的更多信息？",
        "intention":"知识问答",
        "reply":"有关 AWS 安全性的更多信息，请参阅我们的 [Amazon Web Services：安全流程概览](https://d1.awsstatic.com/whitepapers/aws-security-whitepaper.pdf)白皮书和[运行 Windows 的 Amazon EC2 安全指南](https://aws.amazon.com/cn/answers/security/aws-securing-windows-instances/)。"
    },
    {
        "query":"Amazon CloudWatch 接收和聚合数据的最小时间间隔粒度是多少？",
        "intention":"知识问答",
        "reply":"以 1 分钟为间隔接收和聚合指标。"
    },
    {
        "query":"Amazon CloudWatch 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 接收和提供适用于所有 Amazon EC2 实例的指标，应该适用于 Amazon EC2 服务目前支持的所有操作系统。"
    },
    {
        "query":"如果停用某个 Amazon EC2 实例的监控，是否会丢失指标数据？",
        "intention":"知识问答",
        "reply":"您可以接收自开始监控 Amazon EC2 实例起最多 2 周时间内的指标数据。两周后，如果已停用了 Amazon EC2 实例的监控，则该 Amazon EC2 实例的指标数据将不可用。如果要存档 2 周以上的指标，您可以从命令行中调用 mon-get-stats 命令，并在 Amazon S3 或 Amazon SimpleDB 中存储结果。"
    },
    {
        "query":"是否可以访问已终止的 Amazon EC2 实例或已删除的 Elastic Load Balancer 的指标数据？",
        "intention":"知识问答",
        "reply":"是的。Amazon CloudWatch 为已终止的 Amazon EC2 实例或已删除的 Elastic Load Balancer 存储 2 周的指标数据。"
    },
    {
        "query":"当我在 5 分钟和 1 分钟时段内查看时，为什么同一时间窗口的图形会有不同？",
        "intention":"知识问答",
        "reply":"如果在 5 分钟和 1 分钟时段内查看同一时间窗口，您可能会发现数据点显示在图形中不同的位置上。对于您在图形中指定的时段，Amazon CloudWatch 会查找所有可用的数据点，再计算出单个聚合点来代表整个时段。在 5 分钟时段的情况下，该单一数据点会处于 5 分钟时间窗口的开头。在 1 分钟时段的情况下，该单一数据点会处于 1 分钟标记上。我们建议使用 1 分钟周期来进行故障诊断，以及其他要求最精确的时段图形的活动。"
    },
    {
        "query":"是否可以自动扩展 Amazon EC2 Auto Scaling 组？",
        "intention":"知识问答",
        "reply":"可以。[Amazon EC2 Auto Scaling](https://aws.amazon.com/cn/ec2/autoscaling/) 是一项完全托管的服务，可自动启动或终止 Amazon EC2 实例，以帮助确保您拥有适当数量的 Amazon EC2 实例来处理应用程序负载。EC2 Auto Scaling 可以针对 EC2 实例进行队列管理，具体方式是检测并替换不正常的实例，并根据您定义的条件自动增加或减少 Amazon EC2 容量，从而帮助您保持应用程序的可用性。在需求高峰期，您可以使用 EC2 Auto Scaling 来自动增加 Amazon EC2 实例的数量以便保持性能，当需求较低时，则可以减少容量以便降低成本。\nEC2 Auto Scaling 中的分配策略用于确定如何从 Spot 实例池中实施您的队列中的 Spot 实例。容量优化分配策略意在通过分析容量指标从最可用的 Spot 实例池中预置 Spot 实例。此策略适用于大数据和分析、图像和媒体渲染、机器学习以及高性能计算等具有更高中断成本的工作负载。最低价格分配策略跨“新”价格最低实例池启动严格基于多样化的 Spot 实例。\n有关更多信息，请参阅 [Amazon EC2 Auto Scaling 常见问题](https://aws.amazon.com/cn/ec2/autoscaling/faqs/)。"
    },
    {
        "query":"为何应该休眠实例？",
        "intention":"知识问答",
        "reply":"如果实例和应用程序引导（例如加载内存缓存）需要很长时间，那么可以休眠一个实例来快速启动和运行它们。您可以启动实例，到达所需的状态之后将其休眠。这些“预热”实例稍后可以重新运行，以缩短让实例进入正常运行状态所需的时间。在停止/启动循环内，休眠可以保持内存状态。"
    },
    {
        "query":"休眠实例时，会出现什么情况？",
        "intention":"知识问答",
        "reply":"休眠实例时，您在 EBS 根卷和任何附加 EBS 数据卷上的数据都将持久保存。此外，来自实例的存储器 (RAM) 的内容将永久保存到 EBS 根卷。实例重启时，会恢复之前的状态，并重新加载 RAM 内容。"
    },
    {
        "query":"休眠和停止有什么区别？",
        "intention":"知识问答",
        "reply":"在休眠的情况下，您的实例会进入休眠状态，RAM 数据将持久保存。在停止的情况下，您的实例会关闭，RAM 数据将被清除。\n在这两种情况下，您在 EBS 根卷和任何附加 EBS 数据卷上的数据都将持久保存。您的私有 IP 地址保持不变，就像您的弹性 IP 地址一样（如适用）。网络层的行为将类似于 EC2 停止启动工作流。停止和休眠选项仅适用于 Amazon EBS 提供支持的实例。本地实例存储不会持久保存。"
    },
    {
        "query":"如何休眠实例？",
        "intention":"知识问答",
        "reply":"需要在启动实例时启用休眠。启用后，您就可以使用 StopInstances API 和一个额外参数“Hibernate”来触发休眠。您还可以通过控制台选择实例，然后单击 Actions> instance State > Stop - Hibernate 来完成此操作。有关使用休眠的更多信息，请参阅[用户指南](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html)。"
    },
    {
        "query":"如何重新启用休眠实例？",
        "intention":"知识问答",
        "reply":"您可以像对待一般的停止实例一样，通过调用 StartInstances API 来恢复。您还可以通过控制台选择实例，然后单击 Actions > Instance State > Start 来完成此操作。"
    },
    {
        "query":"我可以在现有实例上启用休眠吗？",
        "intention":"知识问答",
        "reply":"不，您不能在现有实例（正在运行或已停止）上启用休眠。需要在启动实例期间启用。"
    },
    {
        "query":"如何判断实例已休眠？",
        "intention":"知识问答",
        "reply":"您可以通过查看状态原因来确定实例是否已休眠。状态原因应该是“Client.UserInitiatedHibernate”。您可以在控制台的 “Instances - Details” 视图下查看，也可以在 DescribeInstances API 响应 “reason”（原因）字段中查看。"
    },
    {
        "query":"实例休眠时，显示什么状态？",
        "intention":"知识问答",
        "reply":"休眠实例显示“停止”状态。"
    },
    {
        "query":"休眠实例时，哪些数据会被保存？",
        "intention":"知识问答",
        "reply":"会保存 EBS 卷存储（引导卷和附加数据卷）和内存 (RAM)。您的私有 IP 地址保持不变（面向 VPC），就像您的弹性 IP 地址一样（如适用）。网络层的行为将类似于 EC2 停止启动工作流。"
    },
    {
        "query":"休眠实例时，我的数据会保存在什么位置？",
        "intention":"知识问答",
        "reply":"与停止功能一样，根设备和附加设备数据会被保存到对应的 EBS 卷上。内存 (RAM) 内容被保存到 EBS 根卷中。"
    },
    {
        "query":"移动到 EBS 时，我的内存 (RAM) 数据会加密吗？",
        "intention":"知识问答",
        "reply":"是的，RAM 数据在移到 EBS 根卷时始终会进行加密处理。会在实例启动时强制对 EBS 根卷加密。这是为了确保在休眠时保护内存中的任何敏感内容。"
    },
    {
        "query":"实例保持休眠的时间是多久？",
        "intention":"知识问答",
        "reply":"我们支持的实例休眠时间不超过 60 天。如果希望将实例保留更长时间，则需要恢复该实例并经历停止和启动（没有休眠）过程。我们会不断地通过升级和安全补丁来更新平台，其中一些升级和补丁可能与旧的休眠实例冲突。推出关键更新，需要您恢复休眠实例，并执行关闭或重启操作时，我们会通知您。"
    },
    {
        "query":"休眠实例需要满足哪些前提条件？",
        "intention":"知识问答",
        "reply":"要使用休眠，根卷必须是加密的 EBS 卷。需要将实例配置为接收休眠 ACPID 信号（或者使用针对休眠而配置的由 Amazon 发布的 AMI）。此外，您的实例在 EBS 根卷上应有足够的空间来从内存中写入数据。"
    },
    {
        "query":"哪些实例和操作系统支持休眠？",
        "intention":"知识问答",
        "reply":"例如，运行 Amazon Linux、Amazon Linux 2、Ubuntu 和 Windows 的 C3、C4、C5、C5d、I3、M3、M4、M5、M5a、M5ad、M5d、R3、R4、R5、R5a、R5ad、R5d、T2、T3 和 T3a 实例都支持休眠。\n例如，运行 CentOS、Fedora 和 Red Hat Enterprise Linux 的 C5、C5d、M5、M5a、M5ad、M5d、R5、R5a、R5ad、R5d、T3 和 T3a 实例都支持休眠。\n对于 Windows，最大占用 16GB RAM 的实例支持休眠。对于其他操作系统，RAM 小于 150GB 的实例支持休眠功能。要查看受支持操作系统版本和实例类型的列表，请参阅[用户指南](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Hibernate.html)。"
    },
    {
        "query":"如果我想要休眠实例，是否应使用特定的 Amazon Machine Image (AMI)？",
        "intention":"知识问答",
        "reply":"您可以使用任何为支持休眠而配置的 AMI。您可以使用默认支持休眠的、由 AWS 发布的 AMI。或者，在遵循休眠先决条件检查表并适当配置实例之后，您可以从实例创建自定义映像。"
    },
    {
        "query":"如果我的 EBS 根卷不够大，无法针对休眠存储内存状态 (RAM)，该怎么办？",
        "intention":"知识问答",
        "reply":"为了启用休眠，根卷上需要分配空间来存储实例内存 (RAM)。确保根卷足够大，可以存储 RAM 内容并满足您的预期使用需求，例如操作系统和应用程序。如果 EBS 根卷没有足够的空间，则休眠将失败，实例会关闭。"
    },
    {
        "query":"什么是 VM Import/Export？",
        "intention":"知识问答",
        "reply":"客户可以通过使用 VM Import/Export 导入虚拟机（VM）映像来创建 Amazon EC2 实例。此外，客户还可以通过导出以前导入的 EC2 实例来创建 VM。客户可以通过使用 VM Import/Export 将其 VM 迁移到 Amazon EC2 来利用以前在构建 VM 方面的投资。"
    },
    {
        "query":"支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"VM Import/Export 当前支持 Windows 和 Linux 虚拟机，包括 [Windows Server 2003](https://aws.amazon.com/cn/windows/products/ec2/server2003/)、Windows Server 2003 R2、Windows Server 2008、Windows Server 2012 R1、Red Hat Enterprise Linux (RHEL) 5.1-6.5（使用 Cloud Access）、Centos 5.1-6.5、Ubuntu 12.04、12.10、13.04、13.10 和 Debian 6.0.0-6.0.8、7.0.0-7.2.0。有关 VM Import 的更多详细信息，包括支持的文件格式、架构和操作系统配置，请参阅 [Amazon EC2 用户指南](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/VMImportPrerequisites.html)中的“VM Import/Export”部分。"
    },
    {
        "query":"支持哪些虚拟机文件格式？",
        "intention":"知识问答",
        "reply":"您可以将 VMware ESX VMDK 映像、Citrix Xen VHD 映像、Microsoft Hyper-V VHD 映像和 RAW 映像导入为 Amazon EC2 实例。您可以将 EC2 实例导出到 VMware ESX VMDK、VMware ESX OVA、Microsoft Hyper-V VHD 或 Citrix Xen VHD 映像。有关支持的操作系统的完整列表，请参阅[支持哪些操作系统?](https://aws.amazon.com/cn/ec2/faqs#supported-operating-systems)"
    },
    {
        "query":"什么是 VMDK？",
        "intention":"知识问答",
        "reply":"VMDK 是一种文件格式，用于指定在单个文件内封装的虚拟机硬盘。它通常供虚拟 IT 基础设施使用，例如 VMware, Inc. 销售的此类产品。"
    },
    {
        "query":"如何准备 VMDK 文件，以便使用 VMware vSphere 客户端导入？",
        "intention":"知识问答",
        "reply":"可以通过调用 VMware vSphere Client 中的 File-Export-Export to OVF 模板准备 VMDK 文件。生成的 VMDK 文件会被压缩以缩小映像大小，并与 VM Import/Export 兼容。如果您使用 Amazon EC2 VM Import Connector vApp for VMware vCenter，则无需进行特别的准备。"
    },
    {
        "query":"什么是 VHD？",
        "intention":"知识问答",
        "reply":"VHD（虚拟硬盘）是一种文件格式，它指定在单个文件内封装的虚拟机硬盘。VHD 映像格式由 Microsoft Hyper-V 和 Citrix Xen 等虚拟平台使用。"
    },
    {
        "query":"如何准备 VHD 文件，以便从 Citrix Xen 导入？",
        "intention":"知识问答",
        "reply":"打开 Citrix XenCenter，然后选择要导出的虚拟机。在“Tools”菜单下，选择“Virtual Appliance Tools”，然后选择“Export Appliance”以启动导出任务。导出完成后，您可以在导出对话框中指定的目标目录中找到 VHD 映像文件。"
    },
    {
        "query":"如何准备 VHD 文件，以便从 Microsoft Hyper-V 导入？",
        "intention":"知识问答",
        "reply":"打开 Hyper-V Manager，然后选择要导出的虚拟机。在虚拟机的“Actions”窗格中，选择“Export”以启动导出任务。导出完成后，您便可以在导出对话框中指定的目标目录中找到 VHD 映像文件。"
    },
    {
        "query":"导入 VM 到 Amazon EC2 中时是否还有任何其他要求？",
        "intention":"知识问答",
        "reply":"在生成 VMDK 或 VHD 映像前，虚拟机必须处于已停止状态。虚拟机不可处于暂停或挂起状态。我们建议您导出仅连接了引导卷的虚拟机。您可以使用 ImportVolume 命令导入其他的磁盘，再使用 AttachVolume 将它们连接到虚拟机。此外，也不支持加密的磁盘 (如 Bit Locker) 和加密的映像文件。您也需负责确保您拥有必要的权限和许可，将 VM 映像中包含的任何软件导入 AWS 中运行。"
    },
    {
        "query":"是否需要对虚拟机进行任何特定的配置，以便能导入到 Amazon EC2？",
        "intention":"知识问答",
        "reply":"确保为远程访问启用远程桌面（RDP）或安全 Shell（SSH），并确认您的主机防火墙（Windows 防火墙、iptable 或类似防火墙）（如果已配置）允许访问 RDP 或 SSH。否则在导入完成后，您将无法访问您的实例。另请确保，为包括管理员在内的所有用户将 Windows VM 配置为使用强密码并将 Linux VM 配置为使用公有密钥进行 SSH 访问。"
    },
    {
        "query":"如何将虚拟机导入到 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon EC2 API 工具导入您的 VM 映像：\n或者，如果您使用的是 VMware vSphere 虚拟平台，也可以使用通过 [AWS Management Portal for vCenter](https://aws.amazon.com/cn/ec2/vcenter-portal/) 提供的图形用户界面将虚拟机导入到 Amazon EC2。请参阅 AWS Management Portal for vCenter 中的《入门指南》。AWS Management Portal for vCenter 包含对 VM Import 的集成支持。在 vCenter 中安装门户后，您可以右键点击一个虚拟机，然后选择“Migrate to EC2”，便可从该虚拟机创建一个 EC2 实例。门户会将虚拟机从 vCenter 导出并上传到 S3，然后将其转换到 EC2 实例中，这个过程无需任何额外的工作。您还可以追踪门户中进行的虚拟机迁移进度。"
    },
    {
        "query":"如何将 Amazon EC2 实例导回到我的内部虚拟环境中？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon EC2 CLI 工具导出 Amazon EC2 实例："
    },
    {
        "query":"使用 VM Import/Export 导出 EC2 实例是否有任何其他要求？",
        "intention":"知识问答",
        "reply":"对于之前用 VM Import/Export 导入的 EC2 实例，您可以导出正在运行或已停止的实例。如果实例正在运行中，它会暂时停止以便为引导卷拍摄快照。无法导出 EBS 数据卷。无法导出具有多个网络接口的 EC2 实例。"
    },
    {
        "query":"是否可以导出连接了一个或多个 EBS 数据卷的 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"可以。但是 VM Import/Export 仅导出 EC2 实例的引导卷。"
    },
    {
        "query":"导入 Windows Server 2003 或 2008 的虚拟机时，操作系统许可由谁负责提供？",
        "intention":"知识问答",
        "reply":"在启动使用 Microsoft Windows Server 2003 或 2008 的已导入 VM 时，您需支付标准的实例小时费，以便 Amazon EC2 运行相应的 Windows Server 版本，这其中包含了在 Amazon EC2 中使用该操作系统的权限。您需负责确保所有已安装的其他软件具有适当的许可。\n那么，在导入 Windows Server 2003 或 2008 的 VM 后，我内部的 Microsoft Windows 许可密钥会出现什么情况？ 在将您导入的 VM 作为 EC2 实例运行时，不会使用之前与该 VM 关联的内部 Microsoft Windows 许可密钥，因此您可以将该密钥重复用于内部虚拟环境中的其他 VM。"
    },
    {
        "query":"将 EC2 实例导回到我的内部虚拟环境后，是否可以继续使用 AWS 提供的 Microsoft Windows 许可密钥？",
        "intention":"知识问答",
        "reply":"不可以。导出 EC2 实例后，该 EC2 实例中使用的许可证密钥便不再可用。在内部虚拟平台中启动导出的 VM 后，您将需要重新激活并指定新的许可密钥。"
    },
    {
        "query":"导入 Red Hat Enterprise Linux (RHEL) VM 时，谁负责提供操作系统许可证？",
        "intention":"知识问答",
        "reply":"导入 Red Hat Enterprise Linux (RHEL) VM 映像时，您可以对 RHEL 实例使用许可证可移植功能。使用许可证可移植性时，您需负责维护所导入实例的 RHEL 许可证，这可以使用 Red Hat Enterprise Linux 的 Cloud Access 订阅来实现。如需了解更多有关 Cloud Access 的信息以及确认您的资格，请联系 Red Hat。"
    },
    {
        "query":"导入虚拟机需要多长时间？",
        "intention":"知识问答",
        "reply":"导入虚拟机所需的时间取决于磁盘映像的大小，以及您的网络连接速度。举例而言，导入一个 10 GB Windows Server 2008 SP2 VMDK 映像时，如果通过 10 Mbps 网络连接传输，需要大约 2 小时。如果您的网络连接较慢或者要上传的磁盘很大，可能会大大延长导入时间。"
    },
    {
        "query":"哪些 Amazon EC2 地区中可以使用 VM Import/Export？",
        "intention":"知识问答",
        "reply":"请访问[区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)页面，按区域查看产品和服务的可用性。"
    },
    {
        "query":"我可以同时执行多少个导入或导出任务？",
        "intention":"知识问答",
        "reply":"每个账户在每个地区最多可有 5 个活动导入任务和 5 个导出任务。"
    },
    {
        "query":"是否可以在 Amazon Virtual Private Cloud (VPC) 中运行导入的虚拟机？",
        "intention":"知识问答",
        "reply":"可以，您可以在 Amazon VPC 中启动导入的虚拟机。"
    },
    {
        "query":"是否可以通过 AWS 管理控制台使用 VM Import/Export？",
        "intention":"知识问答",
        "reply":"不可以。VM Import/Export 命令可以通过 EC2 CLI 和 API 使用。您还可以使用 [AWS Management Portal for vCenter](https://aws.amazon.com/cn/ec2/vcenter-portal/) 将虚拟机导入到 Amazon EC2。导入后，生成的实例即可通过 AWS 管理控制台使用。"
    },
    {
        "query":"我的 Amazon EC2 系统的账单周期怎么计算？",
        "intention":"知识问答",
        "reply":"从 Amazon EC2 启动 AMI 实例的引导序列时开始计费。该实例终止时停止计费，可以通过 Web 服务命令或运行“shutdown -h”命令终止实例，实例故障也会导致实例终止。当您停止实例时，我们会将其关闭，而且不会对已经停止的实例收取小时使用费或数据传输费，但是我们会对所有的 Amazon EBS 卷收取存储费。有关更多信息，请访问 [AWS 文档](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html)。"
    },
    {
        "query":"EC2 实例在什么情况下会计算使用费？",
        "intention":"知识问答",
        "reply":"当您的实例处于“运行”状态时，我们会计算实例使用费。如果您不再希望您的实例被收取费用，您必须“停止”或“终止”该实例，以免产生更多实例使用费。当实例进入运行状态时就会开始计费。"
    },
    {
        "query":"什么是可转换 RI？",
        "intention":"知识问答",
        "reply":"可转换 RI 是可以在运行期限内更改属性的一种预留实例。"
    },
    {
        "query":"什么时候应该购买可转换 RI 而不购买标准 RI？",
        "intention":"知识问答",
        "reply":"如果客户愿意使用 EC2 实例三年时间以便获得大幅折扣，但是不确定自己在未来的实例需求，或者如果客户想要在价格变化时获得好处，则可以使用可转换 RI。"
    },
    {
        "query":"可转换 RI 的使用期限有哪些选择？",
        "intention":"知识问答",
        "reply":"与标准 RI 一样，可转换 RI 有一年期和三年期两种购买选择。"
    },
    {
        "query":"能不能把一个可转换 RI 更换成具有不同实例类型、操作系统、租期或付款选项的另一个可转换 RI？",
        "intention":"知识问答",
        "reply":"可以。在更换可转换 RI 时，您可以选择新的实例类型、操作系统、租期或付款选项。您还可以更换一部分可转换 RI，也可以在一次更换中把多个可转换 RI 的价值合并到一起。"
    },
    {
        "query":"能否将可转换 RI 或标准 RI 从一个区域转移到另一个区域？",
        "intention":"知识问答",
        "reply":"不能。RI 与特定区域相关联，这种关联在预留持续期限内固定不变。"
    },
    {
        "query":"如何更改可转换 RI 的配置？",
        "intention":"知识问答",
        "reply":"您可以使用 EC2 管理控制台或 [GetReservedInstancesExchangeQuote API](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_GetReservedInstancesExchangeQuote.html) 来更改可转换 RI 的配置。您还可以更换一部分可转换 RI，也可以在一次更换中把多个可转换 RI 的价值合并到一起。要了解有关更换可转换 RI 的更多信息，请[单击此处](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ri-convertible-exchange.html)。"
    },
    {
        "query":"可转换 RI 采用什么更换机制？",
        "intention":"知识问答",
        "reply":"当您用一个可转换 RI 更换另一个时，EC2 会确保可转换 RI 的总价值在转换过程中保持不变。因此，如果您将总价值为 1000 USD 的 RI 转换为另一个 RI，那么您收到的可转换 RI 的总价值会等于或大于 1000 USD。您不能将自己的可转换 RI 转换为总价值更低的可转换 RI。"
    },
    {
        "query":"怎样确定总价值？",
        "intention":"知识问答",
        "reply":"总价值是您在 RI 运行期限内预计将会支付的全部款项之和。"
    },
    {
        "query":"能否自己指定在更换可转换 RI 后收到的实例数量？",
        "intention":"知识问答",
        "reply":"不能。EC2 根据您要更换的可转换 RI 的价值来计算您将收到的可转换 RI 的最低数量，并会确保更换后的可转换 RI 的价值与之前相同或比其更高。"
    },
    {
        "query":"可转换 RI 是否存在更换限制？",
        "intention":"知识问答",
        "reply":"没有。可转换 RI 不存在任何更换限制。"
    },
    {
        "query":"在更换可转换 RI 时，我能否自由选择实例类型？",
        "intention":"知识问答",
        "reply":"不能。您只能更换为 AWS 当前提供的可转换 RI。"
    },
    {
        "query":"我能否升级与可转换 RI 相关联的付款选项？",
        "intention":"知识问答",
        "reply":"可以。您可以升级与 RI 相关联的付款选项。例如，您可以将无费用预付 RI 更换为预付部分费用或预付全费 RI，以便享受更优惠的定价。您不能将付款选项从“预付全费”更改为“无费用预付”，也不能将其从“预付部分费用”更改为“无费用预付”。"
    },
    {
        "query":"可转换 RI 是否允许我享受降价优惠？",
        "intention":"知识问答",
        "reply":"允许。您可以更换 RI 来享受更低的定价。例如，如果新的可转换 RI 的价格降低了 10%，那么您可以更换您的可转换 RI，从而享受 10% 的降价优惠。"
    },
    {
        "query":"什么是 Amazon EC2 Fleet？",
        "intention":"知识问答",
        "reply":"借助 EC2 Fleet，您只需调用一次 API，即可跨不同实例类型和可用区以及跨按需型实例、预留实例（RI）和竞价型实例购买模型预置计算容量，从而帮助优化规模、性能和成本。"
    },
    {
        "query":"如果我当前使用的是 Amazon EC2 竞价型实例集，是否需要迁移到 Amazon EC2 Fleet？",
        "intention":"知识问答",
        "reply":"如果您使用的是 Amazon EC2 竞价型实例及竞价型实例集，则可继续使用。Spot 队列和 EC2 队列提供的功能相同，因此无需进行迁移。"
    },
    {
        "query":"使用 Amazon EC2 Fleet 能否享受预留实例（RI）折扣？",
        "intention":"知识问答",
        "reply":"是的。与启动 EC2 实例的其他 EC2 API 或其他 AWS 服务类似，如果 EC2 队列启动的按需实例与现有 RI 匹配，则该实例将获得 RI 折扣。例如，如果您拥有 M4 实例的区域性 RI，并且您在 EC2 队列中只指定了 M4 实例，那么使用 M4 时将自动应用 RI 折扣。"
    },
    {
        "query":"如果 EC2 竞价型实例容量不够，Amazon EC2 Fleet 能否失效转移到按需型实例？",
        "intention":"知识问答",
        "reply":"否，EC2 Fleet 将继续尝试根据您在队列启动规格中请求的竞价型实例数量来满足您想要的竞价型实例容量。"
    },
    {
        "query":"Amazon EC2 Fleet 如何定价？",
        "intention":"知识问答",
        "reply":"EC2 Fleet 不额外收费；您只需为 EC2 Fleet 启动的底层资源付费。\n您能否列举一个真实示例来说明如何使用 Amazon EC2 Fleet？\n可以通过多种方法利用 Amazon EC2 Fleet，例如在大数据工作负载、容器化应用程序、网格处理工作负载等中。在这个基因组测序工作负载[示例](https://aws.amazon.com/blogs/aws/ec2-fleet-manage-thousands-of-on-demand-and-spot-instances-with-one-request/)中，您只需调用一次 API 即可启动一个网格的 Worker 节点：选择您最喜欢的实例，为这些实例分配权重，为按需型实例和竞价型实例指定目标容量，并在数秒钟内构建一个队列以快速处理基因组数据。"
    },
    {
        "query":"如何在 Amazon EC2 Fleet 中分配资源？",
        "intention":"知识问答",
        "reply":"默认情况下，EC2 Fleet 将启动价格最低的按需选项。对于 Spot 实例，EC2 队列提供三种分配策略：容量优化、最低价格和多样化。容量优化分配策略意在通过分析容量指标从最可用的 Spot 实例池中预置 Spot 实例。此策略适用于大数据和分析、图像和媒体渲染、机器学习以及高性能计算等具有更高中断成本的工作负载。\n借助最低价格策略，您可以在请求时单位容量价格最低的池中预置 Spot 实例。借助多样化策略，您不仅可以在多个竞价型实例池中预置竞价型实例，还能在增加应用程序时保持队列的目标容量。"
    },
    {
        "query":"我能否提交多区域 Amazon EC2 Fleet 请求？",
        "intention":"知识问答",
        "reply":"否，我们不支持多区域 EC2 Fleet 请求。"
    },
    {
        "query":"我能否标记 Amazon EC2 Fleet？",
        "intention":"知识问答",
        "reply":"是的。您可以标记 EC2 Fleet 请求来创建与业务相关的标记分组，从而整理技术、业务和安全资源。"
    },
    {
        "query":"我能否修改 Amazon EC2 Fleet？",
        "intention":"知识问答",
        "reply":"能，您可以在维护模式下修改 EC2 Fleet 的总目标容量。您可能需要取消该请求，然后提交一个新请求来更改其他请求配置参数。"
    },
    {
        "query":"我能否为希望使用的每个实例类型指定不同的 AMI？",
        "intention":"知识问答",
        "reply":"能，只需指定要用于您在 EC2 实例集中提供的每种启动规格的 AMI。\n按需容量预留是 EC2 提供的一项功能，可让您在 Amazon EC2 上创建和管理预留容量。您可以通过选择可用区和数量（实例数）以及实例类型和租赁等其他实例规范来创建容量预留。创建预留后，不论您是否运行实例，该 EC2 容量都将为您保留。"
    },
    {
        "query":"使用容量预留时，是否可以享受折扣？",
        "intention":"知识问答",
        "reply":"可以。Savings Plans 或区域 RI（限定于某个区域的 RI）折扣适用于容量预留。在运行预留的实例时，您无需为该预留付费。Savings Plans 或区域 RI 将为此使用付费，如同按需使用一样。如果未使用预留，则未使用容量预留属性与某个活动 Savings Plan 或区域 RI 的属性匹配时，AWS 账单将自动执行您的折扣。\n例如，如果您有 10 个 c5.2xlarge 实例的区域 RI，并且在同一区域拥有 10 个 c5.2xlarge 实例的未使用容量预留，则 RI 折扣将适用于该预留中所有 10 个实例。请注意，区域 RI 折扣将优先适用于正在运行的实例使用量，然后再用于未使用的容量预留。这意味着，如果您在该区域中有任何其他运行的 c5 实例，我们将区域 RI 优先适用于这些实例，然后将剩余的折扣适用于未使用的容量预留。\n注意：区域 RI 是限定于某个 AWS 区域的 EC2 RI。可用区 RI（限定于一个区域内的某个可用区的 RI）折扣不适用于按需容量预留，因为可用区 RI 已附带容量预留。"
    },
    {
        "query":"我应该在何时使用 Savings Plans、EC2 RI 和容量预留？",
        "intention":"知识问答",
        "reply":"Savings Plans 或区域 RI 是通过承诺一年或三年的使用量来降低费用。Savings Plans 与按需方案（例如 EC2 RI）相比，可以带来显著的节约，并且可以自动降低跨任何 AWS 区域的客户计算使用费，即使使用情况发生了变化。如果您需要增强保证，以便能够启动实例，请使用容量预留。容量预留可以按任意时间长度创建并可独立于您的 Savings Plans 或 RI 进行管理。如果您有 Savings Plans 或区域 RI，系统会自动针对所匹配的容量预留应用这些折扣。这让您可以灵活、有选择性地为您的部分实例占用空间添加容量预留，同时继续在使用实例时享受折扣。"
    },
    {
        "query":"我具有也提供容量预留的可用区 RI（划分到可用区的 RI）。这与容量预留有何区别？",
        "intention":"知识问答",
        "reply":"可用区 RI 在特定可用区内提供折扣优惠和容量预留，但同时需要一至三年的承诺。容量预留功能允许独立于 RI 承诺和期限长度创建和管理预留容量。\n按需容量预留可以与 Savings Plan 或区域 RI 结合使用，以至少获得与可用区 RI 相同的所有优势（无需额外费用）。您还可以享受 Savings Plan（或区域 RI）更好的灵活性并发挥容量预留的特点：随时添加或减少预留容量、实时查看预留利用率以及为特定工作负载限定容量预留。\n将可用区 RI 重新限定到某个区域后，您可立即获得在执行 RI 折扣上的可用区和实例大小灵活性。您可以使用 EC2 控制台或 ModifyReservedInstances API，将标准可用区 RI 的范围从特定可用区改为某个区域，从而将该 RI 转换为区域 RI。"
    },
    {
        "query":"我创建了一个容量预留。如何使用它？",
        "intention":"知识问答",
        "reply":"容量预留与特定的可用区绑定，默认情况下由该可用区中运行的实例自动使用。当您启动与预留属性匹配的新实例时，它们将自动与预留匹配。\n如果您愿意，还可以针对特定工作负载/实例定位预留。请参阅 [Linux](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) 或 [Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) 技术文档，详细了解定位选项。"
    },
    {
        "query":"我可以预留多少个实例？",
        "intention":"知识问答",
        "reply":"您可以预留的实例数量取决于您账户的按需型实例限制。您可以在限制允许的数量减去已经运行的实例数量范围内，预留任意数量的实例。\n如果需要提高上限，请联系 AWS 销售代表，或依据您的使用案例填写 Amazon EC2 实例[申请表](https://aws.amazon.com/cn/contact-us/ec2-request/)，我们随后将考虑您的申请。实例上限的提高与请求所针对的区域有关。"
    },
    {
        "query":"我是否可以在容量预留启动后修改它？",
        "intention":"知识问答",
        "reply":"是的。您可以随时减少预留的实例数量。您还可以增加实例的数量（取决于实例可用性）。您还可以修改预留的结束时间。但您不能修改已经终止或已经删除的容量预留。"
    },
    {
        "query":"我是否可以在容量预留启动后终止它？",
        "intention":"知识问答",
        "reply":"是的。您可以通过控制台或 API/开发工具包取消容量预留，或者修改您的预留以指定一个将使其自动到期的结束时间，从而终止容量预留。正在运行的实例不受容量预留的更改影响，包括预留的删除或到期。"
    },
    {
        "query":"在哪里可以找到有关容量预留使用情况的更多信息？",
        "intention":"知识问答",
        "reply":"有关创建和使用容量预留的信息，请参阅 [Linux](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) 或 [Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) 技术文档。"
    },
    {
        "query":"我是否可以与其他 AWS 账户共享容量预留？",
        "intention":"知识问答",
        "reply":"可以，您可以通过 [AWS Resource Access Manager](https://aws.amazon.com/cn/ram/) 服务与其他 AWS 账户或在 AWS 组织内共享容量预留。您可以通过三个简单的步骤共享 EC2 容量预留：通过 AWS Resource Access Manager 创建资源共享，向资源共享添加资源（容量预留），然后指定您想要与其共享资源的目标账户。\n请注意，容量预留的共享不适用于新 AWS 账户或账单历史记录有限的 AWS 账户。与合格的主（付款人）账户或通过 AWS 组织关联的新账户不受此限制。"
    },
    {
        "query":"如果我与其他 AWS 账户共享了容量预留，会发生什么情况？",
        "intention":"知识问答",
        "reply":"与其他账户共享容量预留时，这些账户可以使用预留容量来运行其 EC2 实例。实际行为取决于在容量预留上设置的首选项。默认情况下，容量预留会自动匹配具有预留共享访问权限的其他账户中的现有实例和新实例。您还可以针对特定工作负载/实例定位容量预留。单个账户可以控制其中哪些实例使用容量预留。请参阅 [Linux](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html) 或 [Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2-capacity-reservations.html) 技术文档，了解更多有关实例匹配选项的信息。"
    },
    {
        "query":"在多个账户之间共享容量预留时，谁需要付费？",
        "intention":"知识问答",
        "reply":"如果多个账户正在使用容量预留，则每个账户都需要为其自己的使用的实例付费。对于未使用的预留容量（如果有），将从拥有容量预留的账户中收取费用。如果共享容量预留的账户之间存在整合账单安排，则由主账户支付所有关联账户使用的实例的费用。"
    },
    {
        "query":"我可以在具有共享访问权限的 AWS 账户中优先访问容量预留吗？",
        "intention":"知识问答",
        "reply":"不可以。容量预留中的实例点按先到先得的原则提供给具有共享访问权限的任何账户。"
    },
    {
        "query":"AWS 账户中的可用区（AZ）名称映射可能不同，我该如何向其他账户通知容量预留的 AZ？",
        "intention":"知识问答",
        "reply":"现在，您可以使用可用区 ID（AZ ID）来代替 AZ 名称。可用区 ID 是静态参考，可提供一致的方式来识别所有账户中资源的位置。这样，您就可以更轻松地在单个账户中集中预配置资源，并在多个账户之间共享资源。\n共享容量预留后，我还可以停止共享吗？\n可以，共享容量预留（CR）之后，可以停止共享。当您停止与特定账户共享 CR 或完全停止共享时，其他账户将无法在 CR 中启动新实例。从其他账户运行的实例占用的任何容量都将还给 CR 以供您使用（视供可用性而定）。"
    },
    {
        "query":"在哪里可以找到有关共享容量预留的更多信息？",
        "intention":"知识问答",
        "reply":"有关共享容量预留的信息，请参阅 [Linux](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/capacity-reservation-sharing.html) 或 [Windows](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/capacity-reservation-sharing.html) 技术文档。"
    },
    {
        "query":"使用容量预留时，是否可以享受折扣？",
        "intention":"知识问答",
        "reply":"可以。Savings Plans 或区域 RI 折扣适用于容量预留。只要容量预留的属性与某个 Savings Plan 或区域 RI 的属性匹配，AWS 账单将自动执行该折扣。如果某个实例使用容量预留，您只需为该实例付费（执行 Savings Plan 或 RI 折扣）。折扣将优先适用于已产生的实例使用量，然后再用于未使用的容量预留。\n*注意：区域 RI 是限定于某个 AWS 区域的 EC2 RI。可用区 RI（限定于一个区域内的某个可用区的 RI）折扣不适用于按需容量预留，因为可用区 RI 已附带容量预留。*"
    },
    {
        "query":"什么是预留实例？",
        "intention":"知识问答",
        "reply":"预留实例 (RI) 是一种 EC2 产品，如果您承诺预留一年或三年，它可为您提供可观的 EC2 使用折扣。"
    },
    {
        "query":"标准 RI 与可转换 RI 之间有何区别？",
        "intention":"知识问答",
        "reply":"如果您承诺使用特定的实例系列，标准 RI 可为您提供可观的 EC2 实例使用折扣。可转换 RI 提供了选项，供您在使用期内更改实例配置，并且仍然可以享受 EC2 使用折扣。有关可转换 RI 的更多信息，请单击[此处](https://aws.amazon.com/cn/ec2/faqs#Convertible_Reserved_Instances)。"
    },
    {
        "query":"RI 是否提供容量预留？",
        "intention":"知识问答",
        "reply":"是的，当标准 RI 或可转换 RI 限定于特定可用区 (AZ) 时，系统会预留与 RI 配置严格匹配的实例容量供您使用，供您使用，这些预留实例被称为“可用区 RI”。可用区 RI 使您更相信自己能够按需启动实例。\n您也可以选择放弃容量预留，并且购买限定于某个地区的标准或可转换 RI（称为“地区 RI”）。地区 RI 将对该地区内各种可用区和实例大小的使用情况自动应用折扣，便于您更充分地利用 RI 的折扣费率。"
    },
    {
        "query":"什么时候应该购买可用区 RI？",
        "intention":"知识问答",
        "reply":"如果您想要利用容量预留，则应该购买特定可用区中的 RI。"
    },
    {
        "query":"什么时候应该购买地区 RI？",
        "intention":"知识问答",
        "reply":"如果您不需要容量预留，则应该购买地区 RI。地区 RI 可提供 AZ 和实例大小灵活性，从而更广泛地应用 RI 的折扣费率。"
    },
    {
        "query":"可用区和实例大小灵活性是什么？",
        "intention":"知识问答",
        "reply":"可用区和实例大小灵活性可方便您充分利用地区 RI 的折扣费率。可用区灵活性可对某个地区内任何可用区的使用情况应用 RI 的折扣费率，而实例大小灵活性则对某个实例系列中任意实例大小的使用情况应用 RI 的折扣费率。假设您拥有美国东部 (弗吉尼亚北部) 的一个默认租赁的 m5.2xlarge Linux/Unix 地区 RI。那么此 RI 的折扣费率可自动应用于 us-east-1a 中的两个 m5.xlarge 实例或 us-east-1b 中的四个 m5.large 实例。"
    },
    {
        "query":"哪种 RI 能提供实例大小灵活性？",
        "intention":"知识问答",
        "reply":"具有默认租期的 Linux/Unix 地区 RI 提供实例大小灵活性。实例大小灵活性不适用于其他平台上的 RI ，例如，Windows、带有 SQL Standard 的 Windows、带有 SQL Server Enterprise 的 Windows、带有 SQL Server Web 的 Windows、RHEL 和 SLES 或 G4 实例。"
    },
    {
        "query":"要充分利用可用区和实例大小灵活性，我需要执行任何操作吗？",
        "intention":"知识问答",
        "reply":"地区 RI 无需任何操作，即可充分利用可用区和实例大小灵活性。"
    },
    {
        "query":"我拥有可用区 RI。如何将它们分配到某个地区？",
        "intention":"知识问答",
        "reply":"您可以从 EC2 控制台或通过调用 ModifyReservedInstances API，将 RI 的范围从特定可用区改为相应的地区，从而将标准可用区 RI 分配到相关地区。"
    },
    {
        "query":"如何购买 RI？",
        "intention":"知识问答",
        "reply":"要开始使用，您可以从 EC2 控制台或通过使用 AWS CLI 来购买 RI。只需指定实例类型、平台、租期、使用期、付款选项和地区或可用区即可。"
    },
    {
        "query":"是否可以为正在运行的实例购买 RI？",
        "intention":"知识问答",
        "reply":"是的，AWS 将在购买时，会自动将 RI 的折扣费率应用至任何适用的实例使用情况。有关更多信息，请访问[入门](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#apply_ri)页面。"
    },
    {
        "query":"我是否可以控制哪些实例按照折扣费率进行计费？",
        "intention":"知识问答",
        "reply":"不可以。AWS 将自动优化哪些实例按照折扣费率进行计费，以确保您始终支付最低金额。有关账单和 RI 账单的更多信息，请参阅[账单优惠和付款选项](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html)。"
    },
    {
        "query":"实例大小灵活性是如何实现的？",
        "intention":"知识问答",
        "reply":"EC2 使用如下所示的大小，在实例系列中比较不同的大小。就 RI 的实例大小灵活性而言，此大小用于将 RI 的折扣费率应用至标准化的实例系列使用情况。例如，如果您拥有一个限定于某个地区的 m5.2xlarge RI，则您的折扣费率可能会应用至 1 个 m5.2xlarge 或 2 个 m5.xlarge 实例的使用情况。\n有关 RI 的实例大小灵活性如何应用至 EC2 使用情况的更多信息，请[单击此处](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#apply_ri)。有关成本和使用率报告中如何显示 RI 的实例大小灵活性的更多信息，请[单击此处](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports.html#enhanced-RI)。\n|  |  |\n| --- | --- |\n| 实例大小 | 标准化因子 |\n| nano |  0.25 |\n| 微型 | 0.5 |\n| small | 1 |\n| medium | 2 |\n| large | 4 |\n| xlarge | 8 |\n| 2xlarge | 16 |\n| 4xlarge | 32 |\n| 8xlarge | 64 |\n| 9xlarge | 72 |\n| 10xlarge | 80 |\n| 12xlarge | 96 |\n| 16xlarge | 128 |\n| 18xlarge | 144 |\n| 24xlarge | 192 |\n| 32xlarge | 256 |\n实例大小\n标准化因子\nnano\n0.25"
    },
    {
        "query":"在使用期内，是否可以更改 RI？",
        "intention":"知识问答",
        "reply":"是的，您可以修改 RI 的可用区，将 RI 的范围从可用区改为区域（反之亦可），将网络平台从 EC2-VPC 改为 EC2-Classic（反之亦可），或者在同一实例系列中修改实例大小（在 Linux/Unix 平台上）。"
    },
    {
        "query":"在使用期内，是否可以更改 RI 的实例类型？",
        "intention":"知识问答",
        "reply":"是的。可转换 RI 提供了选项，供您在使用期内更改 RI 的实例类型、操作系统、租期或付款选项。有关更多信息，请参阅“常见问题”的“可转换 RI”部分。"
    },
    {
        "query":"RI 有哪些不同付款选项？",
        "intention":"知识问答",
        "reply":"当您购买 RI 时，有三种付款选项可供选择。若选择“全额预付”选项，您将通过一次预付款支付整个预留实例的费用。若选择“部分预付”选项，您需要进行较低额度的预付款。然后，在 RI 的使用期内，按折扣的小时费率支付实例费用。“不预付”选项不需要任何预付款，并在使用期内提供折扣的小时费率。"
    },
    {
        "query":"RI 在何时被激活？",
        "intention":"知识问答",
        "reply":"您的付款成功获得批准后，计费折扣和容量预留 (如果适用) 随即便会激活。您可以通过 Amazon EC2 控制台的“预留实例”页面查看 RI 的状态 (Pending | Active | Retired)。。"
    },
    {
        "query":"RI 是否能应用于 Spot 实例或在专用主机上运行的实例？",
        "intention":"知识问答",
        "reply":"不能，RI 不适用于 Spot 实例或在专用主机上运行的实例。要减少使用专用主机的成本，请购买专用主机预留。"
    },
    {
        "query":"RI 如何与整合账单结合使用？",
        "intention":"知识问答",
        "reply":"我们的系统将自动优化哪些实例按照折扣费率收费，确保整合账户始终支付最低的金额。如果您拥有的 RI 适用于某个可用区，则只有拥有此类 RI 的账户才能获得容量预留。但折扣将自动应用于整个整合账单系列内任何账户的使用情况。"
    },
    {
        "query":"购买 RI 时，我可以获得折扣吗？",
        "intention":"知识问答",
        "reply":"可以，EC2 在您购买 RI 时提供套餐折扣。这些折扣是根据您在每个地区的活跃 RI 的总标价 (非折扣价格) 来确定的。总标价指一个 RI 在其使用期内预计将支付的所有款项之和，包括预付费和后续的小时费用。套餐范围和相应折扣如下所示。\n|  |  |  |\n| --- | --- | --- |\n| 报价套餐范围 | 预付费折扣 | 小时费用折扣 |\n| 低于 500000 USD | 0% | 0% |\n| 500000-4000000 USD | 5% | 5% |\n| 4000000-10000000 USD | 10% | 10% |\n| 超过 10000000 USD | 致电我们 |  |\n报价套餐范围\n预付费折扣\n小时费用折扣\n低于 500000 USD\n0%\n0%\n500000-4000000 USD\n5%\n5%"
    },
    {
        "query":"您能介绍一下批量折扣如何应用于我购买的 RI 吗？",
        "intention":"知识问答",
        "reply":"当然可以！假设您当前在 US-east-1 地区拥有价值 400000 USD 的活跃 RI。现在，如果您想在同一地区购买价值 150000 USD 的 RI，那么在此次购买中，前 100000 USD 部分的折扣为零。但剩余的 50000 USD 可享受 5% 的折扣，因此，对于此部分，您在此次购买期限内基于您的付款选项仅需支付 47500 USD。\n如需了解更多信息，请参阅 [Amazon EC2 用户指南](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Welcome.html) 的[了解预留实例折扣定价级别](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-application.html#reserved-instances-discounts)部分。"
    },
    {
        "query":"如何计算一个 RI 的标价？",
        "intention":"知识问答",
        "reply":"下面是三年期“部分预付”预留实例的标价计算示例：\n美国东部区域的 3 年期部分预付款批量折扣价值\n|  |  |  |  |  |\n| --- | --- | --- | --- | --- |\n|  | 预付，USD | 产生的每小时费用，USD | 产生的小时价值 | 列表价值 |\n| m3.xlarge | 1345 USD | 0.060 USD | 1577 USD | 2922 USD |\n| c3.xlarge | 1016 USD | 0.045 USD | 1183 USD | 2199 USD |"
    },
    {
        "query":"如果我使用整合账单，批量折扣是如何计算的？",
        "intention":"知识问答",
        "reply":"如果您使用整合账单，AWS 将使用您所有整合账户中的活跃 RI 的总标价来确定应用哪一批量折扣级别。批量折扣级别是在购买时确定的，因此您应当在购买 RI 前先激活整合账单，以确保您的整合账户有资格享受最大批量折扣，从而使您受益。"
    },
    {
        "query":"可转换 RI 有资格享受批量折扣吗？",
        "intention":"知识问答",
        "reply":"没有，但是您购买的每个可转换 RI 的价值都有助于提高您的批量折扣级别。"
    },
    {
        "query":"如何确定我适用哪一个批量折扣级别？",
        "intention":"知识问答",
        "reply":"要确定您当前的批量折扣级别，请参阅 [Amazon EC2 用户指南](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/Welcome.html)的[了解预留实例折扣定价套餐](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/concepts-reserved-instances-tiers.html)部分。"
    },
    {
        "query":"如果我未来的数量让我有资格享受其他折扣级别，我的 RI 成本是否会改变？",
        "intention":"知识问答",
        "reply":"不可以。批量折扣是在购买时确定的，因此即使您有资格享受其他折扣级别，您的 RI 成本仍将保持不变。任何新的购买活动都将在购买时根据您有资格享受的批量折扣级别来应用折扣。"
    },
    {
        "query":"要获得批量折扣，我是否需要在购买时执行任何操作？",
        "intention":"知识问答",
        "reply":"不需要，在使用现有的 PurchaseReservedInstance API 或 EC2 管理控制台界面购买 RI 时，您将自动享受批量折扣。如果您购买的 RI 价值超过 10000000 USD，您应该[联系我们](https://aws.amazon.com/cn/contact-us/aws-sales/)，了解除享受自动提供的折扣以外，您还可享受哪些折扣。"
    },
    {
        "query":"预留实例市场是什么？",
        "intention":"知识问答",
        "reply":"预留实例市场在一个在线商场，可让 AWS 客户灵活地向其他企业和组织出售 Amazon EC2 实例。客户也可以浏览预留实例市场，寻找由其他 AWS 客户出售的期限时间更灵活的预留实例以及更丰富的定价选项。"
    },
    {
        "query":"何时能在预留实例市场展示出售预留实例？",
        "intention":"知识问答",
        "reply":"您可以在满足以下条件后展示出售预留实例："
    },
    {
        "query":"如何注册成为预留实例市场的卖家？",
        "intention":"知识问答",
        "reply":"要注册预留实例市场，您可以通过从 [EC2 管理控制台](https://console.aws.amazon.com/)出售预留实例或在 AWS 门户网站的“账户设置”页面设置个人资料来进入注册工作流程。无论使用什么途径，您都需要完成以下步骤：\n如果您在售的预留实例总价值超过 20000 USD，或计划出售 50 个或更多预留实例，则需要在展示您的预留实例之前提供税务信息。选择“Continue with Tax Interview”。在税务信息采集渠道中，系统会使用 TIMS 工作流程提示您输入公司名称、联系人姓名、地址以及税标识号。\n此外，如果您计划在一年内出售的预留实例总额超过 50000 USD，那么您还需要提交增加销售额上限的请求。"
    },
    {
        "query":"如何了解是否可以开始在预留实例市场进行销售活动？",
        "intention":"知识问答",
        "reply":"在通过注册流程添加银行账户后，您就可以开始在预留实例市场进行销售了。激活后，您会收到一封确认电子邮件。但是，请务必注意，必须等到我们从您的银行收到验证信息后，您才能收到支付的款项。根据您选择的银行不同，验证过程最多可能需要两周时间。"
    },
    {
        "query":"如何展示出售预留实例？",
        "intention":"知识问答",
        "reply":"要展示出售预留实例，只需在 Amazon EC2 控制台中完成以下步骤即可："
    },
    {
        "query":"可以展示出售哪些预留实例？",
        "intention":"知识问答",
        "reply":"您可以展示出售处于活动状态不少于 30 天且我们已收到付款的任何预留实例。通常情况下，这意味着一旦预留处于 Active 状态，您就可以将其展示出售。但需要注意的是，如果您是需要发票的客户，则您的预留实例将在 AWS 收到付款之前就已处于 Active 状态。在这种情况下，要等我们收到付款后，您才能展示出售该预留实例。"
    },
    {
        "query":"如何向买家显示所展示的预留实例？",
        "intention":"知识问答",
        "reply":"买家可以在 Amazon EC2 控制台的“预留实例”部分查看预留实例市场上展示的预留实例（包括第三方实例和由 AWS 提供的实例）。您也可以调用 DescribeReservedInstancesListings API。\n展示的预留实例均按类型、剩余期限、预付价格和小时价格进行分组。这种分组更易于买家找到要购买的适当预留实例。"
    },
    {
        "query":"可以展示预留实例的期限有多长？",
        "intention":"知识问答",
        "reply":"您可以出售预留实例的剩余期限，要向下舍入为最近的月数。例如，如果还剩有 9 个月 13 天的期限，那么您将标为出售有 9 个月期限的预留实例。"
    },
    {
        "query":"是否可以删除已展示出售的预留实例？",
        "intention":"知识问答",
        "reply":"可以，您可以在销售状态显示为待处理之前的任何时间删除您展示出售的预留实例。（“待处理”意味着买方已经购买您的预留实例，正在等待确认付款。）"
    },
    {
        "query":"可为要展示出售的预留实例设定哪些定价范围？",
        "intention":"知识问答",
        "reply":"使用预留实例市场，您可以设置您乐意接受的预付价格。您不能设置小时价格并且不会收到与小时价格相关的款项（为原始预留实例设定的小时价格保持不变）。"
    },
    {
        "query":"是否可以继续使用在预留实例市场展示出售的预留？",
        "intention":"知识问答",
        "reply":"可以，您将继续享有该预留的容量和计费优惠，直至售出为止。一旦售出，以折扣费率计费的所有运行中的实例都将以按需费率计费，除非您购买新的预留或终止实例。"
    },
    {
        "query":"是否可以转售从预留实例市场购得的预留实例？",
        "intention":"知识问答",
        "reply":"可以，您可以像出售其他预留实例一样转售从预留实例市场购得的预留实例。"
    },
    {
        "query":"出售预留实例时是否有任何限制？",
        "intention":"知识问答",
        "reply":"有，要在预留实例市场出售预留实例，您必须拥有一个美国境内的银行账户。我们很快就会支持美国境外的银行账户。另外，您也不得在美国政府云 GovCloud 地区出售预留实例。"
    },
    {
        "query":"是否可以出售通过公共批量定价级别购得的预留实例？",
        "intention":"知识问答",
        "reply":"不可以，此功能尚不可用。"
    },
    {
        "query":"AWS 能否出售我所展示出售的预留实例中的一部分？",
        "intention":"知识问答",
        "reply":"可以，AWS 可以出售您已展示出售的预留实例的一部分。例如，如果您展示了 100 个预留实例，我们可以仅向希望购买 50 个预留实例的买家显示您的预留实例。我们会出售这 50 个预留实例并继续展示剩下的 50 个预留实例，直至您决定不再展示。"
    },
    {
        "query":"买家如何为他们购买的预留实例付款？",
        "intention":"知识问答",
        "reply":"我们会通过 ACH 将已出售预留实例的付款电汇到一个美国境内银行账户。"
    },
    {
        "query":"何时能收到款项？",
        "intention":"知识问答",
        "reply":"AWS 从购买您预留的客户处收到款项后，我们就会向您在注册预留实例市场时指定的银行账户电汇款项。\n然后，我们会向您发送电子邮件通知，告诉您我们已向您电汇款项。一般而言，款项会在您的预留实例售出后 3 到 5 天内到账。"
    },
    {
        "query":"是否会通知我预留实例市场活动的相关信息？",
        "intention":"知识问答",
        "reply":"会的，您每天会收到一封电子邮件，详细描述您预留实例市场的活动，例如您创建或取消预留实例展示项目、买家购买您展示出售的项目或者 AWS 向您的银行账户支付款项等。"
    },
    {
        "query":"买家和卖家需要交换哪些信息以便计算交易税？",
        "intention":"知识问答",
        "reply":"买家应通过付款报告向卖家提供其所在的国家/地区、州、市以及邮政编码等信息。卖家将使用这些信息来计算需向政府缴纳的所有交易税 (如营业税、增值税等)。卖家需在购货发票上提供卖方法人实体名称。"
    },
    {
        "query":"购买第三方预留实例时，对客户是否有任何限制？",
        "intention":"知识问答",
        "reply":"有限制，客户不能购买自己展示出售的预留实例，包括任何关联账户下的实例（通过整合账单）。"
    },
    {
        "query":"什么是 Savings Plans？",
        "intention":"知识问答",
        "reply":"Savings Plans 是一种灵活的定价模式，它以较低的 EC2、Lambda 和 Fargate 使用价格，换取在 1 年或 3 年期限内的稳定使用量承诺（以 USD/小时为单位衡量）。注册 Savings Plans 后，不超过承付额的使用量将按 Savings Plans 折扣价格计费。例如，如果您承诺支付每小时 10 USD 的计算使用费，则不超过 10 USD 的使用量将按 Savings Plans 价格计费，而超过该承付额的任何使用量都将以按需价格计费。"
    },
    {
        "query":"AWS 提供哪些类型的 Savings Plans？",
        "intention":"知识问答",
        "reply":"AWS 提供两种类型的 Savings Plans："
    },
    {
        "query":"与 EC2 RI 相比，Savings Plans 的效果如何？",
        "intention":"知识问答",
        "reply":"Savings Plans 与按需方案（例如 EC2 RI）相比，节省大量开支，并且可以自动降低您的跨 AWS 区域计算使用费，即使使用情况发生了变化。这让您可以灵活地使用最适合自己需求的计算选项，继续节约资金，而无需进行任何交换或修改。\nCompute Savings Plans 最高可提供 66% 的成本节省（与可转换 RI 类似），它会自动降低您的一切 EC2 实例使用费，不分区域、实例系列、大小、操作系统、租期，甚至包括在 AWS Fargate 和 Lambda 上的使用费。EC2 Instance Savings Plans 最高可提供 72% 的成本节省（与标准 RI 类似），它会自动降低您在选定区域的选定 EC2 实例系列（例如弗吉尼亚北部区域的 M5 实例）内的一切实例使用费，不分实例大小、操作系统和租期。"
    },
    {
        "query":"Savings Plans 是否提供 EC2 实例容量预留？",
        "intention":"知识问答",
        "reply":"不提供，Savings Plans 不提供任何容量预留。不过，您可以通过[按需容量预留](https://aws.amazon.com/cn/ec2/faqs#On-Demand_Capacity_Reservation)来预留容量，并通过 Savings Plans 来支付较低的价格。"
    },
    {
        "query":"如何开始使用 Savings Plans？",
        "intention":"知识问答",
        "reply":"您可以从管理控制台中的 AWS Cost Explorer 或者通过 API/CLI 开始使用 Savings Plans。您可以借助 [AWS Cost Explorer](https://console.aws.amazon.com/cost-reports/home?region=us-east-1#/dashboard) 中提供的建议，轻松承诺使用某个 Savings Plan 并实现最大的成本节省。建议的小时承付额基于您的历史按需使用量以及您选择的计划类型、期限长度和付款选项。注册 Savings Plan 后，您的计算使用量将自动按 Savings Plan 折扣价格计费，超过承付额的任何使用量都将按正常按需价格计费。"
    },
    {
        "query":"我是否可以继续购买 EC2 RI？",
        "intention":"知识问答",
        "reply":"是的。您可以继续购买 RI 以保持与现有成本管理流程的兼容性，同时您的 RI 将与 Savings Plans 结合来降低您的总体费用。但随着您的 RI 到期，我们建议您注册 Savings Plans，因为这些计划能够提供与 RI 相同的成本节省，同时还具有更高的灵活性。"
    },
    {
        "query":"什么是 Spot 实例？",
        "intention":"知识问答",
        "reply":"Spot 实例是备用 EC2 容量，最多能够为您节省 90% 的按需价格，此类实例可由 AWS 通过 2 分钟通知进行中断。Spot 实例使用与按需和预留实例相同的底层 EC2 实例，最适合具有容错能力的灵活工作负载。Spot 实例提供额外的选项以获得计算容量，并且能够与按需和预留实例搭配使用。"
    },
    {
        "query":"Spot 实例与按需实例或预留实例有何区别？",
        "intention":"知识问答",
        "reply":"在运行时，Spot 实例与按需或预留实例完全相同。主要区别在于，Spot 实例通常会提供巨额按需价格折扣；您的实例可由 Amazon EC2 通过 2 分钟通知根据容量要求进行中断；Spot 价格根据长期供应和对备用 EC2 容量的需求逐渐调整。\n有关 Spot 实例的更多详细信息，请参阅[此处](https://aws.amazon.com/cn/ec2/spotathon/)。"
    },
    {
        "query":"如何购买和启动 Spot 实例？",
        "intention":"知识问答",
        "reply":"Spot 实例可以使用与您当前启动实例所用的相同工具来启动，其中包括 AWS 管理控制台、Auto-Scaling 组、运行实例和 Spot 队列。此外，许多 AWS 服务支持启动诸如 EMR、ECS、Datapipeline、CloudFormation 和 Batch 等 Spot 实例。\n要启动 Spot 实例，您只需选择一个启动模板和您想要请求的实例数量即可。\n有关如何请求 Spot 实例的更多详细信息，请参阅[此处](https://aws.amazon.com/cn/ec2/spot/details/)。"
    },
    {
        "query":"我可以请求多少个 Spot 实例？",
        "intention":"知识问答",
        "reply":"您可以请求的 Spot 实例最多为每个区域的 Spot 上限。请注意，新 AWS 客户的上限一开始可能会较低。如需了解有关 Spot 实例限制的更多信息，请参阅 [Amazon EC2 用户指南](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html)。\n如果需要提高上限，请依据您的使用案例填写 [Amazon EC2 实例请求表](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fsupport.console.aws.amazon.com%2Fsupport%2Fhome%3FhashArgs%3D%2523case%252Fcreate%253FissueType%253Dservice-limit-increase%2526limitType%253Dservice-code-ec2-instances%2526serviceLimitIncreaseType%253Dec2-instances%2526type%253Dservice_limit_increase%2526isauthcode%253Dtrue%2526code%253DdzkwDcZ52oii6pr9iPYylIvuM78ObPVkQug42ntPetVgfanCcFjKifdSEPXRx2_tIQp6hLDGGq_GSvJ7t1wKy_3x97YfW6IheoEZJhc9I_rifBs7i_76ZG8f5qZ8EU10kPjq1Bm6L-vOdh3iTfdFaObJ_irgWqaWTsMcZrt0Je9t9HV3272554QNYYjLS0PdDnBFbZlalCUf4p37KTyoifrZPgMGdVVZZuRE0KKJIOvEZo3GIw-MpYkcA0MlUqT3jenFQ9V8CYtkM0T7BCfdWmdXN59U4fmS9NKp75gpAvub4PTi1J5GqzS6QRE_UsKy6BXqguDhyQs57Unu93COwLZdwEmqMqo6WBhAi90ZY10XfleVigCgLvcp1Nh7_dPZ2W6Dn4oldC3odsTS4ZrX7tfsa13LsysDgEdgI6TzNeZ3rV1UpRlUwQe8W7tVYLmKQNPHz4DdEKynfj7Zas-RSTAUOJcbGmylTsraI4Vx9mpnZgs8vnFf-3sAzgmuchdoZLx0qmTrJSZWNm7qOLwxUVbNX2kaGocCzioUn1wxcN2AFcyanjFUHuVlxRoSYc4WYGncCZGuCS-bnoNZqYmTxLZniybzAixVS3UecOgOFG8QX8LJkVFkB-I2LUdfp4Cvq1UqT9rB00VKRNW2NPauDVxb2zYpcOabNGylt9dZiitfTsCy3mrULMRPOZQiBRqHyCIQ6Th-UZfT9uelnfpCXG5WD2lEEIN0W7ZZEpkoYbmVrFv23y2ahqXkzXLs3_YqOwDw9ODQt8jpc9_v-lPXaHLwvwOJNEYLzbFDdWo07E6w6dBiXoOBjBgOtFLC8lUU4UmrrMEahS32I-WdShTpBrQAPfx1TVGDAFhPbhEG-DG199LowkOlVAPWVWXZrHmKHxapnpflHWOm6ZNrA_dh4a5xho-ca101el-3AG2CEwIPZw8s0L5f2t9clLrwzuVH6OD5NbH23PptJs3iGVN20bjwPgpzlxThzxKMHziT4wXAcrTOAzFUa7t0v5wtbLNJSPURrXYKWYX7SJmzZELL7z9YKqRYUGCyiVmvyIhOHHjSLhsmvqfWO3lgjeBkNBTeKEbsLzMHwGNlFZKGqnyD8SCGwdrIBvLxanjR2XsAmPX-CrWAJU9KaRfXDZli-OusDX-T1DWcUKoLtJe1hnOiqZgzCgrb7wABkRRpCG8hgmvVaeKPSp-_YvlFbg%26isauthcode%3Dtrue%26state%3DhashArgsFromTB_us-east-1_ac2de5ad60d80e55&client_id=arn%3Aaws%3Asignin%3A%3A%3Aconsole%2Fsupportcenter&forceMobileApp=0&code_challenge=s09BEPQFrE7XeVc6pvE23KCcnuutUGXyIZINR-WsJKw&code_challenge_method=SHA-256)，我们随后将考虑您的申请。实例上限的提高与请求所针对的区域有关。"
    },
    {
        "query":"什么是 Spot 容量池？",
        "intention":"知识问答",
        "reply":"Spot 容量池是一组未使用的 EC2 实例，具有相同的实例类型、操作系统、可用区和网络平台 (EC2-Classic 或 EC2-VPC)。每个 Spot 容量池的价格都不同，具体取决于供需情况。"
    },
    {
        "query":"使用 Spot 实例的最佳实践是什么？",
        "intention":"知识问答",
        "reply":"我们强烈建议使用多个 Spot 容量池来最大限度地增加可用的 Spot 容量。EC2 内置有自动化功能，可以使用 EC2 Auto Scaling、EC2 队列或 Spot 队列从多个 Spot 容量池中找到最经济高效的容量。有关更多信息，请参阅[竞价型实例最佳实践](https://aws.amazon.com/cn/ec2/spot/spot-getting-started/)。"
    },
    {
        "query":"如何确定 Spot 请求的状态？",
        "intention":"知识问答",
        "reply":"您可以通过 Spot 请求状态代码和消息来确定 Spot 请求的状态。您可以在 AWS 管理控制台上 EC2 控制台的 Spot 实例页面访问 Spot 请求状态信息，也可以通过 API 和 CLI 查看。有关更多信息，请访问 [Amazon EC2 开发人员指南](https://docs.aws.amazon.com/ec2/index.html)。"
    },
    {
        "query":"Spot 实例是否适用于所有实例系列和大小，并在所有区域中可用？",
        "intention":"知识问答",
        "reply":"Spot 实例可在所有公共 AWS 区域使用。Spot 适用于几乎所有 EC2 实例系列和大小，包括最新的计算优化型实例、加速图形，以及 FPGA 实例类型。有关每个地区支持的实例类型的完整列表，请参阅[此处](https://aws.amazon.com/cn/ec2/spot/pricing/)。"
    },
    {
        "query":"哪些操作系统可作为 Spot 实例提供？",
        "intention":"知识问答",
        "reply":"Linux/UNIX、Windows Server 和 Red Hat Enterprise Linux (RHEL)。搭载 SQL Server 的 Windows Server 目前不支持。"
    },
    {
        "query":"是否可以将 Spot 实例与针对第三方软件（如 IBM 软件包）的付费 AMI 结合使用？",
        "intention":"知识问答",
        "reply":"目前不可以。"
    },
    {
        "query":"如果我的 Spot 实例停止或中断，我将如何付费？",
        "intention":"知识问答",
        "reply":"如果 Spot 实例在第一个小时内被 Amazon EC2 终止或停止，那么您无需支付使用费。但是如果您自己停止或终止了 Spot 实例，您就需要按使用秒数付费。如果 Spot 实例在第一个小时后的任何时间被 Amazon EC2 终止或停止，那么您需要按使用秒数付费。如果您在 Windows 或 Red Hat Enterprise Linux (RHEL) 上运行并且自己停止或终止了 Spot 实例，您就需要支付一整个小时的费用。"
    },
    {
        "query":"Spot 实例何时会中断？",
        "intention":"知识问答",
        "reply":"在过去 3 个月里，92% 的 Spot 实例中断是客户因应用程序已完成任务而手动终止的。\n如果 EC2 需要收回您的 Spot 实例，则可能有两个原因，其中主要原因是 Amazon EC2 容量需求（如使用按需或预留实例）。或者，如果您已选择设置“最大 Spot 价格”，而实际 Spot 价格高于这一价格，EC2 便会通过两分钟通知收回您的实例。此参数决定了您愿意按小时为 Spot 实例支付的最高价格，并默认设置为按需价格。与之前一样，在实例运行时，您将按每秒的增量继续支付 Spot 市场价格，而非最高价格。"
    },
    {
        "query":"如果我的 Spot 实例中断，会怎样？",
        "intention":"知识问答",
        "reply":"如果 Spot 实例中断，您可以选择让其终止、停止或休眠。停止和休眠选项可用于持久 Spot 请求以及启用了“维护”选项的 Spot 队列。默认情况下，您的实例将会终止。\n有关如何处理中断的更多信息，请参阅 [Spot 休眠](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-hibernation.html)。"
    },
    {
        "query":"停止和休眠中断操作有何区别？",
        "intention":"知识问答",
        "reply":"在休眠的情况下，您的实例会进入休眠状态，RAM 数据将持久保存。在停止的情况下，您的实例会关闭，RAM 数据将被清除。\n在这两种情况下，您在 EBS 根卷和任何附加 EBS 数据卷上的数据都将持久保存。您的私有 IP 地址保持不变，就像您的弹性 IP 地址一样（如适用）。网络层的行为将类似于 [EC2 停止启动工作流](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Stop_Start.html)。停止和休眠选项仅适用于 Amazon EBS 提供支持的实例。本地实例存储不会持久保存。"
    },
    {
        "query":"如果我的 EBS 根卷不够大，无法针对休眠存储内存状态 (RAM)，该怎么办？",
        "intention":"知识问答",
        "reply":"您应该在 EBS 根卷上有足够的空间来从内存中写入数据。如果 EBS 根卷没有足够的空间，则休眠将失败，实例会关闭。在选择休眠选项之前，请确保您的 EBS 卷足够大，能够持久保存内存数据。"
    },
    {
        "query":"Spot 在中断时休眠我的实例有什么优势？",
        "intention":"知识问答",
        "reply":"使用休眠选项，Spot 实例将暂停并恢复任何中断，这样您的工作负载便可从中断的位置恢复。如果您的实例需要在关闭启动周期内保持实例状态 (也就是当您在 Spot 上运行的应用程序依赖于存储在 RAM 中的上下文、业务或会话数据时)，您便可使用休眠选项。"
    },
    {
        "query":"要为我的 Spot 实例启用休眠选项，我需要做些什么？",
        "intention":"知识问答",
        "reply":"请参阅 [Spot 休眠](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-hibernation.html)，了解如何为 Spot 实例启用休眠选项。"
    },
    {
        "query":"休眠 Spot 实例是否需要付费？",
        "intention":"知识问答",
        "reply":"除了 EBS 存储成本以及其他任何您可能使用的 EC2 资源之外，休眠实例不会产生任何额外费用。一旦实例休眠，您就无需支付实例使用费。"
    },
    {
        "query":"是否可以重新启用休眠实例？",
        "intention":"知识问答",
        "reply":"不可以，您无法直接重启休眠的实例。休眠恢复周期是由 Amazon EC2 控制的。如果某个实例被 Spot 休眠，那么当容量可用时，Amazon EC2 会将其恢复。"
    },
    {
        "query":"哪些实例和操作系统支持休眠？",
        "intention":"知识问答",
        "reply":"目前，在内存 (RAM) 小于 100GiB 的任意 C3、C4、C5、M4、M5、R3、R4 系列实例类型上运行的 Amazon Linux AMI、Ubuntu 和 Microsoft Windows 操作系统均支持 Spot 休眠。\n要查看受支持操作系统版本的列表，请参阅 [Spot 休眠](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-hibernation.html)。"
    },
    {
        "query":"Spot 数据块（固定期限 Spot 实例）是否会中断？",
        "intention":"知识问答",
        "reply":"Spot 数据块被设计为不会中断，无论 Spot 市场价格如何，都会在您选择的期限内不间断运行。在极少数情况下，Spot 数据块会由于 AWS 的容量需求而中断。在这种情况下，我们将在终止您的实例前提供一条两分钟的警告（[终止通知](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-interruptions.html#spot-instance-termination-notices)），您无需为受影响的实例支付费用。"
    },
    {
        "query":"什么是 Spot 队列？",
        "intention":"知识问答",
        "reply":"Spot 队列可让您自动请求并管理多个为集群或应用程序提供最低单位容量价格的 Spot 实例，例如批处理作业、Hadoop 工作流，或 HPC 网格计算作业等。您可以添加应用程序可以使用的实例类型。您可以根据应用程序需求 (按实例、vCPU、内存、存储或网络吞吐量等) 定义目标容量，并在队列启动后更新目标容量。Spot 队列可让您启动和维持目标容量，并自动请求资源来替换任何中断或手动终止的资源。[了解有关 Spot 队列的更多信息](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html)。"
    },
    {
        "query":"Spot 队列请求存在什么限制？",
        "intention":"知识问答",
        "reply":"请参阅《Amazon EC2 用户指南》的 [Spot 队列限制](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-limits.html#spot-fleet-limitations)部分，了解适用于您的 Spot 队列请求的限制。"
    },
    {
        "query":"如果我的 Spot 队列请求尝试启动 Spot 实例，但超过区域 Spot 请求限制该怎么办？",
        "intention":"知识问答",
        "reply":"如果您的 Spot 队列请求超过区域 Spot 实例请求限制，单个 Spot 实例请求将失败，并显示“超出 Spot 请求限制的请求状态”。您的 Spot 队列请求历史记录将显示队列请求收到的任何 Spot 请求限制错误。请参阅《Amazon EC2 用户指南》的[监控您的 Spot 队列](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet-requests.html#manage-spot-fleet)部分，了解如何描述您的 Spot 队列请求历史记录。"
    },
    {
        "query":"问：是否可以保证满足 Spot 队列请求？",
        "intention":"知识问答",
        "reply":"不可以。Spot 队列请求可让您同时提交多个 Spot 实例请求，但其受可用性和价格的影响程度与单一 Spot 实例请求相同。例如，如果您的 Spot 队列请求中列出的实例类型没有可用的资源，那么我们可能无法部分或全部满足您的请求。我们建议您将可能适合工作负载的所有实例类型和可用区都添加到 Spot 队列中。"
    },
    {
        "query":"我能否提交多可用区 Spot 队列请求？",
        "intention":"知识问答",
        "reply":"能。请参阅《Amazon EC2 用户指南》的 [Spot 队列示例](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet-examples.html)部分，了解如何提交多可用区 Spot 队列请求。"
    },
    {
        "query":"我能否提交多区域 Spot 队列请求？",
        "intention":"知识问答",
        "reply":"否，我们不支持多区域队列请求。"
    },
    {
        "query":"Spot 队列如何跨启动说明中指定的各种 Spot 实例池分配资源？",
        "intention":"知识问答",
        "reply":"RequestSpotFleet API 提供以下三种分配策略：容量优化、最低价格和多样性。容量优化分配策略意在通过分析容量指标从最可用的 Spot 实例池中预置 Spot 实例。此策略适用于大数据和分析、图像和媒体渲染、机器学习以及高性能计算等具有更高中断成本的工作负载。\n借助 lowestPrice 策略，您可以在请求时单位容量价格最低的实例池中预置您的 Spot 队列资源。借助多样化策略，您可以跨多个 Spot 实例池预置您的 Spot 队列资源。这样，您既能维持队列的目标容量，又能随着 Spot 实例容量的波动提高应用程序的可用性。\n跨不同的 Spot 实例池运行您应用程序的资源还可以进一步降低您队列的累计运营成本。有关更多信息，请参阅 [Amazon EC2 用户指南](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html#spot-fleet-allocation-strategy)。"
    },
    {
        "query":"我能否标记 Spot 队列请求？",
        "intention":"知识问答",
        "reply":"您可以请求通过 Spot 队列使用标记启动 Spot 实例。队列本身无法标记。"
    },
    {
        "query":"如何查看哪个 Spot 队列拥有我的 Spot 实例？",
        "intention":"知识问答",
        "reply":"您可以通过描述队列请求，确定与 Spot 队列关联的 Spot 实例。终止其所有 Spot 实例后，集群请求在 48 小时内可用。有关如何描述 Spot 队列请求的信息，请参阅 [Amazon EC2 用户指南](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet-requests.html#manage-spot-fleet)。"
    },
    {
        "query":"我能否修改 Spot 队列请求？",
        "intention":"知识问答",
        "reply":"目前，您只能修改 Spot 队列请求的目标容量。您可能需要取消该请求，然后提交一个新请求来更改其他请求配置参数。"
    },
    {
        "query":"我能否为希望使用的每个实例类型指定不同的 AMI？",
        "intention":"知识问答",
        "reply":"能，只需指定希望为 Spot 队列请求提供的每种启动规格使用的 AMI。"
    },
    {
        "query":"我能否将 Spot 队列与 Elastic Load Balancing、Auto Scaling 或 Elastic MapReduce 配合使用？",
        "intention":"知识问答",
        "reply":"您可以将 Spot 队列与 Auto Scaling 功能（如目标跟踪、运行状况检查和 CloudWatch 指标等）配合使用，还可以将实例连接到 Elastic Load Balancer（Classic Load Balancer 和 Application Load Balancer）。Elastic MapReduce 有一项名为“实例队列”的功能，其类似于 Spot 队列。"
    },
    {
        "query":"如果 Spot 实例停止在最低价或容量优化 Spot 池中运行，Spot 队列请求是否会终止 Spot 实例，然后重新启动？",
        "intention":"知识问答",
        "reply":"不会，Spot 队列请求不会在实例运行时自动终止和重启它们。但是，如果您终止了一个 Spot 实例，那么 Spot 队列将基于您的分配策略，使用新的最低价池或容量优化池中的新 Spot 实例进行补充。"
    },
    {
        "query":"我能否对 Spot 队列执行停止或休眠中断操作？",
        "intention":"知识问答",
        "reply":"能，启用了“维护”队列选项的 Spot 队列支持停止启动和休眠恢复。"
    },
    {
        "query":"如何使用该服务？",
        "intention":"知识问答",
        "reply":"该服务在本地链接 IP 地址 (169.254.169.123) 上提供了 NTP 终端节点，其可从在 VPC 中运行的任意实例进行访问。有关配置 NTP 客户端的说明适用于 [Linux](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html) 和 [Windows](http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/windows-set-time.html)。"
    },
    {
        "query":"使用该服务可以获得哪些主要优势？",
        "intention":"知识问答",
        "reply":"一致且准确的参考时间源对于许多应用程序和服务都至关重要。Amazon Time Sync Service 提供的时间参考可从实例安全地进行访问，而不需要更改和更新 VPC 配置。该服务建立在 Amazon 久经考验的网络基础设施之上，并且使用冗余的参考时间源来确保高准确性和可用性。"
    },
    {
        "query":"该服务支持哪些实例类型？",
        "intention":"知识问答",
        "reply":"在 VPC 中运行的所有实例均可访问该服务。"
    },
    {
        "query":"可用区之间的隔离程度如何？",
        "intention":"知识问答",
        "reply":"每个可用区在其独立的、物理上显著不同的基础设施中运行，具有高度可靠性。可用区之间不共用像发电机和冷却设备那样的常见故障点。此外，它们在物理上也是相互独立的，即使火灾、龙卷风或洪涝等极为罕见的灾难也只会影响单个可用区。"
    },
    {
        "query":"Amazon EC2 是否在多个 AWS 区域运行？",
        "intention":"知识问答",
        "reply":"可以。请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，进一步详细了解我们的产品和服务在不同区域的具体提供情况。"
    },
    {
        "query":"如何确保我与另一开发人员处于同一可用区域中？",
        "intention":"知识问答",
        "reply":"我们当前不支持协调不同 AWS 开发人员账户启动到同一可用区域的功能。两个 AWS 客户账户中的一个可用区名称（例如 us-east-1a）可能与不同的物理可用区相关联。"
    },
    {
        "query":"什么是集群计算实例？",
        "intention":"知识问答",
        "reply":"集群计算实例将丰富的计算资源和高性能联网相结合，适合 HPC 应用程序和其他高要求的网络绑定型应用程序。集群计算实例提供与其他 Amazon EC2 实例相似的功能，但经过了专门设计，能够提供高性能联网功能。\n用户可以通过 Amazon EC2 集群放置组功能将集群计算实例分组到集群中，让应用程序获得紧密耦合节点对节点通信（许多 HPC 应用程序的典型特征）所需的低延迟网络性能。集群计算实例还可大幅提升 Amazon EC2 环境内以及至 Internet 的网络吞吐量。因此，这些实例也非常适合需要执行网络密集型操作的客户应用程序。\n[详细了解](https://aws.amazon.com/cn/hpc/)如何将此实例类型用于 HPC 应用程序。"
    },
    {
        "query":"在集群置放群组中启动实例时有望实现哪些网络性能？",
        "intention":"知识问答",
        "reply":"EC2 实例在集群置放群组中可利用的带宽取决于实例类型及其联网性能规格。对于同一地区内的实例间流量，单支流量可利用 5Gbps，多支流量可利用最高 25Gbps。当在一个置放群组中启动时，部分 EC2 实例的单支流量可利用最高 10Gbps。"
    },
    {
        "query":"什么是集群 GPU 实例？",
        "intention":"知识问答",
        "reply":"集群 GPU 实例提供通用的图形处理单元 (GPU) 以及比例较高的 CPU 和更高的网络性能，适用于可使用 CUDA 和 OpenCL 编程模型通过 GPU 对高度并行处理进行加速，从而受益的应用程序。常见的应用程序包括建模和模拟、渲染，以及媒体处理。\n集群 GPU 实例为具有 HPC 工作负载的客户提供了集群计算实例之外的一个选项，使他们可以在云中进一步自定义其高性能集群，适用于可以从 GPU 的并行计算能力中获益的应用程序。\n集群 GPU 实例与集群计算实例使用相同的集群放置组功能，将实例分组到集群中，让应用程序获得紧密耦合节点对节点通信（许多 HPC 应用程序的典型特征）所需的低延迟网络性能。\n[详细了解](https://aws.amazon.com/cn/hpc/) AWS 上的 HPC。"
    },
    {
        "query":"什么是内存增强型集群实例？",
        "intention":"知识问答",
        "reply":"除了较高的网络能力外，内存增强型集群实例还为客户提供了大量的内存和 CPU 能力。这些实例类型非常适合于内存密集型的工作负载，包括内存分析系统、图形分析，以及许多科学和工程应用。\n内存增强型集群实例与集群计算实例使用相同的集群置放群组功能，将实例分组到集群中，让应用程序获得紧密耦合的节点间通信（许多 HPC 和其他网络密集型应用程序的典型特征）所需的低延迟、高带宽网络性能。"
    },
    {
        "query":"集群计算实例和集群 GPU 实例的使用与其他 Amazon EC2 实例类型是否不同？",
        "intention":"知识问答",
        "reply":"集群计算实例和集群 GPU 实例的使用与其他 Amazon EC2 实例类型有两个方面的区别。\n首先，群集计算实例和群集 GPU 实例使用基于硬件虚拟机 (HVM) 的虚拟化技术，仅运行基于 HVM 虚拟化的 Amazon 系统映像 (AMI)。其他 Amazon EC2 实例类型所用的基于半虚拟机 (PVM) 的 AMI 无法用于群集计算实例和群集 GPU 实例。\n第二，为了能够充分受益于实例之间可用的低延迟对分带宽，必须通过 Amazon EC2 API 或 AWS 管理控制台将集群计算实例和集群 GPU 实例发送到集群置放群组中。"
    },
    {
        "query":"什么是集群置放群组？",
        "intention":"知识问答",
        "reply":"集群置放群组是一种逻辑实体，可以通过作为组的一部分启动实例来创建实例集群。然后，实例群集会在同一组中的实例之间提供低延迟连接。您可以通过 Amazon EC2 API 或 AWS 管理控制台创建集群置放群组。"
    },
    {
        "query":"Amazon EC2 的所有功能是否都可用于集群计算实例和集群 GPU 实例？",
        "intention":"知识问答",
        "reply":"目前 Amazon DevPay 不可用于集群计算实例和集群 GPU 实例。"
    },
    {
        "query":"可以使用的集群计算实例或集群 GPU 实例的数量，及/或通过集群计算实例或集群 GPU 实例启动到集群置放群组而创建的集群的大小是否有限制？",
        "intention":"知识问答",
        "reply":"对于集群计算实例而言，没有具体的限制。对于群集 GPU 实例来说，您可以自行启动 2 个实例。如果需要更多的容量，请填写 [Amazon EC2 实例申请表](https://aws.amazon.com/cn/contact-us/ec2-request/)（选择适当的主实例类型）。"
    },
    {
        "query":"通过集群置放群组为集群请求实例时，是否有什么方式可以优化我收到完整数量的实例的可能性？",
        "intention":"知识问答",
        "reply":"我们建议您在一次启动中启动加入集群所需的最低数量的实例。对于非常大的集群，您应当启动多个放置组（例如，两个包含 128 个实例的放置组），将它们组合起来创建一个更大的 256 实例集群。"
    },
    {
        "query":"集群 GPU 实例和集群计算实例是否可以启动到同一个集群置放群组中？",
        "intention":"知识问答",
        "reply":"尽管或许可以将不同的集群实例类型启动到一个放置组中，我们目前仅支持同类放置组。"
    },
    {
        "query":"如果集群置放群组中的某个实例停止后又重新启动，该实例是否会保留在该集群置放群组中？",
        "intention":"知识问答",
        "reply":"是的。停止的实例会作为停止时所属的群集置放群组的一部分启动。如果没有容量供其在所属集群置放群组中启动，启动会失败。"
    },
    {
        "query":"EC2 实例提供哪些 CPU 选项？",
        "intention":"知识问答",
        "reply":"EC2 实例提供各种 CPU 选项帮助客户平衡性能和成本要求。  EC2 根据实例类型提供 CPU 选择，其中包括 AWS Graviton/Graviton2 处理器 (Arm)、AMD 处理器 (x86) 和 Intel 处理器 (x86)。"
    },
    {
        "query":"我的应用程序堆栈将在哪类硬件上运行？",
        "intention":"知识问答",
        "reply":"请访问 [Amazon EC2 实例类型](https://aws.amazon.com/cn/ec2/instance-types/)，查看各区域提供的 EC2 实例列表。"
    },
    {
        "query":"EC2 如何执行维护？",
        "intention":"知识问答",
        "reply":"AWS 定期执行常规硬件、软件、电源和网络维护，将 EC2 实例类型中断情况降至最低。这是通过跨整个 AWS 全球基础设施的技术和方法的组合来实现的，例如实时更新和实时迁移以及冗余且可同时维护的系统。实时更新和实时迁移等非侵入式维护技术不需要停止或重启实例。客户无需在实时迁移或实时更新之前、期间或之后执行任何操作。这些技术有助于提高应用程序的正常运行时间并减少您的运营工作量。Amazon EC2 使用实时更新将软件快速部署到服务器，同时最大程度地降低对客户实例的影响。实时更新可确保客户的工作负载在服务器上运行，该服务器上的软件是最新的，具有安全补丁、新实例功能和性能改进。当需要将正在运行的实例从一台服务器移动到另一台服务器以进行硬件维护或优化实例放置或动态管理 CPU 资源时，Amazon EC2 会使用实时迁移。多年来，Amazon EC2 一直在扩大非侵入式维护技术的范围和覆盖面，因此定期维护事件是一种备用选项，而不是启用日常维护的主要方式。"
    },
    {
        "query":"我如何选择正确的实例类型？",
        "intention":"知识问答",
        "reply":"Amazon EC2 实例分为 5 个系列：“通用型”、“计算优化型”、“内存优化型”、“存储优化型”和“加速计算型”实例。通用型实例的内存与 CPU 之比适合大部分通用应用，并且附带固定性能或突发性能；计算优化型实例的 CPU 资源按比例多于内存 (RAM) 并且非常适合于计算密集型应用和高性能计算 (HPC) 工作负载；内存优化型实例为内存密集型应用提供更大的内存，其中包括数据库和内存缓存应用；加速计算实例使用硬件加速器或协同处理器来执行浮点数计算、图形处理或数据模式匹配之类的功能，比使用在 CPU 上运行的软件更高效；存储优化型实例使用基于 SSD 的本地实例存储提供低延迟和 I/O 容量，适用于 I/O 密集型应用；以及密集 HDD 存储实例，其为数据仓库、Hadoop 和其他数据密集型应用提供本地高存储密度和连续 I/O 性能。在选择实例类型时，应该考虑您的应用程序在资源使用率（即 CPU、内存和存储）方面的特点，选择最佳的实例系列和大小。"
    },
    {
        "query":"什么是“EC2 计算单位”，为什么要引入此单位？",
        "intention":"知识问答",
        "reply":"向效用计算模型的过渡从根本上改变了开发人员对 CPU 资源的惯性思维。您不再购买或租用特定的处理器并用上数月或数年，而是以小时为单位租用容量。由于 Amazon EC2 是在商用硬件基础上构建的，随着时间推移，可能会有多种不同类型的物理硬件为 EC2 实例提供支持。我们的目标是提供一致的 CPU 容量，无论实际的底层硬件是什么。\nAmazon EC2 通过多种衡量标准，为每个实例提供一致且可预计的 CPU 容量。为了便于开发人员可以在不同的实例类型之间比较 CPU 容量，我们定义了 Amazon EC2 计算单位。分配给特定实例的 CPU 量是以这些 EC2 计算单位来表示的。我们使用多种基准和测试来管理一个 EC2 计算单位的性能一致性和可预计性。EC2 计算单位 (ECU) 可为 Amazon EC2 实例的整数处理能力提供相对的衡量标准。随着时间推移，如果我们发现能更明确地表示计算容量的指标，我们可能会增加或替换进入 EC2 计算单位定义的衡量标准。"
    },
    {
        "query":"EC2 随着时间的推移如何确保实例类型的一致性能？",
        "intention":"知识问答",
        "reply":"AWS 对 EC2 实例类型的 Linux 和 Windows 计算性能进行年度性能基准测试。请联系您的销售代表获取基准测试结果、客户可用于进行独立测试的测试套件，以及基于 NDA 提供的有关 M、C、R、T 和 z1d 实例的预期性能差异的指导。"
    },
    {
        "query":"各种 Amazon EC2 实例类型分别在哪些区域可用？",
        "intention":"知识问答",
        "reply":"有关所有实例和区域可用性的列表，请访问 [Amazon EC2 定价](https://aws.amazon.com/cn/ec2/pricing/)。"
    },
    {
        "query":"微型实例可以提供多少计算能力？",
        "intention":"知识问答",
        "reply":"微型实例提供少量持续的 CPU 资源，但您可用其他周期在短时间内将 CPU 容量突增至 2 个 ECU。它们非常适合具备下述特点的较低吞吐量应用程序和网站：定期消耗大量的计算周期，但在其他时间中只消耗极少的 CPU 来用于后台进程和守护进程等。[详细了解](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/concepts_micro_instances.html)如何使用实例类型。"
    },
    {
        "query":"微型实例与标准小型实例相比，在计算能力上有何不同？",
        "intention":"知识问答",
        "reply":"在稳定状态时，微型实例接收的计算资源仅占小型实例所能接收的一小部分。因此，如果您的应用程序具有计算密集型或稳定状态需求，我们建议您使用小型实例 (或者依据您的需求，使用更大型的实例)。然而，微型实例可以定期突增至多达 2 个 ECU (短时间内)。这是标准小型实例可用的 ECU 数的两倍。因此，如果您有相对较低吞吐量的应用程序或网站，并且偶尔需要消耗大量的计算周期，则建议您使用微型实例。"
    },
    {
        "query":"如何判断应用程序需要的 CPU 资源是否超过微型实例所提供的资源？",
        "intention":"知识问答",
        "reply":"如果在 CloudWatch 监控的分钟内，实例突发量超过其可用的 CPU 资源量，CPU 使用率的 CloudWatch 指标会报告 100% 使用率。CloudWatch 报告 100% CPU 使用率时，表示您应当考虑（手动或通过 Auto Scaling）增大到更大的实例类型，或扩展为多个微型实例。"
    },
    {
        "query":"Amazon EC2 的所有功能是否都可用于微型实例？",
        "intention":"知识问答",
        "reply":"目前，Amazon DevPay 不可用于微型实例。"
    },
    {
        "query":"问：什么是 Nitro 管理程序？",
        "intention":"知识问答",
        "reply":"我们在发布 C5 实例时针对 Amazon EC2 推出了一种新管理程序，即 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器。作为 Nitro 系统的一部分，Nitro 管理程序主要为 EC2 实例提供 CPU 和内存隔离。VPC 联网和 EBS 存储资源由专用的硬件组件“Nitro 卡”(属于最新一代 EC2 实例系列) 实施。Nitro 管理程序采用核心 Linux 基于内核的虚拟机 (KVM) 技术，但不包含通用操作系统组件。"
    },
    {
        "query":"问：Nitro 管理程序能够为客户带来哪些优势？",
        "intention":"知识问答",
        "reply":"[Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器去除了主机系统软件组件，可以为 EC2 虚拟化实例提供稳定的性能和更多的计算和内存资源。它让 AWS 能够提供更大的、可以从服务器向客户提供几乎所有资源的实例（例如 c5.18xlarge）。以前，C3 和 C4 实例将 VPC 和 EBS 的功能转移到由 AWS 设计和构建的硬件上，从而去除了软件组件。这种硬件让 Nitro 管理程序变得非常小，而且不参与联网和存储方面的数据处理任务。"
    },
    {
        "query":"问：所有 EC2 实例都会使用 Nitro 管理程序吗？",
        "intention":"知识问答",
        "reply":"所有新的实例类型最终都会使用 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器，但是在短期内，某些新的实例类型会使用 Xen，具体取决于平台的要求。"
    },
    {
        "query":"问：AWS 会继续投资基于 Xen 的管理程序吗？",
        "intention":"知识问答",
        "reply":"是的。随着 AWS 扩展其全球云基础设施，EC2 对其基于 Xen 的管理程序的使用也将继续增长。在可预见的未来，Xen 将仍然是 EC2 实例的核心组件。AWS 是 Xen 项目 (前身为 Linux 基金会合作项目) 的创始成员之一，并且一直是其顾问委员会的积极参与者。随着 AWS 扩展其全球云基础设施，EC2 基于 Xen 的管理程序也将继续开发。因此，EC2 对 Xen 的投资仍将增加，而不会减少。"
    },
    {
        "query":"使用 Nitro 管理程序的实例可以连接多少个 EBS 卷和弹性网络接口 (ENI)？",
        "intention":"知识问答",
        "reply":"使用 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器的实例最多支持 27 个额外的用于 EBS 卷和 VPC ENI 的 PCI 设备。每个 EBS 卷或 VPC ENI 都使用一个 PCI 设备。例如，如果您额外将 3 个网络接口连接到一个使用 Nitro 管理程序的实例，那么该实例最多可以连接 24 个 EBS 卷。"
    },
    {
        "query":"问：Nitro 管理程序是否会改变用来与 EC2 实例交互的 API？",
        "intention":"知识问答",
        "reply":"不会，用来与使用 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器运行的 EC2 实例交互的所有公开 API 都会保持不变。例如，对于所有 EC2 实例（包括使用 Nitro 管理程序的实例），在对 DescribeInstances 的响应中，“hypervisor”（管理程序）字段仍会显示“xen”。未来版本的 EC2 API 可能会移除这一字段。"
    },
    {
        "query":"使用 Nitro 管理程序的实例支持哪些 AMI？",
        "intention":"知识问答",
        "reply":"使用 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器的实例可以使用由 EBS 提供支持、支持 ENA 联网并能从 NVMe 存储启动的 HVM AMI。Amazon 提供的最新 Amazon Linux AMI 和 Windows AMI 以及最新的 Ubuntu、Debian、Red Hat Enterprise Linux、SUSE Enterprise Linux、CentOS 和 FreeBSD AMI 都会受到支持。"
    },
    {
        "query":"使用 Xen 管理程序和使用 Nitro 管理程序的实例之间有没有差别？",
        "intention":"知识问答",
        "reply":"是的。例如，使用 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器的实例通过 NVMe 接口从 EBS 卷启动。使用 Xen 的实例从一个模拟的 IDE 硬盘驱动器启动，然后切换到 Xen 半虚拟化块存储设备驱动程序。\n操作系统可以识别出自己使用的管理程序。某些软件会假设 EC2 实例将会使用 Xen 管理程序，然后根据系统的检测结果做出反应。当实例使用 Nitro 管理程序时，操作系统会检测出自己在运行 KVM，所以用于识别 EC2 实例的过程也应该用于识别使用两种管理程序的 EC2 实例。\n在使用 Xen 和使用 Nitro 管理程序的实例上，EC2 的所有功能（如实例元数据服务）均以同样的方式运行。只要操作系统具备 ENA 联网和 NVMe 存储所需的支持，那么大多数应用程序在 Xen 和 [Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器下均以同样的方式运行。"
    },
    {
        "query":"Nitro 管理程序如何实施实例重启和终止 EC2 API 请求？",
        "intention":"知识问答",
        "reply":"[Nitro](https://aws.amazon.com/cn/ec2/nitro/) 虚拟机监控器会向实例中运行的操作系统发送信号，告知其应该使用行业标准的 ACPI 方法彻底将自己关闭。对于 Linux 实例，这需要安装 acpid 并且其能正常运行。如果 acpid 没有在实例中运行，那么终止事件将延迟几分钟，然后执行为硬重置或关闭。"
    },
    {
        "query":"被 NVMe 接口访问时，EBS 卷会怎样运作？",
        "intention":"知识问答",
        "reply":"操作系统 NVMe 驱动程序与 Xen 半虚拟化 (PV) 块驱动程序在行为上有一些重要差别。\n首先，基于 Linux 的操作系统使用的 NVMe 设备名称将会不同于 EBS 卷连接请求的参数，也不同于块存储设备映射条目 (例如/dev/xvda 和 /dev/xvdf)。NVMe 设备会被操作系统列举为 /dev/nvme0n1、/dev/nvme1n1 等，以此类推。NVMe 设备名称不会与卷保持持续映射，因此在配置文件系统的自动安装或其他启动活动时，应该使用文件系统 UUID 或标签等其他方式。当 EBS 卷被通过 NVMe 接口访问时，EBS 卷 ID 会通过控制器序列号来提供，而在 EC2 API 请求中指定的设备名称由 NVMe 供应商反馈给 Identify Controller 命令。这样，一个实用工具脚本就可以创建向后兼容的符号链接。有关更多信息，请参阅关于设备命名和基于 NVMe 的 EBS 卷的 EC2 文档。\n其次，在默认情况下，大多数操作系统中包含的 NVMe 驱动程序都会进行 I/O 超时。如果 I/O 没有在实现特定的时间（通常为几十秒）内完成，驱动程序将尝试取消此 I/O 并重试，或向发出此 I/O 的组件返回错误。Xen PV 块储存设备接口不会产生 I/O 超时，这会导致无法终止等待 I/O 的进程。可以通过为 nvme.io 超时内核模块参数指定更大的值来修改 Linux NVMe 驱动程序行为。\n第三，与 Xen PV 数据块接口相比，NVMe 接口可以在每次 I/O 操作时传输更多的数据，并且在某些情况下可以支持更多待处理的 I/O 请求。如果向用于支持吞吐量工作负载的卷 (例如 EBS 吞吐量优化型 HDD (st1) 卷和 Cold HDD (sc1) 卷) 发送非常大的 I/O 或大量 I/O 请求，这可能会导致更高的 I/O 延迟。在上述情况下，对于吞吐量优化型卷，这种 I/O 延迟是正常的，但可能会导致 NVMe 驱动程序中的 I/O 超时。可以通过为 nvme\\_core.io\\_timeout 内核模块参数指定一个较大的值来调整 Linux 驱动程序中的 I/O 超时。"
    },
    {
        "query":"什么是优化 CPU？",
        "intention":"知识问答",
        "reply":"优化 CPU 功能使您能够更好地控制两个正面的 EC2 实例。首先，您可以在启动新实例时指定自定义数量的 vCPU，以节省基于 vCPU 的许可成本。其次，您可以针对在单线程 CPU 条件下运行良好的工作负载禁用 Intel 超线程技术 (Intel HT Technology)，例如某些 HPC 应用程序。"
    },
    {
        "query":"为何要使用优化 CPU 功能？",
        "intention":"知识问答",
        "reply":"如果您属于以下情况，则应该使用优化 CPU："
    },
    {
        "query":"CPU 优化实例如何定价？",
        "intention":"知识问答",
        "reply":"CPU 优化实例的定价规则与同等的全尺寸实例相同。"
    },
    {
        "query":"在 EC2 上使用优化 CPU 时，我的应用程序性能会如何变化？",
        "intention":"知识问答",
        "reply":"您的应用程序性能通过优化 CPU 发生变化的情况主要取决于您在 EC2 上运行的工作负载。我们建议您使用优化 CPU 对您的应用程序性能进行基准测试，以实现合适数量的 vCPU 和应用程序的最佳超线程行为。"
    },
    {
        "query":"能否在 EC2 裸机实例类型（例如 i3.metal）上使用优化 CPU？",
        "intention":"知识问答",
        "reply":"不可以。您只能在虚拟 EC2 实例上使用优化 CPU。"
    },
    {
        "query":"如何开始将优化 CPU 用于 EC2 实例？",
        "intention":"知识问答",
        "reply":"有关如何开始使用优化 CPU 以及受支持实例类型的更多信息，请访问[此处](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/instance-optimize-cpu.html)的优化 CPU 文档页面。"
    },
    {
        "query":"使用 Amazon EC2 运行 IBM 软件时如何计费？",
        "intention":"知识问答",
        "reply":"按实际用量付费，而且没有最低费用。定价依据为每种实例类型所消耗的实例小时数。运行未满一小时的实例，将按一小时计费。Amazon EC2 运行 IBM 软件的数据传输与 Amazon EC2 分开计费和分级。同一地区内两种 Amazon Web Services 之间传输数据不收费 (例如在美国西部 Amazon EC2 和美国西部的另一 AWS 服务之间)。在不同地区的 AWS 服务之间传输数据时，将在传输的两端收取 Internet 数据传输费。\n有关运行 IBM 软件的 Amazon EC2 的定价信息，请访问[“运行 IBM 软件的 Amazon EC2”详细信息页面](https://aws.amazon.com/cn/partners/find/partnerdetails/?n=IBM-&id=001E000000UfakGIAR)中的定价部分。"
    },
    {
        "query":"是否可以将 Amazon DevPay 与 Amazon EC2 运行 IBM 软件配合使用？",
        "intention":"知识问答",
        "reply":"不可以。目前您无法使用 DevPay 捆绑运行 IBM 软件的 Amazon EC2 上的产品。"
    },
    {
        "query":"是否可以将现有的 Windows Server 许可用于 EC2？",
        "intention":"知识问答",
        "reply":"是的，可以。当您使用 ImportImage 工具导入自有的 Windows Server 系统映像后，您可以在 EC2 专用主机上启动这些系统映像的实例，以便有效管理实例和报告使用情况。Microsoft 通常会要求您针对物理资源 (例如套接字和内核) 跟踪许可证的使用情况，而专用主机会帮助您执行此操作。有关如何在 Amazon EC2 专用主机上使用自有 Windows Server 许可证的更多信息，请访问专属主机详细信息页面。"
    },
    {
        "query":"我可以将什么软件许可带入 Windows 环境？",
        "intention":"知识问答",
        "reply":"具体的软件许可证条款因供应商而异。因此，我们建议您查看软件供应商的许可条款，以确定您现有的许可证是否已获得授权，可以在 Amazon EC2 中使用。"
    },
    {
        "query":"什么是 Amazon EC2 Mac 实例？",
        "intention":"知识问答",
        "reply":"Amazon EC2 Mac 实例使客户能够首次在云中按需运行 macOS 工作负载，从而将 AWS 的灵活性，可扩展性和成本优势扩展到所有 Apple 开发人员。借助 EC2 Mac 实例，在 iPhone、iPad、Mac、Apple Watch、Apple TV 和 Safari 上创建应用程序的开发人员可以在数分钟内预置和访问 macOS 环境，根据需要动态扩展容量，并从 AWS 的即用即付定价模式中受益。"
    },
    {
        "query":"您应该在 EC2 Mac 实例上运行哪些工作负载？",
        "intention":"知识问答",
        "reply":"Amazon EC2 Mac 实例旨在为 iOS、iPadOS、watchOS、tvOS、macOS 和 Safari 等 Apple 平台构建、测试、签名和发布应用程序。与在本地运行 macOS 相比，Pinterest、Intuit、FlipBoard、Twitch 和 Goldman Sachs 等客户的构建性能提高了 75%，构建失败率降低了 80%，并行构建数量增加了 5 倍。"
    },
    {
        "query":"什么是 EC2 x86 Mac 实例？",
        "intention":"知识问答",
        "reply":"基于 x86 的 EC2 Mac 实例在搭载 Intel Core i7 处理器并由 [AWS Nitro System](https://aws.amazon.com/cn/ec2/nitro/) 提供支持的 Apple Mac 迷你计算机上构建。他们为客户提供了 macOS Mojave（10.14）、macOS Catalina（10.15）、macOS Big Sur（11）和 macOS Monterey（12）作为 Amazon 机器映像（AMI）的选择。基于 x86 的 EC2 实例在 12 个区域中可用：美国东部（俄亥俄州、弗吉尼亚州北部）、美国西部（俄勒冈州）、欧洲地区（阿姆斯特丹、法兰克福、爱尔兰、伦敦）和亚太地区（孟买、首尔、新加坡、悉尼、东京）。可在[此处](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)了解详情并开始使用基于 x86 的 EC2 Mac 实例。"
    },
    {
        "query":"什么是 EC2 M1 Mac 实例？",
        "intention":"知识问答",
        "reply":"EC2 M1 Mac 实例在 Apple M1 Mac 迷你计算机上构建并由 [AWS Nitro System](https://aws.amazon.com/cn/ec2/nitro/) 提供支持。 与基于 x86 的 EC2 Mac 实例相比，可将面向 iOS 和 macOS 应用程序构建工作负载的性价比提高最多 60%。EC2 M1 Mac 实例首次在 AWS 中启用了 ARM64 macOS 环境，并支持作为 Amazon 机器映像（AMI）的 macOS Big Sur（11）和 macOS Monterey（12）。EC2 M1 Mac 实例已在 4 个区域中可用：美国东部（弗吉尼亚州北部）、美国西部（俄勒冈州）、欧洲地区（爱尔兰）以及亚太地区（新加坡）。可在[此处](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-launch)了解详情并开始使用 EC2 M1 Mac 实例。"
    },
    {
        "query":"EC2 Mac 实例有哪些定价模型？",
        "intention":"知识问答",
        "reply":"Amazon EC2 Mac 实例可以通过按需和 Savings Plans 定价模型作为专属主机购买。专属主机是 EC2 Mac 实例的计费单位。为遵守 Apple macOS 软件许可协议，在专属主机最低 24 小时的分配期内按每秒计费。在 24 小时的最低分配期结束后，主机可以随时发布，无需进一步承诺。计算和实例 Savings Plans 均适用于 EC2 Mac 实例，并提供最高 44% 的按需定价折扣。有关更多信息，请访问[专属主机定价](https://aws.amazon.com/cn/ec2/dedicated-hosts/pricing/)页面。（注意：请选择“专属主机”租赁和“Linux”操作系统以查看详细信息。） 您还可以在[专属主机 AWS 定价计算器](https://calculator.aws/#/)上访问 EC2 Mac 实例定价。"
    },
    {
        "query":"如何释放专属主机？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例专属主机的最短分配期限为 24 小时。分配期限超过 24 小时后，首先停止或终止在主机上运行的实例，然后使用 aws ec2 release-hosts CLI 命令或 AWS 管理控制台释放主机。"
    },
    {
        "query":"您能否与组织中的其他 AWS 账户共享 EC2 Mac 专属主机？",
        "intention":"知识问答",
        "reply":"是。您可以通过 AWS Resource Access Manager 与 AWS 组织内的 AWS 账户、AWS 组织内的组织单位或整个 AWS 组织共享 EC2 Mac 专属主机。有关更多信息，请参阅 [AWS 资源访问管理器](https://aws.amazon.com/cn/ram/)文档。"
    },
    {
        "query":"您可以在 EC2 Mac 专属主机上运行多少个 EC2 Mac 实例？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例利用底层 Mac mini 硬件的全部功能。您可以在每个 EC2 Mac 专属主机上运行 1 个 EC2 Mac 实例。"
    },
    {
        "query":"能否更新 EC2 Mac 实例上的 EFI NVRAM 变量？",
        "intention":"知识问答",
        "reply":"是的，您可以更新 EC2 Mac 实例上的某些 EFI NVRAM 变量，这些变量将在重新启动后持续存在。但是，如果实例停止或终止，EFI NVRAM 变量将被重置。有关更多信息，请参阅 [EC2 Mac 实例文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-stop)。"
    },
    {
        "query":"您能否使用 FileVault 加密 EC2 Mac 实例上的 Amazon Elastic Block Store（Amazon EBS）启动卷？",
        "intention":"知识问答",
        "reply":"FileVault 需要在启动到 macOS 之前和启用远程访问之前登录。如果启用 FileVault，您将无法在实例重新启动、停止或终止时访问启动卷上的数据。我们强烈建议您不要启用 FileVault。相反，我们建议对 EC2 Mac 实例上的启动和数据 EBS 卷使用 Amazon EBS 加密。"
    },
    {
        "query":"您可以访问 EC2 Mac 实例上的麦克风输入或音频输出吗？",
        "intention":"知识问答",
        "reply":"无法访问 EC2 Mac 实例上的麦克风输入。内置的 Apple Remote Desktop VNC 服务器不支持音频输出。[Teradici CAS](https://aws.amazon.com/marketplace/pp/prodview-isaghmqny2wr6) 等第三方远程桌面软件支持 macOS 上的远程音频。"
    },
    {
        "query":"哪些基于 macOS 的 Amazon 机器映像（AMI）可用于 EC2 Mac 实例？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例使用物理 Mac mini 硬件来运行 macOS。苹果硬件只支持硬件自带的 macOS 版本（或更高版本），基于 x86 的 EC2 Mac 实例使用 2018 Intel Core i7 Mac mini，这意味着 macOS Mojave（10.14.x）的所有版本都支持，因为 2018 Mac mini 随附 Mojave。EC2 M1 Mac 实例使用 macOS Big Sur（11.x）随附的 2020 M1 Mac mini。要查看哪些最新版本的 macOS 可用作 EC2 Mac AMI，请访问[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html)。"
    },
    {
        "query":"如何在 EC2 Mac 实例上运行旧版本的 macOS？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例是裸机实例，不使用 Nitro 虚拟机监控器。您可以在基于 x86 的 EC2 Mac 实例上安装和运行类型 2 虚拟化层，以访问 macOS High Sierra、Sierra 或更旧的 macOS 版本。在 EC2 M1 Mac 实例上，由于 macOS Big Sur 是第一个支持 Apple Silicon 的 macOS 版本，旧的 macOS 版本即使在虚拟化下也无法运行。\n问：如何在 EC2 Mac 实例上运行 macOS 的测试版或预览版？\nEC2 Mac 实例目前不支持 macOS 的测试版和预览版。\n问：如何将 EC2 用户数据与 EC2 Mac 实例一起使用？\n与 EC2 Linux 和 Windows 实例一样，您可以将自定义用户数据传递给 EC2 Mac 实例。EC2 Mac 实例不使用 [cloud-init](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html)，而是使用开源启动进程守护程序：[ec2-macos-init](https://github.com/aws/ec2-macos-init)。您可以将此数据以纯文本、文件或 base64 编码文本的形式传递到 EC2 启动向导中。"
    },
    {
        "query":"如何在 EC2 M1 Mac 实例上安装 Xcode？",
        "intention":"知识问答",
        "reply":"AWS 提供基本 macOS AMI，无需事先安装任何 Xcode IDE。您可以像在任何其他 macOS 系统上一样安装 Xcode（并接受 EULA）。您可以从 App Store 安装最新的 Xcode IDE，或者从 Apple Developer 网站安装更早的 Xcode 版本。安装 Xcode 后，我们建议您创建 AMI 的快照以供将来使用。"
    },
    {
        "query":"macOS AMI 的发布节奏是怎样的？",
        "intention":"知识问答",
        "reply":"我们尽最大努力提供新的 macOS AMI。您可以订阅 SNS 通知以了解更新情况。我们的目标是在 macOS 次要版本更新后 30-60 天和 macOS 主要版本更新后 90-120 天发布官方 macOS AMI。"
    },
    {
        "query":"EC2 macOS AMI 中包含哪些代理和程序包？",
        "intention":"知识问答",
        "reply":"默认情况下，EC2 macOS AMI 中包含以下代理和程序包："
    },
    {
        "query":"能否更新 macOS AMI 中包含的代理和程序包？",
        "intention":"知识问答",
        "reply":"有一个 [Homebrew tap 的公共 GitHub 存储库](https://github.com/aws/homebrew-aws)，用于添加到基本 macOS 映像的所有代理和程序包。您可以使用 Homebrew 在 macOS 实例上安装最新版本的代理和软件包。"
    },
    {
        "query":"您能否直接从 Apple 更新服务器将操作系统和软件更新应用到您的 Mac 实例？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例上禁用自动 macOS 软件更新。我们建议使用我们官方提供的 macOS AMI 来启动您需要的 macOS 版本。在基于 x86 的 EC2 Mac 实例上，您可以通过软件更新首选项窗格或软件更新 CLI 命令更新 macOS 的版本。我们目前不支持 EC2 M1 Mac 实例上的 macOS 更新。在两个 EC2 Mac 实例上，您可以安装和更新应用程序和任何其他用户空间软件。\n问：如何通过 SSH 连接到 EC2 Mac 实例？\n启动实例并收到实例 ID 后，您可以使用以下命令轮询实例并确定它何时准备好进行 SSH 访问。通过 SSH 连接到 EC2 Mac 实例的过程与连接到其他 EC2 实例（例如运行 Linux 或 Windows 的实例）的过程相同。要支持使用 SSH 连接到您的实例，请使用密钥对和允许 SSH 访问的安全组启动实例。连接到实例时提供密钥对的 .pem 文件。有关更多信息，请参阅[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-ssh)。\n问：如何通过 VNC 连接到 EC2 Mac 实例？\nmacOS 具有默认禁用的内置屏幕共享功能，但可以启用并用于连接到 EC2 Mac 实例的图形（桌面）会话。有关如何启用内置屏幕共享的更多信息，请参阅此[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-mac-instances.html#mac-instance-vnc)。\n问：如何使用 AWS Systems Manager Session Manager 连接到 EC2 Mac 实例？\n您可以使用 AWS Systems Manager Session Manager（SSM）连接到您的 EC2 Mac 实例。Session Manager 是一项完全托管的 [AWS Systems Manager](https://aws.amazon.com/cn/systems-manager/) 功能，可提供安全且可审计的实例管理。它消除了保持开放入站端口、维护堡垒机或管理 SSH 密钥的需要。SSM 代理默认预安装在所有 EC2 macOS AMI 上。有关更多信息，请参阅[此博客文章](https://aws.amazon.com/blogs/mt/manage-your-amazon-ec2-macos-instances-with-aws-systems-manager/)。"
    },
    {
        "query":"EC2 Mac 实例支持多少个 Amazon EBS 卷和弹性网络接口（ENI）？",
        "intention":"知识问答",
        "reply":"基于 x86 的 EC2 Mac 实例支持 16 个 EBS 卷和 8 个 ENI 附件，EC2 M1 Mac 实例最多支持 10 个 EBS 卷和 8 个 ENI 附件。"
    },
    {
        "query":"EC2 Mac 实例是否支持 EBS？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例默认针对 EBS 进行了优化，可以为加密和未加密 EBS 卷提供高达 8 Gbps 的专用 EBS 带宽。"
    },
    {
        "query":"EC2 Mac 实例是否支持从本地存储引导？",
        "intention":"知识问答",
        "reply":"EC2 Mac 实例只能从 EBS 支持的 macOS AMI 引导。Mac mini 的内部 SSD 存在于“磁盘工具”中，但不可引导。"
    },
    {
        "query":"EC2 Mac 实例是否支持 Amazon FSx？",
        "intention":"知识问答",
        "reply":"是。EC2 Mac 实例支持使用 SMB 协议的 FSx。您需要将 EC2 Mac 实例注册到受支持的目录服务（例如 Active Directory 或 AWS Directory Service）中才能在 EC2 Mac 实例上启用 FSx。有关 FSx 的更多信息，请访问[产品页面](https://aws.amazon.com/cn/fsx/windows/)。"
    },
    {
        "query":"EC2 Mac 实例是否支持 Amazon Elastic File System（Amazon EFS）？",
        "intention":"知识问答",
        "reply":"是的，EC2 Mac 实例支持基于 NFSv4 协议的 EFS。有关 EFS 的更多信息，请访问[产品页面](https://aws.amazon.com/cn/efs/)。"
    },
    {
        "query":"什么是 Nitro 系统对上一代实例的支持？",
        "intention":"知识问答",
        "reply":"AWS Nitro 系统现在将为上一代 EC2 实例提供其现代硬件和软件组件，以延长服务的使用寿命，使其超出基础硬件的典型生命周期。使用 Nitro 系统支持，客户可以继续在构建它们的实例系列上运行工作负载和应用程序。"
    },
    {
        "query":"哪些上一代实例将接受 Nitro 系统支持，在什么时间范围内？",
        "intention":"知识问答",
        "reply":"从 2022 年开始，以下上一代实例将接受 Nitro System 支持：M1、M2 和 M3。这些实例的客户将收到至 Nitro System 迁移的维护通知。我们将在 2023 年增加对其他实例的支持。"
    },
    {
        "query":"为了迁移现有的上一代实例，我需要采取什么操作？",
        "intention":"知识问答",
        "reply":"客户不需要为迁移运行在上一代硬件上的活跃的前一代实例采取任何操作。对于上一代硬件上的实例，映射到实例的每个客户账户 ID 将在计划维护前 2 周收到一封电子邮件通知。\n与我们的典型维护活动类似，客户可以选择在最初计划的维护时间之后的 2 周内根据需要重新安排维护时间。"
    },
    {
        "query":"在此维护活动期间，我的实例会发生什么？",
        "intention":"知识问答",
        "reply":"在我们的[标准 AWS 维护过程](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-instances-status-check_sched.html)中，我们将与客户合作。多个 AWS 团队已在 Nitro 硬件上迁移并运行上一代实例。维护期间，实例将重新启动，这可能需要 30 分钟，具体时间取决于实例的大小和属性。例如：有本地磁盘的实例比没有本地磁盘的实例需要更长的迁移时间。重新启动后，您的实例将在本地实例存储卷上保留其 IP 地址、DNS 名称和任何数据。"
    },
    {
        "query":"我是否需要在迁移到 AWS Nitro 系统的上一代实例上重建/重新认证要运行的工作负载？",
        "intention":"知识问答",
        "reply":"否，客户不需要在迁移到 AWS Nitro 系统的上一代实例上重建/重新认证工作负载。"
    },
    {
        "query":"一旦迁移到 AWS Nitro 系统，我的实例规范是否会有任何变化？",
        "intention":"知识问答",
        "reply":"当实例迁移到 AWS Nitro 系统后，上一代实例的实例规范将不会产生任何变化。"
    },
    {
        "query":"上一代实例上的所有功能和 AMI 将在此次迁移中得到支持吗？",
        "intention":"知识问答",
        "reply":"是，上一代实例上支持的所有现有功能和 AMI 都将在我们将这些实例迁移到 AWS Nitro 系统时获得支持。但是，请注意，典型联网[已宣布](https://aws.amazon.com/blogs/aws/ec2-classic-is-retiring-heres-how-to-prepare/)停用，在运行于 Nitro 系统的上一代实例上将不受支持。我们将仅在客户迁移到 VPC 后迁移运行典型联网的上一代实例。"
    },
    {
        "query":"当上一代实例迁移到 AWS Nitro 系统时，定价和计费会有变化吗？",
        "intention":"知识问答",
        "reply":"计费和定价将不会产生变化。我们将继续支持目前为上一代实例支持的定价模式（按需、1 年/3 年预留实例、Savings Plan、Spot）。"
    },
    {
        "query":"什么是 AWS Cloud9？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 是一种基于云的集成开发环境 (IDE)，您只需要一个浏览器，即可编写、运行和调试代码。它将代码完成、代码提示和逐步调试等丰富的 IDE 代码编辑功能与完整的 Linux 服务器访问相结合，以运行和存储代码。 有关更多信息，请参阅 [AWS Cloud9 用户指南](https://docs.aws.amazon.com/cloud9/latest/user-guide/welcome.html)。"
    },
    {
        "query":"哪些人应该使用 AWS Cloud9？",
        "intention":"知识问答",
        "reply":"任何编写代码的人员都可以使用 AWS Cloud9。那些使用 Node.js (JavaScript)、Python、PHP、Ruby、Go 和 C++ 开发应用程序的人员都可以使用 Cloud9，并可通过预先安装的运行时、程序包管理器和调试工具，在自己的浏览器中直接访问完全配置的开发环境。使用 Cloud9，您无需再受限于单个开发机器，可以从任意联网的计算机访问您的开发环境。\nAWS 开发人员和评估新的 AWS 服务的人员可以使用 AWS Cloud9 通过预配置的 AWS Command Line interface (AWS CLI) 轻松访问他们的 AWS 资源，以准备运行针对 AWS 服务的命令。在 AWS Lambda 上使用 Node.js 或 Python 开发无服务器应用程序的人员可以使用 Cloud9 中的内置工具从 IDE 内部创建、编辑、运行、调试和部署它们的 Lambda 函数。"
    },
    {
        "query":"Amazon Polly 支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 支持 40 多种编程语言，包括 Node.js (JavaScript)、Python、PHP、Ruby、Go 和 C++。其功能包括语法突出显示、大纲视图、代码提示、代码完成、应用程序运行器和逐步调试，适用于多种常见编程语言。要详细了解 Cloud9 中支持的语言功能，请参阅我们的用户指南的[语言支持](https://docs.aws.amazon.com/cloud9/latest/user-guide/language-support.html)主题。"
    },
    {
        "query":"我可以使用哪些 Web 浏览器来访问 AWS Cloud9？",
        "intention":"知识问答",
        "reply":"最新版本的 Google Chrome、Safari、Firefox 和 Microsoft Edge 完全支持 AWS Cloud9。"
    },
    {
        "query":"AWS Cloud9 如何定价？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 无需额外付费。如果您针对 AWS Cloud9 开发环境使用 Amazon EC2 实例，您只需为用于运行和存储代码的计算和存储资源（即 EC2 实例、EBS 卷）付费。您还可以通过 SSH 将您的 Cloud9 开发环境连接至现有的 Linux 服务器（例如本地服务器)，而无需额外付费。有关更多详细信息，请参见 [AWS Cloud9 定价页面](https://aws.amazon.com/cn/cloud9/pricing/)。"
    },
    {
        "query":"AWS 还支持哪些 IDE？",
        "intention":"知识问答",
        "reply":"AWS 提供广泛的 IDE 支持选择，以促进 AWS 应用程序的开发。要详细了解 AWS 支持的 IDE 工具包，请访问 [AWS 工具页面的 IDE 工具包部分](https://aws.amazon.com/cn/tools/#ide)。"
    },
    {
        "query":"如果我在使用 AWS Cloud9 时遇到错误，应该怎么办？",
        "intention":"知识问答",
        "reply":"您可以在用户指南的[故障排除](https://docs.aws.amazon.com/cloud9/latest/user-guide/troubleshooting.html)主题中找到您可能遇到的一些错误及其可能的解决方案。"
    },
    {
        "query":"如何开始使用 AWS Cloud9？",
        "intention":"知识问答",
        "reply":"您可以登录 AWS 管理控制台，然后选择 AWS Cloud9。控制台将指导您选择您想要与 Cloud9 连接的 Linux 服务器。只需几个简单步骤，您便可以启动一个新的 Amazon EC2 实例（AWS Cloud9 EC2 环境），或者连接您现有的 Linux 服务器（AWS Cloud9 SSH 环境）。创建 Cloud9 环境后，您便可以访问您的 IDE 并在一个完全配置的开发环境中编写代码。 有关更多信息，请参阅我们有关[设置 AWS Cloud9](https://docs.aws.amazon.com/cloud9/latest/user-guide/setting-up.html) 的文档，然后完成[基本教程](https://docs.aws.amazon.com/cloud9/latest/user-guide/tutorials-basic.html)。"
    },
    {
        "query":"什么是 AWS Cloud9 开发环境？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 开发环境是存储项目代码文件和运行用以开发应用程序的工具的地方。每个环境中都存储了独特的 IDE 设置。这使您能够轻松地在许多不同的开发环境中创建和切换，每个环境都可自定义特定项目要求的工具、运行时、文件以及 IDE 设置。"
    },
    {
        "query":"AWS Cloud9 开发环境的类型有哪些？",
        "intention":"知识问答",
        "reply":"有两种 AWS Cloud9 环境类型可供您使用。"
    },
    {
        "query":"我可以通过 AWS Cloud9 使用现有的 Amazon EC2 或 Amazon Lightsail 实例吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 SSH 环境将基于 Linux 的现有 EC2 或 Lightsail 实例与 AWS Cloud9 连接。"
    },
    {
        "query":"我该怎样编辑我的代码？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 IDE 拥有先进的代码编辑器，具有自动完成、代码折叠、提示、语法突出显示和行式操作等功能。代码编辑器为您提供了 30 多种控制语法突出显示和 UI 的颜色方案，可随意选择。您还可以通过编辑样式表完全自定义 Cloud9 UI。"
    },
    {
        "query":"AWS Cloud9 EC2 环境中预先安装了哪些工具和程序包？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 EC2 环境预先安装了常用的开发工具，如 Git 和 Docker。还包含了适用于多种常用编程语言（如 Node.js 和 Python）的语言运行时间和程序包管理器。要查看 Cloud9 EC2 环境中预先安装的工具和程序包的完整列表，请参阅我们的[文档](https://docs.aws.amazon.com/console/cloud9/ami-contents)。"
    },
    {
        "query":"我该怎样运行我的代码？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 IDE 工具栏中有一个运行按钮，并且内置了适用于 10 多种不同语言的运行器，将使用最新更改的代码自动启动您的应用程序。为了完全控制您运行软件的方式，您还可以自定义现有的运行器、创建自己的运行器或从终端运行您的代码。"
    },
    {
        "query":"我该如何运行 CLI 命令？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 IDE 拥有一个内置的终端窗口，可以交互式地运行 CLI 命令。您还拥有该实例的全部管理权限（sudo 权利），能够安装开发所需的任何其他工具，也可托管您的应用程序。"
    },
    {
        "query":"该如何连接到源代码控制管理系统？",
        "intention":"知识问答",
        "reply":"您可以在 IDE 中打开终端窗口，并使用您在本地机器上使用的同一命令行工具访问您的源代码控制系统。AWS Cloud9 EC2 环境预先安装了 Git，使您能够轻松访问您的源代码。"
    },
    {
        "query":"AWS Cloud9 支持哪些 AWS 地区域？",
        "intention":"知识问答",
        "reply":"有关详细信息，请参阅[区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"AWS Cloud9 在哪里存储我的代码？",
        "intention":"知识问答",
        "reply":"您在 AWS Cloud9 环境中存储的任何数据（如代码文件、程序包或依赖关系）始终存储在您的资源中。如果您使用 EC2 环境，数据会存储在您 AWS 账户中关联的 Amazon Elastic Block Store (EBS) 卷中。如果您使用 SSH 环境，那么数据将存储在 Linux 服务器上的本地存储中。"
    },
    {
        "query":"AWS Cloud9 为 Amazon EC2 环境创建的资源有哪些?",
        "intention":"知识问答",
        "reply":"当您创建 Amazon EC2 环境后，AWS Cloud9 会在您的 AWS 账户中创建所需的计算和存储资源。这些资源包括一个 Amazon EC2 实例、一个 8-GB Amazon Elastic Block Store (EBS) 卷、一个 Amazon EC2 安全组和一个 AWS CloudFormation 堆栈。您可以通过单个 AWS 服务控制台访问这些资源。当您删除环境时，Cloud9 会自动为您删除这些资源。"
    },
    {
        "query":"AWS Cloud9 是否为 Amazon EC2 环境管理在 AWS Cloud9 中创建的资源?",
        "intention":"知识问答",
        "reply":"除了代表您创建和删除 AWS Cloud9 EC2 环境资源之外，Cloud9 还可以自动启动和停止 EC2 实例以降低成本。这些资源的所有其他管理任务则由您负责，如在 EC2 实例上安装软件补丁和备份 EBS 卷。"
    },
    {
        "query":"AWS Cloud9 环境中的 Amazon EC2 实例会一直运行吗？",
        "intention":"知识问答",
        "reply":"不会。AWS Cloud9 为您通过 Cloud9 创建的 Amazon EC2 实例提供了一个默认 30 分钟的自动休眠设置。通过此设置，您的 EC2 实例可在关闭 IDE 的 30 分钟后自动停止，并且只有在重新打开 IDE 时才重新启动。因此，通常只有工作时才产生 EC2 实例费用。如果您的实例需要重新启动，您将丢失 IDE 中所有活动的终端会话，并可能在打开 IDE 时还需要等待。您可以根据您的使用案例配置自动休眠设置，甚至还可以选择让您的 EC2 实例保持“始终运行”状态。"
    },
    {
        "query":"我可以更改现有 EC2 环境的 Amazon EC2 实例类型吗？",
        "intention":"知识问答",
        "reply":"可以。您可以更改最初为 AWS Cloud9 环境选择的 Amazon EC2 实例类型。要进行更改，您需要导航到 EC2 控制台中该实例的位置，找到您的实例，然后遵循 [Amazon EC2 文档](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-resize.html)的说明执行操作。"
    },
    {
        "query":"我该如何与其他人共享我的 AWS Cloud9 环境？",
        "intention":"知识问答",
        "reply":"您可以通过单击 IDE 右上方的共享按钮来共享您的 AWS Cloud9 环境。系统将提示您输入 AWS Identity and Access Management (IAM) 用户名以及您想与之合作的人员的访问级别。您输入这些详细信息后，所有参与者便都可使用此环境，从而在 IDE 功能和命令行会话中实现实时协作。"
    },
    {
        "query":"我可以与不同 AWS 账户中的 IAM 用户共享 AWS Cloud9 环境吗？",
        "intention":"知识问答",
        "reply":"不可以。AWS Cloud9 环境当前只能与相同 AWS 账户中的 IAM 用户共享。如果您想邀请一位没有 IAM 用户访问权限的新用户，您可以访问此链接，在共享对话框内创建一个新的 IAM 用户。"
    },
    {
        "query":"如何从 AWS Cloud9 中访问 AWS 服务？",
        "intention":"知识问答",
        "reply":"AWS Cloud9 EC2 环境预先安装了 AWS CLI，可通过已登录的 AWS 用户的权限自动进行身份验证。借此，您可以从 Cloud9 中内置的终端窗口运行针对 AWS 服务的交互式 CLI 命令，而无需任何其他配置。"
    },
    {
        "query":"如何使用 AWS Cloud9 开发适用于 AWS Lambda 的无服务器应用程序？",
        "intention":"知识问答",
        "reply":"您可以从 IDE 的 AWS 资源面板中访问适用于 AWS Lambda 的内置工具。您可以使用这些工具以 Node.js 和 Python 语言导入现有的 Lambda 函数或创建新的 Lambda 函数。您可以直接从 IDE 中轻松运行、预览、调试和部署这些函数。AWS Cloud9 也为 [AWS 无服务器应用程序模型 (AWS SAM)](https://github.com/awslabs/serverless-application-model) 框架提供支持。这使您能够在应用程序中轻松地管理多个 Lambda 函数和无服务器资源。如果您使用 AWS CodeStar 预置您的项目，那么对应用程序做出的任何更改都将直接以 git push 的方式构建并部署到 Lambda 中。"
    },
    {
        "query":"我可以使用 AWS Cloud9 在本地测试我的 AWS Lambda 函数吗？",
        "intention":"知识问答",
        "reply":"可以。AWS Cloud9 可以模拟 Node.js 和 Python 的 AWS Lambda 执行环境，以在 IDE 中本地运行您的函数。这使您能够通过逐步调试来测试无服务器应用程序，而无需将应用程序的更改上传到 Lambda。测试完毕后，您也可以直接从 IDE 将应用程序的更改部署到 Lambda。"
    },
    {
        "query":"如何通过 AWS CodeStar 使用 AWS Cloud9？",
        "intention":"知识问答",
        "reply":"您可以直接从 AWS CodeStar 启动 AWS Cloud9 环境，然后在 Cloud9 IDE 中立即开始编辑并提交您的 CodeStar 项目代码。您从 Cloud9 向项目源存储库提交的所有代码更改都将使用 CodeStar 预置的工具自动进行构建和部署。要了解有关使用此集成的更多信息，请参阅 [AWS CodeStar 文档](https://docs.aws.amazon.com/console/codestar/cloud9)。\nAWS Cloud9 入门"
    },
    {
        "query":"What is Amazon Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"With Amazon Kinesis Data Streams, you can build custom applications that process or analyze streaming data for specialized needs. You can add various types of data such as clickstreams, application logs, and social media to a Kinesis data stream from hundreds of thousands of sources. Within seconds, the data will be available for your applications to read and process from the stream."
    },
    {
        "query":"What does Amazon Kinesis Data Streams manage on my behalf?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Data Streams manages the infrastructure, storage, networking, and configuration needed to stream your data at the level of your data throughput. You don't have to worry about provisioning, deployment, or ongoing maintenance of hardware, software, or other services for your data streams. In addition, Kinesis Data Streams synchronously replicates data across three Availability Zones, providing high availability and data durability. By default, Kinesis Data Streams scales capacity automatically, freeing you from provisioning and managing capacity. You can choose provisioned mode if you want to provision and manage throughput on your own."
    },
    {
        "query":"What can I do with Amazon Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams is useful for rapidly moving data off data producers and then continuously processing the data, whether that means transforming it before emitting to a data store, running real-time metrics and analytics, or deriving more complex data streams for further processing.\nThe following are typical scenarios for using Kinesis Data Streams:\nAccelerated log and data feed intake: Instead of waiting to batch the data, you can have your data producers push data to a Kinesis data stream as soon as the data is produced, preventing data loss in case of producer failure. For example, system and application logs can be continuously added to a data stream and be available for processing within seconds.\nReal-time metrics and reporting: You can extract metrics and generate reports from Kinesis data stream data in real time. For example, your Amazon Kinesis application can work on metrics and reporting for system and application logs as the data is streaming in, rather than waiting to receive data batches.\nReal-time data analytics: With Kinesis Data Streams, you can run real-time streaming data analytics. For example, you can add clickstreams to your Kinesis data stream and have your Kinesis application run analytics in real time, allowing you to gain insights from your data in minutes instead of hours or days.\nLog and event data collection: Collect log and event data from sources such as servers, desktops, and mobile devices. You can then build applications using Amazon Lambda or Kinesis Data Analytics to continuously process the data, generate metrics, power live dashboards, and emit aggregated data into stores such as Amazon Simple Storage Service (S3).\nPower event-driven applications: Quickly pair with AWS Lambda to respond or adjust to immediate occurrences within the event-driven applications in your environment, at any scale."
    },
    {
        "query":"How do I use Amazon Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"After you sign up for AWS, you can start using Kinesis Data Streams by creating a Kinesis data stream through either the AWS Management Console or the CreateStream operation. Then configure your data producers to continuously add data to your data stream. You can optionally send data from existing resources in AWS services such as [Amazon DynamoDB](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/kds.html), [Amazon Aurora,](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/DBActivityStreams.html) [Amazon CloudWatch](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html), and [AWS IoT Core](https://docs.aws.amazon.com/iot/latest/developerguide/kinesis-rule-action.html). You can then use AWS Lambda, Amazon Kinesis Data Analytics, or AWS Glue Streaming to quickly process data stored in Kinesis Data Streams. You can also build custom applications that run on Amazon Elastic Compute Cloud (EC2), Amazon Elastic Container Service (ECS), and Amazon Elastic Kubernetes Service (EKS) using either Amazon Kinesis API or Amazon Kinesis Client Library (KCL)."
    },
    {
        "query":"What is a shard, producer, and consumer in Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"A shard has a sequence of data records in a stream. It serves as a base throughput unit of a Kinesis data stream. A shard supports 1 MB/second and 1,000 records per second for writes and 2 MB/second for reads. The shard limits ensure predictable performance, making it easy to design and operate a highly reliable data streaming workflow. A producer puts data records into shards and a consumer gets data records from shards. Consumers use shards for parallel data processing and for consuming data in the exact order in which they are stored. If writes and reads exceed the shard limits, the producer and consumer applications will receive throttles, which can be handled through retries."
    },
    {
        "query":"What is a record?",
        "intention":"知识问答",
        "reply":"A record is the unit of data stored in an Amazon Kinesis data stream. A record is composed of a sequence number, partition key, and data blob. Data blob is the data of interest your data producer adds to a data stream. The maximum size of a data blob (the data payload before Base64-encoding) is 1 megabyte (MB)."
    },
    {
        "query":"What is a partition key?",
        "intention":"知识问答",
        "reply":"A partition key is used to segregate and route records to different shards of a data stream. A partition key is specified by your data producer while adding data to a Kinesis data stream. For example, let’s say you have a data stream with two shards (shard 1 and shard 2). You can configure your data producer to use two partition keys (key A and key B) so that all records with key A are added to shard 1 and all records with key B are added to shard 2."
    },
    {
        "query":"What is a sequence number?",
        "intention":"知识问答",
        "reply":"A sequence number is a unique identifier for each record. Sequence number is assigned by Amazon Kinesis when a data producer calls PutRecord or PutRecords operation to add data to a Amazon Kinesis data stream. Sequence numbers for the same partition key generally increase over time; the longer the time period between [PutRecord](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html) or [PutRecords](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html) requests, the larger the sequence numbers become."
    },
    {
        "query":"What is a capacity mode?",
        "intention":"知识问答",
        "reply":"The capacity mode of Kinesis Data Streams determines how capacity is managed and usage is charged for a data stream. You can choose between provisioned and on-demand modes. In provisioned mode, you specify the number of shards for the data stream. The total capacity of a data stream is the sum of the capacities of its shards. You can increase or decrease the number of shards in a data stream as needed, and you pay for the number of shards at an hourly rate. In on-demand mode, AWS manages the shards to provide the necessary throughput. You pay only for the actual throughput used, and Kinesis Data Streams automatically accommodates your workload throughput needs as they ramp up or down. All Kinesis Data Streams write and read APIs, along with optional features such as Extended Retention and Enhanced Fan-Out, are supported in both capacity modes."
    },
    {
        "query":"How do I choose between on-demand and provisioned mode?",
        "intention":"知识问答",
        "reply":"On-demand mode is best suited for workloads with unpredictable and highly variable traffic patterns. You should use this mode if you prefer AWS to manage capacity on your behalf or prefer pay-per-throughput pricing. Provisioned mode is best suited for predictable traffic, where capacity requirements are easy to forecast. You should consider using provisioned mode if you want fine-grained control over how data is distributed across shards. Provisioned mode is also suitable if you want to provision additional shards so the consuming application can have more read throughput to speed up the overall processing."
    },
    {
        "query":"Can I switch between on-demand and provisioned mode?",
        "intention":"知识问答",
        "reply":"Yes. You can switch between on-demand and provisioned mode twice a day. The shard count of your data stream remains the same when you switch from provisioned mode to on-demand mode and vice versa. With the switch from provisioned to on-demand capacity mode, your data stream retains whatever shard count it had before the transition. But from that point on, Kinesis Data Streams monitors your data traffic and scales the shard count of this on-demand data stream up or down depending on traffic increase or decrease."
    },
    {
        "query":"How do I add data to my Amazon Kinesis data stream?",
        "intention":"知识问答",
        "reply":"You can add data to a Kinesis data stream through PutRecord and PutRecords operations, Amazon Kinesis Producer Library (KPL), or Amazon Kinesis Agent."
    },
    {
        "query":"What is the difference between PutRecord and PutRecords?",
        "intention":"知识问答",
        "reply":"PutRecord operation allows a single data record within an API call, and PutRecords operation allows multiple data records within an API call. For more information, see [PutRecord](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html) and [PutRecords](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html)."
    },
    {
        "query":"What is Amazon Kinesis Producer Library (KPL)?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Producer Library (KPL) is an easy-to-use and highly configurable library that helps you put data into an Amazon Kinesis data stream. KPL presents a simple, asynchronous, and reliable interface that enables you to quickly achieve high producer throughput with minimal client resources."
    },
    {
        "query":"What is Amazon Kinesis Agent?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Agent is a prebuilt Java application that offers an easy way to collect and send data to your Amazon Kinesis data stream. You can install the agent on Linux-based server environments such as web servers, log servers, and database servers. The agent monitors certain files and continuously sends data to your data stream. For more information, see [Writing with Agents](https://docs.aws.amazon.com/kinesis/latest/dev/writing-with-agents.html#setting-up-agent)."
    },
    {
        "query":"What data is counted against the data throughput of an Amazon Kinesis data stream during a PutRecord or PutRecords call?",
        "intention":"知识问答",
        "reply":"Your data blob, partition key, and data stream name are required parameters of a [PutRecord](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecord.html) or [PutRecords](https://docs.aws.amazon.com/kinesis/latest/APIReference/API_PutRecords.html) call. The size of your data blob (before Base64 encoding) and partition key will be counted against the data throughput of your Amazon Kinesis data stream, which is determined by the number of shards within the data stream."
    },
    {
        "query":"What is a consumer, and what are different consumer types offered by Amazon Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"A consumer is an application that processes all data from a Kinesis data stream. You can choose between shared fan-out and enhanced fan-out consumer types to read data from a Kinesis data stream. The shared fan-out consumers all share a shard’s 2 MB/second of read throughput and five transactions per second limits and require the use of the GetRecords API. An enhanced fan-out consumer gets its own 2 MB/second allotment of read throughput, allowing multiple consumers to read data from the same stream in parallel, without contending for read throughput with other consumers. You need to use the SubscribeToShard API with the enhanced fan-out consumers. We recommend using enhanced fan-out consumers if you want to add more than one consumer to your data stream."
    },
    {
        "query":"How I can process data captured and stored in Amazon Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"You can use managed services such as AWS Lambda, Amazon Kinesis Data Analytics, and AWS Glue to process data stored in Kinesis Data Streams. These managed services take care of provisioning and managing the underlying infrastructure so you can focus on writing your business logic. You can also deliver data stored in Kinesis Data Streams to Amazon S3, [Amazon OpenSearch Service](https://aws.amazon.com/opensearch-service/), Amazon Redshift, and custom HTTP endpoints using its prebuilt integration with Kinesis Data Firehose. You can also build custom applications using Amazon Kinesis Client Library, a prebuilt library, or the Amazon Kinesis Data Streams API."
    },
    {
        "query":"What is Amazon Kinesis Client Library (KCL)?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Client Library (KCL) for Java, Python, Ruby, Node.js, and .NET is a prebuilt library that helps you easily build Amazon Kinesis applications for reading and processing data from an Amazon Kinesis data stream.\nKCL handles complex issues such as adapting to changes in data stream volume, load-balancing streaming data, coordinating distributed services, and processing data with fault tolerance. KCL enables you to focus on business logic while building applications. Refer to Kinesis Data Streams documentation [here](https://docs.aws.amazon.com/streams/latest/dev/shared-throughput-kcl-consumers.html) for more details on KCL."
    },
    {
        "query":"What is the SubscribeToShard API?",
        "intention":"知识问答",
        "reply":"The SubscribeToShard API is a high-performance streaming API that pushes data from shards to consumers over a persistent connection without a request cycle from the client. The SubscribeToShard API uses the HTTP/2 protocol to deliver data to registered consumers whenever new data arrives on the shard, typically within 70 milliseconds, offering approximately 65% faster delivery compared to the GetRecords API. The consumers will enjoy fast delivery even when multiple registered consumers are reading from the same shard."
    },
    {
        "query":"What is enhanced fan-out?",
        "intention":"知识问答",
        "reply":"Enhanced fan-out is an optional feature for Kinesis Data Streams consumers that provides logical 2 MB/second throughput pipes between consumers and shards. This allows you to scale the number of consumers reading from a data stream in parallel, while maintaining high performance."
    },
    {
        "query":"When should I use enhanced fan-out?",
        "intention":"知识问答",
        "reply":"You should use enhanced fan-out if you have, or expect to have, multiple consumers retrieving data from a stream in parallel, or if you have at least one consumer that requires the use of the SubscribeToShard API to provide sub-200 millisecond data delivery speeds between producers and consumers."
    },
    {
        "query":"How is enhanced fan-out used by a consumer?",
        "intention":"知识问答",
        "reply":"Consumers use enhanced fan-out by retrieving data with the SubscribeToShard API. The name of the registered consumer is used within the SubscribeToShard API, which leads to utilization of the enhanced fan-out benefit provided to the registered consumer."
    },
    {
        "query":"Can I have some consumers using enhanced fan-out, and other not?",
        "intention":"知识问答",
        "reply":"Yes. You can have multiple consumers using enhanced fan-out and others not using enhanced fan-out at the same time. The use of enhanced fan-out does not impact the limits of shards for traditional GetRecords usage."
    },
    {
        "query":"Do I need to use enhanced fan-out if I want to use SubscribeToShard?",
        "intention":"知识问答",
        "reply":"Yes. To use SubscribeToShard, you need to register your consumers, which activates enhanced fan-out. By default, your consumer will use enhanced fan-out automatically when data is retrieved through SubscribeToShard."
    },
    {
        "query":"What are the default throughput quotas to write data into data stream using on-demand mode?",
        "intention":"知识问答",
        "reply":"A new data stream created in on-demand mode has a quota of 4 MB/second and 4,000 records per second for writes. By default, these streams automatically scale up to 200 MB/second and 200,000 records per second for writes."
    },
    {
        "query":"How do data streams scale in on-demand mode to handle increase in write throughput?",
        "intention":"知识问答",
        "reply":"A data stream in on-demand mode accommodates up to double its previous peak write throughput observed in the last 30 days. As your data stream’s write throughput hits a new peak, Kinesis Data Streams scales the stream’s capacity automatically. For example, if your data stream has a write throughput that varies between 10 MB/second and 40 MB/second, Kinesis Data Streams will ensure that you can easily burst to double the peak throughput of 80 MB/second. Subsequently, if the same data stream sustains a new peak throughput of 50 MB/second, Data Streams will ensure that there is enough capacity to ingest 100 MB/second of write throughput. However, you will see “ProvisionedThroughputExceeded” exceptions if your traffic grows more than double the previous peak within a 15-minute duration. You need to retry these throttled requests."
    },
    {
        "query":"What are the throughput limits for reading data from streams in on-demand mode?",
        "intention":"知识问答",
        "reply":"On-demand mode’s aggregate read capacity increases proportionally to write throughput to ensure that consuming applications always have adequate read throughput to process incoming data in real time. You get at least twice the write throughput to read data using the GetRecords API. We recommend using one consumer with the GetRecord API so it has enough room to catch up when the application needs to recover from downtime. To add more than one consuming application, you need to use enhanced fan-out, which supports adding up to 20 consumers to a data stream using the SubscribeToShard API, with each having dedicated throughput."
    },
    {
        "query":"What are the limits of Kinesis Data Streams in provisioned mode?",
        "intention":"知识问答",
        "reply":"The throughput of a Kinesis data stream in provisioned mode is designed to scale without limits by increasing the number of shards within a data stream."
    },
    {
        "query":"How do I scale capacity of Kinesis Data Streams in provisioned mode?",
        "intention":"知识问答",
        "reply":"You can scale up a Kinesis Data Stream capacity in provisioned mode by splitting existing shards using the SplitShard API. You can scale down capacity by merging two shards using the MergeShard API. Alternatively, you can use UpdateShardCount API to scale up (or down) a stream capacity to a specific shard count."
    },
    {
        "query":"How do I decide the throughput of my Amazon Kinesis data stream in provisioned mode?",
        "intention":"知识问答",
        "reply":"The throughput of a Kinesis data stream is determined by the number of shards within the data stream. Follow the steps below to estimate the initial number of shards your data stream needs in provisioned mode. Note that you can dynamically adjust the number of shards within your data stream through resharding.\nEstimate the average size of the record written to the data stream in kilobytes (KB), rounded up to the nearest 1 KB. (average\\_data\\_size\\_in\\_KB)\nEstimate the number of records written to the data stream per second. (number\\_of\\_records\\_per\\_second)\nDecide the number of Amazon Kinesis Applications consuming data concurrently and independently from the data stream. (number\\_of\\_consumers)\nCalculate the incoming write bandwidth in KB (incoming\\_write\\_bandwidth\\_in\\_KB), which is equal to the average\\_data\\_size\\_in\\_KB multiplied by the number\\_of\\_records\\_per\\_second.\nCalculate the outgoing read bandwidth in KB (outgoing\\_read\\_bandwidth\\_in\\_KB), which is equal to the incoming\\_write\\_bandwidth\\_in\\_KB multiplied by the number\\_of\\_consumers.\nYou can then calculate the initial number of shards (number\\_of\\_shards) your data stream needs using the following formula: number\\_of\\_shards = max (incoming\\_write\\_bandwidth\\_in\\_KB/1000, outgoing\\_read\\_bandwidth\\_in\\_KB/2000)"
    },
    {
        "query":"What is the maximum throughput I can request for my Amazon Kinesis data stream in provisioned mode?",
        "intention":"知识问答",
        "reply":"The throughput of a Kinesis data stream is designed to scale without limits. The default shard quota is 500 shards per stream for the following AWS Regions: US East (N. Virginia), US West (Oregon), and Europe (Ireland). For all other Regions, the default shard quota is 200 shards per stream. You can request the increase in the shard quota using the AWS Service Quotas console."
    },
    {
        "query":"What happens if the capacity limits of an Amazon Kinesis data stream are exceeded while the data producer adds data to the data stream in provisioned mode?",
        "intention":"知识问答",
        "reply":"In provisioned mode, the capacity limits of a Kinesis data stream are defined by the number of shards within the data stream. The limits can be exceeded either by data throughput or by the number of PUT records. While the capacity limits are exceeded, the put data call will be rejected with a ProvisionedThroughputExceeded exception. If this is due to a temporary rise of the data stream’s input data rate, retry by the data producer will eventually lead to completion of the requests. If it’s due to a sustained rise of the data stream’s input data rate, you should increase the number of shards within your data stream to provide enough capacity for the put data calls to consistently succeed. In both cases, Amazon CloudWatch metrics allow you to learn about the change of the data stream’s input data rate and the occurrence of ProvisionedThroughputExceeded exceptions."
    },
    {
        "query":"What happens if the capacity limits of an Amazon Kinesis data stream are exceeded while the Amazon Kinesis application reads data from the data stream in provisioned mode?",
        "intention":"知识问答",
        "reply":"In provisioned mode, the capacity limits of a Kinesis data stream are defined by the number of shards within the data stream. The limits can be exceeded either by data throughput or by the number of read data calls. While the capacity limits are exceeded, the read data call will be rejected with a ProvisionedThroughputExceeded exception. If this is due to a temporary rise of the data stream’s output data rate, retry by the Amazon Kinesis application will eventually lead to completion of the requests. If it’s due to a sustained rise of the data stream’s output data rate, you should increase the number of shards within your data stream to provide enough capacity for the read data calls to consistently succeed. In both cases, Amazon CloudWatch metrics allow you to learn about the change of the data stream’s output data rate and the occurrence of ProvisionedThroughputExceeded exceptions."
    },
    {
        "query":"What is the retention period supported by Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"The default retention period of 24 hours covers scenarios where intermittent lags in processing require catch-up with the real-time data. A seven-day retention lets you reprocess data for up to seven days to resolve potential downstream data losses. Long term data retention greater than seven days and up to 365 days lets you reprocess old data for use cases such as algorithm back testing, data store backfills, and auditing."
    },
    {
        "query":"Can I use the existing Kinesis Data Streams APIs to read data older than seven days?",
        "intention":"知识问答",
        "reply":"Yes. You can use the same getShardIterator, GetRecords, and SubscribeToShard APIs to read data retained for more than seven days. The consumers can move the iterator to the desired location in the stream, retrieve the shard map (including both open and closed), and read the records."
    },
    {
        "query":"Are there any new APIs to further assist in reading old data?",
        "intention":"知识问答",
        "reply":"Yes. There are API enhancements to ListShards, GetRecords, and SubscribeToShard APIs. You can use the new filtering option with the TimeStamp parameter available in the ListShards API to efficiently retrieve the shard map and improve the performance of reading old data. The TimeStamp filter lets applications discover and enumerate shards from the point in time you wish to reprocess data and eliminate the need to start at the trim horizon. GetRecords and SubscribeToShards have a new field, ChildShards, which allows you to quickly discover the children shards when an application finishes reading data from a closed shard, instead of having to traverse the shard map again. The fast discovery of shards makes efficient use of the consuming application’s compute resources for any sized stream, irrespective of the data retention period."
    },
    {
        "query":"When do I use the API enhancements?",
        "intention":"知识问答",
        "reply":"You should consider the API enhancements if you plan to retain data longer and scale your stream’s capacity regularly. Stream scaling operations close existing shards and open new child shards. The data in all the open and closed shards is retained until the end of the retention period. So the total number of shards increase linearly with a longer retention period and multiple scaling operations. This increase in the shard map requires you to use ListShards with the TimeStamp filter and ChildShards field in GetRecords, and SubscribeToShard API for efficient discovery of shards for data retrieval. You will need to upgrade your KCL to the latest version (1.x for standard consumers and 2.x for enhanced fan-out consumers) for these features."
    },
    {
        "query":"Does Amazon Kinesis Data Streams support schema registration?",
        "intention":"知识问答",
        "reply":"Yes. Clients of Kinesis Data Streams can use the AWS Glue Schema Registry, a serverless feature of AWS Glue, either through the Kinesis Producer Library (KPL) and Kinesis Client Libraries (KCL) or through AWS Glue Schema Registry APIs in the AWS Java SDK. The Schema Registry is available at no additional charge.\nVisit the Schema Registry [user documentation](https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html) to get started and to learn more."
    },
    {
        "query":"How do I change the throughput of my Amazon Kinesis data stream in provisioned mode?",
        "intention":"知识问答",
        "reply":"There are two ways to change the throughput of your data stream. You can use the UpdateShardCount API or the AWS Management Console to scale the number of shards in a data stream, or you can change the throughput of an Amazon Kinesis data stream by adjusting the number of shards within the data stream (resharding)."
    },
    {
        "query":"How long does it take to change the throughput of my Amazon Kinesis data stream running in provisioned mode using UpdateShardCount or the AWS Management Console?",
        "intention":"知识问答",
        "reply":"Typical scaling requests should take a few minutes to complete. Larger scaling requests will take longer than smaller ones."
    },
    {
        "query":"Does Amazon Kinesis Data Streams remain available when I change the throughput of my Kinesis data stream in provisioned mode or when the scaling happens automatically in on-demand mode?",
        "intention":"知识问答",
        "reply":"Yes. You can continue adding data to and reading data from your Kinesis data stream while you use UpdateShardCount or reshard to change the throughput of the data stream or when Kinesis Data Streams does it automatically in on-demand mode."
    },
    {
        "query":"How do I monitor the operations and performance of my Amazon Kinesis data stream?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Data Streams Management Console displays key operational and performance metrics such as throughput of data input and output of your Kinesis data streams. Kinesis Data Streams also integrates with Amazon CloudWatch so you can collect, view, and analyze CloudWatch metrics for your data streams and shards within those data streams. For more information about Amazon Kinesis Data Streams metrics, see [Monitoring Amazon Kinesis Data Streams with Amazon CloudWatch](https://docs.aws.amazon.com/kinesis/latest/dev/monitoring_with_cloudwatch.html).\nNote that all stream-level metrics are free of charge. All enabled shard-level metrics are charged at Amazon CloudWatch Pricing."
    },
    {
        "query":"How do I manage and control access to my Amazon Kinesis data stream?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Data Streams integrates with AWS Identity and Access Management (IAM), a service that enables you to securely control access to your AWS services and resources for your users. For example, you can create a policy that allows only a specific user or group to add data to your Kinesis data stream. For more information about access management and control of your data stream, see [Controlling Access to Amazon Kinesis Data Streams Resources using IAM](https://docs.aws.amazon.com/kinesis/latest/dev/kinesis-using-iam.html)."
    },
    {
        "query":"How do I log API calls made to my Amazon Kinesis data stream for security analysis and operational troubleshooting?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams integrates with Amazon CloudTrail, a service that records AWS API calls for your account and delivers log files to you. For more information about API call logging and a list of supported Amazon Kinesis API operations, see [Logging Amazon Kinesis API calls Using Amazon CloudTrail](https://docs.aws.amazon.com/kinesis/latest/dev/logging_using_cloudtrail.html)."
    },
    {
        "query":"How do I effectively manage my Amazon Kinesis data streams and the costs associated with them?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams allows you to tag your Kinesis data streams for easier resource and cost management. A tag is a user-defined label expressed as a key-value pair that helps organize AWS resources. For example, you can tag your data streams by cost centers so you can categorize and track your Kinesis Data Streams costs based on cost centers. For more information about Amazon Kinesis Data Streams tagging, see [Tagging Your Amazon Kinesis Data Streams](https://docs.aws.amazon.com/kinesis/latest/dev/tagging.html)."
    },
    {
        "query":"When I use Kinesis Data Streams, how secure is my data?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis is secure by default. Only the account and data stream owners have access to the Kinesis resources they create. Kinesis supports user authentication to control access to data. You can use AWS IAM policies to selectively grant permissions to users and groups of users. You can securely put and get your data from Kinesis through SSL endpoints using the HTTPS protocol. If you need extra security, you can use server-side encryption with AWS Key Management Service (KMS) keys to encrypt data stored in your data stream. AWS KMS allows you to use AWS-generated KMS keys for encryption, or if you prefer, you can bring your own KMS key into AWS KMS. Lastly, you can use your own encryption libraries to encrypt data on the client side before putting the data into Kinesis."
    },
    {
        "query":"Can I privately access Kinesis Data Streams APIs from my Amazon Virtual Private Cloud (VPC) without using public IPs?",
        "intention":"知识问答",
        "reply":"Yes. You can privately access Kinesis Data Streams APIs from your Amazon VPC by creating VPC Endpoints. With VPC Endpoints, the routing between the VPC and Kinesis Data Streams is handled by the AWS network without the need for an internet gateway, NAT gateway, or VPN connection. The latest generation of VPC Endpoints used by Kinesis Data Streams are powered by AWS PrivateLink, a technology that enables private connectivity between AWS services using Elastic Network Interfaces (ENI) with private IPs in your VPCs. To learn more about PrivateLink, visit the [PrivateLink documentation](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html#what-is-privatelink)."
    },
    {
        "query":"Can I encrypt the data I put into a Kinesis data stream?",
        "intention":"知识问答",
        "reply":"Yes, and there are two options for doing so. You can use server-side encryption, which is a fully managed feature that automatically encrypts and decrypts data as you put and get it from a data stream. You can also write encrypted data to a data stream by encrypting and decrypting on the client side."
    },
    {
        "query":"Why should I use server-side encryption instead of client-side encryption?",
        "intention":"知识问答",
        "reply":"You might choose server-side encryption over client-side encryption for any of the following reason:"
    },
    {
        "query":"What is server-side encryption?",
        "intention":"知识问答",
        "reply":"Server-side encryption for Kinesis Data Streams automatically encrypts data using a user specified AWS KMS key before it is written to the data stream storage layer, and decrypts the data after it is retrieved from storage. Encryption makes writes impossible and the payload and the partition key unreadable unless the user writing or reading from the data stream has the permission to use the key selected for encryption on the data stream. As a result, server-side encryption can make it easier to meet internal security and compliance requirements governing your data.\nWith server-side encryption your client-side applications (producers and consumers) do not need to be aware of encryption, they do not need to manage KMS keys or cryptographic operations, and your data is encrypted when it is at rest and in motion within the Kinesis Data Streams service. All KMS keys used by the server-side encryption feature are provided by the AWS KMS. AWS KMS makes it easy to use an AWS-managed KMS key for Kinesis (a “one-click” encryption method), your own AWS KMS customer-managed key, or a KMS key that you imported for encryption."
    },
    {
        "query":"Is there a server-side encryption getting started guide?",
        "intention":"知识问答",
        "reply":"Yes, there is a getting started guide in the user [documentation](https://docs.aws.amazon.com/streams/latest/dev/server-side-encryption.html)."
    },
    {
        "query":"Does server-side encryption interfere with how my applications interact with Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"Possibly. It depends on the key you use for encryption and the permissions governing access to the key."
    },
    {
        "query":"Is there an additional cost associated with the use of server-side encryption?",
        "intention":"知识问答",
        "reply":"Yes, however if you are using the AWS-managed KMS key for Kinesis and are not exceeding the AWS Free Tier KMS API usage costs, your use of server-side encryption is free. The following describes the costs by resource:\nKeys:\nThe AWS-managed KMS key for Kinesis (alias = “aws/kinesis”) is free.  \n Customer managed KMS keys are subject to KMS key costs. [Learn more](https://aws.amazon.com/kms/pricing/#Keys).\nKMS API Usage:\nAPI usage costs apply for every KMS key, including custom ones. Kinesis Data Streams calls KMS approximately every five minutes when it’s rotating the data key. In a 30-day month, the total cost of KMS API calls initiated by a Kinesis data stream should be less than a few dollars. Note that this cost scales with the number of user credentials you use on your data producers and consumers because each user credential requires a unique API call to AWS KMS. When you use IAM role for authentication, each assume role-call will result in unique user credentials, and you might want to cache user credentials returned by the assume-role-call to save KMS costs."
    },
    {
        "query":"Which AWS regions offer server-side encryption for Kinesis Data Streams?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams server-side encryption is available in the AWS GovCloud Region and all public Regions except the China (Beijing) region."
    },
    {
        "query":"How do I start, update, or remove server-side encryption from a data stream?",
        "intention":"知识问答",
        "reply":"All of these operations can be completed using the AWS Management Console or the AWS SDK. To learn more, see the [Kinesis Data Streams server-side encryption getting started guide](https://docs.aws.amazon.com/streams/latest/dev/server-side-encryption.html)."
    },
    {
        "query":"What encryption algorithm is used for server-side encryption?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams uses an [AES-GCM 256 algorithm](https://docs.aws.amazon.com/kms/latest/developerguide/crypto-intro.html) for encryption."
    },
    {
        "query":"If I encrypt a data stream that already has data written to it, either in plain text or ciphertext, will all of the data in the data stream be encrypted or decrypted if I update encryption?",
        "intention":"知识问答",
        "reply":"No. Only new data written into the data stream will be encrypted (or left decrypted) by the new application of encryption."
    },
    {
        "query":"What does server-side encryption for Kinesis Data Streams encrypt?",
        "intention":"知识问答",
        "reply":"Server-side encryption encrypts the payload of the message along with the partition key, which is specified by the data stream producer applications."
    },
    {
        "query":"Is server-side encryption a shard specific feature or a stream specific feature?",
        "intention":"知识问答",
        "reply":"Server-side encryption is a stream specific feature."
    },
    {
        "query":"Can I change the KMS key that is used to encrypt a specific data stream?",
        "intention":"知识问答",
        "reply":"Yes, using the AWS Management Console or the AWS SDK, you can choose a new KMS key to apply to a specific data stream."
    },
    {
        "query":"Is Amazon Kinesis Data Streams available in the AWS Free Tier?",
        "intention":"知识问答",
        "reply":"No. Amazon Kinesis Data Streams is not currently available in the AWS Free Tier. AWS  \n Free Tier is a program that offers free trial for a group of AWS services. For more  \n details about AWS Free Tier, see [AWS Free Tier](https://aws.amazon.com/free/)."
    },
    {
        "query":"What does the Amazon Kinesis Data Streams SLA guarantee?",
        "intention":"知识问答",
        "reply":"Our Kinesis Data Streams SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Kinesis Data Streams."
    },
    {
        "query":"How do I know if I qualify for a SLA Service Credit?",
        "intention":"知识问答",
        "reply":"You are eligible for a SLA credit for Kinesis Data Streams under the Kinesis Data Streams SLA if more than one Availability Zone in which you are running a task, within the same Region has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle.\nFor full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim, please see the [Amazon Kinesis Data Streams SLA details page](https://aws.amazon.com/kinesis/data-streams/sla/)."
    },
    {
        "query":"How does Amazon Kinesis Data Streams pricing work?",
        "intention":"知识问答",
        "reply":"Kinesis Data Streams uses simple pay-as-you-go pricing. There are no upfront costs or minimum fees, and you pay only for the resources you use. Kinesis Data Streams has two capacity modes—on-demand and provisioned—and both come with specific billing options."
    },
    {
        "query":"How does Kinesis Data Streams pricing work in on-demand mode?",
        "intention":"知识问答",
        "reply":"With on-demand capacity mode, you don’t need to specify how much read and write throughput you expect your application to perform. In this mode, pricing is based on the volume of data ingested and retrieved along with a per-hour charge for each data stream in your account. There are additional charges for optional features: Extended data retention (beyond the first 24 hours and within the first seven days), Long-Term data retention (beyond seven days and up to one year), and Enhanced Fan-Out. For more information about Kinesis Data Streams costs, see [Amazon Kinesis Data Streams Pricing](https://aws.amazon.com/kinesis/data-streams/pricing/)."
    },
    {
        "query":"How does Kinesis Data Streams pricing work in provisioned mode?",
        "intention":"知识问答",
        "reply":"With provisioned capacity mode, you specify the number of shards necessary for your application based on its write and read request rate. A shard is a unit of capacity that provides 1 MB/second of write and 2 MB/second of read throughout. You’re charged for each shard at an hourly rate. You also pay for records written into your Kinesis data stream. You incur additional charges when you use optional features such as Extended retention and Enhanced Fan-Out.\nFollowing are two core dimensions and three optional dimensions in Kinesis Data Streams provisioned mode:\nOptional:\nFor more information about Kinesis Data Streams costs, see [Amazon Kinesis Data Streams Pricing](https://aws.amazon.com/kinesis/data-streams/pricing/)."
    },
    {
        "query":"How is a consumer-shard hour calculated for Enhanced Fan-Out usage in provisioned mode?",
        "intention":"知识问答",
        "reply":"A consumer-shard hour is calculated by multiplying the number of registered stream consumers with the number of shards in the stream. You will also pay only for the prorated portion of the hour the consumer was registered to use enhanced fan-out. For example, if a consumer-shard hour costs $0.015, for a 10-shard data stream, this consumer using enhanced fan-out would be able to read from 10 shards, and thus incur a consumer-shard hour charge of $0.15 per hour (1 consumer \\* 10 shards \\* $0.015 per consumers-shard hour). If there were two consumers registered for enhanced fan-out simultaneously, the total consumer-shard hour charge would be $0.30 per hour (2 consumers \\* 10 shards \\* $0.015)."
    },
    {
        "query":"How does Amazon Kinesis Data Streams differ from Amazon SQS?",
        "intention":"知识问答",
        "reply":"Amazon Kinesis Data Streams enables real-time processing of streaming big data. It provides ordering of records, as well as the ability to read and/or replay records in the same order to multiple Amazon Kinesis Applications. The Amazon Kinesis Client Library (KCL) delivers all records for a given partition key to the same record processor, making it easier to build multiple applications reading from the same Kinesis data stream (for example, to perform counting, aggregation, and filtering). Amazon Simple Queue Service (SQS) offers a reliable, highly scalable hosted queue for storing messages as they travel between computers. Amazon SQS lets you easily move data between distributed application components and helps you build applications in which messages are processed independently (with message-level ack/fail semantics), such as automated workflows."
    },
    {
        "query":"When should I use Amazon Kinesis Data Streams, and when should I use Amazon SQS?",
        "intention":"知识问答",
        "reply":"We recommend Kinesis Data Streams for use cases with requirements that are similar to the following:\nRouting related records to the same record processor (as in streaming MapReduce). For example, counting and aggregation are simpler when all records for a given key are routed to the same record processor.\nOrdering of records. For example, you want to transfer log data from the application host to the processing/archival host while maintaining the order of log statements.\nAbility for multiple applications to consume the same stream concurrently. For example, you have one application that updates a real-time dashboard and another that archives data to Amazon Redshift. You want both applications to consume data from the same stream concurrently and independently.\nAbility to consume records in the same order a few hours later. For example, you have a billing application and an audit application that runs a few hours behind the billing application. Because Kinesis Data Streams stores data for up to 365 days, you can run the audit application up to 365 days behind the billing application.\nWe recommend Amazon SQS for use cases with requirements that are similar to the following:\nMessaging semantics (such as message-level ack/fail) and visibility timeout. For example, you have a queue of work items and want to track the successful completion of each item independently. Amazon SQS tracks the ack/fail so the application doesn’t have to maintain a persistent checkpoint/cursor. Amazon SQS will delete acked messages and redeliver failed messages after a configured visibility timeout.\nIndividual message delay. For example, you have a job queue and need to schedule individual jobs with a delay. With Amazon SQS, you can configure individual messages to have a delay of up to 15 minutes.\nDynamically increasing concurrency/throughput at read time. For example, you have a work queue and want to add more readers until the backlog is cleared. With Kinesis Data Streams, you can scale up to a sufficient number of shards (note, however, that you’ll need to provision enough shards ahead of time).\nUsing the ability of Amazon SQS to scale transparently. For example, you buffer requests and the load changes as a result of occasional load spikes or the natural growth of your business. Because each buffered request can be processed independently, Amazon SQS can scale transparently to handle the load without any provisioning instructions from you.\nLearn more about Amazon Kinesis Data Streams pricing"
    },
    {
        "query":"What is AWS CloudShell?",
        "intention":"知识问答",
        "reply":"AWS CloudShell is a browser-based shell that makes it easier to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development and operations tools are pre-installed, so there’s no need to install or configure software on your local machine. With CloudShell, you can quickly run scripts with the AWS Command Line Interface (AWS CLI), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to be more productive."
    },
    {
        "query":"What can I do with CloudShell?",
        "intention":"知识问答",
        "reply":"CloudShell gets you started with the AWS CLI more quickly, so you can automate tasks, manage infrastructure, and interact with AWS services. You can use CloudShell to clone repositories containing commonly used scripts, make edits to those scripts, and store them for future use. You can use AWS SDKs to develop applications and use common CLIs, such as the Amazon Elastic Container Service (Amazon ECS) CLI and the AWS Serverless Application Model (AWS SAM) CLI, to manage your AWS resources. You can save your work at no cost in 1 GB of persistent storage available in your home directory."
    },
    {
        "query":"What’s pre-installed in CloudShell?",
        "intention":"知识问答",
        "reply":"CloudShell runs on Amazon Linux 2 and contains common AWS command line interfaces, including AWS CLI, Amazon ECS CLI, AWS SAM CLI, along with runtimes and AWS SDKs for Python and Node.js. Other commonly used command line utilities for shells (Bash, PowerShell, Zsh), editors (vi), source control (Git), and package management (npm, pip) are also installed. For a complete list of pre-installed tools, see the [AWS CloudShell User Guide](https://docs.aws.amazon.com/cloudshell/latest/userguide/vm-specs.html)."
    },
    {
        "query":"What is the pricing for CloudShell?",
        "intention":"知识问答",
        "reply":"There is no additional charge for CloudShell. You pay for any other AWS resources you use with CloudShell to create and run your applications. You pay only for what you use, as you use it; there are no minimum fees and no upfront commitments. Data transfer is billed at standard AWS [data transfer rates](https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer)."
    },
    {
        "query":"Can I upload and download files through the browser?",
        "intention":"知识问答",
        "reply":"Yes, you can upload files to the home directory of your CloudShell instance through your browser from your local machine. You can also download files up to 1 GB in size from your CloudShell environment to your local machine."
    },
    {
        "query":"How is CloudShell different from Amazon EC2 Instance Connect?",
        "intention":"知识问答",
        "reply":"Amazon EC2 Instance Connect enables you to connect to existing EC2 instances in your account, using a terminal in the browser. CloudShell does not require any resources in your account. EC2 Instance Connect is most useful for connecting to existing EC2 instances via SSH while CloudShell is most useful for running AWS CLI commands and general purpose scripting."
    },
    {
        "query":"What is the difference between CloudShell and the AWS Cloud9 terminal?",
        "intention":"知识问答",
        "reply":"AWS Cloud9 is an integrated development environment (IDE) that gives users access to a terminal when using a Cloud9 environment that requires an EC2 instance in your account. CloudShell is a standalone, general purpose tool that you can use to run commands on AWS. When using Cloud9, you are billed for the EC2 instance that runs your Cloud9 environment. CloudShell can be used at no additional cost; you pay only for the AWS resources needed to run scripts and commands. In both cases you are billed for data transfer at standard [data transfer rates](https://aws.amazon.com/ec2/pricing/on-demand/#Data_Transfer)."
    },
    {
        "query":"Do changes that I make to the CloudShell environment persist?",
        "intention":"知识问答",
        "reply":"Only changes made inside your home directory will persist across CloudShell sessions per AWS Region. You can store up to 1 GB of files in your home directory in each supported AWS Region. Storage is not synchronized across AWS Regions."
    },
    {
        "query":"Can I access resources in a VPC with CloudShell?",
        "intention":"知识问答",
        "reply":"No, you cannot currently access resources that are in your private VPC in this release of CloudShell."
    },
    {
        "query":"Does CloudShell have an API?",
        "intention":"知识问答",
        "reply":"No, CloudShell is intended to be used from the AWS Management Console and does not currently support programmatic interaction."
    },
    {
        "query":"How do I access CloudShell?",
        "intention":"知识问答",
        "reply":"CloudShell is available from the AWS Management Console. Clicking the shell icon in the top navigation bar opens a CloudShell environment within a new browser tab. The new browser tab uses your console credentials."
    },
    {
        "query":"Is any software installation required?",
        "intention":"知识问答",
        "reply":"No, CloudShell is browser-based and requires no software installation, manual updates, or patch management."
    },
    {
        "query":"Which networks can CloudShell access by default?",
        "intention":"知识问答",
        "reply":"By default, CloudShell has public internet egress, but does not have ingress capability."
    },
    {
        "query":"Can I disallow access to CloudShell across my company?",
        "intention":"知识问答",
        "reply":"Yes, using an AWS Identity and Access Management (IAM) policy you can restrict the ability to launch CloudShell. Additionally, only users that have the Administrator or PowerUser role can start a CloudShell session by default. Administrators can configure access to CloudShell for their organization. If you choose to restrict this ability, the CloudShell icon will be visible, but a CloudShell session will not start. Your users will receive a message stating that they do not have CloudShell access."
    },
    {
        "query":"How much storage do I have in CloudShell?",
        "intention":"知识问答",
        "reply":"CloudShell comes with 1 GB of persistent storage for your home directory, per Region."
    },
    {
        "query":"Can I attach more storage to CloudShell?",
        "intention":"知识问答",
        "reply":"No, you cannot directly attach more storage to CloudShell. If you need to store more than 1 GB, you can create and use an S3 bucket from CloudShell."
    },
    {
        "query":"Can I delete my own CloudShell data?",
        "intention":"知识问答",
        "reply":"Yes. Files removed from CloudShell are deleted permanently. To back up the files, use [another storage option](https://aws.amazon.com/products/storage/)."
    },
    {
        "query":"Can I get a Windows or macOS-backed CloudShell?",
        "intention":"知识问答",
        "reply":"No, CloudShell does not currently support Windows or macOS instances. PowerShell is pre-installed and can be used on Linux."
    },
    {
        "query":"How do I customize my CloudShell environment?",
        "intention":"知识问答",
        "reply":"You can customize your CloudShell environment by checking out configuration files from a Git repository or by uploading them to your CloudShell environment. You can customize the look of CloudShell by clicking the settings icon and selecting your desired theme and font size. The shell updates immediately in response to your selection. Software installed outside of your home directory does not persist across sessions."
    },
    {
        "query":"Can I install my own software?",
        "intention":"知识问答",
        "reply":"Yes, you can install your own software in CloudShell. Software installed completely within your home directory will persist across sessions so that you do not need to re-install it when you use CloudShell. You are responsible for maintaining any additional software that you install."
    },
    {
        "query":"Can I use my own image for CloudShell?",
        "intention":"知识问答",
        "reply":"No, using your own image is not currently supported."
    },
    {
        "query":"Is CloudShell secure?",
        "intention":"知识问答",
        "reply":"Yes, users must sign in to the AWS Management Console to access CloudShell and then only have the privileges granted to them by their console login credentials. You have the same privileges as if you were to install, configure, and use the AWS CLI on your local machine with the same credentials – no more, no less. Account administrators can deny access to CloudShell by defining appropriate IAM policies. CloudShell usage information is logged to AWS CloudTrail and AWS API calls made from the shell are annotated to indicate that they are initiated from a specific users’ CloudShell session."
    },
    {
        "query":"Who can use CloudShell?",
        "intention":"知识问答",
        "reply":"Currently, only users that have the Administrator or PowerUser role can start a CloudShell session by default. All other users must be granted permission from an administrator in order to be able to start a CloudShell session. For a complete list of access procedures, see the [AWS CloudShell User Guide](https://docs.aws.amazon.com/cloudshell/latest/userguide/sec-auth-with-identities.html)."
    },
    {
        "query":"Who can grant access for others to use CloudShell?",
        "intention":"知识问答",
        "reply":"Access to CloudShell is managed via IAM. Any user with IAM administrator permissions can grant access to CloudShell. If you choose to restrict this ability, the CloudShell icon will be visible, but a CloudShell session will not start, instead your users will receive a message stating that they do not have CloudShell access."
    },
    {
        "query":"What are the CloudShell limits?",
        "intention":"知识问答",
        "reply":"Your home directory is limited to 1 GB of storage that will persist across your CloudShell sessions on a per-Region basis. CloudShell uses a temporary compute environment that restores data stored in your home directory when you connect to it so changes made outside your home directory are not saved when your session ends. CloudShell is intended for interactive workloads rather than long running processes. To run a long process, consider using another AWS compute service. CloudShell will automatically stop after a period of keyboard input inactivity. Processes running in the background do not constitute activity and may be terminated without notice. Your CloudShell connection will automatically disconnect all sessions when your console session ends. For a complete list of CloudShell limits, see the [AWS CloudShell User Guide.](https://docs.aws.amazon.com/cloudshell/latest/userguide/limits.html)"
    },
    {
        "query":"How many shells can I have?",
        "intention":"知识问答",
        "reply":"CloudShell supports one virtual machine per Region, per user. Users can have up to 10 sessions per virtual machine active concurrently. Users can have shells from multiple Regions open simultaneously. A user is defined as any IAM principal that can be used to sign in to the AWS Management Console, including federated roles and AWS Single Sign-On."
    },
    {
        "query":"How long will CloudShell keep my data?",
        "intention":"知识问答",
        "reply":"CloudShell environments will preserve files stored in your home directory ($HOME) for up to 120 days from the last time you initiated a CloudShell session. This limit applies on a regional basis. If you use CloudShell in multiple Regions, each Region has a separate timer, which begins from the time your last CloudShell session was closed per Region. Accessing CloudShell in the expiring Region through the same IAM principal will reset the timer."
    },
    {
        "query":"How can I prevent my CloudShell storage from being deleted?",
        "intention":"知识问答",
        "reply":"Sign in to the AWS Management Console and open CloudShell in the expiring Region. This will reset the time associated with your storage in the given Region."
    },
    {
        "query":"Will my CloudShell data in all Regions be deleted when the retention period ends?",
        "intention":"知识问答",
        "reply":"No. The CloudShell retention policy applies on a regional basis. Each Region has its own timer associated with your storage."
    },
    {
        "query":"Will I be notified before my data is going to be deleted?",
        "intention":"知识问答",
        "reply":"Yes. You will be notified via the personal health dashboard before your CloudShell data is deleted."
    },
    {
        "query":"Where can I find a complete list of CloudShell limits?",
        "intention":"知识问答",
        "reply":"For a complete list of CloudShell limits, see the [AWS CloudShell User Guide](https://docs.aws.amazon.com/cloudshell/latest/userguide/limits.html)."
    },
    {
        "query":"什么是 Amazon Kendra？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 是一项由机器学习 (ML) 提供支持的企业搜索服务，高度准确且易于使用。开发人员能够利用它为他们的应用程序添加搜索功能，这样他们的最终用户就可以发现存储在整个公司范围内的海量内容中的信息。包括手册、研究报告、常见问题、人力资源 (HR) 文档和客户服务指南中的数据，这些数据可以在各种系统中找到，如 Amazon Simple Storage service (S3)、Microsoft SharePoint、Salesforce、ServiceNow、RDS 数据库或 Microsoft OneDrive。当您键入问题时，服务使用 ML 算法来理解上下文并返回最相关的结果，无论是精确的答案还是整个文档。例如，您可以询问“公司信用卡的现金奖励是多少？”之类的问题，然后 Amazon Kendra 将映射到相关文档并返回一个具体的答案，如“2%”。Kendra 提供示例代码，让您可以快速入门，并轻松地将高度准确的搜索集成到新应用程序或现有的应用程序中。"
    },
    {
        "query":"Amazon Kendra 如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 为存储在 AWS 中的所有非结构化数据提供 ML 驱动的搜索功能。Amazon Kendra 提供了易于使用的本机连接器，以连接 Amazon S3、Amazon RDS 数据库等常用类型的 AWS 存储库。其他 AI 服务（例如 Amazon Comprehend、Amazon Transcribe 和 Amazon Comprehend Medical）可用于对文档进行预处理、生成可搜索文本、提取实体以及丰富其元数据，以提供更专业的搜索体验。"
    },
    {
        "query":"如果我的数据不包含 Amazon Kendra 寻找的准确答案会发生什么情况？",
        "intention":"知识问答",
        "reply":"当您的数据不包含问题的准确答案时，Amazon Kendra 会返回一个按深度学习模型排列的最相关文档列表。"
    },
    {
        "query":"Amazon Kendra 不能回答哪种类型的问题？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 尚不支持需要跨文档段落汇总或计算的问题。"
    },
    {
        "query":"如何开始使用 Amazon Kendra？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 控制台提供简单的入门方法。您可以将 Amazon Kendra 指向存储在 Amazon S3 中的非结构化和半结构化文档（如常见问题）。提取之后，您可以直接在控制台的“搜索”部分键入问题来开始测试 Kendra。然后，您可以通过两种简单的方式部署 Amazon Kendra：(1) 使用 Experience Builder 中的可视化 UI 编辑器（无需代码），或 (2) 使用几行代码实施 Amazon Kendra API，实现更精确的控制。控制台中还提供了代码示例，以加快 API 执行。"
    },
    {
        "query":"如何自定义 Amazon Kendra 以更好地适应我公司的领域或业务专长？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 为 IT、制药、保险、能源、工业、金融服务、法律、媒体和娱乐、旅游与酒店、卫生健康、人力资源、新闻、电信以及汽车行业提供特定领域的专业知识。您可以通过提供自己的同义词列表来进一步优化和扩展 Kendra 对特定领域的理解。只需上传带有特定术语的文件，然后 Amazon Kendra 将使用这些同义词来丰富用户搜索。"
    },
    {
        "query":"Amazon Kendra 支持哪些文件类型？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 支持 .html、MS Office（.doc、.ppt）、PDF 和文本格式的非结构化和半结构化数据。借助 [MediaSearch 解决方案](https://aws.amazon.com/blogs/machine-learning/make-your-audio-and-video-files-searchable-using-amazon-transcribe-and-amazon-kendra/)，您还可以使用 Amazon Kendra 搜索音频和视频文件。"
    },
    {
        "query":"Amazon Kendra 如何处理增量数据更新？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 提供两种保持索引更新的方法。第一种，连接器提供定期自动同步数据源的计划。第二种，Amazon Kendra API 允许您构建自己的连接器，以便通过您现有的 ETL 作业或应用程序直接从数据源向 Amazon Kendra 发送数据。"
    },
    {
        "query":"Amazon Kendra 支持哪些语言？",
        "intention":"知识问答",
        "reply":"有关语言支持的信息，请参阅此[文档](https://docs.aws.amazon.com/kendra/latest/dg/in-adding-languages)页面。"
    },
    {
        "query":"需要对代码进行哪些更改才能使用 Amazon Kendra？",
        "intention":"知识问答",
        "reply":"在使用本机连接器时，提取内容不需要编码。您还可以使用 Amazon Kendra 开发工具包编写自己的自定义连接器以与其他数据源集成。您可以通过两种简单的方式部署 Amazon Kendra search：(1) 使用 Experience Builder 中的可视化 UI 编辑器（无需代码），或 (2) 使用几行代码实现 Kendra API，实现更灵活的应用。控制台中还提供了代码示例，以加快 API 执行。开发工具包提供了对最终用户体验的完全控制和灵活性。"
    },
    {
        "query":"在哪些区域可以使用 Amazon Kendra？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)页面，了解更多详情。"
    },
    {
        "query":"是否可以添加自定义连接器？",
        "intention":"知识问答",
        "reply":"您可以使用 Amzon Kendra 自定义数据源 API 编写自己的连接器。此外，Amazon Kendra 有一个搜索专家合作伙伴生态系统，可以帮助构建 AWS 目前不提供的连接器。有关合作伙伴网络的详细信息，请与我们联系。"
    },
    {
        "query":"Amazon Kendra 如何处理安全性？",
        "intention":"知识问答",
        "reply":"Amazon Kendra 可以加密传输中的数据和静态数据。对于静态数据的加密密钥，您有三种选择：AWS 拥有的 KMS 密钥、您账户中由 AWS 托管的 KMS 密钥或客户托管的 KMS 密钥。对于传输中的数据，Amazon Kendra 使用 HTTPS 协议与您的客户端应用程序进行通信。通过网络访问 Amazon Kendra 的 API 调用使用客户端必须支持的传输层安全性 (TLS)。"
    },
    {
        "query":"Amazon CloudWatch 是什么？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 是一项针对云资源和在 AWS 上运行的应用程序的 AWS 监控服务。使用 Amazon CloudWatch 可以收集和跟踪指标、收集和监控日志文件以及设置警报。Amazon CloudWatch 可以监控各种 AWS 资源，例如 Amazon EC2 实例、Amazon DynamoDB 表和 Amazon RDS 数据库实例，应用程序和服务生成的自定义指标，以及应用程序生成的、本地托管的、混合或在其他云端的任何日志文件。您可通过使用 Amazon CloudWatch 全面地了解系统的资源使用率、应用程序性能和运行状况。使用这些洞察，您可以及时做出反应，保证应用程序顺畅运行。\n要开始监控，您可以使用融合 AWS 最佳实践的自动化控制面板，查看基于账户和资源的指标与告警视图，并轻松深入分析以了解性能问题的根本原因。"
    },
    {
        "query":"我可以使用什么来访问 CloudWatch？",
        "intention":"知识问答",
        "reply":"您可以使用 API、命令行界面、AWS 软件开发工具包和 AWS 管理控制台访问 Amazon CloudWatch。"
    },
    {
        "query":"Amazon CloudWatch 支持哪些操作系统？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 接收和提供适用于所有 Amazon EC2 实例的指标，应该适用于 Amazon EC2 服务目前支持的所有操作系统。"
    },
    {
        "query":"我可以为 CloudWatch 实施哪些访问管理策略？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 集成了 AWS Identity and Access Management (IAM)，可以支持您指定 AWS 账户中的用户可以执行的 CloudWatch 操作。例如，您可以创建一个向组织中的特定用户授予 GetMetricStatistics 使用权限的 IAM 策略。然后，他们可以使用该操作来检索有关您的云资源的数据。\n您无法使用 IAM 控制对有关特定资源的 CloudWatch 数据的访问。例如，您无法仅为一组特定的实例或特定的 LoadBalancer 授予对 CloudWatch 数据的用户访问权限。使用 IAM 授予的权限涵盖所有通过 CloudWatch 监控的云资源。此外，您不能在 Amazon CloudWatch 命令行工具中使用 IAM 角色。"
    },
    {
        "query":"什么是 Amazon CloudWatch Logs？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch Logs 支持您使用现有系统、应用程序和自定义日志文件来监控系统与应用程序，并进行故障排除。\n借助 CloudWatch Logs，您可以近乎实时地监控日志中的特定短语、值或模式。例如，您可以针对系统日志中出错的次数设置警报，或查看应用程序日志中的 Web 请求延迟图表。然后，您可以查看原始日志数据，了解问题根源。日志数据可以在高持久性低成本的存储器中无限期保存，您既能够访问所需数据，又无需担心填满硬盘。"
    },
    {
        "query":"我可以使用 CloudWatch Logs 完成哪些工作？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 能够监控并存储日志，以帮助您更好地了解并运行系统和应用程序。您可以通过多种方式使用 CloudWatch Logs。\n实时监控应用程序和系统：您可以使用 CloudWatch Logs 通过日志数据来监控应用程序和系统。例如，CloudWatch Logs 能够追踪应用程序日志中的出错次数，并在错误率超过指定阈值时向您发送通知。CloudWatch Logs 使用日志数据进行监控，因此无需更改代码。\n长期保留日志：您可以使用 CloudWatch Logs 将日志数据长期存储在高持久性且经济高效的存储中，无需担心耗尽硬盘空间。CloudWatch Logs Agent 能够支持您轻松快速地将已轮换和未轮换的日志文件从主机移动到日志服务系统。然后，您可以按需访问原始日志事件数据。"
    },
    {
        "query":"CloudWatch Logs Agent 支持哪些平台？",
        "intention":"知识问答",
        "reply":"Amazon Linux、Ubuntu、CentOS、Red Hat Enterprise Linux 和 Windows 均支持 CloudWatch Logs Agent。此代理支持在主机上监控各个日志文件的功能。"
    },
    {
        "query":"CloudWatch Logs Agent 是否支持 IAM 角色？",
        "intention":"知识问答",
        "reply":"是。CloudWatch Logs Agent 集成了 Identity and Access Management (IAM)，同时支持访问密钥和 IAM 角色。"
    },
    {
        "query":"什么是 Amazon CloudWatch Logs Insights？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch Logs Insights 是用于 CloudWatch Logs 的一项随用随付的交互式集成日志分析功能。它允许开发人员、操作人员和系统工程师搜索和可视化其日志，以帮助他们了解、改进和调试其应用程序。Logs Insights 与 CloudWatch 完全集成，让您能够管理、探索和分析自己的日志。您还可以利用 CloudWatch 指标、警报和控制面板结合日志，获取对应用程序的全面可视性。这样能够支持您了解自己的应用程序、做出改进，并快速地找出和修复问题，从而让您能够继续快速地创新。您可以使用聚合、筛选条件和正则表达式编写查询，以从日志中获取可行的见解。您还可以可视化时间序列数据，深入查看各个日志事件以及将查询结果导出到 CloudWatch 控制面板。"
    },
    {
        "query":"我应如何开始使用 CloudWatch Logs Insights？",
        "intention":"知识问答",
        "reply":"您可以立即开始使用 Logs Insights 对正在发送到 CloudWatch Logs 的所有日志运行查询。无需进行设置，也无需管理基础设施。您可以从 AWS 管理控制台访问 Logs Insights，也可以使用 AWS 软件开发工具包通过应用程序以编程方式访问。"
    },
    {
        "query":"什么是 Amazon CloudWatch 异常检测？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 异常检测应用机器学习算法来连续分析系统和应用程序的单时间序列，确定正常基线并发现异常，需要的用户干预极少。它允许您创建基于自然指标模式（例如一天中的时间、星期几、季节性或变化的趋势）自动调整阈值的告警。您还可以使用控制面板上的异常检测将指标可视化，监控、隔离指标中的意外变化并进行故障排除。"
    },
    {
        "query":"我要如何开始使用 Amazon CloudWatch 异常检测？",
        "intention":"知识问答",
        "reply":"异常检测的入门很简单。在 CloudWatch 控制台中，转至导航窗格中的告警以便创建告警，或者通过指标将指标的预期值以区段的形式叠加到图表上。您还可以通过 AWS CLI、AWS SDK 或 AWS CloudFormation 模板启用异常检测。要了解详情，请访问 CloudWatch [异常检测文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Anomaly_Detection.html)和[定价](https://aws.amazon.com/cn/cloudwatch/pricing/)页面。"
    },
    {
        "query":"什么是 Amazon CloudWatch Contributor Insights？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 现已包含 Contributor Insights，它可以分析时间序列数据，进而了解影响系统性能的几大因素。安装完成后，Contributor Insights 将持续运行，用户无需干预。这有助于开发人员和操作人员在事件运行期间更快地隔离、诊断和补救问题。"
    },
    {
        "query":"我要如何开始使用 CloudWatch Contributor Insights？",
        "intention":"知识问答",
        "reply":"在 CloudWatch 控制台中，转到导航窗格中的 Contributor Insights，创建 Contributor Insights 规则。您还可以通过 AWS CLI、AWS 开发工具包或 AWS CloudFormation 模板启用 Contributor Insights。所有商业 AWS 区域均已推出 Contributor Insights。要了解更多信息，请访问 CloudWatch Contributor Insights 文档。"
    },
    {
        "query":"什么是 Amazon CloudWatch ServiceLens？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch ServiceLens 功能可让您在一个地方直观呈现和分析应用程序的运行状况、性能和可用性。CloudWatch ServiceLens 将 CloudWatch 指标和日志以及来自 AWS X-Ray 的跟踪结合在一起，为您提供应用程序及其依赖关系的完整视图。这能让您快速查明性能瓶颈、找出应用程序问题的根本原因和确定受影响的用户。利用 CloudWatch ServiceLens，您可以从三个主要方面了解应用程序：基础设施监控（使用指标和日志了解支持应用程序的资源）、事务监控（使用跟踪了解资源之间的依赖关系）及最终用户监控（使用 Canary 监控您的终端节点并在您的最终用户体验降低时通知您）。"
    },
    {
        "query":"我要如何开始使用 CloudWatch ServiceLens？",
        "intention":"知识问答",
        "reply":"如果您已使用 AWS X-Ray，那么您可以根据原定设置在 CloudWatch 控制台上访问 CloudWatch ServiceLens。如果您尚未使用 AWS X-Ray，则首先可以使用 X-Ray 开发工具包在应用程序中启用 AWS X-Ray。Amazon CloudWatch ServiceLens 已在 AWS-X-Ray 可用的所有公共 AWS 区域推出。要了解更多信息，请访问 Amazon CloudWatch ServiceLens 的相关文档。"
    },
    {
        "query":"什么是 Amazon CloudWatch Synthetics？",
        "intention":"知识问答",
        "reply":"借助 Amazon CloudWatch Synthetics，您可以更加轻松地监控应用程序终端节点。它全天候对终端节点运行测试，并在应用程序终端节点运行不正常时立即发出提醒。可以自定义测试，在应用程序中检查可用性、延迟、交易、坏链接或死链接、分步任务的完成情况、页面加载错误、UI 资产加载延迟、复杂的向导流或检出流。您还可以使用 CloudWatch Synthetics 隔离警报应用程序终端节点，并将它们映射回底层基础设施问题，以缩短解决问题的平均时间。"
    },
    {
        "query":"您要如何开始使用 CloudWatch Synthetics？",
        "intention":"知识问答",
        "reply":"CloudWatch Synthetics 非常容易上手。您可以在几分钟内编写自己的第一个通过的 Canary。要了解详情，请访问 [Amazon CloudWatch Synthetics 的相关文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries.html)。"
    },
    {
        "query":"为什么我在 2017 年 7 月的 AWS CloudWatch 每月账单与之前几个月的不同？",
        "intention":"知识问答",
        "reply":"在 2017 年 7 月之前，CloudWatch 费用分开显示在 AWS 账单与成本和使用率报告中的两个不同部分。由于历史原因，CloudWatch 警报、CloudWatch 指标和 CloudWatch API 的使用费显示在您账单的“Elastic Compute Cloud (EC2)”详情部分，而 CloudWatch Logs 和 CloudWatch 控制面板的使用费显示在“CloudWatch”详情部分。为了合并和简化您的每月 AWS CloudWatch 使用费和账单，我们将 CloudWatch 指标、警报和 API 的使用费从账单的“EC2”部分移到了“CloudWatch”部分，从而有效地将您的所有 CloudWatch 监控费用整合到了“CloudWatch”部分。请注意，这不会影响您的 AWS 账单总额。您的账单与成本和使用率报告现在在一个部分即可显示 CloudWatch 使用费。\n另外，可将 CloudWatch 中名为“预估费用”的账单指标看作“总预估费用”，并且还可按服务对该指标进行细分。“总预估费用”指标不会发生变化。但是，当“ServiceName”维度等于“AmazonEC2”和“ServiceName”等于“AmazonCloudWatch”时，按服务细分的“EstimatedCharges”指标将会发生变化。由于账单合并，您可能会发现您的 Amazon EC2 账单指标减少了，而 Amazon CloudWatch 账单指标增加了，因为使用率和账单费用从 EC2 移到了 CloudWatch。"
    },
    {
        "query":"CloudWatch Logs Insights 如何定价？",
        "intention":"知识问答",
        "reply":"Logs Insights 按查询定价，并基于查询扫描的摄取日志数据量收费。如需了解关于定价的其他详细信息，请查看 [CloudWatch 定价](https://aws.amazon.com/cn/cloudwatch/pricing/)。"
    },
    {
        "query":"CloudWatch 中的跨账户可观测性是什么？",
        "intention":"知识问答",
        "reply":"CloudWatch 中的跨账户可观测性让您可以监控跨越一个区域内多个账户的应用程序并对其进行故障排除。使用跨账户可观测性，您可以无缝搜索、可视化和分析您的指标、日志和跟踪，而不必担心账户边界问题。您可以从应用程序的聚合跨账户视图开始，以直观地识别出现错误的资源，并深入研究相关的跟踪、指标和日志以找出问题的根源。跨账户监控支持的无缝跨账户数据访问和导航可帮助您减少解决问题所需的手动工作，并节省宝贵的解决时间。跨账户可观测性是对 CloudWatch 统一可观测性功能的补充。"
    },
    {
        "query":"如何开始使用跨账户可观测性？",
        "intention":"知识问答",
        "reply":"跨账户可观测性引入了两个新的账户概念。“监控账户”是一个中央 AWS 账户，可以查看跨其他账户生成的可观测性数据并与之交互。“源账户”是一个单独的 AWS 账户，它为驻留在其中的资源生成可观测性数据。一旦您确定了您的监控账户和源账户，您就可以通过选择要与您的监控账户共享哪些遥测数据来完成跨账户监控配置。您只需几分钟即可轻松设置中央监控账户，并可以从中全面了解跨多个相关账户或整个 AWS 组织部署的应用程序的运行状况和性能。借助 CloudWatch 中的跨账户可观测性，您可以鸟瞰可能影响服务可用性的跨应用程序依赖关系，并且可以主动查明问题并进行故障排除，从而缩短平均解决时间。"
    },
    {
        "query":"我可以跨多个 AWS 账户使用哪些 CloudWatch 监控功能？",
        "intention":"知识问答",
        "reply":"使用跨账户可观测性，您可以从中央视图搜索跨多个账户存储的日志组，运行跨账户 Logs Insights 查询、Live Tail 分析，并跨账户创建 Contributor Insights 规则以识别生成日志条目的前 N 个贡献者。您可以使用指标搜索在整合视图中可视化来自多个账户的指标，创建警报来评估来自其他账户的指标以收到异常和趋势问题的通知，并在集中式控制面板上可视化它们。您还可以使用此功能设置单个跨账户指标流，以包含跨 AWS 区域中多个 AWS 账户的指标。借助跨账户可观测性，您还可以使用 ServiceLens 查看跨账户应用程序的交互式地图，并一步深入到相关指标、日志和跟踪。"
    },
    {
        "query":"我仍然可以在我的控制台上使用 CloudWatch 跨账户、跨区域功能吗？",
        "intention":"知识问答",
        "reply":"CloudWatch 中的跨账户监控和跨账户跨区域功能都将在 CloudWatch 控制台上可用。当您在 CloudWatch 中设置跨账户可观测性时，跨账户、跨区域下拉菜单将从控制台中删除。请注意，CloudWatch 中的跨账户可观测性体验一次在一个区域内可用。跨账户、跨区域功能允许通过 IAM 角色访问组织范围的遥测数据。CloudWatch 中的跨账户可观测性使用可观察性访问管理器 API 来定义访问策略。有关更多信息，请参阅我们的文档。"
    },
    {
        "query":"通过 Amazon CloudWatch 指标能够衡量什么？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 可使您监控 AWS 上运行的 AWS 云资源和应用程序。指标将自动提供给多种 AWS 产品和服务，包括 Amazon EC2 实例、EBS 卷、Elastic Load Balancer、Auto Scaling 组、EMR 作业流、RDS DB 实例、DynamoDB 表、ElastiCache 集群、RedShift 集群、OpsWorks 堆栈、Route 53 状态检查、SNS 主题、SQS 队列、SWF 工作流和 Storage Gateway。您还可以监控自己的应用程序和服务生成的自定义指标。"
    },
    {
        "query":"所有指标的保留期有多长？",
        "intention":"知识问答",
        "reply":"您可以发布和存储低至 1 秒钟分辨率的自定义指标。CloudWatch 于 2016 年 11 月 1 日推出了更长的指标保留期，此项功能使得客户所有指标的存储期从之前的 14 天延长为 15 个月。CloudWatch 支持以下几种指标数据保留方式：\n您可以将最初发布的时段较短的数据点聚合在一起，以获取长期存储。例如，如果您以 1 分钟为间隔收集数据，则分辨率为 1 分钟的数据可保留 15 天。15 天之后，此数据仍然可用，但已聚合起来，只能以 5 分钟的分辨率进行检索。63 天后，这些数据将进一步聚合，并以 1 小时的分辨率进行保留。如果您需要比上述期限更长的指标保留期，可以使用 GetMetricStatistics API 检索离线数据点或不同存储的数据点。\n此项功能目前在以下地区可用：美国东部（弗吉尼亚北部）、美国西部（俄勒冈）、美国西部（加利福尼亚北部）、欧洲（爱尔兰）、欧洲（法兰克福）、南美洲（圣保罗）、亚太地区（新加坡）、亚太地区（东京）、亚太地区（首尔）、亚太地区（孟买）、亚太地区（悉尼）、欧洲（伦敦）、加拿大（中部）、美国东部（俄亥俄）和中国（北京）。"
    },
    {
        "query":"Amazon CloudWatch 接收和聚合数据的最小分辨率是多少？",
        "intention":"知识问答",
        "reply":"CloudWatch 支持的最小分辨率是 1 秒钟数据点，这是一种高分辨率指标，或者，您也可以使用 1 分钟的时间间隔存储指标。有时，Cloudwatch 会以各种时间间隔接收指标，例如 3 分钟或 5 分钟的时间间隔。如果您没有将指标指定为高分辨率，可以在 PutMetricData API 请求中设置 StorageResolution 字段，根据原定设置，CloudWatch 将以 1 分钟的分辨率聚合并存储指标。\n系统会按上述保留期限中定义的分辨率提供指标，具体取决于请求的数据在生成后经过的时间。例如，如果您在 10 天前的某天请求 1 分钟数据，您会收到 1440 个数据点。但是，如果您在 5 个月前请求 1 分钟数据，UI 会自动将时间间隔更改为 1 小时，并且 GetMetricStatistics API 不会返回任何输出。"
    },
    {
        "query":"是否可以删除指标？",
        "intention":"知识问答",
        "reply":"CloudWatch 不支持指标删除功能。指标过期与否取决于上述保留期限。"
    },
    {
        "query":"如果停用某个 Amazon EC2 实例的监控，是否会丢失指标数据？",
        "intention":"知识问答",
        "reply":"否。您始终可以按照上述保留期限，检索任何 Amazon EC2 实例的指标数据。但是，CloudWatch 控制台会将对指标的搜索限制到某个指标被摄取后 2 周内，以确保最新实例显示在您的命名空间中。"
    },
    {
        "query":"是否可以访问已终止的 Amazon EC2 实例或已删除的 Elastic Load Balancer 的指标数据？",
        "intention":"知识问答",
        "reply":"是。对于已终止的 Amazon EC2 实例或已删除的 Elastic Load Balancer，Amazon CloudWatch 会将其指标存储 15 个月。"
    },
    {
        "query":"当查看我 5 分钟和 1 分钟时段内的指标时，为什么同一时间窗口的图形会有所不同？",
        "intention":"知识问答",
        "reply":"如果在 5 分钟和 1 分钟时段内查看同一时间窗口，您可能会发现数据点显示在图形中不同的位置上。对于您在图形中指定的时段，Amazon CloudWatch 会查找所有可用的数据点，再计算出单个聚合点来代表整个时段。在 5 分钟时段的情况下，该单一数据点会处于 5 分钟时间窗口的开头。在 1 分钟时段的情况下，该单一数据点会处于 1 分钟标记上。我们建议使用 1 分钟时段来进行故障诊断，以及其他要求最精确的时段图形的活动。"
    },
    {
        "query":"什么是自定义指标？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon CloudWatch 来监控应用程序、脚本和服务生成的数据。自定义指标即您向 Amazon CloudWatch 提供的任何指标。例如，您可以使用自定义指标来监控网页加载时间、请求出错率、实例进程或线程数，以及应用程序所执行的工作量。您可以通过使用 PutMetricData API、适用于 Windows 和 Linux 的监控脚本样本、CloudWatch collectd 插件以及 AWS 合作伙伴提供的多种应用程序和工具，开始使用自定义指标。"
    },
    {
        "query":"自定义指标可以采用哪种分辨率？",
        "intention":"知识问答",
        "reply":"自定义指标可采取的分辨率如下：\n根据原定设置，系统会以 1 分钟的分辨率将指标存储在 CloudWatch 中。通过在 PutMetricData API 请求中将 StorageResolution 参数设置为 1，您可以将指标定义为高分辨率。如果您没有设置可选的 StorageResolution 参数，根据原定设置，CloudWatch 将以 1 分钟的分辨率存储指标。\n在发布高分辨率指标时，CloudWatch 将以 1 秒钟的分辨率进行存储，您可以使用 1 秒钟、5 秒钟、10 秒钟、30 秒钟的时段或 60 秒钟的任意倍数的时段进行读取和检索。\n自定义指标的保留期限与上述保留期限相同。"
    },
    {
        "query":"哪些指标是以高分辨率提供的？",
        "intention":"知识问答",
        "reply":"目前，只有您发布到 CloudWatch 的自定义指标是以高分辨率提供的。高分辨率自定义指标以 1 秒钟的分辨率存储在 CloudWatch 中。高分辨率是由 PutMetricData API 请求中的 StorageResolution 参数字段（参数值为 1）定义的，该字段不是必填字段。如果您没有指定可选 StorageResolution 字段的值，根据原定设置，CloudWatch 将以 1 分钟的分辨率存储自定义指标。"
    },
    {
        "query":"高分辨率自定义指标与常规自定义指标的定价方式是否有所不同？",
        "intention":"知识问答",
        "reply":"否。高分辨率自定义指标与标准 1 分钟自定义指标的定价方式相同。"
    },
    {
        "query":"我何时应使用自定义指标，而不是由应用程序向 CloudWatch Logs 发送日志？",
        "intention":"知识问答",
        "reply":"您可以使用自定义指标、CloudWatch Logs 或两者结合的方式来监控自己的数据。如果您的数据并非以日志格式生成，例如操作系统进程或性能测量信息，您可能需要使用自定义指标。或者，您可能期望编写或使用自己的或由 AWS 合作伙伴提供的应用程序或脚本。如果您想要存储并保存单独的测量数据和其他详细信息，可能需要使用 CloudWatch Logs。"
    },
    {
        "query":"我可以在 CloudWatch 中查看哪些统计结果并绘制图表？",
        "intention":"知识问答",
        "reply":"您可以检索 Amazon CloudWatch 指标的以下统计值：平均值、合计、最小值、最大值和采样计数，并绘制图表和设置告警。您可以计算从 60 秒到一天内任意时间段内的统计数据。对于高分辨率自定义指标，您可以计算从 1 秒到 3 小时内任意时间段内的统计数据。"
    },
    {
        "query":"适用于 .NET 和 SQL Server 的 CloudWatch Application Insights 是什么？",
        "intention":"知识问答",
        "reply":"适用于 .NET 和 SQL Server 的 Amazon CloudWatch Application Insights 是一项功能，您可以借此轻松监控您的 .NET 和 SQL Server 应用程序。该功能有助于跨应用程序资源和技术堆栈识别和设置关键指标和日志，即数据库、Web (IIS) 应用程序服务器、操作系统、负载均衡器、队列等。它会持续监控这些遥测数据，以检测和关联异常和错误，并向您通知应用程序中的任何问题。为帮助排查问题，它会创建自动化控制面板来直观呈现它检测到的问题，包括相关的指标异常和日志错误，以及帮助您分析潜在根源的其他洞察。"
    },
    {
        "query":"我如何开始使用适用于 .NET 和 SQL Server 的 CloudWatch Application Insights 进行监控？",
        "intention":"知识问答",
        "reply":"板载应用程序：通过选择与您要监控的应用程序关联的 [AWS 资源组](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-resource-groups.html)来指定该应用程序。\n确定应用程序组件：它会分析您的应用程序资源，以确定应用程序组件（独立资源或相关资源组，例如自动缩放组和负载均衡器组）。您还可以通过将资源分组来自定义组件，以获得更好的见解并轻松进行注册。\n启用监控：对于应用程序组件，您可以指定技术层，即 IIS 前端层、.NET 辅助角色层等。根据您的选择，它会为您推荐一组可以根据您的需求进行自定义的指标和日志。保存这些“监控器”之后，适用于 .NET 和 SQL Server 的 Application Insights 会设置 CloudWatch，以代表您收集这些信息。\n设置完成之后，适用于 .NET 和 SQL Server 的 Application Insights 会组合使用预构建规则和机器学习模型来开始确定应用程序问题。它会在 CloudWatch 上创建自动化控制面板，其中包含检测到的问题列表、这些问题的详细视图，以及相关的异常和错误。"
    },
    {
        "query":"什么是 CloudWatch Metric Streams？",
        "intention":"知识问答",
        "reply":"CloudWatch Metric Streams 是一种功能，支持您以最少的设置和配置将 CloudWatch 指标连续流式传输到您选择的目的地。这是一种完全托管的解决方案，无需编写任何代码或维护任何基础设施。只需点击几下，您就可以向目的地（如 Amazon Simple Storage Service (S3)）配置指标流。您还可以将指标发送给选定的第三方服务提供商，使运营仪表板保持最新。  \n   \n 问：为何要使用 CloudWatch Metric Streams？\nMetric Streams 提供了一种无需轮询 API 即可从 CloudWatch 获取指标数据的替代方法。您只需点击几下就可以创建指标流，并且指标数据已开始流向您的目的地。您可以轻松将指标传输到 Data Lake on AWS，如 Amazon S3，并开始使用 Amazon Athena 等工具分析使用情况或性能。Metrics Streams 还简化了使用 Amazon Kinesis Data Firehose HTTP 终端节点向常用的第三方服务提供商发送 CloudWatch 指标的流程。您可以创建包含最新的 CloudWatch 指标数据的连续、可扩展的流，为仪表板、警报和其他依赖于准确及时指标数据的工具提供支持。"
    },
    {
        "query":"如何创建和管理 CloudWatch Metric Streams？",
        "intention":"知识问答",
        "reply":"您可以通过 CloudWatch 控制台或以编程方式通过 CloudWatch API、AWS SDK、AWS CLI 或 AWS CloudFormation 创建和管理 Metric Streams，以预置和配置 Metric Streams。您还可以使用由第三方服务提供商提供的 AWS CloudFormation 模板将 Metric Streams 传递设置为传输到 AWS 外部的目标位置。有关更多信息，请参阅 [CloudWatch Metric Streams 的文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Metric-Streams.html)。"
    },
    {
        "query":"我可以管理 CloudWatch Metric Stream 中要包含的指标吗？",
        "intention":"知识问答",
        "reply":"可以。您可以选择在默认情况下发送所有指标，也可以创建过滤规则，包括和排除由命名空间（如 AWS/EC2）定义的指标组。Metric Streams 能够自动检测与过滤规则匹配的新指标，并在流式传输中包含指标更新。当资源终止时，Metric Streams 将自动停止发送非活动指标的更新。"
    },
    {
        "query":"CloudWatch Metric Streams 支持哪些格式？",
        "intention":"知识问答",
        "reply":"Metric Streams 能够输出 OpenTelemetry 或 JSON 格式。您可以在创建或管理指标流时选择输出格式。"
    },
    {
        "query":"Amazon CloudWatch 提供什么日志监控？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 支持您使用现有系统、应用程序和自定义日志文件监控系统和应用程序，并排除故障。\n借助 CloudWatch Logs，您可以近乎实时地监控日志中的特定短语、值或模式。例如，您可以针对系统日志中出错的次数设置警报，或查看应用程序日志中的 Web 请求延迟图表。然后，您可以查看原始日志数据，了解问题根源。日志数据可以在高持久性低成本的存储中保存任意长的时间，因此无需担心硬盘空间不足。"
    },
    {
        "query":"什么是 Amazon CloudWatch 公开日志？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 公开日志是由 AWS 产品代表客户发布在本地的日志。VPC 流日志是第一种将从该分级模型中受益的公开日志。不过，我们日后将会向公开日志类型增加更多 AWS 服务日志类型。"
    },
    {
        "query":"CloudWatch Logs 是否在所有地区都可用？",
        "intention":"知识问答",
        "reply":"请参见[地区性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 CloudWatch Logs 服务在不同地区的具体提供情况。"
    },
    {
        "query":"我可以对日志和 Amazon CloudWatch 执行哪些操作？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 能够监控并存储日志，以帮助您更好地了解并运行系统和应用程序。当使用 CloudWatch Logs 处理日志时，它会使用现有的日志数据进行监控，因此您将无需修改代码。以下是您可以对 Amazon CloudWatch 和日志执行操作的两个示例：\n实时监控应用程序和系统：您可以使用 CloudWatch Logs 通过日志数据近乎实时地监控应用程序和系统。例如，CloudWatch Logs 能够追踪应用程序日志中的出错次数，并在错误率超过指定阈值时向您发送通知。Amazon CloudWatch 使用日志数据进行监控，因此您将无需修改代码。\n长期保留日志：您可以根据需要使用 CloudWatch Logs 在高持久性且经济高效的存储中长期保存日志数据，无需担心耗尽硬盘空间。CloudWatch Logs Agent 能够支持您轻松快速地将已轮换和未轮换的日志文件从主机移动到日志服务系统。然后，您可以按需访问原始日志事件数据。"
    },
    {
        "query":"我可以从运行 Microsoft SQL Server 和 Microsoft Windows Server 的 EC2 实例将什么类型的数据发送至 Amazon CloudWatch Logs？",
        "intention":"知识问答",
        "reply":"您可以将 EC2Config 服务配置为将各种数据和日志文件发送至 CloudWatch，其中包括：自定义文本日志、事件（应用程序、自定义、安全、系统）日志、事件跟踪 (ETW) 日志和性能计时器 (PCW) 数据。在[此处](https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ec2config-service.html)了解有关 EC2Config 服务的更多信息。"
    },
    {
        "query":"CloudWatch Logs Agent 以何种频率发送数据？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs Agent 在默认状态下每五秒发送一次日志数据，可由用户配置。"
    },
    {
        "query":"CloudWatch Logs 支持什么日志格式？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 能够导入、聚合并监控基于常见日志数据的任何文本或 JSON 格式的日志。"
    },
    {
        "query":"如果配置 CloudWatch Logs Agent 发送非文本日志数据会怎样？",
        "intention":"知识问答",
        "reply":"如果配置 CloudWatch Logs Agent 来报告非文本日志数据，则它将记录错误。错误记录在 /var/logs/awslogs.log 中。"
    },
    {
        "query":"如何使用 CloudWatch Logs 开始监控我的日志？",
        "intention":"知识问答",
        "reply":"通过创建指标筛选条件，可以在日志事件发送到 CloudWatch 日志服务时对其进行监控。指标筛选条件将日志数据转换为用于绘制图表或发出警报的 Amazon CloudWatch 指标。指标筛选条件可在控制台或 CLI 中创建。指标筛选条件搜索并匹配日志事件中的术语、短语或值。当指标筛选条件找到日志事件中的一个术语、短语或值时，即将其计入所选择的 Amazon CloudWatch 指标。例如，您可以创建一个指标筛选条件来搜索并统计单词“Error”在日志事件中的出现次数。指标筛选条件还可以提取空格分隔日志事件的值，例如 Web 请求的延迟情况。此外，您也可以使用条件运算符和通配符创建精确匹配。Amazon CloudWatch 控制台可以帮助您在创建指标筛选条件之前测试模式。"
    },
    {
        "query":"什么是指标筛选条件模式的语法？",
        "intention":"知识问答",
        "reply":"指标筛选条件模式可以包含搜索术语或常见日志或 JSON 事件格式的规范。\n例如，如果您想要搜索术语 Error，指标筛选条件的模式即为术语 Error。筛选条件中可同时包含多个搜索术语，用于搜索多个术语。例如，如果您想统计含有术语 Error 和 Exception 的事件数量，可以使用模式 Error Exception。如果您想精确匹配术语 Error Exception，则需要为搜索术语加上双引号“Error Exception”。您可以根据需要指定多个搜索术语。\nCloudWatch Logs 还能用于从常见日志格式或 JSON 格式中的日志事件提取值。例如，您可以访问 Apache 日志传输的字节数。或者也可以使用条件运算符和通配符匹配并提取感兴趣的数据。要使用指标筛选条件的提取功能，日志事件必须以空格分隔，且必须在字段的开始和末尾处使用双引号“\"”或方括号“[ ]”，以围住字段。或者，可以是 JSON 格式的日志事件。如需查看语法和示例的完整详细信息，请参阅[指标筛选条件开发人员指南](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatchLogs.html)。"
    },
    {
        "query":"我如何知道指定的指标筛选条件模式将能够匹配日志事件？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 支持您在创建指标筛选条件之前测试指标筛选条件模式。您可以针对 CloudWatch Logs 中已存在的日志数据测试模式，也可以提供自己的日志事件进行测试。通过测试模式，您可以了解哪些日志事件匹配该指标筛选条件；以及如果提取这些值，将会提取测试数据中的哪些值。指标筛选条件测试功能可以在控制台和 CLI 中使用。"
    },
    {
        "query":"我是否可以对我的日志数据使用正则表达式？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 指标筛选条件不支持正则表达式。如需使用正则表达式处理日志数据，请考虑使用 [Amazon Kinesis](https://aws.amazon.com/cn/kinesis/)，并将该数据流连接到正则表达式处理引擎。"
    },
    {
        "query":"如何检索日志数据？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch Logs 控制台或通过 CloudWatch Logs CLI 来检索任何日志数据。日志事件可以基于日志组、日志流和关联的时间进行检索。适用于检索日志事件的 CloudWatch Logs API 是 GetLogEvents。"
    },
    {
        "query":"如何搜索日志？",
        "intention":"知识问答",
        "reply":"您可以使用 CLI 来检索日志事件，并使用命令行 grep 或类似的搜索功能进行搜索。"
    },
    {
        "query":"CloudWatch Logs 能够将日志数据储存多久？",
        "intention":"知识问答",
        "reply":"您可以根据需要在 CloudWatch Logs 中长久保存日志数据。默认情况下，CloudWatch Logs 将无限期保存日志数据。您可以随时更改每个日志组的保留期限。"
    },
    {
        "query":"访问 Logs Insights 需要什么权限？",
        "intention":"知识问答",
        "reply":"要访问 Logs Insights，您的 IAM 策略中必须包括用于 logs:DescribeLogGroups 和 logs:FilterLogEvents 的权限。"
    },
    {
        "query":"使用 CloudWatch Logs Insights 可以查询哪些日志？",
        "intention":"知识问答",
        "reply":"您可以使用 Logs Insights 查询正在发送到 CloudWatch 的所有日志。Logs Insights 自动从来自 AWS 服务的日志获得日志字段，例如 Lambda、CloudTrail、Route53 和 VPC 流日志以及生成 JSON 格式的日志事件的任何应用程序日志。此外，对于所有日志类型，它会为发送到 CloudWatch 所有日志生成 3 个系统字段：@message、@logStream 和 @timestamp。@message 包含未解析的原始日志事件，@logStream 包含生成日志事件的源的名称，@timestamp 包含日志事件添加到 CloudWatch 的时间。"
    },
    {
        "query":"CloudWatch Logs Insights 支持哪种查询语言？",
        "intention":"知识问答",
        "reply":"Logs Insights 引入了专门构建的新查询语言用于日志处理。该查询语言支持一些简单而强大的查询命令。您可以编写命令来检索一个或多个日志字段、寻找与一个或多个搜索条件匹配的日志事件、聚合日志数据，以及从基于文本的日志中提取临时字段。该查询语言很容易学习，Logs Insights 使用示例查询、命令描述和查询自动完成的格式提供产品帮助，以帮助您完成入门。您可以在此处找到关于该查询语言的其他详细信息。"
    },
    {
        "query":"CloudWatch Logs Insights 有哪些服务限制？",
        "intention":"知识问答",
        "reply":"服务限制记录在[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/cloudwatch_limits_cwl.html)。"
    },
    {
        "query":"CloudWatch Logs Insights 在哪些区域中推出？",
        "intention":"知识问答",
        "reply":"Logs Insights 在以下区域推出：美国西部（俄勒冈）、美国西部（加利福尼亚北部）、美国东部（俄亥俄）、美国东部（弗吉尼亚北部）、亚太地区（孟买）、亚太区域（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲（法兰克福）、欧洲（爱尔兰）、欧洲（伦敦）、欧洲（巴黎）、南美洲（圣保罗）。"
    },
    {
        "query":"CloudWatch Logs Insights 支持哪些查询类型？",
        "intention":"知识问答",
        "reply":"您可以编写包含聚合、筛选条件、正则表达式和文本搜索的查询。您还可以从日志事件提取数据以创建临时字段，这些字段可由查询语言进一步处理以帮助您评估您正在查找的信息。查询语言支持字符串、数字和数学函数，例如 concat、strlen、trim、log 和 sqrt 以及其他函数。您还可以使用布尔和逻辑表达式，并聚合多种函数，例如最小值、最大值、求和、平均和百分位以及其他函数。您可以在[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)找到关于该查询语言和可支持的函数的其他详细信息。"
    },
    {
        "query":"我可以将哪些查询命令和函数用于 CloudWatch Logs Insights？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)找到查询命令列表。您可以在[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)找到可支持的函数列表。\n问：我可以将哪些数据可视化用于 CloudWatch Logs Insights？\n您可以使用可视化功能来识别日志中随着时间出现的趋势和模式。Logs Insights 支持使用折线图和堆叠面积图进行数据可视化。它可以生成包含一个或多个聚合函数的所有查询的可视化格式，数据按照使用 bin() 函数指定的间隔时间进行分组。您可以在[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)找到关于可视化时间序列的其他详细信息。"
    },
    {
        "query":"我是否可将正则表达式用于 CloudWatch Logs Insights？",
        "intention":"知识问答",
        "reply":"您可以将 Java 型正则表达式用于 Logs Insights。正则表达式可用在筛选条件命令中。您可以在产品帮助中或[此处](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html)找到使用正则表达式进行查询的示例。"
    },
    {
        "query":"使用 CloudWatch Logs Insights 查询时如何转义特殊字符？",
        "intention":"知识问答",
        "reply":"您可以使用反引号转义特殊字符。包含非字母数字、@ 和 . 字符的日志字段名称需要使用反引号转义。"
    },
    {
        "query":"为什么特定日志字段中包含“@”符号而其他的没有？",
        "intention":"知识问答",
        "reply":"Logs Insights 生成的系统字段以 @ 开头。Logs Insights 目前可生成 3 种系统字段：@message 包含发送到 CloudWatch 的未解析的原始日志事件，@logStream 包含生成日志事件的源的名称，@timestamp 包含日志事件添加到 CloudWatch 的时间。"
    },
    {
        "query":"能否使用 CloudWatch Logs Insights 查询历史日志？",
        "intention":"知识问答",
        "reply":"通过 Logs Insights，您可以查询 2018 年 11 月 5 日或之后添加到 CloudWatch Logs 的日志数据。"
    },
    {
        "query":"能否从特定日志流搜索日志事件？",
        "intention":"知识问答",
        "reply":"您可以向日志查询添加查询命令   \n 筛选条件 @logStream = \"log\\_stream\\_name\"，以从特定日志流搜索日志事件。"
    },
    {
        "query":"今天我使用 AWS 合作伙伴 ISV 解决方案分析来自 CloudWatch 的日志。CloudWatch Logs Insights 为我带来了什么变化？",
        "intention":"知识问答",
        "reply":"CloudWatch Logs 已经支持与其他 AWS 服务（例如，Amazon Kinesis、Amazon Kinesis Data Firehose、Amazon Elasticsearch 以及 Splunk、Sumo Logic 和 DataDog 之类的 AWS 合作伙伴 ISV 解决方案和其他服务）进行集成的选项，以便为您提供涉及所有环境的选择和灵活性，用于满足自定义日志处理、扩充、分析和可视化需要。此外，CloudWatch Logs Insights 的查询功能还可用于通过 AWS 软件开发工具包进行的编程访问，以促使 AWS ISV 合作伙伴在 CloudWatch Logs Insights 的基础上构建更深层次的集成、高级分析和创造其他价值。"
    },
    {
        "query":"通过 AWS ISV 合作伙伴解决方案获得 CloudWatch Logs Insights 的查询功能如何使受益？",
        "intention":"知识问答",
        "reply":"ISV 合作伙伴与 CloudWatch Logs Insights 集成后，您可将日志数据存放在一个位置，并能够采用高性能且经济实惠的方式使用自己选择的工具和框架进行分析，而不必移动大量的数据。它还能通过消除与数据传输相关的延迟让您更快地访问日志，并杜绝配置和维护特定数据传输的操作复杂性。"
    },
    {
        "query":"什么是 Amazon CloudWatch Logs Live Tail？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch Logs Live Tail 是一项新的交互式分析功能，可让您实时查看传入日志。使用 Live Tail 可以快速解决问题：开发人员可以利用日志的流式视图来调试代码，而 IT 工程师可以可靠监控其部署状态。Live Tail 在相关事件的上下文中提供日志的实时交互式视图，有助于缩短平均检测时间，进而缩短平均解决时间。"
    },
    {
        "query":"我为什么应该使用 Cloudwatch Logs Live Tail？",
        "intention":"知识问答",
        "reply":"您应该使用交互式 CloudWatch Live Tail 功能在您的原生 AWS 可观测性工具中开箱即用地检测应用程序或部署问题。Live Tail 使开发运维团队可以在开发环境中深入了解您的关键应用程序日志和调试代码，而无需在多个工具之间切换。通过使用 Live Tail 监控部署的状态和运行状况，IT 工程师、运营支持和中央安全团队可以高效监控其服务和应用程序，从而加快根本原因分析并缩短平均解决时间。"
    },
    {
        "query":"Live tail 如何与其他 AWS 或第三方服务集成或交互？",
        "intention":"知识问答",
        "reply":"除了在自定义应用程序日志上提供 Live Tail 功能外，Live Tail 还有助于客户深入了解 Amazon Virtual Private Cloud、Amazon Route53、AWS Lambda、Amazon Elastic Kubernetes Service、Amazon Elastic Container Service 等 AWS 服务的日志。 AWS 服务可以通过使用 Live Tail 小部件，将相同的交互式实时跟踪体验嵌入到您的控制台中。此外，也可以通过其他服务（例如 Amazon Managed Grafana、AWS Thinkbox）实施直接集成，以便在您自己的控制台和任何生成日志事件的应用程序日志中为您提供相同的深入分析功能。"
    },
    {
        "query":"访问 Live Tail 需要什么权限？",
        "intention":"知识问答",
        "reply":"要使此功能按预期运行，应允许用户执行以下操作。启动 Live Tail 会话时，如果您不是管理员角色的一员或拥有包含 logs: 的策略\\*，请确保在策略声明中添加以下操作：logs:StartLiveTail 和 logs:StopLiveTail。"
    },
    {
        "query":"Live Tail 有哪些服务限制？",
        "intention":"知识问答",
        "reply":"了解有关 Live Tail [服务限制](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/cloudwatch_limits_cwl.html)的更多信息。"
    },
    {
        "query":"Live Tail 在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"Live Tail 现已在以下区域推出：美国东部（俄亥俄州）、美国东部（弗吉尼亚州北部）、美国西部（北加利福尼亚）、美国西部（俄勒冈州）、亚太地区（孟买）、亚太地区（首尔）亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）和南美洲（圣保罗）。"
    },
    {
        "query":"CloudWatch Logs Live Tail 支持哪种类型的筛选？",
        "intention":"知识问答",
        "reply":"您可以根据日志组、日志流进行筛选，也可以按关键字进行筛选。在监控账户中，日志组选择支持在多个账户中进行多项选择（跨账户可观测性）。日志流选择支持基于名称或前缀的多项选择。按关键字筛选区分大小写。可以输入一个或多个关键字（例如，error、exception 或 fault）以进一步缩小搜索范围。您可以键入关键字，也可以从 “信息” 面板中提供的示例中复制和粘贴。[了解有关筛选模式的更多信息。](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/FilterAndPatternSyntax.html#matching-terms-events)"
    },
    {
        "query":"我能否使用 Live Tail 查看历史日志？",
        "intention":"知识问答",
        "reply":"不能，Live Tail 提供 CloudWatch 收集的日志数据的实时视图。有关历史日志，请参阅 Logs Insights 和日志组功能。"
    },
    {
        "query":"Amazon CloudWatch Logs 中的数据保护是什么？",
        "intention":"知识问答",
        "reply":"数据保护是 CloudWatch Logs 中的一项功能，允许您定义自己的规则和策略，以自动检测和屏蔽从您的系统和应用程序收集的日志中的敏感数据。这是使用机器学习（ML）和模式匹配完成的。可以使用提升的身份和访问管理（IAM）权限查看未屏蔽的数据。"
    },
    {
        "query":"为什么我应该在 CloudWatch Logs 中使用数据保护？",
        "intention":"知识问答",
        "reply":"为了防止记录敏感数据，客户有时依赖于手动调查或通过配置简短的日志保留策略来删除日志，这会带来有价值的操作日志丢失的风险。CloudWatch Logs 数据保护会使用模式匹配和 ML 自动识别和屏蔽日志中的敏感信息，而无需任何人访问它们。此功能对于需要确保不存储任何个人信息的严格法规下的行业很有用。此外，构建需要大量个人和敏感信息的支付或身份验证服务的客户可以使用此新功能来降低不需要的信息存储在其日志中的可能性。"
    },
    {
        "query":"我可以在 CloudWatch Logs 中保护哪些类型的敏感数据？",
        "intention":"知识问答",
        "reply":"在 CloudWatch Logs 中创建数据保护策略时，您可以指定要保护的数据。有许多数据标识符供您选择，例如电子邮件地址、许多国家/地区的驾驶执照、信用卡号、地址等等。这些多种多样的目标数据标识符让您可以灵活地选择您的应用程序使用哪些敏感数据，并屏蔽不需要轻松访问的敏感数据。重要的是您要决定哪些信息对您的应用程序敏感，并为您的用例选择相关的标识符。"
    },
    {
        "query":"可以创建哪些类型的 CloudWatch 警报？",
        "intention":"知识问答",
        "reply":"您可以在账户中创建警报来监控任何 Amazon CloudWatch 指标。例如，您可以创建警报来监控 Amazon EC2 实例 CPU 使用情况、Amazon ELB 请求延迟、Amazon DynamoDB 表吞吐量、Amazon SQS 队列长度、甚至 AWS 账单费用。\n您还可以为特定于自定义应用程序或基础设施的自定义指标创建警报。如果自定义指标是高分辨率指标，您可以选择创建高分辨率警报，该警报将在 10 秒钟或 30 秒钟时段时发出提醒。\n使用复合警报，您可以将多个警报合并到警报层次结构。在多个警报同时触发时，仅触发一次可减少警报噪音。您可以为应用程序、AWS 区域或可用区等资源分组提供一个整体状态。\n请参阅 [CloudWatch 定价页面](https://aws.amazon.com/cn/cloudwatch/pricing/)，了解更多信息。"
    },
    {
        "query":"我可以执行 CloudWatch 警报的哪些操作？",
        "intention":"知识问答",
        "reply":"创建警报时，可进行配置，以便在所选监控指标超出所定义的阈值时执行一项或多项自动操作。例如，您可以设置发送电子邮件的警报，发布到 SQS 队列，停止或终止一个 Amazon EC2 实例，或执行 Auto Scaling 策略。由于 Amazon CloudWatch 警报与 Amazon Simple Notification Service 实现集成，因此还可使用由 SNS 支持的任意通知类型。 当警报进入 ALARM 状态时，您可以使用 AWS Systems Manager OpsCenter 操作自动创建 OpsItem。这有助于您通过单个控制台快速诊断和修复 AWS 资源问题。"
    },
    {
        "query":"可以设置哪些阈值来触发 CloudWatch 警报？",
        "intention":"知识问答",
        "reply":"创建警报时，首先要选择期望用之实施监控的 Amazon CloudWatch 指标。接下来，您要选择评估时长（例如，五分钟或一小时）和要测量的统计值（如平均值或最大值）。设定阈值时，设定一个目标值，并选择当实际值大于 (>)、大于等于 (>=)、小于 (<)、或小于等于 (<=) 该目标值时是否触发警报。"
    },
    {
        "query":"我的 CloudWatch 警报总是处于警报状态，是哪里出了问题？",
        "intention":"知识问答",
        "reply":"警报会持续根据您选择的阈值来评估指标，即便已被触发也不例外。这可使您随时查看当前的最新状态。您可能注意到，其中一个警报长时间处于 ALARM 状态。如果您的指标值始终超出阈值，警报将一直保持 ALARM 状态，直到不再超出阈值。这是正常现象。如果您希望警报将这种新状态处理为正常，可以相应地调节警报阈值。"
    },
    {
        "query":"我可以查看多长时间的警报历史记录？",
        "intention":"知识问答",
        "reply":"警报历史记录有效期为 14 天。要查看警报历史记录，请在 AWS 管理控制台登录 CloudWatch，选择左侧菜单中的“Alarms”，然后单击下方面板中的“History”选项卡。您可以在这里查找警报状态更改的历史记录以及警报配置修改。"
    },
    {
        "query":"什么是 CloudWatch 控制面板？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch 控制面板让您能够创建、自定义、交互和保存 AWS 资源及自定义指标的图表。"
    },
    {
        "query":"如何开始使用 CloudWatch 控制面板？",
        "intention":"知识问答",
        "reply":"要开始使用，请访问 [Amazon CloudWatch 控制台](https://console.aws.amazon.com/cloudwatch)，然后选择“Dashboards”。单击“Create Dashboard”按钮。 您还可以单击“选项” -> “添加到控制面板”以从自动化控制面板复制所需的视图。"
    },
    {
        "query":"自动化控制面板的优点是什么？",
        "intention":"知识问答",
        "reply":"自动化控制面板预先构建了 AWS 服务建议的最佳实践，保持资源感知，并能动态更新以反映重要性能指标的最新状态。您现在可以对特定视图进行筛选和故障排除，无需添加其他代码来反映 AWS 资源的最新状态。确定性能问题的根本原因之后，您就可以直接转到 AWS 资源以快速采取行动。"
    },
    {
        "query":"控制面板支持自动刷新吗？",
        "intention":"知识问答",
        "reply":"支持。控制面板处于打开状态时会自动刷新。"
    },
    {
        "query":"我可以共享控制面板吗？",
        "intention":"知识问答",
        "reply":"可以。只要拥有针对您账户的正确权限，任何人都可以访问您的控制面板。"
    },
    {
        "query":"什么是 CloudWatch Events？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch Events (CWE) 是一个描述 AWS 资源更改的系统事件流。该事件流扩充了现有的 CloudWatch 指标和日志流，以提供更为完整的应用程序运行状况和状态概况。您可以编写声明式规则，将您关注的事件与要执行的自动化操作关联起来。"
    },
    {
        "query":"哪些服务可发送 CloudWatch Events？",
        "intention":"知识问答",
        "reply":"目前支持 Amazon EC2、Auto Scaling 和 AWS CloudTrail。通过 AWS CloudTrail，可在 CloudWatch Events 中查看所有服务的更改类 API 调用（即，除 Describe\\*、List\\* 和 Get\\* 之外的所有调用）。"
    },
    {
        "query":"收到事件后我该怎么做？",
        "intention":"知识问答",
        "reply":"当某个事件与您在系统中创建的某条规则匹配时，您可以自动调用一个 AWS Lambda 函数、将事件中继到 Amazon Kinesis 流、发送 Amazon SNS 主题通知，或调用一个内置工作流。"
    },
    {
        "query":"我可以生成自己的事件吗？",
        "intention":"知识问答",
        "reply":"可以。通过使用 PutEvents API，您的应用程序可发送自定义事件，并采用专门满足您需求的负载。"
    },
    {
        "query":"我可以按固定的计划进行操作吗？",
        "intention":"知识问答",
        "reply":"通过使用常见的 Unix cron 语法，CloudWatch Events 能够按您设定的计划生成事件。通过监控这些事件，您可实施计划应用程序。"
    },
    {
        "query":"CloudWatch Events 与 AWS CloudTrail 有什么区别？",
        "intention":"知识问答",
        "reply":"CloudWatch Events 是一个近乎实时的系统事件流，用于描述 AWS 资源的更改。借助 CloudWatch Events，您可以定义规则，从而以自动方式监控特定的事件并执行相应操作。AWS CloudTrail 是一种服务，用于记录 AWS 账户的 API 调用并将包含 API 调用的日志文件发送到 Amazon S3 存储桶或 CloudWatch Logs 日志组。借助 AWS CloudTrail，您可以查看与 AWS 资源的创建、删除和修改有关的 API 活动历史记录，还可以排查运行和安全问题。"
    },
    {
        "query":"CloudWatch Events 与 AWS Config 有什么区别？",
        "intention":"知识问答",
        "reply":"AWS Config 是一种完全托管的服务，可为您提供 AWS 资源库存、配置历史记录和配置更改通知，以确保安全性和方便管理。Config 规则可帮助您确定配置更改是否合规。CloudWatch Events 用于近乎实时地应对资源状态更改。它不会裁定这些更改是否符合政策，也不会像 Config/Config Rules 那样提供详细的历史记录。它是一个通用的事件流。"
    },
    {
        "query":"什么是 CloudWatch Container Insights？",
        "intention":"知识问答",
        "reply":"CloudWatch 容器见解提供了监控、排查容器化应用程序和微服务和针对其发布警报的功能。容器见解简化了影响容器环境的性能问题的隔离和分析。开发运营和系统工程师可以访问 CloudWatch 控制台中的自动控制面板，获得按 Pod/任务、容器和服务汇总 [Amazon Elastic Container Service for Kubernetes (EKS)](https://aws.amazon.com/cn/eks/)、[Amazon Elastic Container Service (ECS)](https://aws.amazon.com/cn/ecs/)、[AWS Fargate](https://aws.amazon.com/cn/fargate/) 和 [Kubernetes](https://aws.amazon.com/cn/kubernetes/) 集群的性能和运行状况的指标、日志和分布式跟踪的端到端运营可见性。"
    },
    {
        "query":"我要如何开始使用 CloudWatch Container Insights？",
        "intention":"知识问答",
        "reply":"遵循 [CloudWatch Container Insights 文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html)中的这些步骤，只需单击几下，即可开始从容器和集群中收集详细的性能指标、日志和元数据。"
    },
    {
        "query":"CloudWatch Container Insights 如何定价？",
        "intention":"知识问答",
        "reply":"CloudWatch 容器见解自动从容器环境中摄入为 CloudWatch Logs 的性能事件收集自定义指标。有关定价的更多详细信息，请访问 [CloudWatch 定价页面](https://aws.amazon.com/cn/cloudwatch/pricing/)。"
    },
    {
        "query":"什么是 Prometheus，为什么需要在 CloudWatch 中收集 Prometheus 指标？",
        "intention":"知识问答",
        "reply":"Prometheus 是一个受欢迎的开源监控项目，它是 [Cloud Native Compute Foundation (CNCF)](https://www.cncf.io/announcement/2018/08/09/prometheus-graduates/) 的一部分。该开源社区已经构建了 150 多个插件，并定义了一个框架，开发运营团队可以使用该框架通过基于拉取的方法公开要从应用程序中收集的自定义指标。借助这项新功能，DevOps 团队可以自动发现针对容器化工作负载的服务，例如 [AWS App Mesh](https://aws.amazon.com/cn/app-mesh/)、NGINX 和 Java/JMX。他们随后可以在这些服务上公开自定义指标，并将指标摄取到 CloudWatch 中。通过安排 Prometheus 指标的收集和聚合，CloudWatch 用户可以在减少所用监控工具数量的同时，对应用程序性能下降和故障进行监控、故障排除和警报。"
    },
    {
        "query":"从我的容器环境中摄取 Prometheus 指标时，如何定价？",
        "intention":"知识问答",
        "reply":"您需要支付所使用的以下服务的费用：(1) 摄取的 CloudWatch Logs (GB)，(2) 存储的 CloudWatch Logs，以及 (3) CloudWatch 自定义指标。请参阅 [CloudWatch 定价页面](https://aws.amazon.com/cn/cloudwatch/pricing/)，了解您所在的 AWS 区域的定价详情。"
    },
    {
        "query":"摄取为 CloudWatch Logs 的 Prometheus 指标高基数事件的存储保留期是否可配置？",
        "intention":"知识问答",
        "reply":"可以。每个 Kubernetes (k8s) 集群均拥有其自己的事件日志组（如，/aws/containerinsights/<cluster-name>/prometheus）及自己的可配置保留期。有关详细信息，请参阅[日志组保留文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Working-with-log-groups-and-streams.html)。"
    },
    {
        "query":"Prometheus 指标的指标存储保留是如何工作的？",
        "intention":"知识问答",
        "reply":"Prometheus 指标将会自动摄取为 CloudWatch 自定义指标。保留期为每个指标数据点 15 个月，并且会自动汇总（3 小时可用 <60 秒，15 天可用 1 分钟，63 天可用 5 分钟，15 个月可用 1 小时）。要了解更多信息，请参阅 [CloudWatch 指标保留文档](https://aws.amazon.com/about-aws/whats-new/2016/11/cloudwatch-extends-metrics-retention-and-new-user-interface/)。"
    },
    {
        "query":"公共测试版是否支持所有 Prometheus 指标类型？",
        "intention":"知识问答",
        "reply":"否，目前受支持的指标类型为表盘图和计数器。计划将在即将推出的版本中支持直方图和汇总指标。"
    },
    {
        "query":"是否支持将 PromQL 用作查询语言？",
        "intention":"知识问答",
        "reply":"否。所有指标均摄取为 CloudWatch Logs 事件，可使用 CloudWatch Logs Insights 查询对其进行查询。有关更多信息，请参阅 [CloudWatch Logs Insights 搜索语言语法文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html)。"
    },
    {
        "query":"如何开始使用网络监测仪？",
        "intention":"知识问答",
        "reply":"要使用网络监测仪，您需要创建一个监测仪并将应用程序的资源、Amazon Virtual Private Clouds (VPC)、CloudFront 分配或 WorkSpaces 目录与其相关联，以使网络监测仪能够了解您的应用程序的互联网流量所在的位置。然后，网络监测仪将提供来自 AWS 的网络测量结果，这些测量结果特定于与您的应用程序通信的位置和网络。\n然后，您可以使用 CloudWatch 控制面板了解运行状况事件、查看性能和可用性分数、探索不同地理粒度的应用程序历史数据，并深入了解如何配置应用程序以提高最终用户的性能。\n网络监测仪将网络测量结果发布到 CloudWatch Logs 和 CloudWatch Metrics，因此，您可以轻松使用 CloudWatch 工具全面了解特定于您的应用程序的地理位置和网络中的应用程序运行状况。网络监测仪还会将运行状况事件发送到 Amazon EventBridge，让您可以设置通知。"
    },
    {
        "query":"网络监测仪有哪些组件？",
        "intention":"知识问答",
        "reply":"在探索网络监测仪时，熟悉服务中引用的组件和概念会有所帮助。网络监测仪使用或引用以下术语：监测、CloudWatch 日志、CloudWatch 指标、城市网络、运行状况事件、自治系统号（ASN）、受监测的资源、网络测量结果、往返时间、传输的字节数以及性能和可用性分数。\n阅读[文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-IM-components.html)中对这些组件的简短描述。"
    },
    {
        "query":"网络监测仪在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"对于网络监测仪，区域支持取决于您添加到监测仪的资源类型。对于 Amazon CloudFront 分配和 Amazon WorkSpaces 目录，网络监测仪在所有受支持的区域均可用。对于 Amazon Virtual Private Clouds (VPC)，来自选择加入区域的 VPC 只能添加到在同一区域中创建的监测仪。有关受支持的 AWS 区域的完整列表，请参阅 [Amazon CloudWatch 网络监测仪端点](https://docs.aws.amazon.com/general/latest/gr/cwim_region.html)。"
    },
    {
        "query":"什么是 Amazon CloudWatch 数字化体验监控 (DEM)？",
        "intention":"知识问答",
        "reply":"借助 Amazon CloudWatch DEM，您可以监控终端用户对应用程序的体验（包括性能、可用性和易用性）。\n发现间歇性问题，即使没有用户流量也能得到通知，并使用 CloudWatch Synthetic Canary 监控端点和 UI。CloudWatch RUM 与综合监控相补充，以了解终端用户的影响，并获得数字体验的更好可见性。借助 CloudWatch Evidently，通过试验和验证新设计和新功能，改善终端用户的数字化体验。"
    },
    {
        "query":"什么是 Amazon CloudWatch RUM？",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch RUM 是一项真实的用户监控功能，使您可以了解应用程序的客户端性能，帮助您减少解决问题的平均时间 (MTTR)。借助 CloudWatch RUM，您可以实时收集关于 Web 应用程序性能的客户端数据，以识别和调试问题。它对 CloudWatch Synthetics 数据进行补充，使您更加了解终端用户的数字化体验。你可以将性能异常可视化，并使用相关调试数据（如错误信息、堆栈跟踪和用户会话）来修复性能问题（如 JavaScript 错误、崩溃和延迟）。你还可以了解终端用户影响的范围，包括会话数量、地理位置或浏览器。CloudWatch RUM 聚合应用程序中关于用户旅程的所有数据，从而帮助您确定要启动哪些功能和优先修复哪些错误。"
    },
    {
        "query":"我要如何开始使用 CloudWatch RUM？",
        "intention":"知识问答",
        "reply":"在 CloudWatch RUM 中创建一个应用程序监视器，并在应用程序的 HTML 标头中添加轻量级 Web 客户端。然后使用 CloudWatch RUM 的控制面板启动，以接收来自不同地理位置、设备、平台和浏览器的用户洞察。"
    },
    {
        "query":"什么是 Amazon CloudWatch Evidently？",
        "intention":"知识问答",
        "reply":"借助 Amazon CloudWatch Evidently，您可以在推出新功能供普遍使用之前进行试验，以提前发现意外后果，从而减少与推出新功能有关的风险。 Evidently 能够使您在发布新功能之前在整个应用程序堆栈中验证这些功能，确保所发布的功能更加安全。 在发布新功能时，您可以对小范围用户群开放，监控页面加载时间或转化率等关键指标，然后调高流量。Evidently 还允许开发人员测试不同的设计方案，收集用户数据，在生产中发布最有效的设计。该服务可帮助您解释试验结果并采取行动，而无需高级统计知识。您可以在试验进行时使用 Evidently 统计引擎提供的洞察（例如任何时候的 p 值和置信区间）做出决策。"
    },
    {
        "query":"我要如何开始使用 CloudWatch Evidently？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch RUM JavaScript 代码段收集客户端的用户旅程数据和性能指标。您还可以使用 Evidently API 按需添加自定义指标，如转换率。下一步，您可以使用 CloudWatch Evidently SDK 测试需要检测的新功能，该功能使您能够控制用户如何访问新功能。现在，您可以使用 AWS 控制台 或 CLI 运行启动和试验。"
    },
    {
        "query":"什么是 Amazon CloudWatch Synthetics？",
        "intention":"知识问答",
        "reply":"借助 Amazon CloudWatch Synthetics，您可以更加轻松地监控应用程序终端节点。它全天候对终端节点运行测试，并在应用程序终端节点运行不正常时立即发出提醒。可以自定义测试，在应用程序中检查可用性、延迟、交易、坏链接或死链接、分步任务的完成情况、页面加载错误、UI 资产加载延迟、复杂的向导流或检出流。您还可以使用 CloudWatch Synthetics 隔离警报应用程序终端节点，并将它们映射回底层基础设施问题，以缩短解决问题的平均时间。"
    },
    {
        "query":"您要如何开始使用 CloudWatch Synthetics？",
        "intention":"知识问答",
        "reply":"CloudWatch Synthetics 非常容易上手。您可以在几分钟内编写自己的第一个通过的 Canary。要了解详情，请访问 [Amazon CloudWatch Synthetics 的相关文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries.html)。"
    },
    {
        "query":"何时应使用 Amazon CloudWatch Evidently 或 AWS AppConfig？",
        "intention":"知识问答",
        "reply":"这两种服务可以单独使用，但结合使用效果更好。\nAppConfig 是 AWS Systems Manager 的一项功能，可用于创建、管理和部署功能标志和其他应用程序配置。在开发新功能时，您可以使用 AppConfig 将新功能部署到生产中，但是可以把功能隐藏在标志切换后面。准备好启动之后，只需更新配置即可立即或逐渐发布此功能。\n如需更高级的功能管理和试验，您可以使用 Evidently，这是 Amazon CloudWatch 的一项新功能。借助 Evidently，您可以根据不同的功能变化运行试验，将其与基准功能对比，或如期发布功能变化，同时监控业务指标（如访问持续时间和收入）。Evidently 还与提供客户端侧应用程序性能监控功能的 CloudWatch RUM 集成，是您能够直接在 Evidently 中使用 RUM 指标。"
    },
    {
        "query":"什么是 Amazon CloudWatch Metrics Insights？",
        "intention":"知识问答",
        "reply":"CloudWatch Metrics Insights 是一个高性能查询引擎，它可以帮助您实时切割运营指标，使用标准 SQL 查询动态地创建聚合。借助 Metrics Insights，您可以通过大规模分析指标，了解应用程序的运行状况和性能状况。它与 CloudWatch 控制面板集成，因此您可以将查询保存到您的运行状况和性能控制面板中，以主动监控和快速查明问题。"
    },
    {
        "query":"我要如何开始使用 CloudWatch Metrics Insights？",
        "intention":"知识问答",
        "reply":"开始使用前，只需单击 CloudWatch 控制台上的指标选项卡，您将在“查询”选项卡下发现 Metrics Insights 作为内置的查询引擎，无需额外付费。Metrics Insights 配备标准 SQL 语言，但也可以使用可视化查询生成器开始使用 Metrics Insights。要使用查询生成器，请可视化选择感兴趣的指标、命名空间和尺寸，控制台将根据您的选择自动构建 SQL 查询。您可以使用查询编辑器随时在原始 SQL 查询中键入内容，深入挖掘并在进一步精细细节确定问题。Metrics Insights 还提供了一组即时可用的示例查询，这可以帮助您立即开始监控和调查应用程序的性能。Metrics Insights 也可以通过 CloudFormation、AWS SDK 和 CLI 以编程方式使用。\n了解有关 Amazon CloudWatch 定价的更多信息"
    },
    {
        "query":"What is Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: Amazon FinSpace is a fully managed data management and analytics service that makes it easy to store, catalog, and prepare financial industry data at scale, which reduces the time it takes for financial services industry (FSI) customers to find and access all types of financial data for analysis from months to minutes.\nFinancial services organizations analyze data from internal data stores like portfolio, actuarial, and risk management systems as well as petabytes of data from third-party data feeds, such as historical securities prices from stock exchanges. When performing analysis, it can take months to find the right data, get permissions to access the data in a compliant way, and prepare it for analysis."
    },
    {
        "query":"Why should I use FinSpace?",
        "intention":"知识问答",
        "reply":"A: FinSpace simplifies the process of discovering data, gaining permissions to access data, and transforming data to be ready for analysis—thus saving months of prep work done by financial services customers today.\nFinancial services organizations rely on hundreds of datasets sourced internally or externally to build investment models, manage risk, and improve customer experience. Today, it is taking analysts longer and longer to test new research ideas because data volumes are increasing, customers want to use more diverse datasets, and compute resources cannot keep up with the latest algorithms and data volumes. FinSpace helps data analysts be more productive and agile by reducing the time they spend searching for data, obtaining access to the data, and acquiring the compute resources needed to match their data volumes."
    },
    {
        "query":"How do I get started with FinSpace?",
        "intention":"知识问答",
        "reply":"A: To start using Amazon FinSpace, sign in to the AWS Management Console, navigate to “Amazon FinSpace” in the Analytics category, and then create a FinSpace environment. We have made available a sample dataset, typically used in capital markets, so that it’s easy to evaluate FinSpace’s features and capabilities. Users of the FinSpace web application can drag and drop files from their desktop to load into FinSpace. Developers can use FinSpace’s SDK to ingest data directly from S3."
    },
    {
        "query":"In which regions is Amazon FinSpace available?",
        "intention":"知识问答",
        "reply":"A: Please refer to the [AWS Region Table](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/) for details on Amazon FinSpace service availability by region."
    },
    {
        "query":"How does Amazon FinSpace integrate with my existing enterprise data lake (EDL)?",
        "intention":"知识问答",
        "reply":"A: Using FinSpace APIs, you can build integrations with an existing enterprise data lake and ingest data from S3."
    },
    {
        "query":"How do I load data into Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: You can use Amazon FinSpace’s API to ingest data programmatically into FinSpace. Learn more about Amazon FinSpace’s API in the API reference documentation. You can also drag and drop files directly into the FinSpace web application."
    },
    {
        "query":"Does FinSpace support streaming data?",
        "intention":"知识问答",
        "reply":"A: You can collect streaming data into change sets, which you then load into FinSpace using the FinSpace API so that you can perform historical analysis on the data."
    },
    {
        "query":"What security measures does Amazon FinSpace have?",
        "intention":"知识问答",
        "reply":"A: Amazon FinSpace ensures that all data managed within the application is encrypted in transit and at rest. Requests to the FinSpace API and web application are made over a secure (SSL) connection using TLS 1.2. You can integrate with your organization’s identity provider (IdP) using SAML. FinSpace will use an AWS Key Management Service (KMS) customer-managed customer master key (CMK) to encrypt all data stored in Amazon FinSpace. Amazon FinSpace is a single tenant service providing data and network isolation."
    },
    {
        "query":"How do I track activity in FinSpace for audit and compliance purposes?",
        "intention":"知识问答",
        "reply":"A: FinSpace automatically tracks application activity such as user logins, dataset and metadata operations, data access, and compute resources so that, at any point in time, you can determine who is accessing which data and how. You can generate and export activity reports using FinSpace Audit Report functionality."
    },
    {
        "query":"How does FinSpace make it easy for me to manage data access policies?",
        "intention":"知识问答",
        "reply":"A: In FinSpace, you can define user groups and then assign those groups to datasets, along with the fine grained access control."
    },
    {
        "query":"How do I manage data access with FinSpace?",
        "intention":"知识问答",
        "reply":"A: You create a FinSpace environment and load data inside it. You create users for that FinSpace environment. You assign permissions to users to access data by putting them into User groups. Permissions to perform any action in FinSpace are assigned to user groups, not directly to the user. User groups can be assigned to Datasets with fine-grained permissions."
    },
    {
        "query":"How do I access data stored in Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: You can access data in Amazon FinSpace using the web application, which includes a notebook, or you can use FinSpace APIs to access data through secured S3 access based on your access controls specified in FinSpace."
    },
    {
        "query":"How am I charged for Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: With Amazon FinSpace, you pay for users who have access to the application, the storage you use monthly, and the clusters used to prepare and analyze your data. See the [Amazon FinSpace pricing page](https://aws.amazon.com/finspace/pricing/) for details."
    },
    {
        "query":"How am I billed for data stored in Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: You pay only for the GB of data you load into FinSpace prorated according to the hours that the data is stored."
    },
    {
        "query":"How am I billed for users in Amazon FinSpace?",
        "intention":"知识问答",
        "reply":"A: You pay a monthly fee for each user enabled in FinSpace. The monthly charge is prorated according to the hours that the user is enabled."
    },
    {
        "query":"什么是 Amazon Location Service？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 是一项完全托管式服务，可让开发人员轻松地为应用程序添加位置功能（如地图、兴趣点、地理编码、路线规划、追踪和地理围栏），而无需牺牲数据安全性、用户隐私、数据质量或成本。  \n   \n 问：为什么要在应用程序中使用位置数据？  \n   \n 位置功能在商业和消费者应用程序中的应用日益增多。您可以使用位置服务来解决许多问题，例如在地图上显示数据以提供地理环境、确定旅行时间和距离、查找兴趣点以及将操作限制在特定位置。使用位置功能可实现基于地图的可视化、资产追踪、基于位置的客户互动以及配送或拼车应用程序等功能。访问 [Amazon Location Services 客户](https://aws.amazon.com/cn/location/customers/)页面，获取真实示例。  \n   \n 问：Amazon Location Service 有哪些用途？\n借助 Amazon Location Service，您可以使用来自全球可信提供商 Esri、HERE 和 GrabMaps 的高质量数据来访问具有成本效益且基于位置的服务（LBS）。您可以轻松将地图、兴趣点、地理编码、路线规划、追踪和地理围栏集成到应用程序中。除了 Esri、HERE 和 GrabMaps 提供的高质量选项外，Open Data Maps 也有助于开发人员以更灵活的方式将数据整合到应用程序中。\n借助 Amazon Location Service，您能够快速地将复杂的启用位置服务的应用程序投入生产，而无需花费高成本进行定制开发。它经济实惠的数据（包括追踪和地理围栏功能）以及用于监控运行状况的内置指标可帮助您降低成本并缩短开发时间。此外，Amazon Location Service 与多个 AWS 服务集成，可进一步加快应用程序开发的速度。有关 AWS 集成的更多信息，请参阅“问：Amazon Location Service 如何与其他 AWS 服务集成？” 此外，也可以访问功能页面，了解有关各项 [Amazon Location Service 功能](https://aws.amazon.com/cn/location/features/)的更多信息。"
    },
    {
        "query":"Amazon Location Service 已在哪些区域推出？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 现已面向以下区域推出：美国东部（俄亥俄州）、美国东部（弗吉尼亚州北部）、美国西部（俄勒冈州）、亚太地区（孟买）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（斯德哥尔摩）和南美洲（圣保罗）。\nAmazon Location Service 提供来自多个数据提供商的全球位置数据。请访问我们的[数据提供商页面](https://aws.amazon.com/cn/location/data-providers/)，了解更多信息。"
    },
    {
        "query":"什么是 Amazon Location Service 资源？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 资源是您用于所有位置 API 请求的实体。其中包括五种资源类型，每种类型都有自己的专用 API 和参考文档：地图资源、位置索引资源（通常称为位置）、路线规划计算器资源、地理围栏集资源和追踪器资源。"
    },
    {
        "query":"什么是 Amazon Location 地图资源？",
        "intention":"知识问答",
        "reply":"Amazon Location 地图资源是用于所有地图 API 请求的实体。地图由样式、地图图块以及可选的相关字体（字形）和图标（精灵）组成。根据所选样式，Amazon Location Service 将提供矢量格式的地图图块（通常用于抽象表示，例如街道地图）或栅格格式的地图图块（通常用于卫星或航空影像）。要在应用程序中显示地图，请将 Amazon Location Service 地图资源与渲染库（例如 MapLibre）结合使用（请参阅[此处的开发人员指南](https://docs.aws.amazon.com/location/latest/developerguide/tutorial-maplibre.html)）。然后，开发工具包可以请求区域的图块、样式、字形和精灵以及您要显示的缩放级别。无论您选择哪家提供商、选择哪种样式，Amazon Location Service 都会提供一致的地图 API。"
    },
    {
        "query":"什么是 Amazon Location 位置索引资源？",
        "intention":"知识问答",
        "reply":"Amazon Location 位置索引资源是一个地理搜索引擎，可用于搜索兴趣点、街道地址（地理编码）和地理坐标（反向地理编码）。在 Amazon Location 上，创建位置索引资源时，可以选择最适合您使用案例的数据供应商。创建资源后，您可以使用位置 API 发出搜索请求。位置 API 是一致的，在创建资源时适用于所有提供商。"
    },
    {
        "query":"什么是 Amazon Location Service 路线规划计算器资源？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 路线规划计算器资源是一个路线规划计算器，您可以使用它来请求行车路线规划、行车时间和地理位置之间的行车距离。在 Amazon Location Service 上，创建路线规划计算器资源时，可以选择最适合您使用案例的数据供应商。创建资源后，您可以使用路线规划 API 发出路线规划计算请求。路线规划 API 是一致的，在创建资源时适用于所有提供商。"
    },
    {
        "query":"什么是 Amazon Location 地理围栏集资源？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 地理围栏集资源是一个容器实体，用于存储地理围栏（地图上的虚拟边界）。您可以使用地理围栏 API 根据地理围栏集资源中的所有地理围栏来估算一个位置。如果位置更新越过集中任何地理围栏的边界，则资源将针对每个越界的地理围栏发出进入和退出事件。"
    },
    {
        "query":"什么是 Amazon Location 追踪器资源？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 追踪器资源是一个容器实体，用于存储设备中的位置更新。您可以使用追踪器 API 提交位置更新，然后查询当前和历史位置。您还可以将追踪器资源链接到您的 Amazon Location Service 地理围栏集资源，会根据您的所有地理围栏对位置进行自动更新。如果位置更新越过任何地理围栏的边界，则地理围栏集资源将针对每个越界的地理围栏发出进入和退出事件。在根据地理围栏存储或评估位置更新之前，您可以通过从未移动的设备中过滤掉位置更新来降低成本。"
    },
    {
        "query":"什么是 Amazon Location 数据供应商？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 使用来自全球的可信[数据供应商](https://aws.amazon.com/location/data-providers/)提供的数据，通过一致的 API 向我们的客户交付地图、地理编码和路线规划。在使用这些提供商提供的位置数据时，要了解有关特定条款和条件以及定价规则的更多信息，请阅读[服务条款](https://aws.amazon.com/cn/service-terms/)和[定价页面](https://aws.amazon.com/cn/location/pricing/)。  \n   \n 问：我可以为地图、地理编码和路线规划不同的提供商吗？\n可以。借助 Amazon Location Service，您可以为地图、地理编码和路线规划不同的提供商。您可以将不同提供商的位置数据用于不同的地理区域。我们建议您对同一地理区域使用来自同一提供商的地图、兴趣点和路线规划，以确保兼容性。请注意，您不能在 HERE 的地图上对另一个数据供应商的路线规划进行分层，也不能在另一个数据供应商的地图上对 HERE 的路线规划进行分层。  \n   \n 问：我应该选择什么样的数据供应商？\n对于大多数使用案例，我们建议您选择适用于各种使用案例的服务中的默认选择。您可以根据自己的偏好和此前的经验来选择提供商。对于需要专业数据或区域专业知识的使用案例，您可以对所有数据供应商进行评估，然后选择最适合您的特定应用程序的一种。"
    },
    {
        "query":"Amazon Location Service 支持何种精度？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 可以接收精确到小数点后六位 (0.000001) 的位置数据，这相当于赤道上的大约 11 厘米或 4.4 英寸。使用追踪功能时，您可以将位置更新发送到最多可精确到小数点后六位的 Amazon Location Service 追踪器。使用地理围栏功能时，最小的地理围栏必须至少有 3 个11 厘米或 4.4 英寸的顶点，覆盖 0.05 平方米或 77 平方英寸的面积。但是，在大多数应用程序中，物理设备在计算其 GPS 位置时的精度和准确性会成为限制因素。除非您使用的是专门的定位设备，否则我们建议您通过概念验证来确定应用程序的准确性，并使用大于 1000 平方米或 10000 平方英尺的地理围栏。"
    },
    {
        "query":"Amazon Location Service 地图支持哪种输出格式？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 地图以常用的开源 Mapbox Style Specification (MSS) 格式提供地图样式信息，以 Mapbox Vector Tile (MVT) 格式提供地图图块。您可以选择最适合应用程序的输出格式，并在使用 Amazon Location Service 时在它们之间切换。"
    },
    {
        "query":"Amazon Location 资源和使用有什么限制吗？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 可以支持大量并行活动的地理围栏，同时根据大量移动资产对它们进行估算，而且，通常情况下，所有功能都支持每秒大量事务 (TPS)。如果您的应用程序可能需要超过 50000 个地理围栏，请访问我们的文档[开发人员指南中的限制和配额](https://docs.aws.amazon.com/location/latest/developerguide/location-quotas.html)。"
    },
    {
        "query":"Amazon Location Service 提供哪些开发工具包？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 提供适用于 Android、iOS 和 Web 的前端开发工具包。您可以通过 [AWS 工具页面](https://aws.amazon.com/cn/tools/)上列出的后端开发工具包访问 Amazon Location Service。[AWS 命令行界面 (CLI)](https://aws.amazon.com/cn/cli/) 支持 Amazon Location Service。CLI 是一个统一工具，可让您从命令行下载、配置和控制多个 AWS 服务，并通过脚本自动执行这些服务。"
    },
    {
        "query":"Amazon Location Service 如何与其他 AWS 服务集成？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 与 AWS CloudFormation、Amazon CloudWatch、AWS CloudTrail 和 Amazon EventBridge 集成，因此您可以有效地预置和管理资源、监控运行状况指标并自动对事件执行操作。借助这些功能，可以加快应用程序的投产速度。借助 AWS CloudFormation，使用 Amazon Location Service 创建模板，以便快速一致地预置资源。您可以使用 Amazon CloudWatch 监控有关服务使用情况和运行状况的指标（包括请求、延迟和故障），因此您不必构建自己的运行状况监控工具。Amazon Location Service 与 AWS CloudTrail 集成，用于记录并持续监控账户活动。与 Amazon EventBridge 集成后可支持事件驱动型应用程序架构，因此可以使用 AWS Lambda 函数来响应事件（例如追踪进入或退出地理围栏的资产）。此外，您还可以在一个视图中使用标签帮助管理、识别、组织、搜索和筛选 Amazon Location Service 资源。您可以创建标签，以按用途、拥有者、环境或计费关系对资源进行分类。"
    },
    {
        "query":"我有哪些访问控制选项？",
        "intention":"知识问答",
        "reply":"您可以使用 IAM 来管理 AWS 账户的用户、组和角色。IAM 使您能够安全地管理对 AWS 服务和资源的访问。对于 Web 和移动开发工具包，您可以使用 Amazon Cognito 来管理应用程序最终用户的身份验证和授权。您还可以自带身份验证堆栈，并将其与 Cognito 结合使用，而无需复制用户身份。Amazon Location Service 还与 AWS Key Management Service (KMS) 集成，让您可以使用现有密钥来加密追踪和地理围栏数据。要了解更多信息，请访问有关 Amazon Location Service 的[文档](https://docs.aws.amazon.com/location/latest/developerguide/what-is.html)。"
    },
    {
        "query":"使用 Amazon Location Service 时，我的数据会离开我的 AWS 账户吗？",
        "intention":"知识问答",
        "reply":"发送到追踪和地理围栏的数据不会离开您的 AWS 账户。我们会将地图、位置和路线规划请求中的参数值发送到您选择的位置数据供应商，以便他们可以处理这些请求。Amazon Location Service 仅包含处理请求所需的参数，由此来匿名化处理对我们的提供商发出的请求。所有静态数据和传输中数据都是加密的，只有在处理时才会解密。此外，除了处理您的请求外，我们禁止 Amazon Location Service 提供商存储或使用您的内容。我们会定期审核 Amazon Location Service 第三方提供商的安全性，以确保满足网络安全性、访问控制、数据保护和物理安全性的标准。"
    },
    {
        "query":"Amazon Location Service 如何使用我的请求中的数据？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 只使用您的数据来维护和提供此服务。地理围栏和追踪数据存储在您所使用服务的所在区域中的 AWS 账户中。我们会将地图、位置和路线规划请求中的参数值发送到您选择的位置数据供应商，以便他们可以处理这些请求。请参阅“问：使用 Amazon Location Service 时，我的数据会离开我的 AWS 账户吗？”；有关更多信息，请参阅我们的[服务条款。](https://aws.amazon.com/service-terms/)"
    },
    {
        "query":"我可以使用 Amazon Location Service 构建配送应用程序吗？",
        "intention":"知识问答",
        "reply":"可以。配送应用程序需要存储、追踪和协调源位置、配送车辆以及目的地。Amazon Location Service 为您提供了一套构建配送应用程序的功能和数据。例如，使用 Amazon Location Service 构建的送餐应用程序可以使用位置追踪和地理围栏，当指定的配送司机在附近时，自动通知餐厅，从而减少司机的等待时间，并帮助确保送达时食物的新鲜度。请访问我们[关于配送应用程序的文档](https://docs.aws.amazon.com/location/latest/developerguide/delivery.html)，获取解决方案指南。"
    },
    {
        "query":"我可以使用 Amazon Location Service 进行资产追踪吗？",
        "intention":"知识问答",
        "reply":"可以。借助 Amazon Location Service，您可以快速开始存储资产位置、在地图上可视化资产位置、基于资产邻近度触发事件以及分析位置历史记录。资产追踪帮助企业了解其产品、人员和基础设施的当前位置和位置历史记录。开发人员可以使用资产追踪数据来确保途中运输安全、最大限度提高派遣效率、追踪设备等等。请访问我们[有关资产追踪的文档](https://docs.aws.amazon.com/location/latest/developerguide/asset-tracking.html)，并参阅解决方案指南，了解更多信息。"
    },
    {
        "query":"我可以使用 Amazon Location Service 进行地理营销吗？",
        "intention":"知识问答",
        "reply":"可以。您可以尝试使用地理营销功能，然后通过 Amazon Location Service 将其整合到您的应用程序中。地理营销是指结合地理位置进行的营销活动。它根据客户位置和行为个性化时间和消息内容，来提高营销传播的有效性。例如，进入购物中心的客户可以从他们最喜欢的商店中获得特惠，或者从他们路过的咖啡厅获得免费咖啡。请访问我们[有关地理营销的文档](https://docs.aws.amazon.com/location/latest/developerguide/user-engagement-geomarketing.html)，获取解决方案指南。"
    },
    {
        "query":"使用 Amazon Location Service 如何付费？",
        "intention":"知识问答",
        "reply":"Amazon Location Service 无需预付费用，也没有最低消费限制。只需按使用量付费即可。Amazon Location Service 为前三个月使用期提供免费套餐。位置数据根据您的应用程序向服务发出的每个请求计费。除了 Amazon Location Service 免费套餐之外，您还需要为应用程序向服务发出的请求付费。"
    },
    {
        "query":"什么是 Amazon OpenSearch Service？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 是一项托管服务，可以让您轻松地进行交互式日志分析、实时应用程序监控和网站搜索等工作。[OpenSearch](https://aws.amazon.com/cn/opensearch-service/the-elk-stack/what-is-opensearch/) 是一款开源的分布式搜索和分析套件，衍生自 Elasticsearch。Amazon OpenSearch Service 提供最新版本的 OpenSearch，支持 19 个版本的 Elasticsearch（1.5 到 7.10 版本），以及支持由 OpenSearch Dashboards 和 Kibana（1.5 到 7.10 版本）提供的可视化功能。Amazon OpenSearch Service 目前已经拥有上万个活跃客户，托管了数十万个集群，每月处理数万亿个请求。更多详细信息，请参阅 [Amazon OpenSearch Service 常见安问题](https://aws.amazon.com/cn/what-is/opensearch/)。"
    },
    {
        "query":"Amazon OpenSearch Service 支持哪些 OpenSearch 和 Elasticsearch 版本？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 提供最新版本的 OpenSearch，并支持 19 个版本的 Elasticsearch（1.5 至 7.10 版）。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-gsg-supported-operations.html)。"
    },
    {
        "query":"什么是 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 域是使用 Amazon OpenSearch Service 控制台、CLI 或 API 创建的 Elasticsearch（1.5 至 7.10）或 OpenSearch 集群。每个域都是云中的一个 OpenSearch 或 Elasticsearch 集群，其中包含您指定的计算和存储资源。您可以创建和删除域、定义基础设施属性以及控制访问和安全性。您可以运行一个或多个 Amazon OpenSearch Service 域。"
    },
    {
        "query":"Amazon OpenSearch Service 可托管哪些内容？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 可管理设置域所涉及的工作，从在您请求的网络环境中预置基础设施资源到安装 OpenSearch 或 Elasticsearch 软件。一旦您的域开始运行，Amazon OpenSearch Service 会自动执行常见的管理任务，例如执行备份、监控实例以及软件补丁。Amazon OpenSearch Service 与 Amazon CloudWatch 集成，以生成提供有关该域状态信息的指标。Amazon OpenSearch Service 还提供了修改域实例和存储设置的选项，以简化根据您的应用程序需求定制域的任务。"
    },
    {
        "query":"Amazon OpenSearch Service 是否支持开源 Elasticsearch 和 OpenSearch API？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 支持大多数常用的 OpenSearch 和 Elasticsearch API，因此，您在 Elasticsearch（7.10 及更低版本）或 OpenSearch 环境中正在使用的代码、应用程序和常见工具可以无缝地正常工作。有关可支持操作的完整列表，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-gsg-supported-operations.html)。"
    },
    {
        "query":"Amazon OpenSearch Service 上提供哪些可用区（AZ）部署选项？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 为客户提供了跨一个、两个或三个可用区部署实例的选项。运行开发或测试工作负载的客户可以选择单个可用区选项。运行生产级工作负载的客户应使用两个或三个可用区。强烈建议对具有更高可用性要求的工作负载部署三个可用区。\n注意：三个可用区选项仅适用于具有三个或更多可用区的区域。"
    },
    {
        "query":"Amazon OpenSearch Service 在哪些区域提供三个可用区部署？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 在提供该服务的所有区域中均支持三个可用区部署，美国西部（北加利福尼亚）除外，我们在该区域仅支持两个可用区。"
    },
    {
        "query":"如何将 Amazon OpenSearch Service 用于在本地或其他云上运行的资源？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 是一项完全托管的服务，允许您运行与扩展 OpenSearch 集群，而不必为基础设施的管理、监控和维护担心，并且无需具备有关操作 OpenSearch 集群的深厚专业知识。作为一项完全托管的服务，Amazon OpenSearch Service 目前在 AWS 上运行。但是，OpenSearch 是一个分布式、社区驱动、Apache 2.0 许可的 100% 开源搜索和分析套件，可在本地或[混合和多云环境](https://aws.amazon.com/hybrid-multicloud/)中运行。例如，有些合作伙伴在其他云平台上提供 OpenSearch，或者在其应用程序中使用 OpenSearch。OpenSearch 可帮助您更轻松地为一系列应用场景（如日志分析、应用程序搜索、企业搜索，等等）提取、保护、搜索、聚合、查看以及分析数据。OpenSearch 提供了一个高度可扩展的系统，通过集成的可视化工具 OpenSearch 控制面板快速访问和响应大量数据，使用户可以更轻松地探索他们的数据。OpenSearch 由 Apache Lucene 搜索库提供技术支持，它支持一系列搜索及分析功能，如 k-最近邻 (KNN) 搜索、SQL、异常检测、Machine Learning Commons、Trace Analytics、全文搜索等。"
    },
    {
        "query":"我是否可以通过 Amazon OpenSearch Service 控制台创建和修改 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"是的。您只需单击几下即可在控制台中使用域创建向导创建新的 Amazon OpenSearch Service 域。创建新的域时，您可以指定实例数量、实例类型以及您希望分配给域的 EBS 卷。您还可以在控制台中修改或删除现有的 Amazon OpenSearch Service 域。"
    },
    {
        "query":"Amazon OpenSearch Service 是否支持 Amazon VPC？",
        "intention":"知识问答",
        "reply":"是的。Amazon OpenSearch Service 可以和 Amazon VPC 集成。选择 VPC 访问后，VPC 中的 IP 地址会挂载到 Amazon OpenSearch Service 域，并且所有网络流量均保持在 AWS 网络内，且无法通过 Internet 访问。此外，您还可以使用安全规则组和 IAM 策略，以限制对 Amazon OpenSearch Service 域的访问。"
    },
    {
        "query":"我是否可以使用 CloudFormation 模板预置 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"是的。[AWS CloudFormation](https://aws.amazon.com/cn/cloudformation/) 支持 Amazon OpenSearch Service。更多详细信息，请参阅 [CloudFormation 模板参考](http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticsearch-domain.html)文档。"
    },
    {
        "query":"Amazon OpenSearch Service 是否支持配置专用的主节点？",
        "intention":"知识问答",
        "reply":"是的。您可以为域配置专用的主节点。在选择专用的主节点配置时，您可以指定实例类型和实例数量。"
    },
    {
        "query":"我是否在可以在单个 Amazon OpenSearch Service 域中创建多个 Elasticsearch 或 OpenSearch 索引？",
        "intention":"知识问答",
        "reply":"是的。您可以在同一个 Amazon OpenSearch Service 域中创建多个 Elasticsearch 或 OpenSearch 索引。Elasticsearch 和 OpenSearch 会自动在分配到该域的实例之间分发索引和所有相关副本。"
    },
    {
        "query":"我如何将数据摄取到 Amazon OpenSearch Service 域中？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 支持三种数据摄取方式："
    },
    {
        "query":"Amazon OpenSearch Service 是否支持与 Logstash 集成？",
        "intention":"知识问答",
        "reply":"是的。Amazon OpenSearch Service 支持与 Logstash 的集成。您可以将 Amazon OpenSearch Service 域配置为数据存储，用于存储所有来自 Logstash 的日志。您可以在 Amazon OpenSearch Service 域上设置访问控制，可以使用请求签名来验证来自 Logstash 的调用，或者使用基于资源的 IAM 策略允许运行 Logstash 实例的 IP 地址进行访问。"
    },
    {
        "query":"Amazon OpenSearch Service 是否支持与 Kibana 集成？",
        "intention":"知识问答",
        "reply":"是的。Amazon OpenSearch Service 提供由 OpenSearch Dashboards 和 Kibana（1.5 至 7.10 版本）支持的可视化功能。"
    },
    {
        "query":"Amazon OpenSearch Service 具有哪些存储选项？",
        "intention":"知识问答",
        "reply":"您可以选择本地实例存储或 EBS 卷。在创建域的过程中，如果您选择 EBS 存储，则可以按需增加和减少存储卷的大小。"
    },
    {
        "query":"Amazon OpenSearch Service 支持哪些类型的 EBS 卷？",
        "intention":"知识问答",
        "reply":"您可以选择磁介质卷、通用型卷和预置 IOPS EBS 卷。\n问：可以分配给 Amazon OpenSearch Service 域的存储容量是否存在限制？\n是的。Amazon OpenSearch Service 根据实例的选择和/或关联的 EBS 卷的大小部署存储。对于存储为 EBS gp3 的 R6g.12xlarge 实例，每个节点的最大存储量为 24 TB。在默认情况下，每个 Amazon OpenSearch Service 域最多可有 80 个数据节点，因此，您可以为一个域分配 1920 TB 左右的存储容量。您可以在 [AWS Support Center](https://console.aws.amazon.com/support/home#/) 创建一个问题来申请提高服务限制，将每个域的实例数增加到 200 个。通过这 200 个实例，您可以为一个域分配 3 PB 左右的存储容量。"
    },
    {
        "query":"如何在可用区之间分配专用主实例？",
        "intention":"知识问答",
        "reply":"如果在单个可用区中部署数据实例，则专用主实例也会部署在同一个可用区中。但是，如果跨两个或三个可用区部署数据实例，Amazon OpenSearch Service 会自动在三个可用区中分配专用主实例。如果某个区域只有两个可用区，或者您为主实例选择了不是在所有可用区中都可用的较老一代实例类型，则会出现例外情况。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"生产工作负载的推荐可用区配置是什么？",
        "intention":"知识问答",
        "reply":"对于生产工作负载，我们建议跨三个可用区部署数据实例，因为这样可以提供更好的可用性。此外，我们还建议预置的实例数为三的倍数，以便在可用区之间均匀分布。在没有三个可用区的区域，我们建议使用两个可用区部署，数据实例数设置为偶数。在所有情况下，我们都建议预置三个专用的主实例。"
    },
    {
        "query":"如何配置我的域启用三个可用区部署？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 控制台、CLI 或软件开发工具包，为现有域和新域启用三个可用区部署。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"启用三个可用区部署是否需要付费？",
        "intention":"知识问答",
        "reply":"不需要，Amazon OpenSearch Service 不会针对启用三个可用区部署收取任何费用。您只需根据域中的实例数量付费，而不是部署实例的可用区数。"
    },
    {
        "query":"我没有在控制台中看到曾经的“可用区感知”选项。是域不再有可用区感知了吗？",
        "intention":"知识问答",
        "reply":"配置了多个可用区的所有域都会启用可用区感知，以确保在可用区之间分配分片。在控制台中，您现在可以显式地选择两个或三个可用区部署。除非重新配置，否则先前使用“可用区感知”配置的域将继续部署在两个可用区中。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"Amazon OpenSearch Service 如何处理实例故障和可用区中断？",
        "intention":"知识问答",
        "reply":"如果可用区中的一个或多个实例无法访问或无法使用，Amazon OpenSearch Service 会自动尝试在同一个可用区中启动新实例以替换受影响的实例。在罕见的情况下，例如无法在可用区中启动新实例，如果该域配置为跨多个可用区部署，则 Amazon OpenSearch Service 会在其他可用区中启动新实例。一旦可用区问题得到解决，Amazon OpenSearch Service 会重新平衡实例，以便将其均匀分布在为域配置的可用区中。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"如果我的域中的索引只有一个副本，那么应该使用两个还是三个可用区？",
        "intention":"知识问答",
        "reply":"即使配置一个副本，我们也建议使用三个可用区。如果在三个可用区域中发生可用区中断，则只会丢失三分之一的容量，但如果在两个可用区域中发生中断，则会损失一半的容量，这可能会更具破坏性。此外，在三个可用区域中，当可用区中断时，Amazon OpenSearch Service 可以回退到剩下的两个可用区，并且仍然支持跨可用区复制。在两个可用区域中，如果一个可用区中断，则会失去跨可用区复制能力，从而进一步降低可用性。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"如何为我的 VPC 域配置三个可用区部署？",
        "intention":"知识问答",
        "reply":"域部署的可用区数量与您为 VPC 域配置的子网数量相对应。您需要在 VPC 域中配置至少三个子网才能启用三个可用区部署。有关配置 VPC 的更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-managedomains.html#es-managedomains-multiaz)。"
    },
    {
        "query":"在我自己的数据中心的服务器上运行的程序是否可以访问我的 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"是的。所有能够访问公共 Internet 的程序均可通过公有端点访问 Amazon OpenSearch Service 域。如果您的数据中心已通过 Direct Connect 或 SSH 隧道连接了 Amazon VPC，您还可以通过 VPC 访问。这两种情况下，您都可以通过配置 IAM 策略和安全规则组，来允许在 AWS 外部的服务器上运行的程序访问 Amazon OpenSearch Service 域。 [单击此处](http://docs.aws.amazon.com/general/latest/gr/signature-version-4.html)可以了解有关签名请求的更多信息。"
    },
    {
        "query":"如何将数据从现有的 OpenSearch/Elasticsearch 集群迁移到新的 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"要从现有 Elasticsearch 或 OpenSearch 集群迁移数据，您应创建现有集群的快照，并将该快照存储在 Amazon S3 存储桶中。然后，您可以创建一个新的 Amazon OpenSearch Service 域，使用还原 API 将快照中的数据加载到新创建的 Amazon OpenSearch Service 域中。"
    },
    {
        "query":"如何扩展 Amazon OpenSearch Service 域？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 允许您使用控制台、API 和 CLI 控制 Amazon OpenSearch Service 域的扩展。您可以根据应用程序需求，通过添加、删除或修改实例或存储卷扩展您的 Amazon OpenSearch Service 域。Amazon OpenSearch Service 与 Amazon CloudWatch 集成以提供有关 Amazon OpenSearch Service 域状态的指标，从而使您能够为域做出适当的扩展决策。"
    },
    {
        "query":"扩展 Amazon OpenSearch Service 域是否需要停机？",
        "intention":"知识问答",
        "reply":"不需要。通过添加或修改实例和存储卷扩展 Amazon OpenSearch Service 域是一项在线操作，完全不需要停机。"
    },
    {
        "query":"Amazon OpenSearch Service 是否支持跨可用区复制？",
        "intention":"知识问答",
        "reply":"是的。如果为 OpenSearch/Elasticsearch 索引启用副本并使用多个可用区，则 Amazon OpenSearch Service 会自动在不同可用区中的实例之间分发主分片和副本分片。"
    },
    {
        "query":"Amazon OpenSearch Service 是否会通过 Amazon CloudWatch 发布任何性能指标？",
        "intention":"知识问答",
        "reply":"是的。Amazon OpenSearch Service 通过 Amazon CloudWatch 公开了多个性能指标，包括节点数量、集群运行状况、可搜索文档、EBS 指标（如果适用的话）、数据节点和主节点的 CPU、内存以及磁盘利用率。有关可用 CloudWatch 指标的完整列表，请参阅服务文档。"
    },
    {
        "query":"我希望对我的 Amazon OpenSearch Service 部署执行安全分析或操作故障排除。我是否能够获得我的账户上所有 Amazon OpenSearch Service API 调用的历史记录？",
        "intention":"知识问答",
        "reply":"是的。AWS CloudTrail 是一项 Web 服务，为您的账户记录 AWS API 调用并为您提供日志文件。由 AWS CloudTrail 生成的 AWS API 调用历史记录可支持安全分析、资源更改跟踪及合规性审计。您可以访问 [AWS CloudTrail 详细信息页面](https://aws.amazon.com/cn/cloudtrail/)了解有关 AWS CloudTrail 的更多信息，还可以通过 [CloudTrail 的“AWS 管理控制台”主页](https://console.aws.amazon.com/cloudtrail/home)进行查看。"
    },
    {
        "query":"什么是快照？",
        "intention":"知识问答",
        "reply":"快照是 Amazon OpenSearch Service 域在某一时刻的副本。"
    },
    {
        "query":"为什么需要快照？",
        "intention":"知识问答",
        "reply":"对于因节点故障以及不太可能出现的硬件故障造成的数据丢失，创建快照非常有用。您可以使用快照恢复具有预加载数据的 Amazon OpenSearch Service 域，或者创建具有预加载数据的新 Amazon OpenSearch Service 域。使用备份的另一个常见原因是用于存档。快照存储在 Amazon S3 中。"
    },
    {
        "query":"Amazon OpenSearch Service 是否提供自动快照？",
        "intention":"知识问答",
        "reply":"是的。默认情况下，Amazon OpenSearch Service 每小时会为每个 Amazon OpenSearch Service 域自动创建快照，并将其保留 14 天。"
    },
    {
        "query":"对于自动创建的每小时快照 Amazon OpenSearch Service 会保留多长时间？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 会保留过去 14 天自动创建的每小时快照。"
    },
    {
        "query":"是否可以根据需要创建更多 Amazon OpenSearch Service 域快照？",
        "intention":"知识问答",
        "reply":"是的。除 Amazon OpenSearch Service 创建的每日自动快照外，您可以使用 OpenSearch 快照 API 手动创建其他快照。手动快照存储在您的 S3 存储桶中，且将产生相关的 Amazon S3 使用费用。"
    },
    {
        "query":"出现故障时，是否可以使用由手动创建的快照来恢复域？",
        "intention":"知识问答",
        "reply":"是的。客户可以创建新的 Amazon OpenSearch Service 域，并使用 OpenSearch/Elasticsearch 还原 API 将快照中的数据加载到新建的 Amazon OpenSearch Service 域中。"
    },
    {
        "query":"如果我删除 Amazon OpenSearch Service 域，我的快照会发生什么？",
        "intention":"知识问答",
        "reply":"删除域时，将同时删除由 Amazon OpenSearch Service 保留的每日快照。删除域之前，您应该考虑使用手动快照流程在您自己的 S3 存储桶中创建该域的快照。如果您删除 Amazon OpenSearch Service 域，存储在 S3 存储桶中的快照将不受影响。"
    },
    {
        "query":"Amazon OpenSearch Service 会发布哪些类型的 OpenSearch/Elasticsearch 日志？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 会通过 Amazon CloudWatch Logs 发布三种 Elasticsearch 或 OpenSearch 日志：错误日志、慢搜索日志和慢索引日志。这些日志对于排查某个域的性能和稳定性问题非常有用。"
    },
    {
        "query":"什么是慢日志？",
        "intention":"知识问答",
        "reply":"慢日志是一种日志文件，可以帮助您跟踪一项操作在不同阶段的性能。OpenSearch 和 Elasticsearch 发布两种类型的慢日志：\n有关慢日志的更多详细信息，请参阅 [OpenSearch 文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-slowlog.html)。"
    },
    {
        "query":"如何在 Amazon OpenSearch Service 上启用慢日志？",
        "intention":"知识问答",
        "reply":"您可以通过单击控制台中的按钮或者通过 CLI 或 API 来启用慢日志。更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"是否能够只为特定索引启用慢日志？",
        "intention":"知识问答",
        "reply":"是的。您可以更新针对特定索引的设置，从而为其启用或禁用慢日志。更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"如果在 Amazon OpenSearch Service 中打开慢日志，是否会自动针对所有索引启用日志记录？",
        "intention":"知识问答",
        "reply":"在 Amazon OpenSearch Service 中打开慢日志后，您可以针对指定域中的索引，将生成的日志发布到 Amazon CloudWatch Logs。但是，要生成日志，您必须更新针对一个或多个索引的设置，这样才能启动日志记录过程。有关设置索引配置以启用慢日志的更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"在 Amazon OpenSearch Service 中关闭慢日志后，系统是否就不再生成日志文件了？",
        "intention":"知识问答",
        "reply":"不，是否生成日志文件取决于索引设置。要停止生成日志文件，您必须更新索引配置。有关设置索引配置以启用慢日志的更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"是否可以更改日志记录的粒度？",
        "intention":"知识问答",
        "reply":"您只能更改慢日志的日志记录粒度。OpenSearch 和 Elasticsearch 为慢日志提供了多个级别的日志记录。您需要在索引配置中设置适当的级别。有关慢日志的更多详细信息，请参阅 [OpenSearch 文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules-slowlog.html)。"
    },
    {
        "query":"启用慢日志或错误日志是否需要付费？",
        "intention":"知识问答",
        "reply":"启用慢日志或错误日志之后，Amazon OpenSearch Service 会向 CloudWatch Logs 发布生成的日志。Amazon OpenSearch Service 不会针对启用日志收取任何费用。但是，我们会收取标准的 [CloudWatch 费用](https://aws.amazon.com/cn/cloudwatch/pricing/)。"
    },
    {
        "query":"Amazon OpenSearch Service 会发布哪些类型的错误日志？",
        "intention":"知识问答",
        "reply":"OpenSearch 使用 [Apache Log4j 2](https://logging.apache.org/log4j/2.x/) 及其内置日志级别（严重级别从最低到最高）：TRACE、DEBUG、INFO、WARN、ERROR 和 FATAL。如果启用错误日志，Amazon OpenSearch Service 会将 WARN、ERROR、FATAL 级别的日志行以及从 DEBUG 级别选择的错误发布到 CloudWatch。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"如何在 Amazon OpenSearch Service 上启用错误日志？",
        "intention":"知识问答",
        "reply":"您可以通过单击 AWS 控制台中的按钮或者通过 CLI 或 API 来启用错误日志。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"是否可以仅为特定索引启用错误日志？",
        "intention":"知识问答",
        "reply":"不可以，系统将会发布整个域的错误日志。也就是说，一旦启用，域中所有索引的日志条目都将被发布。"
    },
    {
        "query":"Amazon OpenSearch Service 支持的所有Elasticsearch版本是否都可以使用错误日志？",
        "intention":"知识问答",
        "reply":"不，只有 Elasticsearch 5.x 及更高版本才可使用错误日志。"
    },
    {
        "query":"每个日志条目的大小是否有任何限制？",
        "intention":"知识问答",
        "reply":"是的。发布到 CloudWatch 的每个日志条目的大小不得超过 255000 个字符。超出这一限制的日志条目会被截断为 255000 个字符。"
    },
    {
        "query":"对于使用慢日志，有哪些建议的最佳实践？",
        "intention":"知识问答",
        "reply":"只有在排查索引问题或优化性能时，您才需要使用慢日志。建议您只针对要具体了解其性能的索引来启用日志记录。此外，完成调查后，您应该关闭日志记录，这样就不会再产生额外的费用。有关详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"如何使用 CloudWatch Logs 生成的日志？",
        "intention":"知识问答",
        "reply":"CloudWatch 支持多种日志使用方式。您可以[查看日志数据](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Working-with-log-groups-and-streams.html#ViewingLogData)、[将日志导入 S3](http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/S3Export.html) 或者[实时处理日志](http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html)。更多详细信息，请参阅 [CloudWatch Logs 开发人员指南](http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html)。"
    },
    {
        "query":"Amazon OpenSearch Service 支持的所有 OpenSearch 和 Elasticsearch 版本是否都可以使用慢日志？",
        "intention":"知识问答",
        "reply":"是的，Amazon OpenSearch Service 支持的所有 OpenSearch 和 Elasticsearch 版本都可以启用慢日志。但是，为不同版本的 Elasticsearch 指定日志设置的方式会稍有不同。更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-createupdatedomains.html#es-createdomain-configure-slow-logs)。"
    },
    {
        "query":"打开或关闭日志记录时，集群是否会中断运行？",
        "intention":"知识问答",
        "reply":"不会发生中断。每次日志状态更新时，我们都会在后台部署一个新集群，并用其替换已有集群。这一过程不会造成任何中断。但是，由于部署了新集群，日志状态不会即时更新。"
    },
    {
        "query":"哪些 Elasticsearch 和 OpenSearch 版本支持就地升级功能？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 目前支持所有 OpenSearch 版本或 Elasticsearch 5.x 及更高版本的域的就地升级。我们支持升级的目标版本是 5.6、6.3、6.4、6.5、6.7、6.8、7.1、7.4、7.7、7.8、7.9 和 7.10。 更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)。"
    },
    {
        "query":"我的域运行的是 5.x 之前版本的 Elasticsearch。如何升级这些域？",
        "intention":"知识问答",
        "reply":"请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)，以了解从不同 Elasticsearch 版本进行迁移的详细信息。"
    },
    {
        "query":"就地升级过程中，我的域是否会处于离线状态？",
        "intention":"知识问答",
        "reply":"不会。您的域在升级过程中仍然可用。但是，部分升级过程涉及分片的重新分配，这可能会影响域的性能。建议在您的域负载较低时进行升级。"
    },
    {
        "query":"如何确认我的域的 Elasticsearch 版本是否可以升级？",
        "intention":"知识问答",
        "reply":"就地版本升级功能仅适用于运行 Elasticsearch 5.x 及更高版本的域。如果您的域是 5.x 及更高版本，您可以运行升级资格检查来验证您的域能否升级为所需版本。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)。"
    },
    {
        "query":"Amazon OpenSearch Service 通过哪些测试来验证我的域的升级资格？",
        "intention":"知识问答",
        "reply":"有关我们为验证升级资格而运行的测试的详细列表，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)。"
    },
    {
        "query":"能否在版本升级过程中更新域配置？",
        "intention":"知识问答",
        "reply":"不能。启动就地版本升级后，您就无法更改域配置，直到升级完成或失败为止。在升级过程中，您可以继续读取和写入数据。另外，您可以删除该域，在这种情况下，系统会终止升级并将该域删除。"
    },
    {
        "query":"就地版本升级过程中，自动系统快照会出现什么情况？",
        "intention":"知识问答",
        "reply":"版本升级过程会自动创建系统快照，并且只在快照创建成功后才启动实际升级。如果在升级过程中到达了自动快照的开始时间，则系统会在当天跳过自动快照，并在第二天继续。"
    },
    {
        "query":"Amazon OpenSearch Service 如何防止在版本升级过程中出现问题？",
        "intention":"知识问答",
        "reply":"Amazon OpenSearch Service 会在启动升级之前运行一组测试，以便检查可能阻碍升级的已知问题。如果未出现问题，该服务会创建域的快照并在快照创建成功后启动升级过程。如果任何步骤遇到任何问题，则不会启动升级。"
    },
    {
        "query":"如果系统在执行就地版本升级时遇到问题，将会怎样？",
        "intention":"知识问答",
        "reply":"如果遇到的问题较小且可修复，Amazon OpenSearch Service 会自动尝试解决问题并解除升级锁定。但是，如果问题阻碍了升级，该服务将恢复到升级之前创建的快照并记录错误。有关查看升级过程日志的更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)。"
    },
    {
        "query":"是否可以查看域的升级历史记录？",
        "intention":"知识问答",
        "reply":"是的。您可以从 AWS 控制台查看升级日志或使用 CLI 或 SDK 请求升级日志。更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/es-version-migration.html)。"
    },
    {
        "query":"启动版本升级后，是否可以暂停或取消升级？",
        "intention":"知识问答",
        "reply":"不可以。升级一旦启动就无法暂停或取消，直到升级完成或失败为止。"
    },
    {
        "query":"是否可以在多个域上同时进行就地版本升级？",
        "intention":"知识问答",
        "reply":"是的。但是，如果您想让所有域保持同一版本，我们建议在升级之前在所有域上运行升级资格检查。这一额外步骤有助于发现在某个域中存在、但在其他域中可能不存在的问题。"
    },
    {
        "query":"就地版本升级需要多长时间？",
        "intention":"知识问答",
        "reply":"根据数据量和集群的大小，升级可能需要几分钟到几个小时的时间。"
    },
    {
        "query":"能否快速升级域而不保留任何数据？",
        "intention":"知识问答",
        "reply":"不可以。进行就地版本升级时，集群中的所有数据也会在升级过程中恢复。如果您只想单独升级域，您可以进行数据快照，删除域中的所有索引，然后再触发就地版本升级。此外，您还可以使用较新版本创建单独的域，然后将数据还原到该域。"
    },
    {
        "query":"如果不适应新版本，是否可以降级为之前的版本？",
        "intention":"知识问答",
        "reply":"否。如果您需要降级到较旧版本，请联系 AWS Support，以在新域上恢复升级前自动创建的快照。如果您对原始域进行了手动快照，您可以自行执行恢复步骤。"
    },
    {
        "query":"什么是带备用实例的多可用区？",
        "intention":"知识问答",
        "reply":"带备用实例的多可用区是 Amazon OpenSearch Service 的新部署选项，可为业务关键型工作负载提供高可用性和一致的性能。借助带备用实例的多可用区，OpenSearch Service 托管集群可以灵活应对节点丢失或单个可用区故障等基础设施故障，从而确保即使在单个可用区出现故障时也不会对性能或可用性产生影响。带备用实例的多可用区通过实施最佳实践和降低复杂性，提供简化集群配置和管理的额外优势。"
    },
    {
        "query":"使用带备用实例的多可用区创建或更新集群的先决条件是什么？",
        "intention":"知识问答",
        "reply":"要启用带备用实例的多可用区，托管集群需要满足以下条件："
    },
    {
        "query":"该功能涵盖和未涵盖的故障场景有哪些？",
        "intention":"知识问答",
        "reply":"借助带备用实例的多可用区，Amazon OpenSearch Service 可检测某些基础设施故障并自动从中恢复。发生以下任何事件时，Amazon OpenSearch Service 会在不到一分钟的时间内自动从活动节点故障转移到备用节点：\n目前，带备用实例的多可用区不涵盖以下事件："
    },
    {
        "query":"使用带备用实例的多可用区的托管集群是否需要调整大小？ 我们如何调整带备用实例的多可用区的托管集群规模？",
        "intention":"知识问答",
        "reply":"不需要。原则上，大小准则保持不变。带备用实例的多可用区具有简化集群调整规模所需思维模式的先决条件。考虑托管集群调整规模的方法是，您应该考虑为工作负载提供服务所需的容量，然后增加 50% 以实现冗余。当前的“区域感知”选项和带备用实例的多可用区选项之间的主要区别在于如何处理冗余或额外容量以保持可用性。带备用实例的多可用区要求您在每个可用区中至少有一个数据副本，以便带备用实例的多可用区可以在一个可用区中明确预留容量作为备用。在可用区中断或实例故障期间，此备用容量充当失效转移目标。现有模型要求您保持最佳资源水平以满足工作负载的需求。您将继续监控集群的规模问题，并在工作负载特征变化时采取纠正措施。"
    },
    {
        "query":"选择带备用实例的多可用区是否意味着我不必再确保集群大小和资源都适合自己的工作负载？",
        "intention":"知识问答",
        "reply":"不。Amazon OpenSearch Service 采用责任共担模式。您有责任确保集群的大小与自己的工作负载相符。带备用实例的多可用区使设置集群的思维模式变得简单。您应继续监控错误和延迟指标以及存储、CPU 和 RAM 利用率，以查看集群超载且可能需要扩展的信号。"
    },
    {
        "query":"Amazon OpenSearch Service SLA 可保证哪些内容？",
        "intention":"知识问答",
        "reply":"我们的 Amazon OpenSearch Service SLA 可保证 Amazon OpenSearch Service 的月度正常运行时间百分比至少达到 99.9%。"
    },
    {
        "query":"怎样确定我是否有资格获得 SLA 服务抵扣？",
        "intention":"知识问答",
        "reply":"如果 Amazon OpenSearch Service 上的多可用区域在任何每月计费周期中的月度正常运行时间百分比低于 99.9%，则按照 Amazon OpenSearch Service SLA，您符合 Amazon OpenSearch Service 的 SLA 抵扣资格。\n如需 SLA 的所有条款与条件的完整详细信息，以及如何提交索赔的详细信息，请参阅 [Amazon OpenSearch Service SLA 详细信息页面](https://aws.amazon.com/cn/elasticsearch-service/sla/)。"
    },
    {
        "query":"什么是跨集群搜索？",
        "intention":"知识问答",
        "reply":"跨集群搜索是 Elasticsearch 和 OpenSearch 的一项支持跨两个互联集群执行查询和聚合的功能。它的工作原理是在参与的集群之间建立一个轻量级单向连接。"
    },
    {
        "query":"对参与跨集群搜索的域有哪些最低要求？",
        "intention":"知识问答",
        "reply":"参与跨集群搜索的域需要满足以下条件："
    },
    {
        "query":"哪些实例类型支持跨集群搜索？",
        "intention":"知识问答",
        "reply":"目前以下实例类型支持跨集群搜索："
    },
    {
        "query":"哪些实例类型不支持跨集群搜索？",
        "intention":"知识问答",
        "reply":"由于技术限制，t2 和 m3 系列实例不支持跨集群搜索。"
    },
    {
        "query":"两个不同 AWS 账户中的域是否可以参与跨集群搜索？",
        "intention":"知识问答",
        "reply":"是的。参与的域可以属于两个不同的 AWS 账户。"
    },
    {
        "query":"两个不同 AWS 区域中的域是否可以参与跨集群搜索？",
        "intention":"知识问答",
        "reply":"不可以。"
    },
    {
        "query":"如何开始使用跨集群搜索？",
        "intention":"知识问答",
        "reply":"要开始使用跨集群搜索，请按照[此处](https://docs.aws.amazon.com/elasticsearch-service/latest/developerguide/cross-cluster-search.html)的文档执行操作"
    },
    {
        "query":"什么是跨集群复制？",
        "intention":"知识问答",
        "reply":"跨集群复制是一项新功能，它允许 Amazon OpenSearch Service 客户在相同或不同的 AWS 区域中以低延迟自动将索引从一个集群复制和同步到另一个集群。"
    },
    {
        "query":"对参与跨集群复制的域有哪些最低要求？",
        "intention":"知识问答",
        "reply":"参与跨集群复制的域需要满足以下条件："
    },
    {
        "query":"两个不同 AWS 区域中的域是否可以参与跨集群复制？",
        "intention":"知识问答",
        "reply":"可以。两个不同 AWS 区域中的域可以参与跨集群复制。"
    },
    {
        "query":"跨集群复制是否支持 Ultrawarm 和 Cold Storage?",
        "intention":"知识问答",
        "reply":"不支持。跨集群复制的当前实施不支持 Ultrawarm 或 Cold Storage。"
    },
    {
        "query":"为什么服务名称从 Amazon Elasticsearch Service 变更为 Amazon OpenSearch Service？",
        "intention":"知识问答",
        "reply":"我们于 2021 年 4 月 12 日发布了 OpenSearch 项目，这是由社区开发的 Elasticsearch 和 Kibana 开源分支。我们承诺长期投入 OpenSearch，以确保用户继续获得安全、高质量、完全开源的搜索和分析套件，并建立丰富的新功能和创新路线图。此项目包括 OpenSearch（源自 Elasticsearch 7.10.2）和 OpenSearch Dashboards（源自 Kibana 7.10.2）。我们于 2021 年 7 月 12 日发布了 OpenSearch 的1.0 版本。作为对 OpenSearch 的长期承诺的一部分，我们于 2021 年 9 月 7 日在托管服务中增加了对 OpenSearch 1.0 的支持，并将名称从 Amazon Elasticsearch Service 变更为 Amazon OpenSearch Service。除了 OpenSearch 1.0 之外，我们还继续支持在服务中使用 7.10 及之前版本的 Elasticsearch。除了名称变更之外，其他方面您都无需担心，我们将继续提供同样出色的体验，而不会对现有的操作、开发方法或业务使用产生任何影响。您可以从此处了解更多关于 OpenSearch 的信息：<https://opensearch.org/>。"
    },
    {
        "query":"作为客户，在此次名称变更中我是否必须采取任何行动？",
        "intention":"知识问答",
        "reply":"我们设法让此次名称变更尽可能无缝地融入您的体验。但有些方面，例如新的开发工具包/配置 API，会要求您采取一些措施以确保从服务中获得最大优势。虽然从兼容性角度来说现有的开发工具包可以继续使用，但是需要新配置 API 的任何新功能都将仅在新的开发工具包中实现。因此，我们建议您改用新开发工具包。此外，无论是否使用新开发工具包，我们都强烈建议您迁移现有 IAM 策略以使用重命名的配置 API。迄今为止，您的现有 IAM 策略都将继续适用于旧的 API 定义。但是，我们将逐渐过渡到基于新 API 的权限验证，最终我们将要求您在策略中使用新 API（尤其是对发生了名称变更的 API；例如，从 CreateElasticsearchDomain 变更为 CreateDomain）。请参阅文档以了解更多详细信息。"
    },
    {
        "query":"要升级到 OpenSearch 1.0，我必须要改用新的开发工具包吗？",
        "intention":"知识问答",
        "reply":"不。从向后兼容的角度来说，我们将确保现有的设置继续适用于 OpenSearch 1.0。但是，我们建议您最终改用最新的开发工具包，以获得上面所述的更清晰的最新体验。"
    },
    {
        "query":"在此次名称变更之后，定价是否发生任何变化？",
        "intention":"知识问答",
        "reply":"不，定价没有变化。\n*OpenSearch 包括某些来自 Elasticsearch B.V. 和其他源代码且经 Apache 许可的 Elasticsearch 代码。Elasticsearch B.V. 不是该其他源代码的来源。ELASTICSEARCH 是 Elasticsearch B.V. 的注册商标。*"
    },
    {
        "query":"我正在 Amazon OpenSearch Service 中使用 Elasticsearch 引擎。为什么我要升级到 OpenSearch 1.x 引擎？ 对我有何优势？",
        "intention":"知识问答",
        "reply":"升级到 OpenSearch 1.x 可以确保您的搜索基础设施建立在一个不断发展和变化的并且是 Apache 许可的开源项目上，并使您能够访问 OpenSearch 1.2（截至本文撰写之时）中提供的大量创新改进和功能。 企业级安全、警报、数据生命周期管理、可观察性、基于 ML 的异常检测等功能都是 OpenSearch Service 的一部分，无需额外的许可费。"
    },
    {
        "query":"如果升级，我会停机吗？",
        "intention":"知识问答",
        "reply":"我们在升级期间使用蓝/绿（BG）部署过程。在 BG 期间，该服务会向新配置和新版本的 OpenSearch Service 集群中添加节点，从旧节点迁移数据，并在数据迁移完成后删除旧节点。在 BG 期间，搜索和索引 API 依然可用，并且可以正常使用。虽然 BG 的设计不会干扰查询和索引请求，但某些更改（尤其是涉及安全相关设置的更改）可能会导致仪表板在更改期间不可用。"
    },
    {
        "query":"AWS 是否会弃用 Elasticsearch Service 的旧版本？",
        "intention":"知识问答",
        "reply":"AWS 维护了 19 个 Apache-2.0 许可的 Elasticsearch 版本。目前，这些版本均未弃用或计划弃用。"
    },
    {
        "query":"升级会触发 BG 吗？  如果不会，升级节点的过程是什么？",
        "intention":"知识问答",
        "reply":"是的，升级将触发 BG 部署过程。请在[此处](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/version-migration.html)查看升级准备和步骤。"
    },
    {
        "query":"我想转到 Amazon OpenSearch Service 1.x 来利用 AWS Graviton2 实例，但我被现有的预留实例所束缚。 这种情况下该怎么办？",
        "intention":"知识问答",
        "reply":"请与您的 AWS 客户团队合作，根据您 RI 的具体情况获取相关信息。"
    },
    {
        "query":"在开始升级到 Amazon OpenSearch Service 1.x 或更高版本之前，我应该做什么计划？",
        "intention":"知识问答",
        "reply":"OpenSearch 项目 1.0 是开源 Elasticsearch 7.10.2 的一个分支。其与 Elasticsearch 7.10 兼容，您无需更改使用方法。如需迁移，您可以将域从 6.x 和 7.x 系列中的任何早期版本升级到 Elasticsearch 7.10 版本，获取快照，并将该快照还原到运行 OpenSearch Service 1.x 的域。一些客户端或工具包含版本检查，可能导致客户端或工具无法与 OpenSearch Service 一起工作。[升级](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/rename.html#rename-upgrade)时，启用兼容性模式可以绕过这些版本检查。"
    },
    {
        "query":"我可以继续在 Amazon OpenSearch Service 1.x 中使用我现有的客户端、数据收集和数据摄取工具吗？",
        "intention":"知识问答",
        "reply":"在大多数情况下，您可以继续使用现有客户端。API 和核心搜索功能与 Elasticsearch 7.10.2 版本兼容。如果您的客户端版本较旧、客户端会执行版本检查，或者客户端要使用针对 Elasticsearch 较旧版本（如主版本 5 或 6）的功能，那么我们建议您尝试将您的客户端提高到 7.10.2 支持的最低标准，以确保平稳过渡。\nOpenSearch 项目支持广泛的客户端，专门为解决 Amazon OpenSearch Service 上引擎的 OpenSearch 版本而构建。根据[最新的 OpenSearch 客户端列表和这些客户端支持的编程语言](https://opensearch.org/docs/latest/clients/index/)检查您的客户端。\n您可以启用[兼容性模式](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/rename.html#rename-upgrade)与其他供应商的客户端进行互操作，但请记住检查 OpenSearch 报告的版本。启用此设置可确保服务使用 7.10.2 版本响应在引入 OpenSearch Service 引擎之前开发的客户端。"
    },
    {
        "query":"我正在运行 Elasticsearch 5.x 或更早版本。我最好的升级途径是什么？",
        "intention":"知识问答",
        "reply":"Elasticsearch 5.x 索引与 Elasticsearch 7.10 或 OpenSearch 1.x 不兼容。您必须创建一个新索引并从源加载数据。如果您正在运行日志分析工作负载，则可以在新域上构建完整数据集时，评估数据留存策略是否支持并行运行。"
    },
    {
        "query":"有没有合作伙伴可以帮我升级？",
        "intention":"知识问答",
        "reply":"是的，请联系 [opensearchmigration-si-support@amazon.com](mailto:opensearchmigration-si-support@amazon.com)，根据您所在地区、行业和项目的复杂性，请求合作伙伴列表。[AWS 合作伙伴网络（APN）合作伙伴](https://aws.amazon.com/cn/partners/work-with-partners/)经过培训，具有丰富的经验帮助您升级。"
    },
    {
        "query":"Amazon OpenSearch Service 将来仍会与 Elasticsearch 兼容吗？ 未来的计划是什么？",
        "intention":"知识问答",
        "reply":"OpenSearch 1.0 是 Elasticsearch 7.10.2 的一个分支。OpenSearch 和 Elasticsearch 兼容。如果启用兼容模式，Elasticsearch 客户端还可以与 OpenSearch 1.0 兼容。\nAmazon OpenSearch Service 没有也不会提供 7.10.2 版之后的 Elasticsearch 引擎版本。\n正如 [AWS 在推出 Elasticsearch 时宣布的](https://aws.amazon.com/cn/blogs/opensource/introducing-opensearch/)，我们计划围绕 OpenSearch 建立一个蓬勃发展的社区。我们已经发布了 [OpenSearch 的路线图](https://github.com/orgs/opensearch-project/projects/1)，包括社区意见和对功能优先级的共识。我们将尽一切合理努力保持与 Elasticsearch 的兼容性。我们的目标是与我们的社区和 Amazon OpenSearch Service 客户一起成长。\n您可以直接从 Elasticsearch 和 Kibana 版本 6.8.0 至 7.10.2，以及 open distro for Elasticsearch（ODFE）1.x 升级到 OpenSearch Service 1.0。对于从 ODFE 到 OpenSearch 的滚动升级，我们建议首先升级到 ODFE 1.13，然后升级到 OpenSearch 1.0。\n迁移资源如下：  \n [分析迁移](https://aws.amazon.com/cn/big-data/datalakes-and-analytics/migrations/)  \n [迁移至 Amazon OpenSearch Service](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/migration.html)\n了解有关 Amazon OpenSearch Service 定价的更多信息"
    },
    {
        "query":"How does License Manager work?",
        "intention":"知识问答",
        "reply":"A: License Manager provides you with the flexibility and control to manage license usage to match your organizational structure and processes. License Manager can be set in different configurations to address specific business needs. Here are three steps to get started with License Manager:"
    },
    {
        "query":"What types of software licenses can I track using License Manager?",
        "intention":"知识问答",
        "reply":"A: With License Manager, you can track software that is licensed based on virtual cores (vCPUs), physical cores, sockets, or number of instances. This includes a variety of software products from vendors including Microsoft, Oracle, IBM, and SAP. Common use cases include tracking Oracle databases, Microsoft Windows Servers, and SQL Server licenses that can be licensed by physical and virtual cores."
    },
    {
        "query":"Which AWS services are supported through License Manager?",
        "intention":"知识问答",
        "reply":"A: AWS License Manager supports Amazon, [Amazon Relational Database Service (RDS)](https://aws.amazon.com/rds/), [AWS Marketplace](https://aws.amazon.com/marketplace), and Systems Manager (includes support for on-premises environments and AWS Cloud). You can use License Manager to track licenses across your EC2 instances using default tenancy, Dedicated Instances, Dedicated Hosts, Spot Instances, Spot Fleet, and Auto Scaling groups."
    },
    {
        "query":"Does License Manager support tracking license usage on Amazon Relational Database Service (RDS)?",
        "intention":"知识问答",
        "reply":"A: You can configure License Manager to help you automatically track licenses of Oracle database engine editions, options, and packs as you grow your database footprint on RDS."
    },
    {
        "query":"Does License Manager support tracking license usage outside of AWS?",
        "intention":"知识问答",
        "reply":"A: Yes. You can use License Manager along with AWS Systems Manager Agent to track licenses outside of AWS, including licenses for on-premises servers."
    },
    {
        "query":"How does License Manager work with Organizations?",
        "intention":"知识问答",
        "reply":"A: License Manager integrates with AWS Organizations seamlessly. Administrators can sign in to their organizational management account and link all their organizational accounts. They can manage and control license usage centrally using the management account."
    },
    {
        "query":"How can I use the benefits of License Manager with bring your own license (BYOL) products purchased from AWS Marketplace?",
        "intention":"知识问答",
        "reply":"A: License Manager helps you associate licensing rules to AWS Marketplace BYOL AMI products and benefit from centralized license management tracking and compliance. License Manager doesn’t change the way you obtain or activate your BYOL AMIs in AWS Marketplace. For example, if you launch an EC2 instance, you provide the license key obtained directly from the seller to activate the software.\nQ: How does License Manager help me stay compliant?\nA: License Manager reduces the risk of non-compliance by increasing transparency and enforcing and tracking licensing rules that administrators define. License Manager provides built-in dashboards that can be used when considering new license purchases, reporting to procurement, and in vendor audits. However, customers are responsible for compliance and assume the responsibility of carefully understanding and adding rules into License Manager based on their licensing agreements. While AWS cannot participate in audits, License Manager’s rich report provides valuable insights that help attain more accuracy and transparency."
    },
    {
        "query":"As an administrator, how do I use License Manager managed entitlements with purchases in AWS Marketplace?",
        "intention":"知识问答",
        "reply":"A: When you purchase software licenses in AWS Marketplace, you can track them in License Manager managed entitlements. You can distribute different tiers of licenses to different groups of users (for example, business units) you create in the software, whenever tiered licenses are available from supported vendors."
    },
    {
        "query":"As an administrator, can I use managed entitlements with other AWS services?",
        "intention":"知识问答",
        "reply":"A: Yes, you can use managed entitlements with other AWS services such as AWS Service Catalog to simplify deployments and governance of licensed software. This also applies to third-party software licenses purchased in AWS Marketplace, which are automatically created in License Manager. You can use managed entitlements with Identity and Access Management (IAM) or with AWS accounts to control which workloads and users can use those licenses."
    },
    {
        "query":"As an administrator, can I use managed entitlements to manage software licenses on AWS and on-premises deployments?",
        "intention":"知识问答",
        "reply":"A: When you purchase licenses from participating independent software vendors (ISVs) in AWS Marketplace, you can extend license management across both AWS Cloud accounts and on-premises environments. You can pay for software licenses through AWS Marketplace, and then manage distribution and track entitlements using managed entitlements."
    },
    {
        "query":"As an administrator, can I track and govern license use across my AWS Organization?",
        "intention":"知识问答",
        "reply":"A: Yes, you can turn on the AWS Organizations integration in License Manager. Using the management account, you can now view all licenses distributed to identities in your AWS Organization across all AWS Regions. You can see detailed information about each license, including the expiration date and software capabilities. You also get metrics showing how much of the license is consumed by each identity."
    },
    {
        "query":"As a software vendor, how do I onboard directly to License Manager for licenses sold outside of AWS Marketplace?",
        "intention":"知识问答",
        "reply":"A: You can onboard directly through License Manager by creating a public and private key pair through the console or application programming interface (API). License information returned by the API operations is signed with your private key and you can use the public key to verify the signature. Using AWS License Manager’s API operations, you can integrate with your sales order system to create licenses for customers after their purchase and update licenses after renewals. You can also use the API operations to migrate existing licenses from your current system to AWS License Manager. You will need to modify your software to call the API operations to verify a customer’s license before provisioning software capabilities. To simplify integration with the APIs, use the API operations, use AWS SDK."
    },
    {
        "query":"As a software vendor, can I enforce that customers are using licenses in compliance with my terms?",
        "intention":"知识问答",
        "reply":"A: Yes. License Manager helps you enforce license use by tracking the number of software capabilities customers are using against the amount they are entitled. License Manager tracks usage across all of the customer identities with access to the licenses. When customers stop using your software, they can return the licenses back to the pool and make them available for reuse through the API operations or let the licenses expire automatically."
    },
    {
        "query":"As a software vendor, how do I use License Manager managed entitlements for software a service (SaaS) software?",
        "intention":"知识问答",
        "reply":"A: You can use License Manager to assign licenses to users. For example, a customer might want to give a license with more capabilities to power users, and a different license to the average user. You can enable this by mapping your users to  IAM roles with Amazon Cognito, and then using License Manager to distribute the licenses to those users by specifying their associated IAM roles."
    },
    {
        "query":"As a software vendor, how do I use License Manager on-premises without using AWS Identity?",
        "intention":"知识问答",
        "reply":"A: Customers do not have to use AWS Identity with their on-premises applications. You can use License Manager to create a unique short lived token to identify the customer to whom you are giving a license. Next, share this token with the customer. When they launch your software, the customer enters the token to activate the license. Your software should pass the short lived token to the API operations and exchange it for a long lived customer identifier that you use in API calls. For on-premises workloads that do not have an internet connection, you can generate a license file unique to the host that customers can use to run your software on that host."
    },
    {
        "query":"How do I get started with automated discovery?",
        "intention":"知识问答",
        "reply":"A: You can get started with automated discovery by specifying the product information along with licensing rules in License Manager. Product information might include the name of the software, the publisher, and the version, which tells License Manager how to detect installed software."
    },
    {
        "query":"How do I set up tags, and search using these tags?",
        "intention":"知识问答",
        "reply":"A: Consider having an organization-wide tagging strategy that can help you organize your resources, allocate cost, automate processes, control access, and manage security risk. If you are new to tagging, review AWS recommended [tagging best practices](https://aws.amazon.com/answers/account-management/aws-tagging-strategies/) to learn how to set up and search using tags."
    },
    {
        "query":"Can I search license Included instances as well?",
        "intention":"知识问答",
        "reply":"A: Yes, you can search instances running AWS license Included software."
    },
    {
        "query":"Can I combine a tag-based search with other search filters?",
        "intention":"知识问答",
        "reply":"A: Yes, you can combine a tag-based search with other search filters that License Manager supports. Other search filters include names of operating systems and applications, whether they are license Included or not, or AWS account IDs, and resource IDs."
    },
    {
        "query":"How does automated discovery help you track uninstalled software?",
        "intention":"知识问答",
        "reply":"A: Automated discovery helps you track all instances as you install software. If software is specified in automated discovery rules, the instances will automatically get tracked by License Manager. Once you uninstall software,  License Manager will automatically stop tracking those instances and make the licenses available to you for reuse."
    },
    {
        "query":"Do I need to opt in to use the automated accounting feature?",
        "intention":"知识问答",
        "reply":"A: Yes, you need to opt in. You can opt in by specifying a simple setting in automated discovery thatwill ask License Manager to stop tracking an instance when applications are uninstalled. See the [documentation](https://docs.aws.amazon.com/license-manager/latest/userguide/license-manager.html)."
    },
    {
        "query":"If I install the software again, what happens?",
        "intention":"知识问答",
        "reply":"A: If you install the software again, License Manager’s automated discovery capability will detect it and account for the license usage again."
    },
    {
        "query":"What if my vendor agreement says that the licenses are node-locked and that I need to consider them as consumed even if I uninstall?",
        "intention":"知识问答",
        "reply":"A: If your licenses are node-locked to a physical server, you can use License Manager’s license affinity property where you can specify the time period for which your licenses need to be node-locked. License Manager will continue to account for the usage until the license affinity period has elapsed, even if you uninstall your software.\nHere are steps to get started. For more information on the prerequisites, see our  \n documentation."
    },
    {
        "query":"How do user-based license subscriptions work?",
        "intention":"知识问答",
        "reply":"AWS will bill you through a monthly subscription, based on the number of users associated with the license included Microsoft Office or Visual Studio instances. These per-user charges are billed per calendar month, and the billing starts from the time you subscribe to the product. If you remove access to a user during the existing month, you will be billed for the user for the remainder of the month. You will stop incurring charges for the user the following month."
    },
    {
        "query":"If the same user connects to different EC2 instances, does it count as multiple users?",
        "intention":"知识问答",
        "reply":"No, a user is only counted once. You get charged per user for Microsoft Office and Visual Studio, irrespective of the number of EC2 instances the user connects. However, Windows Server licenses are bundled with the EC2 instances and are charged per vCPU along with the instance charges."
    },
    {
        "query":"Which instances support license included Microsoft Office and Visual Studio on EC2?",
        "intention":"知识问答",
        "reply":"All EC2 instances that are Nitro based support license included Microsoft Office and Visual Studio."
    },
    {
        "query":"Are there additional charges attached with using AWS License Manager?",
        "intention":"知识问答",
        "reply":"A: There is no charge for using License Manager. You pay for only the resources created in your account. These include Amazon Elastic Compute Cloud (EC2) instances but can also include an Amazon Simple Storage Service (S3) bucket for storing software based on AWS Systems Manager. It can also include Amazon Athena queries, and AWS Glue jobs for enabling the centralized discovery of the Systems Manager data, and Amazon Simple Notification Service (SNS) notifications."
    },
    {
        "query":"什么是 Amazon Personalize？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 是一项完全托管的机器学习（ML）服务，使用您的数据为您的用户生成产品和内容推荐。您提供有关最终用户（例如，年龄、位置、设备类型）、目录中的商品（例如类型、价格）以及用户与商品之间的交互（例如点击、购买）的数据。Personalize 使用这些数据来训练自定义的专用模型，从而生成可通过 API 显示的推荐。\n该服务使用算法来分析客户行为并推荐他们可能感兴趣的产品、内容和服务。这种增强的客户体验方法可以提高客户参与度、忠诚度和销售额，从而增加收入和盈利能力。Personalize 由 [Amazon.com](http://amazon.com/) 使用的 ML 技术提供支持，允许任何开发人员轻松地向现有应用程序、网站、推送通知、营销通信等添加个性化设置，所有这些都无需任何 ML 经验。Personalize 使用实时数据洞察，根据用户行为即时提供个性化推荐。您可以使用针对您的业务领域进行应用场景优化的推荐器快速上手，也可以创建自己的可配置自定义资源。"
    },
    {
        "query":"使用 Amazon Personalize 有哪些好处？",
        "intention":"知识问答",
        "reply":"以下是企业选择使用 Amazon Personalize 进行个性化的一些原因："
    },
    {
        "query":"各公司如何使用 Amazon Personalize？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 可用于通过任何数字渠道实现最终用户体验个性化。示例包括，电子商务的产品推荐、出版物、媒体和社交网络、旅游网站的酒店推荐、银行的信用卡推荐以及约会网站的配对推荐。Amazon Personalize 还可用于在通过物理渠道进行用户交互时自定义用户体验，例如送餐公司可以在订阅计划中个性化每周用餐。其他应用场景示例包括以下内容。查看我们的[客户参考案例](https://aws.amazon.com/personalize/customers/)，了解真实的客户成功案例。"
    },
    {
        "query":"如何快速试用 Amazon Personalize？",
        "intention":"知识问答",
        "reply":"来看看 Magic Movie Machine，这是一款简短的交互游戏，您将在这款游戏中寻找符合您个人兴趣的电影推荐。亲自了解 Amazon Personalize 如何了解您的喜好，然后实时调整给您的推荐。[立即演示。](https://dohy8sp8i3s5p.cloudfront.net/)"
    },
    {
        "query":"Amazon Personalize 是如何运作的？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 有一个简单的三步流程，只需在 AWS 管理控制台中点击几下，或者进行一组简单的 API 调用。首先，将 Amazon Personalize 指向 Amazon S3 中的用户交互数据（浏览量、点击次数、购买等的历史日志），使用简单的 API 调用上传数据，或者使用 SageMaker Data Wrangler 准备和导入数据。或者，您可以提供商品或用户数据集，其中包含有关您的目录和客户群的更多信息。其次，只需在控制台中点击几下或进行一次 API 调用，即可为您的数据训练一个自定义的私人推荐模型。第三，检索个性化推荐。[观看此 Amazon Personalize 深入探究视频系列，了解更多信息。](https://www.youtube.com/watch?v=3gJmhoLaLIo&t=1s)"
    },
    {
        "query":"如何开始使用 Amazon Personalize？",
        "intention":"知识问答",
        "reply":"首先创建一个账户，然后访问 Amazon Personalize 开发人员控制台，该控制台将引导您完成一个直观的设置向导。您可以选择使用 JavaScript API 和 Server-Side SDK 将实时活动流数据发送到 Amazon Personalize 或使用用户事件的历史日志引导启动服务。您也可以通过 Amazon Simple Storage Service（S3）或使用 SageMaker Data Wrangler 导入数据。然后，只需进行几次 API 调用即可训练一个个性化模型，让服务通过 AutoML 选择适用于您的数据集的算法，或者手动从多个可用的算法选项中选择一个。一经训练，即可利用单个 API 调用部署模型，然后再供生产应用程序使用。部署完成后，从您的生产服务中调用服务以获得实时推荐，Amazon Personalize 将根据需求自动进行扩展。"
    },
    {
        "query":"我需要向 Amazon Personalize 提供哪些数据？",
        "intention":"知识问答",
        "reply":"用户应向 Amazon Personalize 提供以下数据：\nAmazon Personalize 将基于这些数据训练和部署一个模型。然后，您可以使用一个简单的推理 API 在运行时获得个性化推荐，并根据个性化模型的类型生成最终用户的个性化体验（例如用户个性化、相关商品或个性化重新排名）。\n以下数据可以帮助提高您的推荐相关性，强烈建议包括以下数据：\n有关 Amazon Personalize 可以使用的数据类型的更多信息，请参阅[可以导入到 Amazon Personalize 的数据类型](https://docs.aws.amazon.com/personalize/latest/dg/data.html)。"
    },
    {
        "query":"如何使用 SageMaker DataWrangler 导入我的数据？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 让您可以通过 [Amazon SageMaker Data Wrangler](https://aws.amazon.com/sagemaker/data-wrangler) 轻松导入和准备数据，然后在 Amazon Personalize 中使用数据。通过 SageMaker Data Wrangler，您可以从 40 多个支持的数据来源导入数据，并在单个用户界面中执行端到端的数据准备（包括大规模的数据选择、清理、探索、可视化和处理），这个过程几乎不需要代码。这使您可以利用 Amazon SageMaker Data Wrangler 快速准备用户、商品或交互数据集，方法是利用特定于 Amazon Personalize 的转换和 300 多种常规内置数据转换，检索数据见解，并通过修复数据问题进行快速迭代。只需访问 [Amazon Personalize 控制台](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fpersonalize%2Fhome%3FhashArgs%3D%2523%26isauthcode%3Dtrue%26state%3DhashArgsFromTB_us-east-2_b24b204e230ef3ef&client_id=arn%3Aaws%3Asignin%3A%3A%3Aconsole%2Fconcierge&forceMobileApp=0&code_challenge=xkRQIOf8skojLGzTpH-5jqdVvyFUxtohMB6aG1ntoPQ&code_challenge_method=SHA-256)，从您的数据集组中打开数据集，选择“导入并准备数据”，然后选择“使用 Data Wrangler 准备数据”即可。 请注意，使用 Amazon SageMaker Data Wrangler 的客户将根据其使用情况产生额外费用。查看其定价页面。"
    },
    {
        "query":"我可以在推荐中显示没有交互的商品吗？",
        "intention":"知识问答",
        "reply":"可以。Amazon Personalize 允许您指定“新商品探索权重”，从而帮助您的用户发现新产品和商品。 然后，Amazon Personalize 将使用此输入自动在向用户展示新内容和提供最相关的推荐之间取得适当的平衡。Amazon Personalize 还会考虑用户接触过但选择不与之交互的商品的相关数据。"
    },
    {
        "query":"如何为 Amazon Personalize 优化我的数据？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 可对您的数据进行分析，让您轻松上手。它可以分析您提供的数据，并提供建议以帮助您改进数据准备工作。个性化系统的性能取决于为模型提供有关用户及其与目录中商品交互的高质量数据。通过发现潜在的数据缺陷并提供建议来帮助客户进行补救，Amazon Personalize 使训练性能模型变得更加轻松，并减少了执行故障排除的需求。"
    },
    {
        "query":"如何将 Amazon Personalize 推荐应用/导出到我的商业工作流或应用程序？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 向客户提供了两个推理 API：getRecommendations 和 getPersonalizedRanking。这些 API 会返回一个用户的推荐 itemID 列表、一个商品的类似商品列表或一个用户的重新排名的列表。该 itemID 可以是产品标识符、videoID 等。然后，您需要通过一系列步骤（例如获取图片和描述，然后渲染显示内容）使用这些 itemID 生成最终用户体验。在某些情况下，您可能会与 AWS 服务、第三方电子邮件传送服务或通知服务等集成以生成所需的最终用户体验。"
    },
    {
        "query":"我应该如何将 Amazon Personalize 与现有的应用程序集成？",
        "intention":"知识问答",
        "reply":"查看[个性化 API](https://github.com/aws-samples/personalization-apis) 解决方案，该解决方案解释了位于您的应用程序和推荐系统（例如 Amazon Personalize）之间的实时低延迟 API 框架。该解决方案还提供响应缓存、API 网关配置、使用 [Amazon CloudWatch Evidently](https://docs.aws.amazon.com/cloudwatchevidently/latest/APIReference/Welcome.html) 进行的 A/B 测试、推理时间商品元数据、自动上下文推荐等的最佳实践实施。"
    },
    {
        "query":"我怎么知道 Amazon Personalize 是否提供了好的推荐？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 中的一些内置功能可用作检查点，帮助您确保针对高质量的推荐进行优化。"
    },
    {
        "query":"Amazon Personalize 能否帮助我衡量推荐的影响？",
        "intention":"知识问答",
        "reply":"您可以通过向系统发送的任何事件来衡量任何 Amazon Personalize 推荐的业务成果。然后，您可以可视化并评估一项或多项推荐的影响，以制定更加以数据为导向的个性化策略。从 Amazon Personalize 控制台或 API，定义“指标属性”，即您想要评估和报告的交互（即事件类型）列表。例如，您可能需要跟踪两个指标：推荐内容的点击率（CTR）和总购买量。对于每个事件类型，您只需定义要评估的指标和函数（总和或计数），Amazon Personalize 将执行计算并将报告发送到 CloudWatch 或 S3 账户。"
    },
    {
        "query":"我的数据是否安全且私密？",
        "intention":"知识问答",
        "reply":"所有 Amazon Personalize 模型都是客户的数据集所独有的，不会在其他 AWS 账户之间或与 Amazon Retail、Amazon Prime 或任何其他业务部门共享。我们不会使用您的任何数据为其他客户训练或创建模型，客户的模型输入和输出完全由其账户拥有。客户与 Amazon Personalize 的每次交互都将受到加密保护。Amazon Personalize 处理的任何用户、商品或交互数据都将通过 AWS Key Management Service 使用客户密钥进一步加密，而且是在客户当前使用该服务的 AWS 区域中进行静态和传输中加密。管理员还可以通过 [AWS Identity and Access Management](https://aws.amazon.com/iam/)（IAM）权限策略来控制对 Amazon Personalize 的访问，确保敏感信息的安全性和保密性。"
    },
    {
        "query":"Amazon Personalize 的主要特点和功能是什么？",
        "intention":"知识问答",
        "reply":"Amazon Personalize 根据客户反馈和长期路线图目标不断改进，同时，我们也在努力进行优化，使其易于上手和使用。这里列出了一些超越基本机器学习实践的有影响力的 Amazon Personalize 功能。有关功能的完整列表，请查看我们的[功能页面](https://aws.amazon.com/personalize/features/)。"
    },
    {
        "query":"如何优化我的 Amazon Personalize 成本？",
        "intention":"知识问答",
        "reply":"使用 Amazon Personalize 时，您只需按使用量付费；既没有最低费用，也无需预先承诺。以下是有关如何管理成本的一些技巧。"
    },
    {
        "query":"What application developer languages are supported in AWS AppSync?",
        "intention":"知识问答",
        "reply":"AWS AppSync SDKs support iOS, Android, and JavaScript. The JavaScript support spans web frameworks such as React and Angular as well as technologies such as React Native and Ionic. You can also use open source clients to connect to the AppSync GraphQL endpoint for using other platform such as generic HTTP libraries or even a simple CURL command."
    },
    {
        "query":"What is GraphQL ?",
        "intention":"知识问答",
        "reply":"GraphQL is a data language to enable client apps to fetch, change and subscribe to data from servers. In a GraphQL query, the client specifies how the data is to be structured when it is returned by the server. This makes it possible for the client to query only for the data it needs, in the format that it needs it in."
    },
    {
        "query":"What is a GraphQL Schema?",
        "intention":"知识问答",
        "reply":"A GraphQL schema is a definition of what data capabilities are available for the client application to operate on. For example, a schema might say what queries are available or how an app can subscribe to data without needing to know about the underlying data source. Schemas are defined by a type system, which an application's data model can leverage."
    },
    {
        "query":"Do I need to know GraphQL to get started?",
        "intention":"知识问答",
        "reply":"No, AWS AppSync can automatically setup your entire API, schema, and connect data sources with a simple UI builder that allows you to type in your data model in seconds. You can then immediately begin using the endpoint in a client application. The console also provides many sample schema and data sources for fully functioning applications."
    },
    {
        "query":"Can I use AWS AppSync with my existing AWS resources?",
        "intention":"知识问答",
        "reply":"Yes. With AWS AppSync you can use existing tables, functions, and domains from Amazon DynamoDB, AWS Lambda and Amazon OpenSearch Service with a GraphQL schema. AWS AppSync allows you to create data sources using existing AWS resources and configure the interactions using Mapping Templates."
    },
    {
        "query":"How is data secured with AWS AppSync?",
        "intention":"知识问答",
        "reply":"Application data is stored at rest in your AWS account and not in the AWS AppSync service. You can protect access to this data from applications by using security controls with AWS AppSync including AWS Identity and Access Management (IAM), as well as Amazon Cognito User Pools. Additionally, user context can be passed through for authenticated requests so that you can perform fine-grained access control logic against your resources with Mapping Templates in AWS AppSync."
    },
    {
        "query":"Can I make my data real-time with AWS AppSync?",
        "intention":"知识问答",
        "reply":"Yes. Subscriptions are supported with AWS AppSync against any of the data sources, so that when a mutation occurs, the results can be passed down to clients subscribing to the event stream immediately using over WebSockets."
    },
    {
        "query":"What AWS Regions are available for AWS AppSync?",
        "intention":"知识问答",
        "reply":"AWS AppSync is available in different regions around the globe, please refer to the [AWS Regions table](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/) for more details."
    },
    {
        "query":"Can I import existing Amazon DynamoDB tables?",
        "intention":"知识问答",
        "reply":"AWS AppSync can automatically generate a GraphQL schema from an existing DynamoDB table, including the inference of your table’s key schema and indexes. Once the import is complete GraphQL queries, mutations, and subscriptions can be used with zero coding. AppSync will also “auto-map” non-key attributes from your GraphQL types to DynamoDB attributes."
    },
    {
        "query":"Can AWS AppSync create a database for me?",
        "intention":"知识问答",
        "reply":"Customers can create a GraphQL schema, either by hand or using the console, and AWS AppSync can automatically provision Amazon DynamoDB tables and appropriate indexes for you. Additionally, it will connect the data sources to \"GraphQL resolvers\" allowing you to just focus on your application code and data structures."
    },
    {
        "query":"What clients can I use to connect my application to my AppSync API?",
        "intention":"知识问答",
        "reply":"You can use any HTTP or GraphQL client to connect to a GraphQL API on AppSync. We do recommend using the [Amplify](https://aws-amplify.github.io/) clients which are optimized to connect to the AppSync backend. There are some options depending on your application's use case:"
    },
    {
        "query":"Can I use my own domain name to access my AppSync GraphQL endpoint?",
        "intention":"知识问答",
        "reply":"AWS AppSync enables customers to use custom domain names with their AWS AppSync API to access their GraphQl endpoint and real-time endpoint. To create a custom domain name in AppSync, you simply provide a domain name you own and indicate a valid AWS Certificate Manager (ACM) certificate that covers your domain. Once the custom domain name is created, you can associate the domain name with any available AppSync API in your account. After you have updated your DNS record to map to to the AppSync-provided domain name, you can configure your applications to use the new GraphQL and real-time endpoints. You can change the API association on your custom domain at any time without having to update your applications. When AppSync receives a request on the custom domain endpoint, it routes it to the associated API for handling."
    },
    {
        "query":"Can I create private APIs with AppSync?",
        "intention":"知识问答",
        "reply":"Yes, AWS AppSync supports private APIs. With private APIs, you can create GraphQL APIs that can only be accessed from your Amazon Virtual Private Cloud (VPC)."
    },
    {
        "query":"What are resolvers?",
        "intention":"知识问答",
        "reply":"AWS AppSync lets you respond to GraphQL requests by performing operations on your data sources. For each GraphQL field you wish to run a query, mutation, or subscription on, a resolver must be attached. Each resolver is configured with one or more functions that communicate with data sources. You can write your resolvers directly in JavaScript or bundle your TypeScript code.\nLearn more about AWS AppSync Customers"
    },
    {
        "query":"为何我应该使用 AWS Proton？",
        "intention":"知识问答",
        "reply":"AWS Proton 让平台团队能够连接和协调您的开发团队在基础设施预置、代码部署、监控和更新方面所需的所有不同工具。由于基础设施就位于您的账户中，因此您拥有按需进行管理、更新和故障排除的完整能力。这为您提供了完整的灵活性，可以按照您选择的方式运行基础设施。开发人员可以使用 AWS Proton 自助服务界面，以最低配置部署其应用程序。"
    },
    {
        "query":"平台团队在 AWS Proton 中能做什么？",
        "intention":"知识问答",
        "reply":"AWS Proton 使平台团队能够定义其基础设施和部署工具，同时为开发人员提供获得基础设施和部署代码的自助服务体验。通过 AWS Proton，平台团队可预置共享资源并定义应用程序堆栈，包括持续集成/持续交付 (CI/CD) 管道和可观测性工具。随即您可以进行管理，指定哪些基础设施和部署功能能够为开发人员所用。Proton 在持续基础上提供了对您的基础设施的可见性和进行集中更改的能力。"
    },
    {
        "query":"应用程序开发人员能够在 AWS Proton 中做什么？",
        "intention":"知识问答",
        "reply":"对于使用 Proton 的企业，应用程序开发人员可以从基础设施模板中进行自助服务，为他们的应用程序代码预调配所需的基础设施。通过 AWS Proton，应用程序开发人员可以选择满足其需求的服务模板，并且可以通过支持的 CI/CD 管道轻松出发部署，而不必编写基础设施即代码模板。使用 Proton 组件，应用程序开发人员还可以自定义模板以满足特定的应用程序需求。"
    },
    {
        "query":"AWS Proton 能够管理什么类型的架构要素？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Proton 来管理和协调任何可以使用现有的基础设施即代码工具（包括 AWS CloudFormation、Terraform 和 AWS Cloud 开发套件）预调配和描述的任何要素。"
    },
    {
        "query":"AWS Proton 与 CloudFormation 或 Service Catalog 之类的其他工具有何差别？",
        "intention":"知识问答",
        "reply":"AWS Proton 是适用于现代应用程序的一项部署工作流工具。它可用于管理使用 CloudFormation 或 Terraform 之类的工具构建的基础设施即代码（IaC）模板。相比之下，Service Catalog 是一个 AWS 资源目录，它允许客户存储、共享和管理基础设施即代码模板，并针对特定的构建块（如 S3 存储桶产品）等创建单个堆栈。有些 AWS 客户已经使用 AWS Proton 管理包括 Service Catalog 产品组件的架构。\n问：哪些 AWS 区域提供 Proton？\n以下 AWS 区域支持 AWS Proton，客户可以在这些区域中运行的账户中创建 Proton 资源。目前，客户无法使用一个区域中的模板将基础设施部署到另一个不同的区域：\n|  |  |\n| --- | --- |\n| 美国东部（俄亥俄州） | us-east-2 |\n| 美国东部（弗吉尼亚北部） | us-east-1 |\n| 美国西部（俄勒冈州） | us-west-2 |\n| 加拿大（中部） | ca-central-1 |\n| 欧洲（法兰克福） | eu-central-1 |\n| 欧洲（爱尔兰） | eu-west-1 |\n| 欧洲（伦敦） | eu-west-2 |\n| 亚太地区（悉尼） | ap-southeast-2 |\n| 亚太地区（东京） | ap-northeast-1 |\n| 亚太地区（首尔） | ap-northeast-2 |\n| 亚太地区（新加坡） | ap-southeast-1 |\n美国东部（俄亥俄州）\nus-east-2\n美国东部（弗吉尼亚北部）\nus-east-1\n美国西部（俄勒冈州）\nus-west-2\n加拿大（中部）\nca-central-1\n欧洲（法兰克福）\neu-central-1\n欧洲（爱尔兰）\neu-west-1\n欧洲（伦敦）\neu-west-2\n亚太地区（悉尼）\nap-southeast-2\n亚太地区（东京）\nap-northeast-1\n亚太地区（首尔）\nap-northeast-2\n亚太地区（新加坡）\nap-southeast-1"
    },
    {
        "query":"如何开始使用 AWS Proton？",
        "intention":"知识问答",
        "reply":"首先，[登录您的 AWS 账户](https://console.aws.amazon.com/proton/home)。要开始定义您的基础设施，请前往 AWS Proton 控制台，了解上传基础设施即代码模板的过程，并注册一个应用程序堆栈。这包括环境模板（共享资源）和服务模板（特定于给定应用程序的资源）。通常，平台工程师将管理环境和服务模板的创建，然后触发环境部署。他们还可以使用“自带环境”功能将现有环境加载到 Proton 中。然后，开发人员可以使用服务模板部署基础设施。他们可以从列表中选择应用程序堆栈，输入所需的参数，然后部署。"
    },
    {
        "query":"AWS Proton 如何帮助我保持基础设施为最新？",
        "intention":"知识问答",
        "reply":"平台团队使用 AWS Proton 来创建一个“堆栈”，作为可重用的版本控制模板呈现给开发人员。这些堆栈是使用基础设施即代码、以简单的声明式风格来定义的，其中包括预置、部署和管理服务所需的一切，包括计算、网络、代码管道、安全性和监控。AWS Proton 帮助平台团队在模板更新时更容易地确定和更新过期的基础架构。"
    },
    {
        "query":"我如何定义和预置应用程序模板？",
        "intention":"知识问答",
        "reply":"AWS Proton 包括了[一组开源模板](https://github.com/aws-samples/aws-proton-sample-templates)，您可以使用这些模板作为起点，通过基础设施即代码工具来定义您的架构。您还可以通过以下方式开始使用：采用现有的基础设施即代码文件，然后对其进行更新以定义 AWS Proton 将在预调配资源时与输入值结合的输入参数。当您定义了新的模板时，您可将其保存在 Amazon Simple Storage Service（Amazon S3）存储桶中并在 AWS Proton 中注册。AWS Proton 从存储桶中读取模板并将其注册到控制台中，您可以在控制台中测试存储桶，将其发布给开发人员，并根据需要对其进行更新。\n开发人员能够在 AWS Proton 中做什么？\n开发人员可以将 AWS Proton 作为自助式界面来预置基础设施并部署其项目，而无需与底层资源进行交互。AWS Proton 为您的应用程序提供一般状态的可见性，包括正在使用的堆栈和堆栈运行状况。您可以访问每一个应用程序堆栈的 CI/CD 管道、可观测性工具和源代码控制。"
    },
    {
        "query":"如何开始使用 AWS Proton？",
        "intention":"知识问答",
        "reply":"登录 [AWS Proton 控制台](https://console.aws.amazon.com/proton/home)，查看您的平台团队提供哪些应用程序模板。输入您的服务配置参数，AWS Proton 就会使用由您的平台团队定义的共享资源为您预置基础设施。有关更多信息，请访问 AWS Proton [入门](https://aws.amazon.com/cn/proton/getting-started/)页面。"
    },
    {
        "query":"什么是 AWS Glue？",
        "intention":"知识问答",
        "reply":"AWS Glue 是一项无服务器数据集成服务，它简化了发现、准备和合并数据以进行分析、机器学习和应用程序开发的工作。 AWS Glue 提供数据集成所需的全部功能，使您只需几分钟时间便可以开始分析数据并将数据投入使用，而不用耗时几个月。AWS Glue 为您提供可视化界面和基于代码的界面来简化数据集成。用户使用 AWS Glue 数据目录可以轻松找到并访问数据。数据工程师和 ETL（即提取、转换和加载）开发人员只需在 AWS Glue Studio 中点击几次，便能够以可视化的方式创建、运行和监控 ETL 工作流程。数据分析师和数据科学家可以使用 AWS Glue DataBrew 可视化方式丰富、清理和标准化数据，而无需编写代码。"
    },
    {
        "query":"如何开始使用 AWS Glue？",
        "intention":"知识问答",
        "reply":"要开始使用 AWS Glue，只需登录 AWS 管理控制台，然后导航到“分析”分类下的“Glue”即可。您可以按照我们的其中一个指导教程进行操作，它将向您介绍 AWS Glue 的示例使用案例。您还可以在 AWS Labs 下的 [GitHub 存储库](https://github.com/awslabs/aws-glue-samples)中找到示例 ETL 代码。"
    },
    {
        "query":"AWS Glue 的主要组件有什么？",
        "intention":"知识问答",
        "reply":"AWS Glue 包含一个数据目录，该目录是一个中央元数据存储库；一个可以自动生成 Scala 或 Python 代码的 ETL 引擎；一个用于处理依赖项解析、作业监控和重试的灵活调度程序；AWS Glue DataBrew，用于通过可视化界面清理和标准化数据。这些组件结合在一起，自动执行与发现、分类、清理、丰富和移动数据相关的许多无差别的繁重任务，因此您可以将更多时间用在数据分析上。"
    },
    {
        "query":"何时应使用 AWS Glue？",
        "intention":"知识问答",
        "reply":"您应该使用 AWS Glue 来发现您所拥有的数据的属性、将其进行转换并准备好进行分析。Glue 可以自动发现存储在 [Amazon S3](https://aws.amazon.com/cn/s3/) 数据湖、[Amazon Redshift](https://aws.amazon.com/cn/redshift/) 数据仓库以及在 AWS 上运行的各种数据库中的结构化和半结构化数据。它通过 Glue 数据目录提供统一的数据视图，该数据目录可用于 ETL 以及使用 [Amazon Athena](https://aws.amazon.com/cn/athena/)、[Amazon EMR](https://aws.amazon.com/cn/emr/) 和 [Amazon Redshift Spectrum](https://aws.amazon.com/cn/redshift/) 等服务进行查询和报告。Glue 会自动为您的 ETL 作业生成 Scala 或 Python 代码，您可以使用熟悉的工具对这些代码进一步进行自定义。 您可以使用 AWS Glue DataBrew 以可视化方式清理和标准化数据，而无需编写代码。"
    },
    {
        "query":"AWS Glue 支持哪些数据源？",
        "intention":"知识问答",
        "reply":"AWS Glue 为以下位置存储的数据提供原生支持：[Amazon Aurora](https://aws.amazon.com/rds/aurora/)、[Amazon RDS for MySQL](https://aws.amazon.com/rds/mysql/)、[Amazon RDS for Oracle](https://aws.amazon.com/rds/oracle/)、[Amazon RDS for PostgreSQL](https://aws.amazon.com/rds/postgresql/)、[Amazon RDS for SQL Server](https://aws.amazon.com/rds/sqlserver/)、[Amazon Redshift](https://aws.amazon.com/redshift/)、DynamoDB 和 [Amazon S3](https://aws.amazon.com/s3/)，以及 Amazon EC2 上运行的 Virtual Private Cloud (Amazon VPC) 中的 MySQL、Oracle、Microsoft SQL Server 和 PostgreSQL 数据库。AWS Glue 还支持来自 Amazon MSK、Amazon Kinesis Data Streams 和 Apache Kafka 的数据流。\n您还可以编写自定义 Scala 或 Python 代码，并在 AWS Glue ETL 作业中导入自定义库和 Jar 文件，以访问 AWS Glue 非原生支持的数据源。有关导入自定义库的更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/glue/index.html)。"
    },
    {
        "query":"AWS Glue 如何与 AWS Lake Formation 相关联？",
        "intention":"知识问答",
        "reply":"Lake Formation 利用与 AWS Glue 的共享基础设施，包括控制台控件、ETL 代码创建和作业监控、通用数据目录和无服务器架构。虽然 AWS Glue 仍然专注于这些类型的功能，但 Lake Formation 涵盖了 AWS Glue 功能，并提供了旨在帮助构建、保护和管理数据湖的其他功能。有关更多详细信息，请参阅 [AWS Lake Formation 页面](https://aws.amazon.com/cn/lake-formation/)。"
    },
    {
        "query":"什么是 AWS Glue 数据目录？",
        "intention":"知识问答",
        "reply":"AWS Glue 数据目录是一个中央存储库，用于存储所有数据资产的结构和操作元数据。对于给定的数据集，您可以存储其表定义和物理位置、添加业务相关属性以及跟踪此数据如何随着时间发生变化。\nAWS Glue 数据目录与 Apache Hive 元数据库兼容，可以替代用于 Amazon EMR 上运行的大数据应用程序的 Apache Hive 元数据库。有关设置 EMR 集群以将 AWS Glue 数据目录用作 Apache Hive 元数据库的更多信息，请单击[此处](https://docs.aws.amazon.com/glue/index.html)。\nAWS Glue 数据目录还实现了与 [Amazon Athena](https://aws.amazon.com/cn/athena/)、[Amazon EMR](https://aws.amazon.com/cn/emr/) 和 [Amazon Redshift Spectrum](https://aws.amazon.com/cn/redshift/) 之间的开箱即用集成。当您将表定义添加到 Glue 数据目录后，它们即可用于 ETL，并且还可以在 Amazon Athena、Amazon EMR 和 Amazon Redshift Spectrum 中轻松查询，以便您能够对这些服务之间的数据有一个通用视图。"
    },
    {
        "query":"如何将元数据导入 AWS Glue 数据目录？",
        "intention":"知识问答",
        "reply":"AWS Glue 提供了多种将元数据填充到 AWS Glue 数据目录中的方法。Glue 抓取程序会扫描您拥有的各种数据存储，以自动推断出架构和分区结构，并使用相应的表定义和统计信息来填充 Glue 数据目录。您还可以安排抓取程序定期运行，以便您的元数据始终处于最新状态并与底层数据保持同步。或者，您可以通过使用 AWS Glue 控制台或调用 API 来手动添加和更新表详细信息。您还可以通过 [Amazon Athena](https://aws.amazon.com/cn/athena/) 控制台或 [Amazon EMR](https://aws.amazon.com/cn/emr/) 集群上的 Hive 客户端来运行 Hive DDL 语句。最后，如果您已经拥有了永久 Apache Hive 元数据库，则可以使用我们的导入脚本将这些元数据批量导入到 AWS Glue 数据目录中。"
    },
    {
        "query":"什么是 AWS Glue 抓取程序？",
        "intention":"知识问答",
        "reply":"AWS Glue 抓取程序可连接到数据存储，使用分类器的优先级列表来提取数据和其他统计数据的架构，然后使用该元数据填充 Glue 数据目录。抓取程序可定期运行，以检测新数据的可用性以及现有数据的更改，包括表定义的更改。抓取程序会自动将新表、新分区以及新版本的表定义添加到现有表。您可以自定义 Glue 抓取程序以对自己的文件类型进行分类。"
    },
    {
        "query":"如何将数据从现有的 Apache Hive 元数据库导入到 AWS Glue 数据目录中？",
        "intention":"知识问答",
        "reply":"您只需运行 ETL 作业即可，该作业将从 Apache Hive 元数据库读取数据，并将数据以中间格式导出到 [Amazon S3](https://aws.amazon.com/cn/s3/) 中，然后再将该数据导入 AWS Glue 数据目录中。"
    },
    {
        "query":"如果将元数据存储在 AWS Glue 数据目录中，那么是否还需要保留 Apache Hive 元数据库？",
        "intention":"知识问答",
        "reply":"不需要。AWS Glue 数据目录与 Apache Hive 元数据库兼容。您可以指向 Glue 数据目录终端节点，并使用它来替换 Apache Hive 元数据库。有关如何配置集群，将 AWS Glue 数据目录用作 Apache Hive 元数据库的更多信息，请访问[此处](https://docs.aws.amazon.com/glue/index.html)阅读我们的文档。"
    },
    {
        "query":"如果已经在使用 Amazon Athena 或 Amazon Redshift Spectrum，并且也已经在 Amazon Athena 的内部数据目录中存储了表，那么如何开始使用 AWS Glue 数据目录作为通用元数据存储库？",
        "intention":"知识问答",
        "reply":"您必须先将 Amazon Athena 数据目录升级到 AWS Glue 数据目录，然后才能开始使用 AWS Glue 数据目录作为 [Amazon Athena](https://aws.amazon.com/cn/athena/)、[Amazon Redshift Spectrum](https://aws.amazon.com/cn/redshift/) 和 AWS Glue 之间的通用元数据存储库。[此处](http://docs.aws.amazon.com/athena/latest/ug/glue-athena.html)详细介绍了升级所需的步骤。"
    },
    {
        "query":"哪些分析服务使用 AWS Glue 数据目录？",
        "intention":"知识问答",
        "reply":"您可以从 Glue ETL、[Amazon Athena](https://aws.amazon.com/athena/)、[Amazon EMR](https://aws.amazon.com/emr/)、[Amazon Redshift Spectrum](https://aws.amazon.com/redshift/) 和第三方服务轻松访问存储在 AWS Glue 数据目录中的元数据。"
    },
    {
        "query":"什么是 AWS Glue Schema Registry？",
        "intention":"知识问答",
        "reply":"[AWS Glue Schema Registry](https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html) 是 [AWS Glue](https://aws.amazon.com/cn/glue/) 的无服务器功能，让您可以使用 Apache Avro 和 JSON 架构数据格式中注册的架构来验证和控制流式传输数据的演变，无需支付额外费用。通过 Apache 许可的序列化器和反序列化器，Schema Registry 与为 Apache Kafka 开发的 Java 应用程序/适用于 Apache Kafka 的 [Amazon Managed Streaming for Apache Kafka (MSK)](https://aws.amazon.com/cn/msk/)、[Amazon Kinesis Data Streams](https://aws.amazon.com/cn/kinesis/data-streams/)、Apache Flink/[适用于 Apache Flink 的 Amazon Kinesis Data Analytics](https://aws.amazon.com/cn/kinesis/data-analytics/) 和 [AWS Lambda](https://aws.amazon.com/cn/lambda/) 集成。当数据流处理应用程序与 Schema Registry 集成时，您可以改善数据质量并使用管辖 Schema 发展的兼容性检查来防止出现意外更改。另外，您还可以使用存储在注册表中的 Apache Avro 架构来创建或更新 AWS Glue 表和分区。"
    },
    {
        "query":"为何应该使用 AWS Glue Schema Registry？",
        "intention":"知识问答",
        "reply":"借助 AWS Glue Schema Registry，您可以："
    },
    {
        "query":"AWS Glue Schema Registry 支持哪些数据格式、客户端语言和集成？",
        "intention":"知识问答",
        "reply":"Schema Registry 支持 Apache Avro 和 JSON Schema 数据格式以及 Java 客户端应用程序。我们计划继续扩展对其他数据格式和非 Java 客户端的支持。Schema Registry 与为 Apache Kafka 开发的应用程序、[Amazon Managed Streaming for Apache Kafka (MSK)](https://aws.amazon.com/cn/msk/)、[Amazon Kinesis Data Streams](https://aws.amazon.com/cn/kinesis/data-streams/)、[Apache Flink、适用于 Apache Flink 的 Amazon Kinesis Data Analytics](https://aws.amazon.com/cn/kinesis/data-analytics/) 和 [AWS Lambda](https://aws.amazon.com/cn/lambda/) 集成。"
    },
    {
        "query":"AWS Glue Schema Registry 支持哪些演变规则？",
        "intention":"知识问答",
        "reply":"以下兼容模式可供您管理架构演变：向后、全部向后、向前、全部向前、完整、全部、无和禁用。访问 Schema Registry [用户文档](https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html)以了解有关兼容性规则的更多信息。"
    },
    {
        "query":"AWS Glue Schema Registry 如何保持应用程序的高可用性？",
        "intention":"知识问答",
        "reply":"Schema Registry 存储和控制层面专为实现高可用性而设计，并由 [AWS Glue SLA](https://aws.amazon.com/cn/glue/sla/) 提供支持，并且序列化器和反序列化器利用最佳实践缓存技术来最大化客户端内的架构可用性。"
    },
    {
        "query":"AWS Glue Schema Registry 是否开源？",
        "intention":"知识问答",
        "reply":"AWS Glue Schema Registry 存储是一项 AWS 服务，而序列化程序和反序列化程序是 Apache 许可的开源组件。"
    },
    {
        "query":"AWS Glue Schema Registry 是否提供静态加密和传输中加密？",
        "intention":"知识问答",
        "reply":"是的，您的客户端通过 API 调用与 Schema Registry 进行通信，而 API 调用使用通过 HTTPS 的 TLS 加密对传输中的数据进行加密。 存储在 Schema Registry 中的架构始终使用服务托管的 KMS 密钥进行静态加密。"
    },
    {
        "query":"如何以私有方式连接到 AWS Glue Schema Registry？",
        "intention":"知识问答",
        "reply":"您可以通过为 AWS Glue 定义接口 VPC 终端节点，使用 AWS PrivateLink 将数据生产者的 VPC 连接到 AWS Glue。使用 VPC 接口终端节点时，VPC 与 AWS Glue 之间的通信将完全在 AWS 网络中进行。有关更多信息，请访问[用户文档](https://docs.aws.amazon.com/glue/latest/dg/vpc-endpoint.html)。"
    },
    {
        "query":"如何监控我的 AWS Glue Schema Registry 使用情况？",
        "intention":"知识问答",
        "reply":"AWS CloudWatch 指标在 CloudWatch 免费套餐中提供。您可以在 CloudWatch 控制台中访问这些指标。请访问 AWS Glue Schema Registry [用户文档](https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html)以了解更多信息。"
    },
    {
        "query":"AWS Glue Schema Registry 是否提供工具来管理用户授权？",
        "intention":"知识问答",
        "reply":"是的，Schema Registry 支持资源级权限和基于身份的 IAM 策略。"
    },
    {
        "query":"如何从现有架构注册表迁移到 AWS Glue Schema Registry？",
        "intention":"知识问答",
        "reply":"[用户文档](https://docs.aws.amazon.com/glue/latest/dg/schema-registry.html)中提供了从第三方架构注册表迁移到 AWS Glue Schema Registry 的步骤。"
    },
    {
        "query":"AWS Glue 是否有可视化 ETL 的无代码界面？",
        "intention":"知识问答",
        "reply":"是。AWS Glue Studio 提供一个图形界面来编写 Glue 作业以处理您的数据。当您定义数据源的流、可视化界面中的转换和目标之后，AWS Glue Studio 将代表您生成 Apache Spark 代码。"
    },
    {
        "query":"我可以使用哪种编程语言为 AWS Glue 编写 ETL 代码？",
        "intention":"知识问答",
        "reply":"您可以使用 Scala 或 Python。"
    },
    {
        "query":"如何自定义 AWS Glue 生成的 ETL 代码？",
        "intention":"知识问答",
        "reply":"AWS Glue 的 ETL 脚本推荐系统生成 Scala 或 Python 代码。它利用 Glue 的自定义 ETL 库来简化对数据源的访问以及管理作业执行情况。有关库的更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/glue/index.html)。您可以使用 AWS Glue 的自定义库来编写 ETL 代码，或者也可以使用 Scala 或 Python 语言编写任意代码，方法是通过 AWS Glue 控制台的脚本编辑器使用内联编辑，下载自动生成的代码，然后在自己的 IDE 中进行编辑。您也可以一开始使用我们的 [Github 存储库](https://github.com/awslabs/aws-glue-samples)中托管的许多示例代码之一，然后自定义此代码。"
    },
    {
        "query":"是否可以导入自定义库作为 ETL 脚本的一部分？",
        "intention":"知识问答",
        "reply":"支持。您可以将自定义 Python 库和 Jar 文件导入 AWS Glue ETL 作业。有关更多详细信息，请在[此处](https://docs.aws.amazon.com/glue/index.html)参阅我们的文档。"
    },
    {
        "query":"是否可以使用自己的代码？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS Glue 的 ETL 库自己编写代码，或者自己编写 Scala 或 Python 代码，然后将其上传到 Glue ETL 作业。有关更多详细信息，请在[此处](https://docs.aws.amazon.com/glue/index.html)参阅我们的文档。"
    },
    {
        "query":"如何使用自己的 IDE 开发 ETL 代码？",
        "intention":"知识问答",
        "reply":"您可以创建开发终端节点并进行连接，从而获得连接到笔记本和 IDE 的方法。"
    },
    {
        "query":"如何使用 AWS Glue 中的多个作业构建端到端的 ETL 工作流？",
        "intention":"知识问答",
        "reply":"除了 ETL 库和代码生成，AWS Glue 还提供一套强大的编排功能，可让您管理多个作业之间的依赖关系，以构建端到端的 ETL 工作流。AWS Glue ETL 作业可以按计划或按作业完成事件进行触发。可并行触发多个作业，也可以按作业完成事件依次触发作业。您还可以从外部来源触发一个或多个 Glue 作业，例如 [AWS Lambda](https://aws.amazon.com/cn/lambda/) 函数。"
    },
    {
        "query":"AWS Glue 如何监控依赖关系？",
        "intention":"知识问答",
        "reply":"AWS Glue 可使用触发器管理两个或多个作业之间的依赖关系或外部事件上的依赖关系。触发器可以监控以及调用一个或多个作业。您可以使用计划触发器来定期调用作业，也可以使用按需触发器或作业完成触发器来调用作业。"
    },
    {
        "query":"AWS Glue 如何处理 ETL 错误？",
        "intention":"知识问答",
        "reply":"AWS Glue 可监控作业事件指标和错误，并会将所有通知推送到 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/)。您可以借助 Amazon CloudWatch 配置大量可基于 AWS Glue 特定通知触发的操作。例如，如果您从 Glue 获得错误或成功通知，则可以触发 [AWS Lambda](https://aws.amazon.com/cn/lambda/) 函数。Glue 还提供默认重试行为，会在发送错误通知之前，重试三次所有失败的操作。"
    },
    {
        "query":"是否可以使用 AWS Glue 运行现有的 ETL 作业？",
        "intention":"知识问答",
        "reply":"支持。您可以在 AWS Glue 上运行现有的 Scala 或 Python 代码。仅需将代码上传到 [Amazon S3](https://aws.amazon.com/cn/s3/)，然后创建一个或多个使用此代码的作业即可。您可以将多个作业指向 Amazon S3 上的同一代码位置，从而可以跨这些作业重复使用同一代码。"
    },
    {
        "query":"如何使用 AWS Glue 来对流数据执行 ETL 操作？",
        "intention":"知识问答",
        "reply":"AWS Glue 支持对来自 Amazon Kinesis Data Streams、Apache Kafka 和 Amazon MSK 的数据流的 ETL 操作。将流添加到 Glue 数据目录，然后在设置 AWS Glue 作业时将其选择为数据源。"
    },
    {
        "query":"是否必须同时使用 AWS Glue 数据目录和 Glue ETL 才能使用该服务？",
        "intention":"知识问答",
        "reply":"不是。虽然我们确信同时使用 AWS Glue 数据目录和 ETL 可提供端到端的 ETL 体验，但您也可以单独使用其中任意一个。"
    },
    {
        "query":"应该何时使用 AWS Glue 流，何时使用 Amazon Kinesis Data Analytics？",
        "intention":"知识问答",
        "reply":"AWS Glue 和 Amazon Kinesis Data Analytics 均可轻松处理流数据。当您的使用案例主要是 ETL，以及您希望在基于 Apache Spark 的无服务器平台上运行作业时，建议使用 AWS Glue。当您的使用案例主要是分析，以及您希望在基于 Apache Flink 的无服务器平台上运行作业时，建议使用 Amazon Kinesis Data Analytics。\nAWS Glue 中的流 ETL 支持使用您当前用于批处理作业的无服务器按需支付平台对流数据进行高级 ETL 操作。AWS Glue 生成可自定义的 ETL 代码，以便在传输过程中准备您的数据，并具有内置功能以处理半结构化或具有演进架构的流数据。使用 Glue 将其内置转换和 Spark 本机转换应用于数据流，并将其加载到数据湖或数据仓库中。\nAmazon Kinesis Data Analytics 使您能够构建复杂的流应用程序，以实时分析流数据。它提供了无服务器的 Apache Flink 运行时，无需服务器即可自动扩展，并可持久地保存应用程序状态。使用 Amazon Kinesis Data Analytics 进行实时分析和更通用的流数据处理。"
    },
    {
        "query":"应该何时使用 AWS Glue，何时使用 Amazon Kinesis Data Firehose？",
        "intention":"知识问答",
        "reply":"AWS Glue 和 Amazon Kinesis Data Firehose 均可用于进行流式 ETL 操作。对于复杂的 ETL 操作，建议使用 AWS Glue，包括加入流以及根据数据内容在 Amazon S3 中对输出进行分区。当您的使用案例专注于数据交付并准备数据以便在交付后进行处理时，建议使用 Amazon Kinesis Data Firehose。\nAWS Glue 中的流 ETL 支持使用您当前用于批处理作业的无服务器按需支付平台对流数据进行高级 ETL 操作。AWS Glue 生成可自定义的 ETL 代码，以便在传输过程中准备您的数据，并具有内置功能以处理半结构化或具有演进架构的流数据。使用 Glue 将复杂的转换应用于数据流，使用来自其他流和持久数据存储的信息丰富记录，然后将记录加载到数据湖或数据仓库中。\n在 Amazon Kinesis Data Firehose 中进行流 ETL 操作使您能够轻松捕获、转换和交付流数据。Amazon Kinesis Data Firehose 提供 ETL 功能，包括通过 AWS Lambda 进行无服务器数据转换，以及从 JSON 到 Parquet 的格式转换。它包括旨在使数据在交付后更易于处理的 ETL 功能，但不包括 AWS Glue 支持的高级 ETL 功能。"
    },
    {
        "query":"FindMatches ML 转换解决了哪些类型的问题？",
        "intention":"知识问答",
        "reply":"FindMatches 通常解决记录连接和数据删除重复问题。删除重复是当您试图识别数据库中的记录时必须做的事情，这些记录在概念上是“相同的”，但是您有单独的记录。如果重复记录可以用唯一的键标识（例如，如果产品可以用 UPC 代码唯一标识），那么这个问题就很简单，但是当您必须进行“模糊匹配”时，这个问题就变得非常具有挑战性。\n记录连接基本上与底层的数据删除重复问题相同，但这个术语通常意味着您正在对两个不共享唯一键的数据库进行“模糊连接”，而不是对单个数据库进行删除重复。例如，考虑将客户大型数据库与已知欺诈者的小型数据库进行匹配的问题。FindMatches 可以用于记录连接和删除重复问题。\n例如，AWS Glue 的 FindMatches ML 转换可以帮助您解决以下问题：\n将医院之间的患者记录连接起来，这样医生就有了更多的背景信息，并且能够通过在单独的数据库中使用 FindMatches 来更好地治疗患者，这些数据库都包含姓名、生日、家庭住址、电话号码等常见字段。\n对包含诸如“标题”、“情节概要”、“发行年份”、“运行时间”和“演员表”等列的电影数据库进行删除重复操作。例如，同一部电影可能被识别为不同名称：“星球大战”、“星球大战：新希望”和“星球大战：第四集——新希望（特别版）”。\n通过识别服装产品目录中的等效项目，自动将店面中的所有相关产品组合在一起，您要在其中定义“等效”以表示它们相同，忽略大小和颜色的差异。因此，将“Levi 501 Blue Jeans，size 34x34”定义为与“Levi 501 Jeans — black，size 32x31”相同。"
    },
    {
        "query":"AWS Glue 如何对我的数据进行删除重复操作？",
        "intention":"知识问答",
        "reply":"AWS Glue 的 FindMatches ML 转换可以轻松查找和连接引用同一实体但不共享可靠标识符的记录。在 FindMatches 之前，开发人员通常会通过编写大量手动调整的规则来确定性地解决数据匹配问题。FindMatches 在幕后使用机器学习算法来学习如何根据每个开发人员自己的业务标准匹配记录。FindMatches 首先识别客户的记录，以标记它们是否匹配，然后使用机器学习创建 ML 转换。然后，客户可以在他们的数据库上执行此转换以查找匹配的记录，或者他们可以要求 FindMatches 为他们提供附加记录来进行标记，从而将他们的 ML 转换提升到更高的精度级别。"
    },
    {
        "query":"ML 转换是什么？",
        "intention":"知识问答",
        "reply":"ML 转换为创建和管理机器学习的转换提供了一个目标。这些 ML 转换一旦创建并经过训练，就可以在标准的 AWS Glue 脚本中执行。客户选择特定算法（例如，FindMatches ML 转换），然后输入数据集和训练示例，以及该算法所需的调整参数。AWS Glue 使用这些输入来构建 ML 转换，该转换可以合并到一个正常的 ETL 作业工作流中。"
    },
    {
        "query":"ML 转换是如何工作的？",
        "intention":"知识问答",
        "reply":"AWS Glue 包括专门的基于 ML 的数据集转换算法，客户可以使用这些算法创建自己的 ML 转换。这些包括删除重复记录和查找匹配。\n客户首先导航到控制台的 ML 转换标签（或使用 ML 转换服务终端节点或通过 CLI 访问 ML 转换训练），创建他们的第一个 ML 转换模型。ML 转换标签为管理用户转换提供了一个用户友好的视图。ML 转换需要与其他转换不同的工作流要求，包括需要单独的训练、参数调整和执行工作流；需要估算生成转换的质量指标；以及需要管理和收集额外的真值标签，用于训练和主动学习。\n为了通过控制台创建 ML 转换，客户首先选择转换类型（如删除重复记录或匹配记录），并提供以前在数据目录中发现的适当数据源。根据转换的不同，可能会要求客户为训练或附加参数提供实际真值标签数据。客户可以监控它们的训练作业的状态，并查看每个转换的质量指标。（使用客户提供的标签数据的保留集报告质量指标。）\n客户一旦满意 ML 转换模型的性能，就可以在生产中推广使用该模型。然后，可以在 ETL 工作流期间使用 ML 转换，既可以在服务自动生成的代码中使用，也可以在随其他作业提交的用户定义脚本中使用，类似于其他 AWS Glue 库中提供的预构建转换。"
    },
    {
        "query":"我是否可以看到有关使用 AWS Glue（和 AWS Lake Formation）查找匹配和删除重复记录的演示文稿？",
        "intention":"知识问答",
        "reply":"可以， AWS 在线技术讨论的完整记录，[“使用 AWS Lake Formation 的 ML 转换进行模糊匹配和删除重复数据”在此提供。](https://pages.awscloud.com/Fuzzy-Matching-and-Deduplicating-Data-with-ML-Transforms-for-AWS-Lake-Formation_2019_0304-ABD_OD.html)"
    },
    {
        "query":"什么是 AWS Glue DataBrew？",
        "intention":"知识问答",
        "reply":"AWS Glue DataBrew 是一种可视化的数据准备工具，它使数据分析师和数据科学家能够通过一个交互式、点击式可视化界面轻松地准备数据，而不需要编写代码。使用 Glue DataBrew，您可以直接从湖内数仓、数据仓库和数据库（包括 Amazon S3、Amazon Redshift、Amazon Aurora 和 Amazon RDS）中轻松可视化、整理和标准化数 TB，甚至是数 PB 数据。AWS Glue DataBrew 现已在美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（俄勒冈）、欧洲（爱尔兰）、欧洲（法兰克福）、亚太地区（悉尼）和亚太地区（东京）全面推出。"
    },
    {
        "query":"谁可以使用 AWS Glue DataBrew？",
        "intention":"知识问答",
        "reply":"AWS Glue DataBrew 专为需要清理和标准化数据以进行分析和机器学习的用户而建立。数据分析师和数据科学家是主要用户。对于数据分析师，其工作职能包括商业智能分析师、运营分析师、市场情报分析师、法律分析师、金融分析师、经济专家、定量分析专家或会计师等。对于数据科学家，其工作职能包括材料科学家、生物分析科学家和科学研究人员等。"
    },
    {
        "query":"AWS Glue DataBrew 支持什么类型的转换？",
        "intention":"知识问答",
        "reply":"您可以从 250 多个内置的转换中进行选择，无需编写代码即可合并、转变和转置数据。AWS Glue DataBrew 还会自动推荐一些转换，例如筛选异常，纠正无效、不正确分类或重复的数据，将数据标准化为标准日期和时间值，或生成用于分析的聚合。对于复杂的转换，比如将单词转换为通用的基本单词或根单词，Glue DataBrew 提供了使用高级机器学习技术（如自然语言处理）的转换。您可以将多个转换分组在一起、将它们另存为配方，并将配方直接应用于新的传入数据。"
    },
    {
        "query":"AWS Glue DataBrew 支持什么文件格式？",
        "intention":"知识问答",
        "reply":"对于输入数据，AWS Glue DataBrew 支持常用的文件格式，如逗号分隔值 (.csv)、JSON 和嵌套 JSON、Apache Parquet 和嵌套 Apache Parquet 以及 Excel 表格。对于输出数据，AWS Glue DataBrew 支持逗号分隔值 (.csv)、JSON、Apache Parquet、Apache Avro、Apache ORC 和 XML。"
    },
    {
        "query":"我是否能免费试用 AWS Glue DataBrew？",
        "intention":"知识问答",
        "reply":"可以。注册 [AWS 免费套餐](https://portal.aws.amazon.com/billing/signup?redirect_url=https%3A%2F%2Faws.amazon.com%2Fregistration-confirmation#/start)账户，然后访问 [AWS Glue DataBrew 管理控制台](https://console.aws.amazon.com/databrew/home)，立即免费开始使用。如果您是第一次使用 Glue DataBrew，则前 40 个交互式会话免费。请访问 [AWS Glue 定价](https://aws.amazon.com/cn/glue/pricing/)页面，以了解更多信息。"
    },
    {
        "query":"我是否需要使用 AWS Glue 数据目录或 AWS Lake Formation 来使用 AWS Glue DataBrew？",
        "intention":"知识问答",
        "reply":"否。您无需使用 AWS Glue 数据目录或 AWS Lake Formation 即可使用 AWS Glue DataBrew。但是，如果您使用 AWS Glue 数据目录或 AWS Lake Formation，DataBrew 用户可以从他们的集成式数据目录中选择可用的数据集。"
    },
    {
        "query":"我是否能保留对我的数据进行的所有更改的记录？",
        "intention":"知识问答",
        "reply":"可以。您可以在 [AWS Glue DataBrew 管理控制台](https://console.aws.amazon.com/databrew/home)中可视化跟踪对您的数据进行的所有更改。通过可视化视图，可以很容易地跟踪对数据集、项目和配方以及所有其他相关作业所做的更改及其关系。此外，Glue DataBrew 将所有账户活动作为日志保存在 AWS CloudTrail 中。"
    },
    {
        "query":"什么是 Glue Flex？",
        "intention":"知识问答",
        "reply":"AWS Glue Flex 是一个灵活的执行任务类，您可以通过它将非紧急数据集成工作负载（如预生产任务、测试、数据负载等）的成本降低高达 35%。Glue 具有两个任务执行类：标准和灵活。标准执行类是需要快速启动任务和专用资源的时间敏感型工作负载的理想之选。灵活执行类适合于开始和完成时间可能不同的非紧急任务。AWS Glue Flex 可以降低非时间敏感型工作负载（例如，夜间批处理 ETL 任务、周末任务、一次性批量数据摄取等）的成本。"
    },
    {
        "query":"AWS Glue 的标准和灵活执行类有何不同？",
        "intention":"知识问答",
        "reply":"AWS Glue 的标准和灵活执行类具有不同的执行属性。如果是标准执行类，则任务将会立即启动并且在运行时具有专用资源。灵活执行类任务在 AWS 中的可在任务运行时回收的非专用计算资源中运行，其开始和完成时间可能不同。因此，这两种执行类适合于不同工作负载。标准执行类是需要快速启动任务和专用资源的时间敏感型工作负载的理想之选。灵活执行类经济实惠，适合于可接受不同开始和结束时间的非紧急任务。"
    },
    {
        "query":"如何开始使用 AWS Glue Flex 灵活执行类任务？",
        "intention":"知识问答",
        "reply":"灵活执行类可用于 Glue Spark 任务。要使用灵活执行类，您只需将执行类参数的默认设置从“STANDARD”（标准）改为“FLEX”（灵活）。您可以通过 Glue Studio 或 CLI 完成此操作。请访问 AWS Glue 用户文档，以了解更多信息。"
    },
    {
        "query":"哪些类型的数据集成和 ETL 工作负载不适合于 AWS Glue Flex 灵活执行类？",
        "intention":"知识问答",
        "reply":"AWS Glue Flex 灵活执行类不适合于需要一致的任务开始和运行时间的时间敏感型工作负载，也不适合于必须在特定时间执行的任务。此外，不推荐将 AWS Glue Flex 用于长时间运行的数据集成工作负载，因为它们很有可能中断，导致频繁取消。"
    },
    {
        "query":"使用 AWS Glue Flex 灵活执行类的任务多久会中断一次？",
        "intention":"知识问答",
        "reply":"AWS Glue Flex 的可用性和中断频率取决于多个因素，包括所在区域和可用区（AZ）、当天的时间、周中日。资源可用性决定了 Glue Flex jobs 是否会启动。尽管高峰时期的中断率可以为 5-10%，但我们仍希望 Glue Flex 任务的中断率在 5% 左右或者因中断导致的 Glue Flex 任务的故障率低于 5%。"
    },
    {
        "query":"灵活执行类是否始终可用？",
        "intention":"知识问答",
        "reply":"是，您始终可以选择灵活执行类来运行 Glue 任务。但是，AWS Glue 执行这些任务的能力取决于非专用 AWS 容量以及为任务选择的工作程序数量。可能出现的情况是，在高峰时段，Glue 没有足够的容量来运行任务。在这种情况下，任务不会启动。您可以指定一个超时值，Glue 在此值之后将会取消任务。超时值越长，执行任务的几率越大。"
    },
    {
        "query":"如果 AWS Glue Flex 任务在执行时中断，则会出现什么情况？",
        "intention":"知识问答",
        "reply":"根据指定的工作程序数量，如果没有足够的工作程序来完成任务而导致 Glue Flex 任务中断，则任务将会失败。在取消任务之前，Glue 会将失败的任务重试指定的[任务定义重试](https://docs.aws.amazon.com/glue/latest/dg/aws-glue-api-jobs-job.html#aws-glue-api-jobs-job-Job)最大次数。您应无法将灵活执行类用于任何在其他系统或进程中具有下游依赖项的任务。"
    },
    {
        "query":"灵活执行类支持哪些类型的 AWS Glue 任务？",
        "intention":"知识问答",
        "reply":"灵活执行类仅支持 Glue Spark 任务。不支持 Pythonshell 和流式传输。Glue 版本 3.0 及更高版本支持 AWS Glue Flex。灵活执行类目前不支持流式传输工作负载。"
    },
    {
        "query":"何时应使用 AWS Glue？何时应使用 AWS Data Pipeline？",
        "intention":"知识问答",
        "reply":"AWS Glue 可提供在无服务器 Apache Spark 环境中运行的托管 ETL 服务。这使您能够专注于 ETL 作业，不用担心配置和管理底层计算资源。AWS Glue 采用数据第一的方式，可让您专注于数据属性和数据操作，以将数据转换为您可以获取业务见解的形式。它可提供集成的数据目录，以便对元数据执行 ETL 操作，以及可通过 [Amazon Athena](https://aws.amazon.com/cn/athena/) 和 [Amazon Redshift Spectrum](https://aws.amazon.com/cn/redshift/) 进行查询。\n[AWS Data Pipeline](https://aws.amazon.com/cn/datapipeline/) 可提供托管编排服务，为您在执行环境、访问和控制运行代码的计算资源以及本身执行数据处理的代码方面提供更大的灵活性。AWS Data Pipeline 可在您的账户中启动计算资源，从而使您能够直接访问 Amazon EC2 实例或 [Amazon EMR](https://aws.amazon.com/cn/emr/) 集群。\n此外，AWS Glue ETL 作业均使用 Scala 或 Python 语言。如果您的使用案例要求您使用 Apache Spark 以外的引擎，或者您想运行在各种引擎（如 Hive、Pig 等）上运行的异构作业集，那么 AWS Data Pipeline 将是一个更好的选择。"
    },
    {
        "query":"何时应使用 AWS Glue？何时应使用 Amazon EMR？",
        "intention":"知识问答",
        "reply":"AWS Glue 基于 Apache Spark 环境运行，为数据转换作业提供横向扩展的执行环境。AWS Glue 可推断、拓展和监控 ETL 作业，大大简化了作业的创建和维护过程。[Amazon EMR](https://aws.amazon.com/cn/emr/) 可让您直接访问 Hadoop 环境，为您在使用 Spark 以外的工具时提供较低级的访问权限和更高的灵活性。"
    },
    {
        "query":"何时应使用 AWS Glue？何时应使用 AWS Database Migration Service？",
        "intention":"知识问答",
        "reply":"[AWS Database Migration Service](https://aws.amazon.com/cn/dms/) (DMS) 可帮助您轻松并安全地将数据库迁移至 AWS。如果需要将数据库从本地迁移至 AWS 或需要本地源与 AWS 上的源之间进行数据库复制，我们建议您使用 AWS DMS。一旦数据位于 AWS 中，您就可以使用 AWS Glue 将数据源中的数据移动、合并、复制到另一个数据库或数据仓库（比如 [Amazon Redshift](https://aws.amazon.com/cn/redshift/)）中并进行转换。"
    },
    {
        "query":"何时应使用 AWS Glue？何时应使用 AWS Batch？",
        "intention":"知识问答",
        "reply":"[AWS Batch](https://aws.amazon.com/cn/batch/) 使您能够轻松有效地在 AWS 上运行任何批量计算作业，而无需考虑作业的性质。AWS Batch 可在您的 AWS 账户中创建和管理计算资源，使您能够全面控制和了解所使用的资源。AWS Glue 是一项完全托管的 ETL 服务，可提供无服务器的 Apache Spark 环境来运行 ETL 作业。对于 ETL 使用案例，我们建议您探索使用 AWS Glue。对于其他面向批量操作的使用案例，其中包括一些 ETL 使用案例，AWS Batch 可能是更合适的选择。"
    },
    {
        "query":"AWS Glue 作业的计费何时开始，何时结束？",
        "intention":"知识问答",
        "reply":"计费在作业安排执行后立即开始，并持续至整个作业完成。使用 AWS Glue 时，您只需针对作业运行的时间付费，而无需为环境预置或关闭时间付费。"
    },
    {
        "query":"AWS Glue 如何确保数据安全？",
        "intention":"知识问答",
        "reply":"我们为静态数据提供服务器端加密，为动态数据提供 SSL 加密。"
    },
    {
        "query":"AWS Glue 有哪些服务限制？",
        "intention":"知识问答",
        "reply":"有关服务限制的更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/glue/index.html)。"
    },
    {
        "query":"哪些区域提供 AWS Glue？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 AWS Glue 服务在不同区域的具体提供情况。"
    },
    {
        "query":"为开发终端节点分配了多少 DPU（数据处理单元）？",
        "intention":"知识问答",
        "reply":"一个开发终端节点默认预置 5 个 DPU。您可以为开发终端节点配置最少 2 个，最多 5 个 DPU。"
    },
    {
        "query":"如何扩展 AWS Glue ETL 作业的规模和性能？",
        "intention":"知识问答",
        "reply":"您仅需指定想分配给 ETL 作业的 DPU（数据处理单元）数量即可。一个 Glue ETL 作业至少需要 2 个 DPU。默认情况下，AWS Glue 会为每个 ETL 作业分配 10 个 DPU。"
    },
    {
        "query":"如何监控 AWS Glue 作业的执行情况？",
        "intention":"知识问答",
        "reply":"AWS Glue 会提供每个作业的状态，并将所有通知推送到 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/)。您可以通过 CloudWatch 操作设置 SNS 通知，接收作业失败或完成通知。"
    },
    {
        "query":"AWS Glue SLA 提供什么保障？",
        "intention":"知识问答",
        "reply":"我们的 AWS Glue SLA 保证 AWS Glue 的月度正常运行时间百分比至少为 99.9%。"
    },
    {
        "query":"怎样确定我是否有资格获得 SLA 服务抵扣？",
        "intention":"知识问答",
        "reply":"如果您运行任务的可用区不止一个，且在任意月度计费周期内，相同区域内的月度正常运行时间百分比低于 99.9%，那么根据 AWS Glue SLA 的规定，您有资格获得 SLA 针对 AWS Glue 提供的抵扣。\n如需 SLA 的所有条款与条件的完整详细信息，以及如何提交索赔的详细信息，请参阅 [AWS Glue SLA 详细信息页面](https://aws.amazon.com/cn/glue/sla/)。\n浏览 AWS Glue 的定价选项。\n立即享受 AWS 免费套餐。\n在 AWS 管理控制台中，使用 AWS Glue 开始构建。"
    },
    {
        "query":"如何才能试用 Amazon Pinpoint？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 是自助服务，因此，您在购买前可以先试用，无需与销售人员交谈、填写 RFP 或聘请顾问或专业服务。只需使用您的 AWS 账户登录 Amazon Pinpoint 控制台，然后设置一个 Amazon Pinpoint 项目即可。要了解如何设置 Amazon Pinpoint，请参阅[入门教程](https://docs.aws.amazon.com/pinpoint/latest/userguide/gettingstarted.html)。"
    },
    {
        "query":"历程中的活动是什么？",
        "intention":"知识问答",
        "reply":"历程可以自动开展多步骤活动。历程中的每个活动要么是一项操作（例如发送电子邮件）、一次基于时间的等待、根据客户操作（例如打开电子邮件和不打开电子邮件）划分历程细分，要么是强制执行保留。\n要了解有关这些活动的更多信息，请参阅 [Amazon Pinpoint 用户指南](https://docs.aws.amazon.com/pinpoint/latest/userguide/welcome.html)中的历程。"
    },
    {
        "query":"我可以安排我的历程吗？",
        "intention":"知识问答",
        "reply":"您可以将每个历程配置为在特定时间开始和结束。每个历程最多可以连续运行 18 个月。\n您还可以安排新参与者进入历程的频率。创建历程时，您可以指定参与其中的一部分客户。您可以设置您的历程，以便定期（每小时、每天、每月、每季度、每年或根本不）更新这一细分。"
    },
    {
        "query":"如果我在历程中犯了错误，该怎么办？",
        "intention":"知识问答",
        "reply":"历程包含一个内置的审查流程，该流程会检查“显示停止”的错误，同时还会提供建议和最佳实践。在您启动每个历程之前，必须完成此审查流程。\n历程还包含一项测试功能，通过此功能可以轻松地在整个历程中派送一组测试参与者。通过测试您的历程，您可以确保它按您预期的方式运行。\n如果您在历程运行期间遇到相关问题，可以随时停止。当您停止历程时，参与者会暂停他们当前正在进行的活动，并且绝不会继续进行下一个活动。"
    },
    {
        "query":"如何才能使用 Amazon Pinpoint 开展并管理活动？",
        "intention":"知识问答",
        "reply":"借助 Amazon Pinpoint，您可以通过不同渠道（包括电子邮件、SMS、推送通知、应用程序内消息或自定义渠道），轻松开展有针对性的活动并推动客户沟通。 Amazon Pinpoint 活动使您能够定义目标用户、确定要发送的消息、安排发送消息的最佳时间，以及跟踪活动结果。\nAmazon Pinpoint 可以进行扩展，让您每天能够收集和处理数十亿个事件，并向您的用户发送数十亿条有针对性的消息。"
    },
    {
        "query":"营销人员如何从 Amazon Pinpoint 获益？",
        "intention":"知识问答",
        "reply":"控制台为营销人员提供了活动管理工具，以便他们在应用程序、用户群和设备间创建、开展和管理多渠道活动。他们可以根据用户更改和操作安排或触发活动。对于想要通过多个渠道开展多步骤活动的营销人员来说，他们可以设计历程来编排端到端体验。营销人员还可以利用模板支持来打造个性化最终用户消息。此外，营销人员还可以使用 Pinpoint 分析衡量消息收发效果，从而了解对用户行为产生的影响。"
    },
    {
        "query":"什么是标准活动？",
        "intention":"知识问答",
        "reply":"标准活动包括目标细分（静态或动态）、消息和消息发送计划。创建活动时，您还可以重复使用之前定义的细分或定义一个新的细分。对于每个计划的活动，Amazon Pinpoint 会根据与细分关联的标准重新计算当前受众规模。"
    },
    {
        "query":"什么是 A/B 测试活动？",
        "intention":"知识问答",
        "reply":"A/B 活动是存在多种处理的活动。每种处理在消息或发送计划方面都各不相同。您可以比较每种处理的响应率来确定哪种处理对客户的影响较大。"
    },
    {
        "query":"活动支持哪些计划选项？",
        "intention":"知识问答",
        "reply":"在 Amazon Pinpoint 中设置活动期间，您可以选择发送活动消息的时间。有两个选项，您可以在特定时间发送活动消息，也可以在事件发生时发送活动消息。您可以将基于时间的活动安排为立即开展一次，或者在指定的未来时间开展一次。也可以将活动安排为多次开展 – 每小时、每天、每周或每月开展。要定义重复活动，请选择开始日期和结束日期，并指定是否根据每个接收者的当地时区来传送消息。\n您还可以使用 Amazon Pinpoint 创建活动，以便在客户在应用程序中执行特定操作时向客户发送消息，例如短信、推送通知、应用程序内消息和电子邮件。例如，在客户创建个人资料文件时发送欢迎电子邮件。您可以使用 Amazon Pinpoint 控制台或 Amazon Pinpoint API 创建基于事件的活动。基于事件的活动是实施事务性和有针对性的活动使用案例的有效方式。您可以选择要用于触发活动的特定事件、属性和指标值，而不是定义要向客户发送消息的时间。有关基于事件的活动的更多信息，请参阅我们的博客文章。"
    },
    {
        "query":"如果我使用其他活动管理服务，Amazon Pinpoint 可为我提供哪些帮助？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 的架构是模块化的。各个公司可以选择要使用以及要与其现有的系统和流程集成的服务。Amazon Pinpoint 的核心服务包括：参与度分析、通信渠道、送达率指标、受众管理和细分、模板管理以及活动管理。\n此外，该平台还支持使用数据集成服务扩展 Amazon Pinpoint 分析、来自外部数据来源（例如 S3）的细分数据，以及通过 Kinesis Event Streams 将数据导出以提供给外部市场营销系统。"
    },
    {
        "query":"活动限制如何运作？",
        "intention":"知识问答",
        "reply":"在 Amazon Pinpoint 控制台的常规设置页面上或在活动设置中，您可以配置终端节点能够接收活动的最大消息数量。当您想要严格限制终端节点在特定时间能够接收的消息数量时，此功能非常有用。例如，如果您创建了自动发送给所有新客户的活动，则可以将限制设置为 1。此设置可以确保新客户只收到一次消息。\n请务必注意，此功能基于针对终端节点的消息数量，而不是实际传递到终端节点的消息数量。如果将活动配置为在客户创建新账户时自动发送消息，但终端节点由于某种原因（例如，如果您的活动的安静时间设置应用于终端节点）无法接收消息，那么终端节点仍会被视为目标。在这种情况下，终端节点将从活动的后续开展中删除，直到它们超出限制期限。"
    },
    {
        "query":"历程中的活动是什么？",
        "intention":"知识问答",
        "reply":"历程可以自动开展多步骤活动。历程中的每个活动要么是一项操作（例如发送电子邮件）、一次基于时间的等待、根据客户操作（例如打开电子邮件和不打开电子邮件）划分历程细分，要么是强制执行保留。\n要了解有关这些活动的更多信息，请参阅 [Amazon Pinpoint 用户指南](https://docs.aws.amazon.com/pinpoint/latest/userguide/welcome.html)中的历程。"
    },
    {
        "query":"我可以安排我的历程吗？",
        "intention":"知识问答",
        "reply":"您可以将每个历程配置为在特定时间开始和结束。每个历程最多可以连续运行 18 个月。\n您还可以安排新参与者进入历程的频率。创建历程时，您可以指定参与其中的一部分客户。您可以设置您的历程，以便定期（每小时、每天、每月、每季度、每年或根本不）更新这一细分。"
    },
    {
        "query":"如果我在历程中犯了错误，该怎么办？",
        "intention":"知识问答",
        "reply":"历程包含一个内置的审查流程，该流程会检查“显示停止”的错误，同时还会提供建议和最佳实践。在您启动每个历程之前，必须完成此审查流程。\n历程还包含一项测试功能，通过此功能可以轻松地在整个历程中派送一组测试参与者。通过测试您的历程，您可以确保它按您预期的方式运行。\n如果您在历程运行期间遇到相关问题，可以随时停止。当您停止历程时，参与者会暂停他们当前正在进行的活动，并且绝不会继续进行下一个活动。"
    },
    {
        "query":"开发人员如何才能使用 Amazon Pinpoint？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 为开发人员提供了单个 API 层、CLI 支持和客户端软件开发工具包支持，使他们能够扩展其应用程序与用户进行互动的通信渠道。这些渠道包括：电子邮件、SMS 文本消息、推送通知、语音消息和自定义渠道。Amazon Pinpoint 还为开发人员提供了分析系统，以便其跟踪应用程序用户行为和用户参与度。借助这项服务，开发人员可以了解每位用户喜欢的参与方式，还可以打造个性化最终用户体验，从而提高开发人员的应用程序价值。  \n Amazon Pinpoint 还可以帮助开发人员满足多种消息收发使用案例的需求，例如直接或事务型消息收发、有针对性的消息收发或活动消息收发以及基于事件的消息收发。"
    },
    {
        "query":"什么是基于事件的活动？",
        "intention":"知识问答",
        "reply":"基于事件的活动在客户在应用程序中执行特定操作（例如购买或观看视频）时向客户发送消息，例如短信、推送通知、应用程序内消息和电子邮件。例如，您可以设置活动，以便在客户创建新账户或向购物车添加商品但未购买时发送消息。您可以使用 Amazon Pinpoint 控制台或 Amazon Pinpoint API 创建基于事件的活动。基于事件的活动是实施事务性使用案例（如一次性密码和订单确认消息）和有针对性的使用案例（如营销推广活动）的有效方式。您可以选择要用于触发活动的特定事件、属性和指标值，而不是定义要向客户发送消息的时间。有关基于事件的活动的更多信息，请查看此博客文章。"
    },
    {
        "query":"如何开始使用基于事件的活动？",
        "intention":"知识问答",
        "reply":"设置基于事件的活动的第一步是创建新活动。在活动创建流程的第 4 步，您可以选择发送活动消息的时间。您可以选择在特定时间发送活动消息，也可以选择在事件发生时发送消息。选择“事件发生时间”，然后选择触发活动的事件、属性和指标。"
    },
    {
        "query":"什么是自定义事件？",
        "intention":"知识问答",
        "reply":"自定义事件是指您定义的事件指标。这些事件有助于跟踪特定于应用程序或游戏的用户操作。Amazon Pinpoint 事件图表提供有关自定义事件出现频率的视图。您可以根据属性及其关联值筛选自定义事件。\n您可以通过对事件命名（例如“Item Bought”或“Button Pressed”）来创建自定义事件，然后通过指定属性（用于定性测量）和指标（用于定量测量）来添加背景。例如，如果您的业务目标是跟踪应用程序内的物品购买情况，则可以将“Item Bought”用作自定义事件，将“Item XYZ”用作属性，并将“Item Price”用作指标。您可以使用自定义事件报告来搜索与筛选各个属性或指标。例如，您可以查找购买“Item XYZ”的频率或“Item Price”为 1.99 USD 的频率。您还可以查看指标值（每个会话）的加权平均值并跟踪最小、最大或平均指标值。作为一种最佳做法，我们建议自定义事件的名称尽可能宽泛，而属性的名称尽可能具体。"
    },
    {
        "query":"使用自定义事件有哪些好处？",
        "intention":"知识问答",
        "reply":"自定义事件可以帮助您了解用户在使用您的应用程序时执行的操作。例如，游戏开发人员可能想要了解某个关卡的完成频率以及每个玩家到达关卡末尾时的剩余生命值。利用自定义事件，您可以创建一个名为“level\\_complete”、属性为“add\\_level”、属性值为“health”的事件。每次完成一个关卡，您可以记录一个附带关卡名称和玩家生命值的“level\\_complete”事件。通过查看事件图表，您可能发现某个关卡过于简单，因为每个玩家完成关卡时的生命值都处于最高状态。使用此类数据，您可以调整关卡难度，以便更好地挑战并吸引玩家，这样可能会提高用户保留率。\n您还可以使用自定义事件创建基于事件的活动，以便在客户在您的应用程序中执行特定操作时发送消息。例如，您可以设置活动，以便在客户创建新账户、花费一定金额或向购物车添加商品但未购买时发送消息。\n基于事件的活动可以帮助您发送及时、个性化且与客户相关的消息，最终增加他们对品牌的信任度并为他们提供下次再购买的理由。您可以使用 Amazon Pinpoint 控制台或 Amazon Pinpoint API 创建基于事件的活动。"
    },
    {
        "query":"如果单个用户在多个设备上（例如，在手机和平板电脑设备上）使用相同应用程序，Amazon Pinpoint 能否辨别？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 可以辨别终端节点和用户。终端节点是可将消息发送到的目标，例如用户的移动设备、电子邮件地址或手机号码。用户是具有唯一用户 ID 的人员。此 ID 可与最多 10 个终端节点关联。\n一些 Amazon Pinpoint 分析图表报告终端节点，一些报告用户。如需了解有关各个图表的更多信息，请参阅 [Amazon Pinpoint 用户指南](https://docs.aws.amazon.com/pinpoint/latest/userguide/welcome.html)中的“Amazon Pinpoint 分析的图表参考”。"
    },
    {
        "query":"如何定义“会话”？",
        "intention":"知识问答",
        "reply":"应用程序启动（或前台运行）时，会话开始；应用程序终止（或转向后台运行）后，会话结束。考虑到短暂中断的情况，例如文本消息，不超过 5 秒钟的不活动时期不计为新会话。每日会话总数显示您的应用程序每天的会话数量。每个日活跃用户的平均会话数显示每个用户每天的平均会话数量。"
    },
    {
        "query":"Amazon Pinpoint 跟踪标准活动的哪些指标？",
        "intention":"知识问答",
        "reply":"对于标准活动，您可以跟踪一天不同时间发送的消息、传递的消息、送达率、打开率和活动会话。"
    },
    {
        "query":"我可以在何处访问分析数据？",
        "intention":"知识问答",
        "reply":"您可以在 Amazon Pinpoint 控制台中查看分析数据。对于您的每个项目，控制台都提供详细的图表和指标，以便您可以深入了解客户人口统计、应用程序使用情况、购买活动及活动送达率和参与率等方面。您还可以使用 [Amazon Pinpoint API](https://docs.aws.amazon.com/pinpoint/latest/apireference/welcome.html) 以编程方式访问这些指标的子集。"
    },
    {
        "query":"对于我的移动和 Web 应用程序，Amazon Pinpoint 提供什么类型的分析？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 提供几种类型的标准分析，使您能够深入了解应用程序的执行情况。标准分析包括：活跃用户数、用户活动数和人口统计、会话数、用户保留、活动有效性和事务性消息指标。将这些指标与控制台中的分析工具结合使用，您可以通过对某些细分、自定义属性等进行筛选来执行深入分析。"
    },
    {
        "query":"如何定义日保留数量和周保留数量？",
        "intention":"知识问答",
        "reply":"日保留数量是指在某天首次使用您的应用程序，并在之后七天内、十四天内和三十天内返回继续使用应用程序的用户数量，上述时间分别对应 7 日保留数量、14 日保留数量和 30 日保留数量。"
    },
    {
        "query":"什么是“粘性系数”，如何计算它？",
        "intention":"知识问答",
        "reply":"粘性系数表示在特定日期使用应用程序的用户占每月用户的比例。\n通过将日活跃用户 (DAU) 除以月活跃用户 (MAU) 来计算粘性系数。例如，如果应用程序具有 100000 个 DAU 和 300000 个 MAU，则其粘性系数为 0.33。高粘性系数表示极大的参与度、吸引力和盈利机会。"
    },
    {
        "query":"Amazon Pinpoint 中的人口统计是什么？",
        "intention":"知识问答",
        "reply":"人口统计图表提供有关应用程序用户的设备属性信息。您还可以看到您定义的自定义属性。"
    },
    {
        "query":"Amazon Pinpoint 可以将分析数据存储多久？",
        "intention":"知识问答",
        "reply":"Amazon Pinpoint 可以将您的分析数据自动存储 90 天。您可以在控制台中查看您的数据，也可以使用 Amazon Pinpoint API 以编程方式查询数据的子集。要将数据保存更长时间，您可以将数据从控制台中导出为逗号分隔值 (.csv) 文件或将 Amazon Pinpoint 配置为将事件数据流式传输到 Amazon Kinesis 中。Kinesis 是一项可以从其他 AWS 服务中实时收集、处理和分析数据的 AWS 服务。Amazon Pinpoint 可以将事件数据发送至 Kinesis Data Firehose，后者将数据流式传输到 Amazon S3 或 Amazon Redshift 之类的 AWS 数据存储中。Amazon Pinpoint 还可以将数据流式传输到 Kinesis Data Streams 中，后者摄取并存储多个数据流以在分析应用程序中进行处理。"
    },
    {
        "query":"什么是 10DLC？",
        "intention":"知识问答",
        "reply":"10DLC 是一种新标准，用于将消息从 Amazon Pinpoint 等应用程序发送到各个收件人。这种类型的发送称为应用程序对个人 (A2P) 消息收发。您可以使用 10DLC 电话号码，以高吞吐量和高消息传输率向您的客户发送文本消息。\n要想使用 10DLC 号码，您需要根据运营商要求注册与您的公司以及您的使用案例（也称为您的 10DLC活动）相关的信息。您可以直接在 Amazon Pinpoint 控制台中完成此注册过程。在您的公司和 10DLC 活动获得批准后，您可以购买一个电话号码并将其与您的活动关联。"
    },
    {
        "query":"2021 年 6 月 1 日以后，我还能买到美国长代码吗？",
        "intention":"知识问答",
        "reply":"2021 年 6 月 1 日以后，未注册的美国长号码只能用于语音频道。您将不能使用未注册的美国长代码发送短信。\n要发送短信到美国的收件人，您必须使用短代码、10DLC 电话号码或免费电话号码。"
    },
    {
        "query":"我是否应该删除我的 AWS 账户中现有的未注册美国长代码？",
        "intention":"知识问答",
        "reply":"如果您不执行任何操作，未注册的长代码将保留在您的账户中。您将继续为每个未注册的长代码每月支付 1 USD。但是，您将不能使用未注册的美国长代码发送文本消息。\n如果您打算使用未注册的长代码发送语音消息给您的客户，您可以保留它们。如果您想要继续使用未注册的长代码发送文本消息，您也可以[将它们转换为 10DLC 电话号码](https://docs.aws.amazon.com/pinpoint/latest/userguide/settings-associate-long-code-10dlc.html)。\n如果您不想保留未注册的长代码，您可以在 Amazon Pinpoint 控制台中[删除它们](https://docs.aws.amazon.com/pinpoint/latest/userguide/settings-sms-managing.html#settings-account-sms-remove)。"
    },
    {
        "query":"什么是 10DLC 活动？ 创建一个该活动需要提供哪些信息？  需要注意的是，10DLC 活动完全独立于 Amazon Pinpoint 活动。",
        "intention":"知识问答",
        "reply":"10DLC 活动是对您的使用案例的描述。在 10DLC 活动注册过程中，您必须描述使用案例并提供您计划使用的消息模板。有关更多信息，请参阅 *Amazon Pinpoint 用户指南*中的[注册 10DLC 活动](https://docs.aws.amazon.com/pinpoint/latest/userguide/settings-register-campaign-10dlc.html)。"
    },
    {
        "query":"如果我的账户中只有一个 10DLC 电话号码，那么我发送给美国收件人的每一条短信都会使用此号码发送吗？",
        "intention":"知识问答",
        "reply":"是。如果您的账户中只有一个美国电话号码——无论它是 10DLC 号码、短代码，还是免费电话号码——您发送给美国收件人的所有消息都将通过这个号码发送。\n如果您的 Amazon Pinpoint 账户中有多个号码，您可以在调用 Amazon Pinpoint API 时指定您的发起号码。如果您不指定发起号码，Amazon Pinpoint 会查找发送消息的最佳号码。如果您的账户中有一个短代码，Amazon Pinpoint 将使用该号码发送。如果您没有短代码，它会查找 10DLC 电话号码，并尝试使用该号码发送。如果您没有 10DLC 号码，它会查找免费电话号码，并尝试使用该号码发送。"
    },
    {
        "query":"是否存在获取每种 10DLC 活动指标的方法？  Amazon Pinpoint 中的分析控制面板为当前项目提供整体指标。但是，它们不提供特定 10DLC 活动的指标。您可以启用事件流式传输来捕获消息的传输和响应指标。",
        "intention":"知识问答",
        "reply":"您还可以使用[数字用户参与事件数据库解决方案](https://aws.amazon.com/cn/solutions/implementations/digital-user-engagement-events-database/)来创建 SMS 传输指标的可查询数据库。"
    },
    {
        "query":"如果我的发布速率高于 10DLC 活动支持的速率，我是否会收到限制错误？  默认情况下，Amazon Pinpoint 将您可以发送的短信数量限制为每秒钟 20 个。如果您超出此账户级限制，您将收到限制错误。但是，您可以请求增加此限制。",
        "intention":"知识问答",
        "reply":"通过 10DLC，移动运营商在公司和活动注册过程中计算每个发送方的信任分。此信任分[决定了每个运营商将从您那里接受多少消息](https://docs.aws.amazon.com/pinpoint/latest/userguide/settings-10dlc.html#10dlc-capabilities)。如果您超出了某个特定运营商的限制，该运营商就会开始拒绝您的消息。我们强烈建议您[启用事件流式传输](https://docs.aws.amazon.com/pinpoint/latest/userguide/settings-event-streams.html)以跟踪这些事件。"
    },
    {
        "query":"我已在使用 Amazon SNS 或 Amazon Simple Email Service (SES)。切换到 Amazon Pinpoint 可以获得什么？",
        "intention":"知识问答",
        "reply":"在典型的 Amazon SNS 和 Amazon SES 使用案例中，您必须设置应用程序来管理每个消息的受众、内容和发送计划。使用 Amazon Pinpoint，您可以创建消息模板、发送计划，极具针对性的细分以及完整的活动。"
    },
    {
        "query":"Amazon Pinpoint 语音渠道与 Amazon Connect 有何不同？",
        "intention":"知识问答",
        "reply":"借助 Amazon Pinpoint 语音，您可以通过电话发送语音消息，与客户互动。Pinpoint 语音功能为客户提供了一种绝佳方法来发送事务性消息，例如一次性密码、约会提醒、订单确认等。借助 Pinpoint 语音功能，您可以将文本脚本转化为生动的语音，然后再将个性化语音消息发送给客户。呼叫指标（例如呼叫成功完成次数以及呼叫失败次数）可以帮助您优化日后的语音互动。您可以有选择性地使用 Poinpoint 语音和 SMS 渠道，以便向喜欢文本消息的客户发送 SMS 消息，向不能接收 SMS 消息的客户发送语音消息。增加语音渠道后，您现在可以使用 Amazon Pinpoint 通过推送通知、电子邮件、SMS 和语音呼叫及时向客户发送相关内容，实现无缝互动。\nAmazon Connect 是一项易于使用的全渠道云联络中心服务，可帮助企业以更低的成本提供卓越的客户服务。十多年前，Amazon 的零售业务需要一个联络中心，以便为我们的客户提供贴心、动态和自然的体验。但我们没能找到符合我们需求的联络中心，因此我们自己建设了一个。现在，我们面向所有企业提供这项服务，如今已有成千上万的企业每天都在使用这项服务，这些企业使用的代理数量从十个到上万个不等。要了解更多信息，请参阅 [Amazon Connect](https://aws.amazon.com/cn/connect/)。"
    },
    {
        "query":"Amazon Pinpoint 是否会存储我的客户数据？",
        "intention":"知识问答",
        "reply":"会。Amazon Pinpoint 会存储用户、终端节点和事件数据。我们必须保留此数据，以便您可以创建细分、向接收者发送消息以及捕获应用程序和活动参与度数据。"
    },
    {
        "query":"谁可以访问存储在 Amazon Pinpoint 中的数据？",
        "intention":"知识问答",
        "reply":"只有极少数授权 AWS 员工可以访问存储在您的 Amazon Pinpoint 账户中的数据。维系您的信任是我们的首要任务。我们使用先进的物理和技术控制措施来帮助保护您的隐私并确保您的数据的安全性。系统会对您的数据进行静态和动态加密。我们的流程旨在防止未经授权地访问或披露您的内容。\n有关更多信息，请参阅 [AWS 数据隐私常见问题](https://aws.amazon.com/cn/pinpoint/data-privacy-compliance-faq/)。"
    },
    {
        "query":"由 Amazon Pinpoint 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您的内容的所有权始终归您所有。我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"如何删除 Amazon Pinpoint 存储的数据？",
        "intention":"知识问答",
        "reply":"您可以选择性地删除存储在 Amazon Pinpoint 账户中的数据。您还可以关闭整个 AWS 账户，该账户将删除存储在 Amazon Pinpoint 中的所有数据以及每个 AWS 区域中的所有其他 AWS 服务。有关更多信息，请参阅 [Amazon Pinpoint 开发人员指南](https://docs.aws.amazon.com/pinpoint/latest/developerguide/welcome.html)中的“从 Amazon Pinpoint 中删除数据”。"
    },
    {
        "query":"我收到了 Amazon Pinpoint 用户发送的垃圾邮件或其他未经请求的电子邮件。如何举报这些邮件？",
        "intention":"知识问答",
        "reply":"您可以通过向 [email-abuse@amazon.com](mailto:email-abuse@amazon.com) 发送电子邮件来举报滥用电子邮件的情况。\n为了帮助我们尽快有效地处理问题，请包含原始电子邮件的完整标头。有关获取多个常见电子邮件客户端的电子邮件标头的过程，请参阅 [MxToolbox.com](https://MxToolbox.com) 网站上的“如何获取电子邮件标头”。"
    },
    {
        "query":"如何提交功能请求或发送有关 Amazon Pinpoint 的其他产品反馈？",
        "intention":"知识问答",
        "reply":"您的 AWS 客户经理可以将您的功能请求和反馈直接发送给相应的团队。如果您目前没有 AWS 客户经理，您也可以在 Amazon Pinpoint 论坛上提供反馈。"
    },
    {
        "query":"如何获得 Amazon Pinpoint 的技术支持？",
        "intention":"知识问答",
        "reply":"如果您有 AWS Support 计划，可以直接通过基于 Web 的 AWS 管理控制台创建新的支持案例。AWS Support 计划的起价为每月 29 USD。有关 AWS Support 计划的更多信息，请访问 <https://aws.amazon.com/premiumsupport/>。\n要创建新的技术支持案例，请执行以下操作：\n如果您没有 AWS Support 计划，您也可以在 Amazon Pinpoint 论坛上提出问题并获得答案。"
    },
    {
        "query":"什么是 AWS DataSync？",
        "intention":"知识问答",
        "reply":"AWS DataSync 是一项在线数据移动和发现服务，可简化和加速向 AWS 的数据迁移，以及在本地存储、边缘站点、其他云和 AWS 存储之间移动数据。  \n   \n AWS DataSync Discovery 通过让您了解本地存储性能和利用率，并提供将数据迁移到 AWS 存储服务的建议，帮助您简化迁移规划并加快向 AWS 的数据迁移。DataSync Discovery 使您能够通过自动数据收集和分析更好地了解您的本地存储性能和容量使用情况，从而能够快速识别要迁移的数据，并使用生成的建议来选择符合您的性能和容量需求的 AWS 存储服务。\n对于在线数据传输，AWS DataSync 可简化、自动化和加速本地存储、边缘站点或其他云与 AWS 存储服务之间以及不同 AWS 存储服务之间的大量数据复制。DataSync 可以在 Network File System (NFS) 共享、服务器消息块 (SMB) 共享、Hadoop Distributed File System (HDFS)、自行管理的对象存储、Google Cloud Storage、Azure Files、Azure Blob Storage（包括 Azure Data Lake Storage Gen2 [预览版]）、[AWS Snowcone](https://aws.amazon.com/cn/snowcone/)、Snow 上的 Amazon S3 兼容存储、Amazon Simple Storage Service ([Amazon S3](https://aws.amazon.com/cn/s3/))、Amazon Elastic File System ([Amazon EFS](https://aws.amazon.com/cn/efs/)) 文件系统、[Amazon FSx for Windows File Server](https://aws.amazon.com/cn/fsx/windows/) 文件系统、[Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/ \"Amazon FSx for Lustre\") 文件系统、[Amazon FSx for OpenZFS](https://aws.amazon.com/fsx/openzfs/ \"Amazon FSx for OpenZFS\") 文件系统和 [Amazon FSx for NetApp ONTAP](https://aws.amazon.com/cn/fsx/netapp-ontap/) 文件系统之间复制数据。"
    },
    {
        "query":"为什么应该使用 AWS DataSync？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使您能够安全、快速地发现和移动数据。使用 DataSync Discovery，您可以更好地了解本地存储利用率和接收建议，以告知您的成本估算和迁移到 AWS 的计划。如需数据移动，您可以使用 DataSync 复制包含数百万文件的大型数据集，而无需使用开源工具构建自定义解决方案，也无需许可和管理价格高昂的商业网络加速软件。您可以使用 DataSync 将现用数据集迁移到 AWS，将数据传输到云进行分析和处理，还可以存档数据以释放本地存储容量，或者将数据复制到 AWS 以实现业务连续性。"
    },
    {
        "query":"AWS DataSync Discovery 可以为我解决哪些问题？",
        "intention":"知识问答",
        "reply":"AWS DataSync Discovery 简化并加快了向 AWS 的数据迁移。使用 DataSync Discovery，您可以自动收集有关本地存储系统的数据并在 DataSync 控制台中查看汇总结果。DataSync Discovery 从收集的数据中分析性能、容量和利用率，并建议使用 AWS 存储服务进行迁移。使用 DataSync Discovery，您可以更好地了解本地存储利用率，快速识别要迁移的数据，并选择满足您的性能需求并优化存储成本的 AWS 存储服务。"
    },
    {
        "query":"AWS DataSync 可以为我解决哪些问题？",
        "intention":"知识问答",
        "reply":"AWS DataSync 可降低在线数据传输的复杂性和成本，从而简化本地、边缘或其他云存储与 AWS 存储服务之间以及 AWS 存储服务之间的数据集传输。DataSync 以 HDFS 客户的身份使用标准存储协议（NFS、SMB）、使用 Amazon S3 API 或使用其他云存储 API 连接现有的存储系统和数据来源。它使用专用网络协议和扩展架构，以加速存储系统与 AWS 服务之间的数据传输。DataSync 可自动扩展并处理以下任务：移动文件和对象、计划数据传输、监控传输进度、加密、验证数据传输并在出现问题时通知客户。使用 DataSync 时，您只需为复制的数据量付费，无需最低消费承诺或预付费用。"
    },
    {
        "query":"如何使用 AWS DataSync 将数据迁移到 AWS？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS DataSync 将位于本地、边缘或其他云中的数据迁移到 Amazon S3、Amazon EFS、Amazon FSx for Windows File Server、Amazon FSx for Lustre、Amazon FSx for OpenZFS 和 Amazon FSx for NetApp ONTAP。配置 DataSync 以生成整个数据集的初始副本，并计划更改数据的后续增量传输，直到完成从本地到 AWS 的最后切换。DataSync 包括加密和完整性验证，有助于确保数据安全到达、完好无损且可随时使用。为了将对依赖于您网络连接的工作负载的影响降到最低，您可以将迁移安排在非工作时间运行，或通过配置内置带宽限制来限制 DataSync 使用的网络带宽量。 DataSync 保留具有相似元数据结构的存储系统之间的元数据，以支持最终用户和应用程序平稳过渡到使用目标 AWS 存储服务。阅读存储博客“[使用 AWS DataSync 迁移存储](https://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/)”，了解有关迁移最佳实践和提示的更多信息。"
    },
    {
        "query":"如何使用 AWS DataSync 存档冷数据？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS DataSync 将冷数据直接从本地存储系统移动到持久且安全的长期存储空间，例如 [Amazon S3 Glacier Flexible Retrieval](https://aws.amazon.com/s3/storage-classes/glacier/)（原 S3 Glacier）或 [Amazon S3 Glacier Deep Archive](https://aws.amazon.com/s3/storage-classes/glacier/)。使用 [DataSync 的筛选功能](https://aws.amazon.com/blogs/storage/excluding-and-including-specific-data-in-transfer-tasks-using-aws-datasync-filters/)将临时文件和文件夹排除在复制范围外，或仅复制源位置的文件子集。您可以根据需求选择最具成本效益的存储服务：将数据传输到任何 [S3 存储类](https://aws.amazon.com/cn/s3/storage-classes/)，或组合使用 DataSync 和 EFS 生命周期管理将数据存储在 [Amazon EFS 不频繁访问存储类 (EFS IA)](https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html) 中。使用内置的任务计划功能定期存档应保留的数据，以满足合规性或审计目的，例如日志、原始影像或电子版医疗记录。"
    },
    {
        "query":"如何使用 AWS DataSync 将数据复制到 AWS 以实现业务连续性？",
        "intention":"知识问答",
        "reply":"利用 AWS DataSync，您可以定期将文件复制到 Amazon S3 存储类中，或针对备用文件系统将数据发送到 Amazon EFS、Amazon FSx for Windows File Server、Amazon FSx for Lustre、Amazon FSx for OpenZFS 或 Amazon FSx for NetApp ONTAP。使用内置的任务计划功能，确保对数据集的更改可定期复制到您的目标存储中。阅读这篇 AWS 存储博客， [了解有关使用 AWS DataSync 进行数据保护的更多信息](https://aws.amazon.com/blogs/storage/protect-your-file-and-backup-archives-using-aws-datasync-and-amazon-s3-glacier/)。"
    },
    {
        "query":"如何将 AWS DataSync 用于持续工作流程的本地和 AWS 之间的重复传输？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS DataSync 将本地系统中的数据持续传入或传出 AWS 以进行处理。DataSync 可以帮助需要将现用文件快速移动到 AWS 的行业加快关键混合云存储工作流程。这包括在生命科学领域的机器学习、媒体和娱乐领域的视频制作、金融服务领域的大数据分析以及石油天然气领域的地震研究。DataSync 有助于实现及时交付以确保不会延迟相关流程。您可以指定[排除筛选条件和/或包含筛选条件](https://aws.amazon.com/blogs/storage/excluding-and-including-specific-data-in-transfer-tasks-using-aws-datasync-filters/)，以确定每次运行任务时传输的文件、文件夹或对象。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 将来自其他公有云的数据复制到 AWS？",
        "intention":"知识问答",
        "reply":"可以。借助 AWS DataSync，您可以使用 Amazon S3 API 从 Google Cloud Storage 复制数据，[使用 SMB 协议从 Azure Files](https://aws-blogs-prod.amazon.com/storage/how-to-move-data-from-azure-files-smb-shares-to-aws-using-aws-datasync/) 复制数据。在您的云环境中或 Amazon EC2 上部署 DataSync 代理，然后创建源和目标位置，即可启动任务以开始复制数据。[详细了解](https://aws-blogs-prod.amazon.com/storage/how-to-move-data-from-azure-files-smb-shares-to-aws-using-aws-datasync/)适用于混合和多云环境的 AWS 解决方案。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 构建数据湖？",
        "intention":"知识问答",
        "reply":"可以。借助 AWS DataSync，您可以将本地数据集或其他云中的数据自动传输到 Amazon S3，进而轻松构建数据湖。DataSync 支持以 HDFS 客户端的身份使用标准存储协议（NFS 或 SMB）、使用 Amazon S3 API 或使用其他云存储 API 简单快速地传输整个数据集。初始数据集传输完毕之后，可以安排新数据到 AWS 的后续传输。DataSync 包含加密和完整性验证功能，可帮助确保数据安全到达、完好无损且可随时使用。为了将对依赖于您网络连接的工作负载的影响降到最低，您可以将传输任务安排在非工作时间运行，或通过配置内置带宽限制来限制 DataSync 使用的网络带宽量。将数据传输到 Amazon S3 后，您就可以使用原生 AWS 服务运行大数据分析、人工智能 (AI)、机器学习 (ML)、高性能计算 (HPC) 和媒体数据处理应用程序，以便从非结构化数据集中获得洞察信息。 阅读 [AWS 湖内数仓存储网页](https://aws.amazon.com/cn/products/storage/data-lake-storage/)了解有关构建和利用湖内数仓的更多信息。"
    },
    {
        "query":"如何使用 AWS DataSync 在 AWS 存储服务之间传输数据？",
        "intention":"知识问答",
        "reply":"您可以使用 DataSync 在同一个 AWS 账户内的 Amazon S3、Amazon EFS、Amazon FSx for Windows File Server、Amazon FSx for Lustre、Amazon FSx for OpenZFS 或 Amazon FSx for NetApp ONTAP 之间传输文件或对象。您可以在同一个 AWS 区域中的 AWS 服务之间，除中国以外的不同商业 AWS 区域的服务之间或 AWS GovCloud（美国东部和美国西部）区域之间传输数据。此过程不需要部署 DataSync 代理，并且可以使用 AWS DataSync 控制台、AWS 命令行界面 (CLI) 或 AWS 软件开发工具包 (SDK) 进行端到端配置。"
    },
    {
        "query":"我是否能使用 AWS DataSync 迁移到 Amazon WorkDocs？",
        "intention":"知识问答",
        "reply":"可以。AWS DataSync 通过[自动执行文件到用于迁移的 Amazon S3 存储桶的上传](https://docs.aws.amazon.com/workdocs/latest/adminguide/s3-upload.html)加快 Amazon WorkDocs 迁移服务的所需步骤。DataSync 使您可以更加轻松快速地将主目录和部门共享内容迁移到 WorkDocs。 要了解有关使用 DataSync 迁移到 WorkDocs 的更多信息，请阅读博客“[使用 AWS DataSync 将网络共享文件迁移到 Amazon WorkDocs](https://aws.amazon.com/blogs/storage/migrating-network-file-shares-to-amazon-workdocs-using-aws-datasync/)”。"
    },
    {
        "query":"如何开始使用 AWS DataSync 迁移我的数据？",
        "intention":"知识问答",
        "reply":"您可以在 [AWS 管理控制台](https://docs.aws.amazon.com/datasync/latest/userguide/getting-started.html)中单击几下或通过 [AWS Command Line Interface（CLI）](https://docs.aws.amazon.com/datasync/latest/userguide/using-cli.html)，使用 AWS DataSync 传输数据。要开始使用，请执行下列 3 个步骤：\n1.要在本地、边缘或其他云存储系统与 AWS 存储服务之间传输数据，请部署代理 – 部署 DataSync 代理并通过管理控制台或 API 将该代理与您的 AWS 账户关联。代理将用于访问您的 NFS 服务器、SMB 文件共享、Hadoop 集群或自行管理的或云对象存储，以从中读取数据或向其写入数据。 在同一个 AWS 账户的 AWS 存储服务之间传输数据不需要部署代理。\n2.创建数据传输任务 – 通过指定您的数据源位置和目标位置以及您要用于配置传输的任何选项（如所需的任务计划）来创建任务。\n3.开始传输 – 启动任务并在控制台中或使用 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/) 监控数据移动。"
    },
    {
        "query":"如何部署 AWS DataSync 代理？",
        "intention":"知识问答",
        "reply":"您可以将 AWS DataSync 代理部署到本地监控程序、公有云环境或 [Amazon EC2](https://aws.amazon.com/cn/ec2/) 中。要将数据复制到本地文件服务器或从中复制数据，请从 AWS 管理控制台或 Snow 上的 Amazon S3 兼容存储下载代理虚拟机镜像，并将其部署到本地 VMware ESXi、Linux 基于内核的虚拟机 (KVM) 或 Microsoft Hyper-V 监控程序中。必须部署代理，以便其可以使用 NFS、SMB 协议访问您的文件服务器，访问您的 Hadoop 集群中的 NameNodes 和 DataNodes，或者使用[Amazon S3 API](https://docs.aws.amazon.com/AmazonS3/latest/API/Type_API_Reference.html \"Amazon S3 API\") 访问您的对象存储。 要设置您的 S3 on AWS Outposts 存储桶与 AWS 区域中的 S3 存储桶之间的传输，[请在 Outpost 上部署代理](https://docs.aws.amazon.com/datasync/latest/userguide/deploy-agents.html#outposts-agent)。要在 AWS Snowcone 设备和 AWS 存储之间设置传输，请使用[设备上预装的 DataSync 代理 AMI](https://docs.aws.amazon.com/datasync/latest/userguide/deploy-agents.html#snowcone-agent)。\n在公有云环境和 AWS 存储之间复制数据时，您可以在您的云环境中部署 DataSync 代理，也可以在 Amazon EC2 上部署 DataSync 代理。由于 AWS DataSync 会压缩在 AWS DataSync 代理和 AWS 存储服务之间传输的数据，因此您可以通过在公有云环境中部署 AWS DataSync 代理来降低出站费用。\n在同一个 AWS 账户的 AWS 存储服务之间传输数据不需要部署代理。要将数据复制到自行管理的云内文件服务器或从中复制数据，或在不同 AWS 账户中的 AWS 存储服务之间复制数据，您可以使用 DataSync 代理 AMI 启动 Amazon EC2 实例。"
    },
    {
        "query":"AWS DataSync 代理的资源要求是什么？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/datasync/latest/userguide/agent-requirements.html)查找运行代理所需的最少资源。"
    },
    {
        "query":"我如何启动 AWS DataSync 数据传输任务？",
        "intention":"知识问答",
        "reply":"当您通过 [AWS 管理控制台](https://docs.aws.amazon.com/datasync/latest/userguide/getting-started.html)或 [AWS 命令行界面 (CLI)](https://docs.aws.amazon.com/datasync/latest/userguide/using-cli.html) 启动任务时，AWS DataSync 将复制数据。每次任务运行时，它都将扫描源和目标是否存在更改，并复制源与目标之间的任何数据和元数据差异。您可以配置源的哪些特性用于确定更改的内容，定义[要包括和排除特定文件或文件夹的筛选条件](https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html)，以及控制是否应在源发生更改时覆盖目标中的文件或对象，或在源中找不到时删除它们。"
    },
    {
        "query":"AWS DataSync 如何确保正确复制数据？",
        "intention":"知识问答",
        "reply":"当 AWS DataSync 传输和存储数据时，它将执行完整性检查，以确保写入目标的数据与从源读取的数据相匹配。此外，可以选择性地执行验证检查来在传输结束时对比源和目标。 DataSync 将计算和对比源和目标中存储的数据的完整文件校验和。您可以检查整个数据集或仅检查 DataSync 传输的文件或对象。"
    },
    {
        "query":"如何监控 AWS DataSync 正在传输的数据的状态？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或 CLI 来监控正在传输的数据的状态。利用 Amazon CloudWatch 指标，您可以查看[已复制的文件数和数据量](https://docs.aws.amazon.com/datasync/latest/userguide/monitor-datasync.html#metrics)。 [将单个文件记录到 CloudWatch Logs](https://docs.aws.amazon.com/datasync/latest/userguide/create-task.html) 使您能够识别在给定时间传输的内容，以及 DataSync 执行的内容完整性验证结果。这简化了监控、报告和故障排查过程，并且让您能够为利益相关者提供及时的更新。您可以在 AWS 管理控制台或 CLI 中找到其他信息（如传输进度）。"
    },
    {
        "query":"是否可以筛选 AWS DataSync 传输的文件和文件夹？",
        "intention":"知识问答",
        "reply":"是的。您可以指定排除筛选条件和/或包含筛选条件，以限制每次运行任务时传输的文件、文件夹或对象。包含筛选条件指定在任务运行时应包含的文件路径或对象密钥，并限制 DataSync 在源和目标上扫描的范围。排除筛选条件指定应从复制中排除的文件路径或对象密钥。如果没有配置筛选条件，则每次运行任务时，AWS DataSync 都会将所有更改从源传输到目标位置。创建或更新任务时，您可以配置排除和包含筛选条件。启动任务时，您可以覆盖在任务上配置的筛选条件。请阅读这篇 [AWS 存储博客，详细了解如何将常见筛选条件与 DataSync 结合使用](https://aws.amazon.com/blogs/storage/excluding-and-including-specific-data-in-transfer-tasks-using-aws-datasync-filters/)，了解更多详情。"
    },
    {
        "query":"是否可以配置 AWS DataSync 以按计划进行传输？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 控制台或 AWS 命令行界面 (CLI) 来计划任务，而不必编写和运行脚本来管理重复的传输。任务计划会根据您配置的计划按照控制台中直接提供的每小时、每天或每周选项来自动运行任务。这能够帮助您确保您数据集的更改会自动被检测并复制到您的目标存储中。"
    },
    {
        "query":"AWS DataSync 在复制文件时能否保留目录结构？",
        "intention":"知识问答",
        "reply":"符合。在传输文件时，AWS DataSync 在目标位置创建与源位置中的结构相同的目录结构。"
    },
    {
        "query":"如果 AWS DataSync 任务中断，会发生什么情况？",
        "intention":"知识问答",
        "reply":"如果任务中断（例如，如果网络连接断开或 AWS DataSync 代理重新启动），则将在下次运行任务时传输缺失的文件，并且数据将在此运行结束时保持完整性和一致性。每次启动任务时，它都将执行增量复制，仅向目标传输源中所做的更改。"
    },
    {
        "query":"我能否将 AWS DataSync 与 AWS Direct Connect 结合使用？",
        "intention":"知识问答",
        "reply":"您可以将 AWS DataSync 与 Direct Connect 链接结合使用，以访问公有服务端点或[私有 VPC 端点](https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html)。使用 VPC 端点时，在 DataSync 代理和 AWS 服务之间传输的数据不需要访问公有互联网，也不需要公有 IP 地址，这增加了在网络上复制数据时的安全性。 DataSync Discovery 目前仅支持公有服务端点。"
    },
    {
        "query":"AWS DataSync 是否支持 VPC 端点或 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"是的，数据移动用例支持 VPC 端点。您可以[使用 VPC 端点](https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html)来确保在本地或云中部署的 AWS DataSync 代理之间传输的数据不会访问公有互联网或需要公有 IP 地址。使用 VPC 端点在 [Amazon Virtual Private Cloud（Amazon VPC）](https://aws.amazon.com/cn/vpc/)中保持网络流量，从而提高数据的安全性。 适用于 DataSync 的 VPC 端点由高度可用的可扩展技术 [AWS PrivateLink](https://aws.amazon.com/cn/privatelink/) 提供支持，允许您将 VPC 私密连接到受支持的 AWS 服务。"
    },
    {
        "query":"如何配置 AWS DataSync 来使用 VPC 终端节点？",
        "intention":"知识问答",
        "reply":"要将 VPC 终端节点与 AWS DataSync 结合使用，您可以在选择的 VPC 中为 DataSync 服务创建一个 [AWS PrivateLink](https://aws.amazon.com/cn/privatelink/) 接口 VPC 终端节点，然后在创建 DataSync 代理时选择此终端节点弹性网络接口 (ENI)。您的代理将连接到此 ENI 以激活，随后由该代理传输的所有数据都将保持在您配置的 VPC 中。您可以使用 [AWS DataSync 控制台](https://console.aws.amazon.com/datasync/home)、AWS 命令行界面 (CLI) 或 AWS 开发工具包配置 VPC 终端节点。要了解更多信息，请参阅 [在 Virtual Private Cloud 中使用 AWS DataSync](https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html)。"
    },
    {
        "query":"AWS DataSync 支持哪些 AWS 存储服务？",
        "intention":"知识问答",
        "reply":"AWS DataSync 支持将数据移入、移出或在 Amazon Simple Storage Service[（Amazon S3）](https://aws.amazon.com/s3/)、Amazon Elastic File System [（Amazon EFS）](https://aws.amazon.com/efs/)、[Amazon FSx for Windows File Server](https://aws.amazon.com/fsx/windows/)、[Amazon FSx for Lustre](https://aws.amazon.com/fsx/lustre/)、[Amazon FSx for OpenZFS](https://aws.amazon.com/fsx/openzfs/) 和 [Amazon FSx for NetApp ONTAP 之间移动。](https://aws.amazon.com/fsx/netapp-ontap/)"
    },
    {
        "query":"是否可以将我的数据复制到 Amazon S3 Glacier Flexible Retrieval（原 S3 Glacier）、Amazon S3 Glacier Deep Archive 或其他 S3 存储类？",
        "intention":"知识问答",
        "reply":"是。将 S3 存储桶配置为用于 AWS DataSync 时，您可以选择 DataSync 用于存储对象的 S3 存储类。DataSync 支持将数据直接存储到 S3 标准、S3 智能分层、S3 Standard-Infrequent Access (S3 Standard-IA)、S3 Standard-Infrequent Access (S3 Standard-IA)、Amazon S3 Glacier Flexible Retrieval 和 Amazon S3 Glacier Deep Archive (S3 Glacier Deep Archive) 中。有关 [Amazon S3 存储类](https://aws.amazon.com/cn/s3/storage-classes/)的更多信息，请参阅 [Amazon Simple Storage Service 开发人员指南](https://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html)。\n比每个对象的最小收费容量小的对象将存储在 S3 Standard 中。例如，大小为零字节且只保存元数据的文件夹对象将存储在 S3 Standard 中。在我们的文档中阅读[使用 Amazon S3 存储类的](https://docs.aws.amazon.com/datasync/latest/userguide/create-s3-location.html#using-storage-classes)注意事项，有关最低收费容量的更多信息，请参阅 [Amazon S3 定价](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"AWS DataSync 如何将文件和文件夹转换为 Amazon S3 中的对象或从中转换文件和文件夹？  答：将文件或文件夹复制到 Amazon S3 时，文件或文件夹与对象之间存在一对一关系。文件和文件夹时间戳和 POSIX 权限，包括用户 ID、组 ID 和权限，均存储在 S3 用户元数据中。对于 NFS 共享，存储在 S3 用户元数据中的文件元数据可与文件网关完全互操作，从而提供对 AWS DataSync 存储在 Amazon S3 中的数据的本地文件访问。",
        "intention":"知识问答",
        "reply":"当 DataSync 将包含此用户元数据的对象复制回 NFS 服务器时，系统将恢复文件元数据。从 NFS 复制回 S3 时，符号链接和硬链接也会存储。\n从 SMB 文件共享复制时，默认 POSIX 权限存储在 S3 用户元数据中。当复制回 SMB 文件共享时，所有权将根据在 DataSync 中配置以访问该文件共享的用户进行设置，并且分配默认权限。\n从 HDFS 复制时，文件和文件夹时间戳、用户和组所有权以及 POSIX 权限都存储在 S3 用户元数据中。从 Amazon S3 复制回 HDFS 时，将存储文件和文件夹元数据。\n在我们的文档中了解有关 [DataSync 如何存储文件和元数据](https://docs.aws.amazon.com/datasync/latest/userguide/special-files.html)的更多信息。"
    },
    {
        "query":"在自行管理的对象存储或 Azure Blob Storage（预览版）与 Amazon S3 之间传输对象时，会保留哪些对象元数据？",
        "intention":"知识问答",
        "reply":"在自行管理的对象存储或 Azure Blob Storage（预览版）与 Amazon S3 之间传输对象时，DataSync 会将对象与对象元数据和标签一起复制。"
    },
    {
        "query":"在 Amazon S3 存储桶之间传输对象时，会保留哪些对象元数据？",
        "intention":"知识问答",
        "reply":"在 Amazon S3 存储桶之间传输对象时，DataSync 会将对象与对象元数据和标签一起复制。DataSync 不会复制其他对象信息，如对象 ACL 或以前的对象版本。"
    },
    {
        "query":"我是否可以在 AWS Outposts 上向 Amazon S3 存储桶中复制对象数据以及从中复制数据？  答：可以。您可以在 AWS Outposts 上的 Amazon S3 和 AWS 区域中的 Amazon S3 存储桶之间复制对象。AWS DataSync 复制对象以及对象元数据和对象标签。为了使 DataSync 能够访问 Outposts 存储桶上的 Amazon S3，请在 Outpost 上部署 DataSync EC2 代理。",
        "intention":"知识问答",
        "reply":"将 DataSync 与 Outposts 上的 Amazon S3 结合使用时，仅可从 AWS 区域中的 Amazon S3 存储桶传出或向其中传入数据。您可以在我们的[文档](https://docs.aws.amazon.com/datasync/latest/userguide/working-with-locations.html)中了解有关 DataSync 任务的受支持的来源和目标的更多信息。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Amazon EFS 文件系统？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用 NFS 协议访问您的 Amazon EFS 文件系统。DataSync 服务通过其托管的弹性网络接口 (ENI) 在 VPC 中挂载您的文件系统。DataSync 代表您完全管理这些 ENI 的创建、使用和删除。 您可以选择使用挂载目标或 [EFS 接入点](https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html)挂载自己的 EFS 文件系统。"
    },
    {
        "query":"是否可以将 AWS DataSync 与所有 Amazon EFS 存储类一起使用？",
        "intention":"知识问答",
        "reply":"能。您可以使用 AWS DataSync 将文件复制到 Amazon EFS 中，还可以将 [EFS 生命周期管理](https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html)配置为将一段时期内未访问的文件迁移到不频繁访问（IA）存储类。"
    },
    {
        "query":"如何共用 AWS DataSync 与 Amazon EFS 文件系统资源策略？",
        "intention":"知识问答",
        "reply":"您可以同时使用 IAM 身份策略和资源策略，以可扩展且针对云环境优化的方式控制客户端对 Amazon EFS 资源的访问。当您为 EFS 文件系统创建 DataSync 位置时，可以指定访问 EFS 时 DataSync 将代入的 IAM 角色。然后，您可以使用 [EFS 文件系统策略](https://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html)配置对该 IAM 角色的访问。由于 DataSync 作为根用户挂载 EFS 文件系统，因此您的 IAM 策略必须允许下列操作：elasticfilesystem:ClientRootAccess。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 将我的 Amazon EFS 文件系统复制到另一个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"是。除了 Amazon EFS 提供的内置[复制](https://docs.aws.amazon.com/efs/latest/ug/efs-replication.html)功能，您还可以使用 AWS DataSync 将您的 Amazon EFS 文件系统定期复制计划到同一个 AWS 账户内的第二个 Amazon EFS 文件系统中。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Amazon FSx for Windows File Server 文件系统？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用 SMB 协议访问您的 [Amazon FSx for Windows File Server](https://aws.amazon.com/cn/fsx/windows/) 文件系统，通过您在 AWS 管理控制台或 CLI 中配置的用户名和密码进行身份验证。DataSync 服务通过其托管的弹性网络接口（ENI）在 VPC 中挂载您的文件系统。DataSync 代表您完全管理这些 ENI 的创建、使用和删除。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 将我的 Amazon FSx for Windows File Server 文件系统复制到另一个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将您的 Amazon FSx for Windows File Server 文件系统定期复制计划到同一个 AWS 账户内的第二个文件系统中。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Amazon FSx for Lustre 文件系统？",
        "intention":"知识问答",
        "reply":"当您创建 DataSync 任务以向 FSx for Lustre 文件系统进行复制或从中进行复制时，DataSync 服务将在您的文件系统所处的相同 VPC 和子网中创建弹性网络接口(ENI)。  DataSync 使用这些 ENI 在将 Lustre 协议用作根用户的情况下访问您的 FSx for Lustre 文件系统。  当您为 FSx for Lustre 文件系统创建 DataSync 位置资源时，您最多可以指定五个安全组应用于 ENI，并从 DataSync 服务配置出站访问。  必须将安全组配置为允许 FSx for Lustre 所需的 [网络端口上的出站流量](https://docs.aws.amazon.com/fsx/latest/LustreGuide/limit-access-security-groups.html \"AWS 文档\")。  FSx for Lustre 文件系统上的安全组应被配置为允许从您分配给 FSx for Lustre 文件系统的 DataSync 位置资源的安全组进行入站访问。"
    },
    {
        "query":"我是否能够使用 AWS DataSync 将数据从一个 FSx for Lustre 文件系统迁移到另一个？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将数据从您的 FSx for Lustre 文件系统复制到同一个 AWS 账户内的另一个文件系统。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 将我的 Amazon FSx for Lustre 文件系统复制到另一个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将您的 Amazon FSx for Lustre 文件系统定期复制计划到同一个 AWS 账户内的另一个文件系统中。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"从一个 Amazon FSx for Lustre 文件系统复制到另一个文件系统时，DataSync 是否会复制分段或布局设置？",
        "intention":"知识问答",
        "reply":"否。使用目标文件系统上的文件布局和分段配置写入文件。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Amazon FSx for OpenZFS 文件系统？",
        "intention":"知识问答",
        "reply":"当您创建 DataSync 任务以向 FSx for OpenZFS 文件系统进行复制或从中进行复制时，DataSync 服务将在您的文件系统所处的相同 VPC 和子网中创建弹性网络接口 (ENI)。  DataSync 使用这些 ENI 在将 OpenZFS 协议用作根用户的情况下访问您的 FSx for OpenZFS 文件系统。  当您为 FSx for OpenZFS 文件系统创建 DataSync 位置资源时，您最多可以指定五个安全组应用于 ENI，并从 DataSync 服务配置出站访问。  必须将安全组配置为允许 FSx for OpenZFS 所需的 [网络端口上的出站流量](https://docs.aws.amazon.com/datasync/latest/userguide/what-is-datasync.html \"AWS 文档\")。 FSx for OpenZFS 文件系统上的安全组应被配置为允许从您分配给 FSx for OpenZFS 文件系统的 DataSync 位置资源的安全组进行入站访问。"
    },
    {
        "query":"我是否能够使用 AWS DataSync 将数据从一个 FSx for OpenZFS 文件系统迁移到另一个？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将数据从您的 FSx for OpenZFS 文件系统复制到同一个 AWS 账户内的另一个文件系统。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"我是否可以使用 AWS DataSync 将我的 Amazon FSx for OpenZFS 文件系统复制到另一个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将您的 Amazon FSx for OpenZFS 文件系统定期复制计划到同一个 AWS 账户内的另一个文件系统中。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Amazon FSx for Netapp ONTAP 文件系统？",
        "intention":"知识问答",
        "reply":"当您创建任务时，DataSync 会在您的 [Amazon FSx for NetApp ONTAP](https://aws.amazon.com/cn/fsx/netapp-ontap/) 文件系统所在相同 VPC 的首选子网中创建弹性网络接口（ENI）。首选子网会在您创建 FSx for ONTAP 文件系统时配置，而 DataSync 会利用它在该子网中创建的 ENI 来访问您的 FSx for ONTAP 文件系统。当您为 FSx for ONTAP 文件系统创建 DataSync 位置资源时，您最多可以指定 5 个安全组应用于 ENI，以便配置 DataSync 服务的出站访问。您应该在 FSx for ONTAP 文件系统上配置安全组，以允许从您分配给 FSx for ONTAP 文件系统的 DataSync 位置资源的安全组进行入站访问。"
    },
    {
        "query":"AWS DataSync 可搭配使用哪些协议版本和 Amazon FSx for NetApp ONTAP？",
        "intention":"知识问答",
        "reply":"AWS DataSync 支持使用 NFSv3、SMB 2.1 和 SMB 3。DataSync 目前不支持 NFSv4 或更高版本和 FSx for ONTAP 搭配使用。"
    },
    {
        "query":"在复制数据到我的 Amazon FSx for NetApp ONTAP 文件系统或从其中将数据复制出来时，AWS DataSync 会保留文件系统元数据吗？",
        "intention":"知识问答",
        "reply":"会，当使用 NFS 协议时，AWS DataSync 会复制文件和文件夹时间戳和 POSIX 权限，包括用户 ID、组 ID 和权限。而在使用 SMB 协议时，DataSync 则会复制文件和文件夹时间戳、所有权和 ACL。您可以在我们的[文档](https://docs.aws.amazon.com/datasync/latest/userguide/special-files.html)中了解更多信息，并查看已复制元数据的完整列表。"
    },
    {
        "query":"在将我的数据迁移到 Amazon FSx for NetApp ONTAP 时，我该使用什么协议？",
        "intention":"知识问答",
        "reply":"在通过 SMB 协议从为用户提供服务的 Windows 服务器或 NAS 共享迁移时，对您的 FSx for ONTAP 位置使用 DataSync SMB 源位置和 SMB 协议，确保为 NTFS 配置 FSx for ONTAP 卷的安全样式。而在通过 NFS 协议从为用户提供服务的 Unix 或 Linux 服务器或 NAS 共享迁移时，对您的 FSx for ONTAP 位置使用 DataSync NFS 源位置和 NFS 协议，确保为 Unix 配置 FSx for ONTAP 卷的安全样式。针对多协议迁移，您应该查阅博客[利用 Amazon FSx for NetApp ONTAP 实现多协议工作负载](https://aws.amazon.com/cn/blogs/storage/enabling-multiprotocol-workloads-with-amazon-fsx-for-netapp-ontap/)中所讨论的最佳实践，并使用 SMB 协议以最高保真度保留文件系统元数据。如需了解有关为您的 FSx for ONTAP 卷配置安全样式的更多信息，请见[管理 FSx for ONTAP 卷](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/managing-volumes.html)文档。"
    },
    {
        "query":"我可以使用 AWS DataSync 访问采用不同协议的相同 Amazon FSx for NetApp ONTAP 文件系统吗？",
        "intention":"知识问答",
        "reply":"可以，但您将需要为每个协议（NFS 或 SMB）创建独立的 DataSync 位置和任务资源。为避免发生覆盖数据和数据验证问题，我们不建议使用多个 DataSync 任务同时复制到相同的卷路径（无论使用的是相同协议或不同协议）。"
    },
    {
        "query":"我可以使用 AWS DataSync 将数据传入或传出 Amazon FSx for NetApp ONTAP iSCSI LUN 吗？",
        "intention":"知识问答",
        "reply":"不可以，DataSync 仅支持使用 NFS 或 SMB 协议将文件数据复制到 FSx for ONTAP 卷或从中复制出来。"
    },
    {
        "query":"我可以使用 AWS DataSync 将数据从一个 Amazon FSx for NetApp ONTAP 文件系统复制到另一个吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS DataSync 将数据从您的 FSx for ONTAP 文件系统复制到同一个 AWS 账户内的另一个文件系统。此功能同时适用于相同区域和跨区域部署，且不需要使用 DataSync 代理。"
    },
    {
        "query":"我可以使用 AWS DataSync 将我的 Amazon FSx for NetApp ONTAP 文件系统复制到另一个 AWS 区域中的不同文件系统吗？",
        "intention":"知识问答",
        "reply":"虽然 DataSync 可被用于在您的文件系统之间复制数据，但我们建议使用 [NetApp SnapMirror](https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/scheduled-replication.html) 在您的 FSx for ONTAP 文件系统之间进行复制。不管文件系统中的文件数量或大小，您都可以通过 SnapMirror 实现低 RPO。"
    },
    {
        "query":"我该如何配置 AWS DataSync，从而不用复制快照目录？",
        "intention":"知识问答",
        "reply":"DataSync 将自动排除名为 “.snapshot” 的文件夹。您还可以使用[排除筛选条件](https://docs.aws.amazon.com/datasync/latest/userguide/filtering.html#exclude-filters)，以避免复制与您指定的模式匹配的文件和文件夹。"
    },
    {
        "query":"如何在 AWS Snowcone 和 AWS 存储服务之间移动数据？",
        "intention":"知识问答",
        "reply":"DataSync 代理已作为 AMI 预安装在 [Snowcone](https://aws.amazon.com/cn/snowcone/) 设备上。要将数据在线移动到 AWS，请将 AWS Snowcone 设备连接到外部网络，并使用 [AWS OpsHub](https://docs.aws.amazon.com/snowball/latest/snowcone-guide/aws-opshub.html) 或 CLI 启动 DataSync 代理 AMI。使用 AWS 管理控制台或 CLI 激活代理，然后在 AWS Snowcone 的 NFS 存储与 Amazon S3、Amazon EFS、Amazon FSx for Windows File Server、Amazon FSx for Lustre、Amazon FSx for OpenZFS 或 Amazon FSx for NetApp ONTAP 之间设置在线数据移动任务。"
    },
    {
        "query":"如何在 Snow 上的 Amazon S3 兼容存储和 AWS 存储服务之间 移动数据？",
        "intention":"知识问答",
        "reply":"首先在本地环境中部署 DataSync 代理。使用 AWS 管理控制台或 CLI 激活代理，设置 DataSync 任务，在 Amazon S3 兼容存储上的存储桶与 Amazon S3、Amazon EFS 或任何 Amazon FSx 文件系统之间移动数据。"
    },
    {
        "query":"AWS DataSync 将我的文件系统复制到 AWS 有多快？",
        "intention":"知识问答",
        "reply":"AWS DataSync 复制给定数据集的速率需综合考虑数据量、源和目标存储可达到的 I/O 带宽、可用的网络带宽，以及网络条件。对于本地和 AWS 存储服务之间的数据传输，单个 DataSync 任务能够充分利用 10Gbps 的网络链路。"
    },
    {
        "query":"我能否控制 AWS DataSync 任务使用的网络带宽量？",
        "intention":"知识问答",
        "reply":"可以。通过[配置内置带宽限制](https://docs.aws.amazon.com/datasync/latest/userguide/create-task.html)，您可以控制 AWS DataSync 将使用的网络带宽量。 您可以在数据传输任务运行时提高或减少此限制。这使您能够最大限度地降低对依赖于同一网络连接的其他用户或应用程序的影响。"
    },
    {
        "query":"如何监控 AWS DataSync 的性能？",
        "intention":"知识问答",
        "reply":"AWS DataSync 可生成 [Amazon CloudWatch 指标以提供对传输流程的精细可见性](https://docs.aws.amazon.com/datasync/latest/userguide/monitor-datasync.html#metrics)。利用这些指标，您可以查看已复制的文件数和数据量以及文件发现和验证进度。您可以直接在 DataSync 控制台中查看包含这些指标的 [CloudWatch 图表](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/graph_a_metric.html)。"
    },
    {
        "query":"AWS DataSync 是否会影响我的源文件系统的性能？",
        "intention":"知识问答",
        "reply":"根据您的本地文件存储的容量，以及要传输文件的数量和大小，AWS DataSync 可能会在访问同一源数据存储时，影响其他客户端的响应时间，因为代理将从该存储系统读取或写入数据。为任务[配置带宽限制](https://docs.aws.amazon.com/datasync/latest/userguide/create-task.html)会降低此影响，因为它会限制存储系统的 I/O。"
    },
    {
        "query":"使用 AWS DataSync Discovery 时，如何指定本地存储系统的凭证以及如何保护这些凭证？",
        "intention":"知识问答",
        "reply":"当您配置 AWS DataSync Discovery 来发现您的存储系统时，需要提供用于访问存储的 API 接口的用户名和密码。然后，AWS DataSync Discovery 将自动在 AWS Secrets Manager 中创建密钥来存储凭证。DataSync Discovery 运行发现作业时，它会从密钥中检索密码，对其进行重新加密，然后将加密的密码发送到用于您的作业的代理。该密码仅在作业期间保留在代理的内存中，并且密码在任何时候都不会保留在内存之外。"
    },
    {
        "query":"我的数据在传输和存储过程中是否加密？",
        "intention":"知识问答",
        "reply":"可以。在源和目标之间传输的所有数据都通过传输层安全性 (TLS) 加密，它替代了安全套接字层 (SSL)。数据从来不会保留在 AWS DataSync 中。该服务支持使用 [S3 存储桶的默认加密](https://docs.aws.amazon.com/AmazonS3/latest/dev/bucket-encryption.html)、[静态数据的 Amazon EFS 文件系统加密](https://docs.aws.amazon.com/efs/latest/ug/encryption.html)和 [Amazon FSx 的静态和传输中加密](https://docs.aws.amazon.com/fsx/latest/WindowsGuide/encryption.html)。"
    },
    {
        "query":"AWS DataSync 如何访问我的 NFS 服务器或 SMB 文件共享？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用您部署到 IT 环境或 Amazon EC2 的代理，通过 NFS 或 SMB 协议访问您的文件。此代理连接到 AWS 中的 DataSync 服务终端节点并从 AWS 管理控制台或 CLI 安全地进行管理。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Hadoop 集群上的 HDFS？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用您部署到 IT 环境或 Amazon EC2 的代理，以访问您的 Hadoop 集群。DataSync 代理充当 HDFS 客户并与您的集群中的 NameNode 和 DataNode 通信。当您启动任务时，DataSync 会查询主 NameNode 以确定文件和文件夹在集群上的位置。然后，DataSync 会与集群中的 DataNode 通信，将文件和文件夹复制到 HDFS 或从 HDFS 复制。"
    },
    {
        "query":"AWS DataSync 如何访问我支持 Amazon S3 协议的自行管理存储或云对象存储？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用您部署到数据中心、公有云环境或 Amazon EC2 的代理，以使用 Amazon S3 API 访问您的对象。此代理连接到 AWS 中的 DataSync 服务端点，并从 AWS 管理控制台或 CLI 安全地进行管理。"
    },
    {
        "query":"AWS DataSync 如何访问我的 Azure Blob 存储容器（预览版）？",
        "intention":"知识问答",
        "reply":"AWS DataSync 使用您部署到 Azure 环境或 Amazon EC2 中的代理来访问 Azure Blob 存储容器中的对象。该代理连接到 AWS 中的 DataSync 服务端点，并从 AWS 管理控制台或 CLI 安全地进行管理。代理使用您在创建 DataSync Azure Blob 站点时指定的 SAS 令牌对您的 Azure 容器进行身份验证。"
    },
    {
        "query":"AWS DataSync 是否需要 VPN 才能连接到我的目标存储？",
        "intention":"知识问答",
        "reply":"不需要，向本地或从本地复制数据时，无需设置 VPN/隧道或允许入站连接。可以将您的 AWS DataSync 代理配置为使用标准网络端口来路由通过防火墙。您还可以使用 VPC 终端节点[在您的 Amazon Virtual Private Cloud (Amazon VPC) 中部署 DataSync](https://docs.aws.amazon.com/datasync/latest/userguide/datasync-in-vpc.html)。使用 VPC 终端节点时，在 DataSync 代理和 AWS 服务之间传输的数据不需要遍历公有互联网，也不需要公有 IP 地址。"
    },
    {
        "query":"AWS DataSync 代理如何安全地连接到 AWS？",
        "intention":"知识问答",
        "reply":"您的 AWS DataSync 代理在您选择的 [AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)内连接到 DataSync 服务终端节点。您可以选择让代理连接到面向公有互联网的终端节点、经联邦信息处理标准 (FIPS) 验证的终端节点或其中一个 VPC 内的终端节点。安全地激活代理可将其与您的 AWS 账户关联。要了解更多信息，请参阅[选择服务终端节点](https://docs.aws.amazon.com/datasync/latest/userguide/choose-service-endpoint.html)和[激活代理](https://docs.aws.amazon.com/datasync/latest/userguide/activate-agent.html)。"
    },
    {
        "query":"如何修补和更新我的 AWS DataSync 代理？",
        "intention":"知识问答",
        "reply":"一旦代理被激活，AWS 将自动应用代理 VM 的更新，同时包括底层操作系统和 AWS DataSync 软件包。当代理处于空闲状态且没有执行数据传输任务时，将以非破坏性的方式应用更新。"
    },
    {
        "query":"AWS DataSync 支持哪些合规性计划？",
        "intention":"知识问答",
        "reply":"AWS 具有在云中运行时间最长的合规性计划。AWS 致力于帮助客户满足他们的要求。AWS DataSync 已经过评估，达到了全球和行业安全标准。除了[符合 HIPAA 要求](https://aws.amazon.com/cn/compliance/hipaa-compliance/)以外，DataSync 还符合 [PCI DSS](https://aws.amazon.com/cn/compliance/pci-dss-level-1-faqs/)、ISO [9001](https://aws.amazon.com/cn/compliance/iso-9001-faqs/)、[27001](https://aws.amazon.com/cn/compliance/iso-27001-faqs/)、[27017](https://aws.amazon.com/cn/compliance/iso-27017-faqs/) 和 [27018](https://aws.amazon.com/cn/compliance/iso-27018-faqs/)，以及 [SOC 1、2 和 3](https://aws.amazon.com/cn/compliance/soc-faqs/)。 DataSync 还在 AWS 美国东部/西部区域按照 FedRAMP 中等影响进行了授权，在 AWS GovCloud（美国）区域按照 FedRamp 高影响进行了授权。这使您能够更轻松地验证我们的安全性，并履行您自己的义务。有关更多信息和资源，请访问我们的[合规性页面](https://aws.amazon.com/cn/compliance/)。您也可以转到[按合规性计划提供的范围内服务](https://aws.amazon.com/cn/compliance/services-in-scope/)页面，以查看服务和认证的完整列表。"
    },
    {
        "query":"AWS DataSync PCI 是否合规？",
        "intention":"知识问答",
        "reply":"支持。AWS DataSync 符合 [PCI-DSS](https://aws.amazon.com/cn/compliance/pci-dss-level-1-faqs/)，这意味着您可以使用它来传输付款信息。您可以在 [AWS Artifact](https://aws.amazon.com/cn/artifact/) 中下载 PCI 合规性文件包，以详细了解如何在 AWS 上实现 PCI 合规性。"
    },
    {
        "query":"AWS DataSync 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"可以。AWS DataSync 符合 HIPAA 要求，这意味着如果您有[适用于 AWS 的 HIPAA BAA](https://aws.amazon.com/compliance/hipaa-compliance/)，则可以使用 DataSync 来传输受保护的健康信息 (PHI)。"
    },
    {
        "query":"AWS DataSync 是否在 AWS 美国东部/西部区域获得了 FedRAMP JAB 中等影响临时授权？",
        "intention":"知识问答",
        "reply":"可以。AWS DataSync 已经在美国东部/西部区域依据联邦风险与授权管理计划 (FedRAMP) 中等影响基线的要求从联合授权委员会 (JAB) 取得了临时操作授权 (ATO)。如果您是联邦或商业客户，您可以在 AWS 美国东部/西部区域的授权边界内将 AWS DataSync 用于中等及更低影响等级的数据。"
    },
    {
        "query":"AWS DataSync 是否在 AWS GovCloud（美国）区域获得了 FedRAMP JAB 高影响临时授权？",
        "intention":"知识问答",
        "reply":"可以。AWS DataSync 已经在美国 GovCloud 区域依据联邦风险与授权管理计划 (FedRAMP) 高影响基线的要求从联合授权委员会 (JAB) 取得了临时操作授权 (ATO)。如果您是联邦或商业客户，您可以在 AWS GovCloud（美国）区域的授权边界内将 AWS DataSync 用于高影响及更低等级的数据。"
    },
    {
        "query":"AWS DataSync 与使用 rsync 或 Amazon S3 命令行接口等命令行工具有何不同？",
        "intention":"知识问答",
        "reply":"AWS DataSync 可完全自动化并加快向 AWS 移动大型活跃数据集的过程。它与 Amazon S3、Amazon EFS、Amazon FSx、[Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/) 和 [AWS CloudTrail](https://aws.amazon.com/cn/cloudtrail/) 原生集成，这可对您的存储服务提供无缝和安全的访问体验，还可对传输进行细致监控。\nDataSync 使用专用网络协议和扩展架构来传输数据。 对于本地和 AWS 存储服务之间的数据传输，单个 DataSync 任务能够充分利用 10Gbps 的网络链路。\nDataSync 实现了数据传输的完全自动化。它包含重试和网络弹性机制、网络优化、内置任务计划、监控功能（通过 DataSync API 和控制台实现）、CloudWatch 指标、事件和日志，可提供对传输流程的精细可见性。DataSync 在传输期间和传输结束时都执行数据完整性验证。\nDataSync 提供端到端的安全性并直接与 AWS 存储服务集成。源和目标之间传输的所有数据都通过 TLS 加密，并通过内置的 AWS 安全机制（如 IAM 角色）启用对 AWS 存储的访问。启用使用 VPC 终端节点的 DataSync，以确保在组织和 AWS 之间传输的数据不需要遍历公有互联网，这进一步增加了在网络上复制数据的安全性。"
    },
    {
        "query":"要在存储桶之间传输对象，我要在何时使用 AWS DataSync、何时使用 S3 复制，以及何时使用 S3 批量操作？",
        "intention":"知识问答",
        "reply":"AWS 提供多个工具在您的存储桶之间复制对象。\n使用 AWS DataSync 进行持续的数据分发、数据管道和湖内数仓提取，以及在多个存储桶之间整合或拆分数据。\n使用 [S3 复制](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html)将数据连续复制到特定目标存储桶。\n使用 [S3 批量操作](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/batch-ops.html)对 S3 对象进行大规模批量操作，例如复制对象、设置对象标签或访问控制列表 (ACL)、启动从 Amazon S3 Glacier Flexible Retrieval（原 S3 Glacier）的对象恢复、调用 AWS Lambda 函数以使用对象执行自定义操作、管理 S3 对象锁定依法保留或管理 S3 对象锁定保留日期。"
    },
    {
        "query":"何时使用 AWS DataSync 以及何时使用 AWS Snowball Edge？",
        "intention":"知识问答",
        "reply":"AWS DataSync 是在线数据传输的理想工具。您可以使用 DataSync 将现用数据迁移到 AWS，将数据传输到云进行分析和处理，还可以存档数据以释放本地存储容量，或者将数据复制到 AWS 以实现业务连续性。\n[AWS Snowball Edge](https://aws.amazon.com/cn/snowball-edge/) 适用于离线数据传输，适合带宽受限或从偏远、断开连接或严峻的环境中传输数据的客户。"
    },
    {
        "query":"何时使用 AWS DataSync 以及何时使用 AWS Storage Gateway？",
        "intention":"知识问答",
        "reply":"使用 AWS DataSync 将现有数据迁移到 Amazon S3，随后使用 [AWS Storage Gateway](https://aws.amazon.com/cn/storagegateway/) 的文件网关配置来保留对已迁移数据的访问权限，并从本地基于文件的应用程序进行持续更新。\n您可以组合使用 DataSync 和文件网关来尽量缩减本地基础设施，同时将本地应用程序无缝连接到您的云存储。AWS DataSync 使您能够加速向 AWS 存储服务在线传输数据的过程并实现自动化。 使用 AWS DataSync 完成初始数据传输阶段后，文件网关可为您的本地应用程序提供对已迁移数据的低延迟访问。将 DataSync 与 NFS 共享结合使用时，您的源本地存储中的 POSIX 元数据将被保存，且源存储的权限将在使用文件网关访问文件时应用。"
    },
    {
        "query":"何时使用 AWS DataSync 以及何时使用 Amazon S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"如果您的应用程序已经与 Amazon S3 API 集成，并且您在向 S3 传输大型文件时需要更高的吞吐量，则可以使用 [S3 Transfer Acceleration](https://aws.amazon.com/cn/s3/transfer-acceleration/)。如果您想要从现有存储系统（例如网络附带的存储）或从无法更改的仪器（例如 DNA 顺序分析仪、摄像机）传输数据，或者如果您想要使用多个目标位置，则可以使用 AWS DataSync。此外，通过提供内置重试和网络弹性机制、数据完整性验证与灵活配置等额外功能，DataSync 还可以简化数据传输并实现自动化，以满足您的特定需求，包括带宽限制等。"
    },
    {
        "query":"何时使用 AWS DataSync 以及何时使用 AWS Transfer Family？",
        "intention":"知识问答",
        "reply":"如果您当前使用 SFTP 与第三方交换数据，则 [AWS Transfer Family](https://aws.amazon.com/cn/aws-transfer-family/) 提供可直接传入和传出 Amazon S3 的完全托管式 SFTP、FTPS 和 FTP 传输，同时减少您的运营负担。\n如果您希望在 NFS 服务器、SMB 文件共享、Hadoop 集群、自行管理或云对象存储、AWS Snowcone、Amazon S3、Amazon EFS 和 Amazon FSx 之间进行加速的自动化数据传输，您可以使用 AWS DataSync。对于需要在线迁移现用数据集、及时传输持续生成的数据，或复制用以实现业务连续性的客户，DataSync 是理想之选。"
    },
    {
        "query":"什么是 Amazon AppFlow？",
        "intention":"知识问答",
        "reply":"Amazon AppFlow 是一项完全托管的集成服务，让您只需单击几下即可在 Salesforce、Marketo、Slack 和 ServiceNow 之类的软件即服务 (SaaS) 应用程序与 Amazon S3 和 Amazon Redshift 之类的 AWS 服务之间安全地传输数据。使用 AppFlow，您可以根据计划几乎以任何规模按您选择的频率针对业务事件要求或按需运行数据流。您可以配置强大的数据转换功能，例如筛选和验证，以生成丰富、随时可用的数据作为流本身的一部分，无需执行额外步骤。AppFlow 会自动加密动态数据，使用户可以限制与 AWS PrivateLink 集成的 SaaS 应用程序的数据在公共互联网上流动，从而减少暴露于安全威胁之中的风险。"
    },
    {
        "query":"AppFlow 有哪些好处？",
        "intention":"知识问答",
        "reply":"在 AppFlow 的帮助下，您无需花费大量时间以及投入技能娴熟的开发人员来为 AWS 服务构建和维护自定义 API 连接器，即可与 SaaS 应用程序交换数据。SaaS 应用程序管理员和业务分析人员可以快速实施他们所需的大多数集成，而无需经历数月的等待，让 IT 人员来完成集成项目。具体来说，好处包括："
    },
    {
        "query":"如何开始使用 AppFlow？",
        "intention":"知识问答",
        "reply":"前往 AWS 管理控制台，然后从“服务”菜单中选择 AppFlow。这将启动 AppFlow 主页。获得授权的 IAM 用户可以使用以下步骤创建和配置流：\nAppFlow 在数据源和数据目标之间传输数据，运行选定的转换并监控处理过程。AppFlow 与用于自动化、安全性和监控的基础 AWS 服务相集成，包括 AWS PrivateLink、AWS KMS 和 Amazon CloudTrail。"
    },
    {
        "query":"Amazon AppFlow 支持哪些 AWS 服务？",
        "intention":"知识问答",
        "reply":"支持的 AWS 服务包括 Amazon S3、Amazon RedShift、Amazon Connector Customer Profiles、Amazon Lookout for Metrics 和 Amazon Honeycode，并且我们一直在继续增加更多服务。"
    },
    {
        "query":"可以使用 Amazon AppFlow 配置的流示例有哪些？",
        "intention":"知识问答",
        "reply":"AppFlow 使您可以灵活地配置自己的流。一些流示例包括："
    },
    {
        "query":"可用于流的触发机制有哪些？",
        "intention":"知识问答",
        "reply":"您可以按需、根据业务事件或按计划运行流："
    },
    {
        "query":"我的 SaaS 应用程序现在可以使用公有 API；AppFlow 能够带来哪些附加价值？",
        "intention":"知识问答",
        "reply":"虽然开发人员可以使用 SaaS 应用程序中的公有 API 来拉取或推送数据，但 AppFlow 可以让任何不想编写代码、不想学习各种不同 SaaS 应用程序的 API 文档的人员执行一系列常见的集成任务，从而帮助客户节省时间。AppFlow 是一项完全托管的 API 集成服务，可替代自定义连接器。它可预置计算、存储和网络资源来编排和执行流；使用 SaaS 应用程序管理 API 授权，并管理访问令牌和 API 密钥的生命周期；以及将数据作为流的一部分进行处理。"
    },
    {
        "query":"支持将哪些 SaaS 集成作为源和目标？",
        "intention":"知识问答",
        "reply":"AppFlow 支持 Amazon S3、Salesforce、SAP、Marketo、Zendesk 和 Slack 等源以及许多其他源。它支持将 Amazon S3、Amazon RedShift、Salesforce 和 Snowflake 作为流的目标。要了解更多信息，请访问 [AppFlow 集成页面](https://aws.amazon.com/cn/appflow/integrations/)。"
    },
    {
        "query":"我希望 AppFlow 支持其他 SaaS 集成。如何提出这种请求？",
        "intention":"知识问答",
        "reply":"请[联系我们](mailto:appflow-integrations@amazon.com)，将 SaaS 供应商的名称以及您的使用案例告诉我们。"
    },
    {
        "query":"我是 SaaS 供应商，我希望与 AppFlow 集成。该怎么办？",
        "intention":"知识问答",
        "reply":"我们一直都想增加对新的 SaaS 供应商的支持。请[联系我们](mailto:appflow-integrations@amazon.com)，将您的客户所要求的使用案例告诉我们，我们将开始相关过程。"
    },
    {
        "query":"AppFlow 与 SaaS 应用程序连接时，是否需要 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"不需要。AppFlow 将与未启用 AWS PrivateLink 的 SaaS 应用程序的公有 API 终端节点集成。"
    },
    {
        "query":"如何设置加密密钥？",
        "intention":"知识问答",
        "reply":"借助 AppFlow，您的数据始终会被静态和动态加密。默认情况下，AppFlow 将使用您的 AWS 托管客户主密钥 (CMK) 进行加密。您还可以选择自己的托管密钥 – 用于加密的客户托管 CMK。在 AWS Key Management Service (KMS) 中创建您的自定义密钥。设置完成后，您的自定义密钥将自动可用于流创建。"
    },
    {
        "query":"何时应使用 AppFlow 或 AWS Glue？",
        "intention":"知识问答",
        "reply":"[AWS Glue](https://aws.amazon.com/cn/glue/) 提供托管 ETL 服务，使数据工程师可以轻松地准备和加载存储在 AWS 上的数据以进行分析。它从符合 JDBC 规范的数据源（即数据库）创建数据目录，使元数据可用于 ETL 以及通过 Amazon Athena、Amazon EMR 和 Amazon Redshift Spectrum 进行查询。AppFlow 连接到基于 API 的数据源，使业务部门的用户无需编写代码即可构建数据集成。"
    },
    {
        "query":"何时应使用 AppFlow 或 AWS DataSync？",
        "intention":"知识问答",
        "reply":"[AWS DataSync](https://aws.amazon.com/cn/datasync/) 旨在在本地数据源和 AWS 云之间移动大量数据，以进行批量数据迁移、处理以及备份或灾难恢复。如果经常需要一次性或定期传输数十或数百 TB 数据，AWS DataSync 是理想之选。在这种规模下，需要有效利用网络带宽并实现高吞吐量。而另一方面，AppFlow 则用于在 SaaS 应用程序和 AWS 服务之间交换数据。AppFlow 专为可能由人、事件或计划触发的操作数据流而设计。"
    },
    {
        "query":"何时应使用 AppFlow 或 Amazon EventBridge？",
        "intention":"知识问答",
        "reply":"[Amazon EventBridge](https://aws.amazon.com/cn/eventbridge/) 使开发人员能够构建与 SaaS 应用程序和 AWS 服务交互的事件驱动型应用程序。已与 EventBridge 集成的 SaaS 应用程序会将事件发送到客户的事件总线，然后其可被路由到 Amazon EC2 实例或 Lambda 函数等目标进行处理。AppFlow 支持在 SaaS 应用程序与 AWS 服务之间进行双向数据传输，这可以由人类使用 UI、计划或事件启动 – 所有这些都通过指向与单击式界面完成。"
    },
    {
        "query":"是否可以通过 CloudFormation 模板部署 AppFlow？",
        "intention":"知识问答",
        "reply":"AWS CloudFormation 针对 Amazon AppFlow 的支持可在所有[推出 Amazon AppFlow 的区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)使用。要了解有关如何使用 AWS CloudFormation 预置和管理 Amazon AppFlow 资源的更多信息，请访问我们的[文档](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_AppFlow.html)。"
    },
    {
        "query":"AppFlow 是否支持 CloudTrail？",
        "intention":"知识问答",
        "reply":"支持。要获取从您的账户发起的 AppFlow API 调用的历史记录，您只需在 AWS 管理控制台中打开 CloudTrail 即可。"
    },
    {
        "query":"What is Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: Amazon Lookout for Equipment uses the data from your sensors to detect abnormal equipment behavior, so you can take action before machine failures occur and avoid unplanned downtime.  \n Customers that want to build ML models to monitor the health or efficiency of their equipment can directly upload their historical sensor data to Amazon Lookout for Equipment and automatically build a ML model that learns the normal behavior patterns and alerts to abnormal behavior. Customers can set up Amazon Lookout for Equipment to read real-time data from their equipment and detect the current behavior of the asset."
    },
    {
        "query":"Why should I use Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: Current methods of analyzing data from industrial equipment often lead to too many alerts or an overgeneralized physics or statistics based model that does not adapt to the unique operating conditions of each piece of equipment. Amazon Lookout for Equipment benefits customers who have their own sensors generating data on industrial equipment and want to build custom models to detect abnormal behavior such as failure patterns or inefficient processes. Amazon Lookout for Equipment’s key benefits include:"
    },
    {
        "query":"How does this service relate to and work with other AWS services?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment reads directly from your Amazon S3 bucket and uses a variety of AWS services under the hood. Lookout for Equipment also works with AWS IoT SiteWise as customer can connect their sensors or historical data sets to AWS IoT SiteWise and then leverage Lookout for Equipment for model development."
    },
    {
        "query":"What type of sensors does Lookout for Equipment work with?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment is designed to work with any time series analog data, most commonly referred to as data tags. This can include data such as temperature, flow rates, rpms from components including sensors and actuators. As long as the tags vary over time and are relevant to the machines condition and/or process characteristics, Lookout for Equipment will work with the data."
    },
    {
        "query":"Does Lookout for Equipment use pre-trained models?",
        "intention":"知识问答",
        "reply":"A: No. Lookout for Equipment does not use pre-trained models. The wide variety of industrial equipment types and operating environments make pre-trained models very difficult to use across equipment. Instead, Lookout for Equipment builds a custom model on every data set it is given. Thus, Lookout for Equipment learns the normal operating behavior specific to the equipment and its unique operating environment."
    },
    {
        "query":"Can I bring my own ML model or algorithm to Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: No. Lookout for Equipment is an automated Machine Learning product. The service is designed to search through algorithms and thresholds itself to find the optimal setting for the given data set."
    },
    {
        "query":"Does Lookout for Equipment get smarter over time?",
        "intention":"知识问答",
        "reply":"A: Since Lookout for Equipment is an automated machine learning tool, it can get smarter over time as Lookout for Equipment can be used to retrain a model with new data. This can be done either as new unseen failures occur or as a model drifts over time."
    },
    {
        "query":"Can Lookout for Equipment be used for real time analysis?",
        "intention":"知识问答",
        "reply":"A: Yes. Lookout for Equipment is designed for real time analysis. First, a user needs to set up to publish sensor readings to Amazon S3. Then, with scheduled inferencing, a user can set a schedule ranging from five minutes to one hour. As data arrives in Amazon S3, Lookout for Equipment will grab the new data at the desired schedule, run inferencing on the data, and then deposit the results into another S3 bucket."
    },
    {
        "query":"Are there restrictions on the number of sensors I can use to build a model?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment currently allows up to a maximum of 300 sensors (tags) for one model."
    },
    {
        "query":"What kind of use cases does Lookout for Equipment support? What use cases are not supported?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment is built for applications that involve stationary equipment that operate continuously and with limited variability in their operating conditions. This can include rotating equipment such as pumps, compressors, motors etc. as well as assets like heat exchangers, boilers and inverters. It is not meant for equipment that are run infrequently and that have high variability in operating conditions."
    },
    {
        "query":"How do customers get up and running with Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: You can get started by creating an AWS account at aws.amazon.com and accessing the Amazon Lookout for Equipment developer console which walks you through an intuitive set-up. Developers can then import their historical equipment data via Amazon S3. Then, with only a few API calls, you can train a model automatically. Once trained, the models can be deployed with a scheduled API call. When deployed, developers call the service to get real-time abnormal state detection."
    },
    {
        "query":"What file types does Lookout for Equipment accept?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment works with CSV files."
    },
    {
        "query":"What regions is Lookout for Equipment available?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment is available in US East (N. Virginia), EU (Ireland), and Asia Pacific (Seoul)."
    },
    {
        "query":"What are the key use cases supported by Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: Lookout for Equipment is made for industrial process equipment that operate continuously and with low variability in operating conditions. Some good examples include\nLookout for Equipment may not be effective on highly variable equipment"
    },
    {
        "query":"What are some of the common predictive maintenance applications for Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A:"
    },
    {
        "query":"What data do I have to provide to Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: Your data set should be time series data generated from an industrial asset such as a pump, compressor, motor etc. Each asset should be generating data from sensors (tags). The data used should be representative of the condition and/or operation of the asset. For example, how could you know if your car is out of oil if you are not measuring the oil level? Making sure that you have the right data is crucial. This is why SMEs are required to ensure the data is relevant to the asset. It is equally as important to make sure that unnecessary and/or unrelated inputs are removed from the data. Amazon Lookout for Equipment works with up to 300 inputs, so make sure you choose the inputs that are crucial to the equipment. Too few inputs and you may be missing critical information, too many and the key inputs might have less of an impact on the detection.\nChoosing the right input data is crucial to the success of using Amazon Lookout for Equipment. It may take you multiple trial and error iterations of Amazon Lookout for Equipment to find the right inputs. We make no claims to guarantee results, success is highly dependent on the relevancy of your data to the equipment issues."
    },
    {
        "query":"Are inputs processed by Amazon Lookout for Equipment stored, and how are they used by AWS?",
        "intention":"知识问答",
        "reply":"A: Amazon Lookout for Equipment may store and use content processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Lookout for Equipment and other Amazon machine-learning/artificial-intelligence technologies. Use of your content is important for continuous improvement of your Amazon Lookout for Equipment customer experience, including the development and training of related technologies. We do not use any personally identifiable information that may be contained in your content to target products, services, or marketing to you or your end users. Your trust, privacy, and the security of your content are our highest priority, and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/compliance/data-privacy-faq/) for more information. You may opt out of having your content used to improve and develop the quality of Amazon Lookout for Equipment and other Amazon machine-learning/artificial-intelligence technologies by using an AWS Organizations opt-out policy. For information about how to opt out, see Managing AI services opt-out policy."
    },
    {
        "query":"Is the content processed by Amazon Lookout for Equipment moved outside the AWS region where I am using Amazon Lookout for Equipment?",
        "intention":"知识问答",
        "reply":"A: Any content processed by Amazon Lookout for Equipment is encrypted and stored at rest in the AWS region where you are using Amazon Lookout for Equipment. Some portion of content processed by Amazon Lookout for Equipment may be stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Lookout for Equipment customer experience and other Amazon machine-learning/artificial-intelligence technologies. If you opt out of having your content used to develop the quality of Amazon Lookout for Equipment and other Amazon machine-learning/artificial-intelligence technologies by contacting AWS Support, your content will not be stored in another AWS region. You can request deletion of content associated with your account by contacting AWS Support. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/compliance/data-privacy-faq/) for more information."
    },
    {
        "query":"什么是 AWS Wickr？",
        "intention":"知识问答",
        "reply":"AWS WickrGov 现已在 AWS GovCloud（美国西部）推出。AWS WickrGov 是一项端到端加密服务，可帮助组织在消息收发、通话、文件共享和屏幕共享方面进行协作。AWS WickrGov 用户还可以与网络之外的其他 AWS WickrGov 用户联合。"
    },
    {
        "query":"如何试用 AWS Wickr？",
        "intention":"知识问答",
        "reply":"问：如何开始群组对话？\n要创建群组对话，请使用 rooms（房间）选项卡中的笔记本或手写笔。在添加所需联系人以后，选择 create（创建）以启动新群组并添加新的用户名到您的联系人列表。\n问：该如何给消息加“星号”以及这样做意味着什么？\n您可以选择一条消息，然后选择给消息加星号选项以添加星号。您可以通过单击星星图标并搜索标记星号的项目，从搜索栏快速地访问所选的消息、图像和文件。\n问：什么是基于发送者的消息控制？\n从隐私角度来看，传统的消息收发系统均“基于接收者”；接收者要决定消息的存留时长以及分享消息的方式。AWS Wickr 将控制权交到发送者的手中。AWS Wickr 让您有信心您的私人消息不会显示在丢失或遭窃的手机上，遗留在互联网博客中，或者当您过去使用过的社交媒体被黑客攻击时，这些消息也不会再次出现。\n问：我为什么看不到发送给我的消息？\n最有可能的情况是该消息已过期。 每个发送消息的用户都可以通过设置过期计时来确定消息将被保存多长时间。此外，发送者还可以设置阅后即焚计时；它会在消息被解锁或查阅后开始倒数。\n如果过期计时到期，消息将被自动删除，而不管阅后即焚计时还剩多少时间或您是否已打开该消息。\n问：我可以确定我的消息是否已被查阅吗？\nAWS Wickr 目前不提供阅读回执功能。不过，我们正在开发一种可选的基于权限的阅读回执功能，它不会侵犯接收者的隐私。\n问：该如何判断某人最近是否一直处于活跃状态？\n如果您看到某人的名字和头像旁有绿点，则可以判断他们处于活跃状态。它被称作状态选项，可允许您确定其他用户当前是否在线或有空，以及他们上次活跃的时间。\n问：什么是语音备忘录？\n您可以发送完全加密的语音备忘录到房间或对话。 点击并按住移动设备上的麦克风图标即可发送语音备忘录，最长时间为一分钟。如果使用台式机，选择 to start（开始）与 to end（结束）。语音备忘录的时长不得短于 2 秒。\n问：如何开始通话？\n按住 AWS Wickr 房间、群组或私信屏幕右上方的电话图标，会弹出 “start call”（开始通话）菜单。\n问：我可以呼叫网络以外的用户吗？\n可以，您可以在 Wickr Me 和 AWS Wickr 中呼叫网络以内和网络以外的用户。\n问：我可以对 AWS Wickr 上的通话进行录音吗？\n不可以，您不能在 AWS Wickr 内使用原生方式对通话进行录音。\n问：AWS 可以访问我的组织的通信内容吗？\n不可以，所有消息都经过端到端加密，而且只能在最终用户的设备上读取。\n问：AWS Wickr 会保存我的数据吗？\n我们致力于遵守适用的数据保护及隐私法，出于提供服务的目的有限地收集并存储必要的客户信息。为了将您的内容传输给已注销的用户，我们可能会将这些内容存储在我们的服务器上（不超过数据过期计时设置所设定的时长）。请参阅我们的[隐私声明](https://aws.amazon.com/cn/privacy/)以了解更多详情。\n问：我可以在哪里找到隐私声明？\n请参阅我们的[隐私声明](https://aws.amazon.com/privacy/)以了解更多详情。\n问：我可以在哪里找到服务条款？\n请参阅我们的[服务条款](https://aws.amazon.com/service-terms/)以了解更多详情。\n问：我可以与所在组织以外的人员收发消息吗？\n在默认情况下，AWS Wickr 网络可以与任何使用 AWS Wickr 的人员进行通信。\n问：我可以阻止我的团队收到所在组织以外的人员发送的消息吗？\n管理员可以在群组安全设置中停用 AWS Wickr 网络以外的联合身份验证。\n问：网络 ID 有什么用途？\n网络 ID 可被添加到允许列表，以限制您的团队可以与哪些人员进行通信。\nAWS Wickr 中的数据留存如何运作？\nWickr 中的数据留存默认不会被启用。您的网络的 Wickr 管理员将需要创建并启用[数据留存](https://docs.aws.amazon.com/wickr/latest/adminguide/data-retention.html)功能，以出于审计和监管目的允许留存从您的 Wickr 网络发出的内容。在启用数据留存功能以后，您的 Wickr 网络中的用户将在应用程序中看到通知，告知其所发送的内容将被记录下来。传入的联合身份内容（您的 Wickr 网络以外的联系人发来的消息、文件、元数据，等等）不会被记录。Wickr 绝不会访问记录的内容；所有数据将由客户保存并管理。客户系统管理员将需要确保安全地存储留存的内容，并且遵守会对其业务通信产生影响的法规/政策。\n问：我可以保留我的网络以外的 AWS Wickr 用户发送给网络内用户的消息吗？\n不可以，数据留存仅保存在 AWS Wickr 以内发送的消息或从您的网络发送至其他用户的消息。从不同 AWS Wickr 网络的用户发来的消息不会被保留。\n问：哪些区域提供 AWS Wickr？\nAWS Wickr 现已在美国东部（弗吉尼亚州北部）区域和 AWS GovCloud美国西部（俄勒冈州）区域推出。数据在上述区域处理和存储。\n问：AWS Wickr 或 AWS WickrGov 是否已在 AWS GovCloud（美国）推出？\nAWS WickrGov 已在 AWS GovCloud美国西部（俄勒冈州）区域推出。\n问：我如何了解有关 AWS Wickr 机器人的更多信息？\n管理员可以[查阅有关 AWS Wickr 机器人的更多信息](https://wickrinc.github.io/wickrio-docs/)，包括设置、现有机器人和自定义机器人等。"
    },
    {
        "query":"What is AWS App2Container ?",
        "intention":"知识问答",
        "reply":"AWS App2Container (A2C) is a new command line tool that helps transform existing applications running in virtual machines into containers, without needing any code changes. A2C discovers applications running on a server, identifies dependencies, and generates relevant artifacts for seamless deployment to Amazon ECS and EKS. A2C also provides integration with AWS CodeBuild and CodeDeploy to enable a repeatable way to build and deploy containerized application."
    },
    {
        "query":"What application types are supported by App2Container?",
        "intention":"知识问答",
        "reply":"App2Container (A2C) currently supports the following application types: 1) ASP.NET (.NET 3.5+) web applications running in IIS 7.5+ on Windows. A2C packages these applications with Windows containers. 2) Java applications running on Linux standalone JBoss, Apache Tomcat, and generic Java applications (Spring Boot, IBM WebSphere, Oracle WebLogic, etc.). A2C packages Java applications with Linux containers."
    },
    {
        "query":"What are the benefits of containerizing my existing applications?",
        "intention":"知识问答",
        "reply":"Some of the benefits that are driving organizations of all sizes to containerize their existing applications are:\n• Portability: Containers enable you to run applications in on-premise, cloud, and hybrid cloud models. This portability of the application allows customers to be flexible with their infrastructure environments and achieve business benefits, like no vendor lock-in.  \n • Developer Productivity: Containers help with getting started and shipping new code faster and easier. They remove the requirement for complex application and dependency set up. Developers are quickly able to set up their development environments with containers. This empowers them to be productive and agile with application development.  \n • IT Infrastructure Reduction: You can optimize compute costs by increasing container workload density and better utilization of server compute density. This can also help reduce software licensing costs.  \n • Standardization of CI/CD: Customers can easily build modern CI/CD workflows once legacy applications are containerized. This enables customers to standardize their CI/CD process across their organization and that reduces IT operations cost, and improves business agility for their applications."
    },
    {
        "query":"How does App2Container make it easier to containerize applications?",
        "intention":"知识问答",
        "reply":"App2Container enables you to quickly transform your existing applications running on-premises, in Amazon EC2, or in any other cloud. You get the following benefits by using A2C for containerization:\n• Application Inventory: A2C identifies the supported ASP.NET and Java applications running in a server which enables a quick and accurate inventory of applications in your environment without extensive manual effort.  \n • Detailed Dependency Analysis: A2C analyzes the running application and identifies dependencies including cooperating processes and network port dependencies. This detailed information reduces the manual effort required to understand and document application anatomy and required dependencies.  \n • Seamless Deployment: A2C generates ECS task definitions and Kubernetes deployment YAML for the containerized application following the AWS best practices for security and scalability by integrating with various AWS services such as ECR, ECS, and EKS. A2C generates CloudFormation template to configure required compute, network, and security infrastructure to seamlessly deploy containerized application in AWS. A2C creates CI/CD pipelines for Amazon DevOps services such as CodeBuild and CodeDeploy to build and deploy containers. If you have existing CI/CD tooling (for example, Azure DevOps, and Jenkins), then you can integrate A2C provided deployment artifacts into your existing CI/CD workflows."
    },
    {
        "query":"What are the prerequisites for using App2Container?",
        "intention":"知识问答",
        "reply":"App2Container requires the following prerequisites installed on the server(s) hosting your application: 1) AWS CLI, 2) Docker Tools, 3) Powershell 5.0+ for applications running on Windows. Additionally, you need to provide appropriate IAM permissions to A2C to interact with AWS services. See A2C documentation for more details. Additionally, it is recommended that you use your dev/test environment for containerizing applications."
    },
    {
        "query":"How do I get started?",
        "intention":"知识问答",
        "reply":"Once the prerequisites are met and the App2Container tool is installed on the application server, use the following sequence of commands to containerize the application.\n• Init: Configures the tool with your AWS profile and other related parameters.  \n • Inventory: Identifies all running applications that are supported by A2C. Choose an application to proceed.  \n • Analyze: Performs detailed analysis to identify application artifacts, third-party dependencies, network ports and configuration files, and generates a configuration file to represent the gathered information. You can make additional changes to the configuration file (for example, exclude or include any additional files or directories).  \n • Containerize: Generates a dockerfile and container image for the analyzed application. If needed, you can modify the A2C-generated dockerfile and rebuild the container. You can also perform local testing of the containerized application using docker run command before deploying to AWS container services.  \n • Generate Deployment: Registers the container image with Amazon ECR, creates ECS task definitions, and Kubernetes deployment YAML file to deploy the containerized application to Amazon ECS or Amazon EKS. A2C generates CloudFormation template to create required infrastructure to deploy the containerized application. Optionally, it also generates AWS CodeBuild and CodeDeploy artifacts to enable repeatable way to build and deploy the containerized app."
    },
    {
        "query":"Can I containerize my applications outside the product environment?",
        "intention":"知识问答",
        "reply":"It is recommended that you use your dev/test environment for containerizing applications. App2Container allows you to run inventory, analyzer, and extract commands on the application server without direct internet access and then you manually copy the application artifact tar file generated by A2C to a separate A2C worker machine where the rest of the A2C workflow needs to be completed. The internet access/aws account will be required on the worker machine to complete the rest of the A2C workflows – (the containerize and generate deployment steps)."
    },
    {
        "query":"What artifacts are generated by App2Container?",
        "intention":"知识问答",
        "reply":"App2Container generates the following artifacts for each application component: 1) Application artifacts such as DLLs configuration, 2) Dockerfile, 3) container image in ECR, 4) ECS Task definitions, 5) Kubernetes deployment YAML, 6) CloudFormation Template, 6) AWS CodeBuild and CodeDeploy resources."
    },
    {
        "query":"How can I set up CI/CD processes for the containerized application?",
        "intention":"知识问答",
        "reply":"A2C generates AWS CodeBuild and CodeDeploy artifacts for you to set up your CI/CD workflow. If you have existing CI/CD tooling (for example, Azure DevOps and Jenkins), then you can integrate A2C provided artifacts – dockerfile, ECS task definition, EKS deployment YAML – into your existing CI/CD workflows. See A2C documentation for more details."
    },
    {
        "query":"How do I update my application after it is containerized?",
        "intention":"知识问答",
        "reply":"App2Container generated dockerfile contains commented examples indicating how updates to specific files and dependencies can be captured as part of the build process. You can follow the examples to learn how to deploy updates such as config changes, third-party package updates, deploying a vendor provided WAR/EAR update etc. You can modify the commented parts with the actual application artifacts, and integrate this modified dockerfile into your enterprise CI/CD tools like AWS DevOps services, Jenkins, Spinnaker, and Azure DevOps."
    },
    {
        "query":"How do I containerize multi-tier applications using A2C?",
        "intention":"知识问答",
        "reply":"For applications with multiple tiers, you can use A2C to containerize each application tier separately. A2C creates separate containers and corresponding AWS deployment artifacts for each individual tier. You may have to perform additional configuration before deploying these applications. See A2C documentation for more details."
    },
    {
        "query":"Does App2Container support migrating the database used by the application?",
        "intention":"知识问答",
        "reply":"Dependencies that are external to the application server such as databases are not supported by A2C. You can use tools such as AWS Database Migration Service (DMS) to migrate your application database to AWS."
    },
    {
        "query":"Can I containerize commercial-off-the-self (COTS) applications using App2Container?",
        "intention":"知识问答",
        "reply":"With A2C, you can containerize COTS applications as long as they are based on an application stack supported by A2C. Before starting, check with the application vendor regarding the licensing and support terms and conditions."
    },
    {
        "query":"How does App2Container flag applications that are not supported for containerization?",
        "intention":"知识问答",
        "reply":"App2Container provides mechanisms through which you can identify if the application can be containerized using the tool. First, A2C only generates the inventory of supported applications types – ASP.NET 3.5+ on Windows and Java applications on Linux. Within ASP.NET and Java applications, A2C then flags applications that are using specific feature(s) not supported by A2C e.g. ASP.NET application using. .NET 1.0."
    },
    {
        "query":"What are the limitations of App2Container?",
        "intention":"知识问答",
        "reply":"• A2C doesn't support ASP.NET applications with the following characteristics: 1) application has an OS related dependency on Windows 2008 and 2012, 2) it is using files and registries outside of IIS web application directories, 3) it has dependency on other Windows services or processes outside of IIS.  \n • Except for Tomcat and JBoss 7+ application, A2C’s containerization of generic Java applications (for example, ones using WebSphere or WebLogic) involves packaging entire file system without system and kernel files. This can result in a larger container image. You may have to manually exclude files to reduce the size of the images, if desired.  \n • For Tomcat and JBoss v7+ applications, A2C container image only includes files directly utilized by the application. The container image doesn’t include files related to package management and versioning. If you use A2C generated container image as base image and try to update the applications or its dependencies through a package manager, then such updates may fail.  \n • A2C doesn't currently support Cluster/HA mode for Java applications"
    },
    {
        "query":"什么是 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 是一项快速且易于使用的云支持业务分析服务，它使组织内的所有员工能够在任何设备上随时轻松构建可视化内容、执行临时分析并快速从数据中获得业务见解。上传 CSV 和 Excel 文件；连接到 SaaS 应用程序（如 Salesforce）；访问本地数据库（如 SQL Server、MySQL 和 PostgreSQL）；无缝地发现 AWS 数据源（如 Amazon Redshift、Amazon RDS、Amazon Aurora、Amazon Athena 和 Amazon S3）。借助 QuickSight，组织能够将其业务分析功能扩展到成千上万用户，并通过使用强大的内存中引擎 (SPICE) 交付快速而敏捷的查询性能。"
    },
    {
        "query":"Amazon QuickSight 与传统的商业智能 (BI) 解决方案有何不同？",
        "intention":"知识问答",
        "reply":"在生成报告之前，传统 BI 解决方案往往需要大量数据工程师花几个月的时间来构建复杂的数据模型。这些解决方案通常缺乏互动的临时数据探索和可视化，将用户局限在现成报告和预先选定的查询。传统 BI 解决方案还需要对复杂而昂贵的硬件和软件进行大量前期投资，然后随着数据库规模的增长，客户需要投资更多的基础设施来维持快速的查询性能。这种高成本和复杂性使得公司难以在整个组织内部署分析解决方案。Amazon QuickSight 能够通过将 AWS 云的规模和灵活性引入业务分析，来解决这些问题。不同于传统的 BI 或数据发现解决方案，Amazon QuickSight 入门非常简单、快捷。登录后，Amazon QuickSight 会无缝地发现您的 AWS 产品数据源，如 Amazon Redshift、Amazon RDS、Amazon Athena 和 Amazon Simple Storage Service (Amazon S3)。您可以连接到 Amazon QuickSight 发现的任何数据源，并在几分钟内从该数据中获得见解。底层源中的数据更改时，您可以选择 Amazon QuickSight 来维持 SPICE 中的数据的最新状态。SPICE 支持丰富的数据发现和业务分析功能，可帮助客户从数据中获取有价值的见解，而且不必为预置或管理基础设施而担心。组织为每个 Amazon QuickSight 用户支付较低的月租费，免去了购买长期许可证的成本。借助 Amazon QuickSight，组织无需承担巨大的前期成本即可向所有员工提供丰富的业务分析功能。"
    },
    {
        "query":"什么是 SPICE？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 构建在“SPICE”之上，后者是一种运行超快的并行内存中计算引擎。SPICE 专门针对云进行全新构建，它通过最新的硬件创新和机器代码生成实现列式存储与内存技术的结合，让您能够在大型数据集上运行交互式查询并快速获得响应。SPICE 支持大量计算，可帮助您从分析中获得有价值的见解，而且不必为预置或管理基础设施而担心。SPICE 内的数据将长期保存，直到被用户明确地删除。SPICE 还会自动复制数据以获得高可用性，并且使 QuickSight 能够扩展到成千上万用户，使他们可以同时在各种 AWS 数据源中执行快速的交互式分析。"
    },
    {
        "query":"如何开始使用 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"要开始使用，请登录 Amazon Quicksight，4 名作者可以免费试用 30 天。"
    },
    {
        "query":"在 QuickSight 中使用 SageMaker 推理是否有任何先决条件？",
        "intention":"知识问答",
        "reply":"您的 QuickSight 特权账户管理员需要先授予 QuickSight IAM 权限代表您进行 SageMaker API 调用。要了解更多信息，[请参阅有关授予 QuickSight IAM 权限的文档](https://docs.aws.amazon.com/quicksight/latest/user/managing-users.html)。\nQuickSight 的“作者”是谁？  \n 答：QuickSight 作者是指可以连接到 AWS 内外部数据源、创建视觉内容和分析数据的用户。作者可以使用 QuickSight 的高级功能（如参数和计算字段）创建交互式控制面板，并以账户中其他用户的身份发布这些控制面板。\nQuickSight 的“读者”是谁？  \n QuickSight 读者是指使用交互式控制面板的用户。读者可以使用 Web 浏览器或移动应用程序通过所在组织的首选身份验证机制（QuickSight 用户名/密码、SAML 门户或 AD 身份验证）登录、查看共享的控制面板、筛选数据、查看详细信息或将数据导出为 CSV 文件。系统不会为读者分配任何 SPICE 容量。\n可将个人最终用户预置为以读者身份访问 QuickSight。读者定价仅适用于手动会话交互。我们保留在以下情况下按较高的月度作者费率向读者收费的权利：根据我们的判断，您正在将读者会话用于其他类型的用途（例如，编程查询或自动化查询）。\n能否将读者升级为作者？  \n 可以，读者可以通过 QuickSight 用户管理选项轻松升级为作者。\n我有一个标准版账户。我能添加读者吗？  \n 不能，只有标准版中才有采用“按会话付费”定价模式的读者。如果您拥有标准版账户，可以通过 QuickSight 管理页面升级为企业版账户。\n能否使用 QuickSight 读者账户通过编程方式访问 QuickSight？  \n Amazon QuickSight 的读者定价适用于各用户以交互方式使用数据。我们采用公平使用策略，如果滥用系统，会导致在计费时将读者视为作者。为了避免这种情况，我们建议在需要时使用作者账户通过编程方式来刷新控制面板。\nQuickSight 的“管理员”是谁？  \n QuickSight 管理员是指可以管理 QuickSight 用户和账户级首选项，以及为账户购买 SPICE 容量和年度订阅服务的用户。管理员还能使用所有 QuickSight 创作功能。管理员也可以在需要时将标准版账户升级为企业版账户。\n能否将读者或作者升级为管理员？  \n 随时可以将 Amazon QuickSight 作者和读者升级为管理员。\n每个读者会话持续多长时间？  \n 每个 Amazon QuickSight 读者会话的持续时长为 30 分钟。每个会话的费用为 0.30 USD；每位读者每月的费用最高为 5 USD。\n读者会话何时开始和结束？  \n 读者会话在用户启动操作（如登录、控制面板加载、页面刷新、深入查看或筛选）时开始，之后持续运行 30 分钟。除非用户在页面上启动操作，否则，将 Amazon QuickSight 在后台浏览器窗口/标签页中保持打开状态并不会启动会话。\n时长 30 分钟的会话结束后，读者会注销吗？  \n 不会，读者会话对 QuickSight 读者是透明的。读者会话将每隔 30 分钟自动更新一次；如果在启动后 30 分钟均处于不活动状态，则将超时。如果读者的身份验证到期（取决于现有的身份验证模式，可以是仅使用 QuickSight 的用户、SAML/Open ID Connect 或 Active Directory），读者仅会从 QuickSight 注销。\n如果 QuickSight 在浏览器的后台标签页中打开，是否会向读者收费？  \n 不会，在后台标签页中打开 Amazon QuickSight 不会产生使用费。仅当读者在 QuickSight Web 应用程序中有明确活动时，才会启动会话。如果 QuickSight 页面移动到后台或者最小化，那么，除非读者再次与 QuickSight 交互，否则，除了针对读者在窗口/标签页中处于活动状态时启动的会话收费以外，不会收取任何额外的会话费用。\n读者每月最高支付 5 USD 是什么意思？\n每个会话向读者收取 0.30 USD，每月最多收取 5 USD，费用达到 5 USD 后，读者可以免费在 QuickSight 中访问更多会话。\nQucksight 的“作者”或“读者”能否邀请更多用户？  \n 不能，QuickSight 作者和读者这两种类型的用户不能更改账户权限或邀请更多用户。QuickSight 提供管理员用户，管理员用户可以管理 QuickSight 用户和账户级首选项，以及为账户购买 SPICE 容量和年度订阅服务。管理员还能使用所有 QuickSight 创作功能。管理员也可以在需要时将标准版账户升级为企业版账户。\n能否在监视器或大屏幕上使用 QuickSight 读者账户显示或通过脚本来刷新 QuickSight 控制面板？  \n Amazon QuickSight 的读者定价适用于组织中的最终用户以交互方式使用数据。如需通过编程方式访问或通过脚本刷新，我们建议使用作者账户，确保遵循与 QuickSight 读者相关的公平使用政策。"
    },
    {
        "query":"我能否在移动设备上使用 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"QuickSight 移动应用程序（可在 iOS 和 Android 设备上使用）可让您即时访问您的数据和见解，以便您随时作出决策。浏览、搜索并与您的控制面板交互。添加控制面板到收藏夹中，以便快速、轻松地访问。通过向下钻取、筛选等探索您的数据。您还可以使用任何移动设备的 Web 浏览器来访问 Amazon QuickSight。"
    },
    {
        "query":"哪些浏览器支持 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 支持最新版本的 Mozilla Firefox、Chrome、Safari、Internet Explorer（版本 10 及以上）和 Edge。"
    },
    {
        "query":"Amazon QuickSight 支持哪些数据源？",
        "intention":"知识问答",
        "reply":"您可以连接到 AWS 数据源，包括 Amazon RDS、Amazon Aurora、Amazon Redshift、Amazon Athena 和 Amazon S3。您还可以上传 Excel 电子表格或平面文件（CSV、TSV、CLF 和 ELF），连接到本地数据库（如 SQL Server、MySQL 和 PostgreSQL），并从 SaaS 应用程序（如 Salesforce）导入数据。"
    },
    {
        "query":"能否将 Amazon QuickSight 连接到我的 Amazon EC2 或本地数据库？",
        "intention":"知识问答",
        "reply":"可以。为了将 Amazon QuickSight 连接到 Amazon EC2 或本地数据库，您需要将 [Amazon QuickSight IP 范围](http://docs.aws.amazon.com/quicksight/latest/user/configure-access.html#ip-address-ranges)添加到您的托管数据库中的授权列表。"
    },
    {
        "query":"如何将数据文件上载到 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"您可以直接从 Amazon QuickSight 网站上传 XLSX、CSV、TSV、CLF、XLF 数据文件。您也可以将它们上传到 Amazon S3 存储桶并将 Amazon QuickSight 指向 Amazon S3 对象。"
    },
    {
        "query":"如何访问我在 AWS 数据源中的数据？",
        "intention":"知识问答",
        "reply":"获得您的批准后，Amazon QuickSight 会无缝地发现您的账户中可用的 AWS 数据源。您可以立即开始浏览数据并构建可视化内容。通过提供其他 AWS 数据源的连接详细信息，您还可以明确连接到这些不在您账户中或在不同区域中的数据源。"
    },
    {
        "query":"我的源数据没有使用简洁一致的格式。在可视化之前将如何格式化并转换数据？",
        "intention":"知识问答",
        "reply":"通过 Amazon QuickSight，您可以为尚未可视化就绪的数据做好准备。选择连接对话框中的“准备/预览数据”按钮。Amazon QuickSight 支持各种功能来格式化和转换数据。您可以给数据字段取别名并更改数据类型。您可以使用内置的筛选器创建一个数据子集，然后使用拖放功能执行数据库连接操作。您还可以使用数学运算创建计算字段，并创建各种内置函数，如条件语句、字符串、数字和日期函数。"
    },
    {
        "query":"我可以使用 Amazon QuickSight 分析多少数据？",
        "intention":"知识问答",
        "reply":"凭借 Amazon QuickSight，您不必担心数据规模。您可以无缝地将数据从数百 GB 增长到数 TB，而且无需管理任何基础设施。"
    },
    {
        "query":"QuickSight 与 SageMaker 的集成是如何工作的？",
        "intention":"知识问答",
        "reply":"第一步是连接要从中提取数据的数据源。当您连接到数据源后，立即选择“用 SageMaker 进行增强”选项。从那里开始，从您的 AWS 账户中的 SageMaker 模型列表中选择您要使用的模型并提供架构文件，该文件是 JSON 格式的文件，包含输入、输出和运行时设置。查看输入架构与数据集中的列的映射。完成后，您可以立即执行此作业并开始运行推理。"
    },
    {
        "query":"QuickSight 是否在每次运行时利用 SageMaker 模型对增量数据或完整数据执行推理？",
        "intention":"知识问答",
        "reply":"QuickSight 在每次刷新时都会对完整数据进行推理。"
    },
    {
        "query":"如何管理对 Amazon QuickSight 的用户访问？",
        "intention":"知识问答",
        "reply":"当您创建新的 Amazon QuickSight 账户时，将默认获得管理权限。如果您受邀成为 Amazon QuickSight 用户，邀请人将为您分配 ADMIN 或 USER 角色。若获得 ADMIN 角色，除了使用该服务外，您还可以创建和删除用户账户、购买年度订阅和 SPICE 容量。\n创建用户账户时，您应通过应用程序内界面向该用户发送电子邮件邀请，然后该用户通过指定密码并登录服务来完成账户创建。"
    },
    {
        "query":"如何使用 Amazon QuickSight 创建分析？",
        "intention":"知识问答",
        "reply":"创建分析非常简单。Amazon QuickSight 会无缝地发现您的 AWS 账户中常用 AWS 数据存储库中的数据。只需将 Amazon QuickSight 指向发现的某个数据源即可。要连接到您的 AWS 账户之外或不同区域中的其他 AWS 数据源，您可以提供该源的连接详细信息。然后，选择一个表格并开始分析数据。您也可以上传电子表格和 CSV 文件，并使用 Amazon QuickSight 来分析您的文件。要创建可视化内容，请先选择要分析的数据字段，或将字段直接拖动到可视画布，或结合执行这两个操作。Amazon QuickSight 将根据您选择的数据自动选择要显示的相应可视化内容。"
    },
    {
        "query":"Amazon QuickSight 如何为我的数据选择合适的可视化类型？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 具有称为 AutoGraph 的创新技术，该技术可使它根据数据的属性（如基数和数据类型）选择最适当的可视化类型。所选的可视化类型可以通过有效方式最佳地呈现数据和关系。"
    },
    {
        "query":"如何创建控制面板？",
        "intention":"知识问答",
        "reply":"控制面板是经排列并共同可见的可视化内容、表格和其他可视显示的集合。借助 Amazon QuickSight，您可以通过排列可视化内容的布局和大小在分析中编制控制面板，然后将控制面板发布给组织内的受众。"
    },
    {
        "query":"Amazon QuickSight 支持哪些类型的可视化？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 支持各种各样的可视化，以便于使用各种不同的分析方法："
    },
    {
        "query":"什么是建议的可视化内容？ Amazon QuickSight 如何生成建议？",
        "intention":"知识问答",
        "reply":"Amazon QuickSight 随附一个内置的建议引擎，该引擎根据基本数据集的属性为您提供建议的可视化内容。建议作为分析的第一步或下一步可能执行的操作，可免去执行询问和了解数据架构的耗时任务。在您使用更具体的数据时，建议将进行更新以反映适合当前分析的下一个步骤。"
    },
    {
        "query":"什么是情节？",
        "intention":"知识问答",
        "reply":"情节通过具体的分析视图为您提供指导。它们可用于传达关键点、思维过程或协作分析的发展。您可以通过捕获和注释特定分析状态，在 Amazon QuickSight 中构建情节。当情节的读者单击情节中的图像时，就会进入这一点所在的分析过程，他们可以在那里自行探索。"
    },
    {
        "query":"Amazon QuickSight 支持什么类型的计算？",
        "intention":"知识问答",
        "reply":"您可以执行典型的算术和比较函数；条件函数（如“if, then”函数）和日期、数字和字符串计算。"
    },
    {
        "query":"如何从 QuickSight 中获取示例数据进行探索？",
        "intention":"知识问答",
        "reply":"为方便起见，当您在 Amazon QuickSight 中创建账户时会自动生成示例分析。您还可以使用下列链接下载原始数据：\n这些数据集由 [47Lining](http://www.47lining.com/) 创建，其是一个 AWS 高级咨询合作伙伴，拥有大数据能力认证。"
    },
    {
        "query":"数据如何传输到 Amazon QuickSight？",
        "intention":"知识问答",
        "reply":"您可以通过多种方式让数据进入 Amazon QuickSight：文件上传、连接到 AWS 数据源、通过 JDBC/ODBC 连接到外部数据存储，或通过其他基于 API 的数据存储连接器。"
    },
    {
        "query":"能否选择要通过 JDBC/ODBC 连接到托管或本地数据库的 AWS 区域？",
        "intention":"知识问答",
        "reply":"可以。为了获得更好的性能和用户交互性，建议客户使用存储数据的区域。Amazon QuickSight 的自动发现功能只能对您所连接的 Amazon QuickSight 终端节点的 AWS 区域中的数据源进行检测。要查看支持 Amazon QuickSight 的 AWS 区域的列表，请访问所有 AWS 全球基础设施的[区域产品和服务页面](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"Amazon QuickSight 是否支持多重验证？",
        "intention":"知识问答",
        "reply":"可以。您可以通过 AWS 管理控制台为您的 AWS 账户启用多重验证 (MFA)。"
    },
    {
        "query":"如何将 VPC 与 Amazon QuickSight 连接？",
        "intention":"知识问答",
        "reply":"如果您的 VPC 已经设置为具有公共连接，则您可以将 Amazon QuickSight 的 IP 地址范围添加到数据库实例的安全组规则中，以便流量能够进入您的 VPC 和数据库实例。"
    },
    {
        "query":"什么是行级安全性？",
        "intention":"知识问答",
        "reply":"行级别安全性 (RLS) 使 QuickSight 数据集所有者能够基于和与数据交互的用户关联的权限以行粒度控制对数据的访问。借助 RLS，Amazon QuickSight 用户仅需要管理一组数据并将适当的行级别数据集规则应用到该组数据。所有关联的控制面板和分析将强制实施这些规则，从而简化数据集管理，且无需为具有不同数据访问权限的用户维护多个数据集。"
    },
    {
        "query":"在使用 Amazon QuickSight 时，私有 VPC 访问指什么？",
        "intention":"知识问答",
        "reply":"如果您在 AWS（也许是在 Amazon Redshift、Amazon Relational Database Service (RDS) 中，或在 EC2 上）或本地的没有公共连接的服务器上的 Teradata 或 SQL Server 上存有数据，此功能就是为您准备的。对 QuickSight 的私有 VPC (Virtual Private Cloud) 访问使用一个弹性网络界面 (ENI)，与 VPC 中数据源进行安全的私有通信。它还允许您使用 AWS Direct Connect 创建一个连接本地资源的安全、私有链接。"
    },
    {
        "query":"如何在 Amazon QuickSight 中共享分析、控制面板或情节？",
        "intention":"知识问答",
        "reply":"您可以使用 QuickSight 服务界面中的共享图标，共享分析、控制面板或情节。与他人共享内容之前，您将能够选择收件人（电子邮件地址、用户名或组名）、权限级别和其他选项。"
    },
    {
        "query":"能否从企业版降级为标准版？ 不能，您不能从 Amazon QuickSight 企业版降级为标准版。Amazon QuickSight 企业版提供了一些增强功能，如 QuickSight 读者、与私有 VPC 中数据源的连接性、行级安全性、SPICE 数据刷新功能（每小时刷新一次），以及 AD 连接性和基于组的资产管理功能（针对 AD 账户）。由于功能集存在差异，降级可能会在数据连接和安全性方面带来损失，因此不支持降级。",
        "intention":"知识问答",
        "reply":"要在未来几个月及时了解 QuickSight 的所有创新性新功能，请注册 QuickSight 更新信息电子邮件。"
    },
    {
        "query":"What is Amazon Managed Blockchain?",
        "intention":"知识问答",
        "reply":"A: Amazon Managed Blockchain is a fully managed service that allows you to join public networks or set up and manage scalable private networks using popular open-source frameworks. Amazon Managed Blockchain eliminates the overhead required to create the network or join a public network, and automatically scales to meet the demands of thousands of applications running millions of transactions. Once your network is up and running, Managed Blockchain makes it easy to manage and maintain your blockchain network. It manages your certificates and lets you easily invite new members to join the network."
    },
    {
        "query":"What can I do with Amazon Managed Blockchain?",
        "intention":"知识问答",
        "reply":"A: With Amazon Managed Blockchain, you can easily join public networks or create private networks across multiple AWS accounts with the open-source frameworks, Hyperledger Fabric and Ethereum. These blockchain frameworks enable network members to securely transact and share data on a distributed and immutable ledger. Additionally, you can configure voting rules for your network so members can democratically govern it (i.e., voting on who to invite to join)."
    },
    {
        "query":"How do I get started with Amazon Managed Blockchain?",
        "intention":"知识问答",
        "reply":"A: To get started with Amazon Managed Blockchain, go to the AWS Management Console and click on Amazon Managed Blockchain. Click on \"Create a network\" or “Join a network”. Follow the network creation wizard to create your first network and member, and then invite other AWS accounts to join. Alternatively, follow the join network wizard to join a public network, and then provision nodes to interact with the network.\nFor step-by-step instructions to get started, please visit [Get Started Creating a Hyperledger Fabric Network](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide/managed-blockchain-get-started-tutorial.html) and [Get Started with Ethereum](https://docs.aws.amazon.com/managed-blockchain/latest/ethereum-dev/managed-blockchain-ethereum-overview.html) in the Amazon Managed Blockchain documentation."
    },
    {
        "query":"How do you access Amazon Managed Blockchain?",
        "intention":"知识问答",
        "reply":"A: You can access Amazon Managed Blockchain from the AWS Management Console, AWS Command Line Interface (CLI), or AWS Software Development Kit (SDK).\nTo interact with the Hyperledger Fabric components provisioned and managed by Amazon Managed Blockchain, such as the certificate authority, ordering service, and peer nodes, you can use the open source Hyperledger Fabric CLI and SDK. Amazon Managed Blockchain provides endpoints to access these services, and you create a VPC PrivateLink endpoint for your network to access these endpoints. Please use a compatible version of the Hyperledger Fabric CLI and SDK with the version of Hyperledger Fabric specified in your network.\nTo interact with Ethereum smart contracts, your client uses a WebSocket or HTTP connection to a peer node endpoint in Managed Blockchain. Your node endpoint can only be accessed by your AWS Account. The client uses standard Ethereum JSON-RPC API methods to query and submit transactions to your node, which participates on the Ethereum network."
    },
    {
        "query":"What is a blockchain network?",
        "intention":"知识问答",
        "reply":"A: Blockchain is a technology that makes it possible to build applications where multiple parties can record transactions without the need for a trusted, central authority to ensure that transactions are verified and secure.\nBlockchain enables this by establishing a peer-to-peer network (a blockchain network) where each participant in the network has access to a shared ledger where the transactions are recorded. These transactions are by design, immutable and independently verifiable."
    },
    {
        "query":"What is the difference between Amazon Managed Blockchain and Amazon Quantum Ledger Database (QLDB)?",
        "intention":"知识问答",
        "reply":"A: QLDB is a ledger database purpose-built for customers who need to maintain a complete and verifiable history of data changes in an application that they own and manage in a centralized way. Amazon QLDB is not a blockchain technology. Instead, blockchain technologies focus enabling multiple parties to transact and share data securely in a decentralized way; without a trusted, central authority. Every member in a network has an independently verifiable copy of an immutable ledger, and members can create and endorse transactions in the network. Amazon Managed Blockchain is a fully managed blockchain service that enables multiple parties to transact and share data directly and securely without the need for a central, trusted authority."
    },
    {
        "query":"What open source blockchain frameworks does Amazon Managed Blockchain support?",
        "intention":"知识问答",
        "reply":"A: Amazon Managed Blockchain supports the open source Hyperledger Fabric and Ethereum frameworks."
    },
    {
        "query":"What region is the Amazon Managed Blockchain currently available in?",
        "intention":"知识问答",
        "reply":"A: Please visit the AWS Region Table to see the regions where you can use Amazon Managed Blockchain."
    },
    {
        "query":"What is the difference between the Amazon Managed Blockchain Starter Edition and Standard Edition network types?",
        "intention":"知识问答",
        "reply":"A: Amazon Managed Blockchain offers two different network types: Starter Edition and Standard Edition. Each type is aimed for a particular set of use cases, and has a different hourly membership rate.\nThe Amazon Managed Blockchain Starter Edition network is designed for test networks and small production networks. It has several different attributes than the Standard Edition: You can have a maximum of 5 members per network and 2 peer nodes per member. Available peer node types are bc.t3.small and bc.t3.medium. The ordering service provisioned in a Starter Edition network has lower transaction throughput and availability than that in a Standard Edition network.\nThe Amazon Managed Blockchain Standard Edition network is designed for production networks. It has several different attributes than the Starter Edition: You can have a maximum of 14 members per network and 3 peer nodes per member. The bc.t3, bc.m5, and bc.c5 instance families are available instance types for peer nodes. The ordering service provisioned in a Standard Edition network has higher transaction throughput and availability than that in a Starter Edition network."
    },
    {
        "query":"How do I invite other AWS accounts to join the blockchain network?",
        "intention":"知识问答",
        "reply":"A: You can create a proposal to invite another AWS account to the blockchain network, and the current members in that network vote on the proposal. If the proposal becomes approved based on the voting rules of the network, then the other AWS account will receive an invitation to join the network."
    },
    {
        "query":"Does the account that creates an Amazon Managed Blockchain network own that resource?",
        "intention":"知识问答",
        "reply":"A: An Amazon Managed Blockchain network is a decentralized resource where multiple AWS accounts have an equal ownership stake depending on the voting rules specified at the network’s creation. With the Approval Threshold Policy type, though an initial AWS account creates the network, governance can be distributed among multiple members after they join the network. If the initial member of the network leaves, that network will still be active among the remaining members."
    },
    {
        "query":"How do I delete an Amazon Managed Blockchain network?",
        "intention":"知识问答",
        "reply":"A: An Amazon Managed Blockchain network is deleted once the last member in the network deletes their membership. If you have created a multi-member blockchain network in your AWS account, the network will be deleted once you delete all of the members. If you are in a blockchain network with memberships that you do not own, the network will only be deleted when the last member deletes their membership. If you delete your member and there are other members still in the network, that network will not be terminated. When Amazon Managed Blockchain is generally available, there will be configurable options to terminate a network if the founding member leaves."
    },
    {
        "query":"How do I create a VPC PrivateLink endpoint to access Hyperledger Fabric resources provisioned for the network?",
        "intention":"知识问答",
        "reply":"A: Amazon Managed Blockchain provides endpoints to interact with your Hyperledger Fabric resources, specifically the Hyperledger Fabric certificate authority, ordering service, and peer nodes. To access these endpoints, you need to create a VPC PrivateLink endpoint in the VPC from which you would like to access the network. You can create a VPC PrivateLink endpoint from the VPC console, AWS CLI, or AWS SDK. When creating your endpoint, use the VPC Endpoint Service Name provided in the Amazon Managed Blockchain network details. If you have created multiple members in a single AWS account, you only need to create on VPC PrivateLink endpoint and not one for each member. Please note that you are billed separately for VPC PrivateLink endpoints you create and use. Please visit the [Amazon Managed Blockchain documentation](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide) for more information on creating VPC PrivateLink endpoints for your network."
    },
    {
        "query":"How do I use the open source Hyperledger Fabric CLI or SDK on a client node to interact with my Amazon Managed Blockchain resources?",
        "intention":"知识问答",
        "reply":"A: To interact with the Hyperledger Fabric certificate authority (CA), peer nodes, and ordering service created for your network, you can use the open source Hyperledger Fabric CLI or SDK and configure them with the respective endpoint information provided. Amazon Managed Blockchain exposes the endpoints for these components using a VPC PrivateLink endpoint that you create in your VPC. The Amazon EC2 instance or other resource running the Hyperledger Fabric CLI or SDK must have a route to reach this VPC PrivateLink endpoint. For instructions on how to configure these clients, please visit the [Amazon Managed Blockchain documentation](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide)."
    },
    {
        "query":"What are the components of Hyperledger Fabric?",
        "intention":"知识问答",
        "reply":"A: An Amazon Managed Blockchain for Hyperledger Fabric creates and manages the required components on your behalf that are needed to run a network. A Hyperledger Fabric network includes the ordering service, certificate authority, and peer components.\nTo interact with these components, you use an open source Hyperledger Fabric CLI or SDK from a client host that you create and manage. For more information about Hyperledger Fabric, please visit the [Amazon Managed Blockchain documentation](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide)."
    },
    {
        "query":"How do I create a channel in my Hyperledger Fabric network?",
        "intention":"知识问答",
        "reply":"A: Hyperledger Fabric channel is a private “subnet” of communication between two or more specific network members, for the purpose of conducting private and confidential transactions. Each transaction on the blockchain network is executed on a channel, where each party must be authenticated and authorized to transact on that channel.\nTo create a new channel in your Amazon Managed Blockchain network, you use the open source Hyperledger Fabric CLI or SDK with the endpoints exposed on your Hyperledger Fabric resources. You call configuration system chaincode, which creates a genesis block for the channel ledger, which stores configuration information about the channel policies, members, and anchor peer nodes for the channel. Please visit the [Amazon Managed Blockchain documentation](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide) to learn more about creating a Hyperledger Fabric channel."
    },
    {
        "query":"How do I deploy chaincode applications to Hyperledger Fabric network?",
        "intention":"知识问答",
        "reply":"A: Chaincode is a program that typically handles business logic agreed to by members of the network and is sometimes called a “smart contract.” To install and instantiate chaincode on the blockchain network, you use the open source Hyperledger Fabric CLI or SDK with the endpoints exposed on your Hyperledger Fabric resources. Additionally, only admin users in your membership can do these operations. To learn more about using chaincode with Hyperledger Fabric, please visit the [Amazon Managed Blockchain documentation](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide)."
    },
    {
        "query":"How do I control access to my Amazon Managed Blockchain resources?",
        "intention":"知识问答",
        "reply":"A: Hyperledger Fabric on Managed Blockchain uses certificates to identify users in each membership and determine their permissions on the network. You can create and manage these users using the Hyperledger Fabric certificate authority. Ethereum nodes on Managed Blockchain use Signature Version 4 to authenticate JSON-RPC calls to the node."
    },
    {
        "query":"How do I access the endpoints on the Hyperledger Fabric components managed by Amazon Managed Blockchain?",
        "intention":"知识问答",
        "reply":"A: To access the endpoints on the Hyperledger Fabric components managed by Amazon Managed Blockchain, such as the Hyperledger Fabric certificate authority, ordering service, and peer nodes, you need to create a VPC PrivateLink endpoint in the VPC from which you would like to access the network. You can create a VPC PrivateLink endpoint from the VPC console, Amazon Managed Blockchain console, AWS CLI, or AWS SDK. When creating your endpoint, use the VPC Endpoint Service Name provided in the Amazon Managed Blockchain network details. If you have created multiple members in a single AWS account, you only need to create on VPC PrivateLink endpoint and not one for each member. Your client will also be able to interact with peer nodes from other members in the network to receive endorsements for proposed transactions.\nPlease note that you are billed separately for VPC PrivateLink endpoints you create and use. Please visit the [Amazon Managed Blockchain](https://docs.aws.amazon.com/managed-blockchain/latest/managementguide) documentation for more information on creating VPC PrivateLink endpoints for your network."
    },
    {
        "query":"Can I create multiple peer nodes to increase the availability of my blockchain components?",
        "intention":"知识问答",
        "reply":"A: In the Standard Edition, you can create up to 3 blockchain peer nodes in each membership across Amazon EC2 availability zones for high availability. In the Starter Edition, you can create 2 peer nodes per membership. For Ethereum on Amazon Managed Blockchain, you can create up to 50 nodes per AWS account across Amazon EC2 availability zones."
    },
    {
        "query":"What permissions does the admin user configure when creating my network member?",
        "intention":"知识问答",
        "reply":"A: The admin user you configure when creating your network member serves as the initial user in your Hyperledger Fabric membership. You can use the username and password to enroll this user with your Hyperledger Fabric certificate authority and create additional users in your membership. The admin user can also create channels on the network, and install and instantiate chaincode applications."
    },
    {
        "query":"Is there any maintenance downtime for my blockchain components?",
        "intention":"知识问答",
        "reply":"A: There's no downtime for Ethereum nodes. Hyperledger Fabric peer nodes will have less than a minute downtime when we apply security patches, typically on a monthly basis or as needed. You will receive notification of upcoming maintenance in your Personal Health Dashboard. You can create multiple peers to mitigate this downtime, as only one peer per member will be patched at a time. Having multiple peers is recommended for high availability in general."
    },
    {
        "query":"How is Amazon Managed Blockchain priced?",
        "intention":"知识问答",
        "reply":"A: There is no up-front commitment with Amazon Managed Blockchain. For Hyperledger Fabric on Amazon Managed Blockchain, you simply pay an hourly charge (billed per second) for your network membership, peer nodes, and peer node storage, and you pay for data you write to the network. Amazon Managed Blockchain offers two editions, the Standard Edition and the Starter Edition, and each edition has a different membership hourly rate. Additionally, you pay standard data transfer rates. To interact with your Amazon Managed Blockchain resources, you will need a VPC PrivateLink endpiont that is billed separately. Amazon Managed Blockchain for Ethereum allows you to create nodes and join them to Ethereum public networks. You are charged for the node, node storage, and the number of Ethereum requests you make.\nPlease visit the [Amazon Managed Blockchain pricing page](https://aws.amazon.com/managed-blockchain/pricing/) for more information."
    },
    {
        "query":"Is there a different price for the Amazon Managed Blockchain Starter Edition and Standard Edition?",
        "intention":"知识问答",
        "reply":"A: Yes, there is a different hourly membership rate for the Amazon Managed Blockchain Starter Edition and Standard Edition. Each edition is designed for a particular set of use cases. Please visit the Amazon Managed Blockchain [pricing page](https://aws.amazon.com/managed-blockchain/pricing/) for more information."
    },
    {
        "query":"什么是 Amazon Simple Notification Service (Amazon SNS)？",
        "intention":"知识问答",
        "reply":"Amazon Simple Notification Service (Amazon SNS) 是一种让用户能够轻松设置、操作并从[云](https://aws.amazon.com/cn/what-is-cloud-computing/)中发送通知的 Web 服务。它为开发人员提供高度可扩展、灵活并且经济高效的从应用程序发布消息的功能，并立即将它们发送给订阅者或其他应用程序。该服务旨在让开发人员能更轻松地进行 Web 级的计算。Amazon SNS 遵循“[发布-订阅”(pub-sub) 消息收发范式](https://aws.amazon.com/cn/pub-sub-messaging/)，使用“推送”机制将通知传输到客户端，无需定期检查或“轮询”新信息和更新。Amazon SNS 使用的 API 简单，前期需要投入的开发精力极小，无维护或管理开销，并且按实际用量付费，从而使开发人员能够通过一种简单的机制将功能强大的通知系统融入其应用程序中。"
    },
    {
        "query":"如何开始使用 Amazon SNS？",
        "intention":"知识问答",
        "reply":"您可以完成我们的 10 分钟教程[发送扇出事件通知](https://aws.amazon.com/cn/getting-started/tutorials/send-fanout-event-notifications/)，通过几个步骤创建 Amazon SNS 主题并发布消息。\n有关更多详细信息，请参阅 [Amazon SNS 开发人员指南](http://docs.aws.amazon.com/sns/latest/dg/)和[资源中心内的示例代码](http://aws.amazon.com/code/Amazon-SNS?browse=1)。"
    },
    {
        "query":"使用 Amazon SNS 有哪些好处？",
        "intention":"知识问答",
        "reply":"Amazon SNS 在构建和集成松散耦合的分布式应用程序方面具备多种优势，这也使其成为一种多功能的选择："
    },
    {
        "query":"Amazon SNS 通知有哪些典型用途？",
        "intention":"知识问答",
        "reply":"Amazon SNS 服务可满足各种需求，包括事件通知、监控应用程序、工作流程系统、时间敏感型信息更新、移动应用程序，以及生成或使用通知的任何其他应用程序。例如，在工作流系统中，Amazon SNS 可用来在分布式计算机应用程序中中继事件、在数据存储之间移动数据或更新业务系统中的记录。有关验证、批准、库存更改和发货状态的事件更新和通知，将会立即传输到相关系统组件及最终用户。一种常见的模式是使用 SNS 将消息发布到 [Amazon SQS](https://aws.amazon.com/cn/sqs/) 消息队列，进而以可靠的方式将消息异步发送到一个或多个系统组件。Amazon SNS 的另一种典型用途是将时间关键型事件中继到移动应用程序及设备。由于 Amazon SNS 具备很高的可靠性和可扩展性，所以如果开发人员要创建基于实时事件的应用程序，那他们必会受益匪浅。"
    },
    {
        "query":"Amazon SNS 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon SNS 非常容易上手。开发人员必须首先创建一个“主题”（即一个“接入点”）– 标明特定的主题或事件类型，用来发布消息并允许客户端订阅通知。创建主题后，主题所有者可为其设置策略，例如，限制可以发布消息或订阅通知的人员，或者指定支持哪些通知协议（即 HTTP/HTTPS、电子邮件、SMS）。订阅者是指有兴趣从关注的主题接收通知的客户端；它们可以订阅主题，也可以由主题所有者为其订阅。订阅者需要为传送的通知指定协议和终端节点（URL、电子邮件地址等）。当发布者有需要通知订阅者的信息或更新时，他们可以向该主题发布一条消息 – 这样将立即触发 Amazon SNS 向所有适用的订阅者发送该消息。"
    },
    {
        "query":"Amazon SNS 与 Amazon SQS 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon Simple Queue Service (SQS) 和 Amazon SNS 都是 AWS 中的消息收发服务，但为开发人员提供了不同的优势。Amazon SNS 允许应用程序通过“推送”机制向多个订阅者发送时间关键型消息，并且无需定期检查或“轮询”更新。Amazon SQS 是一种供分布式应用程序使用的[消息队列服务](https://aws.amazon.com/cn/message-queue/)，通过轮询模式交换消息，可用于分离收发组件。Amazon SQS 使应用程序的分布式组件可以灵活地收发消息，并且不要求每个组件同时可用。\n一种常见的模式是使用 SNS 将消息发布到 Amazon SQS 队列，进而以可靠的方式将消息异步发送到一个或多个系统组件。"
    },
    {
        "query":"Amazon SNS 与 Amazon MQ 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon MQ、Amazon SQS 和 Amazon SNS 都是消息收发服务，适用于从初创公司到大型企业的任何规模的企业。如果您正在使用现有应用程序中的消息收发功能，并且想要快速轻松地将消息收发功能移至云中，我们建议您考虑使用 [Amazon MQ](https://aws.amazon.com/cn/amazon-mq/)。它支持多种行业标准 API 和协议，因此您可以从任何基于标准的消息代理切换到 Amazon MQ，无需重新编写应用程序中的消息收发代码。如果您要在云中构建全新的应用程序，我们建议您考虑使用 Amazon SQS 和 Amazon SNS。Amazon SQS 和 SNS 是轻型的、完全托管的消息队列和主题服务，可以几乎无限地进行扩展，并可提供易于使用的简单 API。您可以使用 Amazon SQS 和 SNS 分离和扩展微服务、分布式系统和无服务器应用程序，以及提高可靠性。"
    },
    {
        "query":"如何开始使用 Amazon SNS？",
        "intention":"知识问答",
        "reply":"要注册 Amazon SNS，请单击 Amazon SNS 详细信息页面上的“Sign up for Amazon SNS” 按钮。您必须拥有一个 Amazon Web Services 账户才能访问此服务；如果还没有该账户，则在您开始 Amazon SNS 注册过程时，系统会提示您创建一个账户。注册后，请参阅 Amazon SNS 文档和《入门指南》，以便开始使用 Amazon SNS。使用 AWS 管理控制台，您可以轻松地创建主题、添加订阅者、发送通知和编辑主题策略，所有这一切操作都能从您的浏览器中执行。"
    },
    {
        "query":"AWS 管理控制台中是否支持 Amazon SNS？",
        "intention":"知识问答",
        "reply":"[AWS 管理控制台](http://aws.amazon.com/console)支持 Amazon SNS，并提供了一个基于 Web 的点击式界面来访问和管理 Amazon SNS。使用 AWS 管理控制台，您可以创建主题、添加订阅者和发送通知，所有这一切操作都能从您的浏览器中执行。此外，您还可以使用 AWS 管理控制台轻松将消息发布到所选的终端节点（HTTP、SQS、Lambda、移动推送、电子邮件或 SMS）并编辑主题策略来控制发布者和订阅者的访问权限。"
    },
    {
        "query":"各个区域中 Amazon SNS 服务的接入点是什么？",
        "intention":"知识问答",
        "reply":"有关所有 Amazon SNS 服务接入点的最新列表，请参阅 AWS 文档的 [AWS 区域和终端节点](http://docs.aws.amazon.com/general/latest/gr/rande.html#sns_region)部分。"
    },
    {
        "query":"我能否获得从我的账户发起的所有 SNS API 调用的历史记录，以便用于安全分析和运营方面的故障排除？",
        "intention":"知识问答",
        "reply":"可以。SNS 支持 [AWS CloudTrail](https://aws.amazon.com/cn/cloudtrail/)，该服务是一种记录账户的 AWS API 调用，并向您发送日志文件的 Web 服务。借助 CloudTrail，您可以获得 API 调用者标识、API 调用时间、API 调用者源 IP 地址、请求参数和 SNS 返回的响应元素之类信息的历史纪录。\nSNS 目前仅支持对身份验证调用进行 CloudTrail 审计。现在不能提供未经身份验证的 ConfirmSubscription 和 Unsubscribe 调用的 CloudTrail 审计日志。有关更多信息，请参阅 [SNS 开发人员指南的 CloudTrail 部分](http://docs.aws.amazon.com/sns/latest/dg/logging-using-cloudtrail.html)。\n要获取从您的账户发起的 SNS API 调用的历史记录，您只需[在 AWS 管理控制台中打开 AWS CloudTrail](https://console.aws.amazon.com/cloudtrail) 即可。如需了解有关 AWS CloudTrail 的更多信息，请[单击此处](https://aws.amazon.com/cn/cloudtrail/)。"
    },
    {
        "query":"我的 Amazon SNS 的账单周期怎么计算？",
        "intention":"知识问答",
        "reply":"您的 Amazon SNS 账单周期从每月第一天开始，到每月的最后一天结束。您的月度费用将在每月结束时汇总。"
    },
    {
        "query":"Amazon SNS 主题有什么格式要求？",
        "intention":"知识问答",
        "reply":"主题名称不能超过 256 个字符。允许使用字母数字字符以及连字符 (-) 和下划线 (\\_)。AWS 账户中的主题名称必须唯一。删除主题后，可以重新使用该主题名称。创建主题后，Amazon SNS 将为该主题分配唯一的 ARN（Amazon 资源名称），其中包括服务名称 (SNS)、区域、用户的 AWS ID 和主题名称。ARN 将作为创建主题时使用的 API 调用的一部分返回。无论何时发布者或订阅者需要对该主题执行任何操作，都应引用该唯一主题 ARN。\n下面是由 AWS 账户 ID 为“123456789012”的用户创建并在美国东部区域托管的名为“mytopic”的主题的 ARN：\narn:aws:sns:us-east-1:1234567890123456:mytopic 注意：用户不应尝试从其单独的组件构建主题 ARN，而应始终使用 API 调用返回的名称来创建主题。"
    },
    {
        "query":"Amazon SNS 可使用哪些操作？哪些人可执行这些操作？",
        "intention":"知识问答",
        "reply":"Amazon SNS 提供了一组简单的 API 以便为主题所有者、订阅者和发布者启用事件通知。\n所有者的操作：\n订阅者的操作：\n发布者的操作："
    },
    {
        "query":"为什么有两种不同的 API 用于列出订阅？",
        "intention":"知识问答",
        "reply":"用于列出订阅的两种 API 执行不同的功能并返回不同结果："
    },
    {
        "query":"有哪些不同的传输格式/协议用于接收通知？",
        "intention":"知识问答",
        "reply":"“SQS”– 用户可以将 SQS 标准或 FIFO 队列指定为终端节点；Amazon SNS 将在指定队列对通知消息排队（然后，订阅者就可以使用 ReceiveMessage、DeleteMessage 等 SQS API 进行处理了）。"
    },
    {
        "query":"主题所有者是否可以控制他们所创建/拥有的主题中允许的传输协议？",
        "intention":"知识问答",
        "reply":"主题所有者可以通过访问控制策略设置相应的权限，由此为其主题配置特定的传输协议。"
    },
    {
        "query":"所有者如何设置访问控制策略？",
        "intention":"知识问答",
        "reply":"请参阅《Amazon SNS 入门指南》，了解设置访问控制策略的概况。"
    },
    {
        "query":"单个主题是否支持通过多种传输协议进行订阅？",
        "intention":"知识问答",
        "reply":"Amazon SNS 主题订阅者可以通过主题支持的任何传输协议接收通知。主题可支持通过多种传输协议来传送订阅和通知。"
    },
    {
        "query":"订阅者是否可以选择性地只接收一部分发布至某个主题的消息？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 Amazon Simple Notification Service (SNS) 上的消息筛选功能来构建更简单且更精简的发布/订阅架构。利用消息筛选功能，Amazon SNS 主题订阅者能够选择性地只接收一部分他们感兴趣的消息，而不是接收发布至某个主题的所有消息。要监控 SNS 订阅筛选策略，请使用 Amazon CloudWatch 指标，系统将为您自动收集这些指标。您还可以使用 [AWS CloudFormation](https://aws.amazon.com/cn/cloudformation/) 模板中的 [AWS::SNS::Subscription](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-sns-subscription.html) 资源类型快速部署利用 SNS 消息筛选功能的解决方案。有关更多详细信息，请试用我们的 10 分钟教程[筛选发布到主题的消息](https://aws.amazon.com/cn/getting-started/tutorials/filter-messages-published-to-topics/)，或参阅我们文档中的[使用 Amazon SNS 筛选信息](https://docs.aws.amazon.com/sns/latest/dg/message-filtering.html)。"
    },
    {
        "query":"Amazon SNS 是否可与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"Amazon SNS 可与 Amazon SQS、Amazon EC2 和 Amazon S3 等 AWS 产品配合使用。下面是一个订单处理工作流系统将 Amazon SNS 与 Amazon EC2、SQS 和 SimpleDB 配合使用的示例。在此工作流系统中，每当发生交易或订单在订单处理流程中推进时，应用程序组件之间都会发送消息。客户最初下达订单时，交易首先在 Amazon SimpleDB 中记录，并且 Amazon EC2 上运行的应用程序将订单请求转发到付款处理程序，同时从客户的信用卡或银行账户中扣款。批准后，系统将向 Amazon SNS 主题发布订单确认消息。在这种情况下，该主题包括了多种通过电子邮件/HTTP 的订阅者（商家、客户和供应链合作伙伴），Amazon SNS 针对该主题发送的通知可即时向所有订阅者提供付款处理成功的更新信息。也可使用通知来协调 EC2 上运行的订单处理系统，其中通过 HTTP 发送的通知可以触发相关组件（例如，库存系统或发货服务）中的实时处理。通过集成 Amazon SNS 与 Amazon SQS，传送的所有通知还将保留在 Amazon SQS 队列中，将来由审计应用程序进行处理。"
    },
    {
        "query":"Amazon SNS 是否在提供 AWS 产品的所有区域均可用？",
        "intention":"知识问答",
        "reply":"有关 Amazon SNS 可用性的最新信息，请参阅 AWS 文档的 [AWS 区域和终端节点](http://docs.aws.amazon.com/general/latest/gr/rande.html#sns_region)部分。"
    },
    {
        "query":"客户需要多久才能使用以前的主题名称重新创建主题？",
        "intention":"知识问答",
        "reply":"通常，大约在删除名称相同的旧主题 30-60 秒后，便可重新使用该主题名称了。确切的时间取决于该主题上有效的订阅数 – 主题订阅者越少，重新使用需等待的时间就越短；主题订阅者人数越多，等待的时间就越长。"
    },
    {
        "query":"什么是 SNS FIFO 主题？",
        "intention":"知识问答",
        "reply":"与标准 SNS 主题类似的是，[SNS FIFO 主题](https://docs.aws.amazon.com/sns/latest/dg/sns-fifo-topics.html)可使用户发布消息到主题中，从而使消息可以传输到一系列的订阅终端节点。如果将这些消息传输给订阅者必须按顺序一次进行（先进先出），且您希望 SNS 来处理它，则 SNS FIFO 主题是最好的办法。Amazon SNS FIFO 主题会将按顺序列队的消息传输到 Amazon Simple Queue Service (Amazon SQS) FIFO 队列中，从而为分布式应用程序提供一致的端到端消息排序。您现在可以减少处理高吞吐量、一致性排序交易所需的工作，并简化您的消息收发架构。相关示例使用案例包括银行交易日志、股票报价器、航班跟踪器、价格更新、新闻广播和库存管理。"
    },
    {
        "query":"应该何时使用 SNS FIFO 主题，何时使用 Kinesis Data Streams？",
        "intention":"知识问答",
        "reply":"SNS FIFO 主题和 Kinesis Streams 都可以让您构建需要严格顺序的多对多消息收发的应用程序。SNS FIFO 主题可以进一步发现需要大量按顺序扇出（最多 100 个订阅者）的应用程序集成使用案例。另一方面，Kinesis Streams 支持最高达 5 个订阅者的按顺序扇出，通常用于分析和异常检测使用案例。"
    },
    {
        "query":"用户如何订阅通过电子邮件传送的通知？",
        "intention":"知识问答",
        "reply":"要接收特定主题的电子邮件通知，订阅者应将协议指定为“电子邮件”或“电子邮件-JSON”，并提供有效的电子邮件地址作为终端节点。使用 AWS 管理控制台或直接调用 Amazon SNS API 即可完成此操作。然后，Amazon SNS 将发送一份包含确认链接的电子邮件到指定的电子邮件地址，并要求查阅该电子邮件地址的用户明确同意接收该特定主题的电子邮件通知。用户通过单击提供的链接确认订阅后，系统将向该电子邮件地址传送此主题下发布的所有消息。"
    },
    {
        "query":"为什么 Amazon SNS 提供两种不同的传输协议，以通过电子邮件接收通知？",
        "intention":"知识问答",
        "reply":"这两种电子邮件传输协议面向两种不同的客户/最终用户类型。“电子邮件-JSON”发送 JSON 对象形式的通知，适用于以编程方式处理电子邮件的应用程序。“电子邮件”传输适用于最终用户/消费者，通知为普通的文本消息，易于阅读。"
    },
    {
        "query":"用户是否可更改通过“电子邮件/电子邮件-JSON”发送的通知的主题和显示名称？",
        "intention":"知识问答",
        "reply":"Amazon SNS 允许用户将电子邮件的“Subject”字段指定为从 Publish API 调用中传入的参数，并且对于每个已发布的消息都可以不同。使用 SetTopicAttributes API 可设置主题的显示名称 – 该名称适用于从此主题发送的所有电子邮件。"
    },
    {
        "query":"要接收 Amazon SNS 的通知，订阅者是否需要对其电子邮件设置进行特别配置？",
        "intention":"知识问答",
        "reply":"大多数情况下，用户无需特别操作即可接收 Amazon SNS 的订阅确认和通知。不过，有些时候电子邮件提供商的默认设置或其他用户特定的配置会误将电子邮件转移到垃圾邮件文件夹。为确保用户可看到 Amazon SNS 发送的确认消息和通知，用户可以将“no-reply@sns.amazonaws.com”添加到联系人列表，并检查其垃圾邮件文件夹中是否有 Amazon SNS 的消息。"
    },
    {
        "query":"用户是否需要在订阅前创建 SQS 队列，以防电子邮件地址作为终端节点进入 SQS 队列？ 队列需要什么权限？",
        "intention":"知识问答",
        "reply":"使用 SQS 控制台，用户应先创建 SQS 队列，然后才能使其订阅主题。在控制台上选择此队列，并从工具栏的“Queue Actions”下拉列表中选择“Subscribe Queue to SNS Topic”。在订阅对话框中，从“Choose a Topic”下拉列表中选择主题，并单击“Subscribe”按钮。要获得完整的分步说明，请参阅 [Amazon SNS 文档](https://aws.amazon.com/cn/documentation/sns/)。"
    },
    {
        "query":"要接收 Amazon SNS 通知，开发人员需要如何设置 Amazon SQS 队列？",
        "intention":"知识问答",
        "reply":"要让 Amazon SNS 向 SQS 队列传送通知，开发人员应订阅主题，指定“SQS”为传输协议，并指定有效的 SQS 标准队列为终端节点。为了使 SQS 队列能够接收来自 Amazon SNS 的通知，该 SQS 队列所有者必须订阅有关 Amazon SNS 的主题，以便成功地向队列提交消息。\n如果订阅的 Amazon SNS 主题和接收通知的 SQS 队列归同一用户所有，则无需其他操作。发布到该主题的任何消息将自动传送到指定的 SQS 队列。如果 SQS 队列所有者不是该主题的所有者，则 Amazon SNS 将要求明确确认订阅请求。\n有关 SQS 队列订阅主题以及为 SQS 队列设置访问控制策略的更多详细信息，请参阅 [Amazon SNS 文档](https://aws.amazon.com/cn/documentation/sns/)。"
    },
    {
        "query":"如何向多个 SQS 队列群发相同的消息？",
        "intention":"知识问答",
        "reply":"首先，使用 SNS 创建一个 SNS 主题。然后，创建多个 SQS 标准队列并为其订阅该 SNS 主题。现在，无论消息何时发送到 SNS 主题，都会被群发到 SQS 队列，也就是说，SNS 会将该消息传送给所有订阅该主题的 SQS 队列。"
    },
    {
        "query":"Amazon SNS 发送的结构化通知消息是什么格式？",
        "intention":"知识问答",
        "reply":"由 Amazon SNS 发送并通过 HTTP、HTTPS、电子邮件-JSON 和 SQS 传输协议传送的通知消息包含一个简单的 JSON 对象，它由下列信息组成：\n通过“电子邮件”传输协议发送的通知消息仅包含从发布者接收到的负载（消息正文）。"
    },
    {
        "query":"用户如何订阅通过 SMS 传送的通知？",
        "intention":"知识问答",
        "reply":"请参阅下面的“SMS 相关问题”一节。"
    },
    {
        "query":"用户如何确保向我的主题发送的消息是安全的？",
        "intention":"知识问答",
        "reply":"针对 Amazon SNS 的所有 API 调用都会根据该用户的 AWS ID 和签名进行验证。此外，我们建议用户通过连接到我们安全的 SSL 终端节点，确保网络传输数据的安全性。"
    },
    {
        "query":"谁可以创建主题？",
        "intention":"知识问答",
        "reply":"只有已注册 Amazon SNS、具有有效 AWS ID 的用户才能创建主题。创建主题最简单的方式是使用 AWS 管理控制台。此外，也可以通过 CreateTopic API 创建。可通过以下网址访问 AWS 管理控制台：<http://aws.amazon.com/console>"
    },
    {
        "query":"多个用户是否可以向单个主题发布消息？",
        "intention":"知识问答",
        "reply":"主题所有者可以设置明确权限，以允许多个用户（具有有效 AWS ID）向一个主题发布消息。默认情况下，只有主题所有者拥有向主题发布消息的权限。"
    },
    {
        "query":"所有者如何授予/撤消主题的发布或订阅权限？",
        "intention":"知识问答",
        "reply":"AddPermission 和 RemovePermission API 提供简洁的界面，供开发人员添加和删除主题的权限。但是，对于条件性访问和更高级的使用案例，用户则应使用访问控制策略来管理权限。管理权限最简单的方式是使用 AWS 管理控制台。可通过以下网址访问 AWS 管理控制台：<http://aws.amazon.com/console>"
    },
    {
        "query":"主题所有者如何授予订阅者访问权限？ 订阅者是否必须拥有有效的 AWS ID？",
        "intention":"知识问答",
        "reply":"无论用户有/无 AWS ID，Amazon SNS 都能让他们轻松接收通知。主题所有者可使用访问控制策略为主题设置相应的权限，以便对订阅者授予/限制访问权限。用户可通过两种方式从 Amazon SNS 接收通知：\n在以上两种情况下，订阅终端节点的所有者都需要通过答复 Amazon SNS 发送的确认消息，明确同意并确认订阅。"
    },
    {
        "query":"Amazon SNS 如何对 API 调用进行身份验证？",
        "intention":"知识问答",
        "reply":"Amazon SNS 将对所有 API 调用进行身份验证，其方法是要求使用 AWS ID 账户的密钥签署请求，并验证包含在请求中的签名。"
    },
    {
        "query":"Amazon SNS 如何验证订阅请求，以确保通知不会作为垃圾邮件发送给用户？",
        "intention":"知识问答",
        "reply":"作为订阅注册的一部分，Amazon SNS 将确保通知仅发送到已注册的有效订阅者/终端节点。为防止垃圾邮件并确保订阅者终端节点确实有兴趣接收特定主题的通知，Amazon SNS 将通过“2 步式握手”要求订阅者明确同意接收：\ni.当用户首次调用 Subscribe API 并订阅终端节点时，Amazon SNS 将向指定的终端节点发送确认消息。\nii.当终端节点收到确认消息后，订阅者应通过发送有效答复确认订阅请求。只有此时 Amazon SNS 才会将订阅请求视为有效。如果对询问没有响应，Amazon SNS 则不会向该终端节点发送任何通知。确认订阅的具体机制因所选的传输协议而异：\n注意：如果您向您 Amazon SNS 主题订阅 Amazon SQS 队列，且两者属于同一 AWS 账户“所有”，在这种特殊情况下，您不必执行上述明确“同意”操作。"
    },
    {
        "query":"等待确认时，订阅请求需要在待处理状态保持多长时间？",
        "intention":"知识问答",
        "reply":"对于订阅请求，发送到终端节点的确认消息中附带的令牌有效期为 3 天。"
    },
    {
        "query":"谁可以更改主题的权限？",
        "intention":"知识问答",
        "reply":"只有主题所有者可以更改该主题的权限。"
    },
    {
        "query":"用户如何验证通知消息是从 Amazon SNS 发出的？",
        "intention":"知识问答",
        "reply":"为确保通知的真实性，Amazon SNS 将使用密码安全、非对称的机制（基于证书的私有-公有密钥对）来签署传送的所有通知。Amazon SNS 会将其证书发布到用户熟知的位置（例如，在美国东部区域为 <http://sns.us-east-1.amazonaws.com/SimpleNotificationService.pem>），并使用该证书的私有密钥签署消息。开发人员/应用程序可使用该证书的公有密钥获取证书并验证通知中的签名，以确保该通知确实是由 Amazon SNS 发出的。有关证书位置的更多详细信息，请参阅 Amazon SNS 详细信息页面。"
    },
    {
        "query":"发布者是否也必须签署消息？",
        "intention":"知识问答",
        "reply":"Amazon SNS 要求拥有 AWS ID 的发布者使用其 AWS 秘密密钥签署消息以进行验证，然后再由 Amazon SNS 验证签名。"
    },
    {
        "query":"发布者/订阅者是否可使用 SSL 确保消息的安全性？",
        "intention":"知识问答",
        "reply":"可以，发布者和订阅者都可使用 SSL 帮助确保收发消息的通道安全。发布者可通过 HTTPS 连接到 Amazon SNS，并经由 SSL 通道发布消息。作为订阅注册的一部分，订阅者应注册一个启用了 SSL 的终端节点，这样通知将通过 SSL 通道传送给终端节点。"
    },
    {
        "query":"订阅者要允许 Amazon SNS 向注册的终端节点发送通知，需具有什么权限？",
        "intention":"知识问答",
        "reply":"接收通知的终端节点所有者必须向 Amazon SNS 授予向该终端节点发送消息的权限。"
    },
    {
        "query":"如何取消订阅？",
        "intention":"知识问答",
        "reply":"订阅者可以通过主题所有者、订阅所有者或其他方式取消订阅，具体取决于确认订阅请求所使用的机制。\n在所有情况下，除非由订阅所有者取消订阅，否则都会向终端节点发送一条最终取消消息，以方便终端节点所有者重新订阅该主题（特别是无意中发出取消订阅请求或出现错误的情况）。有关 ConfirmSubscription API 的更多详细信息，请参阅 Amazon SNS 文档。"
    },
    {
        "query":"Amazon SNS 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"是，AWS HIPAA 合规性计划将 Amazon SNS 作为一项符合 HIPAA 要求的服务包含在内。如果您与 AWS 签订了已生效的商业伙伴协议 (BAA)，那么您现在可以使用 Amazon SNS 构建符合 HIPAA 要求的应用程序。如果您未签订商业伙伴协议或者在对您的 HIPAA 合规应用程序使用 AWS 的方面有其他问题，请联系我们，以获取详细信息。请注意，Amazon SNS 移动推送通知和 SMS 功能不符合服务的 HIPAA 资格要求，因此，不适用于传输受保护的健康信息 (PHI)。\n要了解更多信息，请参阅以下资源：\n要查看将 Amazon SNS 纳入范围内的合规性计划的最新列表，请参阅 [AWS 按合规性计划提供的范围内服务](https://aws.amazon.com/cn/compliance/services-in-scope/)。"
    },
    {
        "query":"Amazon SNS 还应符合哪些要求？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 按合规性计划提供的范围内服务](https://aws.amazon.com/cn/compliance/services-in-scope/)，了解有关 SNS 和其他 AWS 产品的最新信息。"
    },
    {
        "query":"我的数据发布到 Amazon SNS 后的持久性如何？",
        "intention":"知识问答",
        "reply":"SNS 为接收的所有消息提供持久存储。接收到发布请求后，SNS 会在向发送者确认接收请求前跨多个可用区存储多个副本（到磁盘）。每个 AWS 区域都有多个相互隔离的位置，称为[可用区](https://aws.amazon.com/cn/about-aws/global-infrastructure/)。虽然罕见，但如果一个可用区出现故障，SNS 的运营和消息的持久性会继续保持而不会中断。"
    },
    {
        "query":"一条通知是否会包含多条消息？",
        "intention":"知识问答",
        "reply":"不会，所有通知消息只包含一条发布的消息。"
    },
    {
        "query":"每条消息会让订阅者收到多少次？",
        "intention":"知识问答",
        "reply":"虽然大多数情况下每条消息只会向您的应用程序传送一次，但 Amazon SNS 的分布式特点和瞬变的网络条件可能导致订阅者端偶尔收到重复的消息。开发人员应将其应用程序设计为多次处理一条消息不会产生任何错误或不一致性。"
    },
    {
        "query":"消息是否会按其发布的确切顺序传送给我？",
        "intention":"知识问答",
        "reply":"Amazon SNS 服务将尝试按消息发布到主题的顺序传送发布者的消息。但是，网络问题可能会导致订阅者端的消息顺序错乱。"
    },
    {
        "query":"是否可删除已发布的消息？",
        "intention":"知识问答",
        "reply":"不可以，一旦将消息成功发布到主题，就无法再撤消。"
    },
    {
        "query":"Amazon SNS 是否确保会将消息传送到订阅的终端节点？",
        "intention":"知识问答",
        "reply":"是，只要订阅的终端节点可访问。当 Amazon SNS 由于客户端或服务器端错误而无法访问订阅的终端节点时，消息传送失败。当订阅的终端节点被终端节点拥有者删除时，或者其访问权限更改，从而阻止 Amazon SNS 将消息传输到此终端节点时，将发生客户端错误。当支持订阅终端节点的服务（如 Amazon SQS 或 AWS Lambda）不可用时，将发生服务器端错误。当 Amazon SNS 接收到客户端错误或继续接收到消息超出相应重试策略指定的重试数量的服务器端错误，Amazon SNS 将丢弃该消息，除非将死信队列附加到订阅。有关更多信息，请参阅[消息传输重试](https://docs.aws.amazon.com/sns/latest/dg/sns-message-delivery-retries.html)和 [Amazon SNS 死信队列](https://docs.aws.amazon.com/sns/latest/dg/sns-dead-letter-queues.html)。"
    },
    {
        "query":"如果订阅终端节点不可用，Amazon SNS 消息会如何？",
        "intention":"知识问答",
        "reply":"如果初次尝试时无法成功传送消息，Amazon SNS 将实施一个 4 阶段重试策略：1) 无延迟重试；2) 最短延迟重试；3) 退避模型重试；4) 最长延迟重试。当消息传输重试策略用尽时，Amazon SNS 可以将消息移动至死信队列 (DLQ)。有关更多信息，请参阅[消息传输重试](https://docs.aws.amazon.com/sns/latest/dg/sns-message-delivery-retries.html)和 [Amazon SNS 死信队列](https://docs.aws.amazon.com/sns/latest/dg/sns-dead-letter-queues.html)。"
    },
    {
        "query":"全新 Worldwide SMS 功能的特点有哪些？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon SNS 将 SMS（文本）消息发送至 200 多个国家/地区，并且无需像从前那样需要收件人明确订阅。如果当地法律法规有相关规定，您就必须先从收件人那里获取权限，然后才能将 SMS 消息发送至其电话号码。此外，您现在还可以将 SMS 消息标记为“事务型”以针对可靠交付进行优化，您也可以将其标记为“促销型”以针对成本节约进行优化。另外，您还可以设置账户级别和消息级别的开销配额，以避免意外超支。"
    },
    {
        "query":"我应该将哪些 SMS 消息标记为“事务型”？",
        "intention":"知识问答",
        "reply":"您应该将有关业务优先事项的 SMS 消息标记为“事务型”。这可以确保含有一次性密码 (OTP) 或 PIN 的消息在具备最高交付可靠性的情况下通过路由发送。在美国以外的国家/地区，此类路由通常比“促销型”消息路由价格昂贵。您绝对不应将市场营销信息标记为“事务型”，因为这会违反某些国家/地区的当地规制政策，否则，您的账户可能会被标记为滥用并暂停。"
    },
    {
        "query":"我应该将哪些 SMS 消息标记为“促销型”？",
        "intention":"知识问答",
        "reply":"您应该将含有市场营销信息的 SMS 消息标记为“促销型”。Amazon SNS 可确保此类消息通过具有一定交付可靠性但成本却比最可靠的路由少很多的路由发送。这还可以让 Amazon SNS 根据当地法律法规的规定处理和发送您的消息。"
    },
    {
        "query":"什么是账户级别和消息级别的开销配额？其工作原理如何？",
        "intention":"知识问答",
        "reply":"您可以针对 AWS 账户和单独的消息指定开销配额，且这些配额仅适用于发送 SMS 消息的费用。\n默认开销配额为每个账户每月 1.00 USD（如果未指定）。如果您想提高此配额，请提交 [SNS 配额提高申请案例](https://console.aws.amazon.com/support/home#/case/create?issueType=service-limit-increase&limitType=service-code-sns)。对于“新的配额值”，请输入您所需的月度开销配额。在“使用案例描述”字段中，解释您申请提高 SMS 月度开销配额的原因。\nAmazon SNS 会发送您发布的 SMS 消息，但是您的 SMS 流量所产生的总费用会低于您在该日历月中的开销配额。一旦超过开销配额，Amazon SNS 会立刻停止发送消息，直到您提高开销配额或下一个日历月开始为止。同样，您也可以针对单独的消息指定开销配额，Amazon SNS 会在费用不超过该配额的情况下发送消息。一旦超过账户级别开销配额，无论是否超过消息级别开销配额，Amazon SNS 都将不再发送您的 SMS 消息。"
    },
    {
        "query":"是否支持双向 SMS？",
        "intention":"知识问答",
        "reply":"Amazon SNS 目前不支持双向 SMS 功能，当地法规要求的退订情况除外。"
    },
    {
        "query":"我是否需要先向某个 SNS 主题订阅电话号码才能向其发送 SMS 消息？",
        "intention":"知识问答",
        "reply":"现在，您无需先向某个 Amazon SNS 主题订阅电话号码就可以向其发送 SMS 消息。您可以直接使用 Amazon SNS 控制台或 Amazon SNS API 中的“Publish”请求向某个电话号码发布消息。"
    },
    {
        "query":"AWS 是否提供用于购买的短代码？",
        "intention":"知识问答",
        "reply":"可以。您可以预留分配给您的账户且供您独家使用的专用短代码。\n要预留短代码，请在 [AWS 支持中心](https://console.aws.amazon.com/support/home#/)创建案例。 有关更多信息，请参阅 *Amazon SNS 开发人员指南*中的[预留专用短代码用于 SMS 消息收发](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-awssupport-short-code.html)。\n有关定价的信息，请参阅 [Worldwide SMS 定价](https://aws.amazon.com/cn/sns/sms-pricing/)。"
    },
    {
        "query":"AWS 是否提供用于购买的长代码？",
        "intention":"知识问答",
        "reply":"是的。您可以按照[此处](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-awssupport-long-code.html)的说明购买长代码以便与 Amazon SNS 结合使用。"
    },
    {
        "query":"SMS 通知是否会来自特定的来源号码？",
        "intention":"知识问答",
        "reply":"Amazon SNS 将会使用为您的账户配置的号码。它将优先使用专用的短代码，然后才会使用专用的长代码。如果您没有专用的号码，Amazon SNS 将转回使用一组共享的号码来发送 SMS 通知。如果使用共享的号码，在向特定目标电话号码发送消息时，Amazon SNS 会尝试使用同一号码。这称为“粘性发件人 ID”。但是，根据网络状况和可用吞吐量等各种因素，Amazon SNS 可能会使用不同的号码。\n要控制 Amazon SNS 用于发送消息的来源身份，您可以保留专用的短代码或专用的长代码。如果您预留一个或多个号码，接收者就可以更轻松地确认消息来自贵组织。有关更多信息，请参阅 Amazon SNS 开发人员指南中的[预留专用的短代码用于 SMS 消息收发](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-awssupport-short-code.html)或[预留专用的长代码用于 SMS 消息收发](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-awssupport-long-code.html)。"
    },
    {
        "query":"Amazon SNS 支持在哪些国家/地区使用 Worldwide SMS？",
        "intention":"知识问答",
        "reply":"Amazon SNS 支持在 200 多个国家/地区使用该项功能，并且我们会继续扩大支持范围。请参阅 SMS 支持的[国家/地区列表](http://docs.aws.amazon.com/sns/latest/dg/sms_supported-countries.html)，以获取支持的调用国家/地区的完整列表。 对于发送至中国的 SMS 消息，请[联系我们](https://aws.amazon.com/cn/contact-us/)。"
    },
    {
        "query":"哪些 AWS 区域支持 Worldwide SMS？",
        "intention":"知识问答",
        "reply":"请参阅 Amazon SNS 文档的 [SNS 支持的区域和国家/地区](https://docs.aws.amazon.com/sns/latest/dg/sns-supported-regions-countries.html)页面，获取可以托管应用程序（使用 Amazon SNS 发送短信）的最新区域列表。"
    },
    {
        "query":"AWS 电话号码是否有更改？",
        "intention":"知识问答",
        "reply":"是的。Amazon SNS 会优先使用账户配置的专用号码，并且短代码优先于长代码。如果没有配置专用号码，Amazon SNS 将会使用共享号码集中的号码。"
    },
    {
        "query":"为什么使用同一运营商的设备会收到来自不同电话号码的消息？",
        "intention":"知识问答",
        "reply":"Amazon SNS 会优先使用账户配置的专用号码，并且短代码优先于长代码。如果没有配置专用号码，Amazon SNS 将会使用共享号码集中的号码。"
    },
    {
        "query":"将消息发送至其他国家/地区采用哪种电话号码格式？",
        "intention":"知识问答",
        "reply":"AWS 强烈鼓励您针对“to”和“from”（如果适用）字段中的所有电话均采用 [E.164 数字格式](http://en.wikipedia.org/wiki/E.164)。请参阅 [SMS 支持的国家/地区列表](http://docs.aws.amazon.com/sns/latest/dg/sms_supported-countries.html)，以获取支持的国家/地区的完整列表。"
    },
    {
        "query":"Amazon SNS 是否可以确定电话号码是手机号码、固定电话号码，还是 VoIP 号码？",
        "intention":"知识问答",
        "reply":"否，Amazon SNS 目前无法检测某个电话号码是手机号码、固定电话号码，还是 VoIP 号码。"
    },
    {
        "query":"SMS 消息是否支持基于时间或按计划发送？",
        "intention":"知识问答",
        "reply":"否，Amazon SNS 目前不支持基于时间或按计划发送。"
    },
    {
        "query":"我该如何追踪我的 SMS 消息的传输状态？",
        "intention":"知识问答",
        "reply":"通过启用 Amazon SNS 中的传输状态功能，您可以获取有关各个消息的以下信息：Message ID、发送时间、目标电话号码、处置、处置原因（如果适用）、价格以及驻留时间。"
    },
    {
        "query":"Amazon SNS 是否支持 MMS？",
        "intention":"知识问答",
        "reply":"否，Amazon SNS 目前不支持 MMS 消息。"
    },
    {
        "query":"收件人如何退订从 AWS 接收 SMS 消息？",
        "intention":"知识问答",
        "reply":"收件人通过其设备使用以下任意内容回复相应消息即可退订：\n要退订，收件人必须回复 Amazon SNS 用于传送该消息的同一长代码或短代码。退订后，收件人将不再接收从您的 AWS 账户传送的 SMS 消息，除非您重新加入其电话号码。"
    },
    {
        "query":"我如何知道某个收件人设备是否已退订 Global SMS？",
        "intention":"知识问答",
        "reply":"SNS 控制台会显示您的账户中已退订号码的列表。此外，Amazon SNS API 会提供“ListPhoneNumbersOptedOut”申请以列出已退订的电话号码。"
    },
    {
        "query":"如果用户退订，该号码是否会从 SNS 主题自动取消订阅？",
        "intention":"知识问答",
        "reply":"否，退订不会从 Amazon SNS 主题取消订阅号码，而是禁用订阅。这意味着，如果订阅了一个电话号码，则无需再向该主题重新订阅该电话号码。"
    },
    {
        "query":"如何确认最终用户是否已接收 SMS 消息？",
        "intention":"知识问答",
        "reply":"您可以使用传输状态功能来获取有关 SMS 消息最终处置结果的消息。有关该功能及其用法的更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/sns/latest/dg/welcome.html)。"
    },
    {
        "query":"Amazon SNS 是否提供针对 SMS 消息的发送收据？",
        "intention":"知识问答",
        "reply":"我们的传输状态功能根据从目标运营商处接收的发送收据提供信息。有关传输状态功能及其用法的更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/sns/latest/dg/welcome.html)。"
    },
    {
        "query":"SMS 是否支持向 Google Voice 或 Hangouts 等 VoIP 服务发送消息？",
        "intention":"知识问答",
        "reply":"可以。Amazon SNS 支持向可以接收 SMS 消息的 VoIP 服务发送消息。"
    },
    {
        "query":"什么是 10DLC？",
        "intention":"知识问答",
        "reply":"10DLC 是一个 10 位数的长代码，您可以在向美国消费者发送短信 (SMS) 时将它用作发端身份。它支持的最大吞吐量为 100 条短信/秒 (TPS)。AWS 不会确定分配给您的吞吐量。当您向 10DLC 注册时，美国运营商会为您分配吞吐量。要使用 10DLC 号码，您需要根据运营商的要求提供您的相关公司和使用案例信息（也称为 10DLC 活动）。\n您必须在 Amazon Pinpoint 控制台中注册您的公司和 10DLC 活动。完成注册之后，您的账户即可使用一个激活的 10DLC，您可以将此号码用作发端身份，并使用 Amazon SNS 发送 SMS。Amazon 支持通过一个第三方中央实体——The Campaign Registry (TCR) 完成注册过程，运营商使用 TCR 来验证品牌信息和 10DLC 活动详细信息。"
    },
    {
        "query":"注册一个 10DLC 活动要花多长时间？",
        "intention":"知识问答",
        "reply":"在某些情况下，注册可以立即完成。例如，如果您此前已经向 The Campaign Registry (TCR) 注册，则他们可能已经拥有了您的信息。但也可能需要一周或更长时间，才能收到某些活动的批准。在您的公司和 10DLC 活动获得 TCR 批准后，您可以购买一个 10DLC 号码并将其与您的活动关联。您购买的 10DLC 号码最多需要一周时间即可激活。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的 [10DLC](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-originating-identities-10dlc.htm)。"
    },
    {
        "query":"我能否获取一个未注册的 P2P 长代码，以便向美国电话号码发送 A2P SMS？",
        "intention":"知识问答",
        "reply":"不能。截至 2021 年 2 月 16 日，您无法从 AWS 获取支持 SMS 且未注册的个人对个人 (P2P) 长代码。自 2021 年 6 月 1 日起，Amazon SNS 不再支持通过未注册的 US 长代码向美国目的地发送应用程序对个人 (A2P) SMS 消息。您可以购买短代码、10DLC 和/或免费电话号码，并将它们用作发端身份向美国目的地发送消息。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的“[发端](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-originating-identities-origination-numbers.html)[号码](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-originating-identities-origination-numbers.html)”。"
    },
    {
        "query":"我是否应该删除我的 AWS 账户中现有的未注册美国长代码？",
        "intention":"知识问答",
        "reply":"是。自 2021 年 6 月 1 日起，运营商将不再传送通过未注册的长代码向美国目的地发送的消息。如果您无需使用它们实现其他用途（例如通过其他 AWS 产品进行语音电话），请将它们从您的账户中删除。要发送 SMS，您可以将现有的未注册长代码与一个 10DLC 活动相关联，以便将它们转换为 10DLC 号码。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的“将长代码与 [10DLC 活动](https://docs.aws.amazon.com/sns/latest/dg/sns-settings-associate-long-code-10dlc.html)相关联”。Amazon SNS 使用 Amazon Pinpoint 来管理 10DLC 活动。"
    },
    {
        "query":"我只使用 Amazon SNS 或 Amazon Cognito。我是否仍然应该使用 Amazon Pinpoint 来注册我的 10DLC 活动？",
        "intention":"知识问答",
        "reply":"是。您必须使用 Amazon Pinpoint 来注册 10DLC 品牌和活动。当您完成注册过程并且 10DLC 号码激活之后，Amazon SNS 和 Amazon Cognito 会自动将您账户中的 10DLC 号码用作发端 ID 来发送 SMS。"
    },
    {
        "query":"将我的长代码迁移到 10DLC 号码之后，我能否继续使用我的长代码？",
        "intention":"知识问答",
        "reply":"可以。将您的长代码转换为 10DLC 号码之后，您可以继续将长代码用作发端 ID。但一定要在 2021 年 6 月 1 日之前完成 10DLC 处理，因为在此日期之后将无法使用未注册的长代码。"
    },
    {
        "query":"什么是 10DLC 活动？ 创建一个该活动需要提供哪些信息？",
        "intention":"知识问答",
        "reply":"一个 10DLC 活动代表一个您用来向客户发送短信的使用案例。例如，您可以在客户的账单到期时向客户发送通知。在发送 SMS 之前，您需要注册用于发送短信的使用案例，并将一个 10DLC 号码与一个 10DLC 活动相关联。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的[注册 10DLC 活动](https://docs.aws.amazon.com/sns/latest/dg/sns-settings-register-campaign-10dlc.html)。Amazon SNS 使用 Amazon Pinpoint 来管理 10DLC 活动。"
    },
    {
        "query":"当发送 SMS 时，Amazon SNS 如何从与我的 AWS 账户相关联的发端身份中进行选择？",
        "intention":"知识问答",
        "reply":"当您向 Amazon SNS 发布消息时，可以设置 AWS.MM.SMS.OriginationNumber 属性，以选择一个已注册的发端身份。AWS 建议您在发布消息时指定发端身份。\n如果在向 Amazon SNS 发布消息时不指定发端身份，则会出现以下情况：\n有关如何指定发端身份的信息，请参阅《Amazon SNS 开发人员指南》中的[发布到手机](https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html)。"
    },
    {
        "query":"我能否将多个 10DLC 号码用于一个活动？",
        "intention":"知识问答",
        "reply":"可以。您可以将多个 10DLC 号码与一个活动关联。但您无法在多个活动中使用同一个 10DLC 号码。"
    },
    {
        "query":"我成功注册了我的 10DLC 公司和活动。但关联的 10DLC 号码卡在“待处理”状态。我该怎么办？",
        "intention":"知识问答",
        "reply":"当 10DLC 号码处于待处理状态时，表明 AWS 正在 10DLC 活动中激活您的号码。要激活一个号码，需要存在一个有效并已激活的 10DLC 品牌和 10DLC 活动。可能需要一周时间才能完成激活。如果 10DLC 号码处于待处理状态超过一周时间，请通过 AWS Support 控制台创建[支持案例](https://console.aws.amazon.com/support/home#/)。"
    },
    {
        "query":"我能否使用 AWS API 操作而不是 Amazon Pinpoint 控制台来索取 10DLC 号码？",
        "intention":"知识问答",
        "reply":"不能。您目前只能通过 Amazon Pinpoint 控制台索取 10DLC 号码。Amazon SNS 使用 Amazon Pinpoint 来管理 10DLC 活动。"
    },
    {
        "query":"我如何在我 AWS 账户中的不同 AWS 区域中使用 10DLC？",
        "intention":"知识问答",
        "reply":"10DLC 公司和 10DLC 活动注册特定于 AWS 账户。但 10DLC 号码特定于 AWS 区域。您可以在一个 AWS 区域中拥有多个 10DLC 号码，并让这些号码引用同一个 10DLC 活动。"
    },
    {
        "query":"我能否获取具有特定区号的 10DLC 号码？",
        "intention":"知识问答",
        "reply":"不能。AWS 目前不支持选择 10DLC 号码。"
    },
    {
        "query":"我能否将 10DLC 号码用作发端身份，以便向美国以外的目的地发送 SMS？",
        "intention":"知识问答",
        "reply":"不能。您只能使用 10DLC 号码向美国目的地发送 SMS 消息。"
    },
    {
        "query":"我能否使用 10DLC 号码发送语音消息？",
        "intention":"知识问答",
        "reply":"可以。要使用 10DLC 号码发送语音消息，请在预置这些号码时选择语音功能。请注意，Amazon SNS 不支持语音消息。但您可以在其他 AWS 服务中使用这些号码。"
    },
    {
        "query":"我能否在我的 10DLC 活动示例消息中使用变量？",
        "intention":"知识问答",
        "reply":"可以。要在示例消息中使用可变内容，您可以在注册 10DLC 活动时提供的模板中使用占位符。例如，假设您希望发送的消息是“你好 John。你的 OTP 是 1234。” 在这种情况下，您可以这样编写模板：“你好 {#var1}。你的 OTP 是 {#var2}。”"
    },
    {
        "query":"有没有办法捕获每个 10DLC 活动的指标？",
        "intention":"知识问答",
        "reply":"Amazon SNS 中目前没有任何指标可以跟踪每个 10DLC 活动或电话号码发送的消息。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的[监控 SMS 活动](https://docs.aws.amazon.com/sns/latest/dg/sms_stats.html)。"
    },
    {
        "query":"我能否将 10DLC 注册从一个 AWS 账户迁移到另一个账户？ 需要多长时间？",
        "intention":"知识问答",
        "reply":"可以。要在您的多个 AWS 账户之间迁移 10DLC 注册，请在 AWS Support 中心创建一个“提高服务配额”[支持案例](https://console.aws.amazon.com/support/home#/)。您通常会在两周内得到答复。"
    },
    {
        "query":"我直接通过 The Campaign Registry (TCR) 门户网站注册了我的公司。我能否对我的多个 AWS 账户使用同一个注册？",
        "intention":"知识问答",
        "reply":"不能。要使用 Amazon SNS 发送 SMS，您必须使用 Amazon Pinpoint 控制台向 AWS 注册您的品牌和 10DLC 活动。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的[开始使用 10DLC](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-originating-identities-10dlc.html)。"
    },
    {
        "query":"我使用 Amazon SNS 从多个 AWS 区域发送 SMS 消息。如何在我开展运营的 AWS 区域中注册一个 10DLC 号码？",
        "intention":"知识问答",
        "reply":"10DLC 号码特定于 AWS 区域。10DLC 公司和活动在同一个 AWS 账户中的多个 AWS 区域中有效。您可以在一个 AWS 区域中注册您的品牌和活动，并为这些 10DLC 活动获取新的 10DLC 号码，以便根据需要在其他 AWS 区域中使用。"
    },
    {
        "query":"当我以高于我的 10DLC 活动吞吐量配额的速度发送 SMS 消息时，会发生什么？",
        "intention":"知识问答",
        "reply":"当您超过您的吞吐量配额时，您的 AWS 账户会出现限制错误。吞吐量配额按如下方式分解："
    },
    {
        "query":"我如何在两个不同的 AWS 账户中注册我的公司？",
        "intention":"知识问答",
        "reply":"10DLC 公司和活动位于同一个 AWS 账户内。如果您有多个账户，则可以将这些其他的账户与您的主账户关联，以便从任意一个这样的账户使用您的 10DLC 号码。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的 [10DLC 跨账户访问](https://docs.aws.amazon.com/sns/latest/dg/sns-settings-sms-crossaccount-10dlc.html)。Amazon SNS 使用 Amazon Pinpoint 来管理 10DLC 活动。"
    },
    {
        "query":"我能否使用短网址来发送 10DLC 消息？",
        "intention":"知识问答",
        "reply":"不能。运营商不允许使用 bit.ly 等服务所提供的短网址。AWS 建议您使用与您公司的域匹配的完整 URL。您也可以使用 URL 缩短服务，这些服务可提供自定义域和/或虚域，而且与发送消息的品牌明显相关。在 10DLC 活动注册期间，请务必在示例消息中提供这些 URL 示例。"
    },
    {
        "query":"我们使用 Amazon SNS 来发送 SMS，但未设置“OriginationNumber”属性。当我们的 AWS 账户中具有一个以上的活动时，Amazon SNS 如何知道要使用哪个 10DLC 活动？",
        "intention":"知识问答",
        "reply":"当您的 AWS 账户中具有多个 10DLC 活动时，AWS 建议您使用“OriginationNumber”参数，并通过 Amazon SNS 发送消息，以使用正确的 10DLC 活动。如果您不指定此参数，Amazon SNS 会为您选择发端身份。\nAmazon SNS 按如下优先顺序选择发端身份类型：短代码、10DLC、免费电话号码。如果您有特定发端 ID 类型的多个号码，Amazon SNS 会在所选的发端 ID 类型内随机选择一个号码。\n问：我使用 Amazon Cognito 发送 SMS 消息，以进行电话号码验证、OTP 和 MFA。我如何使用特定的 10DLC 活动？\n答：Amazon Cognito 会代表您调用 Amazon SNS，以发送 SMS。如果您的 AWS 账户中只注册了一个 10DLC 号码和活动，Amazon SNS 会使用此号码代表您发送 SMS。\n如果您在一个 AWS 区域中配置了一个以上的 10DLC 号码，则可以使用 Amazon Cognito 的 Custom SMS Sender Lambda 触发器，在使用 Amazon SNS 发送 SMS 时选择要使用的发端号码。有关更多信息，请参阅《Amazon Cognito 开发人员指南》中的 [Custom SMS Sender Lambda 触发器](https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-lambda-custom-sms-sender.html)。"
    },
    {
        "query":"如何使用 Amazon SNS，通过 10DLC 号码从 Amazon Pinpoint 不支持的 AWS 区域发送 SMS？",
        "intention":"知识问答",
        "reply":"在一个 AWS 区域中配置了一个号码之后，您可以继续在此区域中使用 Amazon SNS。您可以在一个 AWS 区域中注册一个 10DLC，并创建一个“提高服务配额”支持案例，以请求将此号码转移到您选择的另一个 AWS 区域。有关更多信息，请参阅《Amazon SNS 开发人员指南》中的[索取用于 SMS 消息收发的 10DLC 号码、免费电话号码和 P2P 长代码](https://docs.aws.amazon.com/sns/latest/dg/channels-sms-awssupport-long-code.html)。"
    },
    {
        "query":"我是否需要为未送达的 SMS 消息付费？",
        "intention":"知识问答",
        "reply":"如果目标运营商报告您曾尝试向无效的电话号码发送消息，则您可能需要为传送失败的消息支付费用。电话号码无效的原因有很多，如电话号码不存在、收件人欠费或目标号码是固定号码。在[其他情况下](https://docs.aws.amazon.com/sns/latest/dg/sms_stats_cloudwatch.html#sms_stats_delivery_fail_reasons)，SMS 传送失败也会收取费用。"
    },
    {
        "query":"是否有针对发送 SMS 消息的 AWS Free Tier 限额？",
        "intention":"知识问答",
        "reply":"否。"
    },
    {
        "query":"主题或每个主题的订阅者是否有数量配额？",
        "intention":"知识问答",
        "reply":"SNS 默认为每个主题提供 1000 万个订阅，为每个账户提供 100000 个主题。如需提高配额，请[联系支持团队](https://aws.amazon.com/cn/support/)。"
    },
    {
        "query":"消息中可包含多少数据量以及哪些数据类型？",
        "intention":"知识问答",
        "reply":"Amazon SNS 消息最多可包含 256KB 的文本数据，包括 XML、JSON 和非格式化文本（SMS 消息与此不同）。\n接受以下 Unicode 字符：\n#x9 | #xA | #xD | [#x20 to #xD7FF] | [#xE000 to #xFFFD] | [#x10000 to #x10FFFF]\n（根据 <http://www.w3.org/TR/REC-xml/#charsets>）。\n每 64KB 区块的已发布数据以 1 次请求计费。例如，1 次负载为 256KB 的 API 调用将以 4 次请求计费。\nSMS 消息\n每条 SMS 消息最多可包含 140 个字节，具体字符数限制取决于编码方法。例如，一条 SMS 消息可以包含：\n如果您发布的消息超出大小上限，Amazon SNS 会将其分成多条消息发送，其中每条均不超过大小上限。消息以整个词为边界，不会在一个词的中间截断。就一项 SMS 发布操作而言，总大小上限为 1600 个字节。"
    },
    {
        "query":"一个主题可应用多少个消息筛选条件？",
        "intention":"知识问答",
        "reply":"默认情况下，一个主题在每个区域每个账户可应用 200 个筛选策略。如果需要更多，请联系我们。"
    },
    {
        "query":"是否应将一些 TCP 端口用于 SNS 和 EC2 之间的跨区域通信？",
        "intention":"知识问答",
        "reply":"是的，在 80/443/4080/8443 以外的端口上进行的 SNS 和 EC2 间的跨区域通信无法保证正常工作，应避免使用。"
    },
    {
        "query":"什么是原始消息传输？",
        "intention":"知识问答",
        "reply":"您可以选择让消息以原始形式传送，即和您发布时的消息形式完全一样。默认情况下，消息会以 JSON 编码进行传输，JSON 编码提供消息和主题的元数据。原始消息传输可以通过设置订阅的“RawMessageDelivery”属性来启用。该属性可以使用 AWS 管理控制台或者 API SetSubscriptionAttributes 来设置。\n问：如果订阅的原始消息传输属性未设定，默认行为是什么？\n如果该属性未设定，消息当前会默认以 JSON 形式传输。这确保了现有的应用程序会继续如期运行。\n问：哪些类型的终端节点支持原始消息传输？\nSQS 和 HTTP(S) 终端节点支持原始消息传输。传输到 Lambda、电子邮件和 SMS 终端节点的内容将表现一致，不受“RawMessageDelivery”属性影响。\n问：原始消息如何传输至 HTTP 终端节点？\n在原始格式的消息传输至 HTTP/s 终端节点之后，HTTP POST 主体将会包含消息主体。"
    },
    {
        "query":"什么是 SNS 移动推送？",
        "intention":"知识问答",
        "reply":"借助 SNS 移动推送，您可以使用 Simple Notification Service (SNS) 来向 Apple、Google、Fire OS 和 Windows 设备以及中国内带有[百度云推送](https://push.baidu.com/)功能的 Android 设备推送通知。使用推送通知功能，通过弹出关于某个事件的通知，安装的移动应用程序可以立即通知其用户而不用打开应用程序。例如，如果您安装了一个体育应用程序并启用了推送通知，则该应用程序便可以将您最爱运动队的最新比分发送给您，即使应用程序没有运行。通知会在您的设备上显示，当您了解其中的信息后，可以启动应用程序以显示详细信息。用户体验与 SMS 类似，但是功能更强大且费用低廉很多。"
    },
    {
        "query":"如何开始发送推送通知？",
        "intention":"知识问答",
        "reply":"推送通知只能发送到安装有您的应用程序的设备，且这些设备的用户选择了接收推送通知。SNS 移动推送不需要用户明确地选择接受推送通知，但是 iOS、Android 及 Kindle Fire 操作系统对此有要求。为了通过 SNS 发送推送通知，您同时还要在 SNS 中注册您的应用程序和每个安装了该应用程序的设备。有关更多信息，请参阅[使用 Amazon SNS 移动推送通知](http://docs.aws.amazon.com/sns/latest/dg/SNSMobilePush.html)。"
    },
    {
        "query":"支持哪些推送通知平台？",
        "intention":"知识问答",
        "reply":"目前支持下列推送通知平台："
    },
    {
        "query":"使用 SNS 免费套餐可以发送多少条推送通知？",
        "intention":"知识问答",
        "reply":"SNS 免费套餐包括 100 万次发布，外加 100 万次移动推送发送。因此您每月可以免费发送 100 万条推送通知。向所有移动推送终端节点发送的通知将累计起来达到您 1 百万条免费移动推送发送量。"
    },
    {
        "query":"启用推送通知是否需要对 SNS 移动推送进行任何特殊确认？",
        "intention":"知识问答",
        "reply":"不需要。无论 SNS 是否发送推送通知，最终用户可以在初次运行应用程序时选择接收推送通知。"
    },
    {
        "query":"我是否需要修改我的客户端应用，以便使用 SNS 移动推送功能？",
        "intention":"知识问答",
        "reply":"SNS 不要求您修改客户端应用。百度云推送需将特定于百度的组件添加到客户端代码，以确保正常工作，无论您是否选择使用 SNS 服务。"
    },
    {
        "query":"SNS 主题如何在移动推送中工作？",
        "intention":"知识问答",
        "reply":"SNS 主题可以包含来自任何支持的推送通知平台的订阅者，以及任何其他终端节点类型，例如 SMS 或电子邮件。当您向某个主题发布通知时，SNS 会将该条消息的相同副本发送到订阅该主题的每个终端节点。如果您使用特定于平台的负载来定义发送给每个推送平台的准确负载，那么当您超过相关推送通知平台所规定的最大负载时，您的发布操作将会失败。"
    },
    {
        "query":"不同的目标平台各自支持何种规模的负载大小？",
        "intention":"知识问答",
        "reply":"SNS 支持的最大负载大小与相关原始平台支持的大小相等。客户可以使用 JSON 对象来发送平台特定消息。请参阅[使用 SNS 移动推送 API](http://docs.aws.amazon.com/sns/latest/dg/mobile-push-api.html) 了解更多详细信息。"
    },
    {
        "query":"平台特定的负载如何工作？",
        "intention":"知识问答",
        "reply":"当您向主题发布内容并想要将自定义消息发送到不同推送通知平台的终端节点时，您需要选择发布对话框中的“Use different message body for different protocols”选项，然后更新消息。可以使用平台特定的负载来指定中继到每个推送通知服务的精确 API 字符串。例如，可以使用平台特定的负载通过 APNS 来操纵您的 iOS 应用程序徽章计数。有关更多信息，请参阅[使用 Amazon SNS 移动推送通知](http://docs.aws.amazon.com/sns/latest/dg/SNSMobilePush.html)。"
    },
    {
        "query":"一个令牌能否订阅多个主题？",
        "intention":"知识问答",
        "reply":"可以。每个令牌可以订阅的 SNS 主题没有数量限制。"
    },
    {
        "query":"什么是直接寻址？ 工作原理是什么？",
        "intention":"知识问答",
        "reply":"直接寻址让您可以将通知直接提供给单一终端节点，而不是将相同的消息发送给一个主题的所有订阅者。如果您想将精准定位的消息发送给每一名接收者，该功能便可派上用场。当您在 SNS 注册设备令牌时，SNS 便会创建与此令牌对应的终端节点。您可以像将内容发布到主题一样来将内容发布到令牌终端节点。您可以直接发布通知的文本，或利用平台特定功能（诸如更新应用程序的徽章计数）的优势发布平台特定负载。直接寻址目前仅限推送通知终端节点。"
    },
    {
        "query":"SNS 是否支持 SMS 或电子邮件直接寻址？",
        "intention":"知识问答",
        "reply":"目前，直接寻址将仅支持移动推送终端节点（APNS、FCM、ADM、WNS、MPNS 和百度）及 SMS。电子邮件消息需要使用主题。"
    },
    {
        "query":"SNS 移动推送如何处理通知服务中的令牌反馈？",
        "intention":"知识问答",
        "reply":"推送通知服务（例如 APNS 和 FCM）可提供关于令牌可能已过期或可能已被新令牌替换的反馈。如果 APNS 或 FCM 报告特定令牌已过期或无效，则 SNS 会自动“禁用”与令牌关联的应用程序端点，并通过某一事件通知您此更改。具体而言，FCM 有时不仅表示令牌无效，还会在其对 SNS 的响应中提供与应用程序端点关联的新令牌。发生这种情况时，SNS 会自动为相关终端节点更新新的令牌值，同时使终端节点保持在启用状态，然后通过事件通知您这一变化。"
    },
    {
        "query":"能否将现有应用程序迁移到 SNS 移动推送？",
        "intention":"知识问答",
        "reply":"可以。您可以通过控制台界面或 API 将现有设备令牌批量上传到 Amazon SNS。通过上传相关推送通知服务的凭证，还可以在 SNS 注册您的应用程序，并配置您的代理或应用程序以便将来在 SNS 注册新的令牌。"
    },
    {
        "query":"能否通过 Amazon CloudWatch 监控我的推送通知？",
        "intention":"知识问答",
        "reply":"可以。SNS 发布的 Cloudwatch 指标包括已发布的消息数量、成功通知的数量、失败通知的数量、筛选掉的通知数量和已发布数据的大小。指标以应用程序为单位提供。您可以通过 AWS 管理控制台或 CloudWatch API 访问 Cloudwatch 指标。"
    },
    {
        "query":"Amazon SNS 支持哪种 Windows Push Notifications？",
        "intention":"知识问答",
        "reply":"SNS 支持 Microsoft WNS 和 MPNS 提供的所有推送通知类型，包括 Toast、Tile、Badge 和 Raw 通知。使用 TYPE 消息属性，以指定期望使用的通知类型。当使用默认负载向所有移动平台发送相同的消息时，对于 Windows 平台，SNS 将默认选择广播通知。当您使用平台特定的负载时，必须为 Windows 平台指定通知类型。"
    },
    {
        "query":"SNS 是否支持 Windows Raw 推送通知？",
        "intention":"知识问答",
        "reply":"可以。您必须将通知负载编码为文本才能通过 SNS 发送 Raw 通知。"
    },
    {
        "query":"什么是百度云推送？",
        "intention":"知识问答",
        "reply":"百度云推送是一种适用于 Android 设备的第三方替代推送通知中继服务。您可以使用百度云推送来联系中国的 Android 客户，无论这些客户选择使用哪个 Android 应用商店来下载应用。有关百度云推送的更多信息，请访问 <https://push.baidu.com/>。"
    },
    {
        "query":"我是否能从所有公共 AWS 区域发布百度通知？",
        "intention":"知识问答",
        "reply":"可以，SNS 支持在所有公共 AWS 区域发布百度推送通知。"
    },
    {
        "query":"我是否可以将百度通知用于任何 Android 应用商店？",
        "intention":"知识问答",
        "reply":"可以，百度推送通知可用于经由 Android 应用商店安装的应用。"
    },
    {
        "query":"什么是消息属性？",
        "intention":"知识问答",
        "reply":"消息属性可使您提供消息相关的结构化元数据项目（如时间戳、地理空间数据、签名和标识符）。消息属性是可选的，它与消息正文相互独立，但随同其一起发送。在此信息的帮助下，消息接收方不必先处理消息正文，而是可以预先决定如何处理消息。\n您可以将 SNS 消息属性与 SQS 和移动推送终端节点联合使用。要了解更多有关消息属性的信息，请参阅 [SNS 入门指南](http://docs.aws.amazon.com/sns/latest/dg/GettingStarted.html)。"
    },
    {
        "query":"SNS 中支持什么消息属性？",
        "intention":"知识问答",
        "reply":"SNS 针对各个终端节点支持不同的消息属性，具体取决于它们自己支持的终端节点。"
    },
    {
        "query":"Amazon SNS 是否支持 HTTP/2 对 APNS 终端节点进行移动推送通知？",
        "intention":"知识问答",
        "reply":"Amazon SNS 将 HTTP/2 与 p12 证书结合使用，以通过 Apple Push Notification Service (APNS) 将推送通知发送至 iOS 和 macOS 终端节点。"
    },
    {
        "query":"由于 APNS 二进制协议到 2020 年 11 月将弃用，我是否需要修改我的应用程序？",
        "intention":"知识问答",
        "reply":"Amazon SNS 将 HTTP/2 与 p12 证书结合使用。由于它不依赖于旧版二进制协议，所以不需要对通过 Amazon SNS 发送推送通知的应用程序进行任何更改。"
    },
    {
        "query":"Amazon SNS 中的 AWS Lambda 终端节点支持有什么意义？",
        "intention":"知识问答",
        "reply":"通过将消息发布到订阅了 AWS Lambda 函数的 Amazon SNS 主题，您可以调用 AWS Lambda 函数。Amazon SNS 支持消息群发，因此除了可以将通知传输到支持的 Amazon SNS 目的地（如移动推送、HTTP 终端节点、SQS、电子邮件和 SMS），发布一条消息还可以调用不同的 AWS Lambda 函数或调用 Lambda 函数。"
    },
    {
        "query":"什么是 AWS Lambda？",
        "intention":"知识问答",
        "reply":"AWS Lambda 是一项计算服务，依响应事件运行您的代码和自动为您管理计算资源，因而容易构建快速响应新信息的应用程序。关于 AWS Lambda 的更多信息以及如何创建 AWS Lambda 函数，请从[此处](https://aws.amazon.com/cn/lambda/)查看。"
    },
    {
        "query":"AWS Lambda 函数和 Amazon SNS 有何用途？",
        "intention":"知识问答",
        "reply":"通过将 AWS Lambda 函数订阅到 Amazon SNS 主题，您可以执行自定义消息处理。您可以调用 AWS Lambda 函数来提供自定义消息传输处理，方法是先将消息发布到一个 AWS Lambda 函数，再让 Lambda 函数修改一条消息（例如对语言进行本地化），最后对消息进行筛选并将其发送给其他主题和终端节点。已经发送 Amazon SNS 通知（例如 Amazon CloudWatch）的应用程序和服务现在可以立即利用 AWS Lambda 的优势，不需要预置或管理基础设施来进行自定义消息处理。您还可以使用发送到 AWS Lambda 函数功能来发布到其他 AWS 产品，例如 Amazon Kinesis 或 Amazon S3。您可以将 AWS Lambda 函数订阅到 Amazon SNS 主题，然后让 Lambda 函数轮流写入到另一项服务。"
    },
    {
        "query":"如何激活 Amazon SNS 中的 AWS Lambda 终端节点支持？",
        "intention":"知识问答",
        "reply":"您首先需要通过 AWS 账户和 [AWS Lambda 控制台](https://console.aws.amazon.com/lambda)创建一个 AWS Lambda 函数，然后使用 [Amazon SNS 控制台](https://us-west-2.console.aws.amazon.com/sns/v2/home)或 [Amazon SNS API](http://docs.aws.amazon.com/sns/latest/dg/mobile-push-api.html) 将该 AWS Lambda 函数订阅到一个主题。以上操作完成后，发布到订阅了 Lambda 函数的 Amazon SNS 主题的任意消息将发送到除订阅到该主题任何其他目的地之外的适当的 Lambda 函数。"
    },
    {
        "query":"将消息从 Amazon SNS 发送到 AWS Lambda 函数有何意义？",
        "intention":"知识问答",
        "reply":"将消息从 Amazon SNS 发送到 AWS Lambda 函数会创建 AWS Lambda 函数的实例并连同您的消息一起调用为输入。有关消息格式的更多信息，请参阅 [Amazon SNS 文档](https://aws.amazon.com/cn/documentation/sns/)和 AWS Lambda 文档。"
    },
    {
        "query":"能否将别人创建的 AWS Lambda 函数订阅到我的 Amazon SNS 主题？",
        "intention":"知识问答",
        "reply":"目前不允许 AWS 账户所有者订阅属于其他账户的 AWS Lambda 函数。您可以将自己的 AWS Lambda 函数订阅到自己的 Amazon SNS 主题或者其他账户创建的 Amazon SNS 主题，只要该 SNS 主题的主题策略允许这样的操作。"
    },
    {
        "query":"对于可以订阅到 Amazon SNS 主题的 AWS Lambda 函数的数量有没有配额？",
        "intention":"知识问答",
        "reply":"Amazon SNS 将 AWS Lambda 函数等同其他目的地对待。SNS 默认对每个主题提供 1000 万个订阅。要请求提高配额，请[联系我们](https://aws.amazon.com/cn/support/)。"
    },
    {
        "query":"可以向 AWS Lambda 函数传送什么数据？",
        "intention":"知识问答",
        "reply":"当 AWS Lambda 函数作为 Amazon SNS 消息发送的结果调用时，AWS Lambda 函数会通过 SNS 事件收到各种数据，包括消息 ID、主题 ARN、消息负载和消息属性。有关传送到 AWS Lambda 函数的事件结构的更多信息，请参阅我们的[博客](http://mobile.awsblog.com/post/Tx1VE917Z8J4UDY/Invoking-AWS-Lambda-functions-via-Amazon-SNS)。"
    },
    {
        "query":"我能否跟踪 AWS Lambda 函数的消息发送尝试状态？",
        "intention":"知识问答",
        "reply":"要跟踪消息发送状态是否成功，您需要激活 Amazon SNS 的传输状态功能。有关如何激活此功能的更多信息，请参阅我们的博客。"
    },
    {
        "query":"AWS Lambda 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域和终端节点](http://docs.aws.amazon.com/general/latest/gr/rande.html#lambda_region)，以查看完整列表。"
    },
    {
        "query":"我的 AWS Lambda 函数需不需要与所使用的 Amazon SNS 处在相同的区域？",
        "intention":"知识问答",
        "reply":"您可以将 AWS Lambda 函数订阅到任意区域中的 Amazon SNS 主题。"
    },
    {
        "query":"对于 AWS Lambda 函数的并发数量有没有配额？",
        "intention":"知识问答",
        "reply":"AWS Lambda 目前在每个区域每个 AWS 账户中支持 1000 个并发执行。如果发送到 AWS Lambda 的 Amazon SNS 消息达到了并发数量配额，则 Amazon SNS 消息的发送将被阻断。如果 AWS Lambda 阻断了 Amazon SNS 消息，则 Amazon SNS 将尝试重新发送。有关 AWS Lambda 并发配额的更多信息，请参阅 [AWS Lambda 文档](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html)。"
    },
    {
        "query":"Amazon SNS 能否使用已经在其他服务（例如 Amazon S3）中使用的相同 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以使用已经在其他服务中使用的相同 AWS Lambda 函数，只要此相同函数可以在分析其他服务的事件格式的同时也可以分析 Amazon SNS 中的事件格式。关于 SNS 事件格式，请参阅我们的[博客](http://mobile.awsblog.com/post/Tx1VE917Z8J4UDY/Invoking-AWS-Lambda-functions-via-Amazon-SNS)。"
    },
    {
        "query":"用于 iOS 的 VoIP 推送通知是什么？",
        "intention":"知识问答",
        "reply":"在 iOS 8 和更高版本中，IP 电话 (VoIP) 应用可以注册 VoIP 远程通知，以便 iOS 可在呼入的 VoIP 通话抵达用户时启动或唤醒应用。注册 VoIP 通知的程序类似于在 iOS 上注册常用推送通知的程序。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/sns/latest/dg/mobile-push-apns.html)。"
    },
    {
        "query":"我能否在同一 iOS 应用中同时使用 VoIP 推送通知和其他推送通知？",
        "intention":"知识问答",
        "reply":"可以，您可以使用已注册的 iOS 应用程序接收两种类型的推送通知。然而，除了常用推送通知证书之外，您需要从 Apple 获得 VoIP 推送通知证书，在 Amazon SNS 创建新的平台应用程序并选择 Apple VoIP Push 为平台类型。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/sns/latest/dg/mobile-push-apns.html)。\n问：Mac OS 推送通知是什么？\n您现在可以使用 Amazon SNS 发送推送通知给运行 Mac OS X Lion (10.7) 或更高版本的 Mac OS。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/sns/latest/dg/mobile-push-apns.html)。\n详细了解 Amazon SNS 定价"
    },
    {
        "query":"What is Amazon Managed Grafana?",
        "intention":"知识问答",
        "reply":"Amazon Managed Grafana is a fully managed multicloud, cross-project service with rich, interactive data visualizations to help customers analyze, monitor, and alarm on metrics, logs, and traces across multiple data sources. You can create interactive dashboards and share them with anyone in your organization with an automatically scaled, highly available, and enterprise-secure service. With Amazon Managed Grafana, you can manage user and team access to dashboards across AWS accounts, AWS regions, and data sources. Amazon Managed Grafana provides an intuitive resource discovery experience to help you easily onboard your AWS accounts across multiple regions and securely access AWS services such as Amazon CloudWatch, AWS X-Ray, Amazon Elasticsearch Service, Amazon Timestream, AWS IoT SiteWise, and Amazon Managed Service for Prometheus."
    },
    {
        "query":"What is Grafana?",
        "intention":"知识问答",
        "reply":"Grafana is an open source data visualization and operational dashboarding solution used by hundreds of thousands of organizations and millions of users. Grafana’s rich visualization library and broad support for multiple data sources makes it simple for customers to query, visualize, and alert on a wide variety of operational data, including metrics, logs, and traces in a single console. Amazon Managed Grafana provides fully managed Grafana workspaces compatible with the open source project and developed in partnership with Grafana Labs, parent company of the open source project."
    },
    {
        "query":"What is an Amazon Managed Grafana Workspace?",
        "intention":"知识问答",
        "reply":"A workspace is a logically isolated Grafana server. Once you have created a workspace, you can integrate it with data sources and then query and visualize metrics from these data sources. You can create multiple workspaces per Region, per account, so that you can create isolated Grafana workspaces for monitoring your Prod and Dev workloads separately."
    },
    {
        "query":"How do I enable multi-account, multi-Region access to my AWS data sources?",
        "intention":"知识问答",
        "reply":"Amazon Managed Grafana integrates with AWS Organizations to discover the AWS accounts and resources in your Organizational Units. Using AWS CloudFormation StackSets, Amazon Managed Grafana will automatically create the IAM policies needed to grant read-only access to your AWS Services data for the accounts and Regions you choose. Using the Amazon Managed Grafana console, you can easily add or remove accounts, Organizational Units, and Regions that you want to add to each Grafana workspace."
    },
    {
        "query":"When do I need Grafana Enterprise license?",
        "intention":"知识问答",
        "reply":"Amazon Managed Grafana provides users access to open source Grafana features as well as enhanced features, such as single sign-on via SAML 2.0 and AWS Single Sign-On, audit logging, and team sync. If you need access to Enterprise data source plugins that are developed by Grafana Labs, then you will need to purchase a Grafana Enterprise license via AWS marketplace. This is a one-click process and can be done via the Amazon Managed Grafana console."
    },
    {
        "query":"How do I upgrade to Grafana Enterprise?",
        "intention":"知识问答",
        "reply":"In the Amazon Managed Grafana console, you can select the workspace you’d like to upgrade to Grafana Enterprise. You can optionally upgrade one or more workspaces; each upgraded workspace will have access to Enterprise plugins. This enables you to query and visualize data from AppDynamics, Atlassian Jira, Datadog, Dynatrace, Gitlab, Honeycomb, MongoDB, New Relic, Oracle Database, Salesforce, SAP HANA, ServiceNow, VMware Tanzu Observability by Wavefront, and Snowflake."
    },
    {
        "query":"Is there CloudFormation support for creating Amazon Managed Grafana Workspaces?",
        "intention":"知识问答",
        "reply":"Yes. You can use AWS CloudFormation templates to create, update, and delete your Amazon Managed Grafana workspaces, as well as manage or update workspace SAML authentication settings. To learn more about manage Amazon Managed Grafana workspaces and configuring workspace SAML authentication with CloudFormation, see the Amazon Managed Grafana resource type reference in the [CloudFormation user guide](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/AWS_Grafana.html). To create Amazon Managed Grafana workspaces using AWS CloudFormation, follow the [reference templates](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-grafana-workspace.html#aws-resource-grafana-workspace--examples)."
    },
    {
        "query":"Is there Terraform support for creating, editing, and deleting dashboards for Amazon Managed Grafana Workspaces?",
        "intention":"知识问答",
        "reply":"Yes, Amazon Managed Grafana supports Terraform for dashboard management."
    },
    {
        "query":"What are the types of Grafana users?",
        "intention":"知识问答",
        "reply":"There are three user types in Grafana: Administrators, Editors, and Viewers. Administrators have add, edit, and delete permissions to manage data sources, users, teams, folders, and dashboards. Editors have view, add, edit, and delete permissions to dashboards and alerts. Viewers can view dashboards to which they have been granted access, but cannot add, edit, or delete data sources, dashboards, or alerts."
    },
    {
        "query":"Which Grafana data source plugins are supported?",
        "intention":"知识问答",
        "reply":"Amazon Managed Grafana provides native integration for multiple AWS Services, including Amazon Managed Service for Prometheus, Amazon CloudWatch, Amazon Elasticsearch Service, AWS IoT SiteWise, Amazon Timestream, and AWS X-Ray. Amazon Managed Grafana also supports plugins for other cloud providers, including Azure Monitor and Google Operations, and self-managed data sources such as Graphite, InfluxDB, and more. Directly from the Amazon Managed Grafana console, you can optionally upgrade to paid third-party, enterprise plugins made available with a Grafana Enterprise license purchase, which enables access to AppDynamics, Datadog, Dynatrace, MongoDB, New Relic, Oracle Database, ServiceNow, Snowflake, Splunk, and Wavefront. Reference the [Amazon Managed Grafana User Guide](https://docs.aws.amazon.com/grafana/latest/userguide/AMG-data-sources.html) for the full list of supported data source plugins."
    },
    {
        "query":"What are teams in Amazon Managed Grafana and why should I use them?",
        "intention":"知识问答",
        "reply":"Teams provide a grouping mechanism to organize users in Amazon Managed Grafana. You can use teams to group individual users into entities that are granted access to shared resources such as dashboards, data sources, and alerts. Teams can also be mapped to your LDAP groups. With Team Sync enabled, you can keep team membership and user identities in sync with your Identity Provider's user directories such as Azure Active Directory, Microsoft Active Directory, CyberArk, Okta, OneLogin, and Ping Identity."
    },
    {
        "query":"What is Grafana alerting?",
        "intention":"知识问答",
        "reply":"Grafana alerting is an opt-in Amazon Managed Grafana feature that allows you to visualize alerts from Prometheus Alertmanager data sources in a searchable alerting interface in your Grafana workspace."
    },
    {
        "query":"How do I use the Grafana alerting experience?",
        "intention":"知识问答",
        "reply":"In the Amazon Managed Grafana console, you can select the workspace where you’d like to enable Grafana Alerting to visualize your Prometheus Alertmanager alerts in your Grafana workspace."
    },
    {
        "query":"Can I connect my Amazon Managed Grafana workspace to OpenSearch clusters, RDS Postgres databases, or self-managed data sources?",
        "intention":"知识问答",
        "reply":"Yes, Amazon Managed Grafana can connect to OpenSearch clusters, RDS Postgres databases, or self-managed data sources directly from your VPC without using public IPs or requiring traffic to traverse the Internet. To learn more, see [user guide for Connecting to Amazon VPC from Amazon Managed Grafana](https://docs.aws.amazon.com/grafana/latest/userguide/AMG-configure-vpc.html)."
    },
    {
        "query":"Can I connect multiple Virtual Private Cloud (VPC) endpoints, or VPCs from a different region and different accounts to a single Amazon Managed Grafana workspace?",
        "intention":"知识问答",
        "reply":"Currently, you can connect one Amazon Managed Grafana workspace to one VPC endpoint in the same region and same account. However, you can use [Virtual Private Cloud peering](https://docs.aws.amazon.com/vpc/latest/peering/what-is-vpc-peering.html) or [AWS Transit Gateway](https://docs.aws.amazon.com/vpc/latest/tgw/what-is-transit-gateway.html) to connect the cross-region or cross-account VPCs, then connect the select the VPC endpoint that’s in the same account and same region as your Amazon Managed Grafana workspace. In this way, data sources from different accounts or different region can all be connected to a single Amazon Managed Grafana workspace. If Virtual Private Clouds peering is not an option for you, please share your use cases with your Account Manager, or email us directly at [aws-grafana-feedback@amazon.com](mailto:aws-grafana-feedback@amazon.com)."
    },
    {
        "query":"When my Amazon Managed Grafana workspace is connected to a Virtual Private Cloud (VPC), will I still be able to connect to other public data sources?",
        "intention":"知识问答",
        "reply":"Yes, you can still connect to public data source after you configure the VPC connection in Amazon Managed Grafana workspace. Requests to public data sources must traverse your VPC. If your workspace was previously connected to data sources prior to configuring a VPC endpoint, ensure that the VPC is able to reach the previously connected data sources as all traffic will now route through the VPC connection."
    },
    {
        "query":"Do you support PrivateLink?",
        "intention":"知识问答",
        "reply":"Yes. We provide AWS PrivateLink support between Amazon VPC and Amazon Managed Grafana. You can control access to the Amazon Managed Grafana service from the virtual private cloud (VPC) endpoints by attaching an IAM resource policy for Amazon VPC endpoints. Amazon Managed Grafana supports two different kinds of VPC endpoints. You can connect to the Amazon Managed Grafana service, providing access to the Amazon Managed Grafana APIs to manage workspaces. Or you can create a VPC endpoint to a specific workspace. For information about creating a VPC endpoint for your Grafana workspaces, see [Interface VPC endpoints](https://docs.aws.amazon.com/grafana/latest/userguide/VPC-endpoints.html)."
    },
    {
        "query":"Is my Amazon Managed Grafana workspace URL publicly reachable?",
        "intention":"知识问答",
        "reply":"Not necessarily. You have granular security controls over the rollout of Amazon Managed Grafana workspaces by defining [customer-managed prefix lists](https://docs.aws.amazon.com/vpc/latest/userguide/managed-prefix-lists.html) and [VPC endpoints](https://docs.aws.amazon.com/whitepapers/latest/aws-privatelink/what-are-vpc-endpoints.html) to help you restrict the inbound network traffic that can reach your Grafana workspaces.  Amazon Managed Grafana supports two modes for user and host access of your Grafana workspace: open access and restricted access. The open access mode is the default access setting for Grafana workspaces when there are no VPC endpoints or managed prefix list restrictions to reach your Grafana workspace URL; however, users must still authenticate with the configured identity provider(s) in order to log in to the workspace. The restricted access mode enables you to specify the inbound network traffic that is allowed to reach your workspace. To restrict access, you can configure prefix lists to specify IP address ranges from which users and hosts can reach your Grafana workspace. You can also [create an interface VPC endpoints](https://docs.aws.amazon.com/grafana/latest/userguide/VPC-endpoints.html) to allow AWS resources such as Amazon EC2 instances to access the Amazon Managed Grafana API to manage resources, or you can use a VPC endpoint as part of limiting network access to your Amazon Managed Grafana workspaces."
    },
    {
        "query":"How is Amazon Managed Grafana priced?",
        "intention":"知识问答",
        "reply":"You are billed monthly for the total number of active users that have logged in to each Grafana workspace, with a minimum of one Editor user license per workspace per month. There are two tiers of users: an Editor user price that can be assigned Administrator or Editor roles, and a Viewer user price that can be assigned a Viewer role. For detailed pricing information, please reference the Amazon Managed Grafana [pricing page](https://aws.amazon.com/grafana/pricing/)."
    },
    {
        "query":"What is an active user?",
        "intention":"知识问答",
        "reply":"An “Active user” has logged in to an Amazon Managed Grafana workspace or made an API request at least once during a monthly billing cycle. Users who are provisioned with access to Grafana workspaces but have not used the service at least once in the monthly billing cycle will not be charged. If no users log into a workspace for a month, you will be billed for one minimum Editor user license per workpsace per month."
    },
    {
        "query":"Can I create multiple workspaces?",
        "intention":"知识问答",
        "reply":"Yes, you can create multiple workspaces. Users are billed per workspace per month. For example, if User A belongs to both Workspace 1 and Workspace 2, User A will be billed for using Workspace 1 and separately billed for using Workspace 2."
    },
    {
        "query":"Will I be charged for API requests?",
        "intention":"知识问答",
        "reply":"There are three types of API requests when working with an Amazon Managed Grafana workspace. The first type are Amazon Managed Grafana APIs that are used to create, edit, and delete workspaces. These do not incur charges. The second type are Grafana API keys that are used to manage workspace resources such as dashboards, alerts, and data sources are billed per API user license, and can be granted Administrator, Editor, or Viewer permissions. If multiple API keys are associated with the same API user license, then the higher price will be applied to the API user license. Charges for Grafana API user licenses will appear on your AWS bill under the Amazon Managed Grafana section. The third type are Amazon Managed Grafana data queries made to other AWS Services and third-party ISVs that may charge fees for using their APIs. These API fees are charged by the respective AWS service or third-party ISV and not charged by Amazon Managed Grafana. For example, a dashboard in Amazon Managed Grafana that contains CloudWatch metrics will make requests to Amazon CloudWatch, and this will incur API fees on your CloudWatch bill.\nQ: How do I upgrade my Amazon Managed Grafana workspace to Grafana Enterprise?\nYou can optionally upgrade to Grafana Enterprise directly from the AWS Console, enabling you to access Enterprise plugins that connect to a wide variety of third-party ISVs, as well as access support and training directly from Grafana Labs. By upgrading to Grafana Enterprise, you can continue to use your existing Amazon Managed Grafana workspaces, and receive additional features in the upgraded workspace, all fully managed on Amazon Managed Grafana. If you decide to unsubscribe Grafana Enterprise from a workspace, this will disable Grafana Enterprise features for that workspace; however, you can continue to use the workspace and access Amazon Managed Grafana features."
    },
    {
        "query":"How will I be billed if I have both Amazon Managed Grafana and Grafana Enterprise?",
        "intention":"知识问答",
        "reply":"You will receive one bill with your Amazon Managed Grafana usage, based on active Editor and active Viewer users per workspace per month. If you upgrade your Amazon Managed Grafana workspace(s) to Grafana Enterprise, you will see charges for Grafana Enterprise on your AWS Marketplace bill. Grafana Enterprise pricing is in addition to Amazon Managed Grafana's per Editor and per Viewer pricing.\nLearn more about pricing options for Amazon Managed Grafana.\nInstantly get access to the AWS Free Tier.\nGet started building with Amazon Managed Grafana in the AWS Management Console."
    },
    {
        "query":"什么是 Amazon Transcribe？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 是一项 AWS 人工智能（AI）服务，使您能够轻松实现语音转文本功能。采用自动语音识别（ASR）技术，您可以将 Amazon Transcribe 用于各种业务应用程序，包括转录基于语音的客户服务通话、生成音频/视频内容字幕，以及对音频/视频内容执行（基于文本的）内容分析。"
    },
    {
        "query":"Amazon Transcribe 如何与其他 AWS 产品交互？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 可以将音频输入转换为文本，这为开发基于语音输入的各种文本分析应用程序打开了方便之门。例如，通过将 Amazon Comprehend 用于来自 Amazon Transcribe 的转换后文本数据，您可以进行情绪分析或提取实体和关键短语。同样，通过将 Amazon Translate 与 Amazon Polly 集成，您可以接收一种语言的语音输入，然后将其翻译为另一种语言并生成语音输出，从而有效地实现多种语言对话。还可以将 Amazon Transcribe 与 Amazon Kendra 或 Amazon OpenSearch 集成，以便在音频/视频库内编写索引并执行基于文本的搜索。要了解更多信息，请查看[实时呼叫分析和座席协助](https://aws.amazon.com/cn/blogs/machine-learning/live-call-analytics-and-agent-assist-for-your-contact-center-with-amazon-language-ai-services/)、[呼叫后分析](https://aws.amazon.com/cn/blogs/machine-learning/post-call-analytics-for-your-contact-center-with-amazon-language-ai-services/)、[媒体搜索](https://aws.amazon.com/blogs/machine-learning/make-your-audio-and-video-files-searchable-using-amazon-transcribe-and-amazon-kendra/)或[内容分析](https://aws.amazon.com/solutions/implementations/aws-content-analysis/)解决方案。"
    },
    {
        "query":"我在使用 Amazon Transcribe 之前还应了解什么？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 旨在处理各种语音和声学特征，包括音量、音调和语速的变化。音频信号的质量和内容（包括但不限于背景噪音、扬声器重叠、口音或一个音频文件内语言间的切换等因素）可能会影响服务输出的准确性。我们在不断更新服务，以改进其适应其他声音变化和内容类型的能力。"
    },
    {
        "query":"开发人员将如何访问 Amazon Transcribe？",
        "intention":"知识问答",
        "reply":"开始使用的最简单的方法是使用控制台提交任务来转录音频文件。您也可以从 AWS 命令行界面直接调用该服务，或使用您选择的任一受支持的软件开发工具包，将其与您的应用程序集成。无论哪种方式，您都只需几行代码即可开始使用 Amazon Transcribe 为音频文件生成自动转录。"
    },
    {
        "query":"Amazon Transcribe 是否支持实时转录？",
        "intention":"知识问答",
        "reply":"可以。Amazon Transcribe 允许您通过 HTTP2 打开双向流。您可以在接收返回的文本流的同时，将音频流实时发送到服务。有关更多详细信息，请参阅[文档页面](https://docs.aws.amazon.com/transcribe/latest/dg/streaming.html)。"
    },
    {
        "query":"实时转录支持哪种编码？",
        "intention":"知识问答",
        "reply":"批处理转录和流式转录之间支持的媒体类型有所不同，但两者都建议使用无损格式。有关更多详细信息，请参阅[文档页面](https://docs.aws.amazon.com/transcribe/latest/dg/how-input.html)。"
    },
    {
        "query":"Amazon Transcribe 支持哪些语言？",
        "intention":"知识问答",
        "reply":"有关语言支持的信息，请参阅此[文档](https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html)页面。"
    },
    {
        "query":"哪些设备可以使用 Amazon Transcribe？",
        "intention":"知识问答",
        "reply":"在很大程度上，Amazon Transcribe 不受设备影响。一般而言，具有内置麦克风的任何设备都可以使用，例如手机、PC、平板电脑和物联网设备（如车载音频系统）。Amazon Transcribe API 将能够检测在设备上输入的音频流质量（8kHz 或 16kHz），并相应地选择用于将语音转换为文本的声学模型。此外，开发人员可以通过其应用程序调用 Amazon Transcribe API 来使用语音到文本转换功能。"
    },
    {
        "query":"Amazon Transcribe 可以处理的音频内容是否有大小限制？",
        "intention":"知识问答",
        "reply":"对于我们的批处理服务，Amazon Transcribe 服务调用限制为每个 API 调用四个小时（或 2 GB）。流式处理服务可以容纳长达四小时的开放式连接。"
    },
    {
        "query":"Amazon Transcribe 支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 批处理服务支持 .NET、Go、Java、JavaScript、PHP、Python 和 Ruby。 Amazon Transcribe 实时服务支持 Java 软件开发工具包、Ruby 软件开发工具包和 C++ 软件开发工具包。对其他软件开发工具包的支持也即将推出。有关更多详细信息，请访问[资源](https://aws.amazon.com/transcribe/resources/)和[文档页面](https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html#supported-sdks)。\n问：我的自定义词汇表中的单词总是无法识别。该怎么办？\n除了自定义词汇表条目之外，语音识别输出还取决于许多因素，因此可能无法保证自定义词汇表中的术语会被正确识别。但是，最常见的原因是自定义单词缺少正确的发音。如果您还没有为自定义单词提供发音，请尝试创建发音。如果您已提供发音，请仔细检查其正确性，或者根据需要添加其他发音形式。这可以通过在自定义词汇表文件中创建发音字段不同的多个条目来实现。如需了解更多信息，请参阅[自定义词汇表文档](https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary.html)。"
    },
    {
        "query":"为什么我的输出中出现过多自定义单词？",
        "intention":"知识问答",
        "reply":"自定义词汇表针对一小部分目标单词进行了优化；如果词汇表较大，可能会导致过度生成自定义单词，尤其是当词汇表中包含发音相似的单词时。如果您的词汇表较大，请尝试将其缩小为生僻字和实际上预计会出现在音频文件中的单词。如果您有一个涵盖多个使用案例的大型词汇表，请将它分成针对不同使用案例的单独列表。简短且发音与许多其他单词相似的单词可能会导致过度生成（输出中出现过多自定义单词）。最好将这些单词与周围的单词组合，并将它们列为连字符分隔的短语。例如，自定义单词“A.D.”可以作为“A.D.-converter”这类短语的一部分。"
    },
    {
        "query":"IPA 或 SoundsLike 字段这两种方式均可在自定义词汇表中提供发音。哪种方式更好？",
        "intention":"知识问答",
        "reply":"IPA 可提供更精确的发音。如果您能够生成 IPA（例如通过具有 IPA 发音的词典或在线转换器工具生成），则应提供 IPA 发音。"
    },
    {
        "query":"我想使用 IPA，但我不是语言专家。有没有我可以使用的在线工具？",
        "intention":"知识问答",
        "reply":"牛津英语词典或剑桥词典（包括在线版本）等多种标准词典均可在 IPA 中提供发音。此外，还有在线转换器（例如，英文版 [easypronunciation.com](https://easypronunciation.com/en/) 或 [tophonetics.com](https://tophonetics.com/)）；但请注意，在大多数情况下，这些工具基于底层词典，可能无法为某些单词（如专有名词）生成正确的 IPA。Amazon Transcribe 不为任何第三方工具做宣传。"
    },
    {
        "query":"我是否需要使用针对同一语言不同口音的不同 IPA 标准（例如，美国英语与英国英语）？",
        "intention":"知识问答",
        "reply":"您应该使用适用于要处理的音频文件的 IPA 标准。例如，如果您希望处理来自英国英语使用者的音频，请使用英国英语发音标准。对于 Amazon Transcribe 支持的不同语言和方言，允许的 IPA 符号集可能会有所不同；请确保您的发音仅包含允许的字符。有关 IPA 字符集的详细信息，请参阅文档：[自定义词汇表](https://docs.aws.amazon.com/transcribe/latest/dg/charsets.html)"
    },
    {
        "query":"如何在自定义词汇表中使用 SoundsLike 字段提供发音？",
        "intention":"知识问答",
        "reply":"您可以将单词或短语分成更小的片段，并使用相应语言的标准拼写法为每个片段提供发音，以模仿单词的发音方式。例如，在英语中，您可以为短语“Los-Angeles”提供如下发音提示：loss-ann-gel-es。单词“Etienne”的发音提示就像这样：eh-tee-en。用连字符（-）分隔发音提示的各个部分。您可以针对输入语言使用任何允许的字符。有关详细信息，请访问[自定义词汇表](https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary-create-table.html)页面。"
    },
    {
        "query":"如何使用提供首字母缩略词的两种不同方式（有句点、无句点但有发音）？",
        "intention":"知识问答",
        "reply":"如果您使用包含句点的首字母缩略词，拼写发音将在内部生成。如果您不使用句点，请在发音字段中提供发音。对于一些首字母缩略词，它们是否有拼写发音或类似单词的发音并不明显。例如，“NATO”通常发音为“n eɪ t oʊ”（nay-toh），而不是“ɛn eɪ ti oʊ”（N. A.T. O.)。有关详细信息，请访问[自定义词汇表](https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary-create-table.html)页面。"
    },
    {
        "query":"在哪里可以找到如何使用自定义发音的示例？",
        "intention":"知识问答",
        "reply":"您可以在[此处的文档](https://docs.aws.amazon.com/transcribe/latest/dg/custom-vocabulary-create-table.html)中找到示例输入格式和示例。"
    },
    {
        "query":"如果我使用错误的 IPA 会发生什么情况？ 在我不确定的情况下，是否最好不要输入任何 IPA？",
        "intention":"知识问答",
        "reply":"系统将使用您提供的发音；如果发音正确并且与所说的单词相匹配，应该可以增加正确识别单词的可能性。如果您不确定生成的 IPA 是否正确，请通过使用包含 IPA 发音的词汇表和仅包含单词的词汇表（可以选择 display-as 表单）处理您的音频文件来进行比较。如果您不提供任何发音，该服务将使用近似发音，这可能比您输入的发音好，也可能还不如您输入的发音。"
    },
    {
        "query":"使用 DisplayAs 表单时，是否可以显示与被转录的原始语言无关的字符集（例如，将“Street”输出为“街道”）？",
        "intention":"知识问答",
        "reply":"可以。虽然短语只能对特定语言使用受限制的字符集，但在 DisplayAs 列中允许使用除 \\t（TAB）之外的 UTF-8 字符。"
    },
    {
        "query":"Transcribe 的批处理和流处理 API 是否都可以使用自动内容修订或个人身份信息（PII）修订？",
        "intention":"知识问答",
        "reply":"是的，Amazon Transcribe 支持批处理和流处理 API 的[自动内容修订或 PII 修订](https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html)。"
    },
    {
        "query":"自动内容修订/PII 识别和修订支持哪些语言？",
        "intention":"知识问答",
        "reply":"请参阅 Amazon Transcribe 文档了解有关[自动内容修订/PII 修订的语言可用性](https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html)的信息。"
    },
    {
        "query":"自动内容修订功能是否还会修订源音频中的个人敏感信息？",
        "intention":"知识问答",
        "reply":"否，此功能不会从源音频中删除个人敏感信息。但是，Amazon Transcribe 呼叫分析会从转录本和源音频中删除敏感的个人信息。访问此链接以了解有关呼叫分析如何修订音频的更多详细信息。您还可以使用开始和结束时间戳自行修订源音频中的个人信息，这些时间戳提供在已识别 PII 语句的每个实例的修订记录中。有关标准 Transcribe API，请参阅此[音频修订解决方案](https://aws.amazon.com/cn/blogs/machine-learning/perform-audio-redaction-for-personally-identifiable-information-with-amazon-transcribe/)。\n但是，专门的 Amazon Transcribe 呼叫分析 API 会从转录本和源音频中删除敏感的个人信息。要了解更多信息，请查看[呼叫分析音频修订文档](https://docs.aws.amazon.com/transcribe/latest/dg/call-analytics-insights.html#call-analytics-insights-redaction)。"
    },
    {
        "query":"我能否使用自动内容修订功能修订现有文本转录中的个人信息?",
        "intention":"知识问答",
        "reply":"不能，自动内容修订只能用于作为输入的音频。"
    },
    {
        "query":"我在使用自动内容修订功能前还应了解什么？",
        "intention":"知识问答",
        "reply":"自动内容修订功能旨在识别和删除个人身份信息（PII），但由于机器学习的预测性质，它可能无法识别并删除服务所生成的记录中的所有 PII 实例。您应该查看自动内容修订功能提供的所有输出，以确保它满足您的需求。"
    },
    {
        "query":"流处理和批处理 API 的自动内容修订是否有任何差别？",
        "intention":"知识问答",
        "reply":"是的，流处理 API 的自动内容修订还支持另外两个功能，而批处理 API 不支持这两项功能。您可以决定在使用流处理 API 的内容修订时仅识别 PII 而不进行修订。同时，您还能够使用流处理 API [识别或修订特定 PII 类型](https://docs.aws.amazon.com/transcribe/latest/dg/pii-redaction.html#table-redaction-list)。例如，您可以只修订社会保险号和信用卡信息，保留其他 PII，如姓名和电子邮件地址。"
    },
    {
        "query":"在哪些 AWS 区域提供自动内容修订或 PII 修订？",
        "intention":"知识问答",
        "reply":"请参阅 [Amazon Transcribe 文档](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)了解有关 AWS 区域中批处理和流处理 API 的自动内容修订和 PII 修订可用性的信息。"
    },
    {
        "query":"哪些 API 支持自动语言识别？",
        "intention":"知识问答",
        "reply":"批处理和流处理 API 当前支持自动语言识别。"
    },
    {
        "query":"Amazon Transcribe 可以自动识别哪些语言？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 可以识别批处理和流处理 API 支持的任何语言。单击此处了解[有关支持的语言和语言特定功能的详细信息](https://docs.aws.amazon.com/transcribe/latest/dg/supported-languages.html)。"
    },
    {
        "query":"Amazon Transcribe 能否识别同一音频文件中的多种语言？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 支持批处理的多语言 ID。请参阅[此链接](https://docs.aws.amazon.com/transcribe/latest/dg/lang-id-batch.html#lang-id-batch-multi-language)了解更多信息。"
    },
    {
        "query":"对于自动语言识别，是否有任何方法可以限制供选择的语言列表？",
        "intention":"知识问答",
        "reply":"是的，您可以指定媒体库中可能存在的语言列表。如果您提供了语言列表，系统将从该列表中选择所识别的语言。如果您未指定任何语言，则系统将根据 Amazon Transcribe 支持的所有语言处理音频文件，然后选择最可能的一种语言。提供可供选择的语言列表时，语言识别的准确性会更高。请参阅[此链接](https://docs.aws.amazon.com/transcribe/latest/APIReference/API_StartTranscriptionJob.html#transcribe-StartTranscriptionJob-request-IdentifyLanguage)了解更多信息。"
    },
    {
        "query":"在哪些 AWS 区域提供 Amazon Transcribe？",
        "intention":"知识问答",
        "reply":"请参阅 AWS 全球基础设施[区域表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。点击此处了解[有关 Amazon Transcribe 端点和配额的更多详细信息](https://docs.aws.amazon.com/general/latest/gr/transcribe.html)。"
    },
    {
        "query":"Amazon Transcribe 是否会存储处理过的语音输入？AWS 如何使用这些输入？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 会存储和使用服务处理过的语音输入，这样做只是为了提供和维护服务以及改进和提高 Amazon Transcribe 和其他亚马逊机器学习/人工智能技术的质量。为了持续改善您的 Amazon Transcribe 客户体验并促进相关技术的开发和训练，我们重视使用您的内容。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/cn/compliance/data-privacy-faq/)。您可以通过使用 AWS Organizations 退出策略选择不再使用您的内容来改进或提高 Amazon Transcribe 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅 [AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"我可否删除与 Amazon Transcribe 存储的转录作业相关的数据和构件？",
        "intention":"知识问答",
        "reply":"可以。您可以使用提供的 [Delete API](https://docs.aws.amazon.com/transcribe/latest/dg/API_DeleteTranscriptionJob.html) 删除与转录任务相关的数据和其他构件。如果在此过程中遇到问题，请联系 AWS Support。"
    },
    {
        "query":"谁有权访问 Amazon Transcribe 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问 Amazon Transcribe 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"由 Amazon Transcribe 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"在训练自定义语言模型时使用的数据会发生什么变化？ 我是否仍能拥有它？",
        "intention":"知识问答",
        "reply":"提交用于训练专用模型的文本数据时，您拥有原始文本数据的所有权和生成的自定义模型的所有权。将不会存储文本数据，也不会将其用于改进我们的通用语音识别引擎。使用 CLM 生成的模型是独立模型，并且只能由您访问。"
    },
    {
        "query":"由于该服务将不会保留我的训练数据，转录质量或整体服务体验是否存在任何缺点或下降？",
        "intention":"知识问答",
        "reply":"我们的服务不会存储您的训练数据，不会导致转录质量下降。使用训练数据实际生成自定义语言模型后，您可以自行决定模型本身是否可以重复使用。您上传的原始训练集将从我们的系统中删除。唯一的缺点是如果您需要技术支持。由于我们不会保留您的原始训练数据，因此如果您要求支持团队调查潜在的服务问题，我们将无法方便地访问这些资产或相关的中间构件。仍将提供支持，但不是很方便，因为我们可能需要您提供其他信息。"
    },
    {
        "query":"如何将数据重复用于未来的模型更新或改进？",
        "intention":"知识问答",
        "reply":"由于未存储训练数据，因此必须重新上传相同的数据集和所有其他数据才能训练新模型。当 Amazon Transcribe 提供的基本模型有更新时，将通知您。要利用最新的基本模型，您应该提交数据以训练新模型。然后，您将拥有之前生成的原始自定义模型以及要使用的新版本。"
    },
    {
        "query":"如何删除模型？",
        "intention":"知识问答",
        "reply":"您可以自行决定删除自己生成的任何客户语言模型。"
    },
    {
        "query":"Amazon Transcribe 处理的内容是否会移出到我使用 Amazon Transcribe 所在的 AWS 区域之外？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe 处理的任何内容都会被加密，并静态存储在您使用 Amazon Transcribe 所在的 AWS 区域中。Amazon Transcribe 处理的部分内容可能存储在另一个 AWS 区域中，仅用于持续改进和开发您的 Amazon Transcribe 客户体验及其他 Amazon 机器学习/人工智能技术。如果您通过联系 AWS Support，选择不再使用您的内容来提高 Amazon Transcribe 及其他 Amazon 机器学习/人工智能技术的质量，您的内容将不会存储在其他 AWS 区域中。您可以联系 AWS Support 请求删除与您的账户相关的语音输入。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"是否可以将 Amazon Transcribe 用于面向不满 13 周岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 Amazon Transcribe 服务条款，包括按照 COPPA 的要求提供必要的通知并获得必要的、可验证的家长同意，才能将 Amazon Transcribe 用于全部或部分面向不满 13 周岁儿童的网站、项目或其他应用程序。"
    },
    {
        "query":"怎样确定我的网站、项目或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、程序或其他应用程序是否受 COPPA 约束的指南，请直接参阅[美国联邦贸易委员会](https://www.ftc.gov/business-guidance/resources/complying-coppa-frequently-asked-questions)提供并维护的各种资源。该网站还提供有关如何确定某种服务是否全部或部分针对不满 13 岁儿童的信息。"
    },
    {
        "query":"什么是 Amazon Transcribe 呼叫分析？  Amazon Transcribe 呼叫分析是一种 AI 支持的 API，可提供丰富的通话转录文字和可实施的对话洞察，您可以将其添加到调用应用程序以改善客户体验并提高座席效率。它结合了强大的自定义语音转文本和自然语言处理（NLP）模型，这些模型经过专门训练，可理解客户服务和外拨销售通话。作为 AWS Contact Center Intelligence（CCI）解决方案的一部分，此 API 不受联系中心影响，客户和 ISV 可通过它更轻松地向其应用程序添加呼叫分析功能。  问：Amazon Transcribe 呼叫分析有什么用处？  Amazon Transcribe 呼叫分析可以进行实时和呼叫后分析。通过呼叫分析，开发人员可以快速地添加有价值的情报，例如客户和座席情绪评分、呼叫原因和呼叫类别，直接作为入站或出站呼叫应用程序的 API 输出。常见使用案例包括座席辅助、主管警报和呼叫分析。这里有两个基于 Transribe 呼叫分析的开源示例解决方案：带有座席辅助的实时呼叫分析和呼叫后分析。  问：如何开始使用 Amazon Transcribe 呼叫分析？   您可以通过 API 和 AWS 管理控制台使用 Transcribe 呼叫分析。分析任务可以通过 API 或控制台创建和监控。在控制台中，您将会看到分析任务列表，以及包含输入参数和 JSON 输出预览的任务详细信息页面。除此之外，您还将能够通过 API 或控制台创建和编辑类别，用于自动联系分类功能。  问：Amazon Transcribe 呼叫分析支持哪些语言？  请参阅 Amazon Transcribe 文档了解有关 Amazon Transcribe 呼叫分析的语言可用性的信息。  问：Amazon Transcribe 呼叫分析在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域服务文档](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)，了解 Amazon Transcribe 呼叫分析的 AWS 区域覆盖范围信息。"
    },
    {
        "query":"Amazon Transcribe Medical 是什么？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe Medical 是一种自动语音识别 (ASR) 服务，让开发人员能够轻松地为其应用程序添加医疗语音转文本功能。使用 Amazon Transcribe Medical，您可以出于各种目的快速、准确地将医疗诊断和对话性语音转录成文本，例如记录医生笔记或在下游文本分析中进行处理以提取有意义的见解。"
    },
    {
        "query":"Amazon Transcribe Medical 有什么用处？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe Medical 使用先进的机器学习模型将医学语音准确地转录为文本。Transcribe Medical 可以生成可用于支持各种使用案例的通用文字记录，涵盖从临床文档工作流程和药物安全监控（药物警戒）到远程医疗字幕的使用场景，甚至覆盖医疗保健和生命科学领域的联络中心分析。"
    },
    {
        "query":"要使用 Amazon Transcribe Medical，我是否需要成为自动语音识别 (ASR) 方面的专家？",
        "intention":"知识问答",
        "reply":"否，您不需要具备任何 ASR 或机器学习专业知识即可使用 Amazon Transcribe Medical。您只需要调用 Transcribe Medical 的 API，该服务即可在后端处理所需的机器学习任务，以将医学语音转录为文本。"
    },
    {
        "query":"如何开始使用 Amazon Transcribe Medical？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台或开发工具包开始使用 Amazon Transcribe Medical。有关详细信息，请参阅此[技术文档页面](https://docs.aws.amazon.com/transcribe/latest/dg/transcribe-medical.html)。\nAmazon Transcribe Medical 提供了免费套餐以便您试用此服务。有关更多信息，请参阅此定价页面。"
    },
    {
        "query":"Amazon Transcribe Medical 支持哪些语言？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe Medical 目前支持美国英语的医学转录。"
    },
    {
        "query":"Amazon Transcribe Medical 支持哪些医学专业？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe Medical 支持初级护理和专科护理专业扩展清单内容的转录。请访问我们的[文档](https://docs.aws.amazon.com/transcribe/latest/dg/what-is-transcribe-med.html)以获得可支持医学专业的完整列表。"
    },
    {
        "query":"Amazon Transcribe Medical 在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域服务文档](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)，了解 Amazon Transcribe Medical 的 AWS 区域覆盖范围信息。\n问：Amazon Transcribe Medical 如何定价？\n请参阅 [Amazon Transcribe Medical 定价页面](https://aws.amazon.com/transcribe/pricing/)详细了解定价详情。"
    },
    {
        "query":"Amazon Transcribe Medical 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"是的。"
    },
    {
        "query":"除为了提供此服务以外，Amazon Transcribe Medical 处理的内容是否会被用于任何其他目的？",
        "intention":"知识问答",
        "reply":"除为了提供和维护此服务外，Amazon Transcribe Medical 不会以任何其他理由使用此服务处理的内容。该服务处理的内容不会用于开发或改善 Amazon Transcribe Medical 或任何其他 Amazon 机器学习/人工智能技术的质量。"
    },
    {
        "query":"Amazon Transcribe Medical 是否在不断学习？",
        "intention":"知识问答",
        "reply":"是的，Amazon Transcribe Medical 采用机器学习技术，并会不断受到训练，以便在客户使用案例中表现得更出色。Amazon Transcribe Medical 不会存储或利用该服务所用的客户数据来训练模型"
    },
    {
        "query":"在使用 Amazon Transcribe Medical 服务之前，我还应具备哪些其他知识？",
        "intention":"知识问答",
        "reply":"Amazon Transcribe Medical 并不能代替专业的医学意见、诊断或治疗。您和您的最终用户应依据自己的斟酌、经验和判断来确定 Amazon Transcribe Medical 提供的任何信息的正确性、完整性、及时性和适合性。您与您的最终用户对基于 Amazon Transcribe Medical 的使用，做出的任何决定、建议及行动和/或不作为负全部责任。\nAmazon Transcribe Medical 可能无法在所有情况下准确识别受保护的健康信息，并且不符合根据 HIPAA 取消识别受保护的健康信息的要求。您有责任审核 Amazon Transcribe Medical 提供的任何输出，以确保其符合您的需求。"
    },
    {
        "query":"自定义语言模型目前提供了哪些功能？",
        "intention":"知识问答",
        "reply":"您可以使用自定义语言模型 (CLM) 来训练和开发特定领域的语言模型。CLM 目前支持澳大利亚英语、英国英语、印度语、美国英语和美国西班牙语的批量转录，以及美国英语的流式转录。CLM 支持同时使用自定义词汇进行批量转录。"
    },
    {
        "query":"我需要的训练数据量和类型是什么？ 如何获取数据？ 数据是否需要具有特定的格式？",
        "intention":"知识问答",
        "reply":"文本数据应与要使用自定义模型进行转录的音频相关；它应包含尽可能多的特定于域的单词、短语和单词组合。我们建议在运行文本中使用至少 10 万和最多 1000 万个单词。可以从任何内部或公共来源获得文本数据资源（例如，使用来自客户网站的文本）。我们建议每个纯文本文件包含 20 万个单词或更多，但总文件大小不要超过 1 GB。文本应采用 UTF-8 格式，并且每行使用一个句子。每个句子都应包含标点符号。用户负责检查拼写、删除格式字符并验证编码。"
    },
    {
        "query":"如何使用自定义语言模型 (CLM)？",
        "intention":"知识问答",
        "reply":"要训练自定义语言模型，客户只需在 Amazon S3 存储桶中提供文本数据即可。然后，用户可以使用 Amazon Transcribe 服务控制台加载和处理数据以训练自定义语言模型。训练是全自动化的过程，只需用户最少的干预。当最终自定义模型准备就绪后，将在客户的 AWS 账户中提供，以用于转录特定于域的音频文件。此外，客户可以训练多个自定义模型以用于各种不同的使用案例。"
    },
    {
        "query":"是否保证有所改进？ 是否值得花精力来收集文本数据？",
        "intention":"知识问答",
        "reply":"不能保证有所改进 – 性能的变化将取决于文本数据与音频的匹配程度以及所提供的数据量。通常，数据越多越好，但最重要的是，这些数据应涵盖您打算转录的音频文件中预期出现的单词和单词序列。转录准确性的提高将取决于训练数据量和使用案例。在某些情况下，常规基准测试表明相对准确性会提高 10％ 至 15％。"
    },
    {
        "query":"模型训练需要多长时间？ 何时才能使用它？",
        "intention":"知识问答",
        "reply":"模型训练通常需要 6 到 10 个小时。训练时间的长短取决于数据集的大小。完成训练后，将直接提供自定义模型。"
    },
    {
        "query":"如何使用模型？ 如何知道它是否比 Amazon Transcribe 提供的通用模型更好？",
        "intention":"知识问答",
        "reply":"该模型将采用您在训练开始之前指定的模型 ID 在您的账户中提供。为了使用模型，需要将具有模型 ID 的标志添加到转录请求中。您应在音频文件上测试模型，并将输出与从通用引擎获得的结果进行比较。"
    },
    {
        "query":"我可以训练多少个自定义语言模型？ 是否可以同时为我的账户启用多个模型？",
        "intention":"知识问答",
        "reply":"您可以在任何给定的时间为每个 AWS 账户同时训练最多 5 个不同的模型。对于每个账户，默认情况下最多可以存储 10 个模型。如果需要更多模型，可以在[此处](https://docs.aws.amazon.com/transcribe/latest/dg/limits-guidelines.html)增加服务限制。"
    },
    {
        "query":"是否支持自定义声学模型？",
        "intention":"知识问答",
        "reply":"否。不支持自定义声学模型。自定义语言模型是基于与使用案例或域相关的文本数据构建的。"
    },
    {
        "query":"什么是自然语言处理？",
        "intention":"知识问答",
        "reply":"自然语言处理 (NLP) 是计算机分析和理解文本信息并从中归纳意义的一种有效且智能的方式。利用 NLP，您可以提取重要短语、情绪、语法、重要实体（如品牌、日期、地点、人物等）及文本语言信息。"
    },
    {
        "query":"什么是 Amazon Comprehend？",
        "intention":"知识问答",
        "reply":"Amazon Comprehend 是一项自然语言处理 (NLP) 服务，可利用机器学习发现文本中的意义和洞察信息。"
    },
    {
        "query":"Amazon Comprehend 有什么用处？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon Comprehend 识别文本的语言，提取关键词、地点、人物、品牌或事件，理解对于产品或服务的看法，并根据文档库来识别主要主题。此类文本的来源可以是网页、社交媒体供稿、电子邮件或文章。此外，您还可以将一组文本文档导入 Amazon Comprehend，随后它会识别最能表达该组文档的意思的主题 (或词组)。您可以使用 Amazon Comprehend 的输出了解客户反馈，通过搜索筛选条件提供更好的搜索体验，并使用主题对文档进行分类。"
    },
    {
        "query":"如何开始使用 Amazon Comprehend？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 控制台开始使用 Amazon Comprehend。您可以享受 12 个月的免费套餐，自您首次提交申请时生效。请参阅产品[文档](http://docs.aws.amazon.com/comprehend/latest/dg/what-is.html)，了解如何在应用程序中使用 Amazon Comprehend API。"
    },
    {
        "query":"Amazon Comprehend 最常见的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"最常见的使用案例包括：\n客户语音分析：您可以根据通过客服电话、电子邮件、社交媒体及其他网络渠道获取的反馈判断客户的情绪如何，是正面、中性、负面还是混合的。\n语义搜索：使用 Amazon Comprehend，您可以让搜索引擎将关键词、实体和情绪编入索引，从而提供更好的搜索体验。这使您能够将搜索重点放在文章的意图和上下文上而非基本关键字上。\n知识管理和发现：您可以分析一系列文档并自动按主题对文档进行分类整理。然后，您可以使用主题为客户提供个性化内容。"
    },
    {
        "query":"是否只有自然语言处理专家才能使用 Amazon Comprehend？",
        "intention":"知识问答",
        "reply":"不是，使用 Amazon Comprehend 不需要具备 NLP 专业知识。您只需调用 Amazon Comprehend 的 API，该服务便会负责处理从文本提取相关数据所需的机器学习。"
    },
    {
        "query":"Amazon Comprehend 是不是一种托管服务？",
        "intention":"知识问答",
        "reply":"Amazon Comprehend 是一种完全托管且持续受到训练的服务，因此您无需管理资源扩展、代码维护或训练数据维护。"
    },
    {
        "query":"Amazon Comprehend 是否在不断学习？",
        "intention":"知识问答",
        "reply":"是，Amazon Comprehend 在使用机器学习方面不断受到训练，以便在使用案例中表现得更出色。"
    },
    {
        "query":"Amazon Comprehend 在哪些 AWS 区域可用？",
        "intention":"知识问答",
        "reply":"有关支持 Amazon Comprehend 的 AWS 区域列表，请访问所有 AWS 全球基础设施的 AWS [区域表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。有关更多信息，另请参阅“AWS 一般参考”中的[区域和终端节点](http://docs.aws.amazon.com/general/latest/gr/rande.html)。"
    },
    {
        "query":"Amazon Comprehend 有哪些安全防护保障？",
        "intention":"知识问答",
        "reply":"对 Amazon Comprehend API 和控制台发出的请求全部通过安全 (SSL) 连接进行。您可以使用 AWS Identity and Access Management (AWS IAM) 控制可访问特定 Amazon Comprehend 操作和资源的 IAM 用户。"
    },
    {
        "query":"数据存储在何处？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon Comprehend 从 Amazon S3 中读取数据。此外，您还可以将 Amazon Comprehend 输出的结果写入存储服务、数据库或数据仓库。"
    },
    {
        "query":"如何确定该服务是否可以处理我的数据？",
        "intention":"知识问答",
        "reply":"对于文本分析 API，您将收到一个名为“200”的 HTTP 状态代码，表明已成功处理。如果您的数据无法得到处理或超出[服务限额](http://docs.aws.amazon.com/comprehend/latest/dg/guidelines-and-limits.html)，您将收到相应的 HTTP 错误代码。"
    },
    {
        "query":"如何确定 Amazon Comprehend 是否生成了准确的结果？",
        "intention":"知识问答",
        "reply":"该服务会针对每个结果返回一个置信度。低置信度表明该服务认为结果的准确性较低。反过来，如果该服务高度信任结果，则置信度会接近 1。"
    },
    {
        "query":"我是否可以向 Amazon Comprehend 导入自己的 NLP 模型或将两者结合使用？",
        "intention":"知识问答",
        "reply":"不可以。Comprehend 目前不支持自定义模型。"
    },
    {
        "query":"Amazon Comprehend 如何定价？",
        "intention":"知识问答",
        "reply":"请参阅 Amazon Comprehend [定价页面](https://aws.amazon.com/cn/comprehend/pricing/)，了解有关定价套餐和折扣更多信息。"
    },
    {
        "query":"Amazon Comprehend 是否会存储自己处理过的文本输入？AWS 如何使用这些输入？",
        "intention":"知识问答",
        "reply":"Amazon Comprehend 可能会存储和使用自己处理过的文本输入，但仅用于提供和维护该服务以及改善 Amazon Comprehend 和其他 Amazon 机器学习/人工智能技术的质量。这不适用于 Amazon Comprehend Medical。为了持续改善您的 Amazon Comprehend 客户体验并促进相关技术的开发和训练，使用您的内容很重要。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/cn/compliance/data-privacy-faq/)。您可以通过使用 AWS Organizations 退出策略选择不再使用您的内容来改进或提高 Amazon Comprehend 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)"
    },
    {
        "query":"谁有权访问我由 Amazon Comprehend 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问您由 Amazon Comprehend 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 AWS [数据隐私常见问题](https://aws.amazon.com/compliance/data-privacy-faq/)。"
    },
    {
        "query":"由 Amazon Comprehend 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"Amazon Comprehend 处理的内容是否会移动到我使用 Amazon Comprehend 所在的 AWS 区域之外？",
        "intention":"知识问答",
        "reply":"Amazon Comprehend 处理的任何内容都会加密，并静态存储在您使用 Amazon Comprehend 所在的 AWS 区域中。由 Amazon Comprehend 处理的部分内容可能会存储在另一个 AWS 区域，但仅用于持续改善您的 Amazon Comprehend 客户体验和其他 Amazon 机器学习/人工智能技术。这不适用于 Amazon Comprehend Medical。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"能否将 Amazon Comprehend 用于针对不满 13 岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 Amazon Comprehend 服务条款的规定，包括按照 COPPA 的要求提供任何需要的通知并获得任何必要的、可验证的家长同意，才能将 Amazon Comprehend 用于全部或部分内容针对不满 13 岁的儿童的网站、项目或其他应用程序。"
    },
    {
        "query":"怎样确定我的网站、项目或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、项目或应用程序是否受 COPPA 约束的指南，请直接参阅[美国联邦贸易委员会](https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions)提供并维护的各种资源。该网站还提供有关如何确定某种服务是否全部或部分针对不满 13 岁儿童的信息。\n详细了解 Amazon Comprehend 的功能"
    },
    {
        "query":"我为什么要使用 AWS Outposts 机架而不是在 AWS 区域运营？",
        "intention":"知识问答",
        "reply":"您可以使用 Outposts 机架来支持您具有低延迟或本地数据处理要求的应用程序。这些应用程序可能需要为终端用户应用程序生成近乎实时的响应，或者需要与其他本地系统通信或控制现场设备。它们可能包括在工厂车间中运行的工作负载，用于自动化生产操作、实时患者诊断或医学成像以及内容和流媒体处理。 您可以使用 Outposts 机架安全地存储和处理需要在本地或没有 AWS 区域的国家/地区保留的客户数据。您可以在 Outposts 机架上运行数据密集型工作负载，并且如果将数据传输到 AWS 区域中既昂贵又浪费，而且想要更好的控制数据分析、备份和还原，则在本地处理数据。"
    },
    {
        "query":"Outposts 机架在哪些 AWS 区域提供？",
        "intention":"知识问答",
        "reply":"Outposts 机架在以下 AWS 区域受支持，客户可以将其 Outposts 连接到以下 AWS 区域：\n|  |  |\n| --- | --- |\n| 美国东部（俄亥俄） | us-east-2 |\n| 美国东部（弗吉尼亚北部） | us-east-1 |\n| 美国西部（加利福尼亚北部） | us-west-1 |\n| 美国西部（俄勒冈） | us-west-2 |\n| 加拿大（中部） | ca-central-1 |\n| 南美洲（圣保罗） | sa-east-1 |\n| 欧洲（法兰克福） | eu-central-1 |\n| 欧洲（爱尔兰） | eu-west-1 |\n| 欧洲（斯德哥尔摩） | eu-north-1 |\n| 欧洲（巴黎） | eu-west-3 |\n| 欧洲（伦敦） | eu-west-2 |\n| 欧洲（米兰） | eu-south-1 |\n| 中东（巴林） | me-south-1 |\n| 非洲（开普敦） | af-south-1 |\n| 亚太地区（悉尼） | ap-southeast-2 |\n| 亚太地区（东京） | ap-northeast-1 |\n| 亚太地区（首尔） | ap-northeast-2 |\n| 亚太地区（新加坡） | ap-southeast-1 |\n| 亚太地区（香港） | ap-east-1 |\n| 亚太地区（孟买） | ap-south-1 |\n| 亚太地区（大阪） | ap-northeast-3 |\n| 亚太地区（雅加达） | ap-southeast-3 |\n| AWS GovCloud（美国西部） | us-gov-west-1 |\n| AWS GovCloud（美国东部） | us-gov-east-1 |"
    },
    {
        "query":"Outposts 机架在哪些国家/地区和领土提供？",
        "intention":"知识问答",
        "reply":"Outposts 机架可以运送到以下国家和地区进行安装。\n即将在更多国家和地区推出支持服务。"
    },
    {
        "query":"我能否在未推出 Outposts 机架的国家或地区订购 Outpost，然后再将它链接回支持的区域？",
        "intention":"知识问答",
        "reply":"不能，我们只能在可交付和支持 Outposts 机架的国家和地区交付和安装 Outposts 机架。"
    },
    {
        "query":"当 Outposts 机架没有与 AWS 区域连接或者处于连接断开的环境时，我能否使用它？",
        "intention":"知识问答",
        "reply":"Outpost 依赖与父级 AWS 区域的连接。按设计，Outposts 机架不能用于连接断开的操作或连接有限或没有连接的环境。我们建议客户将高度可用的网络连接回他们的 AWS 区域。如果您想要在断开连接的环境（例如游轮或偏远采矿区域）中利用 AWS 服务，请详细了解 AWS 服务，例如 Snowball Edge，该服务进行了优化，可以在连接有限或没有连接的环境中运行。"
    },
    {
        "query":"我能否在 Outposts 中重新使用我的现有服务器？",
        "intention":"知识问答",
        "reply":"否，AWS Outposts 机架利用 AWS 设计的基础设施，仅支持用于针对安全、高性能和可靠操作优化的 AWS 设计的硬件。"
    },
    {
        "query":"AWS Outposts 机架是否有纯软件版本？",
        "intention":"知识问答",
        "reply":"否，AWS Outposts 机架是一项完全托管式服务，可为您提供对 AWS 服务的本机访问。"
    },
    {
        "query":"我能否订购自己的硬件，作为 Outposts 机架的一部分安装？",
        "intention":"知识问答",
        "reply":"不能，AWS Outposts 机架提供完全集成的 AWS 设计配置，其中带有内置的架顶交换机和冗余电源，可以为您提供理想的 AWS 体验。您可以从一系列可用的 Outposts 机架选项中进行选择，以便根据需要订购计算和存储基础设施，您也可以与我们合作，根据您需要的 Amazon Elastic Compute Cloud (EC2)、Amazon Elastic Block Store (EBS) 和 Amazon Simple Storage Service (S3) 容量创建自定义组合。它们都经过了预先验证和测试，可以确保您无需进行额外的工作或现场配置即可快速开始使用。"
    },
    {
        "query":"我能否使用 EBS 支持的 AMI 在我的 Outposts 上创建 EC2 实例？",
        "intention":"知识问答",
        "reply":"能，您可以使用 EBS gp2 卷类型支持的 AMI 启动 EC2 实例。"
    },
    {
        "query":"EBS 快照存储在哪里？",
        "intention":"知识问答",
        "reply":"Outpost 机架上 EBS 卷的快照默认存储在该区域中 Amazon S3 上。如果 Outpost 是通过 Amazon S3 on Outposts 配置，则还可以选择将快照本地存储在 Outpost 上。EBS 快照采用增量方式，这意味着系统只会保存 Outpost 上在最新快照创建之后发生更改的数据块。您可以从存储的快照中随时恢复（补充）Outposts 上的 EBS 卷。有关更多信息，请访问 EBS 快照[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshots-outposts.html)。\n问： 如何使用 EBS Local Snapshots on Outposts 在 Outposts 机架上实施数据驻留？\n您可以在 Outpost 上为 EBS Local Snapshots on Outposts 和 AMI 映像设置资源级的 IAM 策略和权限，以实施数据驻留。每个账户（或 IAM 用户或角色）都可以为单个或多个 Outposts 设置数据驻留实施策略。这将阻止创建或复制本地快照和映像，以及在指定的 Outposts 机架 ARN 之外调用 API/CLI。所有创建、更新和复制操作都会记录在 CloudTrail 审计日志中，因此您可以追踪本地快照已驻留在您的所在地。有关更多信息，请访问 EBS 快照[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshots-outposts.html)。"
    },
    {
        "query":"S3 on Outposts 最适用于哪些使用场景？",
        "intention":"知识问答",
        "reply":"对于有数据驻留要求的客户或者受监管行业中需要安全地存储和处理客户数据（这些数据需要保留在本地或没有 AWS 区域的位置）的客户，[S3 on Outposts](https://aws.amazon.com/cn/s3/outposts/) 是一种理想的选择。此外，客户可以使用 S3 on Outposts 来运行数据密集型工作负载，以便在本地处理并存储数据。如果您的应用程序需要与其他本地系统进行通信或控制本地设备（例如工厂、医院或研究设施），您也可以使用 S3 on Outposts。"
    },
    {
        "query":"如何在我的 Outpost 和 AWS 区域之间建立网络连接？",
        "intention":"知识问答",
        "reply":"您可以选择通过 AWS Direct Connect 私有连接、公共虚拟接口或公共互联网建立到父级 AWS 区域的 Outposts 机架服务链接 VPN 连接。"
    },
    {
        "query":"Application Load Balancer 是否可以在 Outposts 机架上使用？",
        "intention":"知识问答",
        "reply":"可以，Application Load Balancer 可以在所有提供 Outposts 机架的 AWS 区域中的 Outposts 机架上使用，AWS GovCloud（美国）区域除外。"
    },
    {
        "query":"Outposts 机架是否支持有低延迟要求的实时应用程序？",
        "intention":"知识问答",
        "reply":"支持，借助 Amazon RDS on AWS Outposts，您可以在本地运行托管的 Microsoft SQL Server、MySQL 和 PostgreSQL 数据库来处理需要在本地数据和应用程序附近运行的低延迟工作负载。您可以使用相同的 AWS 管理控制台、API 和 CLI 在云和本地环境中管理 RDS 数据库。对于超低延迟应用程序，ElastiCache on Outposts 可以为实时应用程序提供亚毫秒级响应，包括制造业中在工厂车间运行的用于实现自动化操作的工作负载、实时患者诊断和媒体流。"
    },
    {
        "query":"Outposts 机架是否可以用于满足数据驻留要求？",
        "intention":"知识问答",
        "reply":"是。客户数据可以配置为使用 Amazon Elastic Block Store (EBS) 和 Amazon Simple Storage Service (S3) on Outposts 将数据保留在 Outposts 机架上、客户本地位置或指定的主机托管设施中。使用 Outposts 机架及 AWS 服务和工具的 Well-Architected 的应用程序可满足客户经常提出的数据驻留要求。借助 AWS Identity and Access Management (IAM)，您可以控制用户对 AWS 资源的访问。您可以使用 IAM 和细粒度数据控制规则来指定哪些类型的数据必须保留在 Outposts 机架上，而不得复制到 AWS 区域中。默认情况下，S3 on Outposts 会将数据存储在您的 Outposts 上，而且您可以根据具体的驻留要求将部分或全部数据复制到 AWS 区域中。ElastiCache on Outposts 让您能够在 Outposts 机架上安全地处理本地客户数据。部分受限的元数据（例如实例 ID、监控指标、计量记录、标签、存储桶名称等）将流回 AWS 区域。  \n   \n 为了确保满足您独特的数据驻留要求，我们建议您与合规性与安全性团队确认相关信息并密切合作。"
    },
    {
        "query":"AWS Outposts 机架是否可提供资源共享？",
        "intention":"知识问答",
        "reply":"是。AWS Resource Access Manager (RAM) 是一项服务，让您能够与任何 AWS 账户或在 AWS 组织内共享 AWS 资源。有了 RAM 支持，您作为 Outpost 拥有者可以集中创建和管理 Outpost 资源（包括 EC2 实例、EBS 卷、子网和本地网关 (LGW)），并在同一 AWS 组织内的多个 AWS 账户之间共享资源。这可以让其他人在共享的 Outpost 上配置 VPC，启动和运行实例以及创建 EBS 卷。"
    },
    {
        "query":"哪些 EC2 实例在 Outposts 机架上可用？",
        "intention":"知识问答",
        "reply":"对于在 [AWS Nitro 系统](https://aws.amazon.com/cn/ec2/nitro/)上构建的 EC2 实例，AWS Outposts 机架可支持通用型、计算优化型、内存优化型、存储优化型以及通过英特尔至强可扩展处理器进行的 GPU 优化型，基于 Graviton 处理器的 EC2 实例即将推出。"
    },
    {
        "query":"在我的位置部署 Outpost 42U 机架是否有任何先决条件？",
        "intention":"知识问答",
        "reply":"您的站点必须支持基本电力、网络和空间要求才能托管 Outpost。一个 Outpost 机架需要 5-15 kVA 的电源，可以支持 1/10/40/100 Gbps 的上行传输速度及 42U 机架（尺寸 80\" X 24\" X 48\"）的空间。由于 Outposts 机架需要至 AWS 区域的可靠网络连接，您应该计划使用公共互联网连接。客户必须有 Enterprise Support 或 Enterprise On-Ramp Support，才能获得 15 分钟或 30 分钟内全天候远程支持，具体取决于选择的 Support 计划。"
    },
    {
        "query":"目前适用于 AWS 服务的合规性认证是否也适用于 Outposts 机架上的服务？",
        "intention":"知识问答",
        "reply":"AWS Outposts 机架本身符合 HIPAA、PCI、SOC、ISMAP、IRAP 和 FINMA 要求，并得到 ISO、CSA STAR 和 HITRUST 认证，而且我们将在未来几个月内增加更多合规性认证。 您可以在我们的[服务范围页面上查看关于 Outposts 机架上的 AWS 服务](https://aws.amazon.com/cn/compliance/services-in-scope/)的最新认证状况。Outposts 机架上已经获得 PCI 等证书的 AWS 服务，如 RDS 或 Elasticache Redis，也被视作已通过 Outposts 机架认证。由于 AWS Outposts 机架在客户的数据中心运行，根据 AWS 责任共担模型，客户要对 Outpost 的物理安全和访问控制负责，以便获得合规性认证。"
    },
    {
        "query":"AWS Outposts 机架是否与 GxP 兼容？",
        "intention":"知识问答",
        "reply":"是，AWS Outposts 机架与 GxP 兼容。AWS Outposts 机架可将 AWS 服务扩展到通常位于客户地点的 AWS 托管式基础设施。Outposts 机架容量可通过映射到客户本地网络并具有返回 AWS 区域的连接路径的本地网关在本地访问。您可以在[此处](https://aws.amazon.com/cn/compliance/gxp-part-11-annex-11/)了解更多关于将 AWS Cloud（包括 Outposts 机架）用于 GxP 系统的信息。受 GxP 管制的生命科学组织如果使用 AWS 服务，则自行负责设计和验证其 GxP 合规性。"
    },
    {
        "query":"我的数据中心的 Outposts 机架物理安全由谁负责？",
        "intention":"知识问答",
        "reply":"AWS 提供的服务可以加密静态数据以及传输中的数据，还提供其他精细安全性控制和审计机制。此外，客户数据还将由物理 Nitro 安全密钥进行保护。摧毁设备等同于销毁数据。  作为责任共担模式的一部分，客户需要按照[此处](https://docs.aws.amazon.com/outposts/latest/userguide/outposts-requirements.html)公布的程序，证明 Outpost 的物理安全性和访问控制，以及设施、网络和电力的环境要求。 在退回 Outpost 机架硬件之前，拔下 Nitro 安全密钥以确保客户内容经过加密销毁。"
    },
    {
        "query":"AWS 如何维护 AWS Outposts 机架基础设施？",
        "intention":"知识问答",
        "reply":"当您的 Outpost 已安装并且在 AWS 管理控制台中可见时，AWS 将把它作为公共区域的一部分进行监控，并且将自动执行软件升级和补丁。\n如果需要执行物理维护，AWS 将联系您来计划一个访问您的站点的时间。AWS 可以在适当时更换给定模块，但不会在客户场所进行任何主机或网络交换机的维修。"
    },
    {
        "query":"当我的设施的网络连接故障时，会发生什么？",
        "intention":"知识问答",
        "reply":"Outpost 上的 EC2 实例和 EBS 卷将继续正常操作，并且可以通过本地网关从本地进行访问。同样地，ECS Worker 节点等 AWS 服务资源将继续在本地运行。然而，API 可用性将会降低，例如，运行/启动/停止/终止 API 可能无法工作。实例指标和日志将继续在本地缓存几小时，并且将在连接返回时推送到 AWS 区域。但如果连接断开超过几小时可能会导致指标和日志丢失。这时，Outpost 上对 Route 53 解析程序的 DNS 查询（即，AmazonProvidedDNS）也依赖于到 AWS 的网络连接，因此，默认 DNS 解析将停止工作。如果您预计会失去网络连接，我们强烈建议您定期测试工作负载，以确保当 Outpost 断开连接时，它能在此状态下适当运行。对于 S3 on Outposts，如果与 Outpost 的网络连接丢失，您将无法访问您的对象。系统使用区域 AWS Identity and Access Management (IAM) 服务来验证对象存储和检索请求，如果 Outposts 无法连接到主 AWS 区域，您就不能访问您的数据。在连接断开期间，您的数据仍然安全地存储在 Outposts 上，在连接恢复后，身份验证和请求便会恢复。"
    },
    {
        "query":"什么类型的控制面板信息会流回父级 AWS 区域？",
        "intention":"知识问答",
        "reply":"例如，有关实例运行状况、实例活动（启动、停止）和底层管理程序系统的信息可能会发送回父级 AWS 区域。此信息可使 AWS 提供有关实例运行状况和容量的提醒，并将补丁和更新应用至 Outpost。您的团队无需实施自己的工具即可管理这些元素，或者积极推送您的 Outposts 的安全更新和补丁。对于 S3 on Outposts，某些数据管理和遥测数据（例如存储桶名称和指标）可以存储在 AWS 区域中以便进行报告和管理。如果连接断开，该信息无法发送回父级区域。"
    },
    {
        "query":"AWS 如何支持添加容量到现有 Outposts？",
        "intention":"知识问答",
        "reply":"有两种机制可以增加 AWS Outposts 机架的计算和存储能力。首先，您可以通过从 Outposts 机架目录中增加其他 Outposts 机架来提高容量。其次，如果您的现有 Outposts 机架在机架内有可用电源和位置，您可以将配置从“小型”提高到“中型”或“大型”，或者从“中型”提高到“大型”配置。在支持 10KVA – 15KVA 功耗的机架内，最多可以增加两次计算和存储容量。注：1U 和 2U Outposts 服务器不能安装在 42U Outposts 外形规格中。\n请直接联系我们，了解有关 AWS Outposts 的详情。\n立即享受 AWS 免费套餐。\n开始在 AWS 管理控制台中使用 AWS Outposts。"
    },
    {
        "query":"什么是 AWS Auto Scaling？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 是一种新型 AWS 服务，它能够轻松、安全地扩展多种 AWS 资源，帮助您在优化应用程序性能的同时实现基础设施成本节约。该产品简化了扩展体验，让您只需单击几次即可扩展用于支持应用程序的相关资源集合。AWS Auto Scaling 可以帮助您跨支持应用程序的完整基础设施堆栈配置一致、协调的扩展策略。AWS Auto Scaling 将遵循您选定的扩展策略根据需要自动扩展资源，以便您保持性能并仅为实际需要的资源付费。"
    },
    {
        "query":"AWS Auto Scaling 的优势是什么？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 让您能够快速轻松地优化应用程序的性能和成本。"
    },
    {
        "query":"何时应使用 AWS Auto Scaling？",
        "intention":"知识问答",
        "reply":"如果您有应用程序使用一个或多个可扩展资源且存在可变负载，则应该使用 AWS Auto Scaling。在一天中接收可变流量的电子商务 Web 应用程序是一个不错的示例。它采用的是标准三层架构，其中 Elastic Load Balancing 用于分发传入流量，Amazon EC2 用于计算层，DynamoDB 用于数据层。在该示例中，AWS Auto Scaling 将扩展支持应用程序的一个或多个 EC2 Auto Scaling 组和 DynamoDB 表来响应需求曲线。"
    },
    {
        "query":"如何开始使用 AWS Auto Scaling？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 允许您根据资源标签或 AWS CloudFormation 堆栈选择应用程序。只需单击几次，您就可以为应用程序创建扩展计划，该计划定义了应该如何扩展应用程序中的各项资源。对于各项资源，AWS Auto Scaling 会为相应资源类型的最热门指标创建目标跟踪扩展策略，并使该指标保持在基于选定扩展策略的目标值。要为资源指标设定目标值，您可以从三种预定义的扩展建议（优化可用性、优化成本或平衡可用性与成本）中进行选择。或者，如果您愿意，您可以定义自己的目标值。AWS Auto Scaling 还会自动设定资源的最小/最大值。"
    },
    {
        "query":"我可以通过哪些不同的方式来扩展 AWS 资源？",
        "intention":"知识问答",
        "reply":"AWS 客户可以使用多个选项扩展资源。[Amazon EC2 Auto Scaling](https://aws.amazon.com/cn/ec2/autoscaling/) 可帮助您确保拥有适量的 Amazon EC2 实例来处理您的应用程序负载。EC2 Auto Scaling 还可以检测到实例何时运行状况不佳并终止实例，然后启动新实例以替换它。当您使用 EC2 Auto Scaling 时，您应用程序的容错能力和可用性将会更高，您也可以更好地管理成本。\n要扩展 EC2 以外的资源，您可以使用 [Application Auto Scaling API](https://docs.aws.amazon.com/zh_cn/autoscaling/application/APIReference/Welcome.html)，该 API 允许您定义扩展策略以自动扩展 AWS 资源，或者安排一次性或循环的扩展操作。Application Auto Scaling 可以扩展 Amazon ECS 服务、Amazon EC2 Spot 队列、Amazon EMR 集群、Amazon AppStream 2.0 队列、Amazon DynamoDB 表和全局二级索引的预置读写容量、Amazon Aurora 副本以及 Amazon SageMaker 终端节点变体。\n要为跨多项服务的多个资源配置自动扩展，请使用 AWS Auto Scaling 为支持应用程序的资源创建扩展计划。AWS Auto Scaling 还用于为 EC2 资源创建预测性扩展。"
    },
    {
        "query":"何时应使用 AWS Auto Scaling 与Amazon EC2 Auto Scaling？",
        "intention":"知识问答",
        "reply":"您应该使用 AWS Auto Scaling 来管理跨多项服务的多个资源的扩展。借助 AWS Auto Scaling，您可以使用预定义的扩展策略为多个 EC2 Auto Scaling 组或其他资源定义动态扩展策略。与通过单个服务控制台管理每个资源的扩展策略相比，使用 AWS Auto Scaling 为应用程序中的所有可扩展资源配置扩展策略会更快，同时也更加轻松，因为 AWS Auto Scaling 包含可简化扩展策略设置的预定义扩展策略。如果您想为 EC2 资源创建预测性扩展，也应该使用 AWS Auto Scaling。\n如果您只需要扩展 Amazon EC2 Auto Scaling 组，或只想维持 EC2 队列的运行状况，则应该使用 EC2 Auto Scaling。如果您需要创建或配置 Amazon EC2 Auto Scaling 组，或者需要设置计划或分步扩展策略（因为 AWS Auto Scaling 仅支持目标跟踪扩展策略），也应该使用 EC2 Auto Scaling。\n必须在 AWS Auto Scaling 之外创建和配置 EC2 Auto Scaling 组，例如通过 EC2 控制台、Auto Scaling API 或 CloudFormation。AWS Auto Scaling 可帮助您为现有的 EC2 Auto Scaling 组配置动态扩展策略。"
    },
    {
        "query":"何时应使用 AWS Auto Scaling 与Auto Scaling？",
        "intention":"知识问答",
        "reply":"您应该使用 AWS Auto Scaling 来管理跨多项服务的多个资源的扩展。AWS Auto Scaling 支持对多个资源进行统一扩展，并具有预定义的指导，有助于您更轻松、更快地配置扩展。如果您愿意，也可以选择使用单个服务控制台、Auto Scaling API 或 Application Auto Scaling API 来扩展单项 AWS 服务。如果您想要设置分步扩展策略或计划扩展，也应该使用单个控制台或 API，因为 AWS Auto Scaling 仅可创建目标跟踪扩展策略。"
    },
    {
        "query":"什么是预测式扩展？",
        "intention":"知识问答",
        "reply":"预测式扩展是 AWS Auto Scaling 的一项功能，它可以查看历史流量模式并预测未来的流量模式，以便在适当的未来时间里安排更改 EC2 实例的数量。预测式扩展使用机器学习模型来预测每日和每周的模式。\n通过预测式扩展增强的 Auto Scaling 可提供更快、更简单、更准确的容量预置，从而降低成本并提高应用程序响应速度。通过预测流量变化，预测式扩展在更改流量之前会预置 EC2 实例，提高 Auto Scaling 速度和准确性。"
    },
    {
        "query":"预测式扩展可以与哪些服务结合使用？",
        "intention":"知识问答",
        "reply":"此时，预测式扩展只能为 EC2 实例生成计划。"
    },
    {
        "query":"如何将预测式扩展与目标跟踪结合使用？",
        "intention":"知识问答",
        "reply":"预测式扩展与目标跟踪结合使用，可使您的 EC2 容量更改更快地响应您的传入应用程序流量。尽管预测式扩展会根据预测的流量为您的应用程序设置最小容量，但目标跟踪会根据当前的实际流量更改实际容量。目标跟踪用于跟踪不同流量条件下所需的容量利用率水平，并解决不可预测的流量峰值和其他波动。用户将预测式扩展和目标跟踪一同进行配置，以生成扩展计划。"
    },
    {
        "query":"什么是扩展计划？",
        "intention":"知识问答",
        "reply":"扩展计划是多个 AWS 资源的扩展指令集合。您可以通过首先在 AWS Auto Scaling 中选择应用程序底层的所有 EC2 资源来配置扩展计划。然后，选择要跟踪的资源利用率指标，例如 CPU 利用率，并设置要跟踪的值，例如 50%。最后，选择代表输入流量的 CloudWatch 指标。如果尚未设置，则可能需要进行设置。\n资源利用率指标和传入流量指标是扩展计划的重要参数。预测式扩展使用传入流量指标生成流量预测。根据这些预测，预测式扩展会安排未来的扩展操作以配置最小容量。动态扩展使用资源利用率指标及其目标值，随流量的变化动态更改应用程序的 EC2 容量。"
    },
    {
        "query":"是否可以在不使用预测式扩展的情况下配置扩展计划？",
        "intention":"知识问答",
        "reply":"是的，您可以仅使用动态扩展并选择退出预测式扩展来配置扩展计划。反之，您也可以在未配置动态扩展的情况下启用预测式扩展。"
    },
    {
        "query":"预测式扩展需要多少历史数据才能生成扩展计划？",
        "intention":"知识问答",
        "reply":"预测式扩展最多需要两周的历史数据，但也可以只使用一天的数据量生成预测式扩展计划。"
    },
    {
        "query":"预测式扩展可以预测未来多久的流量？",
        "intention":"知识问答",
        "reply":"预测式扩展每隔 24 小时预测未来 48 小时的流量，并针对这 48 小时安排容量变化。"
    },
    {
        "query":"我是否可以配置预测式扩展，以在实际流量高峰到来之前预置实例？",
        "intention":"知识问答",
        "reply":"是的，您可以选择配置缓冲时间，以便在预测的流量变化之前的某个时间预置实例。这对于一些应用程序来说非常有用，因为这些应用程序的 EC2 实例在其准备好为应用程序流量服务之前需要一些“预热”时间。"
    },
    {
        "query":"AWS Auto Scaling 与各项服务的扩展功能有何不同？",
        "intention":"知识问答",
        "reply":"下表比较了 AWS 的各个扩展选项。\n|  | AWS Auto Scaling | Amazon EC2 Auto Scaling | Auto Scaling Auto Scaling |\n| --- | --- | --- | --- |\n| 可扩展的资源 | EC2 Auto Scaling 组 EC2 Spot 队列 ECS 服务 DynamoDB 表和 GSI 的预置容量 Aurora 副本 | EC2 Auto Scaling 组 | EC2 Spot 队列 ECS 服务 DynamoDB 表和 GSI 的预置容量 Aurora 副本 EMR 集群 Appstream 2.0 队列 Sagemaker 终端节点变体 |\n| 扩展方式 | 使用统一界面的应用程序级扩展 | 一次扩展一个 Auto Scaling 组 | 一次扩展一个资源 |\n| 预测式扩展 | 是（仅限 EC2） | 否 | 否 |\n| 自动发现应用程序中的 所有可扩展资源 | 是 | 否 | 否 |\n| 能够使用统一界面扩展跨多项服务的多个资源 | 是 | 否 | 否 |\n| 设置扩展策略的 指导和建议 | 是 | 否 | 否 |\n| 能够创建和设置 Auto Scaling 组 | 否 | 是 | 不适用 |\n| 能够仅将 Auto Scaling 用于 EC2 队列管理   | 否 | 是 | 不适用 |\n| 设置智能的自我优化式 目标跟踪扩展策略\\* | 是 | 是 | 是 |\n| 设置计划的扩展操作 | 否 | 是 | 是 |\n| 设置分步扩展策略 | 否 | 是 | 是 |\n| 为每个资源配置具有不同指标和阈值的扩展策略 | 否 | 是 | 是 |\n\\*与分步扩展策略相比，建议设置这种扩展策略"
    },
    {
        "query":"我可以使用 AWS Auto Scaling 扩展哪些资源？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Auto Scaling 通过单个统一界面为应用程序中的以下资源设置扩展："
    },
    {
        "query":"AWS Auto Scaling 如何提供扩展建议？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 基于最热门的扩展指标和用于 Auto Scaling 的阈值来提供扩展建议。它还提供关于资源最小和最大规模的建议，以推荐用于扩展的安全防护措施。这样一来，您可以快速入门，然后随着时间推移优化扩展策略。"
    },
    {
        "query":"如何在 AWS Auto Scaling 中选择应用程序堆栈？",
        "intention":"知识问答",
        "reply":"您可以选择 AWS CloudFormation 堆栈或根据共同的资源标签选择资源。请注意，目前无法使用标签发现 ECS 服务。"
    },
    {
        "query":"AWS Auto Scaling 如何发现可以扩展的资源？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 将扫描您选定的 AWS CloudFormation 堆栈或带指定标签的资源来识别可扩展的受支持 AWS 资源类型。请注意，目前无法使用标签发现 ECS 服务。"
    },
    {
        "query":"AWS Auto Scaling 可以在哪些区域使用？",
        "intention":"知识问答",
        "reply":"AWS Auto Scaling 现已在以下地区推出：亚太地区（孟买）、亚太地区（东京）、亚太地区（首尔）、亚太地区（悉尼）、加拿大（中部）、美国西部（加利福尼亚北部）、欧洲（伦敦）、欧洲（法兰克福）、欧洲（巴黎）、欧洲（米兰）、美国东部（弗吉尼亚）、美国东部（俄亥俄）、美国西部（俄勒冈）、欧洲（爱尔兰）和亚太地区（新加坡）。"
    },
    {
        "query":"什么是 Amazon EMR？",
        "intention":"知识问答",
        "reply":"Amazon EMR 是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。借助 EMR，您可以用[不到传统本地解决方案一半的成本](https://pages.awscloud.com/Gated-IDC-The-Economic-Benefits-of-Migrating-Apache-Spark-and-Hadoop-to-Amazon-EMR.html)运行 PB 级分析，并且其速度比标准 Apache Spark [快 1.7 倍以上](https://aws.amazon.com/blogs/big-data/amazon-emr-introduces-emr-runtime-for-apache-spark/)。"
    },
    {
        "query":"为什么应该使用 Amazon EMR？",
        "intention":"知识问答",
        "reply":"通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。"
    },
    {
        "query":"如何部署和管理 Amazon EMR？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon EC2、Amazon Elastic Kubernetes Service (EKS) 或本地部署 AWS Outposts 将工作负载部署到 EMR。您可以使用 EMR 控制台、API、开发工具包或 CLI 运行和管理工作负载，并使用 Amazon Managed Workflow for Apache Airflow (MWAA) 或 AWS Step Functions 进行编排。对于交互式体验，您可以使用 EMR Studio 或 SageMaker Studio。"
    },
    {
        "query":"可以在哪里找到示例代码？",
        "intention":"知识问答",
        "reply":"有关示例代码，请参阅这些[文章和教程](http://aws.amazon.com/articles/Elastic-MapReduce)。如果您使用 EMR Studio，则可以使用一组[笔记本示例](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-configure-workspace.html#emr-studio-notebook-examples)探索这些功能。"
    },
    {
        "query":"如何开发数据处理应用程序？",
        "intention":"知识问答",
        "reply":"您可以在 [Amazon EMR Studio](https://aws.amazon.com/emr/features/studio/) 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在桌面上开发数据处理作业，例如，使用 Eclipse、Spyder、PyCharm 或 RStudio，并在 Amazon EMR 上运行。此外，您可以在启动新集群时在软件配置中选择 [JupyterHub](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-jupyterhub.html) 或 [Zeppelin](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-zeppelin.html)，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。"
    },
    {
        "query":"相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？",
        "intention":"知识问答",
        "reply":"命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。"
    },
    {
        "query":"是否可向已在运行的群集添加步骤？",
        "intention":"知识问答",
        "reply":"可以。任务运行后，您可以通过 AddJobFlowSteps API 选择性地添加更多步骤。AddJobFlowSteps API 将向当前的步骤序列结尾添加新的步骤。您可以使用此 API 在集群中执行条件逻辑或进行调试。"
    },
    {
        "query":"当集群完成时，我是否会收到通知？",
        "intention":"知识问答",
        "reply":"您可以注册 Amazon SNS，让集群在完成后向您发布 SNS 主题。您还可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。"
    },
    {
        "query":"完成步骤后可以终止集群吗？",
        "intention":"知识问答",
        "reply":"可以。可以通过启动自动终止标志，在完成所有步骤后自动终止集群。"
    },
    {
        "query":"Amazon EMR 支持哪些操作系统版本？",
        "intention":"知识问答",
        "reply":"Amazon EMR 5.30.0 及更高版本，以及 Amazon EMR 6.x 系列基于 Amazon Linux 2。您也可以指定一个基于 Amazon Linux 2 创建的自定义 AMI。这让您可以为几乎任何应用程序执行复杂的预配置。有关更多信息，请参阅[使用自定义 AMI](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-custom-ami.html)。"
    },
    {
        "query":"Amazon EMR 是否支持第三方软件包？",
        "intention":"知识问答",
        "reply":"是。 您可以使用引导操作在集群中安装第三方软件包。此外，也可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。EMR 6.x 支持 Hadoop 3，它允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。要了解更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-docker.html)。"
    },
    {
        "query":"我可以使用哪些工具进行调试？",
        "intention":"知识问答",
        "reply":"您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 [Amazon EMR studio](https://aws.amazon.com/emr/features/studio/)，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以[使用 SSH 连接主节点](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-connect-master-node-ssh.html)，并通过这些 [Web 界面](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-web-interfaces.html)查看集群实例。有关更多信息，请参阅[我们的文档](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-troubleshoot-tools.html)。"
    },
    {
        "query":"什么是 EMR Studio？",
        "intention":"知识问答",
        "reply":"EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的[适用于 Apache Spark 的 Amazon EMR 运行时](https://aws.amazon.com/about-aws/whats-new/2019/11/announcing-emr-runtime-for-apache-spark/)，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。"
    },
    {
        "query":"EMR Studio 有什么作用？",
        "intention":"知识问答",
        "reply":"借助 EMR Studio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS 控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的[适用于 Apache Spark 的 Amazon EMR 运行时](https://aws.amazon.com/about-aws/whats-new/2019/11/announcing-emr-runtime-for-apache-spark/)，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。"
    },
    {
        "query":"EMR Studio 与 EMR Notebooks 有何不同？",
        "intention":"知识问答",
        "reply":"有五个主要区别。"
    },
    {
        "query":"EMR Studio 与 SageMaker Studio 有何不同？",
        "intention":"知识问答",
        "reply":"您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。"
    },
    {
        "query":"我如何开始使用 EMR Studio？",
        "intention":"知识问答",
        "reply":"您的管理员必须首先设置 EMR Studio。从管理员那里收到 Amazon EMR Studio 的唯一登录 URL 后，您可以使用企业凭证直接登录到 Studio。"
    },
    {
        "query":"我是否需要登录到 AWS 管理控制台才能使用 EMR Studio？",
        "intention":"知识问答",
        "reply":"不需要。管理员设置 EMR Studio 并提供 Studio 访问 URL 后，您的团队可以使用企业凭证登录。无需登录到 AWS 管理控制台。在 EMR Studio 中，您的团队可以执行任务并访问由管理员配置的资源。"
    },
    {
        "query":"EMR Studio 中的单点登录体验支持哪些身份提供商？",
        "intention":"知识问答",
        "reply":"AWS IAM Identity Center（AWS SSO 的后继者）是 EMR Studio 的单点登录服务提供程序。AWS IAM 支持的身份提供商列表可在我们的[文档](https://docs.aws.amazon.com/singlesignon/latest/userguide/supported-idps.html)中找到。"
    },
    {
        "query":"什么是 EMR Studio 中的工作区？",
        "intention":"知识问答",
        "reply":"Workspace 可帮助您组织 Jupyter Notebooks。工作区中的所有笔记本都保存到同一个 Amazon S3 位置，并在同一集群上运行。您还可以将代码存储库（如 GitHub 存储库）链接到工作区中的所有笔记本。您可以在将工作区附加到集群之前创建和配置工作区，但您应该在运行笔记本之前先连接到集群。"
    },
    {
        "query":"在 EMR Studio 中，是否可以在没有集群的情况下创建工作区或打开工作区？",
        "intention":"知识问答",
        "reply":"是的，您可以创建或打开工作区而无需将其附加到集群。仅在需要执行时，才应该将它们连接到集群。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的[适用于 Apache Spark 的 Amazon EMR 运行时](https://aws.amazon.com/about-aws/whats-new/2019/11/announcing-emr-runtime-for-apache-spark/)，获得分布式数据处理带来的优势。"
    },
    {
        "query":"我能否安装定制库以在我的笔记本代码内使用？",
        "intention":"知识问答",
        "reply":"所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅[文档](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-install-libraries-and-kernels.html)。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的[创建引导操作以安装其他软件](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-bootstrap.html)和[使用自定义 AMI](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-custom-ami.html)。"
    },
    {
        "query":"笔记本保存在哪里？",
        "intention":"知识问答",
        "reply":"工作区和工作区中的笔记本文件自动定期保存到您在创建该工作区时指定的 Amazon S3 位置中的 ipynb 文件。该笔记本文件的名称与您在 Amzon EMR Studio 中的笔记本相同。"
    },
    {
        "query":"如何对我的笔记本应用版本控制？ 能否使用像 GitHub 这样的存储库？",
        "intention":"知识问答",
        "reply":"您可以在版本受控的环境中将 [基于 Git 的存储库与 Amazon EMR Studio Notebooks](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-studio-git-repo.html) 相关联，以保存您的笔记本。"
    },
    {
        "query":"在 EMR Studio 中，我可以在哪些计算资源上运行笔记本？",
        "intention":"知识问答",
        "reply":"使用 EMR Studio，您可以在运行于 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 上或者运行于 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。可以将笔记本附加到现有或新的集群上。您可以在 EMR Studio 中以两种方式创建 EMR 集群：使用预配置的集群模板通过 AWS Service Catalog 创建集群；通过指定集群名称、实例数和实例类型创建集群。"
    },
    {
        "query":"我是否可以在 EMR Studio 中将工作区重新附加到不同的计算资源？",
        "intention":"知识问答",
        "reply":"是的，您可以打开您的工作区，选择左侧的 *EMR 集群*图标，按下*分离*按钮，然后从*选择集群*下拉列表中选择集群，并按下*附加*按钮。"
    },
    {
        "query":"在 EMR Studio 中，我在哪里可以找到所有工作区？",
        "intention":"知识问答",
        "reply":"在 EMR Studio 中，您可以选择左侧的 *WorkSpace* 选项卡，查看您和其他用户在同一个 AWS 账户中创建的所有工作区。"
    },
    {
        "query":"使用 EMR Studio 需要哪些 IAM 策略？",
        "intention":"知识问答",
        "reply":"每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的[策略和权限](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_session)。"
    },
    {
        "query":"在 EMR Studio 中，对附加我工作区的 EMR 集群是否有任何限制？",
        "intention":"知识问答",
        "reply":"可以。目前不支持高可用性（多主控）集群、Kerberos 化集群和 AWS Lake Formation 集群。"
    },
    {
        "query":"EMR Notebooks 有什么作用？",
        "intention":"知识问答",
        "reply":"您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。"
    },
    {
        "query":"我如何开始使用 EMR Notebooks？",
        "intention":"知识问答",
        "reply":"要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。"
    },
    {
        "query":"如何将我的数据导入 Amazon S3？",
        "intention":"知识问答",
        "reply":"Amazon EMR 提供了几种将数据导入集群中的方法。最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。有关更多详细信息，请参阅[文档](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-get-data-in.html)。或者，如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种[云数据迁移](https://aws.amazon.com/cn/cloud-data-migration/)服务。"
    },
    {
        "query":"如何获得已终止集群的日志？",
        "intention":"知识问答",
        "reply":"Hadoop 系统日志及用户日志存放在您在创建集群时指定的 Amazon S3 存储段中。[持久性应用程序 UI](https://docs.aws.amazon.com/emr/latest/ManagementGuide/app-history-spark-UI.html) 在集群外运行，Spark 历史记录服务器、Tez UI 和 YARN 时间线服务器日志在应用程序终止后 30 天内可用。"
    },
    {
        "query":"您是否会压缩日志？",
        "intention":"知识问答",
        "reply":"不会，目前，Amazon EMR 在将日志迁移到 Amazon S3 时，不会压缩日志。"
    },
    {
        "query":"是否可从 Internet 或 Amazon S3 以外的其他位置加载数据？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS Direct Connect 建立到 AWS 的私有专用网络连接。如果您有大量数据，可以使用 AWS Import/Export。有关更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-get-data-in.html)。"
    },
    {
        "query":"Amazon EMR 是否可估算处理我的输入数据需要多长时间？",
        "intention":"知识问答",
        "reply":"由于每个群集和输入数据不同，我们无法估算您的任务持续时间。"
    },
    {
        "query":"Amazon EMR 集群的账单周期如何计算？",
        "intention":"知识问答",
        "reply":"当该集群准备好执行步骤时，Amazon EMR 计费开始。当您请求关闭该集群时，Amazon EMR 计费结束。有关 Amazon EC2 开始和结束计费的详细信息，请参阅 [Amazon EC2 计费常见问题](https://aws.amazon.com/cn/ec2/faqs/#Billing)。"
    },
    {
        "query":"在哪里可以跟踪我的 Amazon EMR、Amazon EC2 和 Amazon S3 使用情况？",
        "intention":"知识问答",
        "reply":"您可以在[账单与收费管理控制台](https://console.aws.amazon.com/billing/home)跟踪您的使用情况。"
    },
    {
        "query":"如何计算控制台中所显示的标准实例小时数？",
        "intention":"知识问答",
        "reply":"在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/apply_ri.html)，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n这只是大致时间，不应用作账单。请参阅[账单与收费管理控制台](https://console.aws.amazon.com/billing/home#/)，了解可计费的 Amazon EMR 使用量。"
    },
    {
        "query":"Amazon EMR 是否支持 Amazon EC2 按需实例、Spot 实例和预留实例？",
        "intention":"知识问答",
        "reply":"是的。Amazon EMR 可无缝支持按需实例、Spot 实例和预留实例。[单击此处](https://aws.amazon.com/cn/ec2/faqs/)详细了解 Amazon EC2 预留实例。[单击此处](https://aws.amazon.com/cn/ec2/spotathon/)详细了解 Amazon EC2 Spot 实例。[单击此处](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-capacity-reservations.html)详细了解 Amazon EC2 容量预留。"
    },
    {
        "query":"在集群执行过程中，如何防止其他用户查看我的数据？",
        "intention":"知识问答",
        "reply":"Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。[单击此处](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/using-network-security.html)详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 [Amazon EMR 阻止公有访问](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-block-public-access.html)。"
    },
    {
        "query":"我的数据的安全性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。"
    },
    {
        "query":"我能否获得我的账户上所有的 EMR API 调用历史记录以用于安全或合规性审计？",
        "intention":"知识问答",
        "reply":"是的。AWS CloudTrail 是一项 web 服务，为您的帐户记录 AWS API 调用并向您交付日志文件。由 CloudTrail 生成的 AWS API 调用历史记录可用于安全分析、资源变更追踪以及合规性审计。在 [AWS CloudTrail 详细信息页面](https://aws.amazon.com/cn/cloudtrail/)了解更多有关 CloudTrail 的信息，或者通过 [CloudTrail 的 AWS 管理控制台](https://console.aws.amazon.com/cloudtrail)将它打开。"
    },
    {
        "query":"如何控制 EMR 用户在 Amazon S3 中可以访问的内容？",
        "intention":"知识问答",
        "reply":"默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 [EC2 实例配置文件](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-iam-role-for-ec2.html)。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。"
    },
    {
        "query":"Amazon EMR 如何运用可用区？",
        "intention":"知识问答",
        "reply":"Amazon EMR 可启动同一 Amazon EC2 可用区中给定集群的所有节点。在同一可用区内运行集群可提高任务流的性能。默认情况下，Amazon EMR 选择运行集群的可用资源最多的可用区域。不过，如果需要，您可以指定其他可用区。您还可以选择为价格最低的按需实例优化分配、优化 Spot 容量或使用按需容量预留。"
    },
    {
        "query":"在哪些区域可以使用 Amazon EMR？",
        "intention":"知识问答",
        "reply":"要了解支持 Amazon EMR 的 AWS 区域列表，请访问所有 AWS 全球基础设施的 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"AWS Local Zones 是否支持 Amazon EMR？",
        "intention":"知识问答",
        "reply":"EMR 支持在洛杉矶 AWS 本地扩展区启动集群。您可以在美国西部（俄勒冈）区域使用 EMR，以在与洛杉矶 AWS 本地扩展区相关的子网中启动集群。"
    },
    {
        "query":"我应选择哪个地区来运行群集？",
        "intention":"知识问答",
        "reply":"创建群集时，通常应选择您的数据所在的区域。"
    },
    {
        "query":"在美国地区运行的集群中是否可使用欧洲数据（反之亦然）？",
        "intention":"知识问答",
        "reply":"是的，您可以。如果您在不同的地区之间传输数据，将对您收取带宽费用。有关带宽定价信息，请访问 [EC2 详细信息页面](https://aws.amazon.com/cn/ec2/)上的定价部分。"
    },
    {
        "query":"AWS GovCloud（美国）地区有何不同之处？",
        "intention":"知识问答",
        "reply":"[AWS GovCloud（美国）](https://aws.amazon.com/cn/govcloud-us/)区域专为美国政府机构和客户而设计。它遵循 US ITAR 要求。在 GovCloud，EMR 不支持 Spot 实例或启用调试功能。EMR 管理控制台在 GovCloud 中尚不可用。\n[Amazon EC2 上的 Amazon EMR](https://aws.amazon.com/cn/emr/faqs#Amazon_EMR_on_Amazon_EC2) | [Amazon EKS 上的 Amazon EMR](https://aws.amazon.com/cn/emr/faqs#Amazon_EMR_on_Amazon_EKS) | [AWS Outposts 上的 Amazon EMR](https://aws.amazon.com/cn/emr/faqs#Amazon_EMR_on_AWS_Outposts)\n[启动](https://aws.amazon.com/cn/emr/faqs#Launching_a_cluster) | [管理](https://aws.amazon.com/cn/emr/faqs#Managing_a_cluster) | [标记](https://aws.amazon.com/cn/emr/faqs#Tagging_a_cluster)"
    },
    {
        "query":"Amazon EMR 如何使用 Amazon EC2 和 Amazon S3？",
        "intention":"知识问答",
        "reply":"可以将您的输入数据和数据处理应用程序上传到 Amazon S3。然后，Amazon EMR 将按您指定启动一定数量的 Amazon EC2 实例。该服务开始执行集群，同时使用 S3 URI 方案将输入数据从 Amazon S3 推入启动的 Amazon EC2 实例。一旦集群完成后，Amazon EMR 即可将输出数据传输到 Amazon S3，您在此可以取回数据或将其用作其他集群的输入数据。"
    },
    {
        "query":"在 Amazon EMR 中如何进行计算？",
        "intention":"知识问答",
        "reply":"Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。"
    },
    {
        "query":"Amazon EMR 支持哪些 Amazon EC2 实例类型？",
        "intention":"知识问答",
        "reply":"有关最新可用实例类型和各区域定价的详细信息，请参阅 [EMR 定价页面](https://aws.amazon.com/cn/emr/pricing/)。"
    },
    {
        "query":"运行集群需要多长时间？",
        "intention":"知识问答",
        "reply":"运行群集所需的时间取决于若干因素，包括群集的类型、输入数据的数量以及您为群集选择的 Amazon EC2 实例数量和类型。"
    },
    {
        "query":"如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？",
        "intention":"知识问答",
        "reply":"可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。"
    },
    {
        "query":"如果集群中的其他节点出现故障，Amazon EMR 是否可以从其恢复？",
        "intention":"知识问答",
        "reply":"能。Amazon EMR 对于节点故障具有容错功能，当节点出现故障时将继续执行任务。Amazon EMR 还将在核心节点出现故障时预置新节点。但如果群集内的所有节点全部丢失，Amazon EMR 不会替换任何节点。"
    },
    {
        "query":"是否可以 SSH 到我的群集节点？",
        "intention":"知识问答",
        "reply":"能。您可以 SSH 到自己的群集节点，并从该位置直接执行 Hadoop 命令。如果您需要 SSH 到特定节点，则必须首先 SSH 到主节点，然后再 SSH 到所需节点。"
    },
    {
        "query":"什么是 Amazon EMR 引导操作？",
        "intention":"知识问答",
        "reply":"引导操作是 Amazon EMR 中的一项功能，为用户提供一种在执行群集前运行自定义设置的方式。运行群集前，可使用引导操作来安装软件或配置实例。有关引导操作的更多信息，请阅读 EMR 的[开发人员指南](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-plan-bootstrap.html)。"
    },
    {
        "query":"如何使用引导操作？",
        "intention":"知识问答",
        "reply":"您可以群集实例中已安装的任何语言编写 Bootstrap Action 脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。可使用一些预定义的引导操作。完成编写脚本后，您需要将其上传到 Amazon S3 并在启动集群时引用其位置。请参阅[开发人员指南](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/)，了解有关如何使用引导操作的详细信息。"
    },
    {
        "query":"如何为集群配置 Hadoop 设置？",
        "intention":"知识问答",
        "reply":"EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的[配置内存密集型引导操作](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/Bootstrap.html#PredefinedBootstrapActions_MemoryIntensive)，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的[配置 Hadoop 引导操作](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/Bootstrap.html#PredefinedBootstrapActions_ConfigureHadoop)，了解相关使用说明。"
    },
    {
        "query":"是否可以修改正在运行的集群中的节点数？",
        "intention":"知识问答",
        "reply":"能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的[调整运行的集群](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/ResizeJobFlow.html)部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。"
    },
    {
        "query":"我何时会希望使用核心节点与任务节点？",
        "intention":"知识问答",
        "reply":"由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。由于任务节点可以添加或删除且不含 HDFS，所以它们非常适合仅临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。"
    },
    {
        "query":"为什么我会希望修改正在运行的集群中的节点数？",
        "intention":"知识问答",
        "reply":"在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。"
    },
    {
        "query":"是否可以自动修改集群步骤之间的节点数？",
        "intention":"知识问答",
        "reply":"能。您可以在工作流中包含预定义的步骤，以自动在已知具有不同容量需求的步骤之间调整群集大小。由于所有步骤都保证按顺序运行，这让您能够设置执行给定集群步骤的节点数。"
    },
    {
        "query":"如何允许其他 IAM 用户访问我的群集？",
        "intention":"知识问答",
        "reply":"要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n有关更多信息，请参阅 EMR 开发人员指南中的[配置用户权限](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/environmentconfig_iam.html)部分。"
    },
    {
        "query":"可以标记哪些 Amazon EMR 资源？",
        "intention":"知识问答",
        "reply":"可以将标记添加到活跃的 Amazon EMR 群集。Amazon EMR 群集由 Amazon EC2 实例组成，添加到 Amazon EMR 群集的标记将传播到该群集的每个活跃 Amazon EC2 实例中。无法在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中添加、编辑或删除标记。"
    },
    {
        "query":"Amazon EMR 标记是否支持 IAM 用户的资源权限？",
        "intention":"知识问答",
        "reply":"不支持，Amazon EMR 不支持按标记确定基于资源的许可。但需要注意的是，传播到 EC2 实例的标记与正常的 Amazon EC2 标记的行为方式相同，这一点非常重要。因此，从 Amazon EMR 传播的标记如果与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。"
    },
    {
        "query":"可以向资源添加多少个标记？",
        "intention":"知识问答",
        "reply":"在 Amazon EMR 群集上最多可以添加十个标记。"
    },
    {
        "query":"我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR 群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？",
        "intention":"知识问答",
        "reply":"是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。"
    },
    {
        "query":"如何在我的账单明细中显示我的标记来划分成本？",
        "intention":"知识问答",
        "reply":"在[此处](https://console.aws.amazon.com/billing/home?#/preferences/tags)选择要在 AWS 账单报告中使用的标记。然后，为了查看您组合资源的成本，您可以根据拥有相同标记键值的资源组织账单信息。"
    },
    {
        "query":"如何分辨哪些 Amazon EC2 实例属于某个 Amazon EMR 群集？",
        "intention":"知识问答",
        "reply":"与 Amazon EMR 群集关联的 Amazon EC2 实例将有两个系统标记："
    },
    {
        "query":"可以直接在 Amazon EC2 实例上编辑标记吗？",
        "intention":"知识问答",
        "reply":"可以，您可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接添加或删除标记。但是，我们不建议这样做，因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。"
    },
    {
        "query":"什么是 Amazon EMR Serverless？",
        "intention":"知识问答",
        "reply":"Amazon EMR Serverless 是 Amazon EMR 中的一个新部署选项，它让您可以运行 Apache Spark 和 Apache Hive 之类的大数据框架，而无需配置、管理和扩展集群。"
    },
    {
        "query":"谁可以使用 EMR Serverless？",
        "intention":"知识问答",
        "reply":"数据工程师、分析师和科学家可以使用 EMR Serverless，以利用 Apache Spark 和 Apache Hive 之类的开源框架构建应用程序。他们可以使用这些框架来转换数据、运行交互式 SQL 查询和机器学习工作负载。\n问：如何开始使用 EMR Serverless？\n您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 [AWS 管理控制台](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fus-east-1.console.aws.amazon.com%2Fconsole%2Fhome%3FhashArgs%3D%2523%26isauthcode%3Dtrue%26nc2%3Dh_ct%26region%3Dus-east-1%26skipRegion%3Dtrue%26src%3Dheader-signin%26state%3DhashArgsFromTB_us-east-1_9b65e1f33ddc422e&client_id=arn%3Aaws%3Asignin%3A%3A%3Aconsole%2Fcanvas&forceMobileApp=0&code_challenge=TU8eW2jlBxLceS5G5ZljvmOVQCs5CIBQ8NlFAoTpunU&code_challenge_method=SHA-256)中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照[入门](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/getting-started.html)指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的[与您的应用程序交互](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/applications-cli.html)，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 [GitHub 存储库](https://github.com/aws-samples/emr-serverless-samples)中找到 EMR Serverless 示例和示例代码。"
    },
    {
        "query":"EMR Serverless 支持哪些开源框架？",
        "intention":"知识问答",
        "reply":"EMR Serverless 当前支持 Apache Spark 和 Apache Hive 引擎。如果您希望支持其他框架，例如 Apache Presto 或 Apache Flink，请发送请求至 [emr-feedback@amazon.com](mailto:emr-feedback@amazon.com.)。"
    },
    {
        "query":"EMR Serverless 在哪些区域中可用？",
        "intention":"知识问答",
        "reply":"EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。"
    },
    {
        "query":"Amazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？",
        "intention":"知识问答",
        "reply":"Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。"
    },
    {
        "query":"EMR Serverless 和 EC2 上的 Amazon EMR 在功能上有哪些区别？",
        "intention":"知识问答",
        "reply":"|  |  |  |  |\n| --- | --- | --- | --- |\n|  功能 |  EMR Serverless |  EC2 上的 Amazon EMR  | EKS 上的 Amazon EMR  |\n|  支持最新的开源版本 |  Y |  Y | Y |\n| 对可用区故障的恢复能力 |  Y |  N | Y |\n| 根据需要自动扩展和缩减资源 |  Y |  Y | Y |\n| 静态数据加密 |  Y |  Y | Y |\n|  支持的开源框架 |  Spark 和 Hive |  [多个](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html) | Spark |\n|  支持使用 AWS Lake Formation 进行细粒度授权 |  N |  Y | N |\n| 支持 Apache Hudi 和 Apache Iceberg | Y | Y | Y |\n| 与 Apache Ranger 集成以实现表级和列级权限控制 |  N |  Y | N |\n| 自定义操作系统映像 |  Y |  Y | Y |\n| 自定义安装的开源框架 | Y | Y | Y |\n| 自定义和加载其他库和依赖项 | Y | Y | Y |\n| 作为机器学习（ML）工作流程的一部分，从 SageMaker Studio 运行工作负载 | N |  Y | N |\n| 连接到自托管式 Jupyter Notebook | N | Y | Y |\n| 使用 Apache Airflow 和 Amazon Managed Workflows for Apache Airflow（MWAA）构建和编排管道 |  Y |  Y | Y |\n| 使用 AWS Step Functions 构建和编排管道 | Y |  Y | Y |\n功能\nEMR Serverless\nEC2 上的 Amazon EMR\nEKS 上的 Amazon EMR\n支持最新的开源版本\nY\nY\nY\n对可用区故障的恢复能力\nY\nN\nY\n根据需要自动扩展和缩减资源\nY\nY\nY\n静态数据加密\nY\nY\nY\n支持的开源框架\nSpark 和 Hive\n[多个](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html)\nSpark\n支持使用 AWS Lake Formation 进行细粒度授权\nN\nY\nN\n支持 Apache Hudi 和 Apache Iceberg\nY\nY\nY\n与 Apache Ranger 集成以实现表级和列级权限控制\nN\nY\nN\n自定义操作系统映像\nY\nY\nY\n自定义安装的开源框架\nY\nY\nY\n自定义和加载其他库和依赖项\nY\nY\nY\n作为机器学习（ML）工作流程的一部分，从 SageMaker Studio 运行工作负载\nN\nY\nN\n连接到自托管式 Jupyter Notebook\nN\nY\nY\n使用 Apache Airflow 和 Amazon Managed Workflows for Apache Airflow（MWAA）构建和编排管道\nY\nY\nY\n使用 AWS Step Functions 构建和编排管道\nY\nY\nY"
    },
    {
        "query":"EMR Serverless 支持哪些 EMR 版本？",
        "intention":"知识问答",
        "reply":"EMR Serverless 支持 EMR 版本标签 6.6 及更高版本。借助 EMR Serverless，您可以获得与在其他 EMR 部署选项中相同的性能优化 EMR 运行时，它与标准开源框架 100% API 兼容。"
    },
    {
        "query":"什么是应用程序以及如何创建？",
        "intention":"知识问答",
        "reply":"借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。"
    },
    {
        "query":"什么是工作线程？",
        "intention":"知识问答",
        "reply":"EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。"
    },
    {
        "query":"我可以指定我的作业可使用的工作线程最小和最大数量吗？",
        "intention":"知识问答",
        "reply":"使用 EMR Serverless，您可以指定并发工作线程的最小和最大数量以及工作线程的 vCPU 和内存配置。您还可以设置应用程序资源的最大容量限制以控制成本。"
    },
    {
        "query":"我应在何时创建多个应用程序？",
        "intention":"知识问答",
        "reply":"在执行以下任一操作时考虑创建多个应用程序："
    },
    {
        "query":"在 EMR Serverless 应用程序创建后能否更改其默认属性？",
        "intention":"知识问答",
        "reply":"是的，您可以使用 EMR Studio 或 update-application API/CLI 调用修改应用程序属性，例如初始容量、最大容量限制和网络配置。"
    },
    {
        "query":"我应何时创建具有预初始化工作线程池的应用程序？",
        "intention":"知识问答",
        "reply":"没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。"
    },
    {
        "query":"如何在 EMR Serverless 上提交和管理作业？",
        "intention":"知识问答",
        "reply":"您可以使用 EMR Studio、开发工具包/CLI 或我们的 Apache Airflow 连接器提交和管理 EMR Serverless 作业。"
    },
    {
        "query":"如何在我想在 EMR Serverless 上运行的作业中包含依赖项？",
        "intention":"知识问答",
        "reply":"对于 PySpark，您可以使用 [virtualenv](https://virtualenv.pypa.io/en/latest/) 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。"
    },
    {
        "query":"EMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？",
        "intention":"知识问答",
        "reply":"EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。"
    },
    {
        "query":"EMR Serverless 支持哪些工作线程配置？",
        "intention":"知识问答",
        "reply":"有关详细信息，请参阅[支持的工作线程配置](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/application-capacity.html#worker-configs)。"
    },
    {
        "query":"如果 EMR Serverless 作业运行时间超过预期，我可以取消它吗？",
        "intention":"知识问答",
        "reply":"是的，您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。"
    },
    {
        "query":"我可以为工作线程增加额外的存储空间吗？",
        "intention":"知识问答",
        "reply":"EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。\n问：可以在哪里找到示例代码？\n您可以在我们的 [GitHub 存储库](https://github.com/aws-samples/emr-serverless-samples)中找到 EMR Serverless 代码示例。"
    },
    {
        "query":"EMR Serverless 中有哪些可用的工作线程选项？",
        "intention":"知识问答",
        "reply":"EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。  \n   \n 问：能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n是的，可以在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。"
    },
    {
        "query":"我能否连接到其他地区的数据存储？",
        "intention":"知识问答",
        "reply":"在没有 VPC 连接的情况下配置时，EMR Serverless 只能访问同一区域中的某些 AWS 资源。请参阅[注意事项](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/considerations.html)。要访问其他区域中的 AWS 资源或非 AWS 资源，您需要[设置 VPC 访问和 NAT 网关](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/vpc-access.html)以路由到 AWS 资源的公共端点。"
    },
    {
        "query":"如何监控 Amazon EMR Serverless 应用程序和作业运行？",
        "intention":"知识问答",
        "reply":"Amazon EMR Serverless 应用程序级和作业级指标每 30 秒向 Amazon CloudWatch 发布一次。"
    },
    {
        "query":"如何使用 EMR Serverless 启动 Spark UI 和 Tez UI？",
        "intention":"知识问答",
        "reply":"在 EMR Studio 中，您可以选择正在运行或已完成的 EMR Serverless 作业，然后单击 Spark UI 或 Tez UI 按钮以启动它们。"
    },
    {
        "query":"我可以访问我的 Amazon Virtual Private Cloud（VPC）中的资源吗？",
        "intention":"知识问答",
        "reply":"是的，您可以配置 Amazon EMR Serverless 应用程序以访问自己的 VPC 中的资源。请参阅文档中的[配置 VPC 访问](https://docs.aws.amazon.com/emr/latest/EMR-Serverless-UserGuide/vpc-access.html)部分以了解更多信息。"
    },
    {
        "query":"使用 EMR Serverless 应用程序可以实现什么样的隔离？",
        "intention":"知识问答",
        "reply":"每个 EMR Serverless 应用程序都与其他应用程序隔离，并在安全 Amazon VPC 上运行。"
    },
    {
        "query":"Amazon EMR Serverless 如何帮助节省大数据部署成本？",
        "intention":"知识问答",
        "reply":"Amazon EMR Serverless 可以通过三种方式帮助您节省成本。首先，管理、保护和扩展集群没有运营开销。其次，EMR Serverless 会在处理作业的每个阶段自动增加工作线程，并在不需要时减少工作线程。您需要为从工作线程开始运行到停止期间使用的汇总 vCPU、内存和存储资源付费，该时间四舍五入到最接近的秒数，最小值为 1 分钟。例如，您的作业在前 10 分钟的作业处理中可能需要 10 个工作线程，而在接下来的 5 分钟需要 50 个工作线程。使用细粒度的自动扩展功能，您只需承担 10 个工作线程运行 10 分钟加 50 个工作线程运行 5 分钟的费用。因此，您不必为未充分利用的资源付费。第三，EMR Serverless 包括适用于 Apache Spark 和 Apache Hive 以及 Presto 的 Amazon EMR 性能优化运行时。Amazon EMR 运行时与 API 兼容，速度是标准开源分析引擎的两倍以上，因此您的作业运行速度更快，计算成本更低。"
    },
    {
        "query":"EMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？",
        "intention":"知识问答",
        "reply":"这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。"
    },
    {
        "query":"我应向谁发出疑问、评论和功能请求？",
        "intention":"知识问答",
        "reply":"请发送电子邮件至 [emr-feedback@amazon.com](mailto:emr-feedback@amazon.com)，以向我们提交您对 EMR Serverless 的疑问和宝贵反馈。"
    },
    {
        "query":"能否对在 EKS 上运行的 EMR 集群和应用程序使用相同的 EMR 发行版？",
        "intention":"知识问答",
        "reply":"可以。您可以对在 EMR 集群上运行的应用程序和在 EKS 上运行的应用程序使用相同的 EMR 发行版。"
    },
    {
        "query":"EKS 上的 EMR 与 EC2 上的 EMR 之间有什么区别？",
        "intention":"知识问答",
        "reply":"|  |  |  |\n| --- | --- | --- |\n| 功能 | EKS 上的 EMR | EC2 上的 EMR |\n| 最新受支持的 EMR 版本 | Y | Y |\n| 作业的多可用区支持 | Y | N |\n| 支持非大数据工作负载的多租户 | Y | N |\n| EMR 版本范围 | 作业 | 集群 |\n| 自动扩展集群 | Y | Y |\n| 托管扩展 | N | Y |\n| 计算提供商 | EC2、Fargate | EC2 |\n| 数据加密 | Y | Y |\n| Kerberos 身份验证 | N | Y |\n| 托管应用程序 | 仅限 Spark | [多个](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html) |\n| AWS Lake Formation | N | Y |\n| Apache Ranger 集成 | N | Y |\n| 自定义 AMI / 镜像 | Y  | Y |\n| 与 Sagemaker 和 Zeppelin 集成 | Y（使用 Livy） | Y |\n| 自托管式笔记本 | N | Y |\n| 与 EMR Studio 集成 | Y | Y |\n| Zeppelin，JEG | N  | Y |\n| 使用 Apache Airflow 编排 | Y | Y |\n| 使用 AWS Stepfunctions 编排 | Y | Y |\n功能\nEKS 上的 EMR\nEC2 上的 EMR\n最新受支持的 EMR 版本\nY\nY\n作业的多可用区支持\nY\nN\n支持非大数据工作负载的多租户\nY\nN\nEMR 版本范围\n作业\n集群\n自动扩展集群\nY\nY\n托管扩展\nN\nY\n计算提供商\nEC2、Fargate\nEC2\n数据加密\nY\nY\nKerberos 身份验证\nN\nY\n托管应用程序\n仅限 Spark\n[多个](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html)\nAWS Lake Formation\nN\nY\nApache Ranger 集成\nN\nY\n自定义 AMI / 镜像\nY\nY\n与 Sagemaker 和 Zeppelin 集成\nY（使用 Livy）\nY\n自托管式笔记本\nY\n与 EMR Studio 集成\nY\nY\nZeppelin，JEG\nN\n使用 Apache Airflow 编排\nY\nY\n使用 AWS Stepfunctions 编排\nY\nY"
    },
    {
        "query":"什么是 Pod 模板？",
        "intention":"知识问答",
        "reply":"EKS 上的 EMR 使您可以使用 Kubernetes Pod 模板来定制作业在 Kubernetes 集群中运行的位置和方式。Kubernetes Pod 模板提供可重复使用的设计模式或样板文件，以声明方式表示 Kubernetes Pod 应该如何部署到您的 EKS 集群。"
    },
    {
        "query":"我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？",
        "intention":"知识问答",
        "reply":"Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。"
    },
    {
        "query":"什么是 Pod？",
        "intention":"知识问答",
        "reply":"Pods 是具有共享网络和存储资源的一个或多个容器，在 Kubernetes 工作线程节点上运行。EKS 上的 EMR 通过将 Spark 驱动程序和执行程序任务计划为单独的 Pod 来使用 Pod 运行作业。"
    },
    {
        "query":"Pod 模板有哪些使用案例？",
        "intention":"知识问答",
        "reply":"您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。"
    },
    {
        "query":"我是否能为我的 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？",
        "intention":"知识问答",
        "reply":"可以，但您不需要为驱动程序和执行程序提供单独的模板。例如，您可以配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在 AWS EC2 按需实例上运行，Spark 执行程序只在 AWS Fargate 实例上运行。在提交作业时，配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 以引用模板的 S3 位置。"
    },
    {
        "query":"我可以指定什么模板值？",
        "intention":"知识问答",
        "reply":"您可以同时指定 Pod 级字段（包括 Volumes、Pod Affinity、Init Containers、Node Selector）和 Spark 主容器级字段（包括 EnvFrom、Working Directory、Lifecycle、Container Volume Mounts）。允许值的完整列表提供在我们的[文档](https://docs.aws.amazon.com/emr/latest/EMR-on-EKS-DevelopmentGuide/pod-templates.html)中。"
    },
    {
        "query":"在何处可以找到有关 Pod 模板的更多信息？",
        "intention":"知识问答",
        "reply":"Amazon EKS 已经支持 Pod 模板，有关 EKS 上的 Amazon EMR 对 Pod 模板的支持的更多信息，请参阅我们的文档和 [Apache Spark Pod 模板文档](https://spark.apache.org/docs/latest/running-on-kubernetes.html#pod-template)。"
    },
    {
        "query":"为什么我应通过 EKS 上的 EMR 使用自定义镜像？",
        "intention":"知识问答",
        "reply":"如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。"
    },
    {
        "query":"什么是自定义镜像？",
        "intention":"知识问答",
        "reply":"自定义镜像是 EKS 上的 EMR 提供的 Docker 镜像（“基础镜像”），包含 EMR 运行时和其他 AWS 服务的连接器，您可以对这些服务进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。新镜像可以存储在 [Amazon Elastic Container Registry (ECR)](https://aws.amazon.com/ecr/) 或您自己的 Docker 容器注册表中。"
    },
    {
        "query":"自定义镜像有哪些使用案例？",
        "intention":"知识问答",
        "reply":"客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。"
    },
    {
        "query":"什么是 AWS Outposts？",
        "intention":"知识问答",
        "reply":"[AWS Outposts](https://aws.amazon.com/cn/outposts/) 可将本地 AWS 服务、基础设施和运营模式引入绝大部分数据中心、主机托管空间或本地设施。使用 [Outposts 上的 EMR](https://aws.amazon.com/cn/emr/features/outposts/)，您可以像在云中一样在本地部署、管理和扩展 EMR 集群。"
    },
    {
        "query":"何时应该使用 Outposts 上的 EMR？",
        "intention":"知识问答",
        "reply":"如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。"
    },
    {
        "query":"Outposts 上的 EMR 支持哪些 EMR 版本？",
        "intention":"知识问答",
        "reply":"支持的最低 Amazon EMR 版本为 5.28.0。"
    },
    {
        "query":"使用 Outposts 时有哪些 EMR 应用程序可用？",
        "intention":"知识问答",
        "reply":"EMR 5.28.0 及更高版本中的所有应用程序均支持。请参阅我们的[发布说明](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-5x.html)，获取完整的 EMR 应用程序列表。"
    },
    {
        "query":"可以使用 Outpost 中的 EMR 集群从我现有的本地 Apache Hadoop 集群中读取数据吗？",
        "intention":"知识问答",
        "reply":"在 Outpost 的 EMR 上运行的工作负载可以在现有 HDFS 存储中读写数据，因而您可以与现有的本地 Apache Hadoop 部署轻松集成。这使您能够使用 EMR 更好地满足数据处理需求，而无需迁移数据。"
    },
    {
        "query":"可以选择在哪里存储数据吗？",
        "intention":"知识问答",
        "reply":"在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。"
    },
    {
        "query":"是否有任何 EMR 功能需要将数据上传到 S3？",
        "intention":"知识问答",
        "reply":"在 Outpost 中启动 EMR 集群时，您可以选择是否[启用日志记录](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-debugging.html)。启用日志记录后，集群日志将被上传到您指定的 S3 存储桶。这些日志用于简化集群终止后的调试。禁用后，日志不会上传到 S3。"
    },
    {
        "query":"Outpost 容量不足时会怎样？",
        "intention":"知识问答",
        "reply":"在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。"
    },
    {
        "query":"如果 Outpost 和 AWS 之间的网络连接中断会怎样？",
        "intention":"知识问答",
        "reply":"如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。"
    },
    {
        "query":"可以做到哪些之前我无法做到的事情？",
        "intention":"知识问答",
        "reply":"大部分 EC2 实例都附带固定的存储容量，称为“实例存储”。现在，您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。利用此功能，您还可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。"
    },
    {
        "query":"向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？",
        "intention":"知识问答",
        "reply":"在以下场景中，您可以通过向实例添加 EBS 卷来获得好处："
    },
    {
        "query":"是否可以在群集终止后保留 EBS 卷上的数据？",
        "intention":"知识问答",
        "reply":"目前，Amazon EMR 将在群集终止后删除卷。如果您希望在群集生命周期外保留数据，不妨考虑将 Amazon S3 作为数据存储使用。"
    },
    {
        "query":"我可以向实例附加哪些类型的 EBS 卷？",
        "intention":"知识问答",
        "reply":"Amazon EMR 允许您使用不同的 EBS 卷类型：通用型 SSD (GP2)、磁性和预置 IOPS (SSD)。"
    },
    {
        "query":"终止群集后，EBS 卷会发生什么？",
        "intention":"知识问答",
        "reply":"Amazon EMR 将在 EMR 群集终止后删除卷。"
    },
    {
        "query":"是否可以将 EBS 与已经具有实例存储的实例结合使用？",
        "intention":"知识问答",
        "reply":"可以，您可以向具有实例存储的实例添加 EBS 卷。"
    },
    {
        "query":"是否可以向正在运行的集群附加 EBS 卷？",
        "intention":"知识问答",
        "reply":"不可以，当前您只能在启动群集时添加 EBS 卷。"
    },
    {
        "query":"是否可以拍摄群集中的卷的快照？",
        "intention":"知识问答",
        "reply":"EBS API 允许您拍摄群集的快照。但是，当前 Amazon EMR 不允许您从快照进行恢复。"
    },
    {
        "query":"是否可以使用加密的 EBS 卷？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS KMS 作为密钥提供程序来加密 EBS 根设备和存储卷。有关更多信息，请参阅[本地磁盘加密](https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-data-encryption-options.html#emr-encryption-localdisk)。"
    },
    {
        "query":"如果我从正在运行的集群删除附加卷，会发生什么？",
        "intention":"知识问答",
        "reply":"如果从正在运行的群集删除附加卷，系统会将其作为节点故障进行处理。Amazon EMR 会将节点和 EBS 卷各替换为相同的节点和 EBS 卷。\n[Hive](https://aws.amazon.com/cn/emr/faqs#Using_Hive) | [Hudi](https://aws.amazon.com/cn/emr/faqs#Using_Hudi) | [Impala](https://aws.amazon.com/cn/emr/faqs#Using_Impala) | [Pig](https://aws.amazon.com/cn/emr/faqs#Using_Pig) | [HBase](https://aws.amazon.com/cn/emr/faqs#Using_HBase)"
    },
    {
        "query":"什么是 Apache Spark？",
        "intention":"知识问答",
        "reply":"[Apache SparkTM](https://aws.amazon.com/cn/big-data/what-is-spark/) 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 [Spark](https://aws.amazon.com/cn/big-data/what-is-spark/) 和 [Amazon EMR 上的 Spark](https://aws.amazon.com/cn/emr/features/spark/)。"
    },
    {
        "query":"什么是 Presto？",
        "intention":"知识问答",
        "reply":"[Presto](https://aws.amazon.com/cn/big-data/what-is-presto/) 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 [Presto](https://aws.amazon.com/cn/big-data/what-is-presto/) 和 [Amazon EMR 上的 Presto](https://aws.amazon.com/cn/emr/features/presto/)。"
    },
    {
        "query":"什么是 Apache Hive？",
        "intention":"知识问答",
        "reply":"Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以[在此处了解有关 Apache Hive 的更多信息](https://aws.amazon.com/cn/big-data/what-is-hive/)。"
    },
    {
        "query":"我用 Amazon EMR 中运行的 Hive 可以做什么？",
        "intention":"知识问答",
        "reply":"当 Pig 与 Amazon EMR 搭配使用时，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Hive 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。"
    },
    {
        "query":"Hive 与传统的 RDBMS 系统有何不同？",
        "intention":"知识问答",
        "reply":"传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。"
    },
    {
        "query":"如何开始使用 Amazon EMR 中运行的 Hive？",
        "intention":"知识问答",
        "reply":"要开始使用，您最好先查看[此处](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html)的书面文档。"
    },
    {
        "query":"特定于 Amazon EMR 的 Hive 是否有新功能？",
        "intention":"知识问答",
        "reply":"可以。有关更多详情，请参阅我们的[文档](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html)："
    },
    {
        "query":"支持哪些类型的 Hive 群集？",
        "intention":"知识问答",
        "reply":"Hive 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Hive 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Hive 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。"
    },
    {
        "query":"如何启动 Hive 群集？",
        "intention":"知识问答",
        "reply":"批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。请参阅发布指南中的 [Hive](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html) 部分，了解有关启动 Hive 群集的更多详细信息。"
    },
    {
        "query":"何时应使用 Hive与 PIG？",
        "intention":"知识问答",
        "reply":"Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。"
    },
    {
        "query":"Amazon EMR 支持哪些版本的 Hive？",
        "intention":"知识问答",
        "reply":"有关最新版本的 Amazon EMR 上的 Hive，请参阅[文档](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hive.html)。"
    },
    {
        "query":"是否可以从两个集群并发写入表？",
        "intention":"知识问答",
        "reply":"Hive 不支持并发写入表。应避免并发写入同一个表，或在向表写入时从中进行读取。Hive 在同时读取和写入或同时写入时会出现不确定性的行为。"
    },
    {
        "query":"是否可以在不同的群集之间共享数据？",
        "intention":"知识问答",
        "reply":"是的。您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。对于要访问的每个外部资源，您需要执行 create table 语句。"
    },
    {
        "query":"我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？",
        "intention":"知识问答",
        "reply":"Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。"
    },
    {
        "query":"是否可以访问本地文件系统中的脚本或 Jar 资源？",
        "intention":"知识问答",
        "reply":"必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。"
    },
    {
        "query":"是否可运行执行多个 Hive 查询的持续性群集？",
        "intention":"知识问答",
        "reply":"可以。在手动终止模式下运行群集，它们则不会在各个 Hive 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。"
    },
    {
        "query":"多个用户是否可基于同一源数据执行 Hive 步骤？",
        "intention":"知识问答",
        "reply":"可以。多个用户在不同群集中执行的 Hive 脚本可能包括 create external table 语句，以并发导入 Amazon S3 中驻留的源数据。"
    },
    {
        "query":"多个用户是否可在同一群集中运行查询？",
        "intention":"知识问答",
        "reply":"可以。在批处理模式下，步骤呈序列化状态。多个用户可以将 Hive 步骤添加到同一集群；但将按顺序执行步骤。在交互式模式下，若干用户可以登录到同一集群，并发执行 Hive 语句。"
    },
    {
        "query":"是否可以在多个 AWS 用户之间共享数据？",
        "intention":"知识问答",
        "reply":"可以。可以使用[此处](http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html)介绍的标准 Amazon S3 共享机制来共享数据。"
    },
    {
        "query":"Hive 是否支持从 JDBC 进行访问？",
        "intention":"知识问答",
        "reply":"是的。Hive 提供 JDBC 驱动器，可用来以编程方式执行 Hive 语句。要在群集中启动 JDBC 服务，您需要在 Amazon EMR 命令行客户端中传递可选参数。此外，还需要建立一个 SSH 隧道，因为安全组不允许外部连接。"
    },
    {
        "query":"在 EMR AMI 中更新软件包的流程是什么？",
        "intention":"知识问答",
        "reply":"首次启动时，适用于 EMR 的 Amazon Linux AMI 会连接到 Amazon Linux AMI yum 存储库，以安装安全更新。使用自定义 AMI 时，您可以禁用此功能。但出于安全考虑，我们不建议这样做。"
    },
    {
        "query":"我是否可以在 EMR 群集中更新自己的软件包？",
        "intention":"知识问答",
        "reply":"可以。您可以使用引导操作向群集中的软件包安装更新。"
    },
    {
        "query":"是否可以使用 Hive 处理 DynamoDB 数据？",
        "intention":"知识问答",
        "reply":"可以。只需根据您的 DynamoDB 表定义一个外部 Hive 表。然后，即可使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。有关更多信息，请访问我们的[开发人员指南](http://docs.amazonwebservices.com/ElasticMapReduce/latest/DeveloperGuide/EMRforDynamoDB.html)。"
    },
    {
        "query":"什么是 Apache Hudi？",
        "intention":"知识问答",
        "reply":"[Apache Hudi](https://hudi.incubator.apache.org/) 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。"
    },
    {
        "query":"何时应使用 Apache Hudi？",
        "intention":"知识问答",
        "reply":"Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益："
    },
    {
        "query":"如何创建 Apache Hudi 数据集？",
        "intention":"知识问答",
        "reply":"使用 Apache Spark 创建 Apache Hudi 数据集。创建数据集像编写 Apache Spark DataFrame 一样简单。可以选择将 Apache Hudi 数据集的元数据存储在 AWS Glue Data Catalog 或 Hive 元存储中，以简化数据发现过程以及与 Apache Hive 和 Presto 集成。"
    },
    {
        "query":"Apache Hudi 如何管理数据集？",
        "intention":"知识问答",
        "reply":"使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。"
    },
    {
        "query":"如何写入到 Apache Hudi 数据集？",
        "intention":"知识问答",
        "reply":"使用 Apache Spark 对 Apache Hudi 数据集进行更改。使用 Apache Spark 时，Apache Hudi 数据集通过 Spark DataSource API 运行，从而使您能够写入和读取数据。可以使用相同的 DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。您也可以使用 Hudi DeltaStreamer 实用程序。"
    },
    {
        "query":"如何从 Apache Hudi 数据集中进行读取？",
        "intention":"知识问答",
        "reply":"您可以使用 Apache Spark、Apache Hive、Presto、Amazon Redshift Spectrum 或 Amazon Athena 读取数据。当您创建数据集时，您可以选择在 AWS Glue Data Catalog 或 Hive 元存储中发布该数据集的元数据。如果您选择在元存储中发布元数据，您的数据集看起来就像一个普通的表格，您可以使用 Apache Hive 和 Presto 查询该表格。"
    },
    {
        "query":"我在使用 Apache Hudi 时应注意哪些注意事项或限制？",
        "intention":"知识问答",
        "reply":"有关使用 Amazon EMR 上的 Apache Hudi 时要注意的注意事项和限制的完整列表，请参阅我们的 [Amazon EMR 文档](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html)。"
    },
    {
        "query":"如何用 Apache Hudi 处理我的现有数据？",
        "intention":"知识问答",
        "reply":"如果拥有想要现在使用 Apache Hudi 进行管理的数据，您可以使用 Amazon EMR 上的 Apache Hudi 提供的导入工具将您的 Apache Parquet 数据轻松转换为 Apache Hudi 数据集，或者使用 Hudi DeltaStreamer 实用程序或 Apache Spark 将您的现有数据重写为 Apache Hudi 数据集。"
    },
    {
        "query":"什么是 Impala？",
        "intention":"知识问答",
        "reply":"Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击[此处](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-impala.html)可以了解有关 Impala 的更多信息。"
    },
    {
        "query":"使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？",
        "intention":"知识问答",
        "reply":"与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。"
    },
    {
        "query":"Impala 与传统的 RDBMS 有何区别？",
        "intention":"知识问答",
        "reply":"传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。"
    },
    {
        "query":"Impala 与 Hive 有何区别？",
        "intention":"知识问答",
        "reply":"Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。"
    },
    {
        "query":"可以使用 Hadoop 1 吗？",
        "intention":"知识问答",
        "reply":"不可以，Impala 需要 Hadoop 2，在使用运行 Hadoop 1.x 的 AMI 的群集上无法运行。"
    },
    {
        "query":"应该对我的 Impala 群集使用什么实例类型？",
        "intention":"知识问答",
        "reply":"为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的[性能测试和查询优化](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/impala-optimization.html)部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。"
    },
    {
        "query":"如果查询时内存不足会发生什么？",
        "intention":"知识问答",
        "reply":"如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。"
    },
    {
        "query":"Impala 支持用户定义的函数吗？",
        "intention":"知识问答",
        "reply":"是，Impala 支持用户定义的函数 (UDF)。可以用 Java 或 C++ 编写专用于 Impala 的 UDF。另外，可以修改为 Hive 创建的 UDF 或用户定义的聚合函数，以便在 Impala 中使用。有关 Hive UDF 的信息，请单击[此处](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF)。"
    },
    {
        "query":"供 Impala 查询的数据存储在何处？",
        "intention":"知识问答",
        "reply":"Impala 会查询 HDFS 或 HBase 表中的数据。"
    },
    {
        "query":"可以在群集上同时运行 Impala 和 MapReduce 吗？",
        "intention":"知识问答",
        "reply":"是的，您可以设置具有 Impala 和 MapReduce 的多租户群集。但是，您应确保使用 Hadoop 2.x 上的 YARN 将资源（内存、磁盘和 CPU）分配给每个应用程序。分配的资源应取决于您计划在每个应用程序上所运行任务的需要。"
    },
    {
        "query":"Impala 支持 ODBC 和 JDBC 驱动程序吗？",
        "intention":"知识问答",
        "reply":"虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅[打开到主节点的 SSH 隧道](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-ssh-tunnel.html)。"
    },
    {
        "query":"什么是 Apache Pig？",
        "intention":"知识问答",
        "reply":"Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。"
    },
    {
        "query":"我该如何使用 Amazon EMR 中运行的 Pig？",
        "intention":"知识问答",
        "reply":"对于 Amazon EMR 使用 Pig，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Pig 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。"
    },
    {
        "query":"如何开始使用 Amazon EMR 中运行的 Pig？",
        "intention":"知识问答",
        "reply":"要开始使用，您最好先查看[此处](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-pig.html)的书面文档。"
    },
    {
        "query":"特定于 Amazon EMR 的 Pig 是否有新功能？",
        "intention":"知识问答",
        "reply":"可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。"
    },
    {
        "query":"支持哪些类型的 Pig 群集？",
        "intention":"知识问答",
        "reply":"Pig 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Pig 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Pig 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。"
    },
    {
        "query":"如何启动 Pig 群集？",
        "intention":"知识问答",
        "reply":"批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。"
    },
    {
        "query":"Amazon EMR 支持哪些版本的 Pig？",
        "intention":"知识问答",
        "reply":"Amazon EMR 支持[多个版本](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-pig.html)的 Pig。"
    },
    {
        "query":"是否可以从两个群集并发写入 S3 存储段？",
        "intention":"知识问答",
        "reply":"是的，可以从两个并发群集写入同一个存储段。"
    },
    {
        "query":"是否可以在不同的群集之间共享 S3 中的输入数据？",
        "intention":"知识问答",
        "reply":"是的，可以从两个并发群集读取 S3 中的相同数据。"
    },
    {
        "query":"是否可以在多个 AWS 用户之间共享数据？",
        "intention":"知识问答",
        "reply":"可以。可以使用此处 <http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html> 描述的标准 Amazon S3 共享机制共享数据"
    },
    {
        "query":"我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？",
        "intention":"知识问答",
        "reply":"Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。"
    },
    {
        "query":"是否可以访问本地文件系统中的脚本或 Jar 资源？",
        "intention":"知识问答",
        "reply":"必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。"
    },
    {
        "query":"是否可运行执行多个 Pig 查询的持续性群集？",
        "intention":"知识问答",
        "reply":"可以。在手动终止模式下运行群集，它们则不会在各个 Pig 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。"
    },
    {
        "query":"Pig 是否支持从 JDBC 进行访问？",
        "intention":"知识问答",
        "reply":"Pig 不支持通过 JDBC 进行访问。"
    },
    {
        "query":"什么是 Apache HBase？",
        "intention":"知识问答",
        "reply":"HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以[在此处了解有关 Apache HBase 的更多信息](https://aws.amazon.com/cn/big-data/what-is-hbase/)。"
    },
    {
        "query":"特定于 Amazon EMR 的 HBase 是否有新功能？",
        "intention":"知识问答",
        "reply":"借助 Amazon EMR，您可以在 Amazon S3 上使用 HBase 将集群的 HBase 根目录和元数据直接存储到 Amazon S3，并创建只读副本和快照。要了解更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hbase.html)。"
    },
    {
        "query":"Amazon EMR 支持哪些版本的 HBase？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/HBase-release-history.html)查看 Amazon EMR 支持的最新 HBase 版本。"
    },
    {
        "query":"添加到 Kinesis 上去的 EMR 连接器支持什么功能？",
        "intention":"知识问答",
        "reply":"该连接器支持 EMR 直接从 Kinesis 串流读取和查询数据。现在，您可以使用现有的 Hadoop 生态系统工具，如 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading，来执行 Kinesis 串流的批处理。"
    },
    {
        "query":"添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？",
        "intention":"知识问答",
        "reply":"读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。"
    },
    {
        "query":"此功能对哪些人有用？",
        "intention":"知识问答",
        "reply":"此功能对以下各类用户有用："
    },
    {
        "query":"这种集成有哪些使用案例？",
        "intention":"知识问答",
        "reply":"以下为此集成支持的代表性使用案例："
    },
    {
        "query":"要使用此连接器，我需要使用什么 EMR AMI 版本？",
        "intention":"知识问答",
        "reply":"您需要使用 EMR AMI 的版本 3.0.4 和更新的版本。"
    },
    {
        "query":"此连接器是独立的工具吗？",
        "intention":"知识问答",
        "reply":"不是，它是 Amazon Hadoop 分配的内置组件，EMR AMI 的版本 3.0.4 及更新版本上提供此组件。客户只需使用版本 3.0.4 或更新版本的 AMI 快速构建一个群集就可以开始使用此功能。"
    },
    {
        "query":"支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？",
        "intention":"知识问答",
        "reply":"EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 [Tap](http://docs.cascading.org/cascading/2.1/userguide/html/ch03s05.html)。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。"
    },
    {
        "query":"在 EMR 中，如何使用 Hive 来分析 Kinesis 串流？",
        "intention":"知识问答",
        "reply":"创建一个引用 Kinesis 串流的表。然后，您可以像分析 Hive 中的其他任何表一样分析此表。请参阅我们的[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)页面了解更多详情。"
    },
    {
        "query":"使用 Hive 时，如何创建结合了 Kinesis 串流数据和其他数据源的查询？",
        "intention":"知识问答",
        "reply":"首先，创建一个引用 Kinesis 串流的表。Hive 表创建好后，您可以将它与映射到其他数据源（如 Amazon S3、Amazon Dynamo DB 和 HDFS）的表结合起来。这会有效地将来自 Kinesis 串流的数据加入到其他数据源中。"
    },
    {
        "query":"此集成仅用于 Hive 吗？",
        "intention":"知识问答",
        "reply":"不是，您可以使用 Hive、Pig、MapReduce、Hadoop 流以及 Cascading。"
    },
    {
        "query":"如何设置要在 Kinesis 串流上运行的既定任务？",
        "intention":"知识问答",
        "reply":"EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n此外，该[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)中还提供了一个示例 Cron 调度脚本。"
    },
    {
        "query":"逻辑名称的元数据和迭代存储在何处？",
        "intention":"知识问答",
        "reply":"允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据存储在 Amazon DynamoDB 中。您必须预配置一个 Amazon Dynamo DB 表并指定其作为 Hadoop 任务的输入参数。注意：您要为该表配置合适的 IOPS 来支持此集成。请参阅入门[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)，了解有关设置 Amazon Dynamo DB 表的更多信息。"
    },
    {
        "query":"当迭代处理失败时，会出现什么情况？",
        "intention":"知识问答",
        "reply":"在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。"
    },
    {
        "query":"是否能在同一迭代中运行多个查询？",
        "intention":"知识问答",
        "reply":"可以，您可以通过在连续处理过程中设定 kinesis.checkpoint.iteration.no 参数来指定之前运行的迭代。该实施确保同一迭代的连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。"
    },
    {
        "query":"如果迭代中的记录在 Kinesis 串流中到期失效，会出现什么情况？",
        "intention":"知识问答",
        "reply":"如果迭代的开始序列号和/或结尾序列号属于已在 Kinesis 串流中到期失效的记录，则 Hadoop 任务会失败。您将需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。"
    },
    {
        "query":"能否将数据从 EMR 推送到 Kinesis 串流中？",
        "intention":"知识问答",
        "reply":"目前，EMR Kinesis 连接器不支持将数据回写到 Kinesis 串流中。"
    },
    {
        "query":"Kinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？",
        "intention":"知识问答",
        "reply":"Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在[此处](https://github.com/awslabs/kinesis-storm-spout)的 GitHub 上获取，您还可以在[此处](http://aws.amazon.com/articles/4926593393724923)找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在[此处](http://docs.aws.amazon.com/kinesis/latest/dev/step-three-build-an-app.html)的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。"
    },
    {
        "query":"是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？",
        "intention":"知识问答",
        "reply":"可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\nHive 代码示例：  \n ...  \n STORED BY  \n 'com.amazon.emr.kinesis.hive.KinesisStorageHandler'  \n TBLPROPERTIES(  \n \"kinesis.accessKey\"=\"AwsAccessKey\",  \n \"kinesis.secretKey\"=\"AwsSecretKey\",  \n );\nPig 代码示例：  \n …  \n raw\\_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin  \n esisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'  \n ) AS (line:chararray);"
    },
    {
        "query":"能否在一个 Kinesis 串流中运行多个并行查询？ 对性能是否有影响？",
        "intention":"知识问答",
        "reply":"可以，客户通过为每个查询使用单独的逻辑名称，可以在同一流中运行多个并行查询。但是，从 Kinesis 串流内的碎片中读取数据受到每秒 2MB 的速率限制。因此，如果在同一串流内运行 N 个并行查询，则串流上的每个碎片的每个查询会获得每秒 (2/N) MB 的出站速率。这可能会降低处理速度，有些情况下，还会导致查询失败。"
    },
    {
        "query":"能否在 EMR 中加入并分析多个 Kinesis 串流？",
        "intention":"知识问答",
        "reply":"可以，例如在 Hive 中，您可以创建两个映射到不同 Kinesis 串流的表并在两个表之间创建连接。"
    },
    {
        "query":"EMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？",
        "intention":"知识问答",
        "reply":"是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。"
    },
    {
        "query":"如果我的流中存在一些“静默”时段，会怎么样？",
        "intention":"知识问答",
        "reply":"该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅[教程](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-kinesis.html)了解如何定义这些参数。"
    },
    {
        "query":"如何调试在每次迭代中持续失败的查询？",
        "intention":"知识问答",
        "reply":"如果处理发生故障，您在调试 Hadoop 任务时可以利用他们当前所用的工具。包括帮助识别和访问错误日志的 Amazon EMR Web 控制台。可在[此处](http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-plan-debugging.html)找到更多有关调试 EMR 任务的详细信息。"
    },
    {
        "query":"如果指定了没有访问权限的 DynamoDB 表，会出现什么情况？",
        "intention":"知识问答",
        "reply":"任务会失败，此异常情况会显示任务的错误日志中。"
    },
    {
        "query":"如果任务没有失败，但是 DynamoDB 的检查点出现故障，会出现什么情况？",
        "intention":"知识问答",
        "reply":"任务会失败，此异常情况会显示任务的错误日志中。"
    },
    {
        "query":"如何将从 Kinesis 串流到 EMR 的读取吞吐量最大化？",
        "intention":"知识问答",
        "reply":"Kinesis 串流的吞吐量的增长随所用实例的大小以及 Kinesis 流中的记录大小而定。我们建议您使用 m1.xlarge 以及更大的实例，以确保将主要节点和核心节点用于此功能。"
    },
    {
        "query":"什么是 Amazon EMR 服务等级协议？",
        "intention":"知识问答",
        "reply":"请参阅我们的[服务等级协议](https://aws.amazon.com/cn/emr/sla/)。"
    },
    {
        "query":"怎样确定我是否有资格获得服务抵扣？ 如何申请？",
        "intention":"知识问答",
        "reply":"了解有关 Amazon EMR 定价的更多信息"
    },
    {
        "query":"什么是 AWS Config？",
        "intention":"知识问答",
        "reply":"AWS Config 是一种完全托管的服务，可为您提供资源库存、配置历史记录和配置更改通知，以使用安全性和管理。借助 AWS Config，您可以找到现有的 AWS 资源，记录第三方资源的配置，导出资源的完整库存清单与所有配置详细信息，并确定在任何时间点上配置资源的方式。这些功能使用合规性审计、安全分析、资源更改跟踪和故障排除。"
    },
    {
        "query":"什么是 AWS Config 规则？",
        "intention":"知识问答",
        "reply":"AWS Config 规则代表某个资源的期望配置，其评估依据是 AWS Config 中记录的相关资源的配置更改。针对资源配置评估规则的结果可在控制面板中查看。使用 AWS Config 规则，您可以从配置角度评估整体合规性和风险状态、查看一段时间内的合规性趋势，以及查明哪些配置更改导致了资源脱离规则合规性。"
    },
    {
        "query":"什么是一致性包？",
        "intention":"知识问答",
        "reply":"一致性包是使用 AWS Config 中的通用框架和打包模型构建的 AWS Config 规则和补救措施的集合。通过打包前述 AWS Config 构件，您可以简化跨多个账户和区域的治理策略和配置合规性的部署和报告方面，并减少资源处于不合规状态的时间。"
    },
    {
        "query":"AWS Config 有哪些好处？",
        "intention":"知识问答",
        "reply":"AWS Config 可用于更加轻松地追踪您的资源配置，而无需预先投资，并且避开了安装和更新代理程序以进行数据收集或大型数据库维护的复杂性。一旦您启用了 AWS Config，您便可以查看与 AWS 资源相关的所有配置属性的持续更新详细信息。您可以通过 Amazon Simple Notification Service（SNS）获得每个配置更改的通知。"
    },
    {
        "query":"AWS Config 如何帮助进行审计？",
        "intention":"知识问答",
        "reply":"AWS Config 可为您提供资源配置历史记录的访问权。您可以将配置更改与可能对配置的更改做出了贡献的 AWS CloudTrail 事件关联起来。通过此信息，您能够充分了解从“谁进行的更改”、“来自哪个 IP 地址”之类的详细信息乃至此更改对 AWS 资源及相关资源产生的影响。您可以使用此信息生成报告，从而在一定的时间段内帮助审计和评估合规性。"
    },
    {
        "query":"哪些人应使用 AWS Config 和 AWS Config 规则？",
        "intention":"知识问答",
        "reply":"任何期望通过持续评估其资源配置以在 AWS 上改进安全性和管理状况的 AWS 客户都可以从此功能获益。在大型组织中推荐配置资源最佳实践的管理员可以将这些规则编写成 AWS Config 规则，然后在用户中安装自管理。监视使用活动和检测漏洞配置的信息安全专家可以从 AWS Config 规则获益。如果您的工作负载必须遵循特定标准（例如 [PCI-DSS 或 HIPAA](https://aws.amazon.com/cn/compliance/)），则可以使用此功能评估其 AWS 基础设施配置的合规性，并为审计人员生成报告。管理大型 AWS 基础设施或频繁变更组件的操作员也可以从 AWS Config 规则获益以进行故障排查。如果您想追踪资源配置更改、获得资源配置相关问题解答、证明合规性、进行故障排除或执行安全性分析，则应启用 AWS Config。"
    },
    {
        "query":"哪些人应使用 AWS Config 一致性包？",
        "intention":"知识问答",
        "reply":"如果您正在寻找一个框架来为多个账户的 AWS 资源配置构建和部署合规性包，则应使用一致性包。此框架可用于针对安全性、DevOps 和其他角色构建自定义包，并且您可以使用其中一个示例一致性包模板快速开始。"
    },
    {
        "query":"该服务能否保证我的配置永不偏离合规性？",
        "intention":"知识问答",
        "reply":"AWS Config 规则和一致性包提供有关您的资源是否符合所指定的配置规则的信息。它们将定期和/或在检测到配置更改时根据 AWS Config 规则评估资源配置，具体取决于您如何配置规则。它们不能保证资源将符合规则或阻止用户执行非合规操作。但是，可以使用它们为每个 AWS Config 规则配置适当的补救措施，使不符合要求的资源重新符合要求。"
    },
    {
        "query":"该服务能否阻止用户执行非合规操作？",
        "intention":"知识问答",
        "reply":"AWS Config 规则不会直接影响最终用户使用 AWS 的方式。AWS Config 规则仅在配置更改已完成并由 AWS Config 记录之后才评估资源配置。AWS Config 规则不会阻止用户进行可能非合规的更改。若要控制您可以对 AWS 进行的预置以及预置期间所使用的配置参数，则分别使用 [AWS Identity and Access Management](https://aws.amazon.com/cn/iam/)（IAM）策略和 [AWS Service Catalog](https://aws.amazon.com/cn/servicecatalog/)。"
    },
    {
        "query":"能否在预置资源之前评估规则？",
        "intention":"知识问答",
        "reply":"可以，AWS Config 规则可以设置为仅主动模式、仅侦测模式，或者同时设置为主动模式和侦测模式。有关这些规则的完整列表，[请参阅文档](https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config-rules.html#list-proactive-rules)。"
    },
    {
        "query":"我已经在预置后对自己的资源使用 AWS Config 规则。如何在主动模式下运行同样的规则？",
        "intention":"知识问答",
        "reply":"您可以使用现有的 PutConfigrule API 或 AWS Config 控制台，在自己账户中的 AWS Config 规则上启用主动模式。"
    },
    {
        "query":"AWS Config 能否记录本地或其他云上的资源配置？",
        "intention":"知识问答",
        "reply":"AWS Config 可帮助您记录第三方资源或自定义资源类型的配置，例如本地服务器、软件即服务（SaaS）监控工具和版本控制系统。为此，必须创建符合并验证资源类型配置的资源提供者架构。您必须使用 [AWS CloudFormation](https://docs.aws.amazon.com/cloudformation-cli/latest/userguide/resource-type-register.html)  或基础设施即代码（IaC）工具注册自定义资源。\n如果您已将 AWS Config 配置为记录所有资源类型，则通过 AWS CloudFormation 管理（创建、更新或删除）的第三方资源将作为配置项目在 AWS Config 中自动进行跟踪。要更深入地了解所需的步骤并了解可在哪些 AWS 区域使用此功能，请参阅 AWS Config 开发人员指南：[记录第三方资源的配置](https://docs.aws.amazon.com/config/latest/developerguide/customresources.html)。"
    },
    {
        "query":"AWS Config 如何与 AWS CloudTrail 协作？",
        "intention":"知识问答",
        "reply":"AWS CloudTrail 会记录您账户上的用户 API 活动，协助您访问有关该活动的信息。您将获得有关 API 操作的完整详细信息，如调用者的身份、该 API 调用的时间、请求参数和 AWS 服务返回的响应元素。AWS Config 将您的 AWS 资源的时间点配置详细信息记录为[配置项](http://docs.aws.amazon.com/config/latest/developerguide/resource-config-reference.html#config-item-table)（CI）。您可以使用 CI 在某个时间点回答“我的 AWS 资源是什么样的？”您可以使用 CloudTrail 回答“谁进行了 API 调用来修改此资源？” 例如，您可以对 AWS Config 使用 AWS 管理控制台以检测安全组“生产数据库”过去的配置是否不正确。使用集成的 CloudTrail 信息，您可以发现是哪个用户错误配置了“生产数据库”安全组。"
    },
    {
        "query":"我能否通过中央账户监控多个账户和地区的合规性信息？",
        "intention":"知识问答",
        "reply":"借助 AWS Config，您能够更加轻松地使用[多账户、多地区数据聚合](https://docs.aws.amazon.com/config/latest/developerguide/config-concepts.html)功能来监控多个账户和地区的合规状态。您可以在任一账户中创建配置聚合器，并从其他账户聚合合规详情。该功能还在 AWS Organizations 上得到利用，因此您可以聚合组织内所有账户的数据。"
    },
    {
        "query":"我可以将 ServiceNow 和 Jira Service Desk 实例连接到 AWS Config 吗？",
        "intention":"知识问答",
        "reply":"可以。适用于 ServiceNow 和 Jira Service Desk 的 AWS Service Management Connector 可协助 ServiceNow 和 Jira Service Desk 最终用户使用 ServiceNow 和 Jira Service Desk 在本地预置、管理和使用 AWS 资源。ServiceNow 用户可以在由 AWS Config 支持的配置项目视图中，通过 AWS Service Management Connector 在 ServiceNow 上无缝跟踪资源。Jira Service Desk 用户可以使用 AWS Service Management Connector 跟踪发布请求中的资源。这简化了针对 ServiceNow 和 Jira Service Desk 用户的 AWS 产品请求操作，并为 ServiceNow 和 Jira Service Desk 管理员提供了对 AWS 产品的管理和监督。\n适用于 ServiceNow 的 AWS Service Management Connector 在 [ServiceNow Store](https://store.servicenow.com/sn_appstore_store.do#!/store/application/f0b117a3db32320093a7d7a0cf961912/) 中免费提供。已推出 AWS Service Catalog 的所有 [AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)均已正式提供这项新功能。有关更多信息，请访问[文档](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/integrations-servicenow.html)。\n适用于 Jira Service Desk 的 AWS Service Management Connector 在 [Atlassian Marketplace](https://marketplace.atlassian.com/1221283) 上免费提供。已推出 AWS Service Catalog 的所有 [AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)均已正式提供这项新功能。有关更多信息，请访问[文档](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/integrations-jiraservicedesk.html)。"
    },
    {
        "query":"如何开始使用该服务？",
        "intention":"知识问答",
        "reply":"开始使用 AWS Config 最快捷的方式就是使用 AWS 管理控制台。几次选择即可启用 AWS Config。有关其他详细信息，请参阅[入门](http://docs.aws.amazon.com/config/latest/developerguide/gs-console.html)文档。"
    },
    {
        "query":"如何访问我的资源配置？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台、AWS 命令行界面或 SDK 查找当前和历史资源配置。\n有关其他详细信息，参阅 [AWS Config 文档](https://aws.amazon.com/cn/documentation/config/)。"
    },
    {
        "query":"我需要在地区范围内还是全球范围内启用 AWS Config？",
        "intention":"知识问答",
        "reply":"您可以基于每个地区为您的账户启用 AWS Config。"
    },
    {
        "query":"AWS Config 能否在不同的 AWS 账户间聚合数据？",
        "intention":"知识问答",
        "reply":"能，一旦适当的 IAM 策略应用到 Amazon S3 存储桶，您就可以将 AWS Config 设置为将配置更新从不同的账户发送到一个 Amazon Simple Storage Service（S3）存储桶中。一旦适当的 IAM 策略应用到 SNS 主题，您还可以向同一地区内的一个 SNS 主题发布通知。"
    },
    {
        "query":"AWS Config 上的 API 活动自身会被 CloudTrail 记录下来吗？",
        "intention":"知识问答",
        "reply":"可以。所有 AWS Config API 活动，包括 AWS Config API操作 的使用到阅读配置数据，都会被 CloudTrail 记录下来。"
    },
    {
        "query":"资源的时间线视图中显示哪些时间和时区？ 什么是夏令时？",
        "intention":"知识问答",
        "reply":"AWS Config 显示在时间轴上记录资源的配置项 (CI) 的时间。所有时间均以国际协调时间（UTC）为准。在管理控制台上直观显示时间轴时，服务使用当前时区（若适用，已针对夏令时调整）在时间轴视图中显示所有时间。"
    },
    {
        "query":"什么是资源的配置？",
        "intention":"知识问答",
        "reply":"资源的配置由 AWS Config 的配置项（CI）中所含的数据定义。AWS Config 规则的初始版本为相关规则提供了资源的 CI。AWS Config 规则可以将此信息与任何其他相关信息（例如其他附加资源和工作时间）一起用于评估资源配置的合规性。"
    },
    {
        "query":"什么是规则？",
        "intention":"知识问答",
        "reply":"规则表示用于资源的期望配置项（CI）属性值，并通过将这些属性值与 AWS Config 所记录的 CI 比较进行评估。规则有两种类型：\nAWS 托管规则：AWS 托管规则由 AWS 预先生成和管理。您可以选择希望启用的规则，然后提供一些配置参数即可开始使用。[了解更多 »](http://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed-rules.html)\n客户托管规则：客户托管规则为自定义规则，由您定义和生成。您可以在 AWS Lambda 中创建能够作为自定义规则的一部分来调用的函数，这些函数将在您的账户中应用。[了解更多 »](http://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_develop-rules.html)\n开始使用 AWS Config 最快捷的方式就是使用 AWS 管理控制台。几次选择即可启用 AWS Config。有关其他详细信息，请参阅[入门](http://docs.aws.amazon.com/config/latest/developerguide/gs-console.html)文档。"
    },
    {
        "query":"如何创建规则？",
        "intention":"知识问答",
        "reply":"规则通常由 AWS 账户管理员建立。可以利用 AWS 托管规则（由 AWS 提供的一组预定义规则）或通过客户托管规则创建它们。借助 AWS 托管规则，对规则进行的更新将自动应用于任何使用该规则的账户。在客户托管模型中，客户拥有规则的完整副本，并在自己的账户中应用该规则。这些规则由客户维护。"
    },
    {
        "query":"可以创建多少个规则？",
        "intention":"知识问答",
        "reply":"默认情况下，您在 AWS 账户中最多可以创建 150 个规则。此外，您可以访问 [AWS 服务限制](http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_config)页面，申请提高您的账户中的规则数量上限。"
    },
    {
        "query":"如何评估规则？",
        "intention":"知识问答",
        "reply":"任何规则都可以作为由更改触发的规则或作为定期规则建立。由更改触发的规则在 AWS Config 为任何指定资源记录配置更改后应用。此外，还必须指定以下项之一：\n定期规则以指定的频率启动。可用频率为 1 小时、3 小时、6 小时、12 小时或 24 小时。定期规则具有适用于该规则的所有资源当前配置项（CI）的完整快照。"
    },
    {
        "query":"什么是评估？",
        "intention":"知识问答",
        "reply":"规则的评估可确定某个规则是否在特定时间点与某个资源相符合。这是针对资源配置评估规则的结果。AWS Config 规则将捕获并存储每个评估的结果。此结果将包含资源、规则、评估时间和导致非合规的配置项（CI）链接。"
    },
    {
        "query":"合规性是什么意思？",
        "intention":"知识问答",
        "reply":"如果资源遵守了适用于其的所有规则，则该资源即为合规；否则，它就不合规。同样地，如果由规则评估的所有资源都符合该规则，则该规则为合规；否则，它就不合规。在某些情况下，例如为规则提供的权限不足时，可能不存在资源评估，从而导致数据不足的状态。此状态不能确定资源或规则的合规性状态。"
    },
    {
        "query":"AWS Config 规则控制面板提供哪些信息？",
        "intention":"知识问答",
        "reply":"AWS Config 规则控制面板为您提供由 AWS Config 跟踪的资源概述以及按资源和按规则显示的当前合规性摘要。当您按资源查看合规性时，您可以确定适用于资源的任何规则当前是否为非合规。您可以按规则查看合规性，这将向您显示规则范围下的任何资源当前是否为非合规。通过使用这些摘要视图，您可以进一步探索资源的 AWS Config 时间线视图，从而确定哪些配置参数发生变更。您可以使用此控制面板从概述开始了解，然后深入查看细化视图，该视图提供有关合规性状态以及哪些更改导致非合规的完整信息。"
    },
    {
        "query":"我应何时使用 AWS Config 规则和一致性包？>>",
        "intention":"知识问答",
        "reply":"您可以使用单个 AWS Config 规则来评估一个或多个账户中的资源配置合规性。一致性包提供了将规则以及补救措施打包到单个实体中的额外好处，只需一次选择即可将该单个实体部署到整个组织中。当您管理多个账户时，一致性包旨在简化合规性管理和大规模报告。一致性包旨在提供包级别的汇总合规性报告和不可变性。这有助于防止组织的个人成员账户修改或删除一致性包中的托管 AWS Config 规则和修复文档。"
    },
    {
        "query":"AWS Config 和 AWS Config 规则与 AWS Security Hub 有何关系？",
        "intention":"知识问答",
        "reply":"AWS Security Hub 是一项安全性与合规性服务，可以服务形式提供安全性与合规性状态管理。它将 AWS Config 和 AWS Config 规则用作其评估 AWS 资源配置的主要机制。AWS Config 规则还可以直接用于评估资源配置。AWS Config 规则也可以供其他 AWS 服务使用，如 AWS Control Tower 和 AWS Firewall Manager。"
    },
    {
        "query":"何时使用 AWS Security Hub 和 AWS Config 一致性包？",
        "intention":"知识问答",
        "reply":"如果 Security Hub 中已存在合规性标准（如 PCI DSS），则更加简单的实施方法是使用完全托管的 Security Hub 服务。您可以通过 Security Hub 与 Amazon Detective 的集成调查结果，并且还可以使用 Security Hub 与 Amazon EventBridge 的集成构建自动化或半自动化的修复操作。但是，如果您想要制定自己的合规性或安全性标准（其中可包括安全、运行或成本优化检查），则 AWS Config 一致性包是您的理想之选。AWS Config 一致性包可以将一组 AWS Config 规则和关联的修复操作打包到单个实体中，从而简化 AWS Config 规则的管理。此打包操作可以简化在组织中部署规则和修复操作。它还支持汇总报告，因为可以在包级别报告合规性摘要。您可以从我们提供的 AWS Config 一致性包示例入手，然后根据您的需要进行自定义。"
    },
    {
        "query":"Security Hub 和 AWS Config 一致性包是否均支持持续合规性监控？",
        "intention":"知识问答",
        "reply":"是，Security Hub 和 AWS Config 一致性包均支持持续合规性监控，前提是它们都依赖 AWS Config 和 AWS Config 规则。基础 AWS Config 规则可定期触发，也可以在检测到资源配置发生更改时触发。这可协助您持续审计和评估 AWS 资源配置在整体上是否符合您组织的策略和指南。"
    },
    {
        "query":"如何开始使用一致性包？",
        "intention":"知识问答",
        "reply":"最快的入门方法是通过 CLI 或 AWS Config 控制台使用我们的某个示例模板创建一致性包。其中一些示例模板包括 S3 操作最佳实践、Amazon DynamoDB 操作最佳实践和 PCI 操作最佳实践。这些模板是用 YAML 编写的。您可以从我们的文档站点下载这些模板，并使用自己喜欢的文本编辑器对其进行修改以适合您的环境。您甚至可以添加以前可能已写入包中的自定义 AWS Config 规则。"
    },
    {
        "query":"什么是多账户、多地区数据聚合？",
        "intention":"知识问答",
        "reply":"AWS Config 中的数据聚合功能可协助您将多个账户和区域的 AWS Config 数据聚合到单个账户和单个区域中。多账户数据聚合功能适合中央 IT 管理员使用，可以监控企业中多个 AWS 账户的合规性。"
    },
    {
        "query":"我能否使用数据聚合功能跨多个账户集中预置 AWS Config 规则？",
        "intention":"知识问答",
        "reply":"数据聚合功能不能用于跨多个账户预置规则。它只是一种报告功能，供您了解合规性信息。您可以使用 [AWS CloudFormation StackSets](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/stacksets-concepts.html) 跨账户和地区预置规则。要了解更多信息，请参阅此[博客链接](https://aws.amazon.com/blogs/aws/use-cloudformation-stacksets-to-provision-resources-across-multiple-aws-accounts-and-regions/)。"
    },
    {
        "query":"如何在账户中启用数据聚合功能？",
        "intention":"知识问答",
        "reply":"如果您在账户中启用了 AWS Config 和 AWS Config 规则，并且账户经过聚合，您便可通过在账户中创建聚合器来启用数据聚合功能。[了解更多](https://docs.aws.amazon.com/config/latest/developerguide/setup-aggregator-console.html)。"
    },
    {
        "query":"什么是聚合器？",
        "intention":"知识问答",
        "reply":"聚合器是一种 AWS Config 资源类型，可从多个账户和地区收集 AWS Config 数据。您可以使用聚合器来查看 AWS Config 中针对多个账户和地区记录的资源配置和合规性数据。"
    },
    {
        "query":"聚合视图提供哪些信息？",
        "intention":"知识问答",
        "reply":"聚合视图将显示整个组织的非合规规则总数、按资源数排序的前五个非合规规则以及具有最多非合规规则的前五个 AWS 账户。然后，您可以深入查看有关违反规则的资源的更多详细信息以及账户违反的规则列表。"
    },
    {
        "query":"我不是 AWS Organizations 客户，还能使用数据聚合功能吗？",
        "intention":"知识问答",
        "reply":"您可以通过上传文件或单独输入账户来指定要聚合其 AWS Config 数据的账户。请注意，这些账户不属于任何 AWS 组织，因此您需要让每个账户均显式授权聚合器账户。[了解更多](https://docs.aws.amazon.com/config/latest/developerguide/authorize-aggregator-account-console.html)。"
    },
    {
        "query":"我只有一个账户，还能使用数据聚合功能吗？",
        "intention":"知识问答",
        "reply":"数据聚合功能对于多地区聚合也很有用。因此，您可以使用该功能跨多个地区聚合您账户的 AWS Config 数据。"
    },
    {
        "query":"多账户、多区域数据聚合功能可在哪些区域使用？",
        "intention":"知识问答",
        "reply":"有关提供多账户、多区域数据聚合的区域的详细信息，请访问 AWS Config 开发人员指南：[多账户多区域数据聚合](https://docs.aws.amazon.com/config/latest/developerguide/aggregate-data.html)。"
    },
    {
        "query":"如果我的账户包含一个不受该功能支持的区域，该怎么办？",
        "intention":"知识问答",
        "reply":"在创建聚合器时，您需要指定可从其聚合数据的区域。该[列表](https://docs.aws.amazon.com/config/latest/developerguide/aggregate-data)仅显示可以使用该功能的区域。您还可以选择“所有区域”，在这种情况下，只要在其他区域添加支持，它就会自动聚合数据。"
    },
    {
        "query":"AWS Config 覆盖了哪些 AWS 资源类型？",
        "intention":"知识问答",
        "reply":"有关受支持资源类型的完整列表，请查看我们的[文档](http://docs.aws.amazon.com/config/latest/developerguide/resource-config-reference.html#supported-resources)。"
    },
    {
        "query":"AWS Config 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"有关已推出 AWS Config 的 AWS 区域的更多信息，请参阅 [AWS 区域](http://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)表。"
    },
    {
        "query":"什么是配置项？",
        "intention":"知识问答",
        "reply":"配置项（CI）指的是一项资源在给定时间点的配置。CI 由五个部分组成：\n[了解有关配置项的更多信息。](http://docs.aws.amazon.com/config/latest/developerguide/resource-config-reference.html#config-item-table)"
    },
    {
        "query":"什么是自定义配置项？",
        "intention":"知识问答",
        "reply":"自定义配置项 (CI) 是第三方或自定义资源的 CI。示例包括本地数据库、Active Directory 服务器、版本控制系统（如 GitHub）和第三方监视工具（如 Datadog）。"
    },
    {
        "query":"什么是 AWS Config 关系，如何使用它们？",
        "intention":"知识问答",
        "reply":"当记录更改时，AWS Config 会将资源之间的关系考虑进去。例如，如果新的 EC2 安全组与 EC2 实例相关联，AWS Config 会在主要资源（EC2 安全组）和相关资源发生更改时，记录它们更新后的配置。"
    },
    {
        "query":"AWS Config 会记录资源曾经历的每一个状态吗？",
        "intention":"知识问答",
        "reply":"AWS Config 检测资源配置的更改并记录由更改导致的配置状态。如果接二连三地对资源进行多次配置更改，则 AWS Config 将只记录代表这一组更改累积影响的最终配置。在这些情况下，AWS Config 将只在配置项的 relatedEvents 字段列出最近的更改。这可协助用户和计划继续更改基础设施配置，而不必等待 AWS Config 记录中级瞬态。"
    },
    {
        "query":"AWS Config 会记录不是由该资源的 API 活动引起的配置更改吗？",
        "intention":"知识问答",
        "reply":"会。AWS Config 将定期扫描资源配置，以获取尚未记录的更改并记录这些更改。从这些扫描记录的 CI 在消息中没有 *relatedEvent* 字段，并且将仅选择尚未记录的最新状态进行记录。"
    },
    {
        "query":"AWS Config 能否记录 EC2 实例中软件的配置更改？",
        "intention":"知识问答",
        "reply":"可以。AWS Config 协助您记录 AWS 账户中的 EC2 实例内软件的配置更改，还可记录本地环境中虚拟机（VM）或服务器的配置更改。AWS Config 记录的配置信息包括操作系统更新、网络配置和已安装的应用程序。您可以使用 AWS Config 规则来评估您的实例、虚拟机和服务器是否符合相关指南。借助 AWS Config 提供的深入洞察和持续监控功能，您可以评估资源的合规情况，并针对操作问题进行故障排除。"
    },
    {
        "query":"如果在您进行定期规则评估后，之前不合规的某项资源仍不合规，AWS Config 是否会继续发送通知？",
        "intention":"知识问答",
        "reply":"只有在合规状态改变后，AWS Config 才会发送通知。如果之前不合规的某项资源仍不合规，AWS Config 不会发送新通知。如果合规状态更改为“合规”，您将会收到关于状态更改的通知。"
    },
    {
        "query":"我能否标记、豁免或排除某些资源，以使它们免受 AWS Conﬁg 规则的评估？",
        "intention":"知识问答",
        "reply":"是的，您可以排除某些资源，方法是在控制台中导航到 AWS Conﬁg 的“记录器设置”页面，选择“排除资源类型”选项并指定所需的排除项。或者，您也可以使用 [PutConfigurationRecorder](https://docs.aws.amazon.com/config/latest/APIReference/API_PutConfigurationRecorder.html) API 来访问此功能。此 API 将禁用该资源类型的配置记录。此外，在配置 AWS Conﬁg 规则时，您可以指定您的规则是否评估指定的资源或带有特定标记的资源。"
    },
    {
        "query":"我想更改我的自定义 AWS Config 规则的 Lambda 函数。建议方法是什么？",
        "intention":"知识问答",
        "reply":"每当创建新规则且新规则处于活动状态时，都会产生费用。如果您必须更新或替换与规则关联的 Lambda 函数，建议的方法是更新规则，而不是将其删除并创建新规则。"
    },
    {
        "query":"AWS Config 可用哪些 AWS 合作伙伴解决方案？",
        "intention":"知识问答",
        "reply":"APN 合作伙伴解决方案（如 Splunk、ServiceNow、Evident.io、CloudCheckr、Redseal 和 Red Hat CloudForms）提供与 AWS Config 中的数据完全集成的服务。2nd Watch 和 CloudNexa 之类的托管服务提供商发布了与 AWS Config 的集成。此外，借助 AWS Config 规则，CloudHealth Technologies、Alert Logic 和 Trend Micro 等合作伙伴还可以提供可使用的集成式产品/服务。这些解决方案包括更改管理和安全分析等功能，可协助您可视化、监控和管理 AWS 资源配置。\n[单击此处了解更多信息](https://aws.amazon.com/config/partners/)。\n了解有关 AWS Config 的更多信息"
    },
    {
        "query":"What is Amazon Textract?",
        "intention":"知识问答",
        "reply":"Amazon Textract is a document analysis service that detects and extracts printed text, handwriting, structured data (such as fields of interest and their values) and tables from images and scans of documents. Amazon Textract's machine learning models have been trained on millions of documents so that virtually any document type you upload is automatically recognized and processed for text extraction. When information is extracted from documents, the service returns a confidence score for each element it identifies so that you can make informed decisions about how you want to use the results. For instance, if you are extracting information from tax documents you can set custom rules to flag any extracted information with a confidence score lower than 95%. Also, all extracted data are returned with bounding box coordinates, which is a rectangular frame that fully encompasses each piece of data identified, so that you can quickly identify where a word or number appears on a document. You can access these features with the Amazon Textract API, in the AWS Management Console, or using the AWS command-line interface (CLI)."
    },
    {
        "query":"What are the most common use cases for Amazon Textract?",
        "intention":"知识问答",
        "reply":"The most common use cases for Amazon Textract include:"
    },
    {
        "query":"What type of text can Amazon Textract detect and extract?",
        "intention":"知识问答",
        "reply":"Amazon Textract can detect printed text and handwriting from the Standard English alphabet and ASCII symbols. Amazon Textract can extract printed text, forms and tables in English, German, French, Spanish, Italian and Portuguese. Amazon Textract also extracts explicitly labeled data, implied data, and line items from an itemized list of goods or services from almost any invoice or receipt in English without any templates or configuration. Amazon Textract can also extract specific or implied data such as names and addresses from identity documents in English such as U.S. passports and driver’s licenses without the need for templates or configuration. Finally, Amazon Textract can extract any specific data from documents without worrying about the structure or variations of the data in the document using Queries in English."
    },
    {
        "query":"What document formats does Amazon Textract support?",
        "intention":"知识问答",
        "reply":"Amazon Textract currently supports PNG, JPEG, TIFF, and PDF formats. For synchronous APIs, you can submit images either as an S3 object or as a byte array. For asynchronous APIs, you can submit S3 objects. If your document is already in one of the file formats that Amazon Textract supports (PDF, TIFF, JPG, PNG), don't convert or downsample it before uploading it to Amazon Textract."
    },
    {
        "query":"How do I get started with Amazon Textract?",
        "intention":"知识问答",
        "reply":"To get started with Amazon Textract, you can click the “Get Started with Amazon Textract” button on the [Amazon Textract page](https://aws.amazon.com/textract/). You must have an Amazon Web Services account; if you do not already have one, you will be prompted to create one during the process. Once you are signed in to your AWS account, try out Amazon Textract with your own images or PDF documents using the [Amazon Textract Management Console](https://console.aws.amazon.com/textract/). You can also download the [Amazon Textract SDKs](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/Textract.html) to start creating your own applications. Please refer to our step-by-step [Getting Started Guide](http://docs.aws.amazon.com/textract/latest/dg/what-is.html) for more information."
    },
    {
        "query":"What APIs does Amazon Textract offer?",
        "intention":"知识问答",
        "reply":"Amazon Textract offers APIs that detect and extract printed text and handwriting from scanned images of documents, extract structured data such as tables, perform key-value pairing on extracted text, and separate APIs focused on extracting data from invoices, receipts, and identity documents.\nAmazon Textract performs OCR using the Detect Document Text API, but goes a step further in the document analyzing process and also performs key-value pair detection so that text extractions remain organized in their intended structure. The Analyze Document API can detect printed text, handwriting, fields, values, their relationships, tables, and other entities within a document along with their associated confidence scores. With the Analyze Document API, developers can automatically capture structured data from a wide variety of documents including tax forms, financial reports, medical records, and loan applications. Analyze Document API also provides developers the flexibility to specify the data they need to extract from documents using Queries without worrying about the structure of the data or variations in how the data is laid out across different formats and versions of the document. The Analyze Expense API can find the vendor name on a receipt even if it's only indicated within a logo on the page without an explicit label called “vendor”. It can also find and extract item, quantity, and prices that are not labeled with column headers for line items. With the Analyze Expense API, developers can used normalized key names and column headers when extracting data from invoices and receipts so that downstream applications can easily compare output from many documents. The Analyze ID API understands the context of identity documents such as U.S. passports and driver’s licenses without the need for templates or configuration. Using Analyze ID, businesses providing ID verification services and those in finance, healthcare, and insurance can easily automate account creation, appointment scheduling, employment applications, and more by allowing customers to submit a picture or scan of their identity document. For details, please refer to the [Amazon Textract API](https://docs.aws.amazon.com/textract/latest/dg/API_Reference.html) reference."
    },
    {
        "query":"What features does the Analyze Document API have?",
        "intention":"知识问答",
        "reply":"Analyze Document API has three features – Forms, Tables and Queries. You can use these features independently or use any combination of these features together. Use Forms to extract data such as key-value pairs (e.g., “First Name” and associated value “Jane Smith”). Use Tables to extract tabular or table data organized in columns and rows. Use Queries to specify the information you need from a document in the form of natural language questions (e.g., “What is the customer name?”) and receive the answer (e.g., “Jane Doe”) as part of the response."
    },
    {
        "query":"How should customers construct/craft/word queries?",
        "intention":"知识问答",
        "reply":"We have published detailed guidance on best practices for crafting Queries as part of our [API Documentation](https://docs.aws.amazon.com/textract/latest/dg/what-is.html) on the Textract Resources page. In general, customers should try to ask a natural language question utilizing words from the document to construct a query."
    },
    {
        "query":"Are there any limits to the number of Queries I can ask per document?",
        "intention":"知识问答",
        "reply":"Queries are processed on a per page basis and information can be extracted using Queries via both synchronous or asynchronous operations. For synchronous operations, a maximum of 15 Queries per page is supported. For asynchronous operations, a maximum of 30 queries per page is supported."
    },
    {
        "query":"How can I get the best results from Amazon Textract?",
        "intention":"知识问答",
        "reply":"Amazon Textract uses machine learning to read virtually any type of document in order to extract printed text, handwriting, and structured information. Keep the following tips in mind in order to get the best results:\nYou can get started with analyzing you own documents with Amazon Textract with just a few clicks in the [Amazon Textract Management Console](https://console.aws.amazon.com/textract/). If you have trouble achieving high accuracy with receipts, identification, or industrial diagrams, please contact us on [amazon-textract@amazon.com](mailto:amazon-textract@amazon.com) for assistance."
    },
    {
        "query":"How do I use the confidence score Amazon Textract provides?",
        "intention":"知识问答",
        "reply":"A confidence score is a number between 0 and 100 that indicates the probability that a given prediction is correct. With Amazon Textract, all extracted printed text, handwriting, and structured data are returned with bounding box coordinates, which is a rectangular frame that fully encompasses each piece of data identified. This allows you to identify the score for each extracted entity so that you can make informed decisions on how you want to use the results."
    },
    {
        "query":"How can I get Amazon Textract predictions reviewed by humans?",
        "intention":"知识问答",
        "reply":"Amazon Textract is directly integrated with Amazon Augmented AI (A2I) so you can easily get low confidence predictions from Amazon Textract reviewed by humans. Using Amazon Textract’s API for form data extraction and the Amazon A2I console, you can specify the conditions under which Amazon A2I routes predictions to reviewers, which can be either a confidence threshold or a random sampling percentage. If you specify a confidence threshold, Amazon A2I routes only those predictions that fall below the threshold for human review. You can adjust these thresholds at any time to achieve the right balance between accuracy and cost-effectiveness. Alternatively, if you specify a sampling percentage, Amazon A2I routes a random sample of the predictions for human review. This can help you implement audits to monitor the prediction accuracy regularly. Amazon A2I also provides reviewers a web interface consisting of all the instructions and tools they need to complete their review tasks. For more information about implementing human review with Amazon Textract, see the [Amazon A2I website](https://aws.amazon.com/augmented-ai/)."
    },
    {
        "query":"In which AWS regions is Amazon Textract available?",
        "intention":"知识问答",
        "reply":"Amazon Textract is currently available in the US East (Northern Virginia), US East (Ohio), US West (Oregon), US West (N. California), AWS GovCloud (US-West), AWS GovCloud (US-East), Canada (Central), EU (Ireland), EU (London), EU (Frankfurt), EU (Paris), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Seoul), and Asia Pacific (Mumbai) Regions."
    },
    {
        "query":"Does Amazon Textract work with AWS CloudTrail?",
        "intention":"知识问答",
        "reply":"Yes. Amazon Textract supports logging of the following actions as CloudTrail events - DetectDocumentText, AnalyzeDocument, StartDocumentTextDetection, StartDocumentAnalysis, GetDocumentTextDetection, and GetDocumentAnalysis. For more details, please see [Logging Amazon Textract API Calls with AWS CloudTrail](https://docs.aws.amazon.com/textract/latest/dg/logging-using-cloudtrail.html)."
    },
    {
        "query":"How does Amazon Textract count the number of pages processed?",
        "intention":"知识问答",
        "reply":"An image (PNG, TIFF, or JPEG) counts as a single page. For PDFs, each page in the document is counted as a page processed."
    },
    {
        "query":"Which APIs am I charged for with Amazon Textract?",
        "intention":"知识问答",
        "reply":"Refer to the Amazon Textract [pricing page](https://aws.amazon.com/textract/pricing/) to learn more about pricing."
    },
    {
        "query":"How much does Amazon Textract cost?",
        "intention":"知识问答",
        "reply":"Amazon Textract charges you based on the number of pages and images processed. For more information, visit the [pricing page](https://aws.amazon.com/textract/pricing/)."
    },
    {
        "query":"Does Amazon Textract participate in the AWS Free Tier?",
        "intention":"知识问答",
        "reply":"Yes. As part of the [AWS Free Tier](https://aws.amazon.com/free/), you can get started with Amazon Textract for free. The Free Tier lasts for three months, and new AWS customers can analyze up to:  \n   \n Detect Document Text API: 1,000 pages per month  \n Analyze Document API:\nAnalyze Expense API: 100 pages per month  \n Analyze ID API: 100 pages per month"
    },
    {
        "query":"Do your prices include taxes?",
        "intention":"知识问答",
        "reply":"For details on taxes, please see [Amazon Web Services Tax Help](https://aws.amazon.com/tax-help/)."
    },
    {
        "query":"Are document and image inputs processed by Amazon Textract stored, and how are they used by AWS?",
        "intention":"知识问答",
        "reply":"Amazon Textract may store and use document and image inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Textract and other Amazon machine-learning/artificial-intelligence technologies. Use of your content is necessary for continuous improvement of your Amazon Textract customer experience, including the development and training of related technologies. We do not use any personally identifiable information that may be contained in your content to target products, services or marketing to you or your end users. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see <https://aws.amazon.com/compliance/data-privacy-faq/> for more information. You may opt out of having your document and image inputs used to improve or develop the quality of Amazon Textract and other Amazon machine-learning/artificial-intelligence technologies using an AWS Organizations opt-out policy. For information about how to opt out, see [Managing AI services opt-out policy](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)."
    },
    {
        "query":"Is the content processed by Amazon Textract moved outside the AWS region where I am using Amazon Textract?",
        "intention":"知识问答",
        "reply":"Any content processed by Amazon Textract is encrypted and stored at rest in the AWS region where you are using Amazon Textract. Unless you opt out as provided below, some portion of content processed by Amazon Textract may be stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Textract customer experience and other Amazon machine-learning/artificial-intelligence technologies. You can request deletion of image and video inputs associated with your account by contacting AWS Support. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see <https://aws.amazon.com/compliance/data-privacy-faq/> for more information. Your content will not be stored in another AWS region if you opt out of having your content used to improve and develop the quality of Amazon Textract and other Amazon machine-learning/artificial-intelligence technologies. For information about how to opt out, see [Managing AI services opt-out policy](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)."
    },
    {
        "query":"Can I delete images and documents stored by Amazon Textract?",
        "intention":"知识问答",
        "reply":"Yes. You can request deletion of document and image inputs associated with your account by contacting AWS Support. Deleting image and document inputs may degrade your Amazon Textract experience."
    },
    {
        "query":"Who has access to my content that is processed and stored by Amazon Textract?",
        "intention":"知识问答",
        "reply":"Only authorized employees will have access to your content that is processed by Amazon Textract. Your trust, privacy, and the security of your content are our highest priority, and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see <https://aws.amazon.com/compliance/data-privacy-faq/> for more information.\nQ: Do I still own my content that is processed and stored by Amazon Textract?\nYes. You always retain ownership of your content, and we will only use your content with your consent."
    },
    {
        "query":"Is Amazon Textract HIPAA eligible?",
        "intention":"知识问答",
        "reply":"Yes, AWS has expanded its HIPAA compliance program to include Amazon Textract as a HIPAA eligible service. If you have an executed Business Associate Agreement (BAA) with AWS, you can use Amazon Textract to extract text including protected health information (PHI) from images.\n[Learn more about HIPAA Compliance »](https://aws.amazon.com/compliance/hipaa-compliance/)"
    },
    {
        "query":"What Compliance Programs are in scope for Amazon Textract?",
        "intention":"知识问答",
        "reply":"Textract is HIPAA eligible, and compliant with PCI, ISO, and SOC. For more information please visit AWS Artifact in the AWS Management Console, or visit [https://aws.amazon.com/compliance/services-in-scope/](https://aws.amazon.com/compliance/services-in-scope/). Textract also supports Amazon [Virtual Private Cloud](https://aws.amazon.com/vpc/) (Amazon VPC) endpoints via [AWS PrivateLink](https://aws.amazon.com/privatelink/), enabling customers to securely initiate API calls to Amazon Textract from within their VPC and avoid using the public internet."
    },
    {
        "query":"什么是 Amazon Virtual Private Cloud？",
        "intention":"知识问答",
        "reply":"Amazon VPC 允许您在 Amazon Web Services (AWS) 云中预置出一个逻辑隔离的部分，让您在自己定义的虚拟网络中启动 AWS 资源。您可以完全掌控您的虚拟网络环境，包括选择自己的 IP 地址范围、创建子网以及配置路由表和网络网关。您也可以在公司数据中心和 VPC 之间创建硬件虚拟专用网络 (VPN) 连接，将 AWS 云用作公司数据中心的扩展。\n您可以轻松自定义 Amazon VPC 的网络配置。例如，您可以为可访问 Internet 的 Web 服务器创建公有子网，而将数据库或应用程序服务器等后端系统放在不能访问 Internet 的私有子网中。您可以利用安全组和网络访问控制列表等多种安全层，帮助对各个子网中 Amazon EC2 实例的访问进行控制。"
    },
    {
        "query":"Amazon VPC 有哪些组成部分？",
        "intention":"知识问答",
        "reply":"Amazon VPC 由多个不同的对象组成，它们对拥有现有网络的客户而言并不陌生："
    },
    {
        "query":"从 VPC 中的 Amazon EC2 实例使用 Amazon S3 等其他 AWS 产品会产生哪些使用费？",
        "intention":"知识问答",
        "reply":"对包括 Amazon EC2 在内的其他 Amazon Web Services 的使用依然按照公布的费率收取费用。通过 VPC 的互联网网关访问 Amazon S3 等 Amazon Web Services 时，不会产生数据传输费用。\n如果您通过 VPN 连接访问 AWS，则会产生 Internet 数据传输费用。"
    },
    {
        "query":"Amazon VPC 有哪些连接选项？",
        "intention":"知识问答",
        "reply":"您可以将 Amazon VPC 连接到："
    },
    {
        "query":"Amazon VPC 中可以使用哪些 IP 地址范围？",
        "intention":"知识问答",
        "reply":"您可以使用主 CIDR 块的任意 [IPv4](http://en.wikipedia.org/wiki/IPv4) 地址范围，其中包括 [RFC 1918](https://tools.ietf.org/html/rfc1918) 或公有可路由 IP 范围。对于辅助 CIDR 块，则存在一些[限制](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html#add-cidr-block-restrictions)。 对于公有可路由 IP 数据块，只能通过虚拟私有网关进行访问，无法通过互联网网关从 Internet 访问。 AWS 并不向 Internet 公告客户自有的 IP 地址数据块。通过调用相关 API 或通过 AWS 管理控制台，您可以向 VPC 分配最多 5 个由 Amazon 提供的或 BYOIP 的 IPv6 GUA CIDR 块。"
    },
    {
        "query":"如何向 Amazon VPC 分配 IP 地址范围？",
        "intention":"知识问答",
        "reply":"您可在创建 VPC 时将单个[无类别互联网域路由 (CIDR)](http://en.wikipedia.org/wiki/CIDR) IP 地址范围指定为主 CIDR 块，并在 VPC 创建完成后添加最多四 (4) 个辅助 CIDR 块。您可以从这些 CIDR 范围内为 VPC 中的子网寻址。请注意，虽然您可以创建 IP 地址范围重叠的多个 VPC，但这样做会妨碍您通过硬件 VPN 连接将这些 VPC 与常用的家庭网络连接。因此，我们建议您不要使用重叠的 IP 地址范围。您可以向 VPC 分配最多 5 个由 Amazon 提供的或 BYOIP 的 IPv6 CIDR 块。"
    },
    {
        "query":"分配至默认 Amazon VPC 的 IP 地址范围是什么？",
        "intention":"知识问答",
        "reply":"默认 VPC 分配有 172.31.0.0/16 的 CIDR 范围。每个默认 VPC 中的默认子网分配有 VPC CIDR 范围内的 /20 个网块。"
    },
    {
        "query":"能否向互联网公告我的 VPC 公有 IP 地址范围，并将通过我的数据中心的流量从 AWS 站点到站点 VPN 路由到我的 Amazon VPC？",
        "intention":"知识问答",
        "reply":"能。您可以通过 AWS 站点到站点 VPN 连接路由流量，也可从家庭网络公告该地址范围。"
    },
    {
        "query":"是否可以在 VPC 中使用我的 IP 地址并通过 Internet 访问它们？",
        "intention":"知识问答",
        "reply":"可以。您可以在 AWS VPC 中使用您的公有 IPv4 地址和 IPv6 GUA 地址，并将它们静态分配给子网和 EC2 实例。如需通过 Internet 访问这些地址，您必须通过本地网络将它们公告到 Internet。您还必须在 VPC 和本地网络之间使用 AWS DX 或 AWS VPN 连接，路由这些地址上的流量。您可以使用虚拟私有网关路由来自 VPC 的流量。同样，您可以使用路由器将来自本地网络的流量路由回 VPC。"
    },
    {
        "query":"可以创建多大的 VPC？",
        "intention":"知识问答",
        "reply":"目前，Amazon VPC 支持五 (5) 个 IP 地址范围，一 (1) 个主和四 (4) 个辅助 IPv4 IP 地址范围。每一个范围的大小都介于 /28（CIDR 表示法）和 /16 之间。VPC 的 IP 地址范围不能与现有网络的 IP 地址范围重叠。\n对于 IPv6，VPC 使用 /56 的固定大小（CIDR 表示法）。VPC 可以同时有 IPv4 和 IPv6 CIDR 块与其关联。"
    },
    {
        "query":"我可以更改 VPC 的大小吗？",
        "intention":"知识问答",
        "reply":"可以。您可以通过向现有 VPC 添加四 (4) 个辅助 IPv4 IP 范围 (CIDR) 来扩展 VPC。您也可以通过删除已添加到 VPC 的辅助 CIDR 块来缩小 VPC。  类似地，您可以向 VPC 添加五个 (5) 其他的 IPv6 IP 范围 (CIDR)。  您可以通过删除这些其他范围来缩小 VPC。"
    },
    {
        "query":"每个 VPC 可以创建多少个子网？",
        "intention":"知识问答",
        "reply":"目前，每个 VPC 可以创建 200 个子网。如果您希望创建更多子网，请[在支持中心提交案例](https://aws.amazon.com/contact-us/vpc-request/)。"
    },
    {
        "query":"子网的大小是否有限制？",
        "intention":"知识问答",
        "reply":"对于 IPv4，子网的大小下限为 /28（或 14 个 IP 地址）。子网的大小不能超过在其中创建它们的 VPC。\n对于 IPv6，子网大小固定为 /64。仅可将一个 IPv6 CIDR 块分配给一个子网。"
    },
    {
        "query":"可否使用分配给某个子网的所有 IP 地址？",
        "intention":"知识问答",
        "reply":"不可以。Amazon 会保留各个子网的前面四 (4) 个 IP 地址和最后一 (1) 个 IP 地址，以作 IP 联网之用。"
    },
    {
        "query":"如何将私有 IP 地址分配给 VPC 中的 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"启动非仅 IPv6 的子网中的 Amazon EC2 实例时，您可以选择指定该实例的主要私有 IPv4 地址。如果不指定主要私有 IPv4 地址，AWS 将从您分配给该子网的 IPv4 地址范围中自动寻址。您可以在以下时间分配辅助私有 IPv4 地址：启动实例时、创建弹性网络接口时，或者启动实例后或创建该接口后的任意时间。当您在仅 IPv6 子网中启动 Amazon EC2 实例时，AWS 自动从该子网的 Amazon 提供的 IPv6 GUA CIDR 中为其寻址。该实例的 IPv6 GUA 仍将保持私有，除非您通过正确的安全组、NACL 和路由表配置使其与互联网相互可达。"
    },
    {
        "query":"可否在 VPC 中的 Amazon EC2 实例运行和/或停止时，更改其私有 IP 地址？",
        "intention":"知识问答",
        "reply":"对于在 IPv4 或双堆栈子网中启动的实例，主要私有 IPv4 地址在该实例或接口的寿命周期中一直保留。辅助私有 IPv4 地址则可随时分配、取消分配，或者在接口或实例之间移动。对于在仅 IPv6 子网中启动的实例，分配的 IPv6 GUA 也是该实例主要子网接口上的第一个 IP 地址，随时可通过关联新 IPv6 GUA 并删除现有 IPv6 GUA 进行修改。"
    },
    {
        "query":"如果停止了 VPC 中的 Amazon EC2 实例，可否在同一 VPC 中启动 IP 地址相同的另一实例？",
        "intention":"知识问答",
        "reply":"只有原先运行的实例处于“已终止”状态时，分配给其的 IPv4 地址才能用于其他实例。但是，分配给正在运行的实例的 IPv6 GUA 在其从该实例删除后，可以再次用于其他实例。"
    },
    {
        "query":"可否同时为多个实例分配 IP 地址？",
        "intention":"知识问答",
        "reply":"不可以，您只能一次为一个实例指定 IP 地址（在启动实例时指定）。"
    },
    {
        "query":"可否将任意 IP 地址分配给实例？",
        "intention":"知识问答",
        "reply":"只要 IP 地址满足以下条件，您便可以将其分配给实例："
    },
    {
        "query":"可否将多个 IP 地址分配给一个实例？",
        "intention":"知识问答",
        "reply":"可以。您可以将一个或多个辅助私有 IP 地址分配给 Amazon VPC 中的弹性网络接口或 EC2 实例。您可以分配的辅助私有 IP 地址的数量取决于实例类型。有关可以按不同实例类型分配的辅助私有 IP 地址数量的更多信息，请参阅 [EC2 用户指南](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html)。"
    },
    {
        "query":"可否将一个或多个弹性 IP (EIP) 地址分配给基于 VPC 的 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"可以。不过，这些 EIP 地址只能从 Internet 访问（不能通过 VPN 连接访问）。每个 EIP 地址必须与实例上的一个唯一私有 IP 地址关联。EIP 地址只应该在被配置为将流量直接路由到互联网网关的子网中的实例上使用。EIP 无法用于配置为使用 NAT 网关或 NAT 实例访问 Internet 的子网中的实例。这仅适用于 IPv4。目前，Amazon VPC 不支持用于 IPv6 的 EIP。"
    },
    {
        "query":"什么是自带 IP 功能？",
        "intention":"知识问答",
        "reply":"借助自带 IP (BYOIP)，客户能够将现有可公共路由的全部或部分 IPv4 或 IPv6 地址空间迁移到 AWS，以便与 AWS 资源一起使用。客户将继续拥有 IP 范围。客户可以从他们迁入 AWS 的 IPv4 空间创建弹性 IP，并将其与 EC2 实例、NAT 网关和 Network Load Balancer 结合使用。此外，客户还可以从他们引入 AWS 的 IPv6 空间将最多 5 个 CIDR 关联到 VPC。客户将持续拥有访问 Amazon 提供 IP 的权限，并可选择使用 BYOIP 弹性 IP、Amazon 提供的 IP 或同时使用二者。"
    },
    {
        "query":"问：为什么应该使用 BYOIP？",
        "intention":"知识问答",
        "reply":"由于以下原因，您可能需要将自己的 IP 地址引入 AWS：  \n IP 声誉：许多客户认为其 IP 地址声誉是一项战略资产，希望在 AWS 上使用这些 IP 及其资源。例如，拥有出站电子邮件 MTA 等服务且 IP 声誉较高的客户现在可以引入自己的 IP 空间，并继续保持其现有发送成功率。\n客户白名单：借助 BYOIP，客户还可以将依赖 IP 地址白名单的工作负载迁移到 AWS，而无需使用新的 IP 地址重新建立白名单。\n硬编码依赖项：一些客户在设备中使用硬编码 IP 或对其 IP 采用了架构依赖项。BYOIP 使这类客户能够轻松迁移到 AWS。\n监管和合规性：出于监管和合规性原因，许多客户必须使用特定 IP。他们也可以使用 BYOIP 来解除这一限制。\n本地 IPv6 网络策略：许多客户只能在本地网络上路由其 IPv6。这些客户可以通过 BYOIP 解除这一限制，因为他们可以将自己的 IPv6 范围分配给 VPC，并选择使用 Internet 或 Direct Connect 路由至本地网络。"
    },
    {
        "query":"问：如何结合使用 BYOIP 前缀中的 IP 地址与 AWS 资源？",
        "intention":"知识问答",
        "reply":"BYOIP 前缀在您的账户中显示为一个 IP 池。您可以从 IPv4 池创建弹性 IP (EIP)，并像使用常规弹性 IP (EIP) 一样将其与任何 AWS 资源（支持 EIP）结合使用。目前，支持 EIP 的 AWS 资源有 EC2 实例、NAT 网关和网络负载均衡器。您可以通过 IPv6 池将 CIDR 关联到 VPC。通过 BYOIP 引入的 IPv6 地址的工作方式与 Amazon 提供的 IPv6 地址的工作方式完全相同。例如，您可以将这些 IPv6 地址关联到 VPC 内的子网、弹性网络接口 (ENI) 和 EC2 实例。"
    },
    {
        "query":"问：如果发布 BYOIP 弹性 IP 会怎样？",
        "intention":"知识问答",
        "reply":"发布 BYOIP 弹性 IP 时，它会返回来源 BYOIP 的 IP 池。"
    },
    {
        "query":"哪些 AWS 区域提供 BYOIP？",
        "intention":"知识问答",
        "reply":"此功能现已在以下区域推出：非洲（开普敦）、亚太地区（香港）、亚太地区（雅加达）、亚太地区（孟买）、亚太地区（大坂）、亚太地区（悉尼）、亚太地区（东京）、亚太地区（首尔）、亚太地区（新加坡）、加拿大（中部）、欧洲地区（都柏林）、欧洲地区（法兰克福）、欧洲地区（伦敦）、欧洲地区（米兰）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、中东（巴林）、中东（UAE）、南美洲（圣保罗）、美国西部（北加利福尼亚）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（俄勒冈州）、AWS GovCloud（美国西部）、AWS GovCloud（美国东部）。"
    },
    {
        "query":"问：可以与同一账户中的多个 VPC 共享 BYOIP 前缀吗？",
        "intention":"知识问答",
        "reply":"可以。您可以对同一账户中任意数量的 VPC 使用此 BYOIP 前缀。"
    },
    {
        "query":"问：我可以通过 BYOIP 引入多少个 IP 范围？",
        "intention":"知识问答",
        "reply":"您最多可以将五个 IP 范围引入您的账户。"
    },
    {
        "query":"我可以通过 BYOIP 引入的最具体的前缀是什么？",
        "intention":"知识问答",
        "reply":"通过 BYOIP，您可以引入的最具体的 IPv4 前缀是 /24 IPv4 前缀和 /56 IPv6 前置。如果想要将 Ipv6 前缀通告至 Internet，则最具体的 IPv6 前缀为 /48。"
    },
    {
        "query":"我可以将哪些 RIR 前缀用于 BYOIP？",
        "intention":"知识问答",
        "reply":"您可以使用 ARIN、RIPE 和 APNIC 注册的前缀。"
    },
    {
        "query":"我可以引入重新分配的前缀吗？",
        "intention":"知识问答",
        "reply":"我们目前不接受重新分配的前缀。IP 范围应该只是一种直接分配的网络类型。"
    },
    {
        "query":"我是否可以将 BYOIP 前缀从一个 AWS 区域移动到另一个区域？",
        "intention":"知识问答",
        "reply":"可以。您可以从当前区域取消 BYOIP 前缀的预置，然后将它预置给新的区域。"
    },
    {
        "query":"可否指定哪个子网将用哪个网关作为其默认网关？",
        "intention":"知识问答",
        "reply":"可以。您可以为各个子网创建默认路由。默认路由可以指引流量通过互联网网关、虚拟私有网关或 NAT 网关从 VPC 传出。"
    },
    {
        "query":"如何确保在 VPC 中运行的 Amazon EC2 实例的安全？",
        "intention":"知识问答",
        "reply":"Amazon EC2 安全组可用来帮助确保 Amazon VPC 内实例的安全。VPC 中的安全组可用于指定允许进出各个 Amazon EC2 实例的进站和出站网络流量。没有被明确允许进出实例的流量将自动被拒绝。\n除了安全组外，也可以通过网络访问控制列表 (ACL) 来允许或拒绝进出各个子网的网络流量。"
    },
    {
        "query":"VPC 中的安全组和 VPC 中的网络 ACL 有什么区别？",
        "intention":"知识问答",
        "reply":"VPC 中的安全组指定允许传入或传出 Amazon EC2 实例的流量。网络 ACL 则在子网级别上运作，评估进出某个子网的流量。网络 ACL 可通过设置允许和拒绝规则来进行使用。Network ACL 不能筛选同一子网中实例之间的流量。此外，网络 ACL 执行无状态筛选，而安全组则执行有状态筛选。"
    },
    {
        "query":"有状态筛选和无状态筛选有什么区别？",
        "intention":"知识问答",
        "reply":"有状态筛选可跟踪请求的来源，并可自动允许将请求的回复返回到来源计算机。例如，允许入站流量进入 Web 服务器上的 TCP 端口 80 的有状态筛选器将允许返回流量（通常为编号较高的端口，如目标 TCP 端口 63、912）通过客户端与 Web 服务器之间的有状态筛选器。筛选设备维护一个状态表，跟踪来源和目标端口编号与 IP 地址。筛选设备上仅需要一条规则：允许流量进入 Web 服务器的 TCP 端口 80。\n无状态筛选则相反，仅检查来源或目标 IP 地址和目标端口，而忽略流量是新请求还是对请求的回复。上例中的筛选设备上需要实施两条规则：一条规则用于允许流量在 TCP 端口 80 上传入 Web 服务器，另一条规则用于允许流量传出 Web 服务器（TCP 端口范围 49、152 到 65、535）。"
    },
    {
        "query":"是否可以在 Amazon VPC 中使用为 Amazon EC2 中实例创建的 SSH 密钥对，而且反过来也可以？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"VPC 中的 Amazon EC2 实例可否与非 VPC 中的 Amazon EC2 实例通信？",
        "intention":"知识问答",
        "reply":"可以。如果配置了互联网网关，目标为位于 VPC 外部的 Amazon EC2 实例的 Amazon VPC 流量将遍历互联网网关，然后进入公有 AWS 网络以到达该 EC2 实例。如果没有配置互联网网关，或者如果实例位于被配置为通过虚拟私有网关路由的子网中，流量将遍历 VPN 连接，从您的数据中心中传出，然后再次进入公有 AWS 网络。"
    },
    {
        "query":"一个区域的 VPC 中的 Amazon EC2 实例可否与另一区域 VPC 中的 Amazon EC2 实例通信？",
        "intention":"知识问答",
        "reply":"可以。一个区域内的实例可使用区域间 VPC 对等连接、公有 IP 地址、NAT 网关、NAT 实例、VPN 连接或 Direct Connect 连接相互通信。"
    },
    {
        "query":"VPC 中的 Amazon EC2 实例可否与 Amazon S3 通信？",
        "intention":"知识问答",
        "reply":"可以。VPC 中的资源可通过多种方式与 Amazon S3 通信。您可以使用 S3 的 VPC 端点，它可确保将所有流量都保持在 Amazon 的网络中，并使您能够将其他访问策略应用于 Amazon S3 流量。您可以使用互联网网关从 VPC 对 Internet 进行访问，并且 VPC 中的实例可以与 Amazon S3 进行通信。您也可以让流向 Amazon S3 的所有流量遍历 Direct Connect 或 VPN 连接，再从数据中心流出，然后重新进入公共 AWS 网络。"
    },
    {
        "query":"是否可以监控我的 VPC 中的网络流量？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 Amazon VPC 流量镜像和 Amazon VPC 流日志功能监控 Amazon VPC 中的网络流量。"
    },
    {
        "query":"什么是 Amazon VPC 流日志？",
        "intention":"知识问答",
        "reply":"VPC 流日志是一项功能，允许您捕获有关进出 VPC 中网络接口的 IP 流量的信息。流日志数据可以发布到 Amazon CloudWatch Logs 或 Amazon S3 中。您可以监控 VPC 流日志，以获取对网络依赖性和流量模式的操作可见性，检测异常并防止数据泄露，或者对网络连接和配置问题进行故障排除。流日志中丰富的元数据可帮助您进一步了解谁发起了 TCP 连接，以及流经中间层（如 NAT 网关）的流量的实际数据包级源和目的地。您还可以存档流日志，以满足合规性要求。要了解更多有关 Amazon VPC 流日志的信息，请参阅[文档](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/flow-logs.html)。"
    },
    {
        "query":"如何使用 VPC 流日志？",
        "intention":"知识问答",
        "reply":"您可以为 VPC、子网或网络接口创建流日志。如果您为子网或 VPC 创建流日志，该子网或 VPC 中的每个网络接口都将被监控。创建流日志订阅时，您可以选择您想要捕获的元数据字段、最大聚合间隔和您的首选日志目的地。您还可以选择捕获所有流量或仅接受或拒绝流量。您可以使用 CloudWatch Log Insights 或 CloudWatch Contributor Insights 等工具分析传输到 CloudWatch Logs 的 VPC 流日志。您可以使用 Amazon Athena 或 AWS QuickSight 等工具查询和可视化传输到 Amazon S3 的 VPC 流日志。您还可以构建自定义下游应用程序以分析您的日志或使用 Splunk、Datadog、Sumo Logic、Cisco StealthWatch、Checkpoint CloudGuard、New Relic 等合作伙伴解决方案。"
    },
    {
        "query":"VPC 流日志是否支持 AWS Transit Gateway？",
        "intention":"知识问答",
        "reply":"支持，您可以为 Transit Gateway 或单独的中转网关连接创建 VPC 流日志。通过此功能，Transit Gateway 可以导出详细的信息，如源/目标 IP 地址、端口、协议、流量计数器、时间戳以及通过 Transit Gateway 遍历的网络流的各种元数据。要了解有关 Amazon VPC 流日志对 Transit Gateway 支持的更多信息，请参阅[文档](https://docs.aws.amazon.com/vpc/latest/tgw/tgw-flow-logs.html)。"
    },
    {
        "query":"使用流日志是否会影响您的网络延迟或性能？",
        "intention":"知识问答",
        "reply":"流日志数据在网络流量路径之外收集，因此不会影响网络吞吐量或延迟。您可以创建或删除流日志，不会产生任何影响网络性能的风险。"
    },
    {
        "query":"什么是 Amazon VPC 流量镜像？",
        "intention":"知识问答",
        "reply":"借助 Amazon VPC 流量镜像，客户可以轻松地将网络流量复制到 Amazon EC2 实例以及从中复制，并将这些流量转发给带外安全和监控设备，用于内容检查、威胁监控和故障排除等使用案例。这些设备可以部署在单独的 EC2 实例上，也可以部署在带有用户数据报协议 (UDP) 侦听器的网络负载均衡器 (NLB) 后面的一组实例上。"
    },
    {
        "query":"Amazon VPC 流量镜像的工作原理是什么？",
        "intention":"知识问答",
        "reply":"流量镜像功能从 Amazon VPC 中 EC2 实例的弹性网络接口 (ENI) 复制网络流量。您可以将镜像流量发送到其他 EC2 实例，也可以发送到带有 UDP 侦听器的 NLB。流量镜像使用 VXLAN 标头封装所有复制的流量。镜像源和目标（监控设备）可以位于同一 VPC 中，也可以位于不同的 VPC 中，通过 VPC 对等或 AWS Transit Gateway 连接。"
    },
    {
        "query":"使用 Amazon VPC 流量镜像可以监控哪些资源？",
        "intention":"知识问答",
        "reply":"流量镜像支持在 EC2 实例的弹性网络接口 (ENI) 级别捕获的网络数据包。请参阅[流量镜像文档](https://docs.aws.amazon.com/vpc/latest/mirroring/traffic-mirroring-considerations.html)了解支持 Amazon VPC 流量镜像的 EC2 实例。"
    },
    {
        "query":"Amazon VPC 流量镜像支持哪些类型的设备？",
        "intention":"知识问答",
        "reply":"客户可以使用开源工具，也可以从 AWS Marketplace 上提供的各种监控解决方案中进行选择。借助流量镜像，客户可以将复制的流量流式传输到任何网络数据包收集器/代理或分析工具，无需安装特定于供应商的代理。"
    },
    {
        "query":"Amazon VPC 流量镜像与 Amazon VPC 流日志有何不同？",
        "intention":"知识问答",
        "reply":"借助 Amazon VPC 流日志，客户可以收集、存储和分析网络流日志。流日志中捕获的信息包括关于允许和拒绝的流量、源和目标 IP 地址、端口、协议编号、数据包和字节数以及操作（接受或拒绝）的信息。您可以使用此功能对连接和安全问题进行故障排除，并确保网络访问规则按预期工作。\n借助 Amazon VPC 流量镜像，您可以分析实际流量内容（包括负载），从而深入了解网络流量。它的使用案例包括分析实际数据包以确定性能问题的根本原因、对复杂的网络攻击进行逆向工程以及检测并阻止内部滥用或受损的工作负载。"
    },
    {
        "query":"可以在哪个（些）Amazon EC2 区域中使用 Amazon VPC？",
        "intention":"知识问答",
        "reply":"Amazon VPC 目前可以在所有 Amazon EC2 区域的多个[可用区](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-regions-availability-zones.html)中使用。"
    },
    {
        "query":"一个 VPC 可否跨越多个可用区？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"一个子网可否跨越多个可用区？",
        "intention":"知识问答",
        "reply":"子网必须位于单个可用区中。"
    },
    {
        "query":"如何指定在哪个可用区中启动我的 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"启动 Amazon EC2 实例时，您必须指定要在其中启动该实例的子网。该实例将在与指定子网关联的可用区中启动。"
    },
    {
        "query":"如何确定我的子网所在的可用区？",
        "intention":"知识问答",
        "reply":"在创建子网时，您必须指定要放置该子网的可用区。使用 VPC 向导时，您可以在向导确认屏幕中选择子网可用区。在使用 API 或 CLI 时，您可以像创建子网时一样指定子网的可用区。如果不指定可用区，则将选取默认的“无首选项”选项，子网也会在相应区域中已有的可用区中创建。"
    },
    {
        "query":"调用 DescribeInstances() 时，可否看到我的所有 Amazon EC2 实例，包括位于 EC2-Classic 和 EC2-VPC 中的实例？",
        "intention":"知识问答",
        "reply":"可以。DescribeInstances() 将返回所有运行中的 Amazon EC2 实例。您可以通过子网字段中的条目区别 EC2-Classic 实例与 EC2-VPC 实例。如果列出了子网 ID，则该实例位于 VPC 中。"
    },
    {
        "query":"调用 DescribeVolumes() 时，可否看到我的所有 Amazon EBS 卷，包括位于 EC2-Classic 和 EC2-VPC 中的卷？",
        "intention":"知识问答",
        "reply":"可以。DescribeVolumes() 将返回您的所有 EBS 卷。"
    },
    {
        "query":"一个 VPC 中可使用多少个 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"对于需要 IPv4 寻址的实例，您可以在一个 VPC 中运行任意数量的 Amazon EC2 实例，只要设置的 VPC 大小足以为每个实例分配一个 IPv4 地址。初始状态下，限制一次最多启动 20 个 Amazon EC2 实例，并且 VPC 的大小上限为 /16（65 536 个 IP）。如果要提高这些限制，请[填写以下表单](http://aws.amazon.com/contact-us/vpc-request/)。 对于仅 IPv6 实例，/56 的 VPC 大小让您能够启动数量几乎不受限的 Amazon EC2 实例。"
    },
    {
        "query":"可否在 Amazon VPC 中使用现有的 AMI？",
        "intention":"知识问答",
        "reply":"您可以在 Amazon VPC 中使用注册区域与您的 VPC 相同的 AMI。例如，您可以将注册在 us-east-1 的 AMI 用于 us-east-1 中的 VPC。有关更多信息，请参阅 [Amazon EC2 区域和可用区常见问题](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/FAQ_Regions_Availability_Zones.html)。"
    },
    {
        "query":"可否使用现有的 Amazon EBS 快照？",
        "intention":"知识问答",
        "reply":"可以。如果 Amazon EBS 快照与您的 VPC 位于同一区域中，您就可以使用它们。有关更多详情，请参阅 [Amazon EC2 区域和可用区常见问题](http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/FAQ_Regions_Availability_Zones.html)。"
    },
    {
        "query":"可否从 Amazon VPC 中的 Amazon EBS 卷启动 Amazon EC2 实例？",
        "intention":"知识问答",
        "reply":"可以。不过，VPC 中使用由 Amazon EBS 支持的 AMI 启动的实例将在停止和重新启动后保持相同的 IP 地址。这与相似的实例从 VPC 之外启动时相反，那时会获取新的 IP 地址。子网中任何停止的实例的 IP 地址将视为不可用。"
    },
    {
        "query":"可否将 Amazon EC2 预留实例用于 Amazon VPC？",
        "intention":"知识问答",
        "reply":"可以。您可以在购买预留实例时，在 Amazon VPC 中预留实例。计算账单时，AWS 不区分您的实例是在 Amazon VPC 中还是在标准的 Amazon EC2 中运行。AWS 将自动优化确认哪些实例按照更低的预留实例费用收费，确保您始终支付最低的金额。不过，您的实例预留将仅限于 Amazon VPC。有关更多详情，请参阅[预留实例](http://aws.amazon.com/ec2/reserved-instances)页面。"
    },
    {
        "query":"可否在 Amazon VPC 中使用 Amazon CloudWatch？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"可否在 Amazon VPC 中使用 Auto Scaling？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"是否可以在 VPC 中启动 Amazon EC2 群集实例？",
        "intention":"知识问答",
        "reply":"可以。Amazon VPC 支持群集实例，但是并非所有实例类型在所有区域和所有可用区都可用。"
    },
    {
        "query":"什么是实例主机名？",
        "intention":"知识问答",
        "reply":"当您启动实例时，会为其分配一个主机名。可用的选项有两个：基于 IP 的名称或基于资源的名称，此参数可在实例启动时配置。基于 IP 的名称使用私有 IPv4 地址的格式，而基于资源的名称使用实例 id 的格式。"
    },
    {
        "query":"我是否可以更改 Amazon EC2 实例的实例主机名？",
        "intention":"知识问答",
        "reply":"可以，您可以停止实例，然后更改基于资源的命名选项，以将实例的主机名从基于 IP 的格式更改为基于资源的格式，反之亦然。"
    },
    {
        "query":"我是否可以使用实例主机名作为 DNS 主机名？",
        "intention":"知识问答",
        "reply":"可以，实例主机名可以用作 DNS 主机名。对于在仅 IPv4 或双堆栈子网中启动的实例，基于 IP 的名称始终解析为实例的主网络接口上的私有 IPv4 地址，此功能无法关闭。此外，基于资源的名称可以配置为解析成主网络接口上的私有 IPv4 地址、主网络接口上的第一个 IPv6 GUA，或者同时解析成这两个地址。对于在仅 IPv6 子网中启动的实例，基于资源的名称可配置为解析成主网络接口上的第一个 IPv6 GUA。"
    },
    {
        "query":"什么是默认 VPC？",
        "intention":"知识问答",
        "reply":"默认 VPC 是 AWS 云中的逻辑独立虚拟网络，在您初次配置 Amazon EC2 资源时，会为您的 AWS 账户自动创建。当您启动实例而未指定子网 ID 时，实例便会在默认 VPC 中启动。"
    },
    {
        "query":"默认 VPC 有哪些优势？",
        "intention":"知识问答",
        "reply":"当您在默认 VPC 中启动资源时，Amazon VPC (EC2-VPC) 的高级网络功能以及 Amazon EC2 (EC2-Classic) 的易用性可为您提供诸多益处。您可以享用各种功能，包括运行中更改安全组成员、安全组出口筛选、多 IP 地址以及多网络接口，而无需专门创建 VPC 并在其中启动实例。"
    },
    {
        "query":"启用默认 VPC 的账户有哪些？",
        "intention":"知识问答",
        "reply":"如果您的 AWS 账户是在 2013 年 3 月 18 日之后创建的，则可以在默认 VPC 中启动资源。请参阅此[论坛公告](https://forums.aws.amazon.com/ann.jspa?annID=1875)以确定哪些区域已经启用默认 VPC 功能集。而对于在所列日期之前创建的账户，则可以在任何已启用默认 VPC 的区域（您未曾在该区域启动过 EC2 实例或预置过 Amazon Elastic Load Balancing、Amazon RDS、Amazon ElastiCache 或 Amazon Redshift 资源）中使用默认 VPC。"
    },
    {
        "query":"如何确定我的账户是否被配置为使用默认 VPC？",
        "intention":"知识问答",
        "reply":"Amazon EC2 控制台会显示在所选区域中您可以启动实例的平台，以及在该区域您是否拥有默认 VPC。在导航栏中，确认选定要使用的区域。在 Amazon EC2 控制台仪表板上，从“账户属性”下找到“支持的平台”。如果有两个值，EC2-Classic 和 EC2-VPC，则可以在任一个平台上启动实例。如果有一个值，EC2-VPC，则只能在 EC2-VPC 中启动实例。如果您的账户被配置为使用默认 VPC，则会在“账户属性”下列出您的默认 VPC ID。您还可以使用 EC2 DescribeAccountAttributes API 或 CLI 来描述您的受支持平台。"
    },
    {
        "query":"是否需要了解一些关于 Amazon VPC 的信息才能使用默认 VPC？",
        "intention":"知识问答",
        "reply":"不需要。您可以使用 AWS 管理控制台、AWS EC2 CLI 或 Amazon EC2 API 在默认 VPC 中启动和管理 EC2 实例及其他 AWS 资源。AWS 会为您自动创建默认 VPC，并在 AWS 区域中的每个可用区中创建默认子网。您的默认 VPC 将会连接到互联网网关，您的实例会自动接收公有 IP 地址，这与 EC2-Classic 类似。"
    },
    {
        "query":"在 EC2-Classic 和 EC2-VPC 中启动的实例有何区别？",
        "intention":"知识问答",
        "reply":"请参阅《EC2 用户指南》中的 [EC2-Classic 与 EC2-VPC 之间的区别](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-vpc.html)。"
    },
    {
        "query":"是否必须通过 VPN 连接使用默认 VPC？",
        "intention":"知识问答",
        "reply":"不是。默认 VPC 会连接到 Internet，并且所有在默认 VPC 的默认子网中启动的实例都会自动接收公有 IP 地址。您可以将 VPN 连接添加到您选择的默认 VPC 中。"
    },
    {
        "query":"可否创建其他 VPC 并与默认 VPC 一同使用？",
        "intention":"知识问答",
        "reply":"可以。要在非默认 VPC 中启动实例，必须在实例启动期间指定子网 ID。"
    },
    {
        "query":"可否在默认 VPC 中创建额外的子网，例如私有子网？",
        "intention":"知识问答",
        "reply":"可以。要启动并进入非默认子网中，您可以使用控制台或者 CLI、API 或 SDK 中的 --subnet 选项设定启动目标。"
    },
    {
        "query":"最多可以拥有多少个默认 VPC？",
        "intention":"知识问答",
        "reply":"对于将“支持的平台”属性设为“EC2-VPC”的每个 AWS 区域，可以拥有一个默认 VPC。"
    },
    {
        "query":"默认 VPC 的 IP 范围是什么？",
        "intention":"知识问答",
        "reply":"默认 VPC CIDR 为 172.31.0.0/16。默认子网在默认 VPC CIDR 中使用 /20 CIDR。"
    },
    {
        "query":"一个默认 VPC 包含多少个默认子网？",
        "intention":"知识问答",
        "reply":"系统会在您的默认 VPC 中为每个可用区创建一个默认子网。"
    },
    {
        "query":"可否自行指定默认 VPC？",
        "intention":"知识问答",
        "reply":"目前不可以。"
    },
    {
        "query":"可否自行指定默认子网？",
        "intention":"知识问答",
        "reply":"目前不可以。"
    },
    {
        "query":"可否删除默认 VPC？",
        "intention":"知识问答",
        "reply":"可以，您可以删除默认 VPC。删除后，您可以直接通过 VPC 控制台或使用 CLI 创建新的默认 VPC。这样做将在相应区域创建一个新的默认 VPC，而不会还原之前删除的 VPC。"
    },
    {
        "query":"可否删除默认子网？",
        "intention":"知识问答",
        "reply":"可以，您可以删除默认子网。删除后，您可以使用 CLI 或 SDK 在可用区中创建新的默认子网。这将在指定的可用区中创建新的默认子网，而不会还原之前删除的子网。"
    },
    {
        "query":"我现在有一个 EC2-Classic 账户。可否获得默认 VPC？",
        "intention":"知识问答",
        "reply":"获得默认 VPC 的最简单方法是，在已启用默认 VPC 的区域中创建一个新账户，或在从未到过的区域中使用现有账户，只要该区域中该账户的“支持的平台”属性设为“EC2-VPC”即可。"
    },
    {
        "query":"我很想让我现有的 EC2 账户拥有默认 VPC。是否可行？",
        "intention":"知识问答",
        "reply":"可以，但是，如果您在该区域的账户中没有任何 EC2-Classic 资源，我们只能为默认 VPC 启用现有账户。此外，您还必须终止该区域中的所有非 VPC 配置的 Elastic Load Balancer、Amazon RDS、Amazon ElastiCache 和 Amazon Redshift 资源。在为您的账户配置默认 VPC 后，所有未来资源启动（包括通过 Auto Scaling 启动实例）都将在您的默认 VPC 中执行。要申请为您的现有账户设置默认 VPC，请转到*账户和账单* -> *服务：账户* -> *C类别：将 EC2 Classic 转换为 VPC*，然后提出申请。我们会审核您的申请、您现有的 AWS 产品以及 EC2-Classic 情况，以指导您完成后续步骤。"
    },
    {
        "query":"默认 VPC 对 IAM 账户有哪些影响？",
        "intention":"知识问答",
        "reply":"如果您的 AWS 账户拥有默认 VPC，则与 AWS 账户关联的任何 IAM 账户会使用与 AWS 账户相同的默认 VPC。"
    },
    {
        "query":"什么是 EC2-Classic？",
        "intention":"知识问答",
        "reply":"EC2-Classic 是我们于 2006 年夏季通过 EC2 发布的一种扁平网络。利用 EC2-Classic，您的实例可在与其他客户共享的单个扁平网络中运行。长期以来，受到客户不断演变的需求启发，我们在 2009 年发布了 Amazon Virtual Private Cloud (VPC)，使您能够在与自己的 AWS 账户逻辑隔离的虚拟私有云中运行实例。今天，虽然我们的大多数客户都使用 Amazon VPC，但还有一些客户仍在使用 EC2-Classic。"
    },
    {
        "query":"有什么变化？",
        "intention":"知识问答",
        "reply":"我们将于 2022 年 8 月 15 日停用 Amazon EC2-Classic，因此我们需要您在此日期之前将 EC2-Classic 上运行的任何 EC2 实例和其他 AWS 资源迁移到 Amazon VPC。下面的部分提供了更多关于 EC2-Class 停用以及可为您的迁移提供支持的工具和资源的信息。"
    },
    {
        "query":"停用 EC2-Classic 对我的账户有什么影响？",
        "intention":"知识问答",
        "reply":"只有当您在自己的账户中为任何 AWS 区域启用了 EC2-Classic 时，此变化才会对您产生影响。您可以使用控制台或 [describe-account-attributes](https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-account-attributes.html) 命令检查您是否为 AWS 区域启用了 EC2-Classic；请参阅此[文档](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-classic-platform.html#ec2-supported-platforms)以了解更多详细信息。  \n   \n 如果您没有任何活动 AWS 资源在任何区域中的 EC2-Classic 上运行，我们请求您从账户中对该区域关闭 EC2-Classic。在区域中关闭 EC2-Classic 将使您可从该处启用默认 VPC。为此，转到 AWS Support Center ([console.aws.amazon.com/support](https://console.aws.amazon.com/support))，选择 Create case（创建案例），然后选择 Account and billing support（账户和账单支持），在 Type（类型）中选择 Account（账户），在 Category（类别）中选择 Convert EC2 Classic to VPC（将 EC2 Classic 转换为 VPC），根据需要填写其他详细信息，然后选择 Submit（提交）。  \n   \n 对于您自 2021 年 1 月 1 日以来没有任何 AWS 资源（EC2 实例、Amazon Relational Database、AWS Elastic Beanstalk、Amazon Redshift、AWS Data Pipeline、Amazon EMR、AWS OpsWorks）在 EC2-Classic 上运行的 AWS 区域，我们将于 2021 年 10 月 30 日从您的账户中自动关闭 EC2-Classic。  \n   \n 另一方面，如果您有 AWS 资源在 EC2-Classic 上运行，我们请求您尽快制定将其迁移到 Amazon VPC 的计划。在 2022 年 8 月 15 日之后，您将无法在 EC2-Classic 平台上启动任何实例或 AWS 服务。随着我们于 2022 年 8 月 16 日开始停用该平台，任何运行状态的工作负载或服务都将逐渐丧失对 EC2-Classic 上的所有 AWS 服务的访问权限。\n在后面的问题中，您将可找到 AWS 资源的迁移指南。"
    },
    {
        "query":"从 EC2-Classic 迁移到 Amazon VPC 有什么益处？",
        "intention":"知识问答",
        "reply":"Amazon VPC 让您能够完全控制自己在 AWS 上的虚拟网络环境，与您的 AWS 账户逻辑隔离。在 EC2-Classic 环境中，您的工作负载与其他客户共享单个扁平网络。与 EC2-Classic 环境相比，Amazon VPC 环境带来了多种其他优势，包括选择自己的 IP 地址空间、公有和私有子网配置以及管理路由表和网络网关的功能。当前在 EC2-Classic 中可用的所有服务和实例在 Amazon VPC 环境中都有类似的服务。Amazon VPC 还可提供比 EC2-Classic 更广泛的新一代实例。关于 Amazon VPC 的更多信息可[在此链接中](https://aws.amazon.com/cn/vpc/)获得。"
    },
    {
        "query":"如何从 EC2-Classic 迁移到 VPC？",
        "intention":"知识问答",
        "reply":"为了帮助您迁移资源，我们发布了手册并构建了解决方案，您可从下面找到。为了进行迁移，您必须在 VPC 中重新创建 EC2-Classic 资源。首先，您可以使用此[脚本](https://github.com/aws-samples/ec2-classic-resource-finder/blob/main/Classic-Resource-Finder.sh)识别在账户内为所有区域中的 EC2-Classic 预置的所有资源。然后，您可以使用下面适用于相关 AWS 资源的迁移指南：\n除了上面的迁移指南之外，我们还提供了高度自动化的直接迁移（更换主机）解决方案：AWS Application Migration Service (AWS MGN)，它可简化和加速应用程序迁移，并降低迁移成本。您可以从此处找到关于 AWS MGN 的相关资源：\n对于简单的单一 EC2 实例从 EC2-Classic 到 VPC 的迁移，除了 AWS MGN 或[实例迁移指南](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/vpc-migrate.html)之外，您还可以使用来自“AWS Systems Manager > 自动化”的“AWSSupport-MigrateEC2 ClassicToVPC”Runbook。该 Runbook 可通过创建 EC2-Classic 中的实例的 AMI，在 VPC 中从该 AMI 创建新实例，并可终止 EC2-Classic 实例，以自动执行将实例从 EC2-Classic 迁移到 VPC 所需的步骤。\n如果您有任何疑问或顾虑，可以通过 [AWS Premium Support](https://aws.amazon.com/support) 联系 AWS Support 团队。  \n   \n 请注意：如果您在多个 AWS 区域中有 AWS 资源在 EC2-Classic 上运行，建议您在将所有资源迁移到这些区域中的 VPC 之后，立即在每个区域中关闭 EC2-Classic。"
    },
    {
        "query":"我应当知道哪些重要日期？",
        "intention":"知识问答",
        "reply":"我们将在 2022 年 8 月 15 日停用日期之前采取两个重要行动："
    },
    {
        "query":"可否在 EC2 实例运行时，连接或断开一个或多个网络接口？",
        "intention":"知识问答",
        "reply":"可以。"
    },
    {
        "query":"一个 EC2 实例可否连接两个以上网络接口？",
        "intention":"知识问答",
        "reply":"EC2 实例上可以连接的网络接口总数取决于实例类型。有关不同类型的实例允许的网络接口数量的更多信息，请参阅《EC2 用户指南》。"
    },
    {
        "query":"可否将一个可用区中的网络接口连接到另一可用区中的实例？",
        "intention":"知识问答",
        "reply":"网络接口只能连接到位于相同可用区中的实例。"
    },
    {
        "query":"可否将一个 VPC 中的网络接口连接到另一 VPC 中的实例？",
        "intention":"知识问答",
        "reply":"网络接口只能连接到该接口所在 VPC 中的实例。"
    },
    {
        "query":"可否使用弹性网络接口这种方式，在一个实例上托管要求单独 IP 地址的多个网站？",
        "intention":"知识问答",
        "reply":"可以。不过，这不是符合多接口的最佳使用案例。相反，您应当为实例分配额外的私有 IP 地址，然后根据需要将 EIP 与这些私有 IP 关联。"
    },
    {
        "query":"可否断开 EC2 实例上的主要接口 (eth0)？",
        "intention":"知识问答",
        "reply":"您可以连接和断开 EC2 实例上的次要接口 (eth1-ethn)，但不能断开 eth0 端口。"
    },
    {
        "query":"可否创建连接到不同区域中的 VPC 的对等连接？",
        "intention":"知识问答",
        "reply":"可以。可面向不同区域中的 VPC 创建对等连接。 区域间 VPC 对等连接已在全球除中国以外的所有商业区域推出。"
    },
    {
        "query":"可否将我的 VPC 对等连接到其他 AWS 账户的 VPC？",
        "intention":"知识问答",
        "reply":"可以，只要其他 VPC 的所有者接受您的对等连接请求。"
    },
    {
        "query":"可否将 IP 地址范围匹配的两个 VPC 进行对等连接？",
        "intention":"知识问答",
        "reply":"不可以。对等连接的 VPC 必须拥有互不重叠的 IP 范围。"
    },
    {
        "query":"可否使用 AWS Direct Connect 或硬件 VPN 连接访问我已经对等连接的 VPC？",
        "intention":"知识问答",
        "reply":"不可以。Amazon VPC 不支持“边缘到边缘路由”。有关更多信息，请参阅 [VPC 对等连接指南](http://docs.aws.amazon.com/AmazonVPC/latest/PeeringGuide/)。"
    },
    {
        "query":"是否需要互联网网关才能使用对等连接？",
        "intention":"知识问答",
        "reply":"VPC 对等连接不需要互联网网关。"
    },
    {
        "query":"VPC 对等流量在区域中是否已加密？",
        "intention":"知识问答",
        "reply":"没有。对等连接的 VPC 中的实例之间的流量始终是私密而隔离的，这类似于相同 VPC 中两个实例之间流量私密而隔离的情形。"
    },
    {
        "query":"如果我删除我这端的对等连接，另一端还能访问我的 VPC 吗？",
        "intention":"知识问答",
        "reply":"不可以。对等连接两端的任一端随时可以中断对等连接。中断对等连接意味着流量不会在两个 VPC 之间产生。"
    },
    {
        "query":"如果将 VPC A 对等连接到 VPC B，再将 VPC B 对等连接到 VPC C，是否表示 VPC A 和 VPC C 已经对等连接？",
        "intention":"知识问答",
        "reply":"不是。不支持传递对等关系。"
    },
    {
        "query":"我的对等连接出现故障怎么办？",
        "intention":"知识问答",
        "reply":"AWS 使用现有 VPC 基础设施创建 VPC 对等连接，既不是网关，也不是 VPN 连接，因此不依赖某个独立的实体硬件。不会发生单点通信故障或带宽瓶颈。\n区域间 VPC 对等连接采用当前支持 VPC 的横向扩展、冗余且高度可用的技术。区域间 VPC 对等连接流量经过具有内置冗余和动态带宽分配的 AWS 主干。不会发生单点通信故障。\n如果区域间对等连接出现故障，流量将不会通过 Internet 路由。"
    },
    {
        "query":"对等连接是否设有带宽限制？",
        "intention":"知识问答",
        "reply":"对等连接的 VPC 中的实例之间的带宽与相同 VPC 中的实例之间的带宽无异。注意：置放群组可跨越多个对等连接的 VPC，但是，您不会在对等连接的 VPC 中的实例之间获取全部的等分带宽。阅读有关[置放群组](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html)的更多信息。"
    },
    {
        "query":"区域间 VPC 对等连接流量是否加密？",
        "intention":"知识问答",
        "reply":"流量使用现代 AEAD（带关联数据的加密认证）算法进行加密。密钥协议和密钥管理由 AWS 完成。"
    },
    {
        "query":"DNS 转换如何使用区域间 VPC 对等连接？",
        "intention":"知识问答",
        "reply":"默认情况下，如果在不同区域的对等连接 VPC 中查询实例的公有主机名，该查询将解析为公有 IP 地址Route 53 的私有 DNS 可使用区域间 VPC 对等连接解析私有 IP 地址。"
    },
    {
        "query":"可否通过区域间 VPC 对等连接引用安全组？",
        "intention":"知识问答",
        "reply":"不可以。安全组无法通过区域间 VPC 对等连接引用。"
    },
    {
        "query":"区域间 VPC 对等连接是否支持 IPv6？",
        "intention":"知识问答",
        "reply":"是。区域间 VPC 对等连接支持 IPv6。"
    },
    {
        "query":"区域间 VPC 对等连接可否与 EC2-Classic Link 结合使用？",
        "intention":"知识问答",
        "reply":"不可以。区域间 VPC 对等连接无法与 EC2-ClassicLink 结合使用。"
    },
    {
        "query":"什么是 ClassicLink？",
        "intention":"知识问答",
        "reply":"Amazon Virtual Private Cloud (VPC) ClassicLink 允许在 EC2-Classic 平台中使用 EC2 实例，以使用私有 IP 地址与 VPC 中的实例进行通信。要使用 ClassicLink，请对账户中的 VPC 启用该功能，然后将 VPC 中的安全组与 EC2-Classic 中的实例进行关联。VPC 安全组的所有规则会应用到 EC2-Classic 中的实例之间的通信，也会应用到 VPC 中的实例之间的通信。"
    },
    {
        "query":"如何使用 ClassicLink？",
        "intention":"知识问答",
        "reply":"要使用 ClassicLink，首先要为 ClassicLink 在账户中至少启用一个 VPC。然后将 VPC 中的安全组与目标 EC2-Classic 实例进行关联。EC2-Classic 实例现在已经与 VPC 关联，而且是 VPC 中所选安全组的一部分。EC2-Classic 实例不能同时关联多个 VPC。"
    },
    {
        "query":"EC2-Classic 实例是否是 VPC 的一部分？",
        "intention":"知识问答",
        "reply":"EC2-Classic 实例不是 VPC 的一部分，而是与实例关联的 VPC 安全组的一部分。VPC 安全组的所有规则和引用会应用到 EC2-Classic 实例中的实例之间的通信，也会应用到 VPC 中的资源之间的通信。"
    },
    {
        "query":"可否使用 EC2-Classic 实例和 EC2-VPC 实例中的 EC2 公有 DNS 主机名来使用私有 IP 进行通信？",
        "intention":"知识问答",
        "reply":"当从 EC2-Classic 实例发起查询时，EC2 公有 DNS 主机名将无法解析 EC2-VPC 实例的私有 IP 地址，反向操作一样行不通。"
    },
    {
        "query":"有没有无法启用 ClassicLink 的 VPC？",
        "intention":"知识问答",
        "reply":"有。如果 VPC 使用无类域间路由 (CIDR) 的方式且在 10.0.0.0/8 的范围内（10.0.0.0/16 和 10.1.0.0/16 除外），则该 VPC 无法启用 ClassicLink。此外，如果 VPC 包含的路由表条目指向 10.0.0.0/8 CIDR 空间而非“本地”目标，则该 VPC 无法启用 ClassicLink。"
    },
    {
        "query":"来自 EC2-Classic 实例的流量可否通过 Amazon VPC 并经互联网网关、虚拟私有网关传出，或传入对等 VPC？",
        "intention":"知识问答",
        "reply":"从 EC2-Classic 实例出来的流量只能路由到 VPC 中的私有 IP 地址。它们不能路由到 VPC 外部的任何目标，包括互联网网关、虚拟私有网关或对等 VPC 目标。"
    },
    {
        "query":"ClassicLink 是否会对 EC2-Classic 实例以及 EC2-Classic 平台中的其他实例的访问控制造成影响？",
        "intention":"知识问答",
        "reply":"ClassicLink 不会改变通过 EC2-Classic 平台中现有的安全组对 EC2-Classic 实例定义的访问控制。"
    },
    {
        "query":"在停止/开始循环中，EC2-Classic 实例中的 ClassicLink 设置是否会持续存在？",
        "intention":"知识问答",
        "reply":"ClassicLink 连接在 EC2-Classic 实例的停止/开始循环中不会持续存在。当 EC2-Classic 实例停止再开始后，您需要将其再次与 VPC 进行关联。但是，ClassicLink 连接在实例重启循环中不会中断。"
    },
    {
        "query":"启用 ClassicLink 后，我的 EC2-Classic 实例会不会分配到新的私有 IP 地址？",
        "intention":"知识问答",
        "reply":"不存在分配给 EC2-Classic 实例的新的私有 IP 地址。当您对 EC2-Classic 实例启用 ClassicLink 后，实例还会使用既有的私有 IP 地址与 VPC 中的资源进行通信。"
    },
    {
        "query":"ClassicLink 是否允许 EC2-Classic 安全组规则引用 VPC 安全组，或者反向引用是否可行？",
        "intention":"知识问答",
        "reply":"ClassicLink 不允许 EC2-Classic 安全组规则引用 VPC 安全组，反向引用也不行。"
    },
    {
        "query":"什么是 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"AWS PrivateLink 使客户能够通过高度可用且可扩展的方式来访问托管在 AWS 上的服务，同时将所有网络流量限制在 AWS 网络内。服务用户可借此从他们的 Amazon Virtual Private Cloud (VPC) 或本地对 PrivateLink 支持的服务进行私有访问，而无需使用公有 IP，也不需要让流量遍历整个 Internet。服务拥有者可以将自己的网络负载均衡器注册到 PrivateLink 服务中，将服务提供给其他 AWS 客户。"
    },
    {
        "query":"如何能使用 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"作为服务用户，您需要为 PrivateLink 支持的服务创建接口类 VPC 终端节点。这些服务终端节点将在 VPC 中显示为带私有 IP 的弹性网络接口 (ENI)。这些终端节点创建后，目标为这些 IP 的所有流量都将以私有方式路由到相应 AWS 产品。\n作为服务拥有者，您可以在您的服务前面部署网络负载均衡器 (NLB) 并创建 PrivateLink 服务以在其中注册 NLB，从而将您的服务加入到 AWS PrivateLink 中。在您将客户的账户和 IAM 角色加入白名单之后，他们能够在他们的 VPC 中建立终端节点以连接到您的服务。"
    },
    {
        "query":"AWS PrivateLink 目前支持哪些服务？",
        "intention":"知识问答",
        "reply":"以下 AWS 服务均支持此功能：Amazon Elastic Compute Cloud (EC2)、Elastic Load Balancing (ELB)、Kinesis Streams、Service Catalog、EC2 Systems Manager、Amazon SNS 和 AWS DataSync。许多 SaaS 解决方案也支持此功能。有关 AWS PrivateLink 支持的更多 SaaS 产品的信息，请访问 [AWS Marketplace](https://aws.amazon.com/marketplace)。"
    },
    {
        "query":"可否通过 AWS Direct Connect 对由 AWS PrivateLink 提供支持的服务进行私有访问？",
        "intention":"知识问答",
        "reply":"可以。您的本地应用程序可通过 AWS Direct Connect 连接到 Amazon VPC 中的服务终端节点。这些服务终端节点会自动将流量定向到由 AWS PrivateLink 提供支持的 AWS 产品。"
    },
    {
        "query":"哪些 CloudWatch 指标可用于基于接口的 VPC 端点？",
        "intention":"知识问答",
        "reply":"目前，没有任何 CloudWatch 指标可用于基于接口的 VPC 端点。"
    },
    {
        "query":"可否使用 AWS 管理控制台控制和管理 Amazon VPC？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 AWS 管理控制台管理 Amazon VPC 对象，如 VPC、子网、路由表、互联网网关和 IPSec VPN 连接。此外，您也可以使用一个简单向导来创建 VPC。"
    },
    {
        "query":"我可以创建多少个 VPC、子网、弹性 IP 地址和互联网网关？",
        "intention":"知识问答",
        "reply":"数量如下：\n有关 VPC 限制的更多信息，请参阅 [Amazon VPC 用户指南](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Appendix_Limits.html)。"
    },
    {
        "query":"能否为 Amazon VPC 获取 AWS 支持？",
        "intention":"知识问答",
        "reply":"能。有关 AWS 支持的更多信息，请[单击此处](http://aws.amazon.com/premiumsupport/)。"
    },
    {
        "query":"可否将 ElasticFox 用于 Amazon VPC？",
        "intention":"知识问答",
        "reply":"通过 ElasticFox 管理 Amazon VPC 不再受官方支持。Amazon VPC 支持可通过 AWS API、命令行工具、AWS 管理控制台以及许多第三方实用程序提供。\n了解 Amazon VPC 的更多信息"
    },
    {
        "query":"What is a data lake?",
        "intention":"知识问答",
        "reply":"A data lake is a scalable central repository of large quantities and varieties of data, both structured and unstructured. Data lakes let you manage the full lifecycle of your data. The first step of building a data lake is ingesting and cataloging data from a variety of sources. The data is then enriched, combined, and cleaned before analysis. This makes it easy to discover and analyze the data with direct queries, visualization, and machine learning (ML). Data lakes complement traditional data warehouses, providing more flexibility, cost-effectiveness, and scalability for ingestion, storage, transformation, and analysis of your data. The traditional challenges around the construction and maintenance of data warehouses and limitations in the types of analysis can be overcome using data lakes.\nRead more about [\"What is a data lake?\"](https://aws.amazon.com/big-data/datalakes-and-analytics/what-is-a-data-lake/)"
    },
    {
        "query":"What is AWS Lake Formation?",
        "intention":"知识问答",
        "reply":"Lake Formation is an integrated data lake service that makes it easy for you to ingest, clean, catalog, transform, and secure your data and make it available for analysis and ML. Lake Formation gives you a central console where you can discover data sources, set up transformation jobs to move data to an Amazon Simple Storage Service (S3) data lake, remove duplicates and match records, catalog data for access by analytic tools, configure data access and security policies, and audit and control access from AWS analytic and ML services. Lake Formation automatically manages access to the registered data in Amazon S3 through services including AWS Glue, Amazon Athena, Amazon Redshift, Amazon QuickSight, and Amazon EMR using Zeppelin notebooks with Apache Spark to ensure compliance with your defined policies. If you’ve set up transformation jobs spanning AWS services, Lake Formation configures the flows, centralizes their orchestration, and lets you monitor the jobs. With Lake Formation, you can configure and manage your data lake without manually integrating multiple underlying AWS services."
    },
    {
        "query":"Why should I use Lake Formation to build my data lake?",
        "intention":"知识问答",
        "reply":"Lake Formation makes it easy to build, secure, and manage your AWS data lake. Lake Formation integrates with underlying AWS security, storage, analysis, and ML services and automatically configures them to comply with your centrally defined access policies. It also gives you a single console to monitor your jobs and data transformation and analytic workflows.\nLake Formation can manage data ingestion through AWS Glue. Data is automatically classified, and relevant data definitions, schema, and metadata are stored in the central data catalog. AWS Glue also converts your data to your choice of open data formats to be stored in Amazon S3 and cleans your data to remove duplicates and link records across datasets. Once your data is in your S3 data lake, you can define access policies, including table-and-column-level access controls, and enforce encryption for data at rest. You can then use a wide variety of AWS analytic and ML services to access your data lake. All access is secured, governed, and auditable."
    },
    {
        "query":"Can I see a presentation on AWS Lake Formation?",
        "intention":"知识问答",
        "reply":"Yes. You can watch the full recording of the [\"Intro to AWS Lake Formation\"](https://www.youtube.com/watch?v=nsiLMqg654s) session from re:Invent."
    },
    {
        "query":"What kind of problems does the FindMatches ML Transform solve?",
        "intention":"知识问答",
        "reply":"FindMatches generally solves record linkage and data deduplication problems. Deduplication is necessary when you’re trying to identify records in a database that are conceptually the same but for which you have separate records. This problem is trivial if duplicate records can be identified by a unique key (for instance, if products can be uniquely identified by a UPC Code), but it becomes very challenging when you have to do a “fuzzy match.”\nRecord linkage is basically the same problem as data deduplication, but this term usually means that you’re doing a “fuzzy join” of two databases that don’t share a unique key rather than deduplicating a single database. As an example, consider the problem of matching a large database of customers to a small database of known fraudsters. FindMatches can be used on both record linkage and deduplication problems.\nFor instance, Lake Formation's FindMatches ML Transform can help you with the following problems:\nLink patient records: Link patient records between hospitals so doctors have more background information and are better able to treat patients. Use FindMatches on separate databases that both contain common fields such as name, birthday, home address, and phone number.\nDeduplicate data: Deduplicate a database of movies containing columns such as “Title,” “Plot synopsis,” “Year of release,” “Run time,” and “Cast.” For example, there might be variations in how the title or the cast names are listed, resulting in duplicates rather than a clean dataset.\nGroup products: Automatically group all related products together in your storefront by identifying equivalent items in an apparel product catalog, where you want to define “equivalent” to mean that they’re the same when ignoring certain differences. For instance, you might consider all pants to be equivalent despite differences in size and color.\nQ: How does Lake Formation deduplicate my data?\nLake Formation's FindMatches ML Transform makes it easy to find and link records that refer to the same entity but don’t share a reliable identifier. Before FindMatches, developers would commonly solve data-matching problems deterministically, by writing huge numbers of hand-tuned rules. FindMatches uses ML algorithms behind the scenes to learn how to match records according to each developer's business criteria. FindMatches first identifies records for you to label as to whether they match or don’t match and then uses ML to create an ML Transform. You can then run this Transform on your database to find matching records, or you can ask FindMatches to give you additional records to label to push your ML Transform to higher levels of accuracy.\nQ: What are ML Transforms?\nML Transforms provide a destination for creating and managing machine-learned transforms. Once created and trained, these ML Transforms can be run in standard AWS Glue scripts. You select an algorithm (for example, the FindMatches ML Transform) and input datasets and training examples, and the tuning parameters needed by that algorithm. AWS Lake Formation uses those inputs to build an ML Transform that can be incorporated into a normal ETL job workflow.\nQ: Can I see a presentation on using AWS Lake Formation to find matches and deduplicate records?\nYes. The full recording of the AWS Online Tech Talk \"[Fuzzy Matching and Deduplicating Data with ML Transforms for AWS Lake Formation](https://pages.awscloud.com/Fuzzy-Matching-and-Deduplicating-Data-with-ML-Transforms-for-AWS-Lake-Formation_2019_0304-ABD_OD.html)\" is available here.\nQ: How does Lake Formation relate to other AWS services?\nLake Formation manages data access for registered data that is stored in Amazon S3 and manages query access from AWS Glue, Athena, Redshift, Amazon QuickSight, and EMR using Zeppelin notebooks with Apache Spark through a unified security model and permissions. Lake Formation can ingest data from S3, Amazon RDS databases, and AWS CloudTrail logs, understand their formats, and make data clean and able to be queried. Lake Formation configures the flows, centralizes their orchestration, and lets you monitor the jobs.\nRead more about [\"Data Lakes and Analytics on AWS\"](https://aws.amazon.com/big-data/datalakes-and-analytics/) including how to build a customized data lake."
    },
    {
        "query":"How does Lake Formation relate to AWS Glue?",
        "intention":"知识问答",
        "reply":"Lake Formation uses a shared infrastructure with AWS Glue, including console controls, ETL code creation and job monitoring, blueprints to create workflows for data ingest, the same data catalog, and a serverless architecture. Although AWS Glue focuses on these types of functions, Lake Formation encompasses all AWS Glue features and provides additional capabilities designed to help build, secure, and manage a data lake. See the [AWS Glue features page](https://aws.amazon.com/glue/features/) for more details.\nQ: How does Lake Formation help me discover the data I can move into my data lake?\nLake Formation automatically discovers all AWS data sources to which it is provided access by your AWS IAM policies. It crawls Amazon S3, Amazon RDS, and AWS CloudTrail sources, and through blueprints it identifies them to you as data that can be ingested into your data lake. No data is ever moved or made accessible to analytic services without your permission. You can also use AWS Glue to ingest data from other sources, including S3 and Amazon DynamoDB.\nYou can also define JDBC connections to allow Lake Formation to access your AWS databases and on-premises databases including Oracle, MySQL, Postgres, SQL Server, and MariaDB.\nLake Formation ensures that all your data is described in a central data catalog, giving you one location to browse the data that you have permission to view and query. The permissions are defined in your data access policy and can be set at the table and column level.\nIn addition to the properties automatically populated by the crawlers, you can add labels (including business attributes such as data sensitivity) at the table or column level, and add field-level comments.\nQ: How does Lake Formation organize my data in a data lake?\nYou can use one of the blueprints available in Lake Formation to ingest data into your data lake. Lake Formation creates Glue workflows that crawl source tables, extract the data, and load it to Amazon S3. In S3, Lake Formation organizes the data for you, setting up partitions and data formats for optimized performance and cost. For data already in S3, you can register those buckets with Lake Formation to manage them.\nLake Formation also crawls your data lake to maintain a data catalog and provides an intuitive user interface for you to search entities (by type, classification, attribute, or free-form text).\nQ: How does Lake Formation use machine learning to clean my data?\nLake Formation provides jobs that run ML algorithms to perform deduplication and link matching records. Creating ML Transforms is as easy as selecting your source, selecting a desired transform, and providing training data for the desired changes. Once trained to your satisfaction, the ML Transforms can be run as part of your regular data movement workflows, with no ML expertise required.\nQ: What are other ways I can ingest data to AWS for use with Lake Formation?\nYou can move petabytes to exabytes of data from your data centers to AWS using physical appliances with AWS Snowball, AWS Snowball Edge, and AWS Snowmobile. You can also connect your on-premises applications directly to AWS with AWS Storage Gateway. You can accelerate data transfer using a dedicated network connection between your network and AWS with AWS Direct Connect, or boost long-distance global data transfers using Amazon’s globally distributed edge locations with Amazon S3 Transfer Acceleration. Amazon Kinesis also provides a useful way to load streaming data to S3. Lake Formation Data Importers can be set up to perform ongoing ETL jobs and prepare ingested data for analysis.\nQ: Can I use my existing data catalog or Hive Metastore with Lake Formation?\nLake Formation provides a way for you to import your existing catalog and metastore into the data catalog. However, Lake Formation requires your metadata to reside in the data catalog to ensure governed access to your data.\nQ: How does Lake Formation protect my data?\nLake Formation protects your data by giving you a central location where you can configure granular data access policies that protect your data, regardless of which services are used to access it.\nTo centralize data access policy controls using Lake Formation, first shut down direct access to your buckets in Amazon S3 so all data access is managed by Lake Formation. Next, configure data protection and access policies using Lake Formation, which enforces those policies across all the AWS services accessing data in your lake. You can configure users and roles and define the data these roles can access, down to the table and column level.\nLake Formation currently supports server-side encryption on S3 (SSE-S3, AES-256). Lake Formation also supports private endpoints in your Amazon Virtual Private Cloud (VPC) and records all activity in AWS CloudTrail, so you have network isolation and auditability.\nQ: How does Lake Formation work with AWS IAM?\nLake Formation integrates with IAM so authenticated users and roles can be automatically mapped to data protection policies that are stored in the data catalog. The IAM integration also lets you use Microsoft Active Directory or LDAP to federate into IAM using SAML.\nQ: How do I convert an existing table in Amazon S3 to a governed table?\nIf you have existing Amazon S3–based tables cataloged in the AWS Glue Data Catalog, you can convert them to governed tables by running the AWS Glue blueprint available on the [AWS Labs Github page](https://github.com/awslabs). Additionally, you can create a new governed table and update the manifest information in Lake Formation using the AWS SDK and CLI. The manifest information contains a list of S3 objects and associated metadata that represent the current state of your table. You can also use AWS Glue ETL to read from an existing table and create a copy of it as a Governed Table. This allows you to migrate your applications and users to the Governed Table at your own pace.\nQ: How does Lake Formation help an analyst or data scientist discover what data they can access?\nLake Formation ensures that all your data is described in the data catalog, giving you a central location to browse the data that you have permission to view and query. The permissions are defined in your data access policy and can be set at the table and column level."
    },
    {
        "query":"Can I use third party business intelligence tools with Lake Formation?",
        "intention":"知识问答",
        "reply":"Yes. You can use third-party business applications, such as Tableau and Looker, to connect to your AWS data sources through services such as Athena or Redshift. Access to data is managed by the underlying data catalog, so regardless of which application you use, you’re assured that access to your data is governed and controlled.\nQ: Does Lake Formation provide APIs or a CLI?\nYes. Lake Formation provides APIs and a CLI to integrate Lake Formation functionality into your custom applications. Java and C++ SDKs are also available to let you integrate your own data engines with Lake Formation.\nQ: What is the AWS Lake Formation Storage API, and why should I use it?\nThe Lake Formation Storage API, provides a single interface for AWS services, ISV solutions and applications developers to securely and reliably read and write data in the data lake. To write data, the Storage API exposes ACID (atomic, consistent, isolated, and durable) transactions that allows you to write data into Governed Tables, a new type of Amazon S3 table, in a reliable and consistent manner. To read data, the Storage API allows you to query data in Governed Tables and standard S3 tables secured with Lake Formation fine-grained permissions. The Storage API will automatically enforce permissions before returning the filtered results to the calling application. Access permissions are enforced consistently across a wide range of services and tools."
    },
    {
        "query":"支持哪些数据来源？ Athena 为 AWS、本地存储和其他云端超过 30 个热门数据存储提供内置连接器，这些数据存储包括 Amazon Redshift、Amazon DynamoDB、Google BigQuery、Google Cloud Storage、Azure Synapse、Azure Data Lake Storage、Snowflake 和 SAP Hana。您可以使用这些连接器在结构化、半结构化、对象、图形、时间序列和其他数据存储类型上支持 SQL 分析使用案例。有关受支持来源的列表，请查看 Amazon Athena 用户指南：可用的数据来源连接器。",
        "intention":"知识问答",
        "reply":"您还可以使用 Athena 数据连接器开发工具包创建自定义数据来源连接器并使用 Athena 来查询它。首先查看[文档](https://github.com/awslabs/aws-athena-query-federation/tree/master/athena-example)和示例连接器实施。"
    },
    {
        "query":"Athena for Apache Spark 如何定价？ 您只需为 Apache Spark 应用程序运行所需的时间付费。我们根据用于运行 Apache Spark 应用程序的数据处理单元（DPU）的数量向您收取小时费率。单个 DPU 提供 4 个 vCPU 和 16 GB 内存。您将按 1 秒的增量计费，四舍五入到最接近的分钟数。",
        "intention":"知识问答",
        "reply":"当您通过在 Athena 控制台上启动笔记本或使用 Athena API 来启动 Spark 会话时，系统会为您的应用程序预配置两个节点：一个笔记本节点，充当笔记本用户界面的服务器；一个 Spark 驱动程序节点，协调该节点 Spark 应用程序并与所有 Spark Worker 节点通信。Athena 将在会话期间向您收取驱动程序和 Worker 节点的费用。Amazon Athena 在控制台上提供笔记本作为用户界面，用于创建、提交和执行 Apache Spark 应用程序，并免费提供给您。Athena 不对 Spark 会话期间使用的笔记本节点收费。"
    },
    {
        "query":"Amazon Sumerian 会转换成什么？  您现有的 Sumerian 场景将在 2023 年 2 月 21 日之前可用，之后将不再可用。因此，我们建议您使用 Amplify Hosting 体验将任何现有场景移动到新的 Babylon.js-AWS，并使用新体验构建任何新场景。",
        "intention":"知识问答",
        "reply":"您可以使用此模板作为起点：<https://github.com/aws-samples/aws-tools-for-babylonjs-editor>"
    },
    {
        "query":"为什么会转换 Amazon Sumerian？  我们相信 Babylon.js 和 AWS Amplify Hosting 的这种新用户体验将带来多功能性，您可以比以前更无缝地发布场景。",
        "intention":"知识问答",
        "reply":"问：Amazon Sumerian 是否接受新客户？\n不能。"
    },
    {
        "query":"我无法访问 Amazon Sumerian 控制面板。我该怎么办？  如果您是 Amazon Sumerian 的新客户，请参阅文档和教程以开始使用 Babylon.js 和 AWS Amplify Hosting",
        "intention":"知识问答",
        "reply":"如果您是 Amazon Sumerian 的现有客户并且无法访问控制面板，请验证您的区域。如果您仍然无法访问您的现有场景，请[联系客户支持](https://aws.amazon.com/cn/contact-us/)。"
    },
    {
        "query":"How do I get my data/assets in or out of Nimble Studio?",
        "intention":"知识问答",
        "reply":"Use the File Transfer feature in Nimble Studio to upload and transfer large media files into and between Amazon Simple Storage Service (S3) buckets."
    },
    {
        "query":"Does Nimble Studio File Transfer cost anything to use?",
        "intention":"知识问答",
        "reply":"The Nimble Studio File Transfer feature is free to use. However, standard Amazon S3 pricing will accrue for transfers to S3, from S3, and at rest in S3. Please see the Pricing Page for details."
    },
    {
        "query":"How do I ensure my data is secure?",
        "intention":"知识问答",
        "reply":"Security at AWS is the highest priority. Data is encrypted at rest and in transit, using either service-owned keys or customer-managed Customer Master Keys (CMK), including encryption of all traffic on AWS global and regional networks. Data is additionally protected by studio administrators who control IAM permissions for project access. Administrators can also access AWS CloudWatch logs to audit Nimble Studio usage.\nAdditionally, AWS has a [shared responsibility model](https://aws.amazon.com/compliance/shared-responsibility-model/) with our customers. AWS manages and controls the components, from the host operating system and virtualization layer down to the physical security of the facilities in which the services operate, and AWS customers are responsible for building and configuring secure applications. We provide a wide variety of best practices documents, encryption tools, and other guidance our customers can leverage in delivering application-level security measures. In addition, AWS Partners offer hundreds of tools and features to help customers meet their security objectives, ranging from network security, configuration management, access control, and data encryption."
    },
    {
        "query":"What is the rendering workflow, and do I have access to manage my jobs?",
        "intention":"知识问答",
        "reply":"Nimble Studio provides access to [Thinkbox Deadline](https://aws.amazon.com/thinkbox-deadline/) , enabling artists to use their digital content creation (DCC) tools to submit render jobs to the farm. Administrators can use the Deadline Monitor to maintain full render farm control. Customers who connect their pre-existing render farms to Nimble Studio can submit jobs through virtual workstations and DCC application plugins."
    },
    {
        "query":"What customer support can I expect?",
        "intention":"知识问答",
        "reply":"AWS Support provides a mix of tools, technology, people, and programs designed to help you proactively optimize performance, lower costs, and innovate faster. [Learn more about AWS Support](https://aws.amazon.com/premiumsupport/?nc=sn&loc=0)."
    },
    {
        "query":"Can I use my on-premises workstations with Nimble Studio (or do I need existing virtual workstations)? You can use on-premises workstations to facilitate high-speed data movement between local facilities and AWS using the Nimble Studio File Transfer feature. You don’t need existing virtual workstations; Nimble Studio and its features are workstation-agnostic.",
        "intention":"知识问答",
        "reply":"Current Nimble Studio Workstation Customers"
    },
    {
        "query":"什么是 AWS Firewall Manager？",
        "intention":"知识问答",
        "reply":"AWS Firewall Manager 是一项安全管理服务，可让您在 [AWS Organization](https://aws.amazon.com/cn/organizations/) 中跨账户和应用程序集中配置和管理防火墙规则。在创建新应用程序时，您可以借助 Firewall Manager 实施一套通用的安全规则，轻松地让新应用程序和资源从一开始就达到合规要求。现在您可以使用单一服务来构建防火墙规则、创建安全策略，并在整个基础设施中以一致、分层的方式执行这些规则和策略。"
    },
    {
        "query":"AWS Firewall Manager 的主要优势是什么？",
        "intention":"知识问答",
        "reply":"AWS Firewall Manager 集成了 [AWS Organizations](https://aws.amazon.com/cn/organizations/)，因此您可以从单一位置跨多个 AWS 账户和资源启用 AWS WAF 规则、AWS Shield 高级防护、VPC 安全组、AWS Network Firewall 和 Amazon Route 53 Resolver DNS Firewall 规则。Firewall Manager 监控新资源或创建的账户，以确保它们从一开始就符合强制性安全策略集。您可以在整个基础设施中组合规则、创建策略，并集中地应用这些策略。例如，您可以在单个账户内委托创建特定应用程序的规则，同时保留跨账户实施全局安全策略的能力。您的安全团队可以收到有关组织受威胁的通知，以便他们能够响应并快速缓解攻击。\nFirewall Manager 还集成了[适用于 AWS WAF 的托管规则](https://aws.amazon.com/cn/mp/security/WAFManagedRules/)，这使您能够轻松地将预先配置的 WAF 规则部署在应用程序前面。\n安全管理员可以利用 Firewall Manager 为您的 Amazon VPC 中的 EC2 实例、Application Load Balancer 和 Elastic Network Interface (ENI) 应用一组安全组基线规则。同时，您还可以从一个位置对您的 VPC 中的任何现有的安全组进行过度宽松的规则审计，并对它们进行修复。\n您可以利用 Firewall Manager 跨您组织中的 VPC 集中部署 AWS Network Firewall 终端节点和关联规则，以控制离开和进入您的网络的流量。 同时，您还可以使用 Firewall Manager 将不同账户中的 VPC 与 Route 53 Resolver DNS Firewall 规则相关联，以阻止针对已知恶意域的 DNS 查询，并且允许针对受信任域的查询。"
    },
    {
        "query":"AWS Firewall Manager 配置什么？",
        "intention":"知识问答",
        "reply":"使用 AWS Firewall Manager，您可以跨您组织中的账户和资源集中配置 AWS WAF 规则、AWS Shield 高级防护、Amazon Virtual Private Cloud (VPC) 安全组、AWS Network Firewall 和 Amazon Route 53 Resolver DNS Firewall 规则。"
    },
    {
        "query":"AWS Firewall Manager 能否配置 VPC 安全组或网络 ACL？",
        "intention":"知识问答",
        "reply":"能。AWS Firewall Manager 确实支持配置 VPC 安全组。但是目前还不支持配置网络 ACL。"
    },
    {
        "query":"AWS Firewall Manager 可以在哪些 AWS 资源上配置规则？",
        "intention":"知识问答",
        "reply":"使用 AWS Firewall Manager，您可以"
    },
    {
        "query":"AWS Firewall Manager 在哪些区域可用？",
        "intention":"知识问答",
        "reply":"请访问 [AWS 区域表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)，以查看 AWS Firewall Manager 的当前可用区域。"
    },
    {
        "query":"AWS Firewall Manager 的先决条件是什么？",
        "intention":"知识问答",
        "reply":"使用 AWS Firewall Manager 有三个必要的先决条件和一个可选的先决条件。"
    },
    {
        "query":"我是否可以创建 Firewall Manager 策略，但不自动修正？",
        "intention":"知识问答",
        "reply":"是，您可以在以下两种模式下配置 Firewall Manager 策略 –"
    },
    {
        "query":"AWS Firewall Manager 可以管理多少个账户？",
        "intention":"知识问答",
        "reply":"每个 Firewall Manager 策略的范围最多可以有 2500 个账户，这是 AWS Organizations 中账户数量的默认限制。"
    },
    {
        "query":"AWS Firewall Manager 可以管理多少个资源？",
        "intention":"知识问答",
        "reply":"目前 Firewall Manager 管理的资源数量没有限制。"
    },
    {
        "query":"我是否可以跨区域创建安全策略？",
        "intention":"知识问答",
        "reply":"否，AWS Firewall Manager 安全策略是区域特定的。每个 Firewall Manager 策略只能包含在指定的 AWS 区域中可用的资源。您可以为您运营的每个区域创建新策略。"
    },
    {
        "query":"我是否可以从策略范围中排除账户或资源？",
        "intention":"知识问答",
        "reply":"可以。您可以排除账户。您还可以使用标签来指定应从策略范围中排除的资源。"
    },
    {
        "query":"什么是 Firewall Manager 安全策略？",
        "intention":"知识问答",
        "reply":"Firewall Manager 安全策略是一组配置，可供客户指定需要关联一组防火墙规则的账户和资源；以及针对每种防火墙类型自定义的其他配置。Firewall Manager 如今支持 AWS WAF、AWS Shield Advanced、VPC 安全组、AWS Network Firewall、Amazon Route 53 Resolver DNS Firewall 和 AWS Marketplace 第三方防火墙。"
    },
    {
        "query":"如何查看特定策略的合规性状态？",
        "intention":"知识问答",
        "reply":"借助 Firewall Manager，您可以通过查看策略范围内包含的账户数量以及其中合规账户的数量，快速查看每个策略的合规性状态。此外，在 Firewall Manager 上配置的每个策略都有一个合规性控制面板。中央合规性控制面板可用于查看哪些账户不符合给定策略，哪些特定资源不合规，还提供有关特定资源不合规的原因的信息。 您还可以在 [AWS Security Hub](https://aws.amazon.com/cn/security-hub/) 上查看每个账户的不合规事件。"
    },
    {
        "query":"当资源不合规时，AWS Firewall Manager 是否提供通知？",
        "intention":"知识问答",
        "reply":"是，您可以创建新的 SNS 通知通道，以便在发现新的不合规资源时收到实时通知。 同样地，对于 [AWS Security Hub](https://aws.amazon.com/cn/security-hub/) 上的不合规事件，也会通知属于 Firewall Manager 策略范围一部分的每个账户。"
    },
    {
        "query":"我如何查看我的组织中的所有威胁？",
        "intention":"知识问答",
        "reply":"对于创建的每个 Firewall Manager 策略，您可以为规则组中的每个规则聚合 CloudWatch 指标，指示整个组织中允许或阻止的请求数量。这为您提供了一个中心位置来为组织中的威胁设置警报。\n了解有关 AWS Firewall Manager 定价的更多信息"
    },
    {
        "query":"什么是 Amazon Elastic Container Service？",
        "intention":"知识问答",
        "reply":"Amazon Elastic Container Service (ECS) 是一项高度可扩展的高性能容器管理服务，支持 Docker 容器，并让您能够在托管的 Amazon Elastic Compute Cloud (Amazon EC2) 实例集群上轻松运行应用程序。使用 Amazon ECS，您将不再需要安装、运维、扩展自己的集群管理基础设施。只需进行简单的 API 调用，您便可以启动和停止支持容器的应用程序，查询集群的完整状态，使用各种熟悉的功能，包括安全组、Elastic Load Balancing、Amazon Elastic Block Store (EBS) 卷和 Identity Access Management (IAM) 角色。您可以使用 Amazon ECS 根据您的资源需求和可用性要求在您的集群中安排容器的置放。您还可以集成自己的计划程序或第三方计划程序，以满足业务或应用程序的特定要求。"
    },
    {
        "query":"为什么应该使用 Amazon ECS？",
        "intention":"知识问答",
        "reply":"使用 Amazon ECS，您将不再需要安装、运维、扩展自己的集群管理基础设施，Amazon ECS 让容器的使用更简单，您可以将其作为构建块用于您的应用程序。Amazon ECS 让您可以使用 Docker 容器来安排长期运行的应用程序、服务和批量进程。Amazon ECS 可以维持应用程序的可用性，让您根据应用程序的容量需求来对容器进行扩缩。Amazon ECS 集成有您熟悉的功能，包括 Elastic Load Balancing、EBS 卷、Amazon Virtual Private Cloud (VPC) 和 IAM。简单的 API 让您可以集成并使用自己的计划程序，或将 Amazon ECS 连接到现有的软件交付流程中。"
    },
    {
        "query":"Amazon ECS 如何定价？",
        "intention":"知识问答",
        "reply":"使用 Amazon ECS 不收取任何额外费用。您只需为您创建的用于存储和运行应用程序的 AWS 资源（例如 Amazon EC2 实例或 EBS 卷）付费。您只需按您的实际用量付费；既没有最低费用，也无需预付费。"
    },
    {
        "query":"Amazon ECS 与 AWS Elastic Beanstalk 有什么区别？",
        "intention":"知识问答",
        "reply":"AWS Elastic Beanstalk 是一个应用程序管理平台，可以帮助客户轻松部署和扩展 Web 应用程序和服务。它将构建块（例如 EC2、Amazon RDS、Elastic Load Balancing、AWS Auto Scaling 和 Amazon CloudWatch）的预置、应用程序的部署、运行状况监控从用户身上分离出来，让用户可以集中精力编写代码。您只需指定要部署的容器映像、CPU 和内存要求、端口映射和容器链接即可。\nElastic Beanstalk 将自动处理所有的具体事务，包括预置 Amazon ECS 集群、均衡负载、自动扩展、监控以及在集群中放置容器。如果您希望利用容器的各种优势，但只想通过上传容器映像，在开发到生产等环节部署应用程序时享受到简易性，则 Elastic Beanstalk 非常适合。如果您需要对自定义应用程序架构进行更多精细化的控制，则可以直接使用 Amazon ECS。"
    },
    {
        "query":"Amazon ECS 与 AWS Lambda 有什么区别？",
        "intention":"知识问答",
        "reply":"Amazon Container Service 是一项高度可扩展的 Docker 容器管理服务，让您可以运行和管理在 Docker 容器中运行的分布式应用程序。AWS Lambda 是一项事件驱动型任务计算服务，在响应数据更改、网站点击或来自其他 AWS 服务的消息等“事件”时运行您的代码，无需您管理任何计算基础设施。"
    },
    {
        "query":"怎样开始使用 Amazon ECS？",
        "intention":"知识问答",
        "reply":"请访问我们的[入门](https://aws.amazon.com/cn/ecs/getting-started/)页面，了解有关如何开始使用 Amazon ECS 的更多信息。"
    },
    {
        "query":"Amazon ECS 是否支持任何其他容器类型？",
        "intention":"知识问答",
        "reply":"不支持。Amazon ECS 目前只支持 Docker 这一容器平台。"
    },
    {
        "query":"我想启动容器。为什么必须启动任务？",
        "intention":"知识问答",
        "reply":"Docker 鼓励您将您的应用程序分成单个组件，Amazon ECS 针对此模式进行了优化。任务让您可以定义想要放置在一起的一组容器或一部分容器、容器的属性及其链接方式。任务中包含 Amazon ECS 确定如何放置所需的所有信息。要启动单个容器，您的任务定义中应该只包含一个容器定义。"
    },
    {
        "query":"Amazon ECS 是否支持应用程序和服务？",
        "intention":"知识问答",
        "reply":"支持。Amazon ECS 服务计划程序可以管理长期运行的应用程序和服务。使用服务计划程序，您可以维持应用程序的可用性，并且根据应用程序的容量要求来扩展或缩小容器。服务计划程序让您可以使用 Elastic Load Balancing (ELB) 在各个容器间分配流量。Amazon ECS 将自动从关联的负载均衡器注册和注销容器。\n服务计划程序还将自动恢复运行状况不佳（例如 ELB 运行状况检查失败）或停止运行的容器，保证正常运行的容器达到所需数量，以便支持您的应用程序。\n通过改变您希望服务运行的容器的数量，可以扩展或缩小应用程序的规模。改变应用程序的定义或使用新的映像可以更新应用程序。计划程序将自动启动使用新定义的新容器并停止运行之前版本的容器（如果使用 ELB，则会等待 ELB 连接耗尽）。"
    },
    {
        "query":"Amazon ECS 是否支持动态端口映射？",
        "intention":"知识问答",
        "reply":"是。可以将 Amazon ECS 上的服务与 ELB 服务的 Application Load Balancer (ALB) 相关联。ALB 支持包含一组实例端口的目标组。您可以在 ECS 任务定义中指定动态端口，这可为安排在 EC2 实例上的容器提供未使用的端口。ECS 计划程序将自动向应用程序负载均衡器中使用此端口的目标组添加任务。"
    },
    {
        "query":"Amazon ECS 是否支持批量作业？",
        "intention":"知识问答",
        "reply":"支持。您可以使用 Amazon ECS Run 任务一次运行一个或多个任务。Run 任务在符合任务要求（包括 CPU、内存和端口要求）的实例中开始任务。"
    },
    {
        "query":"能否将自己的计划程序与 Amazon ECS 配合使用？",
        "intention":"知识问答",
        "reply":"ECS 提供了 Blox，这是一个用于容器管理和编排的开源对象集合。借助 Blox，您可以轻松地从 Amazon ECS 使用事件、在本地存储集群状态以及通过 API 查询本地数据存储。此外，Blox 还包含一个守护程序计划程序，可用作关于如何使用集群状态服务器的引用。请参阅 [Blox GitHub 页面](https://blox.github.io/)了解更多信息。"
    },
    {
        "query":"我是否能够使用自己的 Amazon Machine Image (AMI)？",
        "intention":"知识问答",
        "reply":"是。您可以使用满足 Amazon ECS AMI 规范的任何 AMI。我们建议先从支持 Amazon ECS 的 Amazon Linux AMI 开始用起。兼容 Amazon ECS 的合作伙伴 AMI 也可以使用。您可以查阅[相关文档](https://aws.amazon.com/cn/documentation/ecs/)了解 Amazon ECS AMI 规范的情况。"
    },
    {
        "query":"应该如何配置我的容器实例，以便从 Amazon Elastic Container 注册表中提取？",
        "intention":"知识问答",
        "reply":"Amazon ECR 与 Amazon ECS 集成，让您能够轻松地存储、运行和管理在 Amazon ECS 上运行的应用程序的容器映像。为此，您只需在您的任务定义中指定 Amazon ECR 存储库，然后将 [AmazonEC2ContainerServiceforEC2Role](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/instance_IAM_role.html) 附加至您的实例即可。Amazon ECS 将为您的应用程序检索相应的映像。"
    },
    {
        "query":"AWS Fargate 怎样与 Amazon ECS 配合发挥作用？",
        "intention":"知识问答",
        "reply":"使用 [Fargate](https://aws.amazon.com/cn/fargate/) 便可完全抛弃服务器预置、集群管理和编排的概念。Amazon ECS 使用 Fargate 预置的容器对您的容器进行自动扩展、负载均衡和计划管理工作以便保证可用性，让您可以更轻松地构建和运行容器化应用程序。"
    },
    {
        "query":"怎样在 AWS Fargate 加 Amazon ECS 和只使用 ECS 之间做出选择？",
        "intention":"知识问答",
        "reply":"Amazon ECS 支持 Fargate 技术，客户可以选择使用 AWS Fargate 来启动容器，无需预置或管理 Amazon EC2 实例。AWS Fargate 是在 AWS 上启动和运行容器的最易用的工具。如果客户需要对 EC2 实例进行更高的控制，以便满足合规和监管要求或者支持更多的自定义选项，则可以只使用 ECS 而不使用 Fargate 来启动 EC2 实例。"
    },
    {
        "query":"Amazon ECS 如何隔离属于不同客户的容器？",
        "intention":"知识问答",
        "reply":"Amazon ECS 在客户控制的 Amazon EC2 实例中排定容器的执行，或者使用 AWS Fargate 排定容器的执行，其隔离控制功能和合规性设置与 EC2 相同。您的计算实例位于 Virtual Private Cloud (VPC) 中，它具有指定的 IP 范围。您可以决定哪些实例向互联网公开，哪些实例保持私有状态。"
    },
    {
        "query":"能否对容器实例应用额外的安全配置和隔离框架？",
        "intention":"知识问答",
        "reply":"是。 作为 Amazon EC2 客户，您对您的容器实例的操作系统 (OS) 具有根用户访问权限。您可以拥有操作系统安全设置的所有权，也可以为安全功能配置额外的软件组件，如监控、补丁管理、日志管理和主机入侵检测。"
    },
    {
        "query":"能否以不同的安全设置来运行容器实例，或者将不同的任务隔离在不同的环境中？",
        "intention":"知识问答",
        "reply":"可以。您可以使用您选择的工具配置不同的容器实例。通过构筑集群和针对目标的启动，Amazon ECS 允许您控制任务在不同容器实例中的置放情况。"
    },
    {
        "query":"Amazon ECS 是否支持从私有或内部来源中检索 Docker 镜像？",
        "intention":"知识问答",
        "reply":"是。客户可以对其容器实例进行配置，以访问 VPC 内的私有 Docker 镜像注册表或可从 VPC 外部访问的注册表，如 [Amazon Elastic Container Registry (ECR)](https://aws.amazon.com/ecr/getting-started/)。"
    },
    {
        "query":"如何为 ECS 任务配置 IAM 角色？",
        "intention":"知识问答",
        "reply":"首先，您需要为您的任务创建 IAM 角色，使用“Amazon EC2 Container Service Task Role”服务角色并附加含必要权限的策略即可成功创建。当您新建一项任务定义或修订任务定义时，您可以从“Task Role”下拉列表中选择一个角色，或使用以 JSON 格式存储的“taskRoleArn”来指定角色。"
    },
    {
        "query":"Amazon ECS 符合哪些合规性计划？",
        "intention":"知识问答",
        "reply":"Amazon ECS 符合 PCI DSS 第 1 级、ISO 9001、ISO 27001、ISO 27017、ISO 27018、SOC 1、SOC 2、SOC 3 和 HIPAA 要求的标准。  \n   \n 有关更多信息，请访问我们的[合规性页面](https://aws.amazon.com/cn/compliance/)。\n问：是否可以使用 Amazon ECS 处理受保护健康信息 (PHI) 和其他受 HIPAA 监管的工作负载？\n是的。Amazon ECS 符合 HIPAA 要求。如果您已与 AWS 签署[商业伙伴增订合约 (BAA)](https://aws.amazon.com/cn/compliance/hipaa-compliance/)，则可以利用 Amazon ECS 对采用部署到 [AWS Fargate](https://aws.amazon.com/cn/fargate/) 的启动类型或 Amazon EC2 计算实例的 Docker 容器的加密受保护健康信息 (PHI) 进行处理。\n有关更多信息，请访问我们的 [HIPAA 合规性](https://aws.amazon.com/cn/compliance/hipaa-compliance/)页面。如果您打算处理、存储或传输 PHI 且尚未与 AWS 签署 BAA，请[联系我们](https://aws.amazon.com/cn/contact-us/)获取更多信息。"
    },
    {
        "query":"是否可以使用 Amazon ECS 处理受美国政府监管的工作负载，或处理敏感的受控非机密信息 (CUI)？",
        "intention":"知识问答",
        "reply":"可以。利用 AWS GovCloud（美国）区域，由 Amazon ECS 管理的容器和集群也能满足您的容器的敏感数据和受监管工作负载的要求。  \n   \n 有关更多信息，请访问我们的 [AWS GovCloud](https://aws.amazon.com/cn/govcloud-us/) 页面。"
    },
    {
        "query":"Amazon ECS 的 SLA 有什么保证？",
        "intention":"知识问答",
        "reply":"我们的计算 SLA 保证 Amazon ECS 的月度正常运行时间百分比至少达到 99.99%。"
    },
    {
        "query":"怎样确定我是否有资格获得 SLA 服务抵扣？",
        "intention":"知识问答",
        "reply":"对于您运行任务所在的可用区，如果同一个区域内有一个以上的可用区在任何月度账单周期内的月度正常运行时间百分比没有达到 99.99%，那么您就有资格获得计算 SLA 规定的 Amazon ECS SLA 服务抵扣。\n如需 SLA 的所有条款与条件的完整详细信息，以及如何提交索赔的详细信息，请参阅[计算 SLA 详细信息页面](https://aws.amazon.com/cn/compute/sla/)。\n开始使用 Amazon ECS"
    },
    {
        "query":"为何我应该使用 AWS App Runner？ 答：AWS App Runner 是客户在 AWS 上运行其 Web 应用程序（包括 API 服务、后端 Web 服务和网站）的最简便方法。利用 App Runner，您不再需要基础设施或容器编排。您可以在几分钟之内从现有的容器映像、容器注册表、源代码存储库或现有的 CI/CD 工作流转到 AWS 上完全运行的容器化 Web 应用程序。",
        "intention":"知识问答",
        "reply":"App Runner 与您的开发工作流程无缝集成，以提供适当的自动化水平来部署您的代码或容器映像，而不需要您了解、预置、扩展或管理任何 AWS 计算、联网和路由资源。您可以轻松地运行成千上万的应用程序，这些应用程序将根据您的流量需求自动进行扩展。您的应用程序还可以在由 AWS 维护和运营的基础设施上运行，从而提供安全性和合规性最佳实践，例如自动化安全补丁和加密。"
    },
    {
        "query":"使用 AWS App Runner，我有哪些类型的部署选项？  答：AWS App Runner 支持多种部署选项，包括使用 App Runner 控制台或 AWS CLI 立即部署容器映像的能力。如果现有 CI/CD 工作流使用 AWS CodePipeline、Jenkins、Travis CI、CircleCI 或其他 CI/CD 工具链，则可以使用 App Runner API 或 AWS CLI 轻松地将 App Runner 添加为部署目标。如果您希望 App Runner 自动为您提供连续部署，则可以轻松地连接到现有的容器注册表或源代码存储库，App Runner 将自动为您提供连续的部署管道。",
        "intention":"知识问答",
        "reply":"使用 App Runner，您可以让每个容器映像或源代码分支具有唯一的应用程序，并具有单独的环境变量、部署类型（例如开发应用程序或生产应用程序）以及构建和启动命令。部署后，您将获得在 App Runner 上运行 Web 应用程序的所有益处，包括默认安全性、自动扩展和监控。"
    },
    {
        "query":"如何查看我在 AWS App Runner 上运行的应用程序的日志？ 答：AWS App Runner 与 Amazon CloudWatch Logs 完全集成，并为您提供从所有系统组件、Web 框架、运行时、构建和部署命令以及应用程序/Web 服务器的输出流汇总的运行时日志和部署日志。App Runner 将这些聚集成一个综合渠道，可通过 App Runner 控制台、CloudWatch 控制台和 AWS CLI 使用。",
        "intention":"知识问答",
        "reply":"我是否可以使用编排工具在 AWS App Runner 上运行 Web 应用程序，并在 AWS Fargate 上运行持久性应用程序？  \n 答：可以。如果您需要运行其他应用程序（例如需要持久性文件系统或机器学习作业的内容管理系统），则可以将 AWS Fargate 与能够支持多种资源（例如图形加速或持久化卷）的编排工具一起使用。如果您使用的是 Copilot CLI，则可以继续使用该工具，因为它同时支持 App Runner 和 ECS/Fargate。您还可以将 Amazon CloudWatch 用作单一虚拟管理平台，以监控跨 App Runner 运行的应用程序、在 Fargate 上运行的 Amazon ECS 任务以及在 Fargate 上运行的 Amazon EKS pod。"
    },
    {
        "query":"什么是 Amazon Lex？",
        "intention":"知识问答",
        "reply":"Amazon Lex 是一种使用语音和文本构建对话界面的服务。Amazon Lex 使用的对话引擎与 Alexa 相同，可以提供高质量的语音识别和语言理解功能，让您能够在新的或现有的应用程序中添加掌握自然语言的精密“聊天机器人”。Amazon Lex 可以减少多平台开发的工作量，让您能够轻松将语音或文本聊天机器人发布到移动设备以及 Facebook Messenger、Slack、Kik 或 Twilio SMS 等多种聊天服务。Amazon Lex 可在本地与 AWS Lambda 和 Amazon CloudWatch 进行互操作，还可以轻松集成 AWS 平台上的许多其他服务（包括 Amazon Cognito 和 Amazon DynamoDB），从而让您更轻松地开发机器人。"
    },
    {
        "query":"如何开始使用 Amazon Lex？",
        "intention":"知识问答",
        "reply":"要开始使用 Amazon Lex，只需登录 AWS 管理控制台并导航到“人工智能”分类下的 “Lex” 即可。您必须具有一个 Amazon Web Services 账户才能开始使用 Amazon Lex。如果您没有账户，系统会在注册过程中提示您创建一个账户。有关更多信息，请参阅 [Amazon Lex V2 入门指南](https://docs.aws.amazon.com/lexv2/latest/dg/getting-started.html)。"
    },
    {
        "query":"Amazon Lex 最常见的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"Amazon Lex 最常见的使用案例包括："
    },
    {
        "query":"Amazon Lex 如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"Amazon Lex 利用 AWS Lambda 实现意图，利用 Amazon Cognito 进行用户身份验证，以及利用 Amazon Polly 将文本转换为语音。"
    },
    {
        "query":"我是否必须是机器学习专家才能使用 Amazon Lex？",
        "intention":"知识问答",
        "reply":"不必，使用 Amazon Lex 不需要具备机器学习方面的专门知识。开发人员可以用声明的方式指定对话流程，Amazon Lex 会负责语音识别和自然语言理解工作。开发人员需要用简单的英语提供一些示例语句，并提供他们通过相应提示问题从用户收集的不同参数（信息槽）。之后，Amazon Lex 会自动创建语言模型。"
    },
    {
        "query":"哪些 AWS 区域提供 Amazon Lex 服务？",
        "intention":"知识问答",
        "reply":"有关支持 Amazon Lex 的 AWS 区域列表，请访问所有 AWS 全球基础设施的 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regions_az/)。有关更多信息，另请参阅 AWS 一般参考中的[区域和端点](https://docs.aws.amazon.com/general/latest/gr/rande.html)。"
    },
    {
        "query":"Amazon Lex 可以支持的最大带宽是多少？",
        "intention":"知识问答",
        "reply":"Amazon Lex 可以根据您的需求进行扩展，不存在带宽限制。"
    },
    {
        "query":"Amazon Lex 是不是一种托管服务？",
        "intention":"知识问答",
        "reply":"Amazon Lex 是一种完全托管的服务，所以您无需担心资源扩展或代码维护的问题。Amazon Lex 会自动备份您使用的交互模式和语言模型。我们还提供全面的版本控制功能，便于回滚。Amazon Lex 架构不要求存储或备份终端用户数据。"
    },
    {
        "query":"何时使用 Amazon Polly 和Amazon Lex？",
        "intention":"知识问答",
        "reply":"Amazon Polly 可以将文本转换为语音。Amazon Lex 是一种使用语音和文本构建对话界面的服务。"
    },
    {
        "query":"Amazon Lex 是否会不断提高智能化水平？",
        "intention":"知识问答",
        "reply":"会。借助深度学习技术，Amazon Lex 会不断完善。"
    },
    {
        "query":"如何使用自动化聊天机器人设计器？",
        "intention":"知识问答",
        "reply":"只需单击几下，自动化聊天机器人设计器便可以帮助您创建机器人设计。首先通过 Lex 控制台（或 SDK）提供一个连接至 S3 的链接，其中包含您的对话文本。然后，自动化聊天机器人设计器处理这些对话文本，生成聊天机器人设计，其中包括用户意图、与意图关联的示例短语以及实现这些意图所需的所有信息的列表。您可以查看自动化聊天机器人设计器提供的结果，并添加最适合您的机器人的意图和槽类型。"
    },
    {
        "query":"自动化聊天机器人设计器支持什么格式的转录文本？",
        "intention":"知识问答",
        "reply":"转录文本必须包含来电人和坐席之间的会话，对话转录文本为标准JSON 格式。您可以在 Amazon Lex 文档中找到这种格式的示例转录文本。使用 Contact Lens 的 Amazon Connect 客户可以直接使用原始格式的对话转录文本。来自其他转录服务的对话转录文本可能需要进行简单的转换。可在此处找到有关对话流程的详细信息。"
    },
    {
        "query":"自动化聊天机器人设计器支持什么语言？",
        "intention":"知识问答",
        "reply":"自动化聊天机器人设计器支持 Amazon Lex 支持的所有英语语言（美国、英国、澳大利亚、印度、沙特阿拉伯）。预览版自动化聊天机器人设计器支持美国英语。"
    },
    {
        "query":"V2 增强型控制台和 API 提供了哪些可用性改进？",
        "intention":"知识问答",
        "reply":"Lex V2 控制台和 API 使用更新的信息架构 (IA) 提供简化的版本控制、在机器人中支持多种语言以及流式功能。 其他改进包括保存部分完成的机器人配置、重命名资源、简化导航、批量上传语句和粒度调试。"
    },
    {
        "query":"如何使用流式功能？",
        "intention":"知识问答",
        "reply":"您可以使用流式 API 与 Lex 机器人进行持续流式会话。对于流式会话，机器人会不断进行监听，并且可以设计为主动响应用户中断和暂停。例如，您可以将机器人配置为在用户需要更多时间进行响应时使会话持续进行，发送定期消息即可，例如“别着急。准备好了就告诉我。”"
    },
    {
        "query":"V2 API 的定价详情是什么？",
        "intention":"知识问答",
        "reply":"Amazon Lex 机器人专为请求和响应交互或持续流式会话而设计。对于请求和响应交互，每条用户输入（语音或文本）都作为一个单独的 API 调用进行处理。在流式会话中，跨多个回合的所有用户输入都在一个流式 API 调用中进行处理。有关更多详情，请参阅 [Amazon Lex 定价页面](https://aws.amazon.com/cn/lex/pricing/)。  \n   \n 问：是否可以将使用 V2 API 创建的机器人与 Amazon Connect 联系流集成？\n是，Amazon Connect 联系流可与 Lex V2 和 V1 API 共同使用。您可以使用 Lex V2 控制台创建机器人并将其与 Amazon Connect 相集成。"
    },
    {
        "query":"是否可以对现有机器人利用 V2 API 功能？",
        "intention":"知识问答",
        "reply":"不可以。如果您想利用 V2 功能，需要使用 V2 API 重新创建机器人。Lex V1 API 不兼容，因为 V2 API 使用更新的信息架构，以简化资源版本控制并在机器人中支持多种语言。转换为 V2 API 很容易，因此请参阅此分步迁移指南。"
    },
    {
        "query":"V2 API 支持哪些区域和语言？",
        "intention":"知识问答",
        "reply":"Amazon Lex V2 API 和增强的控制台体验可在所有现有的 8 个区域使用并提供以下语言版本，包括美国英语、西班牙语、法语、德语、意大利语、日语、澳大利亚英语、英国英语、加拿大法语、拉丁美洲西班牙语和美国西班牙语。要查看支持 Amazon Lex 的 AWS 区域列表，请访问 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"现有 API 是否支持新功能，例如简化的版本控制和在机器人支持多种语言？",
        "intention":"知识问答",
        "reply":"否。这些功能仅在 V2 API 中可用。如果您想利用这些功能，可以按照此[迁移指南](https://docs.aws.amazon.com/lexv2/latest/dg/migration.html)迁移到 V2 API。"
    },
    {
        "query":"我是否能访问 V1 控制台？",
        "intention":"知识问答",
        "reply":"能，您可以在 [AWS 管理控制台](https://console.aws.amazon.com/lex/)中访问 V1 控制台。位于 Lex 控制台中后，您可以在 V1 和 V2 控制台之间导航。在 V1 控制台中创建的机器人将只在 V1 控制台中可见。只有在 V2 控制台中重新创建 V1 机器人，才能在 V2 控制台中访问 V1 机器人。将机器人迁移到 V2 很容易，请参阅此分步[迁移指南](https://docs.aws.amazon.com/lexv2/latest/dg/migration.html)。"
    },
    {
        "query":"如何访问 V2 控制台？",
        "intention":"知识问答",
        "reply":"您可以单击左侧导航栏中的链接，选择 V1 或 V2 作为控制台。"
    },
    {
        "query":"是否仍可以使用 Lex V1 API？",
        "intention":"知识问答",
        "reply":"可以。现有 Lex V1 API 仍受支持。您可以继续使用这些 API 构建和执行机器人对话。"
    },
    {
        "query":"Amazon Lex 机器人与 Alexa 技能工具包有何区别？",
        "intention":"知识问答",
        "reply":"利用 Alexa 技能工具包，可以构建在 Alexa 生态系统和设备中使用的技能，并且开发人员可以充分利用所有的 Alexa 功能（例如 Smart Home 和 Flash Briefing API）、流式音频和丰富的 GUI 经验。Amazon Lex 机器人支持语音和文本处理，并且可以部署到各种移动和消息收发平台。"
    },
    {
        "query":"要调用 Amazon Lex 意图，是否需要语音唤醒功能？",
        "intention":"知识问答",
        "reply":"Amazon Lex 不支持语音唤醒功能。集成了 Amazon Lex 的应用程序将负责触发麦克风，即“即按即说”功能。"
    },
    {
        "query":"Amazon Lex 机器人是否可以使用 Alexa 语音做出响应？",
        "intention":"知识问答",
        "reply":"目前，Amazon Lex 不支持使用 Alexa 语音做出响应。但是，我们提供了另外 7 种声音供您选择。"
    },
    {
        "query":"我能否从 Amazon Lex 机器人创建一项 Alexa 技能？",
        "intention":"知识问答",
        "reply":"Amazon Lex 为您提供了将 Amazon Lex 机器人模式导出到与 Amazon Alexa 兼容的 JSON 文件的能力。一旦下载为 JSON，您需要登录到 Alexa 开发人员门户，导航到“交互模型”选项卡，启动 Alexa 技能构建器，并将机器人模式粘贴到 Alexa 技能的代码编辑器中。有关详细信息和步骤，请参阅 [Amazon Lex 文档](http://docs.aws.amazon.com/lex/latest/dg/export.html)。"
    },
    {
        "query":"在导出 Amazon Lex 机器人模式用于 Alexa 技能时，是否会将我的 AWS Lambda 函数导出并包含在机器人模式中？",
        "intention":"知识问答",
        "reply":"不会。仅下载机器人定义。"
    },
    {
        "query":"我使用了模式导出功能，从 Amazon Lex 机器人中创建了一项 Alexa 技能。哪个 Alexa 平台会支持 Amazon Lex 机器人模式？",
        "intention":"知识问答",
        "reply":"所有支持 Alexa 技能的 Alexa 平台都可以使用：Amazon Echo、Amazon Dot、Amazon Look、Amazon Tap、Amazon Echo Show，以及任何其他[启用了 Alexa 的第三方设备](https://www.amazon.com/b/ref=EchoCP_avs_tile_text?node=15443147011)。"
    },
    {
        "query":"Amazon Lex 是否会存储处理过的语音和文本输入？AWS 如何使用这些输入？",
        "intention":"知识问答",
        "reply":"Amazon Lex 可以存储和使用仅由该服务处理的语音和文本输入，以提供和维护服务，以及改进和提高 Amazon Lex 和其他 Amazon 机器学习/人工智能技术的质量。为了持续改善您的 Amazon Lex 客户体验并促进相关技术的开发和训练，我们必须使用您的内容。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/cn/compliance/data-privacy-faq/)。您可以通过使用 AWS Organizations 停用策略，选择不再使用您的内容来改进和提高 Amazon Lex 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"是否可以删除 Amazon Lex 存储的语音和文本输入？",
        "intention":"知识问答",
        "reply":"可以。您可以联系取消删除，请求删除与您的账户相关的语音和文本输入。删除语音和文本输入可能会降低您的 Amazon Lex 体验。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"谁有权访问 Amazon Lex 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问 Amazon Lex 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"由 Amazon Lex 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"是否可以将 Amazon Lex 用于针对不满 13 岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 [Amazon Lex 服务条款](https://aws.amazon.com/service-terms/)的规定，包括按照 COPPA 的要求来提供任何需要的通知并获得任何需要的、可验证的家长同意，才能将 Amazon Lex 用于全部或部分针对不满 13 岁的儿童的网站、项目或其他应用程序。对于客户按照 Amazon Lex 服务条款将其确定为全部或部分针对不满 13 岁的儿童并且受 COPPA 约束的网站、项目或应用程序，Amazon Lex 不会存储或保留其中的语音或文本语句信息。"
    },
    {
        "query":"怎样确定我的网站、项目或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、计划或其他应用是否受 COPPA 约束的指南，请直接参阅[美国联邦贸易委员会](https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions)提供并维护的各种资源。该网站还提供有关如何确定某种服务是否全部或部分针对不满 13 岁儿童的信息。"
    },
    {
        "query":"Amazon Lex 可以支持哪些软件开发工具包？",
        "intention":"知识问答",
        "reply":"Amazon Lex 目前支持适用于运行时服务的软件开发工具包。IoS 和 Android 开发工具包以及 Java、JS、Python、CLI、.Net、Ruby、PHP、Go 和 CPP 均支持文本和语音输入。"
    },
    {
        "query":"能否用 SDK 来构建机器人？",
        "intention":"知识问答",
        "reply":"您可以使用 Java、JavaScript、Python、CLI、.NET、Ruby on Rails、PHP、Go 和 CPP 等开发工具包来构建机器人。"
    },
    {
        "query":"Amazon Lex 如何计算请求数量？",
        "intention":"知识问答",
        "reply":"提供给 Amazon Lex 机器人的每条输入都被计为一条请求。例如，如果一位最终用户在对话过程中向机器人提供了 5 条输入，那么，这 5 条输入将被计为 5 条请求。使用费用是按请求数计量和收费的。"
    },
    {
        "query":"AWS 免费套餐是否包括 Amazon Lex？  可以。您可以免费试用 Amazon Lex。从开始使用 Amazon Lex 之日起，您在第一年内每月可以免费处理多达 10000 条文本请求和 5000 条语音请求。",
        "intention":"知识问答",
        "reply":"了解有关 Amazon Lex 定价的更多信息"
    },
    {
        "query":"什么是 Amazon Braket？",
        "intention":"知识问答",
        "reply":"[Amazon Braket](https://aws.amazon.com/cn/braket/) 是一项完全托管的服务，可帮助您开始探索量子计算。"
    },
    {
        "query":"Amazon Braket 有什么作用？",
        "intention":"知识问答",
        "reply":"通过 Amazon Braket，您可以学习如何对量子计算机进行编程以及如何探索可能的应用情况。您可以从零开始设计自己的量子算法，也可以从一组预先构建的算法中进行选择。Amazon Braket 提供了一个开发工具包，您可以在笔记本电脑上运行，也可以在由 Amazon Braket 完全托管的笔记本环境中运营。软件开发工具包包含量子电路模拟器。AWS Braket 服务还提供完全托管的量子电路模拟器，让您能够在 AWS 托管的基础设施上运行算法，来验证和测试您的实施情况。准备就绪后，您可以在 Amazon Braket 上使用不同的量子计算机或量子处理单元（从我们的[硬件提供商](https://aws.amazon.com/cn/braket/hardware-providers/)处选择）上运行算法。"
    },
    {
        "query":"AWS Braket 如何与其他 AWS 服务集成？",
        "intention":"知识问答",
        "reply":"Amazon Braket 可与 Amazon CloudWatch、Amazon EventBridge、AWS Identity and Access Management（IAM）以及 AWS CloudTrail 集成，进行监控、日志记录、用户访问管理和日志的处理。模拟和量子计算结果将存储在您账户中的 Amazon Simple Storage Service（S3）中。"
    },
    {
        "query":"我们公司目前为何应考虑量子计算？",
        "intention":"知识问答",
        "reply":"量子计算是一项处于早期发展阶段的技术，但它的长期影响有望为许多行业带来变革。要开发量子算法并设计有用的量子应用程序，将需要新的技术以及可能截然不同的方法。构建该技术将需要时间并访问量子技术和编程工具。Amazon Braket 和 [Amazon Quantum Solutions Lab](https://aws.amazon.com/cn/quantum-solutions-lab/) 可帮助组织评估当前技术状态，识别其对业务的影响，并为未来做好准备。"
    },
    {
        "query":"为什么将该服务命名为“Braket”？",
        "intention":"知识问答",
        "reply":"我们是以 bra-ket 符号（量子力学中的标准符号）来命名我们的服务的。它由 Paul Dirac 于 1939 年提出，用于描述量子系统的状态，也称为狄拉克 (Dirac) 符号。"
    },
    {
        "query":"我能在 Amazon Braket 上开展学术研究吗？",
        "intention":"知识问答",
        "reply":"可以。世界各地大学的科学家都在 Amazon Braket 上开展研究。您可以在 [Amazon Braket 控制台](https://console.aws.amazon.com/braket/home)、我们的 [Github 存储库](https://github.com/aws/amazon-braket-examples) 开始，或通过 [AWS Cloud Credit for Research](https://aws.amazon.com/cn/government-education/research-and-technical-computing/cloud-credit-for-research/) 项目为使用 Amazon Braket 申请资金。在申请过程中，如果您没有适用于定价计算器的 URL，请使用占位符提交您的申请。\n什么是 Amazon Braket 开发工具包？\nAmazon Braket 开发工具包 (SDK) 是一个对技术没有要求的开发人员框架，您可以使用 Amazon Braket 服务来开发量子算法并在不同的量子计算硬件和模拟器上运行它们。开发工具包可帮助您跟踪并监控提交给 Amazon Braket 的量子任务并评估结果。Amazon Braket 开发工具包包含本地量子电路模拟器，可用来测试您的算法。"
    },
    {
        "query":"如何使用 Amazon Braket 开发工具包？",
        "intention":"知识问答",
        "reply":"Amazon Braket 提供了完全托管的 Jupyter 笔记本，这些笔记本预安装了 Amazon Braket 开发工具包，并提供了可帮助您快速入门的示例教程。Amazon Braket 开发工具包是一种[开源](https://github.com/aws/amazon-braket-sdk-python)工具包，因此您可以在自己选择的任意本地集成式开发环境（IDE）中使用 Amazon Braket。"
    },
    {
        "query":"什么是脉冲级访问？",
        "intention":"知识问答",
        "reply":"目前的量子计算机噪声很大，研究人员通常需要对硬件进行最低级别的控制，以研究噪声或串扰、开发新的更强大的门、设计错误缓解方案，并探索新的量子算法。通过脉冲控制，您可以操纵控制量子处理器量子位的低级模拟信号或脉冲。"
    },
    {
        "query":"Amazon Braket SDK 是否支持脉冲级编程？",
        "intention":"知识问答",
        "reply":"是。您可以直接使用门、脉冲或它们的组合在 Rigetti Computing 和 Oxford Quantum Circuits 量子计算机上对量子电路进行编程。您还可以有选择地在程序的特定区域插入脉冲指令块，以专注于优化单个操作和微调性能。"
    },
    {
        "query":"什么是 PennyLane？",
        "intention":"知识问答",
        "reply":"PennyLane 是一款开源软件库，可用于与 Amazon Braket 整合的变分量子计算。变分量子计算是一种利用混合量子经典算法迭代地寻找各种领域计算问题的解决方案的范例，如化学、优化和量子机器学习。基于量子可微编程的概念，PennyLane 让你可以像训练神经网络一样训练量子电路。它提供了流行的机器学习库的接口，包括 PyTorch 和 TensorFlow，使训练您的量子算法简单和直观。您可以通过 <https://pennylane.ai> 了解更多关于 PennyLane 的内容，以及单击[此处](https://docs.aws.amazon.com/braket/latest/developerguide/what-is-braket.html)阅读我们的开发人员指南。"
    },
    {
        "query":"我为什么要通过 Amazon Braket 使用 PennyLane？",
        "intention":"知识问答",
        "reply":"化学、优化和量子机器学习领域近期的量子计算应用程序基于变分量子算法，利用经典和量子计算机之间的迭代处理。PennyLane 让您很容易开始在 Amazon Braket 上构建变分和量子机器学习算法。它能让您使用熟悉的工具完成从机器学习到搭建和训练算法的一系列操作。PennyLane 能够提供化学库 qchem，您可以用几行代码将一个计算化学问题映射到量子计算公式。\nAmazon Braket 可帮助您通过 PennyLane 加速创新。当测试和优化您的算法时，我们的完全托管式、高性能按需模拟器可以用本地模拟算法 10 倍多的速度来加速培训速度。  为了加快混合量子算法的速度，您现在可以使用 PennyLane 高性能嵌入式模拟器，例如由 [NVIDIA 的 cuQuantum SDK](https://developer.nvidia.com/cuquantum-sdk) 为基于 GPU 的工作负载进行加速的 lightning.gpu 模拟器。这些模拟器采用了[伴随法](https://pennylane.readthedocs.io/en/stable/introduction/interfaces.html#simulation-based-differentiation)等方法进行梯度计算，可以减少计算和梯度所需的电路数量，并可用于快速迭代实验和原型设计。"
    },
    {
        "query":"如何访问 PennyLane？",
        "intention":"知识问答",
        "reply":"Amazon Braket 笔记本电脑预配置了 PennyLane，同时我们的教程笔记本可方便您快速入门。或者，您也可以针对选择的任一 IDE 安装 Amazon Braket PennyLane 插件。这个插件是开放源，并且可以从[此处](https://github.com/aws/amazon-braket-pennylane-plugin-python)下载。您可以通过 <https://pennylane.ai> 查找 PennyLane 文档。"
    },
    {
        "query":"什么是 OpenQASM？",
        "intention":"知识问答",
        "reply":"[OpenQASM](https://qiskit.github.io/openqasm/) 是用于量子计算程序的开源中间表示形式 (IR)。您可以通过 Amazon Braket 软件开发工具包或通过直接将其提交到 Braket API 在所有基于门的 Braket 设备上运行 OpenQASM 程序。AWS 已经加入了 [OpenQASM 指导委员会](https://aws.amazon.com/blogs/quantum-computing/aws-joins-the-openqasm-3-0-technical-steering-committee/)，以帮助为基于门的量子程序构建开放、与硬件无关且统一的规格。"
    },
    {
        "query":"什么是错误缓解？",
        "intention":"知识问答",
        "reply":"错误缓解包括多种方法，通过将输入电路映射到一组相关电路并对结果应用经典的后处理来减少系统噪声对目前容易出错的硬件的影响。"
    },
    {
        "query":"Amazon Braket SDK 支持错误缓解吗？",
        "intention":"知识问答",
        "reply":"支持。您可以使用 IonQ 的去偏技术在 IonQ Aria QPU 上尝试缓解错误。请注意，这种缓解错误的方法要求对每项任务至少进行 2500 次试验。"
    },
    {
        "query":"我为何要模拟算法？",
        "intention":"知识问答",
        "reply":"量子电路模拟器在传统计算机上运行。使用模拟器后，您测试量子算法的成本将比使用量子硬件更低，而且不必等待访问特定量子设备。模拟是在量子硬件上运行算法之前，快速调试量子电路以及诊断和优化算法的便捷方式。传统模拟对于验证近期量子计算硬件的结果以及研究噪声的影响同样很有必要。"
    },
    {
        "query":"Amazon Braket 提供哪些模拟器？",
        "intention":"知识问答",
        "reply":"Amazon Braket 为您提供四种量子电路模拟器选择：开发工具包中的本地模拟器，以及另外三种按需模拟器：SV1，一种通用型量子电路模拟器；DM1，能够让您在电路中模拟噪声的影响；以及 TN1，一种高性能张量网络模拟器。有了这些选项，您只需从中选择最适合自己需求的方法即可。"
    },
    {
        "query":"什么是本地模拟器？",
        "intention":"知识问答",
        "reply":"本地模拟器包含在 Amazon Braket 开发工具包中，且无需费用。它可以在您的笔记本电脑上运行，或者在由 Amazon Braket 托管的笔记本中运行。您可以将其用来完成对电路设计的快速验证。其中包含多达 25 个不含噪音的量子位，或最多 12 个含噪音的量子位，非常适合进行中小规模模拟，具体条件将取决于您的硬件。"
    },
    {
        "query":"什么是 SV1 模拟器？",
        "intention":"知识问答",
        "reply":"SV1 是一种完全托管的高性能状态向量模拟器，适用于量子电路，最多拥有 34 个量子位。作为状态向量模拟器，它采用了量子状态的全波函数，并应用电路运营来结算结果。当您在 Amazon Braket 开发工具包中使用本地模拟器完成量子算法的设计和调试后，便可以使用 SV1 里执行大规模测试和研究。SV1 能够自动扩展传统计算资源，因此您可以最多同时运行 35 个模拟操作。"
    },
    {
        "query":"什么是 DM1 模拟器？",
        "intention":"知识问答",
        "reply":"DM1 是一种完全托管的密度矩阵模拟器，能够让您研究真实噪声对量子算法的影响。这将帮助您开发策略消除错误，以从如今的量子计算设备中获得更准确的结果。  \n DM1 支持最多 17 个量子位的电路模拟。它能够同时运行多达 35 个模拟，从而加速您的试验进程。要在使用 DM1 前快速创建原型和开展调试，您可以使用 Amazon Braket 软件开发工具包中的本地噪声模拟器。"
    },
    {
        "query":"什么是 TN1 模拟器？",
        "intention":"知识问答",
        "reply":"TN1 是一种完全托管的高性能密度网络模拟器，用于构建包含多达 50 个量子位的量子电路。密度网络模拟器对量子电路进行编程，将其融入架构图片，从而找到计算电路输出的最佳方式。TN1 特别适用于稀疏电路、带局部门的电路以及其他具有固有结构的电路模拟。"
    },
    {
        "query":"如何选择 Amazon Braket 按需模拟器 SV1、TN1 和 DM1？",
        "intention":"知识问答",
        "reply":"SV1 是基于状态向量技术打造的通用型模拟器。它能为 34 个量子位的通用电路提供可预测的执行和高性能。\nDM1 专为支持噪声建模而设计。如果您需要研究不同类型的噪声对算法的影响，请使用 DM1。\nTN1 是专为特定类型的量子电路而设计的模拟器，最多带有 50 个量子位。您可以将它用于稀疏电路、带局部门的电路以及其他具有固有结构的电路。其他电路类型，例如在量子位之间具有全对全连接的电路，通常更适合 SV1。"
    },
    {
        "query":"我为什么要在电路中模拟噪声？",
        "intention":"知识问答",
        "reply":"噪声高是目前量子设备的固有缺点。每个被执行的运营都有可能引入错误。因此，从量子计算机中获得的结果通常会于理想结果有所差异。 DM1 能够帮助您研究算法在真实噪声的影响下所展现出的稳定性，并制定策略消除错误，以利用当今量子计算设备得出更加准确的结果。"
    },
    {
        "query":"我能在 DM1 模拟器上运行无噪声电路吗？",
        "intention":"知识问答",
        "reply":"DM1 可以模拟没有噪声的电路。不过，为了实现最佳性能，我们建议使用 SV1 来执行大规模无噪声电路的模拟。"
    },
    {
        "query":"我必须选择一个实例类型来运行模拟吗？",
        "intention":"知识问答",
        "reply":"使用 Amazon Braket 按需模拟器时不需要。当您使用 SV1、TN1 或 DM1 时，Amazon Braket 将为您管理软件和基础设施。您只需提供要运行的电路即可。\n如果您在 Amazon Braket 托管笔记本上的开发工具包中运行本地模拟器，则它将在您已经为笔记本指定的 Amazon 实例中运行。"
    },
    {
        "query":"我要怎么才能知道自己能否在 TN1 上运行电路？",
        "intention":"知识问答",
        "reply":"只要您的电路在[这里](https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.htm)描述的量子位数和电路深度限制内，TN1 都将尝试模拟。然而，和 SV1 相比，无法单独根据量子位和电路深度精确地提供运行时间。在所谓的排练阶段，TN1 将首先尝试为你的电路确定一个有效的计算路径，并估计下一阶段（收缩阶段）的运行时间。如果预计的收缩时间超过了 TN1 的限制，TN1 将不会尝试收缩，您只会为排练阶段所花费的时间付费。要了解更多信息，请访问[技术文档](https://docs.aws.amazon.com/braket/latest/developerguide/braket-devices.html)。"
    },
    {
        "query":"我是否必须以不同的方式编程/设计算法才可以使用模拟器？",
        "intention":"知识问答",
        "reply":"不，使用 Amazon Braket，只需修改几行代码，就可以在任何模拟器和服务上可用的基于门的量子硬件上运行相同的量子电路。"
    },
    {
        "query":"你们提供用于退火问题的模拟器吗？",
        "intention":"知识问答",
        "reply":"在 AWS Marketplace 上，您可以找到使用最先进的传统方法解决组合优化问题的产品，例如 Meta Analytics 和 Toshiba SBM。"
    },
    {
        "query":"如何使用 Amazon Braket 来访问量子计算机？",
        "intention":"知识问答",
        "reply":"在一个实际的量子处理单元（QPU）上运行电路设计并不难。在 Amazon Braket 开发工具包中创建电路或问题图后，您可以在托管的 Jupyter notebook 或您选择的任何 IDE（如 PyCharm）中提交任务。"
    },
    {
        "query":"在 QPU 上运行任务与在模拟器上运行有何不同？",
        "intention":"知识问答",
        "reply":"在 QPU 上运行量子任务的步骤与在模拟器上运行的步骤相同，您只需在Amazon Braket 开发工具包中进行 API 调用时选择后端*或设备*即可。它们都计算运算，您可以通过 Amazon Braket 开发工具包中的 API 调用请求不同的后端或*设备*。设备选项包括本服务所提供的不同模拟器和量子计算机。从一个设备切换到另一设备就像更改一行代码那样容易。但是，模拟器始终处于可用状态，而 QPU 资源可能需要等待时间。"
    },
    {
        "query":"如何选择使用哪种量子计算机？",
        "intention":"知识问答",
        "reply":"有些类型的量子计算机特别适合解决特定系列的问题。可通过许多因素来确定哪些类型的计算机满足您的需求，例如量子位数、量子位保真度（错误率）、量子位连接性、相干时间和成本。可通过 [Amazon Braket 控制台](https://console.aws.amazon.com/braket/home)了解量子计算机的完整规格。"
    },
    {
        "query":"Amazon Braket 支持哪些量子计算机？",
        "intention":"知识问答",
        "reply":"请[单击此处](https://aws.amazon.com/cn/braket/hardware-providers/)，了解有关 Amazon Braket 硬件提供商的更多信息。"
    },
    {
        "query":"什么是模拟哈密顿模拟？",
        "intention":"知识问答",
        "reply":"模拟哈密顿模拟（或称为 AHS）是一种不同的量子计算范式，不同于通用的基于门的量子计算。支持 AHS 的设备是旨在解决一组限定问题的专用 QPU，以哈密顿量为代表。AHS 允许用户指定感兴趣的哈密顿量，并且量子计算机可以以模拟该哈密顿量下量子态的连续时间演化的方式调整参数。由于这些哈密顿量是直接在系统上实施的，因此 AHS 系统不会受到在电路和门方面制定算法所需的开销的影响，因此已经可以模拟具有数百个量子比特的系统，而这些量子比特是经典模拟所禁止的。Amazon Braket 通过 QuEra QPU 支持 AHS。"
    },
    {
        "query":"我可以在哪里找到 Rigetti QPU 上的系统和性能信息？",
        "intention":"知识问答",
        "reply":"请访问 [Rigetti 的 QPU 页面](https://qcs.rigetti.com/qpus/)，了解 Rigetti QPU 的系统和性能信息，包括门保真度和一致性时间。"
    },
    {
        "query":"我可以在哪里找到关于 IonQ QPU 的最佳实践推荐？",
        "intention":"知识问答",
        "reply":"请访问 [IonQ 最佳实践](https://ionq.com/best-practices)页面，了解有关 IonQ QPU 的拓扑、门和最佳实践的信息。"
    },
    {
        "query":"QuEra QPU 是如何工作的？",
        "intention":"知识问答",
        "reply":"QuEra 系统是一个可编程 QPU，由排列成二维可定制光镊排列的里德伯原子组成。该装置中的量子比特由中性铷 87 原子组成，该原子有两种基态，一种是高度激发的里德堡态。原子之间的里德堡-里德堡相互作用衰减为原子之间距离的六次方，产生具有局部相互作用的有效自旋哈密顿量。此外，激光场可以调节横向磁场，以产生有趣的自旋动力学，从而产生新的基态和非平衡态。通过 Braket 访问该设备的研究人员将能够对二维原子排列的几何形状进行编程，并以与时间相关的方式改变纵向和横向磁场的强度，所有这些都使用 Braket SDK。这将产生一个值得关注的有效哈密顿量，可以在设备上研究其连续时间演化。如需更多信息，请在[此处](https://www.quera.com/aquila)参阅 QuEra 的最佳实践。"
    },
    {
        "query":"我的量子任务可以立即在 QPU 上开始运行吗，还是必须等待？",
        "intention":"知识问答",
        "reply":"量子计算是一项新兴技术，而量子计算机仍属稀缺资源。不同类型的量子计算机具有不同的运算特性和可用性级别，因此处理任务的速度并不相同。如果您选择的 QPU 在线且当前未处于使用状态，则将立即处理您的任务；否则会将任务放入队列等待。QPU 可用后，将根据接收顺序对队列中的任务进行处理。Amazon Braket 会将状态更改事件发送到 Amazon EventBridge，以便在任务完成时通知您。您可以在 EventBridge 中创建一条规则来指定要执行的操作，例如使用 [Amazon Simple Notification Service](https://aws.amazon.com/cn/sns/) (SNS)，它可以通过短信或其他方式（如电子邮件、HTTPS、AWS Lambda 或 Amazon SQS 等）向您发送提醒。"
    },
    {
        "query":"我是否需要编译电路后才能在 QPU 上运行它们？",
        "intention":"知识问答",
        "reply":"不一定。Amazon Braket 会在您运行代码时自动编译代码。但是，您可以选择在 Rigetti、OQC 和 IonQ 设备上按原样运行电路，无需使用逐字编译进行编译器修改。在 Rigetti 上，您还可以仅将特定的代码块定义为按原样运行，而无需任何中间编译器传递。要了解更多信息，请参阅有关[逐字编译](https://docs.aws.amazon.com/braket/latest/developerguide/braket-constructing-circuit.html#verbatim-compilation)的文档。"
    },
    {
        "query":"逐字编译有什么益处？",
        "intention":"知识问答",
        "reply":"量子电路编译会将量子电路转换为编译电路，然后进行量子位分配、到本机门的映射和优化。然而，编译器门优化对于正在开发基准测试或减少错误的电路的研究人员和量子算法专家来说可能存在问题，因为编译器优化会删除或对门和冗余组件进行重新排序。使用逐字编译，用户可以指定部分电路或整个电路按原样运行，而不需要进行任何编译器修改。"
    },
    {
        "query":"我可以访问 AWS Marketplace 上的量子计算机吗？",
        "intention":"知识问答",
        "reply":"可以，您可以通过 AWS Marketplace 访问量子硬件，例如 [D-Wave 的退火设备](https://aws.amazon.com/marketplace/pp/prodview-swm25ss53l2ss?sr=0-1&ref_=beagle&applicationId=AWSMPContessa)。"
    },
    {
        "query":"Hybrid Jobs 的功能是什么？",
        "intention":"知识问答",
        "reply":"Hybrid Jobs 让混合量子经典工作负载的执行变得更轻松、更快速、更可预测。使用此功能，您只需提供您的算法脚本或容器，AWS 将启动请求的资源，运行算法，并在完成后释放资源，因此您只需根据用量支付费用。Hybrid Jobs 功能还提供了对算法度量的实时洞察，因此您可以看到算法的进展情况。最重要的是，任务具有对目标 QPU 的优先访问权，因此执行速度更快，更可预测，受其他用户工作负载的影响更小。"
    },
    {
        "query":"为什么应该使用 Hybrid Jobs？",
        "intention":"知识问答",
        "reply":"Braket Hybrid Jobs 有三大好处。首先，它简化了混合量子经典算法的运行。许多量子研究人员通常是云计算新手，在运行混合算法之前不想设置和管理他们的计算环境。借助 Hybrid Jobs，您只需要指定首选的计算实例，或者使用原定设置实例。 Braket Hybrid Jobs 将加速经典资源，在预构建的容器环境中运行工作负载，将结果返回到 Amazon S3，最后释放计算资源，因此您只需为使用的资源付费。\n其次，Hybrid Jobs 提供了运行算法的实时洞察。您可以将自定义算法指标定义为算法的一部分，可以自动记录至 Amazon CloudWatch 并显示在 Amazon Braket 控制台中。利用这个功能，您可以跟踪算法的进度。\n第三，Amazon Braket Hybrid Jobs 提供了比在您自己的环境中运行混合算法更好的性能。在任务运行的整个过程中，它具有对所选 QPU 的优先访问权。这意味着作为部分任务在该设备上执行的任务优先于在该设备上排队的其他任务执行。这使得混合算法的运行时间更短、更可预测，并通过减少缓慢变化的器件特性（“设备漂移”）对算法性能的不利影响，最终获得更好的结果。"
    },
    {
        "query":"哪些量子计算机可以用于 Hybrid Jobs？",
        "intention":"知识问答",
        "reply":"您可以在 Amazon Braket 上将任何可用的 QPU 用于 Hybrid Jobs。"
    },
    {
        "query":"哪些模拟器可以用于 Hybrid Jobs？",
        "intention":"知识问答",
        "reply":"您可以使用任何可用的 Amazon Braket 按需模拟器（SV1、DM1、TN1）、基于 [PennyLane lightning 插件](https://pennylane-lightning.readthedocs.io/en/latest/)的嵌入式模拟器，或作为混合任务容器嵌入的自定义模拟器。对于嵌入式模拟器或自定义模拟器，可以选择一个或多个 CPU 和 GPU 实例来运行混合工作负载。"
    },
    {
        "query":"为什么要使用嵌入式模拟器运行 Hybrid Jobs？",
        "intention":"知识问答",
        "reply":"嵌入式模拟器是一组高性能模拟器，直接嵌入与应用程序代码相同的容器中，以避免与完全托管式按需模拟器（如 SV1）和容器化经典代码之间的往返相关的延迟。嵌入式模拟器支持高级功能（如[伴随法](https://pennylane.readthedocs.io/en/stable/introduction/interfaces.html#simulation-based-differentiation)）进行梯度计算，可以减少计算梯度所需的电路数量。如今，Amazon Braket 已支持 PennyLane 嵌入式模拟器，如 lightning.gpu 模拟器，该模拟器采用 [NVIDIA cuQuantum SDK](https://developer.nvidia.com/cuquantum-sdk) 加速，专门设计用于在高性能 GPU 上运行量子电路模拟。"
    },
    {
        "query":"我能把我自己的模拟器带到 Amazon Braket Hybrid Jobs 吗？",
        "intention":"知识问答",
        "reply":"可以，您可以通过将模拟器及其依赖项嵌入到容器中，将自己的模拟器库带到 Amazon Braket Hybrid Jobs 中。然后，您可以将代码作为入口点传递给容器，并在 CPU 或 GPU 实例上以 Amazon Braket Hybrid Job 的形式执行代码。Amazon Braket 会在您的任务期间处理旋转资源，您只需为您使用的资源付费。"
    },
    {
        "query":"我必须选择一个实例类型来运行 Hybrid Job 吗？",
        "intention":"知识问答",
        "reply":"不必，原定设置下，任务容器在单个 ml.m5.xlarge 实例类型上运行。如果您使用 Amazon Braket 按需模拟器（SV1、TN1、DM1）或 QPU 运行混合算法，那么 Amazon Braket 将为您管理软件和基础设施。如果使用 PennyLane 嵌入式模拟器或打包为容器的自定义模拟器运行混合算法，则可以选择一个或多个 CPU 或 GPU 实例类型来运行任务。Amazon Braket 可以管理底层基础设施的设置，并在任务完成后释放资源，这样您只需为使用的资源付费。"
    },
    {
        "query":"在运行混合任务时，如何在 Penny Lane 嵌入式状态向量模拟器和 SV1 模拟器之间进行选择？",
        "intention":"知识问答",
        "reply":"如今，PennyLane 嵌入式状态向量模拟器已与 Amazon Braket Hybrid Jobs 容器一起预装，可用于变分算法，可受益于[反向传播或伴随法](https://pennylane.readthedocs.io/en/stable/introduction/interfaces.html)等方法进行梯度计算。这些算法的例子有量子机器学习 (QML)、量子绝热近似算法 (QAOA) 或变分量子本征解算器 (VQE)。如果您的算法可以从基于 GPU 的加速中受益，并且可以装入 GPU 内存，那么在嵌入式模拟器中，您还可以选择使用 GPU 实例。对于采用中间量子位计数 (< 30) 的变分算法和 QML 算法，通常都属于这种情况。否则，请考虑使用 SV1 按需模拟器。由于伴随法目前不支持非零样本，对于样本数量大于零的任何工作负载，请考虑使用 SV1。请注意，嵌入式模拟器仅支持用作混合作业功能的一部分，而 SV1 同时支持独立任务和混合任务。"
    },
    {
        "query":"我如何选择不同的 PennyLane 嵌入式模拟器？",
        "intention":"知识问答",
        "reply":"[PennyLane lightning.gpu](https://github.com/PennyLaneAI/pennylane-lightning-gpu) 模拟器可用于混合算法，如 QML、QAOA 或 VQE，前提是问题大小足够小，可以装入 GPU 内存中。[lightning.qubit](https://github.com/PennyLaneAI/pennylane-lightning) 基于 CPU 的模拟器可用于内存密集型，且无法装入 GPU 内存的算法，如具有高 qubit 计数 (29+ qubits) 的变分算法。 请注意，根据您使用的是 CPU 还是 GPU 实例类型，您的成本会有所不同。有关更多详细信息，请参阅 [PennyLane 文档](https://pennylane.ai/plugins.html)。"
    },
    {
        "query":"如何开启使用 Hybrid Jobs？",
        "intention":"知识问答",
        "reply":"您可以通过访问 Braket 文档的 [Amazon Braket Jobs 用户指南](https://docs.aws.amazon.com/braket/latest/developerguide/braket-jobs.html)部分开始。 [Amazon Braket 混合示例笔记本](https://github.com/aws/amazon-braket-examples/tree/main/examples/hybrid_jobs)提供了关于如何开始任务和运行不同混合算法的教程。这些示例预装在 Amazon Braket 笔记本上，帮助您快速入门。您还可以使用 [Amazon Braket 示例库中](https://github.com/aws/amazon-braket-examples/tree/main/examples/pennylane)的 PennyLane插件查看混合算法示例。"
    },
    {
        "query":"我如何跨不同项目跟踪 Amazon Braket 使用情况和开支？",
        "intention":"知识问答",
        "reply":"您可以通过成本中心、部门或项目这类对团队或业务有意义的逻辑分组，使用标签来组织您的 AWS 资源。在 Amazon Braket 中，您可以将标签应用到您创建的量子任务中。创建并应用用户定义的标签后，您可以在 AWS 账单和成本管理控制面板上激活它们以进行成本分配跟踪。AWS 利用标签来分类成本，并向您交付一份月度成本分配报告，以便您可以跟踪 AWS 成本。成本分配报告将标签键作为附加列显示，每一行都有适用的值，这样如果您使用一组一致的标签键，跟踪成本就会更容易。"
    },
    {
        "query":"AWS 为使用 AWS Braket 的量子计算研究提供抵扣金额吗？",
        "intention":"知识问答",
        "reply":"是的。世界各地大学的科学家都在使用通过 [AWS Cloud Credit for Research](https://aws.amazon.com/government-education/research-and-technical-computing/cloud-credit-for-research/) 项目提供的抵扣金在 Amazon Braket 上开展研究。请在上方的链接提交您的申请。在申请过程中，如果您没有适用于定价计算器的 URL，请使用占位符提交您的请求。"
    },
    {
        "query":"我使用 Amazon Braket 服务时，我的数据是否会离开 AWS 环境？",
        "intention":"知识问答",
        "reply":"会，Amazon Braket 上的 QPU 是由我们的第三方量子硬件提供商托管的。如果您使用 Amazon Braket 访问量子计算机，则会将您的电路以及相关的元数据发送给 AWS 运营设施之外的硬件提供商并由其进行处理。由于您的内容是匿名的，因此仅将处理量子任务所需的内容发送给量子硬件提供商。不会将 AWS 账户信息传输给他们。所有静态数据和传输中数据都是加密的，只有在处理时才会解密。此外，除了处理您的任务外，我们禁止 Amazon Braket 硬件提供商存储或使用您的内容。电路完成后，会将结果返回到 Amazon Braket 并存储在您的 Amazon S3 存储桶中。我们会定期审核 Amazon Braket 第三方量子硬件提供商的安全性，以确保满足网络安全性、访问控制、数据保护和物理安全性的标准。"
    },
    {
        "query":"结果会存储在哪里？",
        "intention":"知识问答",
        "reply":"会将结果存储在 Amazon S3 中。除了提供执行结果，Amazon Braket 还会将完成状态和执行时间等事件日志和性能指标发布至 Amazon CloudWatch。"
    },
    {
        "query":"我能否在 Amazon Virtual Private Cloud（Amazon VPC）中使用 Amazon Braket？",
        "intention":"知识问答",
        "reply":"Amazon Braket 与您的 AWS PrivateLink 集成，因此您能够在 Amazon Virtual Private Cloud（Amazon VPC）内访问 Amazon Braket 而无需让流量遍历整个互联网。这样可以减少基于互联网的攻击所带来的安全威胁，以及敏感数据泄露的风险。"
    },
    {
        "query":"什么是 Quantum Solutions Lab (QSL)？",
        "intention":"知识问答",
        "reply":"Amazon Quantum Solutions Lab 是一项协作式研究和专业服务计划，配备量子计算专家，可以帮助您更有效地探索量子计算，设法克服这一新兴技术带来的挑战。要开始使用，请访问 [Quantum 解决方案实验室页面](https://aws.amazon.com/cn/quantum-solutions-lab/)。"
    },
    {
        "query":"如何加入 QSL？",
        "intention":"知识问答",
        "reply":"您可以通过[提交此表单](https://pages.awscloud.com/amazon-quantum-solutions-lab_contact-us.html)以及通过您的 AWS 客户经理来获取有关加入 QSL 以及与我们的合作伙伴合作的相关信息。"
    },
    {
        "query":"加入 QSL 计划通常会持续多长时间？",
        "intention":"知识问答",
        "reply":"加入 Quantum Solutions Lab 计划通常持续 6 到 12 个月。"
    },
    {
        "query":"我需要去实验室参加吗？",
        "intention":"知识问答",
        "reply":"如果需要，整个过程可以远程完成，在当前疫情期间很可能会出现这种情况。但是，通常情况下，我们需要见面来启动计划，并确定工作节奏。之后，我们将根据需要到访您的现场，并通过视频会议进行常规检查，同时定期进行远程协作。"
    },
    {
        "query":"什么是 AWS Center for Quantum Computing？",
        "intention":"知识问答",
        "reply":"AWS Center for Quantum Computing 是一项研究计划，它汇集了来自 Amazon 的研究人员和工程师，以及在量子计算领域处于领先地位的学术机构的研究人员和工程师。他们可以在近期应用、纠错方案、硬件架构和编程模型方面合作，以探索量子技术的发展。我们在加州理工学院 (Caltech) 的校园里建立了 AWS Center for Quantum Computing。目前，该中心通过 Amazon Scholars 计划与加州理工学院、斯坦福大学、哈佛大学、麻省理工学院和芝加哥大学的研究人员开展合作。"
    },
    {
        "query":"AWS Center for Quantum Computing 发布了哪些研究？",
        "intention":"知识问答",
        "reply":"AWS Center for Quantum Computing 团队会在 [QIP](https://www.amazon.science/blog/aws-scientists-coauthor-13-qip-2021-quantum-computing-papers)、APS 和 IEEE QCE 等会议上定期发布研究和并发表科学论文，主题涉及量子硬件、算法、错误纠正和其他领域。值得注意的研究包括关于“[设计基于薛定谔猫量子位的容错量子计算机](https://aws.amazon.com/blogs/quantum-computing/designing-a-fault-tolerant-quantum-computer-with-cat-qubits/)”的论文。 如需了解其他已发布的研究，请参阅我们的 [Amazon.Science Quantum Technologies 研究领域页面](https://www.amazon.science/quantum-technologies)。"
    },
    {
        "query":"什么是 Amazon CloudFront?",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 是一种 Web 服务，为企业和 Web 应用程序开发人员提供一种简单且经济高效的内容分配方法，不仅延迟低，而且数据传输速度高。与其他 AWS 产品一样，Amazon CloudFront 也是一种按用量付费的自助服务，无需长期承诺或最低费用。使用 CloudFront，您的文件将通过一个全球边缘站点网络来传输至最终用户。"
    },
    {
        "query":"Amazon CloudFront 可以用来做什么?",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 提供简单的 API，让您能够："
    },
    {
        "query":"如何开始使用 Amazon CloudFront?",
        "intention":"知识问答",
        "reply":"在 Amazon CloudFront 详细信息页面上，单击的“创建免费账户”按钮。如果您选择使用其他 AWS 产品作为通过 Amazon CloudFront 提供的文件的来源，那在创建 CloudFront 分配之前，您必须[注册](https://portal.aws.amazon.com/billing/signup)该服务。"
    },
    {
        "query":"如何使用 Amazon CloudFront?",
        "intention":"知识问答",
        "reply":"要使用 Amazon CloudFront，您必须按以下步骤操作："
    },
    {
        "query":"Amazon CloudFront 如何提供更高性能?",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 采用边缘站点和区域性边缘缓存的全球网络，可缓存您的内容副本以更靠近读者。Amazon CloudFront 确保将由距离最近的边缘站点来处理最终用户请求。由此，传输读者请求的距离变短，Amazon CloudFront 也为读者提升了性能。对于没有缓存在边缘站点和区域性边缘缓存上的文件，Amazon CloudFront 将与您的原始服务器保持永久连接，以便尽快从原始服务器提取这些文件。最后，Amazon CloudFront 使用其他优化措施（例如更广的 TCP 初始拥塞窗口），在将您的内容传输至查看者时提供更高的性能。"
    },
    {
        "query":"Amazon CloudFront 如何降低通过 Internet 分配内容的成本？",
        "intention":"知识问答",
        "reply":"与其他 AWS 产品一样，Amazon CloudFront 没有最低承诺，您只需为自己的服务用量付费。与自托管相比，Amazon CloudFront 无需您运行分布在 Internet 上多个站点的缓存服务器网络，从而避免了相关开支和复杂性，也无需您过高预置容量以便处理可能出现的流量峰值。Amazon CloudFront 还运用了多种技术，例如，将在一个边缘站点上针对同一文件发出的多个同步查看者请求重叠到向原始服务器发出的单个请求中。这样可以降低原始服务器上的负载，从而减少扩展原始基础设施的需求，实现进一步成本节省。\n此外，如果您正在使用的是 AWS 原始服务器（如 Amazon S3、Amazon EC2 等），并且是 2014 年 12 月 1 日生效的，我们不再收取向 Amazon CloudFront 传输 AWS 数据的费用。这适用于从所有 AWS 区域向全球 CloudFront 边缘站点的数据传输。"
    },
    {
        "query":"Amazon CloudFront 如何加快整个网站的速度？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 使用您为文件设置的标准缓存控制标头来识别静态内容和动态内容。使用单个 Amazon CloudFront 分发来传输您的所有内容，这有助于确保将性能优化应用于整个网站或 Web 应用程序。使用 AWS 原始服务器时，由于 AWS 能够跟踪和调节原始路由、监控系统运行状况并在出现任何问题时快速响应，而且 Amazon CloudFront 与其他 AWS 产品相集成，因而性能、可靠性和易用性得到了改进，让您从中受益。您可以享受到的还包括针对单个站点上的不同类型内容使用不同来源 – 例如将 Amazon S3 作为静态数据元来源、将 Amazon EC2 作为动态内容来源、将自定义来源用于第三方内容 – 而只需为实际用量付费。"
    },
    {
        "query":"Amazon CloudFront 与 Amazon S3 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 是分发经常访问的静态内容的理想之选，可从边缘站点传输中受益 – 例如常用的网站图像、视频、多媒体文件或软件下载。"
    },
    {
        "query":"Amazon CloudFront 与传统内容传输解决方案有何不同？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 让您能够快速获得高性能内容传输的优势，而无需谈判合同，也无需支付高价格。Amazon CloudFront 让所有开发人员能够在自助服务模式下享受仅按实际用量付费的低定价。它还与其他 Amazon Web Services 紧密集成，让开发人员从中受益。该解决方案能够作为原始服务器简单地与 Amazon S3、Amazon EC2 和 Elastic Load Balancing 配合使用，为开发人员提供持久化存储与高性能传输的强大结合。Amazon CloudFront 还与 Amazon Route 53 和 AWS CloudFormation 相集成，提供进一步性能优势和简单配置。"
    },
    {
        "query":"Amazon CloudFront 支持什么类型的内容？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 支持可以使用 HTTP 或 WebSocket 协议发送的内容。其中包括动态网页和应用程序，例如 HTML 或 PHP 页面或基于 WebSocket 的应用程序，以及作为 Web 应用程序一部分的任何常用静态文件，例如网站图像、音频、视频、媒体文件或软件下载。Amazon CloudFront 还支持通过 HTTP 分发实时或点播媒体流。"
    },
    {
        "query":"Amazon CloudFront 是否可与非 AWS 原始服务器配合使用？",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 可与保存原始、最终版本内容（包括静态和动态）的任何原始服务器配合使用。使用自定义原始服务器不收取任何额外费用。"
    },
    {
        "query":"Amazon CloudFront 如何启用原始服务器冗余？",
        "intention":"知识问答",
        "reply":"对于您添加到 CloudFront 分发的每个源，您可以[分配一个备份源](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/high_availability_origin_failover.html)，以便在主要源不可用时自动提供流量服务。您可以选择 HTTP 4xx/5xx 状态代码的组合，当从主要源返回这些状态码时，它们将会触发备份源的故障转移。这两个源可以是 AWS 源和非 AWS 源的任意组合。"
    },
    {
        "query":"Amazon CloudFront 是否提供服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"是。如果客户的月度正常运行时间百分比在任何账单周期内低于我们的服务承诺，Amazon CloudFront SLA 将提供服务补偿。可在[此处](https://aws.amazon.com/cn/cloudfront/sla/)找到更多信息。"
    },
    {
        "query":"可以将 AWS 管理控制台与 Amazon CloudFront 配合使用吗？",
        "intention":"知识问答",
        "reply":"是。您可以使用 AWS 管理控制台，通过简单的点击式 Web 界面来配置和管理 Amazon CloudFront。AWS 管理控制台支持 Amazon CloudFront 的大部分功能，让您能够利用 Amazon CloudFront 的低延迟传输，而无需编写任何代码或安装任何软件。您可以免费访问 AWS 管理控制台，网址为 <https://console.aws.amazon.com>。"
    },
    {
        "query":"哪些工具和库适用于 Amazon CloudFront？",
        "intention":"知识问答",
        "reply":"在我们的[资源中心](https://aws.amazon.com/cn/cloudfront/resources/)，提供了各种用于管理 Amazon CloudFront 分发的工具和适用于各种编程语言的库。"
    },
    {
        "query":"是否可以将我的域顶点（example.com 与 www.example.com 相比）指向我的 Amazon CloudFront 分配？",
        "intention":"知识问答",
        "reply":"是。通过使用 AWS 权威的 DNS 服务 Amazon Route 53，您可以配置别名记录，并允许您将您的 DNS 名称的顶点或根（example.com）映射到您的 Amazon CloudFront 分发上。然后，Amazon Route 53 将针对您的 CloudFront 分发，使用正确的 IP 地址响应每个 Alias 记录请求。Route 53 对映射到 CloudFront 分配的别名记录的查询不收取费用。这些查询在 Amazon Route 53 使用率报告中列为“Intra-AWS-DNS-Queries”。"
    },
    {
        "query":"CloudFront 区域性边缘缓存站点是什么？",
        "intention":"知识问答",
        "reply":"CloudFront 通过全球数据中心（称作边缘站点）网络传输内容。区域性边缘缓存站点位于原始 Web 服务器和全球边缘站点之间，直接向读者提供内容。这可帮助提升读者的体验，同时降低扩展原始资源的运营负担和成本。"
    },
    {
        "query":"区域性边缘缓存如何运行？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 拥有多个分散到全球的[区域性边缘缓存](https://aws.amazon.com/cn/cloudfront/features/) (REC)，提供靠近最终用户的额外缓存层。它们位于原始 Web 服务器和 AWS 边缘站点之间，直接向用户提供内容。如果缓存对象不再那么受欢迎，各个边缘站点可以移除这些对象，从而为更常请求的内容腾出空间。区域性边缘缓存的缓存宽度比任何单个边缘站点都更大，因此对象会缓存更长时间。这有助于让更多内容更为靠近读者，减少 CloudFront 返回原始 Web 服务器的需要，提升读者阅读体验。例如，欧洲的 CloudFront 边缘站点现在会转到法兰克福的区域性边缘缓存站点来提取对象，然后再返回您的原始 Web 服务器。区域性边缘缓存地点可用于任何来源，例如 S3、EC2 或自定义来源。在您的应用程序来源当前所在的区域中会跳过 REC。"
    },
    {
        "query":"是否默认启用区域性边缘缓存功能？",
        "intention":"知识问答",
        "reply":"是。您无需对 CloudFront 分发进行任何更改；已为所有新的和现有的 CloudFront 分发默认启用本功能。使用此功能不会产生额外的费用。"
    },
    {
        "query":"Amazon CloudFront 使用的边缘网络站点位于哪里？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 使用全球边缘站点和区域性边缘缓存站点的网络进行内容分发。您可以在[此处](https://aws.amazon.com/cn/cloudfront/details/)查看 Amazon CloudFront 站点的完整列表。"
    },
    {
        "query":"我可以选择向指定国家/地区提供内容（或不向其提供内容）吗？",
        "intention":"知识问答",
        "reply":"可以，利用 Geo Restriction 功能可以让您指定用户可以访问您的内容的国家/地区列表。或者，您也可以指定用户不可以访问您的内容的国家/地区列表。在这两种情况中，CloudFront 均以 HTTP 状态代码 403（禁止）响应来自受限制国家/地区的查看者的请求。"
    },
    {
        "query":"您的 GeoIP 数据库的准确程度如何？",
        "intention":"知识问答",
        "reply":"国家/地区查找数据库的 IP 地址准确性因地区而异。根据最近的测试，我们所提供的 IP 地址与国家/地区映射的总体准确性为 99.8%。"
    },
    {
        "query":"我可以向我的最终用户提供自定义错误消息吗？",
        "intention":"知识问答",
        "reply":"可以，您可以针对各种 HTTP 4xx 和 5xx 错误响应使用您自己的品牌和内容创建自定义错误消息（例如 HTML 文件或 .jpg 图形）。然后，您可以对 Amazon CloudFront 进行配置，使其在您的原始服务器向 CloudFront 返回一个指定错误时向查看者返回您的自定义错误消息。"
    },
    {
        "query":"Amazon CloudFront 将我的文件在边缘站点上保存多长时间？",
        "intention":"知识问答",
        "reply":"默认情况下，如果没有设置缓存控制标头，则在上次检查原始服务器以获取文件更改 24 小时之后，每当边缘站点接收到请求时，都会检查该文件的更新版本。这段时间称为“过期时段”。 您可以通过对源文件中的文件设置缓存控制标头，将该过期时段设置为短至 0 秒或长至您需要的任意时间。Amazon CloudFront 使用这些缓存控制标头来确定检查原始服务器中该文件的更新版本的频率。对于设置为 0 秒的过期时段，Amazon CloudFront 将向原始服务器重新验证每个请求。如果文件不经常更改，最好设置较长的过期时段，并实施版本控制系统，以管理对文件的更新。"
    },
    {
        "query":"如何将项目从 Amazon CloudFront 边缘站点中移除？",
        "intention":"知识问答",
        "reply":"您可以通过多个选项将文件从边缘站点删除。您可以从原始文件中删除该文件，并且当边缘站点中的内容到达在每个数据元的 HTTP 标头中定义的过期时段时，它就将被移除。如果需要在指定过期时段之前移除冒犯性的或可能有害的材料，您可以使用无效 API 从所有 Amazon CloudFront 边缘站点中移除该对象。您可以在[此处](https://aws.amazon.com/cn/cloudfront/pricing/)查看进行无效请求的费用。"
    },
    {
        "query":"发出失效请求的数量是否受到限制？",
        "intention":"知识问答",
        "reply":"如果您想逐个让对象失效，则针对每个分配一次可以同时处理 3000 个对象的无效请求。一个无效请求可以支持最多 3000 个对象，或针对一个对象的 3000 个请求，或者合计不超过 3000 个对象的任何组合方式。\n如果您使用 \\* 通配符，则一次最多可以提出 15 个无效路径请求。您一次可以为每个分配的最多 3000 个单独对象提出无效请求，而通配符无效请求的限制与个别失效对象限制无关。如果您超过此限制，额外的无效请求将收到错误响应，直至先前的某个请求完成。\n无效请求应仅在意外情况下使用；如果您事先知道您的文件需要经常从缓存中删除，建议您为文件实施版本控制系统和/或设置较短的有效期限。"
    },
    {
        "query":"Amazon CloudFront 是否符合 PCI 规范?",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 包含在符合支付卡行业数据安全标准 (PCI DSS) 商家第 1 级（服务提供商需要遵循的最高级别）的服务集中。有关更多信息，请参阅[开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/compliance.html)。"
    },
    {
        "query":"Amazon CloudFront 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"符合，AWS 已对其 HIPAA 合规性计划进行扩展，其中已将 Amazon CloudFront 作为一项符合 HIPAA 要求的服务包括进来。如果您已与 AWS 签订商业合伙协议 (BAA)，则可以使用 Amazon CloudFront 来加快交付受保护健康信息 (PHI)。有关更多信息，请参阅[HIPAA 合规性](https://aws.amazon.com/cn/compliance/hipaa-compliance/)和我们的[开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/compliance.html)。"
    },
    {
        "query":"Amazon CloudFront 是否符合 SOC 规范？",
        "intention":"知识问答",
        "reply":"是，Amazon CloudFront 已通过 SOC（系统与组织控制）认证。SOC 报告是独立的第三方检查报告，阐明 AWS 如何达成关键合规性控制和目标。有关更多信息，请参阅[AWS SOC 合规性](https://aws.amazon.com/cn/compliance/soc-faqs/)和我们的[开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/compliance.html)。"
    },
    {
        "query":"如何申请一份 AWS SOC 1、SOC 2 或 SOC 3 报告？",
        "intention":"知识问答",
        "reply":"AWS SOC 1 和 SOC 2 报告面向使用 AWS Artifact 的客户提供。AWS Artifact 是一个自助服务门户，借此可按照需要访问 AWS 的合规性报告。您可以登录 [AWS 管理控制台中的 AWS Artifact](https://console.aws.amazon.com/artifact)，或 [AWS Artifact 入门](https://aws.amazon.com/cn/artifact/getting-started/)了解更多信息。AWS 网站公开发布了最新的[AWS SOC 3 报告](https://d1.awsstatic.com/whitepapers/compliance/AWS_SOC3.pdf)。"
    },
    {
        "query":"Amazon CloudFront 支持哪些类型的 HTTP 请求？",
        "intention":"知识问答",
        "reply":"目前，Amazon CloudFront 支持 GET、HEAD、POST、PUT、PATCH、DELETE 和 OPTIONS 请求。"
    },
    {
        "query":"Amazon CloudFront 是否缓存 POST 响应？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 不会缓存对 POST、PUT、DELETE 和 PATCH 请求的响应，因为这些请求会通过代理返回原始服务器。您可以启用[缓存](https://aws.amazon.com/cn/caching/cdn/)来响应 OPTIONS 的请求。"
    },
    {
        "query":"如何使用 HTTP/2？",
        "intention":"知识问答",
        "reply":"如果您已有 Amazon CloudFront 分配，则可以使用 API 或管理控制台启用 HTTP/2。在控制台中，转到“Distribution Configuration”页面，然后转到“Supported HTTP Versions”部分。 在该部分中，您可以选择“HTTP/2”、“HTTP/1.1”或“HTTP/1.0”。对于所有新的 CloudFront 分配，HTTP/2 自动处于启用状态。"
    },
    {
        "query":"如果我的原始服务器不支持 HTTP/2，该怎么办？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 目前支持使用 HTTP/2 向浏览者的客户端和浏览器分发内容。Amazon CloudFront 将继续使用 HTTP/1.1 传送边缘站点与您的原始服务器之间的通信内容。"
    },
    {
        "query":"Amazon CloudFront 是否支持不采用 TLS 的 HTTP/2？",
        "intention":"知识问答",
        "reply":"暂时不能。不过，大多数现代浏览器只能通过加密连接支持 HTTP/2。您可以单击[此处](https://aws.amazon.com/cn/cloudfront/custom-ssl-domains/)详细了解如何结合使用 SSL 和 Amazon CloudFront。"
    },
    {
        "query":"什么是 HTTP/3？",
        "intention":"知识问答",
        "reply":"HTTP/3 超文本传输协议的第三个主要版本。HTTP/3 使用 QUIC，这是一种基于用户数据报协议 (UDP) 的流多路复用安全传输协议，结合并改进了现有传输控制协议(TCP)、TLS 和 HTTP/2 的功能。与以前的 HTTP 版本相比，HTTP/3 提供了一些优势，包括更快的响应时间和增强的安全性。"
    },
    {
        "query":"什么是 QUIC？",
        "intention":"知识问答",
        "reply":"HTTP/3 由 QUIC 提供支持，它是一个新型的高性能、弹性且安全的互联网传输协议。CloudFront 对 HTTP/3 的支持基于 s2n-quic 构建，这是 Rust 中的一个新开源 QUIC 协议实现。要了解有关 QUIC 的更多信息，请参阅“[s2n-quic 简介](https://aws.amazon.com/cn/blogs/security/introducing-s2n-quic-open-source-protocol-rust/)”博客。"
    },
    {
        "query":"在 Amazon CloudFront 中使用 HTTP/3 的主要好处有哪些？",
        "intention":"知识问答",
        "reply":"客户不断寻求为其最终用户提供更快、更安全的应用程序。随着全球互联网普及率的提高，越来越多的用户通过手机和远程网络上网，对提高性能和可靠性的需求比以往任何时候都更大。HTTP/3 实现了这一点，因为，与以前的 HTTP 版本相比，HTTP/3 具有多项性能改进："
    },
    {
        "query":"如何在我的 CloudFront 分配上启用 HTTP/3？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudFront 控制台、UpdateDistribution API 操作或使用 Cloudformation 模板在新的和现有 Amazon CloudFront 分配中启用 HTTP/3。在控制台中，转到“Distribution Configuration”（分配配置）页面，然后转到“Supported HTTP Versions”（受支持的 HTTP 版本）部分。 在该部分中，您可以选择“HTTP/3, HTTP/2, HTTP/1.1, or HTTP/1.0”（HTTP/3、HTTP/2、HTTP/1.1 或 HTTP/1.0）。"
    },
    {
        "query":"在启用 HTTP/3 之前，我是否需要更改我的应用程序？",
        "intention":"知识问答",
        "reply":"在 CloudFront 分配上启用 HTTP/3 时，CloudFront 将会自动添加 Alt-Svc 标头，用于宣传 HTTP/3 支持可用，您无需手动添加 Alt-Svc 标头。我们希望您在应用程序中启用对多种协议的支持，如果应用程序未能建立 HTTP/3 连接，它将回退至 HTTP /1.1 或 HTTP/2，也就是说，不支持 HTTP/3 的客户端仍可以使用 HTTP/1.1 或 HTTP/2 与启用了 HTTP/3 的 CloudFront 分配的进行通信。回退支持是 HTTP/3 规范不可或缺的一部分，在支持 HTTP/3 的所有主要浏览器中均已实施。"
    },
    {
        "query":"如果我的原始服务器不支持 HTTP/3，该怎么办？",
        "intention":"知识问答",
        "reply":"CloudFront 目前在查看者的客户端浏览器与 CloudFront 边缘站点之间的通信中支持 HTTP/3。CloudFront 将继续使用 HTTP/1.1 传送边缘站点与您的原始服务器之间的通信内容。"
    },
    {
        "query":"Amazon CloudFront 的 TLS 安全策略如何与 HTTP/3 交互？",
        "intention":"知识问答",
        "reply":"HTTP/3 使用 QUIC，后者需要 TLSv1.3。因此，只有 TLSv1.3 和受支持的 TLSv1.3 密码组可用于建立 HTTP/3 连接，不受您选择的安全策略的影响。有关信息信息，请参阅《CloudFront 开发人员指南》中的“查看者与 CloudFront 之前的受支持协议和密码”部分。"
    },
    {
        "query":"什么是 WebSocket？",
        "intention":"知识问答",
        "reply":"WebSocket 是一种实时通信协议，通过长时间保持的 TCP 连接提供客户端与服务器之间的双向通信。通过使用持续的开放连接，客户端和服务器可以互相发送实时数据而不必频繁地重新启动连接以检查是否有要交换的数据。WebSocket 连接通常用于聊天应用程序、协作平台、多人游戏和金融交易平台。请参阅我们的文档，以详细了解如何[结合使用 WebSocket 协议](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.websockets.html)与 Amazon CloudFront。"
    },
    {
        "query":"如何启用 Amazon CloudFront 分发来支持 WebSocket 协议？",
        "intention":"知识问答",
        "reply":"您可以在全局范围内使用 WebSocket，并且不需要额外的配置即可在 CloudFront 资源中启用 WebSocket 协议，因为它现在是默认受支持的。"
    },
    {
        "query":"什么时候通过 Amazon CloudFront 建立 WebSocket 连接？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 仅在客户端包含“Upgrade: websocket”标头且服务器响应 HTTP 状态代码 101 以确认其可以切换到 WebSocket 协议时建立 WebSocket 连接。"
    },
    {
        "query":"Amazon CloudFront 是否支持通过 TLS 保护的 WebSocket？",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 支持使用 SSL/TLS 协议加密的 WebSocket 连接 (WSS)。"
    },
    {
        "query":"是否可以将 CloudFront 分配配置为使用自己的域名通过 HTTPS 分发内容？",
        "intention":"知识问答",
        "reply":"默认情况下，您可以在 URL 中使用 CloudFront 分配域名（例如 https://dxxxxx.cloudfront.net/image.jpg）通过 HTTPS 向浏览者分发内容。如果您想使用自己的域名和 SSL 证书通过 HTTPS 传送内容，则可以使用一项我们的自定义 SSL 证书支持功能。[了解更多](https://aws.amazon.com/cn/cloudfront/custom-ssl-domains/)。"
    },
    {
        "query":"什么是字段级加密？",
        "intention":"知识问答",
        "reply":"字段级加密是 CloudFront 的一项功能，使您可以安全地将用户提交的数据（如信用卡号）上传到您的来源服务器。使用此功能，您可以在将 PUT/POST 请求转发到您的源之前，使用特定于字段的加密密钥（由您提供）对 HTTPS 表单中的敏感数据进行进一步加密。这可确保敏感数据只能被应用程序堆栈中的某些组件或服务解密和查看。要了解有关字段级加密的更多信息，请参阅我们文档中的[字段级加密](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/field-level-encryption.html)。"
    },
    {
        "query":"我已经在使用 CloudFront 的 SSL/TLS 加密，是否还需要使用字段级加密？",
        "intention":"知识问答",
        "reply":"许多 Web 应用程序会从用户那里收集信用卡号等敏感数据，然后交由在来源基础设施上运行的应用程序服务处理。所有这些 Web 应用程序都在最终用户和 CloudFront 之间以及 CloudFront 和您的源之间使用 SSL/TLS 加密。您的源可能有多个微服务，它们根据用户输入执行关键操作。然而在通常情况下，这些微服务中仅有一少部分需要访问敏感信息，这意味着大多数组件都是没有任何缘由便直接访问这些数据。一个简单的编程错误（如将错误的变量记录在日志中）便可能会导致将客户的信用卡号写到一个文件中。\n使用字段级加密，CloudFront 的边缘站点可以对信用卡数据进行加密。从那时起，只有拥有私钥的应用程序才能解密敏感字段。因此，订单履行服务只能查看加密的信用卡号，但付款服务可以解密信用卡数据。这确保了更高的安全性，因为即使其中一个应用程序服务泄露了密文，数据仍然受到密码保护。"
    },
    {
        "query":"SNI 自定义 SSL 与 Amazon CloudFront 的专用 IP 自定义 SSL 之间有什么区别？",
        "intention":"知识问答",
        "reply":"专用 IP 自定义 SSL 分配专用 IP地址来服务于每个 CloudFront 边缘站点处的 SSL 内容。因为 IP 地址与 SSL 证书之间是一对一映射，所以专用 IP 自定义 SSL 使用的是不支持 SNI 的浏览器和其他客户端。根据当前的 IP 地址成本，专用 IP 自定义 SSL 的费用按小时分配是每月 600 USD。\nSNI 自定义 SSL 依赖于传输层安全性协议的 SNI 扩展，允许多个域通过相同的 IP 地址提供 SSL 流量，具体方法是包含查看器试图连接的主机名。与专用 IP 自定义 SSL 一样，CloudFront 也是从每个 Amazon CloudFront 边缘站点分发内容，同时具备与专用 IP 自定义 SSL 功能相同的安全性。SNI 自定义 SSL 可使用大部分现代浏览器，包括 Chrome V 6 和更高版本（运行于 Windows XP 和更高版本或 OS X 10.5.7 和更高版本上之上）、Safari V 3 和更高版本（运行于 Windows Vista 和更高版本或 Mac OS X 10.5.6. 和更高版本之上）、Firefox 2.0 和更高版本，以及 Internet Explorer 7 和更高版本（运行于 Windows Vista 和更高版本之上）。不支持 SNI 的较老浏览器无法与 CloudFront 建立连接以加载您的内容的 HTTPS 版本。除了标准 CloudFront 数据传输和请求费用外，SNI 自定义 SSL 不收取额外费用。"
    },
    {
        "query":"什么是服务器名称指示？",
        "intention":"知识问答",
        "reply":"服务器名称指示 (SNI) 是安全传输层 (TLS) 协议的延伸。该机制识别相关 SSL 请求相关的域（服务器名称）以便在 SSL 握手时使用适当的证书。这允许单个 IP 地址用于多个服务器。SNI 要求浏览器支持添加服务器名称，尽管大部分现代浏览器都支持，但是还有一些老式浏览器不能支持。想要了解更多详细信息，请参阅 [CloudFront 开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/SecureConnections.html#CNAMEsAndHTTPS)中的 SNI 部分，或 [SNI Wikipedia 文章](http://en.wikipedia.org/wiki/Server_Name_Indication)。"
    },
    {
        "query":"CloudFront 是否与 AWS Certificate Manager 实现了集成？",
        "intention":"知识问答",
        "reply":"是的，您现在可以预置 SSL/TLS 证书，并在几分钟内将其与 CloudFront 发布版关联起来。只需使用全新的 AWS Certificate Manager (ACM) 预置证书，然后单击几下鼠标将其部署到您的 CloudFront 发布版，之后让 ACM 为您管理证书更新即可。借助 ACM，您可以预置、部署并管理证书，且无需支付额外费用。\n请注意，CloudFront 仍然支持使用您从第三方证书机构获得并上传至 IAM 证书存储的证书。"
    },
    {
        "query":"Amazon CloudFront 是否支持付费内容或私有内容的访问控制?",
        "intention":"知识问答",
        "reply":"是，Amazon CloudFront 具有一项针对私有内容的可选访问控制功能。启用此选项时，Amazon CloudFront 将对您的请求进行安全签名，仅在您允许时才传输文件。通过阅读 [CloudFront 开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PrivateContent.html)了解此功能的更多信息。"
    },
    {
        "query":"如何保护我的 Web 应用程序在通过 CloudFront 传输信息时，免受 DDoS 攻击？",
        "intention":"知识问答",
        "reply":"作为一名 AWS 客户，您可以免费获得 [AWS Shield Standard](https://aws.amazon.com/cn/shield/)。AWS Shield 是一项托管服务，用于保护 AWS 上运行的 Web 应用程序免受 DDoS 攻击。AWS Shield Standard 可以保护所有 AWS 客户免受常见的、最为频繁的基础设施层（第 3 层和第 4 层）攻击（如 SYN/UDP 洪泛、反射攻击和其他攻击），确保 AWS 上的应用程序具有较高的可用性。\n[AWS Shield Advanced](https://aws.amazon.com/cn/shield/) 是一项可选的付费服务，面向 AWS 商业支持计划和 AWS 企业支持计划的客户提供。AWS Shield Advanced 能为 Elastic Load Balancing (ELB)、Amazon CloudFront 和 Route 53 上运行的应用程序提供额外保护，使其免受更大型、更复杂的攻击。"
    },
    {
        "query":"如何保护通过 CloudFront 分发的 Web 应用程序？",
        "intention":"知识问答",
        "reply":"您可以将您的 CloudFront 分发与 [AWS WAF](https://aws.amazon.com/cn/waf/) 进行集成，AWS WAF 是一个 Web 应用程序防火墙，让您能够根据 IP 地址、HTTP 标头和自定义 URI 字符串配置规则，从而有助于保护 Web 应用程序免受攻击。借助这些规则，AWS WAF 能够阻止、允许或监控（统计）Web 应用程序的 Web 请求。要了解更多信息，请参阅 [AWS WAF 开发人员指南](http://docs.aws.amazon.com/console/waf)。"
    },
    {
        "query":"是否可以添加或修改转发到源的请求标头？",
        "intention":"知识问答",
        "reply":"可以，对于转发到源的请求，您可以配置 Amazon CloudFront 以添加自定义标头，或覆盖现有标头的值。您可以使用这些标头帮助确认对源的请求发自 CloudFront；您甚至可以将自己的源配置为仅允许包含指定自定义标头值的请求。此外，如果要对同一个源使用多个 CloudFront 分配，您可以使用自定义标头来区分每个不同分配所发送的源请求。最后，自定义标头可用来帮助确定为您的请求返回的正确 CORS 标头。您可以通过 CloudFront API 和 AWS 管理控制台来配置自定义标头。此功能不会产生额外的费用。要详细了解如何设置自定义标头，您可以在[此处](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/forward-custom-headers.html)阅读更多内容。"
    },
    {
        "query":"Amazon CloudFront 如何处理 HTTP Cookie？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 支持分发用 HTTP cookie 自定义或个性化的动态内容。要使用此功能，您需要指定是否希望 Amazon CloudFront 将您的部分或全部 Cookie 转发到自定义原始服务器。然后，Amazon CloudFront 会在识别缓存中的唯一对象时考虑到转发的 Cookie 的值。这样，您的最终用户既可以通过 Cookie 享受专为他们个性化的内容，又能享用 Amazon CloudFront 带来的性能优势。您还可以选择将 Cookie 值记录在 Amazon CloudFront 访问日志中。"
    },
    {
        "query":"Amazon CloudFront 如何处理 URL 中的查询字符串参数？",
        "intention":"知识问答",
        "reply":"您可以选择将查询字符串配置为缓存键的一部分，以便识别 Amazon CloudFront 缓存中的对象。这有助于您构建可在边缘站点上缓存特定时间的动态网页（例如搜索结果）。"
    },
    {
        "query":"能否在缓存键中指定使用哪些查询参数？",
        "intention":"知识问答",
        "reply":"可以。借助[查询字符串白名单功能](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-web-values-specify.html#DownloadDistValuesQueryStringWhiteList)，您可以在缓存键中仅使用特定参数轻松配置 Amazon CloudFront，同时仍将所有参数转发到相应源中。"
    },
    {
        "query":"可列入白名单的查询参数是否有数量限制？",
        "intention":"知识问答",
        "reply":"是的。配置 Amazon CloudFront 时，您最多可将 10 个查询参数添加到白名单。"
    },
    {
        "query":"支持哪些参数类型？",
        "intention":"知识问答",
        "reply":"Amazon CloudFront 支持 URI 查询参数（如 RFC3986 的 3.4 节中所定义）。具体而言，它支持嵌入在 HTTP GET 字符串中“?”字符后，并通过“&”字符分隔的查询参数。"
    },
    {
        "query":"CloudFront 是否支持 Gzip 压缩？",
        "intention":"知识问答",
        "reply":"支持。CloudFront 可以自动压缩文本或二进制数据。要使用此功能，只需在您的缓存行为设置中指明您希望 CloudFront 自动压缩对象，并确保您的客户端在请求标头中添加“Accept-Encoding: gzip”（大多数现代 Web 浏览器默认执行此操作）。有关此功能的更多信息，请参阅[我们的开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/ServingCompressedFiles.html)。"
    },
    {
        "query":"什么是流式处理？ 为什么我需要流式处理？",
        "intention":"知识问答",
        "reply":"通常情况下，流式处理指的是通过 Internet 向最终用户分发音频和视频，而无需在播放前下载媒体文件。用于流式处理的协议包括那些使用 HTTP 进行分发的协议，如 Apple 的 HTTP Live Streaming (HLS)、MPEG Dynamic Adaptive Streaming over HTTP (MPEG-DASH)、Adobe 的 HTTP Dynamic Streaming (HDS) 和 Microsoft Smooth Streaming。这些协议与网页和其他在线内容的分发不同，因为流式处理协议是实时分发媒体内容，查看者可在内容传输的同时进行观看。流式处理内容可为您和最终用户提供多种潜在优势："
    },
    {
        "query":"Amazon CloudFront 是否支持视频点播 (VOD) 流式处理协议？",
        "intention":"知识问答",
        "reply":"支持。Amazon CloudFront 会为您提供多种选项，方便您分发点播视频内容。如果您的媒体文件在存储到 Amazon S3（或自定义源服务器）之前已经使用 [AWS Elemental MediaConvert](https://aws.amazon.com/cn/mediaconvert/) 等工具转换为 HLS、MPEG-DASH 或 Microsoft Smooth Streaming 格式，则您可以使用 [Amazon CloudFront Web 分发](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/distribution-working-with.html)来流式传输此格式文件，而无需运行任何媒体服务器。\n另外，您还可以在 Amazon EC2 上运行第三方流式处理服务器（例如，AWS Marketplace 上提供的 Wowza Media Server），它会将媒体文件转换为所需的 HTTP 流格式。然后，可以将该服务器指定为 Amazon CloudFront Web 分发的原始服务器。\n请在 AWS 页面访问[视频点播 (VOD)](https://aws.amazon.com/cn/answers/media-entertainment/video-on-demand-on-aws/)了解更多信息。"
    },
    {
        "query":"Amazon CloudFront 是否支持将实时流传输到多个平台？",
        "intention":"知识问答",
        "reply":"是。您可以将 Amazon CloudFront 实时流与任何可输出基于 HTTP 的流的实时视频创作服务结合使用，例如 [AWS Elemental MediaPackage](https://aws.amazon.com/cn/mediapackage/) 或 [AWS Elemental MediaStore](https://aws.amazon.com/cn/mediastore/)。MediaPackage 是一种视频创作和即时打包服务，支持视频分销商使用多种交付和内容保护标准，以安全可靠的方式大规模分发流内容。MediaStore 是一种 HTTP 创作和存储服务，可提供实时媒体所需的高性能、即时一致性和可预测的低延迟，以及安全持久的 Amazon 存储。\n请访问 [AWS 实时视频流页面](https://aws.amazon.com/cn/answers/media-entertainment/live-streaming/)，了解更多信息。"
    },
    {
        "query":"什么是 Origin Shield?",
        "intention":"知识问答",
        "reply":"Origin Shield 是一个集中化的缓存层，有助于提高缓存命中率，从而减少源服务器上的负载。Origin Shield 还可以跨区域折叠请求，以便只有一个请求传入每个对象的源服务器，从而降低源服务器的运维成本。启用后，CloudFront 会通过 Origin Shield 路由所有源服务器提取，并且如果内容尚未存储在 Origin Shield 缓存中，则 CloudFront 只会向源服务器发送一个请求。"
    },
    {
        "query":"我应何时使用 Origin Shield？",
        "intention":"知识问答",
        "reply":"Origin Shield 非常适合观众分布在不同地理区域的工作负载，或者涉及视频流的即时打包、传输中图像处理或类似过程的工作负载。Origin Shield 置于源服务器之前将减少源服务器提取的冗余数量，方法是首先检查其中心缓存，并仅对 Origin Shield 缓存中尚未包含的内容进行合并的源服务器提取。类似地，Origin Shield 还可以在多 CDN 架构中使用，通过将 Amazon CloudFront 定位为其他 CDN 的源服务器，来减少跨 CDN 的重复源服务器提取次数。请参阅《Amazon CloudFront 开发人员指南》，了解与之相关的更多详细信息以及其他 [Origin Shield 使用案例](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html#origin-shield-use-cases)。"
    },
    {
        "query":"我应使用哪个 Origin Shield 区域？",
        "intention":"知识问答",
        "reply":"在 CloudFront 具有[区域性边缘缓存](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/HowCloudFrontWorks.html#CloudFrontRegionaledgecaches)的 AWS 区域中，Amazon CloudFront 提供 Origin Shield。当您启用 Origin Shield 时，应为 Origin Shield 选择对源服务器延迟最低的 AWS 区域。您可将 Origin Shield 用于 AWS 区域中的源服务器，也可以用于 AWS 之外的源服务器。有关更多信息，请参阅《Amazon CloudFront 开发人员指南》中的为 Origin Shield [选择 AWS 区域](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/origin-shield.html#choose-origin-shield-region)。"
    },
    {
        "query":"Origin Shield 是否具有弹性和高可用性？",
        "intention":"知识问答",
        "reply":"是的。所有 Origin Shield 区域均使用跨多个可用区的高度可用架构进行构建，并且具有 auto-scaling Amazon EC2 实例队列。如果 Origin Shield 主位置不可用，则从 CloudFront 位置到 Origin Shield 的连接还会对每个请求使用活动错误跟踪，从而将请求自动路由到 Origin Shield 备用位置。"
    },
    {
        "query":"如果预期使用峰值高于 150Gbps 或 250000RPS，我可以使用 Amazon CloudFront 吗？",
        "intention":"知识问答",
        "reply":"可以。请在[此处](https://aws.amazon.com/cloudfront-request/)填写提高限制请求，我们将在两个工作日之内为您的账户添加更多容量。"
    },
    {
        "query":"我的 Amazon CloudFront 账户可以传输的分发数量是否受到限制？",
        "intention":"知识问答",
        "reply":"要了解您能为每个 AWS 账户创建的分发数量的当前限制，请参阅 Amazon Web Services 一般引用中的 [Amazon CloudFront 限制](http://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_cloudfront)。要请求提高限制，请填写 [CloudFront 提高限制申请表](https://aws.amazon.com/support/createCase?type=service_limit_increase&serviceLimitIncreaseType=cloudfront-distributions)。"
    },
    {
        "query":"通过 Amazon CloudFront 最多能够传输多大的文件？",
        "intention":"知识问答",
        "reply":"通过 Amazon CloudFront 最多能够传输 30 GB 大小的单个文件。此限制适用于所有 Amazon CloudFront 分发。"
    },
    {
        "query":"Amazon CloudFront 提供哪些日志记录功能？",
        "intention":"知识问答",
        "reply":"当您创建或修改 CloudFront 分发时，您可以启用访问记录。CloudFront 提供了两种方式，用于记录从您的分发中发送的请求：标准日志和实时日志。  \n   \n 系统将 CloudFront 标准日志发送至您选择的 Amazon S3 存储桶（在查看器请求后的几分钟内就会发送日志记录）。启用后，CloudFront 将自动以 W3C 扩展格式将详细日志信息写入您指定的 Amazon S3 存储桶。访问日志包含有关对您内容的每个请求的详细信息，包括请求的数据元、请求的日期和时间、处理请求的边缘站点、客户端 IP 地址、引用网站、用户代理、Cookie 标头以及结果类型（例如缓存命中/未命中/错误）。针对标准日志，CloudFront 不收取费用，但存储和访问日志文件将产生 Amazon S3 费用。  \n   \n 系统将 CloudFront 实时日志发送到 Amazon Kinesis Data Streams 中您选择的数据流中（在查看器请求后的几秒钟内就会发送日志记录）。您可以选择实时日志的采样率 — 即希望接收实时日志记录的请求的百分比。您还可以选择希望在日志记录中接收的特定字段。CloudFront 实时日志包含与标准日志相同的所有数据点，同时包含关于每个请求的特定附加信息，如查看器请求标头和国家/地区代码（采用 W3C 扩展格式）。CloudFront 除了收取因使用 Kinesis 数据流产生的费用外，还针对实时日志进行收费。"
    },
    {
        "query":"如何确定使用案例的适当 CloudFront 日志？",
        "intention":"知识问答",
        "reply":"您可以根据您的使用案例选择目标。如果您拥有时效性很强的使用案例且需要在几秒内快速访问日志数据，则选择实时日志。如果您需要成本更低的实时日志管道，您可以通过仅为特定缓存行为启用日志或选择较低的采样率来选择筛选日志数据。实时日志管道的构建是为了快速传送数据。因此，如果发生数据延迟，日志记录可能会被删除。另一方面，如果您需要低成本的日志处理解决方案且不需要实时数据，则您适合使用当前的标准日志选项。S3 中的标准日志为完整性而构建，且日志通常在几分钟内即可用。可以为整个分发启用这些日志，而不是特定的缓存行为。因此，如果您需要日志进行临时调查、审计和分析，您可以选择仅启用 S3 中的标准日志。您可以选择使用这两种日志的组合。使用经过筛选的实时日志列表，以获取操作可见性，然后使用标准日志进行审计。  \n   \n 问：有哪些可用的不同日志目标选项？  \n CloudFront 标准日志将传送到您的 S3 存储桶中。您还可以使用 DataDog 和 Sumologic 等第三方解决方案构建的集成来从这些日志中创建控制面板。  \n   \n 实时日志将传送到您的 Kinesis Data Stream。从 Kinesis Data Streams 中，可以将日志发布到 Amazon Kinesis Data Firehose。Amazon Kinesis Data Firehose 支持将日志轻松传送至 Amazon S3、Amazon Redshift、Amazon Elasticsearch Service 以及 Datadog、New Relic 和 Splunk 等服务提供商。Kinesis Firehose 还支持将数据传送到通用的 HTTP 终端节点。  \n   \n 问：我的 Kinesis Data Stream 中需要多少 Kinesis 分区？  \n 使用下列步骤估算您需要的分区数量：\n例如，假设您的分发每秒接收 10000 个请求，且您的实时日志记录的典型大小是 1KB。这意味着，您的实时日志配置每秒可以生成 10000000 个字节（10000 乘以 1000）或者 9.53MB 的数据量。在此情况下，您只需要 10 个 Kinesis 分区。您应该考虑至少创建 12 个分区，以便拥有一些缓冲区。"
    },
    {
        "query":"Amazon CloudFront 是否提供直接可用的报告，方便我了解与使用量、查看者和当前服务内容有关的更多信息？",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 提供多种解决方案满足您对报告功能的需求，包括接收详细缓存统计报告，监控 CloudFront 使用量，了解客户从何处查看内容，以及对可操作指标设置几乎实时的警报。在 AWS 管理控制台中访问 Amazon CloudFront 报告与分析控制面板，即可使用所有报告选项。您还可以通过查看 Amazon CloudFront 的[报告和分析页面](https://aws.amazon.com/cn/cloudfront/reporting/)，了解关于各种报告选项的更多信息。"
    },
    {
        "query":"我能否标记分配？",
        "intention":"知识问答",
        "reply":"是。Amazon CloudFront 支持成本分配标记。标签通过对 AWS 资源进行分类和分组，从而让您能够轻松分配成本和优化支出。例如，您可以使用标签按管理员、应用程序名称、成本中心或特定项目对资源进行分组。要了解有关成本分配标记的更多信息，请参阅[使用成本分配标签](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)。如果您已准备好向 CloudFront 分配添加标签，请参阅 [Amazon CloudFront 添加标签页面](http://docs.aws.amazon.com/console/cloudfront/tagging)。"
    },
    {
        "query":"我能否获得我账户上所有的 Amazon CloudFront API 调用历史记录，以用于安全性、操作性或合规性审核？",
        "intention":"知识问答",
        "reply":"是。要获得由您的账户发起的所有 Amazon CloudFront API 调用历史记录，只需在 [CloudTrail 的 AWS 管理控制台](https://console.aws.amazon.com/cloudtrail)中打开 AWS CloudTrail。有关更多信息，请访问 [AWS CloudTrail 主页](https://aws.amazon.com/cn/cloudtrail/)。"
    },
    {
        "query":"你们是否提供对指标进行实时监控和警报的选项？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon CloudWatch 在浏览者发出请求的几分钟内监控、发出报警并接收有关 Amazon CloudFront 分配运行性能的通知。CloudFront 每隔 1 分钟向 Amazon CloudWatch 自动发布六个运行指标。您可以使用 CloudWatch 针对 CloudFront 流量中的任何异常情况设置警报。要了解如何开始通过 CloudWatch 监控 CloudFront 活动和设置警报，请在 [Amazon CloudFront 开发人员指南](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/monitoring-using-cloudwatch.html)中查看我们的操作步骤，或只需导航到 [Amazon CloudFront 管理控制台](https://console.aws.amazon.com/cloudfront/home)，然后在导航窗格中选择“监控和报警”。"
    },
    {
        "query":"什么是 CloudFront Functions？",
        "intention":"知识问答",
        "reply":"CloudFront Functions 是一种无服务器边缘计算功能，允许您在超过 225 个 CloudFront 边缘站点运行 JavaScript 代码以进行轻量级 HTTP(s) 转换和操作。专门构建 Functions 以使客户能够灵活地获得完整编程环境，并达到现代 Web 应用程序要求的性能和安全性。客户可以即时扩展，并以经济的方式支持每秒数以百万计的请求，价格只有 [AWS Lambda@Edge](https://aws.amazon.com/cn/lambda/edge/) 的零头。"
    },
    {
        "query":"如何使用 CloudFront Functions 自定义内容？",
        "intention":"知识问答",
        "reply":"CloudFront Functions 以原生方式构建到 CloudFront 中，让客户能够轻松地在同一服务内构建、测试和部署函数。我们的 [GitHub 存储库](https://github.com/aws-samples/amazon-cloudfront-functions)提供了大量的示例代码，开发人员可以将它们用作构建函数的起点，以此轻松开始使用该功能。您可以在 CloudFront 控制台上使用 IDE 或 CloudFront API/CLI 构建函数。撰写了代码后，您可以对照生产 CloudFront 分发测试自己的函数，确保该函数部署后可正确地执行。控制台中的测试功能提供了一个可视化编辑器，可以快速创建测试事件并验证函数。与 CloudFront 分发关联之后，代码即部署到 AWS 全球分布的边缘站点网络，并执行对 CloudFront 请求的响应。"
    },
    {
        "query":"CloudFront Functions 的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"CloudFront Functions 极其适合轻量级短期运行的函数，例如：\n所有上述不同使用案例的示例函数均可从 CloudFront Functions [GitHub 存储库](https://github.com/aws-samples/amazon-cloudfront-functions)获得，以帮助您快速入门。"
    },
    {
        "query":"AWS 如何确保 CloudFront Functions 的安全？  CloudFront Functions 带来您期待的性能、规模和成本效益优势，但通过独特的安全模型在函数代码之间提供严格隔离边界。当您在共享的多租户计算环境中运行自定义代码时，维护高度安全的执行环境很关键。坏人可能会尝试利用运行时、库或 CPU 中存在的漏洞，将敏感数据从服务器或其他客户函数中泄漏出去。如果函数代码之间没有严密的隔离屏障，就可能会被这样利用漏洞。AWS Lambda 和 Lambda@Edge 都已通过基于 Firecracker 的 VM 隔离实现了这种安全隔离。通过 CloudFront Functions，我们已开发出基于进程的隔离模型，它可针对旁路攻击（例如，Spectre 和 Meltdown）、基于时间的攻击或其他代码漏洞提供相同的安全性。CloudFront Functions 无法访问或修改属于其他客户的数据。我们通过在专用 CPU 上的专用进程中运行函数实现此目的。CloudFront Functions 在每次仅为一个客户服务的工作进程上执行，在两次执行之间将会清除（刷新）所有客户特定的数据。",
        "intention":"知识问答",
        "reply":"CloudFront Functions 不使用 V8 作为 JavaScript 引擎。Functions 的安全模型不同，被认为比 v8 基于部分其他供应商提供的模型进行的隔离更加安全。"
    },
    {
        "query":"什么是 Lambda@Edge？",
        "intention":"知识问答",
        "reply":"[Lambda@Edge](https://aws.amazon.com/cn/lambda/edge/) 是 [AWS Lambda](https://aws.amazon.com/cn/lambda/) 的扩展，允许您在全球边缘站点运行代码，而无需预置或管理服务器。Lambda@Edge 可为复杂函数提供强大而灵活的无服务器计算，并带来更接近您的查看器的完整应用程序逻辑。Lambda@Edge 函数在 Node.js 或 Python 环境中运行。您将函数发布到单个 AWS 区域，当您关联该函数与 CloudFront 分发时，Lambda@Edge 可自动将您的代码复制到世界上任何地点。Lambda@Edge 可自动扩展，从每天数次请求到每秒数千次。"
    },
    {
        "query":"如何使用 Lambda@Edge 自定义内容？",
        "intention":"知识问答",
        "reply":"通过针对 CloudFront 中的特定缓存行为关联函数来执行 Lambda@Edge。您还可以指定函数应在 CloudFront 请求或响应处理期间的哪个点执行（例如，当查看器请求到达时、当请求转发到源或从源返回时，或者就在响应返回最终查看器之前）。您使用 Node.js 或 Python 从 Lambda 控制台、API 或使用 [Serverless Application Model (SAM)](https://aws.amazon.com/cn/serverless/sam/) 之类的框架撰写代码。当您测试函数时，将其与所选 CloudFront 缓存行为和事件触发器关联。保存后，下次对 CloudFront 分发进行请求时，该功能将传播到 CloudFront 边缘，并在必要时扩展和执行。有关更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html)。\n问：通过 Amazon CloudFront，可以触发哪些 Lambda@Edge 事件？\n在响应以下 Amazon CloudFront 事件时，会自动触发您的 Lambda@Edge 函数："
    },
    {
        "query":"什么是 CloudFront 上的持续部署？",
        "intention":"知识问答",
        "reply":"CloudFront 上的持续部署能够在将更改部署到所有查看器之前，使用一部分实时流量测试和验证配置更改的新功能。\nCloudFront 的持续部署为您提供了高级别的部署安全性。现在，您可以部署两个独立但相同的环境（蓝色和绿色），轻松集成到持续集成和交付 (CI/CD) 管道，从而能够逐步推出版本，而无需更改任何域名系统 (DNS)。此功能可以将查看器会话绑定到同一环境，从而确保查看器通过会话粘性获得一致体验。此外，您还可以通过监控标准和实时日志对比更改的效果，并在更改对服务产生负面影响时快速恢复到之前的配置。"
    },
    {
        "query":"如何设置 CloudFront 上的持续部署？",
        "intention":"知识问答",
        "reply":"您可以通过 CloudFront 控制台、SDK、命令行界面（CLI）或 CloudFormation 模板将暂存分配关联到主要分配来设置持续部署。然后，您可以定义规则来拆分流量，方法是配置客户端标头或拨出一定比例的流量以使用暂存分布进行测试。设置完成后，您可以使用所需的更改更新暂存配置。CloudFront 将管理分配给用户的流量并提供相关分析以帮助您决定是继续部署还是回滚。一旦对暂存发行版的测试得到验证，您就可以将更改合并到主要发行版中。\n要了解有关此功能的更多信息，请访问[文档](https://docs.aws.amazon.com/cloudfront/latest/DeveloperGuide/test-configuration-changes.html)。"
    },
    {
        "query":"我要如何衡量持续部署的结果？",
        "intention":"知识问答",
        "reply":"持续部署允许通过实际 Web 流量进行真实的用户监控。您可以使用任何现有的可用监控方法（CloudFront 控制台、CloudFront API、CLI 或 CloudWatch）来单独测量主要和暂存分布的操作指标。您可以通过测量和比较两个发行版之间的吞吐量、延迟和可用性指标来衡量特定应用程序的成功标准。"
    },
    {
        "query":"是否可以使用现有的发行版？",
        "intention":"知识问答",
        "reply":"是，您可以使用任何现有的发行版作为基线来创建暂存发行版并引入和测试更改。"
    },
    {
        "query":"持续部署如何与 CloudFront Functions 和 Lambda@Edge 协同工作？",
        "intention":"知识问答",
        "reply":"通过持续部署，您可以将不同的功能与主要和临时分布相关联。您还可以对两个发行版使用相同的函数。如果您更新两个发行版都使用的函数，则它们都会收到更新。"
    },
    {
        "query":"如何将持续部署发行版与 AWS CloudFormation 配合使用？",
        "intention":"知识问答",
        "reply":"CloudFormation 堆栈中的每个资源都映射到特定的 AWS 资源。暂存分配将拥有自己的资源 ID，其使用方式与任何其他 AWS 资源一样。您可以使用 CloudFormation 创建/更新该资源。"
    },
    {
        "query":"CloudFront 上的持续部署如何支持会话粘性？",
        "intention":"知识问答",
        "reply":"当您使用基于权重的配置将流量路由到暂存分配时，您还可以启用会话粘性，这有助于确保 CloudFront 将来自同一查看器的请求视为单个会话。当您启用会话粘性时，CloudFront 会设置一个 Cookie，以便单个会话中来自同一查看器的所有请求都由一个分配（主要分配或暂存分配）提供服务。"
    },
    {
        "query":"什么是 IPv6？",
        "intention":"知识问答",
        "reply":"连接到 Internet 的每个服务器和设备必须拥有的数字 Internet 协议 (IP) 地址。随着 Internet 的发展和使用 Internet 的用户呈指数增长，对 IP 地址的需求也随之增长。IPv6 是新版 Internet 协议，与其前身 IPv4 相比，IPv6 使用更大的地址空间。在使用 IPv4 时，每个 IP 地址的长度为 32 位，这允许存在 43 亿个唯一的地址。IPv4 地址示例： 192.0.2.1。相比之下，IPv6 地址的长度为 128 位，这允许存在大约 340 万亿个唯一的 IP 地址。这里有一个 IPv6 地址的例子：2001:0db8:85a3:0:0:8a2e:0370:7334"
    },
    {
        "query":"IPv6 可以用来做什么？",
        "intention":"知识问答",
        "reply":"使用适用于 Amazon CloudFront 的 IPv6 支持，应用程序无需任何 IPv6 到 IPv4 转换软件或系统即可连接到 Amazon CloudFront 边缘站点。您可以满足政府设定的 IPv6 采用要求 - 包括[美国联邦政府](https://www.cio.gov/policies-and-priorities/IPV6/) - 受益于 IPv6 可扩展性、网络管理的简单性以及对安全性的额外内置支持。"
    },
    {
        "query":"在使用 IPv6 时，我是否应该期望 Amazon CloudFront 性能发生变化？",
        "intention":"知识问答",
        "reply":"不会，不论是使用 IPv4 还是 IPv6，Amazon CloudFront 的性能都相同。"
    },
    {
        "query":"是否有些 Amazon CloudFront 功能不适用于 IPv6？",
        "intention":"知识问答",
        "reply":"尽管在为您的分发打开 IPv6 之前可能需要对内部 IPv6 地址处理程序进行两处更改，但 Amazon CloudFront 的所有现有功能将继续适用于 IPv6。\n此外，如果您针对可信签署人使用了 IP 白名单，应针对 IP 白名单上的可信签署人 URL 仅使用 IPv4 分配，但可对所有其他内容使用 IPv4/IPv6 分配。该模型可避免发生以下问题：如果签名请求是通过 IPv4 地址到达并也通过该地址进行签署，则只能让内容请求通过不在白名单上的不同 IPv6 地址到达。\n要了解有关 Amazon CloudFront 中 IPv6 支持的更多信息，请参阅 Amazon CloudFront 开发人员指南中的“[Amazon CloudFront 上的 IPv6 支持](http://docs.aws.amazon.com/console/cloudfront/ipv6)”部分。"
    },
    {
        "query":"这是否意味着，如果我想一直使用 IPv6，就无法使用 IP 白名单上的可信签署人 URL？",
        "intention":"知识问答",
        "reply":"否。如果您想同时使用 IPv6 和 IP 白名单上的可信签署人 URL，您应使用两种独立的分配方法。您应该为 IP 白名单上的可信签署人 URL 专门指定分配，并针对此分配禁用 IPv6。然后，您将针对所有其他内容使用另一种同时适用于 IPv4 和 IPv6 的分配。"
    },
    {
        "query":"如果我启用了 IPv6，IPv6 地址将会显示在访问日志中吗？",
        "intention":"知识问答",
        "reply":"会，如果您已经启用了 Amazon CloudFront 访问日志功能，您的查看者的 IPv6 地址现在将在访问日志的“c-ip”字段中显示。在为您的分配打开 IPv6 之前，您可能需要验证您的日志处理系统是否继续适用于 IPv6 地址。如果您对 IPv6 流量影响工具或软件处理访问日志中 IPv6 地址的能力有任何问题，请联系开发人员支持。有关更多详细信息，请参阅 [Amazon CloudFront 访问日志](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat)文档。"
    },
    {
        "query":"我是否可以为我所有的新分配禁用 IPv6？",
        "intention":"知识问答",
        "reply":"可以，对于新分配和现有分配，您可以使用 Amazon CloudFront 控制台或 API 来按分配启用/禁用 IPv6。"
    },
    {
        "query":"我为什么要禁用 IPv6？",
        "intention":"知识问答",
        "reply":"在与客户的讨论中，我们听到的唯一一个常见案例就是内部 IP 地址处理。为 Amazon CloudFront 分发启用 IPv6 后，您除了可以在详细的访问日志中获取 IPv6 地址外，还可以在发送到您的原始系统的“[X-Forwarded-For](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/RequestAndResponseBehaviorS3Origin.html#RequestS3IPAddresses)”标题中获取 IPv6 地址。如果您的原始系统仅能处理 IPv4 地址，则在为您的分发打开 IPv6 之前，您可能需要验证您的原始系统是否继续适用于 IPv6 地址。"
    },
    {
        "query":"我已经为我的分配启用了 IPv6，但 DNS 查找没有返回任何 IPv6 地址。发生了什么？",
        "intention":"知识问答",
        "reply":"虽然 Amazon CloudFront 在全球拥有非常多的连接，但仍然有一些网络还没有普及 IPv6 连接。虽然从长远来看，很显然 IPv6 才是 Internet 的未来，但在可预见的未来，Internet 上的每个终端节点将仍然使用 IPv4 连接。当我们发现 Internet 的部分终端节点使用 IPv4 连接的效果比 IPv6 好时，我们当然更愿意使用前者。"
    },
    {
        "query":"如果我使用 Route 53 来处理我的 DNS 需求，并且已经创建了指向一个 Amazon CloudFront 分配的别名记录，我是否需要更新我的别名记录，以启用 IPv6？",
        "intention":"知识问答",
        "reply":"需要，您可以创建指向您的 Amazon CloudFront 分配的 Route 53 别名记录，以分别使用“A”和“AAAA”记录类型来支持 IPv4 和 IPv6。如果您想仅启用 IPv4，则您仅需要一个“A”类型的别名记录即可。有关别名资源记录集的详细信息，请参阅 [Amazon Route 53 开发人员指南](http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/resource-record-sets-choosing-alias-non-alias.html?shortFooter=true)。"
    },
    {
        "query":"Amazon CloudFront的 AWS 免费套餐包含哪些使用类型？",
        "intention":"知识问答",
        "reply":"从2021年12月1日开始，所有 AWS 客户将获得每月 1 TB 的数据传出、10,000,000 次 HTTP/HTTPS 请求以及 2000000 次 CloudFront 函数调用的使用配额。免费套餐不包括所有其他使用类型（例如 Invalidations、Proxy requests、Lambda@edge、Origin shield、Data Transfer to Origin等）。"
    },
    {
        "query":"如果我们注册了整合账单，是否可以针对每个账户获得 AWS 免费套餐？",
        "intention":"知识问答",
        "reply":"不能。使用整合账单跨多个账户间统一付款的客户只能获得每个组织一个免费套餐。"
    },
    {
        "query":"如果我在多个地区使用，并且超出了免费套餐，会发生什么？",
        "intention":"知识问答",
        "reply":"1 TB 数据传输和 1000 万次请求是所有边缘位置的每月免费套餐限制。如果用量超过了每月免费套餐限制，您只需按标准的 AWS 服务按需支付费率支付每个地区的费用即可。请参阅 [CloudFront 定价](https://aws.amazon.com/cn/cloudfront/pricing/)页面了解完整的定价详情。"
    },
    {
        "query":"如何了解已经使用的用量以及是否已超出免费使用套餐限额？",
        "intention":"知识问答",
        "reply":"登录您的账户并进入账单和成本管理控制面板，您可以按地区查看当前和过去的使用活动。在此面板中，您可以通过 [AWS Budgets](https://console.aws.amazon.com/billing/home?#/budgets) 管理成本和使用情况、 通过 [Cost Explorer](https://console.aws.amazon.com/billing/home?#/costexplorer) 显示成本动因和使用趋势，并通过 [成本和使用情况报告](https://console.aws.amazon.com/billing/home?#/reports) 深入了解您的成本。 要了解有关如何控制 AWS 成本的更多信息，请查看控制 AWS 成本 10 分钟教程。\n问：免费套餐是否适用于订阅 CloudFront Security Savings 捆绑包的客户？\n订阅 CloudFront Security Savings 捆绑包的客户也可以享受免费套餐。如果您觉得有必要根据免费套餐降低对 CloudFront Security Savings 捆绑包的承诺，请联系客户服务部，我们将评估您的更改请求。未来几天，我们将提供更多的细节。请继续收看。\n更多问题，请参见 [https://aws.amazon.com/free/free-tier-faqs/](https://aws.amazon.com/cn/free/free-tier-faqs/)。\n问：使用 Amazon CloudFront 如何收费？\nAmazon CloudFront 根据以下五个方面的服务实际使用量进行收费：数据传出、HTTP/HTTPS 请求、失效请求、实时日志请求，以及与 CloudFront 分配相关联的专用 IP 自定义 SSL 证书。\n借助[AWS 免费试用套餐](https://aws.amazon.com/cn/free/)，您可以开始免费使用 Amazon CloudFront，并随着使用量的增加而降低费率。所有 CloudFront 客户都可以免费接收 1 TB 的数据转出和 10000000 次针对 Amazon CloudFront 的 HTTP 和 HTTPS 请求，即使超出了这些限制。如果\n数据传输的使用套餐针对每个区域单独计量。除非另行说明，否则上述价格不包括适用税费、费用或类似政府收费（如果存在）。"
    },
    {
        "query":"实时日志的成本是多少？ 如果您的分发每秒提供 1000 个请求及 1KB 的日志大小，并在美国东部（俄亥俄）创建具有 2 个分区的 Kinesis 数据流：",
        "intention":"知识问答",
        "reply":"Kinesis 数据流的月度成本为：47.74 USD/月，[在此](https://aws.amazon.com/kinesis/data-streams/pricing/)使用 Kinesis 计算器进行计算。\nCloudFront 实时日志的月度成本：每秒请求数 X 实时日志的成本 = 1000 \\*（60 秒 \\* 60 分钟 \\*24 小时 \\* 30 天）X（0.01 USD /1000000）= 25.92 USD/月"
    },
    {
        "query":"什么是 CloudFront Security Savings Bundle？",
        "intention":"知识问答",
        "reply":"CloudFront Security Savings Bundle 是一种灵活的自助定价计划，可帮助您最多节省 30％ 的 CloudFront 费用，但您需要承诺为期一年的稳定月度使用量（例如每月 100 USD）。  作为一项额外的权益，包含用于保护 CloudFront 资源的 Amazon WAF（Web 应用程序防火墙）使用量（最高为已承诺计划金额的 10％），无需额外付费。 例如，承诺每月使用 100 USD 的 CloudFront 将涵盖价值 142.86 USD 的 CloudFront 使用量，与标准费率相比可节省 30％。此外，还包括高达 10 美元的用于保护 CloudFront 资源的 Amazon WAF 使用量，而无需每月额外付费（最高为 CloudFront 承诺的 10％）。  对于超出您每月支出承诺的任何使用量，将收取标准 CloudFront 和 Amazon WAF 费用。  随着使用量的增长，您可以购买附加的 Savings Bundle，以获取增量使用量的折扣。"
    },
    {
        "query":"CloudFront Security Savings Bundle 涵盖哪些类型的使用？",
        "intention":"知识问答",
        "reply":"通过购买 CloudFront Security Savings Bundle，您将获得 30％ 的节省，该节省将显示在月度账单的 CloudFront 服务部分，这将抵免任何 CloudFront 计费使用类型，包括数据传出、数据传输到源、HTTP/S 请求费用、字段级加密请求、Origin Shield、失效、专用 IP 自定义 SSL 和 Lambda@Edge 费用。  您还将获得其他权益，可帮助您涵盖与 CloudFront 分配相关联的 Amazon WAF 使用量。"
    },
    {
        "query":"如果我的 CloudFront Security Savings Bundle 在 1 年期限后到期，会发生什么情况？",
        "intention":"知识问答",
        "reply":"当 CloudFront Security Savings Bundle 到期后，将对 CloudFront 和 Amazon WAF 收取标准服务费用。   每月 Savings Bundle 承诺将不再计费，并且 Savings Bundle 权益将不再适用。  在服务包到期前的任何时间，您都可以选择加入以自动将 CloudFront Security Savings Bundle 续期一年。"
    },
    {
        "query":"CloudFront Security Savings Bundle 如何与 Amazon Organizations/整合账单一起使用？",
        "intention":"知识问答",
        "reply":"可通过 Amazon Organizations/整合账单系列中的任何账单购买 CloudFront Security Savings Bundle。  CloudFront Security Savings Bundle 权益作为账单上的抵扣金额提供。默认情况下，Savings Bundle 提供的权益适用于 Amazon Organizations/整合账单系列中所有帐户的使用量（已启用抵扣金额共享），并且取决于订阅账户加入或离开组织的时间。  请参阅 [AWS 服务抵扣金](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/useconsolidatedbilling-credits.html)，以详细了解如何在单个和多个账户中应用 AWS 服务抵扣金。"
    },
    {
        "query":"我可以同时激活多个 CloudFront Security Savings Bundles 吗？",
        "intention":"知识问答",
        "reply":"是的，随着使用量的增长，您可以购买附加的 CloudFront Security Savings Bundles，以获取增量使用量的折扣。   在计算您的 Amazon Web Services 账单时，将考虑所有活动的 CloudFront Security Savings Bundles。\n问：CloudFront Security Savings Bundle 如何显示在我的账单上？\n您的每月承诺费用将显示在账单上单独的 CloudFront Security Bundle 部分下。  CloudFront Security Savings Bundle 涵盖的使用量将显示在账单的 CloudFront 和 WAF 部分下，作为抵免标准使用费的抵扣金额。\n问：如果我的使用量超出了 CloudFront Security Savings Bundle 的每月承诺，是否会收到通知？\n是的，当您的实际或预测费用超过阈值时，Amazon Budgets 允许您设置成本和使用量阈值并通过电子邮件或 Amazon SNS 主题接收通知。  您可以创建针对 CloudFront 服务进行筛选的自定义 Amazon Web Services 预算，并将预算阈值金额设置为 CloudFront Security Savings Bundle 涵盖的 CloudFront 按需使用量，一旦超过该阈值，您便会收到通知。   有关预算的更多信息，请参阅 AWS Billing and Cost Management 用户指南中的[利用 Amazon Budgets 管理成本](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-managing-costs.html)和[创建预算](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/budgets-create.html)。\n问：CloudFront Security Savings Bundle 涵盖我的 WAF 账单的哪个部分？\n作为 CloudFront Security Savings Bundle 的一项额外权益，包含用于保护 CloudFront 资源的 Amazon WAF 使用量（最高为已承诺计划金额的 10％），无需额外付费。对于超出 CloudFront Security Savings Bundle 所涵盖的使用量的部分，将收取标准 CloudFront 和 Amazon WAF 费用。  通过 Amazon Marketplace 订阅的托管 WAF 规则未涵盖在 CloudFront Security Savings Bundle 内。\n问：如果我已拥有 CloudFront 的自定义定价协议，我是否也可以订阅 CloudFront Security Savings Bundle？\n您只能订阅一个或另一个。  如果您对自定义定价协议有任何疑问，请联系您的 Amazon Web Services 客户经理。\n问：我可以通过 API 订阅 CloudFront Security Savings Bundle 吗？\n您只能通过 [CloudFront 控制台订阅 CloudFront Security Savings Bundle。](https://console.aws.amazon.com/cloudfront/v2/home#/savings-bundle/overview)  我们将评估通过 API 使其可用（作为未来增强功能提供）。\n了解如何免费开始使用 Amazon CloudFront"
    },
    {
        "query":"What is Amazon Web Services?",
        "intention":"知识问答",
        "reply":"Amazon Web Services (AWS) provides agencies and businesses with an infrastructure web services platform in the [cloud](https://aws.amazon.com/what-is-cloud-computing/). With AWS you can requisition compute, storage, and other services – gaining access to a suite of secure, scalable, and flexible IT infrastructure services as your agency or business demands them. With AWS, you pay only for what you use, making AWS a cost-effective way to deliver your applications."
    },
    {
        "query":"What is AWS GovCloud (US)?",
        "intention":"知识问答",
        "reply":"AWS GovCloud (US) is designed to address specific regulatory and compliance requirements of US government agencies at the federal, state, and local level, as well as contractors, educational institutions, and other U.S. customers that run sensitive workloads in the cloud. Beyond the assurance programs applicable to all AWS Regions, the AWS GovCloud (US) Regions allow customers to adhere to U.S. International Traffic in Arms Regulations (ITAR), Federal Risk and Authorization Management Program (FedRAMP), and Department of Defense (DoD) Cloud Computing Security Requirements Guide (SRG) Impact Levels 2, 4, and 5. Visit the [Compliance Programs page](https://aws.amazon.com/compliance/) for a complete list of U.S. compliance standards supported by AWS GovCloud (US)."
    },
    {
        "query":"What is the AWS GovCloud (US) network?",
        "intention":"知识问答",
        "reply":"The AWS GovCloud (US) network consists of AWS’s internal data center facilities, servers, networking equipment, and host software systems that are within AWS’s reasonable control, which are used to provide AWS services in the AWS GovCloud (US) Regions."
    },
    {
        "query":"Where are the AWS GovCloud (US) Regions located?",
        "intention":"知识问答",
        "reply":"The AWS GovCloud (US) Regions are located in the Eastern and Northwestern parts of the United States. [See our Regions map](https://aws.amazon.com/about-aws/global-infrastructure/) for more information."
    },
    {
        "query":"Do the AWS GovCloud (US) Regions have a FedRAMP JAB P-ATO?",
        "intention":"知识问答",
        "reply":"Yes. Two FedRAMP Joint Authorization Board P-ATOs have been issued; one covers the AWS GovCloud (US) Regions, and the other covers the AWS US East/West Regions. Customers can immediately request access to the FedRAMP package using [AWS Artifact](https://aws.amazon.com/artifact/). Government customers can request access to the \"Amazon Web Services - AWS GovCloud (US) Regions\" FedRAMP package by submitting a request on the [Compliance Contact Us Request Form](https://aws.amazon.com/compliance/public-sector-contact/)."
    },
    {
        "query":"Does AWS GovCloud (US) offer better security than other AWS Regions?",
        "intention":"知识问答",
        "reply":"AWS GovCloud (US) offers the same high level of security as other AWS Regions and supports existing AWS security controls and certifications. These controls can be found on the [AWS Compliance page](https://aws.amazon.com/compliance/). The AWS GovCloud (US) Regions are maintained by U.S. citizens only and provide customers with the ability to access the regions through FIPS 140-2 service endpoints."
    },
    {
        "query":"What are the ITAR requirements?",
        "intention":"知识问答",
        "reply":"The ITAR is the International Traffic in Arms Regulations, which is a set of United States government regulations that control the export and temporary import of defense articles, services, and related technical data. The ITAR requires that ITAR-controlled defense articles, services, and related technical data can only be shared with non-U.S. persons when approved by a valid U.S. Department of State authorization. AWS manages the AWS GovCloud (US) Regions using U.S. citizens and enables customers to architect solutions in the AWS GovCloud (US) Regions involving ITAR data (with due consideration to the customer’s shared responsibility for export-control compliance)."
    },
    {
        "query":"Are the AWS GovCloud (US) Regions ITAR certified?",
        "intention":"知识问答",
        "reply":"Unlike ISO 27001, there is no formal ITAR certification. However, AWS has conducted a third-party review of the AWS GovCloud (US) Regions and our FedRAMP authorizations attest to the controls in place within the AWS GovCloud (US) Regions to ensure AWS supports customers building ITAR compliant systems on AWS."
    },
    {
        "query":"Does the ITAR apply to AWS as a cloud service provider?",
        "intention":"知识问答",
        "reply":"As a cloud service provider, AWS is not an exporter of data as contemplated by the relevant agencies enforcing the ITAR and other export control laws. AWS supports customers with ITAR requirements by restricting access to the AWS GovCloud (US) network controlled by AWS to U.S. citizens. This facilitates a customer’s management of their own compliance obligations while processing and storing data in the AWS GovCloud (US) Regions."
    },
    {
        "query":"How do Government agencies, contractors, and customers access the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"AWS GovCloud (US) requires a separate account ID and user access credentials in addition to those required for an associated standard AWS account. Access is restricted to customers who are U.S. persons, not subject to export restrictions, and who comply with US export control laws and regulations, including the International Traffic in Arms Regulations (ITAR). Qualified customers can request access to AWS GovCloud (US) from the AWS Management Console of a standard AWS account or by [contacting an AWS business representative](https://aws.amazon.com/govcloud-us/contact/)."
    },
    {
        "query":"Do all government agencies need to use AWS GovCloud (US)?",
        "intention":"知识问答",
        "reply":"No. AWS GovCloud (US) is provided for entities that choose, or are required, to utilize a U.S. persons only cloud environment. Agencies that do not want to use a U.S. persons only environment can use our other AWS Regions, which provide FISMA-Moderate controls."
    },
    {
        "query":"Do agencies have to sign a contract to use AWS GovCloud (US)?",
        "intention":"知识问答",
        "reply":"Yes. Agencies must sign a customer agreement and an agreement specific to AWS GovCloud (US) to access the AWS GovCloud (US) Regions. Please contact your AWS business representative, or fill out the [AWS GovCloud (US) Contact Us form](https://aws.amazon.com/govcloud-us/contact/)."
    },
    {
        "query":"What are AWS GovCloud (US) use cases?",
        "intention":"知识问答",
        "reply":"AWS GovCloud (US) can be used to power a wide variety of IT applications and workloads, including enterprise applications (Oracle, SAP, Microsoft Windows Server, etc.), high performance computing (HPC), storage, disaster recovery, and web applications workloads."
    },
    {
        "query":"What services are available in AWS GovCloud (US)?",
        "intention":"知识问答",
        "reply":"See the [AWS GovCloud (US) Product Details](https://aws.amazon.com/govcloud-us/details/) page for the list of available services in the regions."
    },
    {
        "query":"How do I get to the AWS Management Console for the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"Login to the [AWS Management Console](https://signin.amazonaws-us-gov.com/oauth?SignatureVersion=4&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAKRR57OXBZ66K46GA&X-Amz-Date=2019-11-21T21%3A01%3A28.872Z&X-Amz-Signature=5745eb1192ef4d551c3c927017be5be41952aacedd817d2892e0fe0aab3ca5bd&X-Amz-SignedHeaders=host&client_id=arn%3Aaws-us-gov%3Aiam%3A%3A464433863101%3Auser%2Fhomepage&redirect_uri=https%3A%2F%2Fconsole.amazonaws-us-gov.com%2Fconsole%2Fhome%3Fstate%3DhashArgs%2523%26isauthcode%3Dtrue&response_type=code&state=hashArgs%23) for the AWS GovCloud (US) Regions. To learn more about how to setup your unique login credentials for console access, please visit the [AWS GovCloud (US) User Guide](https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/welcome.html)."
    },
    {
        "query":"How do I set up AWS Direct Connect for the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"See the [AWS GovCloud (US) User Guide](https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/govcloud-dc.html) for detailed instructions on how to set up an AWS Direct Connect connection for the AWS GovCloud (US) Regions."
    },
    {
        "query":"Is IPV6 available in AWS GovCloud (US)?",
        "intention":"知识问答",
        "reply":"Yes, IPV6 is available in AWS GovCloud (US) for Elastic Load Balancers (ELB), Amazon Simple Storage Service (Amazon S3), and Amazon Virtual Private Cloud (Amazon VPC).\nAWS Support is available in all regions, including AWS GovCloud (US). As an AWS GovCloud (US) customer, you have access to AWS Support engineers 24 hours a day by email, chat, and phone. By default, support cases might be assigned to support engineers outside the US who are skilled in the service selected. When access to restricted resources is required in support of the case, US-based engineers are available to assist.\nTo sign up for AWS Support, visit the [support sign up page](https://aws.amazon.com/premiumsupport/plans/) and select a plan using the standard AWS root account credentials that are associated with your AWS GovCloud (US) account."
    },
    {
        "query":"What types of customer service and support are provided for the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"Customer Service is available 24/7/365 to answer any billing or account related questions. AWS GovCloud (US) customers can choose from Developer-level, Business-level, or Enterprise-level technical support. If ITAR compliance is a priority, AWS suggests choosing Business or Enterprise Support. Business-level support provides 24/7/365 phone, chat, and email support with a one-hour response, support for third-party software, and architecture support. Enterprise-level support customers receive additional benefits with a 15-minute response time and are assigned a Technical Account Manager (TAM).\nView the AWS GovCloud (US) [Service Health Dashboard](https://status.aws.amazon.com/govcloud) for up-to-the-minute information on service availability in the AWS GovCloud (US) Regions. The Service Health Dashboard for the AWS GovCloud (US) Regions is available for all customers."
    },
    {
        "query":"How do I sign up for technical support?",
        "intention":"知识问答",
        "reply":"To sign up for AWS Support, visit the [support sign up page](https://aws.amazon.com/premiumsupport/plans/) and select a plan using the standard AWS root account credentials that are associated with your AWS GovCloud (US) account."
    },
    {
        "query":"What are the differences between Business and Enterprise level Support for the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"You can compare support plans [here](https://aws.amazon.com/premiumsupport/plans/)."
    },
    {
        "query":"How do I increase resource limits in the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"By default, AWS maintains limits for certain resources in your AWS GovCloud (US) account. For example, accounts have a limit on the number of Amazon Elastic Compute Cloud (Amazon EC2) instances that can be launched. You can see your current limits and request limit increases on the Limits Page in the Amazon EC2 console. When you request a limit increase, specify your AWS GovCloud (US) account ID and select the AWS GovCloud (US) Regions from the region drop-down list. For more information, see [AWS Service Limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html)."
    },
    {
        "query":"How can I access customer service and support for the AWS GovCloud (US) Regions?",
        "intention":"知识问答",
        "reply":"Support can be obtained by navigating to the [Support Center](https://console.amazonaws-us-gov.com/support/home). Log in using your master AWS account, create a case, and indicate that your question or issue is in regard to the AWS GovCloud (US) Regions."
    },
    {
        "query":"How much does AWS GovCloud (US) cost?",
        "intention":"知识问答",
        "reply":"AWS GovCloud (US) provides customers with a choice in how they want to purchase our services. AWS GovCloud (US) costs are based on the quantity of services used and the payment model utilized to procure these services.\nThe on-demand and reserved pricing models available in the traditional AWS cloud are also available in the AWS GovCloud (US) Regions. In addition, Reserved Instances (RI) are available in the AWS GovCloud (US) Regions for Amazon EC2 and AWS data transfer services. Reserved Instance pricing allow AWS GovCloud (US) customers the option to make a one-time fixed payment for each service they want to reserve. After the one-time payment, customers can utilize that service for the duration of their term with no additional payment as long as they don’t exceed the usage they have paid for."
    },
    {
        "query":"什么是 Client VPN 终端节点？",
        "intention":"知识问答",
        "reply":"Client VPN 终端节点是一个区域结构，您可以配置该结构以使用该服务。最终用户的 VPN 会话在 Client VPN 终端节点处终止。作为配置 Client VPN 终端节点的一部分，您可以指定身份验证详细信息、服务器证书信息、客户端 IP 地址分配、日志记录和 VPN 选项。"
    },
    {
        "query":"什么是目标网络？",
        "intention":"知识问答",
        "reply":"目标网络是与 Client VPN 终端节点关联的网络，它可以安全访问 AWS 资源以及本地资源。目前，目标网络是您的 Amazon VPC 中的子网。"
    },
    {
        "query":"如何定义应计费 VPN 连接小时数？",
        "intention":"知识问答",
        "reply":"应计费 VPN 连接小时数是指 VPN 连接处于可用状态的时间。您可以通过 AWS 管理控制台、CLI 或 API 确定 VPN 连接的状态。如果您不想再用 VPN 连接，只需终止 VPN 连接即可避免产生额外的 VPN 连接小时数。"
    },
    {
        "query":"可否使用 AWS 管理控制台控制和管理 AWS Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"是。您可以使用 AWS 管理控制台管理 IPSec VPN 连接，例如 AWS Site-to-Site VPN。"
    },
    {
        "query":"Site-to-Site VPN 的默认限制或配额是多少？",
        "intention":"知识问答",
        "reply":"有关AWS Site-to-Site VPN 限制和配额的详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/vpn/latest/s2svpn/vpn-limits.html)。"
    },
    {
        "query":"VPC 有哪些 VPN 连接选择？",
        "intention":"知识问答",
        "reply":"您可以通过虚拟私有网关使用硬件 VPN 连接将 VPC 连接到企业数据中心。"
    },
    {
        "query":"没有公有 IP 地址的实例如何访问 Internet？",
        "intention":"知识问答",
        "reply":"没有公有 IP 地址的实例可以通过以下两种方式之一访问 Internet：\n没有公有 IP 地址的实例可以通过网络地址转换 (NAT) 网关或 NAT 实例来传输流量，从而访问 Internet。这些实例使用 NAT 网关或 NAT 实例的公有 IP 地址来访问 Internet。NAT 网关或 NAT 实例允许出站通信，但不允许 Internet 上的计算机主动连接具有私有地址的实例。\n对于通过硬件 VPN 或 Direct Connect 进行连接的 VPC，实例可以将其 Internet 流量通过虚拟私有网关下传到现有的数据中心。它可从该处借助现有出口点和网络安全/监控设备访问 Internet。"
    },
    {
        "query":"AWS Site-to-Site VPN 连接如何与 Amazon VPC 搭配使用？",
        "intention":"知识问答",
        "reply":"AWS Site-to-Site VPN 连接将 VPC 与数据中心连接。Amazon 支持 Internet 安全协议 (IPsec) VPN 连接。在 VPC 与数据中心之间传输的数据通过加密的 VPN 连接路由，以保护传输中的数据的机密性和完整性。建立 Site-to-Site VPN 连接不需要使用互联网网关。"
    },
    {
        "query":"什么是 IPSec？",
        "intention":"知识问答",
        "reply":"[IPsec](https://en.wikipedia.org/wiki/IPsec) 是一个协议套件，通过身份验证和加密数据流的每个 IP 数据包来保护 Internet 协议 (IP) 通信。"
    },
    {
        "query":"可以使用哪些客户网关设备连接 Amazon VPC？",
        "intention":"知识问答",
        "reply":"您可以创建两种 AWS Site-to-Site VPN 连接：静态路由 VPN 连接，以及动态路由 VPN 连接。支持静态路由 VPN 连接的客户网关设备必须能够：\n使用预共享密钥建立 IKE 安全关联\n以隧道模式建立 IPsec 安全关联\n利用 AES 128 位、256 位、128 位 GCM-16 或 256 位 GCM-16 加密功能\n使用 SHA-1、SHA-2 (256)、SHA2 (384) 或 SHA2 (512) 哈希功能\n在“Group 2”模式下使用 Diffie-Hellman (DH) Perfect Forward Secrecy 或我们支持的某个其他 DH 组\n加密前执行数据包分段\n除了上述功能外，支持动态路由 Site-to-Site VPN 连接的设备还必须能够：\n建立边界网关协议 (BGP) 对\n将隧道绑定到逻辑接口（基于路由的 VPN）\n利用 IPsec 失效对端检测"
    },
    {
        "query":"Amazon 支持哪些 Diffie-Hellman 组？",
        "intention":"知识问答",
        "reply":"我们支持 Phase 1 和 Phase 2 中的以下 Diffie-Hellman (DH) 组。\nPhase 1 DH 组 2、14-24。\nPhase 2 DH 组 2、5、14-24。"
    },
    {
        "query":"当需要更新 IKE 密钥时，AWS 建议使用哪种算法？",
        "intention":"知识问答",
        "reply":"默认情况下，AWS 端的 VPN 终端节点会建议 AES-128、SHA-1 和 DH 组 2。如果您想提出更新密钥的特定建议，建议您使用“修改 VPN 隧道选项”将隧道选项限制为所需的特定 VPN 参数。"
    },
    {
        "query":"哪些客户网关设备已知可以使用 Amazon VPC？",
        "intention":"知识问答",
        "reply":"在网络管理员指南中，您将找到满足上述要求的设备列表，这些设备已知可与硬件 VPN 连接搭配使用，而且命令行工具也支持自动生成适用于设备的配置文件。"
    },
    {
        "query":"如果我的设备不在列表，何处可以找到有关将它用于 Amazon VPC 的更多信息？",
        "intention":"知识问答",
        "reply":"建议您查看 [Amazon VPC 论坛](http://developer.amazonwebservices.com/connect/forum.jspa?forumID=58)，因为其他客户可能已在使用相同的设备。"
    },
    {
        "query":"Site-to-Site VPN 连接的近似最大吞吐量是多少？",
        "intention":"知识问答",
        "reply":"每个 AWS Site-to-Site VPN 连接都有两条隧道，每条隧道支持最高 1.25Gbps 的最大吞吐量。如果您的 VPN 连接到虚拟私有网关，则适用总吞吐量限制。"
    },
    {
        "query":"虚拟私有网关是否有总吞吐量限制？",
        "intention":"知识问答",
        "reply":"虚拟私有网关对每种连接类型都有总吞吐量限制。连接到同一虚拟私有网关的多个 VPN 连接都受从 AWS 到本地最高 1.25Gbps 的总吞吐量限制的约束。对于虚拟私有网关上的 AWS Direct Connect 连接，其吞吐量受 Direct Connect 物理端口本身约束。要连接到多个 VPC 并获得更高的吞吐量限额，请使用 [AWS Transit Gateway](https://aws.amazon.com/transit-gateway)。"
    },
    {
        "query":"哪些因素会影响 VPN 连接的吞吐量？",
        "intention":"知识问答",
        "reply":"VPN 连接的吞吐量取决于多个因素，如客户网关的功能、连接的容量、平均数据包大小、所用的协议（TCP 与UDP）以及客户网关和虚拟私有网关之间的网络延迟。"
    },
    {
        "query":"Site-to-Site VPN 连接每秒最多传输大约多少个数据包？",
        "intention":"知识问答",
        "reply":"每个 AWS Site-to-Site VPN 连接都有两条隧道，每条隧道支持每秒最多传输 140000 个数据包。"
    },
    {
        "query":"有哪些工具可以帮助我对 Site-to-Site VPN 配置进行故障排除？",
        "intention":"知识问答",
        "reply":"DescribeVPNConnection API 可以显示 VPN 连接的状态，包括各个 VPN 隧道的状态（“up”/“down”），并在有隧道处于“down”状态时显示对应的错误消息。AWS 管理控制台中也可显示此类信息。"
    },
    {
        "query":"如何将 VPC 与我的企业数据中心连接？",
        "intention":"知识问答",
        "reply":"在现有网络和 Amazon VPC 之间建立硬件 VPN 连接，以便可以与 VPC 中的 Amazon EC2 实例交互，就像它们位于您的现有网络中一样。在通过硬件 VPN 连接访问 VPC 时，AWS 不会对 Amazon EC2 实例执行[网络地址转换 (NAT)](http://en.wikipedia.org/wiki/Network_address_translation)。"
    },
    {
        "query":"可以对路由器或防火墙后的客户网关进行 NAT 吗？",
        "intention":"知识问答",
        "reply":"使用 NAT 设备的公有 IP 地址。"
    },
    {
        "query":"客户网关地址需要使用哪个 IP 地址？",
        "intention":"知识问答",
        "reply":"使用 NAT 设备的公有 IP 地址。"
    },
    {
        "query":"如何在我的连接上禁用 NAT-T？",
        "intention":"知识问答",
        "reply":"您需要在设备上禁用 NAT-T。如果您不打算使用 NAT-T 且未在设备上禁用它，我们会尝试在 UDP 端口 4500 上建立隧道。如果未开放该端口，则无法建立隧道。"
    },
    {
        "query":"我打算在 NAT 后面部署多个客户网关，该如何配置？",
        "intention":"知识问答",
        "reply":"您需要在设备上禁用 NAT-T。如果您不打算使用 NAT-T 且未在设备上禁用它，我们会尝试在 UDP 端口 4500 上建立隧道。如果未开放该端口，则无法建立隧道。"
    },
    {
        "query":"每条隧道可同时建立多少个 IPsec 安全关联？",
        "intention":"知识问答",
        "reply":"AWS VPN 服务是一种基于路由的解决方案，因此当您使用基于路由的配置时，不存在 SA 数量限制。但是，如果您使用的是基于策略的解决方案，则只能使用一个 SA，因为该服务是基于路由的解决方案。"
    },
    {
        "query":"可否向 Internet 公布我的 VPC 公有 IP 地址范围，并将通过我的数据中心的流量从 Site-to-Site VPN 路由到我的 VPC？",
        "intention":"知识问答",
        "reply":"可以。您可以通过 VPN 连接路由流量，也可从家庭网络公布该地址范围。"
    },
    {
        "query":"我的 VPN 连接最多将向我的客户网关设备公布多少路由？",
        "intention":"知识问答",
        "reply":"您的 VPN 连接最多将向客户网关设备公布 1000 个路由。对于虚拟私有网关上的 VPN，公布的路由源包括 VPC 路由、其他 VPN 路由和来自 DX 虚拟接口的路由。对于 AWS Transit Gateway 上的 VPN，公布的路由来自与 VPN 连接相关的路由表。如果尝试发送的路由超过 1000 个，则仅会公布 1000 个路由子集。"
    },
    {
        "query":"我的客户网关设备最多可向我的 VPN 连接公布多少路由？",
        "intention":"知识问答",
        "reply":"您最多可以从您的客户网关设备向虚拟私有网关上的 Site-to-Site VPN 连接发布 100 条路由，或向 AWS Transit Gateway 上的 Site-to-Site VPN 连接最多发布 1000 条路由。对于包含静态路由的 VPN 连接，您将不能添加超过 100 个静态路由。对于包含 BGP 的 VPN 连接，如果您尝试公布超过网关类型的最大路由数，BGP 会话将会重置。"
    },
    {
        "query":"VPN 连接是否支持 IPv6 流量？",
        "intention":"知识问答",
        "reply":"是。与 AWS Transit Gateway 的 VPN 连接可以支持 IPv4 或 IPv6 流量，您可以在创建新 VPN 连接时进行选择。要选择为 VPN 流量使用 IPv6，请将 Inside IP Version（内部 IP 版本）的 VPN 隧道选项设置为 IPv6。请注意，隧道终端节点和客户网关 IP 地址仅为 IPv4。"
    },
    {
        "query":"VPN 隧道的哪一端会启动互联网密钥交换 (IKE) 会话？",
        "intention":"知识问答",
        "reply":"默认情况下，您的客户网关 (CGW) 必须启动 IKE。或者，AWS VPN 端点可以通过启用适当的选项来启动。"
    },
    {
        "query":"VPN 连接支持私有 IP 地址吗？",
        "intention":"知识问答",
        "reply":"支持。专用 IP 站点到站点 VPN 功能允许您使用私有 IP 地址部署 VPN 连接到 AWS Transit Gateway。私有 IP VPN 在 AWS Direct Connect 中转虚拟接口（VIF）上运行。您可以在创建新的 VPN 连接时选择私有 IP 地址作为您的外部隧道 IP 地址。请注意，隧道端点和客户网关 IP 地址仅为 IPv4。"
    },
    {
        "query":"公有和私有 IP VPN 协议交互之间是否存在差异？",
        "intention":"知识问答",
        "reply":"没有差异，对私有 IP 站点到站点 VPN 连接和公有 IP VPN 连接来说，IPSec 加密与密钥交换的运行方式相同。"
    },
    {
        "query":"我需要为私有 IP VPN 使用 Transit Gateway 吗？",
        "intention":"知识问答",
        "reply":"是的，您需要使用 Transit Gateway 来部署私有 IP VPN 连接。此外，Transit Gateway 上连接的私有 IP VPN 要求使用 Direct Connect 挂载进行传输。您需要指定 Direct Connect 挂载 ID，同时配置 Transit Gateway 的私有 IP VPN 连接。多个私有 IP VPN 连接可使用相同的 Direct Connect 挂载进行传输。"
    },
    {
        "query":"私有 IP VPN 支持静态路由和 BGP 吗？",
        "intention":"知识问答",
        "reply":"是的，私有 IP VPN 支持静态路由和采用 BGP 的动态路由。如果您的客户网关设备支持边界网关协议（BGP），请在配置您的站点到站点 VPN 连接时指定动态路由。若您的客户网关设备不支持 BGP，则指定静态路由。我们建议您使用支持 BGP 的设备（如果可以），因为 BGP 协议提供稳健的活体检测检查，可在第一条隧道发生故障时协助失效转移到第二条 VPN 隧道。"
    },
    {
        "query":"什么是适用于私有 IP VPN 挂载的 Transit Gateway 路由表关联和传播行为？",
        "intention":"知识问答",
        "reply":"适用于私有 IP VPN 挂载的路由表关联和传播行为和任何其他中转网关连接相同。您可以将 Transit Gateway 路由表关联到私有 IP VPN 挂载，并从私有 IP VPN 挂载传播路由到任何 Transit Gateway 路由表。"
    },
    {
        "query":"我可以通过私有 IP VPN 实现多大的吞吐量？",
        "intention":"知识问答",
        "reply":"和正常的站点到站点 VPN 连接一样，每个私有 IP VPN 连接支持 1.25Gbps 带宽。您可以在多个私有 IP VPN 连接中使用 ECMP（等价多路径）来提高有效带宽。例如，要通过私有 IP VPN 发送 10Gbps 的 DX 流量，您可以在 Transit Gateway 和客户网关配对之间使用 4 个已启用 ECMP 的私有 IP VPN 连接（4 个连接 x 2 条隧道 x 1.25Gbps 带宽）。"
    },
    {
        "query":"我可以在私有 IP VPN 和公有 IP VPN 连接之间发送 ECMP 流量吗？",
        "intention":"知识问答",
        "reply":"不可以，您不可以在私有和公有 IP VPN 连接之间发送 ECMP 流量。私有 IP VPN 的 ECMP 仅适用于有私有 IP 地址的 VPN 连接。"
    },
    {
        "query":"私有 IP VPN 的 MTU（最大传输单位）是多少？",
        "intention":"知识问答",
        "reply":"私有 IP VPN 连接支持 1500 字节的 MTU。\n答：私有 IP VPN 可以和不同拥有者账户（而不是 Transit Gateway 账户拥有者）关联吗？\n答：不可以，Transit Gateway 和站点到站点 VPN 连接必须归相同的 AWS 账户所有。"
    },
    {
        "query":"哪些 AWS 区域提供 AWS Site-to-Site VPN 服务和私有 IP VPN 功能？",
        "intention":"知识问答",
        "reply":"除亚太地区（北京）和亚太地区（宁夏）AWS 区域以外，所有商业区域均提供 AWS Site-to-Site VPN 服务。所有提供 AWS Site-to-Site VPN 服务的 AWS 区域都支持私有 IP VPN 功能。"
    },
    {
        "query":"为什么我需要使用 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"VPN 连接面临不一致的可用性和性能，因为流量在到达 AWS 中的 VPN 终端节点之前会通过 Internet 上的多个公共网络。这些公共网络可能会发生拥塞。每个跳转都可能带来可用性和性能风险。Accelerated Site-to-Site VPN 通过使用高度可用且无拥塞的 AWS 全球网络，提高用户体验的一致性。"
    },
    {
        "query":"如何创建 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"创建 VPN 连接时，将选项“启用加速”设置为“True”。"
    },
    {
        "query":"如何确定我现有的 VPN 连接是否为 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"在 VPN 连接的说明中，“启用加速”的值应设置为“True”。"
    },
    {
        "query":"如何将现有的 Site-to-Site VPN 转换为 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"创建新的 Accelerated Site-to-Site VPN，更新您的客户网关设备以连接到此新 VPN 连接，然后删除现有的 VPN 连接。您将获得新的隧道终端节点 Internet 协议 (IP) 地址，因为加速 VPN 使用与非加速 VPN 连接不同的 IP 地址范围。"
    },
    {
        "query":"虚拟网关和 AWS Transit Gateway 是否支持 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"只有 Transit Gateway 支持 Accelerated Site-to-Site VPN。创建 VPN 连接时应指定 Transit Gateway。AWS 端的 VPN 终端节点在 Transit Gateway 上创建。"
    },
    {
        "query":"Accelerated Site-to-Site VPN 连接是否提供两条隧道以实现高可用性？",
        "intention":"知识问答",
        "reply":"是的，每个 VPN 连接都提供两条隧道以实现高可用性。"
    },
    {
        "query":"Accelerated Site-to-Site VPN 和非 Accelerated Site-to-Site VPN 隧道之间是否存在协议差异？",
        "intention":"知识问答",
        "reply":"需要 NAT-T，并且默认情况下为 Accelerated Site-to-Site VPN 连接启用它。另外，Accelerated VPN 和非 Accelerated VPN 隧道支持相同的 IP 安全 (IPSec) 和 Internet 密钥交换 (IKE) 协议，并且还提供相同的带宽、隧道选项、路由选项和身份验证类型。"
    },
    {
        "query":"Accelerated Site-to-Site VPN 是否提供两个网络区域以实现高可用性？",
        "intention":"知识问答",
        "reply":"是的，我们从两个隧道终端节点的独立网络区域中选择 AWS Global Accelerator 全球互联网协议地址 (IP)。"
    },
    {
        "query":"Accelerated Site-to-Site VPN 是否是 AWS Global Accelerator 中的一个选项？",
        "intention":"知识问答",
        "reply":"不是，Accelerated Site-to-Site VPN 只能通过 AWS Site-to-Site VPN 创建。无法通过 AWS Global Accelerator 控制台或 API 创建 Accelerated Site-to-Site VPN。"
    },
    {
        "query":"是否可以在公有 AWS Direct Connect 虚拟接口上使用 Accelerated VPN？",
        "intention":"知识问答",
        "reply":"不能，公有 Direct Connect 虚拟接口上的 Accelerated Site-to-Site VPN 不可用。在大多数情况下，通过公有 Direct Connect 使用 Accelerated Site-to-Site VPN 不会带来加速优势。"
    },
    {
        "query":"哪些 AWS 区域提供 Accelerated Site-to-Site VPN？",
        "intention":"知识问答",
        "reply":"Accelerated Site-to-Site VPN 目前在以下 AWS 区域提供：美国西部（俄勒冈州）、美国西部（北加利福尼亚）、美国东部（俄亥俄州）、美国东部（弗吉尼亚州北部）、南美洲（圣保罗）、中东（巴林）、欧洲地区（斯德哥尔摩）、欧洲地区（巴黎）、欧洲地区（米兰）、欧洲地区（伦敦）、欧洲地区（爱尔兰）、欧洲地区（法兰克福）、加拿大（中部）、亚太地区（东京）、亚太地区（悉尼）、亚太地区（新加坡）、亚太地区（首尔）、亚太地区（孟买）、亚太地区（香港）、非洲（开普敦）。"
    },
    {
        "query":"AWS Site-to-Site VPN 支持哪些日志？",
        "intention":"知识问答",
        "reply":"Site-to-Site VPN 连接日志包括与 IP 安全性（IPsec）隧道建立活动相关的详细信息，包括 Internet 密钥交换（IKE）协商和失效对端检测（DPD）协议消息。这些日志将每隔 5 分钟定期导出一次，并且将会尽量传输到 CloudWatch Logs。"
    },
    {
        "query":"是否会为至 Transit Gateways 和虚拟网关的 VPN 连接提供 Site-to-Site VPN 日志？",
        "intention":"知识问答",
        "reply":"是，您可以为基于 Transit Gateway 和虚拟网关的 VPN 连接启用 Site-to-Site VPN 日志。"
    },
    {
        "query":"能否在现有 VPN 连接上启用 Site-to-Site VPN 日志？",
        "intention":"知识问答",
        "reply":"可以，您可以在创建或修改连接时通过隧道选项启用 Site-to-Site VPN 日志。"
    },
    {
        "query":"为现有 VPN 连接启用 Site-to-Site VPN 日志后将会出现什么情况？",
        "intention":"知识问答",
        "reply":"使用修改隧道选项为现有 VPN 连接启用 Site-to-Site VPN 日志时，通过该隧道的连接将会中断几分钟。每个 VPN 连接都提供两条隧道以实现高可用性。您可以一次在一个隧道上启用日志记录，并且仅会影响修改的隧道。有关更多信息，请参阅《AWS Site-to-Site VPN 用户指南》中的 [Site-to-Site VPN 隧道端点更换](https://docs.aws.amazon.com/vpn/latest/s2svpn/endpoint-replacements.html)。"
    },
    {
        "query":"如何设置 AWS Client VPN？",
        "intention":"知识问答",
        "reply":"IT 管理员创建 Client VPN 终端节点，将目标网络与该终端节点关联，并设置访问策略以允许最终用户连接。IT 管理员将 Client VPN 配置文件分发给最终用户。最终用户需要下载 OpenVPN 客户端并使用 Client VPN 配置文件来创建它们的 VPN 会话。"
    },
    {
        "query":"最终用户应该如何设置连接？",
        "intention":"知识问答",
        "reply":"最终用户应将 OpenVPN 客户端下载到其设备。然后，用户将 AWS Client VPN 配置文件导入到 OpenVPN 客户端并启动 VPN 连接。"
    },
    {
        "query":"如何启用与其他网络的连接？",
        "intention":"知识问答",
        "reply":"您可以连接到其他网络（如对等的 Amazon VPC）、通过虚拟网关连接到本地网络、或通过终端节点连接到 AWS 服务（如 S3）、通过 AWS PrivateLink 连接到网络或通过互联网网关连接其他资源。要启用连接，请在 Client VPN 路由表中添加到特定网络的路由，并添加授权规则以允许访问特定网络。"
    },
    {
        "query":"Client VPN 终端节点是否可以属于与关联子网不同的账户？",
        "intention":"知识问答",
        "reply":"不可以。关联的子网必须与 Client VPN 终端节点位于同一账户中。"
    },
    {
        "query":"是否可以使用私有 IP 地址访问与设置 TLS 会话的区域不同的其他区域中 VPC 的资源？",
        "intention":"知识问答",
        "reply":"您可以通过以下两个步骤实现此目的：首先，在目标 VPC（在不同区域）和 Client VPN 关联 VPC 之间设置跨区域对等连接。第二步，您应该在 Client VPN 终端节点中为目标 VPC 添加路由和访问规则。您的用户现在可以访问与 Client VPN 终端节点所在区域不同的区域中目标 VPC 中的资源。"
    },
    {
        "query":"Client VPN 支持哪些传输协议？",
        "intention":"知识问答",
        "reply":"您可以为 VPN 会话选择 TCP 或 UDP。"
    },
    {
        "query":"AWS Client VPN 是否支持拆分隧道？",
        "intention":"知识问答",
        "reply":"是。您可以选择创建启用或禁用拆分隧道的终端节点。如果以前创建的终端节点禁用了拆分隧道，则可以选择对其进行修改以启用拆分隧道。如果启用了拆分隧道，则去往终端节点上配置的路线的流量将通过 VPN 隧道进行路由。所有其他流量将通过您的本地网络接口路由。如果禁用了拆分隧道，则来自该设备的所有流量都将通过 VPN 隧道。"
    },
    {
        "query":"AWS Client VPN 支持哪些身份验证机制？",
        "intention":"知识问答",
        "reply":"AWS Client VPN 支持使用 AWS Directory Service 和基于证书的身份验证对 Active Directory 进行身份验证，以及使用 SAML-2.0 的联合身份验证。"
    },
    {
        "query":"是否可以使用本地 Active Directory 服务来对用户进行身份验证？",
        "intention":"知识问答",
        "reply":"是。AWS Client VPN 与 AWS Directory Service 集成，让您可以连接到本地 Active Directory。"
    },
    {
        "query":"AWS Client VPN 是否支持相互身份验证？",
        "intention":"知识问答",
        "reply":"是，AWS Client VPN 支持相互身份验证。启用相互身份验证后，客户必须上传用于在服务器上颁发客户端证书的根证书。"
    },
    {
        "query":"是否可以将客户端证书加入黑名单？",
        "intention":"知识问答",
        "reply":"可以，AWS Client VPN 支持静态配置的证书吊销列表 (CRL)。"
    },
    {
        "query":"AWS Client VPN 是否支持客户携带自己的证书？",
        "intention":"知识问答",
        "reply":"是。您应该上传证书、根证书颁发机构 (CA) 证书和服务器的私有密钥。这些文件将上传到 AWS Certificate Manager。"
    },
    {
        "query":"AWS Client VPN 是否与 AWS Certificate Manager (ACM) 集成以生成服务器证书？",
        "intention":"知识问答",
        "reply":"是。可以将 ACM 用作链接到外部根 CA 的从属 CA。ACM 随后生成服务器证书。在此情况下，ACM 还执行服务器证书轮换。"
    },
    {
        "query":"AWS Client VPN 是否支持态势评估？",
        "intention":"知识问答",
        "reply":"不支持。AWS Client VPN 不支持态势评估。其他 AWS 服务（如 Amazon Inspector）则支持态势评估。"
    },
    {
        "query":"AWS Client VPN 是否支持 Multi-Factor Authentication (MFA)？",
        "intention":"知识问答",
        "reply":"支持，AWS Client VPN 支持使用 AWS Directory Service 和通过外部身份提供商（例如，Okta）对 Active Directory 进行 MFA。"
    },
    {
        "query":"AWS Client VPN 如何支持授权？",
        "intention":"知识问答",
        "reply":"您可以配置授权规则，以限制可以访问网络的用户。对于指定的目标网络，您可以配置允许访问的 Active Directory 组/身份提供商组。只有属于此 Active Directory 组/身份提供商组的用户才能访问指定的网络。"
    },
    {
        "query":"AWS Client VPN 是否支持安全组？",
        "intention":"知识问答",
        "reply":"Client VPN 支持安全组。您可以为关联组指定安全组。关联子网时，我们将自动应用子网 VPC 的默认安全组。"
    },
    {
        "query":"如何使用安全组限制仅通过 Client VPN 连接对我的应用程序的访问？",
        "intention":"知识问答",
        "reply":"对于应用程序，可以指定仅允许从应用于关联子网的安全组进行访问。现在，您只能限制通过 Client VPN 连接的用户的访问权限。"
    },
    {
        "query":"在联合身份验证中，我能修改 IDP 元数据文档吗？",
        "intention":"知识问答",
        "reply":"可以，您可以将新的元数据文档上传到与 Client VPN 终端节点关联的 IAM 身份提供商中。更新后的元数据将在 2 到 4 小时内反映出来。"
    },
    {
        "query":"我可以使用第三方 OpenVPN 客户端连接到配置了联合身份验证的 Client VPN 终端节点吗？",
        "intention":"知识问答",
        "reply":"不能，您必须使用 AWS Client VPN 软件客户端连接到此终端节点。"
    },
    {
        "query":"AWS Client VPN 支持哪些日志？",
        "intention":"知识问答",
        "reply":"Client VPN 尽力将连接日志导出到 CloudWatch Logs。这些日志将以 15 分钟的间隔定期导出。连接日志包括有关创建的和终止的连接请求的详细信息。"
    },
    {
        "query":"Client VPN 是否支持终端节点中的 Amazon VPC 流日志？",
        "intention":"知识问答",
        "reply":"不支持。您可以在关联的 VPC 中使用 Amazon VPC 流日志。"
    },
    {
        "query":"我可以监控活动连接吗？",
        "intention":"知识问答",
        "reply":"可以，您可以使用 CLI 或控制台查看终端节点的当前活动连接并终止活动连接。"
    },
    {
        "query":"是否可以使用 CloudWatch 按终端节点进行监控？",
        "intention":"知识问答",
        "reply":"是。使用 CloudWatch 监视器，您可以查看每个 Client VPN 终端节点的入口和出口字节以及活动连接。"
    },
    {
        "query":"如何为 AWS Client VPN 部署免费软件客户端？",
        "intention":"知识问答",
        "reply":"AWS Client VPN 的软件客户端与现有 AWS Client VPN 配置兼容。客户端支持使用由 AWS Client VPN 服务生成的 OpenVPN 配置文件添加配置文件。创建配置文件后，客户端将根据您的设置连接到终端节点。"
    },
    {
        "query":"支持哪些类型的设备和操作系统版本？",
        "intention":"知识问答",
        "reply":"桌面客户端目前支持 64 位 Windows 10、macOS（Mojave、Catalina 和 Big Sur）以及 Ubuntu Linux（18.04 和 20.04）设备。"
    },
    {
        "query":"我的连接配置文件是否会在我的所有设备之间同步？",
        "intention":"知识问答",
        "reply":"否，但 IT 管理员可以提供用于其软件客户端部署的配置文件，以对设置进行预配置。"
    },
    {
        "query":"在我的设备上运行 AWS Client VPN 的软件客户端是否需要管理员权限？",
        "intention":"知识问答",
        "reply":"是。您需要管理员权限才能在 Windows 和 Mac 上安装该应用程序。之后便不需要管理员权限了。"
    },
    {
        "query":"AWS Client VPN 的客户端使用哪种 VPN 协议？",
        "intention":"知识问答",
        "reply":"AWS Client VPN（包括软件客户端）支持 OpenVPN 协议。"
    },
    {
        "query":"该软件客户端是否支持 AWS Client VPN 服务支持的所有功能？",
        "intention":"知识问答",
        "reply":"是。该客户端支持 AWS Client VPN 服务提供的所有功能。"
    },
    {
        "query":"AWS Client VPN 的软件客户端在连接后是否允许局域网访问？",
        "intention":"知识问答",
        "reply":"是，连接到 AWS VPN Client 后，您可以访问局域网。"
    },
    {
        "query":"该软件客户端支持哪些身份验证功能？",
        "intention":"知识问答",
        "reply":"AWS Client VPN 软件客户端支持 AWS Client VPN 服务提供的所有身份验证机制，包括使用 AWS Directory Service 和基于证书的身份验证对 Active Directory 进行身份验证，以及使用 SAML-2.0 的联合身份验证。"
    },
    {
        "query":"AWS Client VPN 支持哪种类型的客户端日志记录？",
        "intention":"知识问答",
        "reply":"当用户尝试连接时，客户端会记录连接设置的详细信息。连接尝试最多保存 30 天，文件大小不超过 90MB。"
    },
    {
        "query":"我可以混合使用 AWS Client VPN 的软件客户端和连接到 AWS Client VPN 终端节点的基于标准的 OpenVPN 客户端吗？",
        "intention":"知识问答",
        "reply":"可以，可假定基于标准的 OpenVPN 客户端支持在 AWS Client VPN 终端节点上定义的身份验证类型。"
    },
    {
        "query":"在哪里可以下载 AWS Client VPN 的软件客户端？",
        "intention":"知识问答",
        "reply":"您可以从 [AWS Client VPN 产品页面](https://aws.amazon.com/cn/vpn/client-vpn-download/)下载通用客户端，无需进行任何自定义。IT 管理员可以选择将下载内容托管到自己的系统中。"
    },
    {
        "query":"可以在一台设备上运行多种类型的 VPN 客户端吗？",
        "intention":"知识问答",
        "reply":"不建议在一台设备上运行多个 VPN 客户端。这可能会造成冲突，或者这些 VPN 客户端可能会相互干扰，导致连接失败。尽管如此，AWS Client VPN 可以与其他 VPN 客户端一起安装在设备上。"
    },
    {
        "query":"这是什么功能？",
        "intention":"知识问答",
        "reply":"对于任何新虚拟网关来说，借助可配置的私有自治系统编号 (ASN)，客户可为 VPN 和 AWS Direct Connect 私有 VIF 在 BGP 会话的 Amazon 端设置 ASN。"
    },
    {
        "query":"如何将要公布的 ASN 配置/分配为 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"您可以在创建新的虚拟私有网关（虚拟网关）期间将某个要公布的 ASN 配置/指定为 Amazon 端 ASN。您可以使用 VPC 控制台或 EC2/CreateVpnGateway API 调用创建虚拟网关。"
    },
    {
        "query":"在推出该功能之前，Amazon 指定了什么 ASN？",
        "intention":"知识问答",
        "reply":"Amazon 指定了以下 ASN：欧洲西部（都柏林）9059；亚太地区（新加坡）17493 和亚太地区（东京）10124。为所有其他区域均指定了 ASN 7224；这些 ASN 被称为区域的“早期公有 ASN”。"
    },
    {
        "query":"能否使用任何 ASN – 公有和私有？",
        "intention":"知识问答",
        "reply":"您可以将任意私有 ASN 分配到 Amazon 端。在 2018 年 6 月 30 日之前，您可以指定区域的“早期公有 ASN”，但不能指定任何其他公有 ASN。2018 年 6 月 30 日之后，Amazon 将提供 ASN 64512。"
    },
    {
        "query":"为什么不能为 BGP 会话的 Amazon 端分配公有 ASN？",
        "intention":"知识问答",
        "reply":"Amazon 不会验证 ASN 的所有权，因此我们将 Amazon 端 ASN 限定为私有 ASN。我们要保护客户免受 BGP 欺诈。"
    },
    {
        "query":"我可以选择什么 ASN？",
        "intention":"知识问答",
        "reply":"您可以选择任何私有 ASN。16 位私有 ASN 的范围是从 64512 到 65534。您还可以提供介于 4200000000 与 4294967294 之间的 32 位 ASN。\n如果您没有选择 ASN，Amazon 将为虚拟网关提供默认 ASN。在 2018 年 6 月 30 日之前，Amazon 将继续提供区域的“早期公有 ASN”。2018 年 6 月 30 日之后，Amazon 将提供 ASN 64512。"
    },
    {
        "query":"如果我尝试为 BGP 会话的 Amazon 端指定公有 ASN，会怎么样？",
        "intention":"知识问答",
        "reply":"一旦您尝试创建虚拟网关，我们就会要求您重新输入私有 ASN，除非它是区域的“早期公有 ASN”。"
    },
    {
        "query":"如果我不为 BGP 会话的 Amazon 端提供 ASN，那么 Amazon 会向我分配什么 ASN？",
        "intention":"知识问答",
        "reply":"如果您没有选择 ASN，Amazon 将为虚拟网关提供一个 ASN。在 2018 年 6 月 30 日之前，Amazon 将继续提供区域的“早期公有 ASN”。2018 年 6 月 30 日之后，Amazon 将提供 ASN 64512。"
    },
    {
        "query":"我可以在哪里查看 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"您可以在 VPC 控制台的虚拟网关页面和 EC2/DescribeVpnGateways API 响应中查看 Amazon 端 ASN。"
    },
    {
        "query":"如果我有公有 ASN，它是否会与 AWS 端的私有 ASN 搭配使用？",
        "intention":"知识问答",
        "reply":"会的。您可以为 BGP 会话的 Amazon 端配置一个私有 ASN，为您的一端配置一个公有 ASN。"
    },
    {
        "query":"我已配置了私有 VIF，并且想要为现有 VIF 上的 BGP 会话设置一个不同的 Amazon 端 ASN。我应如何进行此项更改？",
        "intention":"知识问答",
        "reply":"您需要创建一个具有所需 ASN 的新虚拟网关，然后创建一个连接新创建的虚拟网关的新 VIF。您的设备配置还需要做出相应更改。"
    },
    {
        "query":"我已配置 VPN 连接，并且想要为这些 VPN 的 BGP 会话修改 Amazon 端 ASN。我应如何进行此项更改？",
        "intention":"知识问答",
        "reply":"您将需要创建使用所需 ASN 的新虚拟网关，并在客户网关和新创建的虚拟网关之间重新创建 VPN 连接。"
    },
    {
        "query":"我已使用 Amazon 指定的公有 ASN 7224 配置了虚拟网关和私有 VIF/VPN 连接。如果 Amazon 自动生成用于新私有虚拟网关的 ASN，那么 Amazon 会为我指定什么 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"Amazon 将为用于新虚拟网关连接的 Amazon 端 ASN 指定 64512。"
    },
    {
        "query":"我已使用 Amazon 指定的公有 ASN 配置了虚拟网关和私有 VIF/VPN 连接。我想将 Amazon 指定的同一公有 ASN 用于我创建的新私有 VIF/VPN 连接。应如何操作？",
        "intention":"知识问答",
        "reply":"您可以在创建新的虚拟私有网关（虚拟网关）期间将某个要公布的 ASN 配置/指定为 Amazon 端 ASN。您可以使用控制台或 EC2/CreateVpnGateway API 调用创建虚拟网关。如前文所述，在 2018 年 6 月 30 日之前，Amazon 将继续提供区域的“早期公有 ASN”。2018 年 6 月 30 日之后，Amazon 将提供 ASN 64512。"
    },
    {
        "query":"我已使用 Amazon 指定的公有 ASN 7224 配置了虚拟网关和私有 VIF/VPN 连接。如果 Amazon 使用同一虚拟网关来自动生成用于新私有 VIF/VPN 连接的 ASN，那么 Amazon 会为我指定什么 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"Amazon 将为用于新 VIF/VPN 连接的 Amazon 端 ASN 指定 7224。用于新私有 VIF/VPN 连接的 Amazon 端 ASN 继承的是您现有的虚拟网关并默认为该 ASN。"
    },
    {
        "query":"我向单个虚拟网关连接了多个私有 VIF。每个 VIF 可否拥有单独的 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"不能。您可以为每个虚拟网关分配/配置单独的 Amazon 端 ASN，但不能为每个 VIF 这样做。用于 VIF 的 Amazon 端 ASN 继承的是所连接虚拟网关的 Amazon 端 ASN。"
    },
    {
        "query":"我对单个虚拟网关创建了多个 VPN 连接。每个 VPN 连接可否拥有单独的 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"不可以，您可以为每个虚拟网关而不是每个 VPN 连接指定/配置单独的 Amazon 端 ASN。用于 VPN 连接的 Amazon 端 ASN 继承的是虚拟网关的 Amazon 端 ASN。"
    },
    {
        "query":"我可以在哪里选择我自己的 ASN？",
        "intention":"知识问答",
        "reply":"在 VPC 控制台中创建虚拟网关时，取消选中询问您是否需要自动生成的 Amazon BGP ASN 并在 BGP 会话中为 Amazon 提供您自己的私有 ASN 的框。虚拟网关配置了 Amazon 端 ASN 后，使用虚拟网关创建的私有 VIF 或 VPN 连接将使用您的 Amazon 端 ASN。"
    },
    {
        "query":"我目前使用的是 CloudHub。我日后是不是一定要调整配置？",
        "intention":"知识问答",
        "reply":"您不需要进行任何更改。"
    },
    {
        "query":"我想选择 32 位 ASN。32 位私有 ASN 的范围是什么？",
        "intention":"知识问答",
        "reply":"我们支持介于 4200000000 与 4294967294 之间的 32 位 ASN。"
    },
    {
        "query":"创建了虚拟网关后，我能否更改或修改 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"不能。您不能在创建网关后修改 Amazon 端 ASN。您可以删除虚拟网关，并使用所需的 ASN 重新创建新的虚拟网关。"
    },
    {
        "query":"是否可以为 Amazon 端 ASN 配置/指定新的 API？",
        "intention":"知识问答",
        "reply":"不可以。您可以使用与之前相同的 API (EC2/CreateVpnGateway) 执行该操作。我们刚向该 API 添加了新的参数 (amazonSideAsn)。"
    },
    {
        "query":"是否可以使用新的 API 来查看 Amazon 端 ASN？",
        "intention":"知识问答",
        "reply":"您可以使用相同的 EC2/DescribeVpnGateways API 来查看 Amazon 端 ASN。我们刚向该 API 添加了新的参数（amazonSideAsn）。"
    },
    {
        "query":"我可以使用哪些 ASN 来配置我的客户网关（CGW）？",
        "intention":"知识问答",
        "reply":"除非注明不可使用，否则您可以使用介于 1 – 2147483647 范围之间的 ASN。请参阅《AWS VPN 用户指南》的[AWS Site-to-Site VPN 连接的客户网关选项](https://docs.aws.amazon.com/vpn/latest/s2svpn/cgw-options.html)部分。     \n   \n 问：我想对我的客户网关使用 32 位 ASN。支持 32 位私有范围 ASN 吗？\n答：支持。请注意，客户网关配置当前不支持介于 4200000000 到 4294967294 范围之间的私有 ASN。 请参阅《AWS VPN 用户指南》的 [AWS Site-to-Site VPN 连接的客户网关选项](https://docs.aws.amazon.com/vpn/latest/s2svpn/cgw-options.html)部分。"
    },
    {
        "query":"什么是 AWS IoT SiteWise？",
        "intention":"知识问答",
        "reply":"AWS IoT SiteWise 是一项托管式服务，使工业企业能够跨多个工业设施收集、存储、组织和可视化数千个传感器数据流。AWS IoT SiteWise 包含运行在设施内网关设备上的软件，可持续从历史数据源或专门的工业服务器收集数据，并将其发送到云。数据也可以通过 AWS IoT Core（通过 MQTT 协议或使用 REST API）提取至 AWS IoT SiteWise。借助 AWS IoT SiteWise，您可以跳过耗费数月开发无差异数据收集和编目解决方案这个过程。相反，您可以专注于使用数据来检测和解决设备问题，查找效率低下现象并提升生产输出。"
    },
    {
        "query":"为什么要使用 AWS IoT SiteWise？",
        "intention":"知识问答",
        "reply":"借助 AWS IoT SiteWise，您可以轻松收集设备数据并进行深入分析，以减少工业运营中常见的浪费。您可以按设备来构建传感器数据，以便识别与检索数据。AWS IoT SiteWise 还可以计算您指定的设备与流程性能指标。这些指标可以帮助您识别各种类型的浪费，例如设备问题、生产差距与质量瑕疵。利用 SiteWise Edge 软件，您还可以在本地使用这些功能，这样即使与云端的连接临时中断，仍可以近乎实时的方式对工厂车间的数据进行可视化，并为本地应用程序提供支持。\n具体而言，AWS IoT SiteWise 还可以让您：  \n 了解和改善单个工业场地或跨多个设施的流程。减少浪费通常要求计算设备数据指标来跟踪各种业务目标。借助 AWS IoT SiteWise，工业工程师可以按生产线来对传感器数据流进行分组，并将生产线按设施分组。公司总部的分析师可以跨所有设施轻松查询传感器数据。借助 AWS IoT SiteWise，您可以创建一个按整个组织范围内所使用的设备与流程来组织的权威数据源。\n了解并高效解决设备问题。工业工程师需要性能指标来查明实体设备的问题。借助 AWS IoT SiteWise，工程技术员可以远程了解每台风力发电机和太阳能发电机的状况，并分配正确的资源以更快地解决问题。这使得工程师有更多的时间专注于他们的核心工作，即理解和设计更好的系统，而不是协调现场操作问题。使用 SiteWise Edge，您不但可以在本地计算这些性能指标，而且还可将其用于现场运行的本地应用程序。\n借助 SiteWise Monitor 功能可视化设备与装置的操作数据。无需编写代码，即可创建一个完全托管的 Web 应用程序，用于可视化来自连接到 AWS IoT 的设备和装置的操作数据并与之交互。自动发现和可视化已经被 AWS IoT SiteWise 提取和建模的资产数据。您可以查看当前数据值、查看资产数据的实时趋势图表，以及查看用户定义时间段内的历史时间序列资产数据图。即使与互联网临时断开，您仍可以使用 SiteWise Edge 在本地访问这些 Web 应用程序。"
    },
    {
        "query":"使用 SiteWise Monitor 有什么先决条件？",
        "intention":"知识问答",
        "reply":"在使用 SiteWise Monitor Web 应用程序之前，必须先配置好您的边缘设备与装置以发送数据至 AWS IoT SiteWise。如果边缘数据存储在本地历史数据源，则 AWS IoT SiteWise 软件可以在边缘网关上运行以传送数据到 AWS。如果使用 MQTT 协议传送边缘数据到 AWS IoT Core，则必须选择 AWS IoT SiteWise 作为“规则引擎”中的目标终端节点。数据流入 AWS 后，必须在 AWS IoT SiteWise 中创建边缘设备与装置的数字模型。最后，您还必须将提取到 AWS IoT SiteWise 的装置数据链接到创建的资产模型，并将代表实际边缘设备与装置的模型实例化。SiteWise Monitor 使用 AWS IAM Identity Center（AWS SSO 的后继者）让用户能够使用他们的企业身份登录。要启用此功能，您必须在 IAM Identity Center 内关联您的企业身份提供商。"
    },
    {
        "query":"如何设置 SiteWise Monitor？",
        "intention":"知识问答",
        "reply":"若要创建一个 Web 应用程序，管理员用户必须登录 AWS 管理控制台并打开 AWS IoT SiteWise 控制台。随后导航至 AWS IoT SiteWise Monitor 菜单下的 Getting Started（开始使用）页。Getting Started（开始使用）页通过简单的分步骤工作流程来引导管理员 1/ 创建一个 Web 门户，2/ 配置一个用于单点登录的活动目录，3/ 选择用户作为 Web 门户的管理员以及 4/ 添加有权访问 Web 网站的用户。"
    },
    {
        "query":"如何保证 SiteWise Monitor 内的操作数据的安全？",
        "intention":"知识问答",
        "reply":"SiteWise Monitor Web 应用程序用户基于其企业身份凭证或 AWS IAM Identity Center（AWS SSO 的后继者）内设置的内置用户凭证来完成身份验证。管理员可以设置哪些资产与资产数据可以通过 Web 应用程序来访问，哪些用户可以获得授权使用该 Web 应用程序。"
    },
    {
        "query":"在提取数据以后，我能够以多快速度开始进行可视化？",
        "intention":"知识问答",
        "reply":"AWS IoT SiteWise 提供创建无代码、完全托管 Web 应用程序的能力，它们会使用 SiteWise Monitor 对来自连接到 AWS IoT 的装置和设备的运营数据进行可视化并与其交互。使用 SiteWise Monitor，您可以近乎实时地查看资产数据与计算数据。要启用此近乎实时对您的数据进行可视化的功能，AWS IoT SiteWise 会自动计算常用的统计聚合，如平均值、总和以及一组时间段的计数。这些自动计算的聚合会被存储在时间序列数据存储当中，并支持通过自定义应用程序进行查询。"
    },
    {
        "query":"如何使用 AWS IoT SiteWise 中的资产以虚拟方式表示我的工业设备？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS IoT SiteWise 中的资产创建您的工业设备或流程的虚拟表示。一项资产代表一台装置、一件设备，或将一条或更多数据流上传到云的一个流程。例如，一台风力涡轮机可以发送空气温度、推进器旋转速度和电力输出时间序列测量数据至其在 AWS IoT SiteWise 中的对应资产。您可以使用数学表达式配置资产，以便转换传入的测量数据，如将温度数据从摄氏度转换为华氏度。 您还可以在用户指定的时间间隔里为您的资产数据定义指标。一项资产可被扩展，以代表设备的逻辑分组，如整座风力发电厂。您可以将资产关联到其他资产，从而创建资产层次结构来表示复杂的工业运营。此类资产可以访问其关联子资产中的数据，因此您可以计算聚合指标，如风力发电厂的净电力输出。"
    },
    {
        "query":"如何使用 SiteWise Edge？",
        "intention":"知识问答",
        "reply":"您可以从 AWS IoT SiteWise 控制台下载 SiteWise Edge 软件，并将其安装到本地硬件上，例如支持 Linux 操作系统的第三方工业计算机或网关。或者，您也可以在 [AWS Outposts](https://aws.amazon.com/cn/outposts/) 或 [AWS Snow](https://aws.amazon.com/cn/snowcone/) 系列计算设备上安装 SiteWise Edge 软件。然后，您可以使用云中的 AWS IoT SiteWise 控制台配置 SiteWise Edge 软件运行时功能。您可以使用控制台，从已建模的可用设备列表中选择数据源，如风力涡轮机上的推进器旋转速度传感器或空气温度传感器。然后，您可以从预定义功能列表中进行选择，以便对数据进行采样，计算常见性能指标（例如，整体设备效率），或者定义自己的自定义功能来处理数据。然后，您可以进行配置，以便将数据发送至云中的 AWS IoT SiteWise，或从其他云目标（如 Amazon S3 和 Amazon Timestream）中进行选择。映射数据流后，您便可以通过配置 SiteWise Monitor Web 应用程序来配置如何可视化数据和计算的指标。最后，只需单击一下，即可将所有这些配置设置复制并部署到在本地网关上运行的 SiteWise Edge 软件中。为简化跨边缘和云的部署，SiteWise Edge 在本地提供了与云中相同的 SiteWise 查询 API。为流程工程师和操作人员构建的本地应用程序可以使用这些 API，读取本地网关中近乎实时的数据和指标。"
    },
    {
        "query":"哪些操作系统支持 SiteWise Edge？",
        "intention":"知识问答",
        "reply":"目前运行 Linux 操作系统的设备支持 SiteWise Edge。"
    },
    {
        "query":"哪些硬件支持 SiteWise Edge？",
        "intention":"知识问答",
        "reply":"SiteWise Edge 可以安装在第三方工业网关和计算机、AWS Outposts 以及 AWS Snow 系列计算设备上。"
    },
    {
        "query":"运行 SiteWise Edge 软件的最低硬件要求是什么？",
        "intention":"知识问答",
        "reply":"硬件必须是符合 AWS IoT Greengrass 条件的设备，其最低技术规格包括 4 核 CPU、16GB 的 RAM 和 256GB 的可用磁盘空间。"
    },
    {
        "query":"数据在边缘网关上可以保留多长时间？",
        "intention":"知识问答",
        "reply":"数据可以在边缘网关上保留最多 30 天（可能根据允许的磁盘空间变化）。"
    },
    {
        "query":"如何将我的设备数据摄取到 AWS IoT SiteWise？",
        "intention":"知识问答",
        "reply":"AWS IoT SiteWise 为您提供多种收集设备数据的方式。第一种，您可以在常用的第三方工业计算机和网关或 AWS Outposts 和 AWS Snow 系列计算设备上运行 SiteWise Edge 软件，也可以使用 Modbus TCP 和 EtherNet/IP 等协议从设备中读取数据，或从 OPC-UA 聚合器和历史数据库中读取数据，以便每秒上传数千个数据流。 在发生远程设施常见的间歇互联网连接时，网关可以在本地缓存数据。第二种，AWS IoT SiteWise 通过和 AWS IoT Core 的集成支持 MQTT 数据摄入。您可以使用 AWS IoT 消息代理订阅从您的工业设备发布消息的主题，然后通过 AWS IoT Core 规则引擎将消息路由至 AWS IoT SiteWise。最后，您还可以使用 AWS 软件开发工具包从任何自定义边缘或云应用程序发送数据。"
    },
    {
        "query":"如何在我的自定义应用程序中使用 AWS IoT SiteWise 数据？",
        "intention":"知识问答",
        "reply":"AWS IoT SiteWise 为您提供两种在自定义云应用程序中使用您的设备和计算数据的方式。第一种，您可以使用 Property Notifications（属性通知），以 MQTT 消息的方式发布结构化物联网数据流。您的应用程序可以订阅 MQTT 主题，并在您的设备和计算数据送达时开始接收消息。您可以在个别资产数据层级对这些通知进行配置，从而选择您的应用程序要接收哪些数据。第二种，您可以使用 AWS 软件开发工具包中的 AWS IoT SiteWise 查询 API 来检索实时和历史数据，以及计算的转换和指标。对于自定义边缘应用程序，您可以使用与本地运行的 SiteWise Edge 软件相同的 AWS IoT SiteWise 查询 API 来检索实时和历史数据，以及任何资产属性的计算转换和指标。"
    },
    {
        "query":"如何将 AWS IoT SiteWise 与 Grafana 一起使用？",
        "intention":"知识问答",
        "reply":"借助 Grafana 的 AWS IoT SiteWise 插件，您可以使用 Grafana 控制面板中广泛的可视化选项，以近乎实时的方式可视化和监控来自 AWS IoT SiteWise 的设备数据和指标。您还可以轻松组合来自多个来源（例如 AWS IoT SiteWise、Amazon Timestream、Amazon CloudWatch）的数据，并使用一个 Grafana 控制面板监控它们。有关更多信息，请参阅[文档](https://docs.aws.amazon.com/iot-sitewise/latest/userguide/grafana-integration.html)。请参阅下面的 Grafana 控制面板屏幕截图示例。"
    },
    {
        "query":"AWS IoT SiteWise 是否支持 AWS CloudFormation？",
        "intention":"知识问答",
        "reply":"支持。您可以创作 [AWS CloudFormation](https://aws.amazon.com/cn/cloudformation/) 模板，以自动创建和管理用于数据摄取和资产建模的 AWS IoT SiteWise 资源，而无需通过 AWS IoT SiteWise 控制台手动预置资源或编写自定义脚本。您还可以跨账户和区域重复使用这些模板，以确保一致性。"
    },
    {
        "query":"什么是部署生命周期事件？ 部署会经过一组预定义阶段，称为部署生命周期事件。部署生命周期事件可让您将代码作为部署的一部分运行。下表以执行顺序列出了目前支持的各种不同的部署生命周期事件，以及您可能想使用它们的时间示例。",
        "intention":"知识问答",
        "reply":"|  |  |\n| --- | --- |\n| 部署生命周期事件 | 描述 |\n| ApplicationStop | 这是第一个部署生命周期事件，发生在下载完成修订版之前。用于此部署生命周期事件的 AppSpec 文件和脚本来自于上一次成功部署的修订版。   如果您想从容地停止应用程序或删除部署准备中当前已安装的软件包，您可以使用 ApplicationStop 部署生命周期事件。 |\n| DownloadBundle | 在此部署生命周期事件期间，代理程序会将修订版文件复制到实例上的临时位置。此部署生命周期事件是为代理程序预留的，不能用于运行用户脚本。 |\n| BeforeInstall | 您可以使用 BeforeInstall 部署生命周期事件执行预安装任务，如解密文件和创建当前版本的备份。 |\n| 安装 | 在此部署生命周期事件期间，代理程序会将修订版文件从临时位置复制到最终目标文件夹中。此部署生命周期事件是为代理程序预留的，不能用于运行用户脚本。 |\n| AfterInstall | 您可以使用 AfterInstall 部署生命周期事件执行应用程序配置或文件权限更改等任务。 |\n| ApplicationStart | 您一般使用 ApplicationStart 部署生命周期事件重新启动在 ApplicationStop 期间停止的服务。 |\n| ValidateService | ValidateService 是最后一个部署生命周期事件，为您提供机会来验证部署是否已成功完成。 |\n这是第一个部署生命周期事件，发生在下载完成修订版之前。用于此部署生命周期事件的 AppSpec 文件和脚本来自于上一次成功部署的修订版。\n如果您想从容地停止应用程序或删除部署准备中当前已安装的软件包，您可以使用 ApplicationStop 部署生命周期事件。"
    },
    {
        "query":"什么是 Amazon GuardDuty？",
        "intention":"知识问答",
        "reply":"GuardDuty 是一种智能威胁检测服务，可持续监测您的 AWS 账户、Amazon Elastic Compute Cloud (Amazon EC2) 实例、AWS Lambda 函数、Amazon Elastic Kubernetes Service (Amazon EKS) 集群、Amazon Aurora 登录活动以及存储在 Amazon Simple Storage Service (Amazon S3) 中的数据是否存在恶意活动。如果检测到潜在恶意活动，例如异常行为、凭证泄漏或命令和控制基础设施 (C2) 通信，GuardDuty 将会生成详细的安全检测结果，可用于获得安全可见性并协助进行修复。此外，使用 Amazon GuardDuty 恶意软件防护功能还有助于检测挂载到 Amazon EC2 实例和容器工作负载的 Amazon Elastic Block Store (Amazon EBS) 卷上的恶意文件。"
    },
    {
        "query":"GuardDuty 的主要优势有哪些？",
        "intention":"知识问答",
        "reply":"借助 GuardDuty，可以轻松实现对 AWS 账户、工作负载和 Amazon S3 中存储的数据的持续监控。GuardDuty 的基础级别设计为完全独立于您的资源运行，并且不会对您的工作负载产生性能或可用性影响。该服务完全托管，集成了威胁情报、机器学习 (ML) 异常检测和恶意软件扫描。GuardDuty 提供的警报内容详细，可行动性强，适合与现有的事件管理和工作流程系统集成。您无需预付任何费用，只需为分析的事件付费，不需要部署额外的软件，也不需要订阅威胁情报源。"
    },
    {
        "query":"是否可以免费试用 GuardDuty？",
        "intention":"知识问答",
        "reply":"可以，GuardDuty 新账户均可以免费试用此服务 30 天。免费试用期间，您可以使用所有的功能和检测服务。在免费试用期间，您可以在 [GuardDuty 控制台](https://docs.aws.amazon.com/guardduty/latest/ug/monitoring_costs.html)使用情况页面查看试用结束后的成本估计。如果是 GuardDuty 管理员，您将可查看自己的成员账户的估计成本。在 30 天以后，您可以前往 AWS Billing Console 查看此功能的实际成本。"
    },
    {
        "query":"GuardDuty 和 Amazon Macie 有什么不同之处？",
        "intention":"知识问答",
        "reply":"GuardDuty 可对您的 AWS 账户、工作负载和数据进行广泛的安全监测，以帮助识别威胁，例如攻击者侦察；实例、账户、桶或 Amazon EKS 集群盗用；以及恶意软件。[Macie](https://aws.amazon.com/cn/macie/) 是一种完全托管的敏感数据发现服务，使用 ML 和模式匹配来发现 Amazon S3 中的敏感数据。"
    },
    {
        "query":"GuardDuty 是区域性服务还是全球性服务？",
        "intention":"知识问答",
        "reply":"GuardDuty 是一种区域性服务。即使启用多个账户并使用多个区域，GuardDuty 的安全检测结果仍然保存在生成底层数据的区域。这样可以确保分析的所有数据以区域为基础，且不会跨越 AWS 区域边界。但是，您可以选择使用 Amazon EventBridge 或将检测结果推送到自己的数据存储（例如 Amazon S3）中，然后在您认为合适时将这些检测结果进行聚合，从而聚合 GuardDuty 在各个区域生成的安全检测结果。您还可以将 GuardDuty 检测结果发送到 AWS Security Hub 并使用其[跨区域聚合](https://docs.aws.amazon.com/securityhub/latest/userguide/finding-aggregation.html)功能。"
    },
    {
        "query":"GuardDuty 支持哪些区域？",
        "intention":"知识问答",
        "reply":"[AWS 区域性服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)中列出了 GuardDuty 区域可用性。"
    },
    {
        "query":"哪些合作伙伴使用 GuardDuty？",
        "intention":"知识问答",
        "reply":"很多技术合作伙伴已集成 GuardDuty 并将其用作构建基础。还有很多拥有关于 GuardDuty 的专业知识的咨询机构、系统集成商和托管安全服务提供商。有关详细信息，请参阅 [Amazon GuardDuty 合作伙伴](https://aws.amazon.com/cn/guardduty/resources/partners/)页面。"
    },
    {
        "query":"GuardDuty 是否有助于满足支付卡行业数据安全标准（PCI DSS）要求？",
        "intention":"知识问答",
        "reply":"Foregenix 发布的[白皮书](https://d1.awsstatic.com/certifications/foregenix_amazon_guardduty_security_review_07-2020.pdf)详细评估了 GuardDuty 帮助满足合规性要求的有效性，例如 PCI DSS 要求 11.4，它要求在网络中的关键点使用入侵检测技术。"
    },
    {
        "query":"如何启用 GuardDuty？",
        "intention":"知识问答",
        "reply":"只需在 AWS 管理控制台中单击几次，即可设置和部署 GuardDuty。启用后，GuardDuty 会立即以近乎实时的方式开始大规模分析持续的账户和网络活动流。无需部署或管理额外的安全软件、传感器或网络设备。该服务预先集成了将会持续更新和维护的威胁情报。"
    },
    {
        "query":"可以使用 GuardDuty 管理多个账户吗？",
        "intention":"知识问答",
        "reply":"可以，GuardDuty 拥有多账户管理功能，允许您从单个管理员账户关联并管理多个 AWS 账户。使用该功能后，系统会将所有安全检测结果聚合到管理员账户，供用户查看并采取修复措施。使用此配置时，Amazon EventBridge 也会聚合到 GuardDuty 管理员账户中。此外，GuardDuty 还与 [AWS Organizations](https://aws.amazon.com/cn/organizations/) 集成，允许您为贵组织委派 GuardDuty 管理员账户。委派管理员（DA）账户是一个集中账户，合并所有结果并能配置所有成员账户。"
    },
    {
        "query":"GuardDuty 分析哪些数据来源？",
        "intention":"知识问答",
        "reply":"GuardDuty 分析的[基础数据来源](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_data-sources.html)包括：AWS CloudTrail 管理事件日志、CloudTrail 管理事件以及 Amazon EC2 VPC 流日志和 DNS 查询日志。可选的 GuardDuty 保护计划可监控其他资源类型，包括 CloudTrail S3 数据事件 (S3 Protection)、Amazon EKS 审核日志和运行时系统活动 (EKS Protection)、Amazon EBS 批量数据（恶意软件防护）、Amazon Aurora 登录事件 (RDS Protection) 和网络活动日志 (Lambda Protection)。该服务经过优化，可以使用大量数据近乎实时地执行安全检测。GuardDuty 使您可以访问专门针对云服务开发和优化的内置检测技术，该数据由 GuardDuty 工程团队维护和不断改进。"
    },
    {
        "query":"GuardDuty 的运行速度如何？",
        "intention":"知识问答",
        "reply":"启用之后，GuardDuty 就开始分析是否存在恶意活动或未经授权的活动。收到检测结果的时间取决于您账户中的活动级别。GuardDuty 不分析历史数据，只分析在其启用后开始的活动。如果 GuardDuty 识别出潜在威胁，您将在 GuardDuty 控制台中收到检测结果。"
    },
    {
        "query":"要使 GuardDuty 正常运行，必须启用 CloudTrail、VPC 流日志、DNS 查询日志或 Amazon EKS 审计日志吗？",
        "intention":"知识问答",
        "reply":"不，GuardDuty 直接从 CloudTrail、VPC 流日志、DNS 查询日志和 Amazon EKS 中提取独立的数据流。您不需要管理 Amazon S3 存储桶策略，也不需要修改收集和存储日志的方式。GuardDuty 权限作为与服务关联的角色管理。您可以随时禁用 GuardDuty，那样将会删除所有 GuardDuty 权限。这使得您可以更轻松地启用该服务，因为避免了复杂的配置。与服务关联的角色也消除了 AWS Identity and Access Management (IAM) 权限错误配置或 Amazon S3 存储桶策略变更影响服务运行的几率。最后，与服务关联的角色使 GuardDuty 能够近乎实时地高效使用大量数据，并且几乎甚至完全不影响您的账户或工作负载的性能和可用性。"
    },
    {
        "query":"在我的账户中启用 GuardDuty 会对性能或可用性产生影响吗？",
        "intention":"知识问答",
        "reply":"当您首次启用 GuardDuty 时，它完全独立于您的 AWS 资源运行。如果您将 GuardDuty EKS 运行时系统监控配置为自动部署 GuardDuty 安全代理，这可能会导致资源使用率增加，还会在用于运行 Amazon EKS 集群的 VPC 中创建 VPC 端点。"
    },
    {
        "query":"GuardDuty 会管理或保存我的日志吗？",
        "intention":"知识问答",
        "reply":"不，GuardDuty 不会管理或保留您的日志。GuardDuty 使用的所有数据都会被近乎实时地分析，然后丢弃。这让 GuardDuty 不仅经济、高效，还能降低数据残留的风险。如需传输和保存日志，您应该直接使用 AWS 的日志记录和监控服务，这些服务可以提供功能全面的传输和保存选项。"
    },
    {
        "query":"怎样阻止 GuardDuty 分析我的日志和数据来源？",
        "intention":"知识问答",
        "reply":"您可以随时在常规设置中选择暂停该服务，以阻止 GuardDuty 分析您的数据来源。这样会让该服务立即停止分析数据，但不会删除您的现有检测结果或配置。您也可以在常规设置中选择禁用该服务。这样会删除包括现有检测结果和配置在内的所有剩余数据，然后撤销该服务的权限并重置该服务。您还可以通过管理控制台或通过 AWS CLI 选择性地禁用一些功能，例如 GuardDuty S3 Protection 或 GuardDuty EKS Protection。"
    },
    {
        "query":"GuardDuty 可以检测哪些风险？",
        "intention":"知识问答",
        "reply":"GuardDuty 让您可以访问专门针对云服务开发和优化的内置检测技术。其检测算法由 GuardDuty 工程师进行维护和不断改进。主要检测类别包括以下各项："
    },
    {
        "query":"什么是 GuardDuty 威胁情报？",
        "intention":"知识问答",
        "reply":"GuardDuty 威胁情报由确定攻击者会使用的 IP 地址和域组成。GuardDuty 威胁情报由 AWS 以及 Proofpoint 和 CrowdStrike 等第三方提供商提供。这些威胁情报馈送数据已预先集成到 GuardDuty 中，并会免费持续更新。"
    },
    {
        "query":"可以提供我自己的威胁情报吗？",
        "intention":"知识问答",
        "reply":"可以，GuardDuty 允许您上传自己的威胁情报或[可信 IP 地址列表](https://aws.amazon.com/cn/premiumsupport/knowledge-center/guardduty-trusted-ip-list/)。使用该功能时，您上传的安全列表仅适用于您的账户，不与其他客户共享。"
    },
    {
        "query":"安全检测结果是如何传输的？",
        "intention":"知识问答",
        "reply":"如果检测到潜在威胁，GuardDuty 会向 GuardDuty 控制台和 EventBridge 发送详细的安全检测结果。这使警报更有可操作性，并能与现有的事件管理或工作流程系统更轻松地集成。检测结果包括类别、受影响的资源以及与该资源相关的元数据，例如严重程度。"
    },
    {
        "query":"GuardDuty 检测结果采用什么格式？",
        "intention":"知识问答",
        "reply":"GuardDuty 检测结果采用常见的 JavaScript 对象表示法（JSON）格式，Macie 和 Amazon Inspector 采用的也是这种格式。客户和合作伙伴可以更轻松地利用这三项服务的安全检测结果，并将其纳入更广泛的事件管理、工作流程或安全解决方案中。"
    },
    {
        "query":"安全检测结果在 GuardDuty 中的保存时间是多久？",
        "intention":"知识问答",
        "reply":"安全检测结果在 GuardDuty 控制台和 API 中的保留时间是 90 天。90 天后，系统会丢弃检测结果。要在 90 天后继续保留检测结果，您可以启用 EventBridge 将检测结果自动推送到您账户的 Amazon S3 存储桶或其他数据存储中进行长期保留。"
    },
    {
        "query":"我可以汇总 GuardDuty 结果吗？",
        "intention":"知识问答",
        "reply":"可以，您可以选择使用 EventBridge 或将检测结果推送到自己的数据存储（例如 Amazon S3）中，然后在您认为合适时将这些检测结果进行聚合，从而聚合 GuardDuty 在各个区域生成的安全检测结果。您还可以将 GuardDuty 检测结果发送到 Security Hub 并使用其[跨区域聚合](https://docs.aws.amazon.com/securityhub/latest/userguide/finding-aggregation.html)功能。"
    },
    {
        "query":"GuardDuty 支持自动预防措施吗？",
        "intention":"知识问答",
        "reply":"借助 GuardDuty、EventBridge 和 AWS Lambda，您可以根据安全检测结果灵活设置自动修复措施。例如，您可以创建一个 Lambda 函数，使其根据安全检测结果来修改 AWS 安全组规则。如果 GuardDuty 检测结果表明已知的恶意 IP 正在探测您的 Amazon EC2 实例之一，您可以利用 EventBridge 规则来发起一个 Lambda 函数，以便自动修改您的安全组规则并限制对相应端口的访问，从而解决这个问题。"
    },
    {
        "query":"GuardDuty 检测功能是如何开发和管理的？",
        "intention":"知识问答",
        "reply":"有专门的团队负责 GuardDuty 检测功能的工程、管理和迭代。这样可以保证新检测功能的定期更新以及现有检测功能的持续迭代。该服务内置了一些反馈机制，例如 GuardDuty 用户界面（UI）中每条安全检测结果都附带表示认可或否定的选项。这让您能够提供反馈，以便纳入以后的 GuardDuty 检测功能中。"
    },
    {
        "query":"可以在 Amazon GuardDuty 中编写自定义检测功能吗？",
        "intention":"知识问答",
        "reply":"不能，GuardDuty 让您摆脱了开发和维护自己的自定义规则带来的沉重负担和复杂性。我们会根据客户的反馈以及 AWS 安全工程师和 GuardDuty 工程团队的研究结果，持续增加新的检测功能。但是，客户配置的自定义选项包括添加您自己的[威胁列表和可信 IP 地址列表](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_upload-lists.html)。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，如何开始使用 S3 Protection？",
        "intention":"知识问答",
        "reply":"对于当前 GuardDuty 账户，可以在 S3 Protection 页面的控制台中激活 S3 Protection，也可以通过 API 激活。这将开始 30 天的 GuardDuty S3 Protection 功能免费试用。"
    },
    {
        "query":"是否可以免费试用 GuardDuty S3 Protection？",
        "intention":"知识问答",
        "reply":"是的，您可以免费试用 30 天。每个区域中的每个账户均可获得 GuardDuty 的 30 天免费试用，包括 S3 Protection 功能。已启用 GuardDuty 的账户在首次激活 S3 Protection 功能时，也将获得 30 天的免费试用期。"
    },
    {
        "query":"如果我是 GuardDuty 的新用户，默认情况下我的账户是否启用了 S3 Protection？",
        "intention":"知识问答",
        "reply":"是。默认情况下，通过控制台或 API 启用 GuardDuty 的任何新账户也将启用 S3 Protection。使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户不会打开 S3 Protection，除非打开了“S3 自动启用”选项。"
    },
    {
        "query":"是否可以在不启用完整 GuardDuty 服务（包括 VPC 流日志、DNS 查询日志和 CloudTrail 管理事件分析）的情况下使用 GuardDuty S3 Protection？",
        "intention":"知识问答",
        "reply":"不能，必须启用 GuardDuty 服务才能使用 S3 Protection。当前的 GuardDuty 账户有用于启用 S3 Protection 的选项，新 GuardDuty 账户在启用 GuardDuty 服务后即默认拥有该功能。"
    },
    {
        "query":"GuardDuty 是否会监控账户中的所有存储桶以帮助保护我的 Amazon S3 部署？",
        "intention":"知识问答",
        "reply":"是的，默认情况下，S3 Protection 会监控环境中的所有 Amazon S3 存储桶。"
    },
    {
        "query":"是否需要为 S3 Protection 打开 CloudTrail S3 数据事件日志记录？",
        "intention":"知识问答",
        "reply":"不，GuardDuty 可以直接访问 CloudTrail S3 数据事件日志。您不需要在 CloudTrail 中启用 S3 数据事件日志记录，因此将不会产生相关的成本。请注意，GuardDuty 不会存储日志，仅会将其用于分析。"
    },
    {
        "query":"GuardDuty EKS Protection 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"GuardDuty EKS Protection 是一种 GuardDuty 功能，通过分析 [Amazon EKS 审计日志](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html)监控 Amazon EKS 集群控制面板活动。GuardDuty 与 Amazon EKS 集成，可直接访问 Amazon EKS 审计日志，而无需您打开或存储这些日志。这些审计日志是与安全相关的时间顺序记录，它们记录在 Amazon EKS 控制面板上执行的操作顺序。此类 Amazon EKS 审计日志为 GuardDuty 提供所需的可见性，以持续监控 Amazon EKS API 活动并应用经过验证的威胁情报和异常检测来识别可能使您的 Amazon EKS 集群遭未经授权访问的恶意活动或配置更改。当发现威胁时，GuardDuty 会生成安全结果，其中包括威胁类型、严重程度和容器级详细信息（例如，容器组 ID、容器映像 ID 和相关标签）。"
    },
    {
        "query":"GuardDuty EKS Protection 可在我的 Amazon EKS 工作负载上检测到哪些威胁类型？",
        "intention":"知识问答",
        "reply":"GuardDuty EKS Protection 可以检测与 Amazon EKS 审计日志中捕获的用户和应用程序相关的威胁。Amazon EKS 威胁检测包括由已知恶意攻击者访问或者来自 Tor 节点、由可能指示错误配置的匿名用户执行的 API 操作以及可能导致未授权访问 Amazon EKS 集群的错误配置的 Amazon EKS 集群。此外，通过使用 ML 模型，GuardDuty 可以识别与特权提升技术一致的模式，例如通过对基础 Amazon EC2 主机的根级访问恶意启动容器。有关所有新检测功能的完整列表，请参阅 [Amazon GuardDuty 结果类型](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_finding-types-active.html)。"
    },
    {
        "query":"我需要启用 Amazon EKS 审计日志吗？",
        "intention":"知识问答",
        "reply":"不需要。GuardDuty 可直接访问 EKS 审计日志。请注意，GuardDuty 只会将这些日志用于分析；它不会存储，而且您也不需要启用或为这些 Amazon EKS 审计日志付费即可与 GuardDuty 进行共享。为优化成本，GuardDuty 会应用智能筛选条件，只使用与安全威胁检测有关的审计日志子集。"
    },
    {
        "query":"是否可以免费试用 GuardDuty EKS Protection？",
        "intention":"知识问答",
        "reply":"是的，您可以免费试用 30 天。每个区域中的每个新 GuardDuty 账户可免费试用 GuardDuty 30 天，其中包括 GuardDuty EKS Protection 功能。现有的 GuardDuty 账户则可以试用 GuardDuty EKS Protection 30 天，而不会产生额外费用。在免费试用期间，您可以在 [GuardDuty 控制台](https://docs.aws.amazon.com/guardduty/latest/ug/monitoring_costs.html)使用情况页面查看试用结束后的成本估计。如果是 GuardDuty 管理员，您将可查看自己的成员账户的估计成本。在 30 天以后，您可以前往 AWS Billing Console 查看此功能的实际成本。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，如何开始使用 GuardDuty EKS Protection？",
        "intention":"知识问答",
        "reply":"必须为每个账户分别开启 GuardDuty EKS Protection。您可以从 GuardDuty EKS Protection 控制台页面的 GuardDuty 控制台中通过单个操作为账户激活该功能。如果您在 GuardDuty 多账户配置中进行操作，则可以从 GuardDuty 管理员账户 GuardDuty EKS Protection 页面为整个组织激活 GuardDuty EKS Protection。此操作将在所有独立成员账户中激活 Amazon EKS 持续监控。对于使用 AWS Organizations 自动激活功能创建的 GuardDuty 账户，您必须明确开启“Amazon EKS 自动激活”。一旦为某个账户激活该功能，该账户中的全部现有及未来 Amazon EKS 集群都将接受威胁监控，而无需在您的 Amazon EKS 集群上执行任何配置。"
    },
    {
        "query":"如果我是新 GuardDuty 用户，默认情况下我的账户是否启用了 GuardDuty EKS Protection？",
        "intention":"知识问答",
        "reply":"是的，默认情况下，通过控制台或 API 开启 GuardDuty 的任何新账户也将开启 GuardDuty EKS Protection。 对于使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户，您需要明确地为 EKS Protection 选项启用“自动启用”。"
    },
    {
        "query":"如何禁用 GuardDuty EKS Protection？",
        "intention":"知识问答",
        "reply":"您可以在控制台中或使用 API 禁用此功能。在 GuardDuty 控制台中，您可以在 GuardDuty EKS Protection 控制台页面上为您的账户禁用 GuardDuty EKS Protection。如果您有 GuardDuty 管理员账户，还可以为您的成员账户禁用此功能。"
    },
    {
        "query":"如果我禁用了 GuardDuty EKS Protection，该如何再次启用？",
        "intention":"知识问答",
        "reply":"如果您以前禁用了 GuardDuty EKS Protection，则可以在控制台中或使用 API 重新启用此功能。在 GuardDuty 控制台中，您可以在 GuardDuty EKS Protection 页面上为您的账户启用 GuardDuty EKS Protection。"
    },
    {
        "query":"我必须在每个 AWS 账户和 Amazon EKS 集群上分别启用 GuardDuty EKS Protection 吗？",
        "intention":"知识问答",
        "reply":"必须为每个账户分别启用 GuardDuty EKS Protection。如果在 GuardDuty 多账户配置中进行操作，您可以为整个组织启用 Amazon EKS 威胁检测，只需在 GuardDuty 管理员账户 GuardDuty EKS Protection 控制台页面上单击一次即可完成。此操作将在所有独立成员账户中启用 Amazon EKS 威胁检测。一旦为某个账户启用该功能，该账户中的全部现有及未来 Amazon EKS 集群都将接受威胁监控，而无需在您的 Amazon EKS 集群上执行手动配置。"
    },
    {
        "query":"是否可以在不启用完整 GuardDuty 服务（包括 VPC 流日志、DNS 查询日志和 CloudTrail 管理事件分析）的情况下启用 GuardDuty EKS Protection？",
        "intention":"知识问答",
        "reply":"不能，必须启用 GuardDuty 服务才可使用 GuardDuty EKS Protection。"
    },
    {
        "query":"GuardDuty EKS Protection 是否为 AWS Fargate 上的 Amazon EKS 部署监控 Amazon EKS 审计日志？",
        "intention":"知识问答",
        "reply":"是，GuardDuty EKS Protection 会监控来自部署在 Amazon EC2 实例上的 Amazon EKS 集群和部署在 Fargate 上的 Amazon EKS 集群的 Amazon EKS 审计日志。"
    },
    {
        "query":"GuardDuty 是否会监控 Amazon EC2 或 Amazon EKS Anywhere 上的非托管 Amazon EKS？",
        "intention":"知识问答",
        "reply":"此功能目前仅支持在 Amazon EC2 实例上运行的 Amazon EKS 部署，而且这些 Amazon EC2 实例必须位于您的账户中或 Fargate 上。"
    },
    {
        "query":"使用 GuardDuty EKS Protection 会影响在 Amazon EKS 上运行的容器的性能和成本吗？",
        "intention":"知识问答",
        "reply":"不会。按照设计，GuardDuty EKS Protection 不会对 Amazon EKS 工作负载部署造成任何性能、可用性或成本影响。"
    },
    {
        "query":"我必须在每个 AWS 区域分别启用 GuardDuty EKS Protection 吗？",
        "intention":"知识问答",
        "reply":"是，GuardDuty 是一项区域性服务，因此 GuardDuty EKS Protection 必须在每个 AWS 区域中分别启用。"
    },
    {
        "query":"GuardDuty EKS 运行时系统监控是如何工作的？",
        "intention":"知识问答",
        "reply":"GuardDuty EKS 运行时系统监控使用完全托管的 Amazon EKS 插件，可深入了解在 Amazon EKS 上运行的单个 Kubernetes 容器的运行时系统活动，例如文件访问、流程执行和网络连接。可以直接从 GuardDuty 为账户中的所有现有和新的 Amazon EKS 集群自动激活该插件，也可以从 Amazon EKS 为单个集群手动激活该插件。该插件会自动将 GuardDuty 安全代理部署为进程守护程序集，从节点上运行的所有容器组 (pod) 收集运行时系统事件并将其传送到 GuardDuty 进行安全分析处理。这使 GuardDuty 可以识别您的 Amazon EKS 集群中可能遭到入侵的特定容器，并检测将权限从单个容器升级到底层 Amazon EC2 主机和更广泛的 AWS 环境的尝试。当 GuardDuty 检测到潜在威胁时，会生成安全发现，其中包含元数据上下文，包括容器、Kubernetes pod 和进程详细信息。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，如何开始使用 EKS 运行时系统监控？",
        "intention":"知识问答",
        "reply":"对于当前 GuardDuty 账户，可以从 [EKS 运行时系统监控](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty-eks-runtime-monitoring.html)页面的 GuardDuty 控制台中激活该功能，也可以通过 API 激活该功能。 了解有关 GuardDuty EKS 运行时系统监控的更多信息。"
    },
    {
        "query":"如果我是 GuardDuty 的新用户，我的账户是否默认启用 EKS 运行时系统监控？",
        "intention":"知识问答",
        "reply":"不。GuardDuty EKS 运行时系统监控是您首次开启 GuardDuty 时唯一一个默认情况下未启用的保护计划。该功能可以从“EKS 运行时系统监控”页面上的 GuardDuty 控制台激活，也可以通过 API 激活。使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户不会开启 EKS 运行时系统监控，除非开启了“Amazon EKS 自动启用”选项。"
    },
    {
        "query":"能否在不激活完整的 GuardDuty 服务的情况下使用 GuardDuty EKS 运行时系统监控？",
        "intention":"知识问答",
        "reply":"不可以，必须启用 GuardDuty 服务才能使用 GuardDuty EKS 运行时系统监控。"
    },
    {
        "query":"GuardDuty EKS 运行时系统监控是否在目前提供 GuardDuty 的所有区域提供？",
        "intention":"知识问答",
        "reply":"有关提供 GuardDuty EKS 运行时系统监控的区域的完整列表，请访问[特定于区域的功能可用性](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_regions.html#gd-regional-feature-availability)。"
    },
    {
        "query":"是否必须分别在每个 AWS 账户和 Amazon EKS 集群上激活 GuardDuty EKS 运行时系统监控？",
        "intention":"知识问答",
        "reply":"必须为每个个人账户启用 GuardDuty EKS 运行时系统监控。如果在 GuardDuty 多账户配置中进行操作，您可以为整个组织开启 Amazon EKS 威胁检测，只需在 GuardDuty 管理员账户的 GuardDuty EKS 运行时系统监控控制台页面上单击一次即可完成。此操作将在所有独立成员账户中激活 Amazon EKS 运行时系统监控。一旦为某个账户激活该功能，该账户中的全部现有及未来 Amazon EKS 集群都将接受运行时系统威胁监控，而无需在您的 Amazon EKS 集群上执行手动配置。"
    },
    {
        "query":"Amazon GuardDuty 恶意软件防护的工作原理是什么？",
        "intention":"知识问答",
        "reply":"当发现可指示 Amazon EC2 实例或容器工作负载中存在恶意软件的可疑行为时，GuardDuty 就开始恶意软件扫描。它扫描 GuardDuty 根据 Amazon EBS 卷的快照生成的副本 Amazon EBS 卷是否存在木马、蠕虫、加密矿工、rootkit、自动程序和更多威胁。GuardDuty 恶意软件防护生成情景化的检测结果，可帮助验证可疑行为的来源。这些检测结果还可以传送给适当的管理员，并可发起自动修复。"
    },
    {
        "query":"Amazon EC2 的哪些 GuardDuty 检测结果类型将启动恶意软件扫描？",
        "intention":"知识问答",
        "reply":"[此处](https://docs.aws.amazon.com/guardduty/latest/ug/gd-findings-initiate-malware-protection-scan.html)列出了将会发起恶意软件扫描的 Amazon EC2 GuardDuty 检测结果。"
    },
    {
        "query":"GuardDuty 恶意软件防护可以扫描哪些资源和文件类型？",
        "intention":"知识问答",
        "reply":"恶意软件防护支持通过扫描挂载到 EC2 实例的 EBS 卷来检测恶意文件。它可以扫描该卷中存在的任何文件，支持的文件系统类型请参见[此处](https://docs.aws.amazon.com/guardduty/latest/ug/malware-protection-limitations.html)。"
    },
    {
        "query":"GuardDuty Malware Protection 可以检测哪些威胁类型？",
        "intention":"知识问答",
        "reply":"Malware Protection 可扫描木马、蠕虫、加密矿工、rootkit 和自动程序之类的威胁，它们可能会被用于盗用工作负载，将资源重新用于恶意用途，以及获得对数据的未经授权访问。"
    },
    {
        "query":"是否需要打开日志记录功能才能使 GuardDuty Malware Protection 正常工作？",
        "intention":"知识问答",
        "reply":"不需要启用服务日志记录 GuardDuty 或 Malware Protection 功能就可以正常工作。Malware Protection 功能是 GuardDuty 的一部分，它是一种 AWS 服务，使用来自集成内部和外部来源的情报。"
    },
    {
        "query":"GuardDuty 恶意软件防护如何在没有代理的情况下完成扫描？",
        "intention":"知识问答",
        "reply":"GuardDuty 恶意软件防护将根据挂载到您的账户中可能受影响的 Amazon EC2 实例或容器工作负载的 Amazon EBS 卷的快照创建一个副本并进行扫描，而不使用安全代理。您通过与服务关联的角色授予 GuardDuty 的权限允许该服务在 GuardDuty 的服务账户中从保留在您的账户中的该快照创建加密卷副本。然后，GuardDuty Malware Protection 将扫描该卷副本是否存在恶意软件。"
    },
    {
        "query":"是否可以免费试用 GuardDuty Malware Protection？",
        "intention":"知识问答",
        "reply":"可以，每个区域内的每个新 GuardDuty 账户可免费试用 GuardDuty 30 天，其中包括 Malware Protection 功能。现有 GuardDuty 账户首次在账户中启用 Malware Protection 时，也可试用 30 天而无需额外收费。在免费试用期间，您可以在 [GuardDuty 控制台](https://docs.aws.amazon.com/guardduty/latest/ug/monitoring_costs.html)使用情况页面查看试用结束后的成本估计。如果是 GuardDuty 管理员，您将可查看自己的成员账户的估计成本。在 30 天以后，您可以前往 AWS Billing Console 查看此功能的实际成本。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，如何开始使用 GuardDuty Malware Protection？",
        "intention":"知识问答",
        "reply":"您可以转到 Malware Protection 页面或使用 API 以在 GuardDuty 控制台中启用 Malware Protection。如果在 GuardDuty 多账户配置中进行操作，您可以在 GuardDuty 管理员账户的 Malware Protection 控制台页面中为整个组织启用此功能。这样将在所有独立成员账户中启用恶意软件监控。对于使用 [AWS Organizations](https://aws.amazon.com/cn/organizations/) 自动启用功能创建的 GuardDuty 账户，您需要明确地为 Malware Protection 选项启用“自动启用”。"
    },
    {
        "query":"如果我是 GuardDuty 的新用户，默认情况下我的账户是否启用了 Malware Protection？",
        "intention":"知识问答",
        "reply":"是，利用控制台或 API 启用了 GuardDuty 的任何新账户默认情况下也将启用 GuardDuty Malware Protection。对于使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户，您需要明确地为 Malware Protection 选项启用“自动启用”。"
    },
    {
        "query":"如何禁用用于 GuardDuty Malware Protection？",
        "intention":"知识问答",
        "reply":"您可以在控制台中或使用 API 禁用此功能。在 GuardDuty 控制台中、Malware Protection 控制台页面上，您将会看到用于为您的账户禁用 Malware Protection 的选项。如果您有 GuardDuty 管理员账户，还可以为您的成员账户禁用 Malware Protection。"
    },
    {
        "query":"如果我禁用了 GuardDuty Malware Protection，该如何再次启用？",
        "intention":"知识问答",
        "reply":"如果禁用了 Malware Protection，您可以在控制台中或使用 API 启用此功能。在 GuardDuty 控制台中、Malware Protection 控制台页面上，您可以为您的账户启用 Malware Protection。"
    },
    {
        "query":"GuardDuty Malware Protection 是否支持多账户管理？",
        "intention":"知识问答",
        "reply":"可以，GuardDuty 拥有多账户管理功能，允许您从单个管理员账户关联并管理多个 AWS 账户。GuardDuty 通过 AWS Organizations 集成支持多账户管理。此集成可帮助安全与合规团队确保 GuardDuty 完全覆盖组织中的所有账户，其中包括 Malware Protection 功能。"
    },
    {
        "query":"我需要执行任何配置更改、部署任何软件，或修改我的 AWS 部署吗？",
        "intention":"知识问答",
        "reply":"否。启用此功能后，GuardDuty 恶意软件防护就将发起恶意软件扫描以响应[相关 Amazon EC2 检测结果](https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html)。您没有部署任何代理，没有需要启用的日志来源，也没有需要进行的其他配置更改。"
    },
    {
        "query":"使用 GuardDuty Malware Protection 是否会影响运行工作负载的性能？",
        "intention":"知识问答",
        "reply":"GuardDuty 恶意软件防护按照设计不会影响您的工作负载的性能。例如，为恶意软件分析创建的 Amazon EBS 卷快照在 24 小时的期限内只能生成一次，并且 GuardDuty 恶意软件防护仅将加密副本和快照保留到完成扫描后几分钟。此外，GuardDuty 恶意软件防护使用 GuardDuty 计算资源进行恶意软件扫描，而非使用客户计算资源。"
    },
    {
        "query":"我必须在每个 AWS 区域分别启用 GuardDuty Malware Protection 吗？",
        "intention":"知识问答",
        "reply":"是，GuardDuty 是一项区域性服务，Malware Protection 必须在每个 AWS 区域中分别启用。"
    },
    {
        "query":"GuardDuty 恶意软件防护如何使用加密？",
        "intention":"知识问答",
        "reply":"GuardDuty 恶意软件防护根据挂载到您的账户中可能受影响的 Amazon EC2 实例或容器工作负载的 Amazon EBS 卷的快照扫描副本。如果 Amazon EBS 卷使用客户管理的密钥进行加密，您可以选择[通过 GuardDuty 共享 AWS Key Management Service (KMS) 密钥，该服务](https://docs.aws.amazon.com/guardduty/latest/ug/data-protection.html)使用相同的密钥来加密副本 Amazon EBS 卷。对于未加密的 Amazon EBS 卷，GuardDuty 使用其自己的密钥来加密副本 Amazon EBS 卷。"
    },
    {
        "query":"Amazon EBS 卷副本是否与原始卷在同一个区域中进行分析？",
        "intention":"知识问答",
        "reply":"是，所有副本 Amazon EBS 卷数据（以及副本卷所基于的快照）都留在与原始 Amazon EBS 卷相同的区域中。"
    },
    {
        "query":"如何估计和控制用在 GuardDuty 恶意软件防护上的支出？",
        "intention":"知识问答",
        "reply":"每个区域内的每个新 GuardDuty 账户可免费试用 GuardDuty 30 天，其中包括 Malware Protection 功能。现有 GuardDuty 账户首次在账户中启用 Malware Protection 时，也可试用 30 天而无需额外收费。在免费试用期间，您可以在 [GuardDuty 控制台](https://docs.aws.amazon.com/guardduty/latest/ug/monitoring_costs.html)使用情况页面估计试用结束后的成本估计。如果是 GuardDuty 管理员，您将可查看自己的成员账户的估计成本。在 30 天以后，您可以前往 AWS Billing Console 查看此功能的实际成本。\n此功能的定价基于在卷中扫描了多少 GB 的数据。您可以从控制台使用[扫描选项](https://docs.aws.amazon.com/guardduty/latest/ug/what-is-guardduty.html)应用自定义，以[使用标签](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html)来标记一些要包含在扫描中或从扫描中排除的 Amazon EC2 实例，从而控制成本。此外，GuardDuty 每 24 小时将仅扫描 Amazon EC2 实例一次。如果 GuardDuty 在 24 小时内为 Amazon EC2 实例生成了多个 Amazon EC2 检测结果，则将仅对第一个相关 Amazon EC2 检测结果进行扫描。如果继续生成 Amazon EC2 检测结果，例如在最后一次恶意扫描 24 小时之后，则将对该实例发起新的恶意软件扫描。"
    },
    {
        "query":"我能否保留 GuardDuty 恶意软件防护创建的快照？",
        "intention":"知识问答",
        "reply":"能，您可以通过相应的设置启用当 Malware Protection 扫描检测到恶意软件时保留快照的功能。您可以从 GuardDuty 控制台的设置页面上启用此设置。默认情况下，完成扫描几分钟后将会删除快照，如果扫描未完成则在 24 小时后删除。"
    },
    {
        "query":"默认情况下，副本 Amazon EBS 卷最多将保留多长时间？",
        "intention":"知识问答",
        "reply":"GuardDuty 恶意软件防护可将它生成和扫描的每个副本 Amazon EBS 卷保留最多 24 小时。默认情况下，GuardDuty 恶意软件防护完成扫描几分钟后将会删除副本 Amazon EBS 卷。但是在有些情况中，如果服务中断或连接问题干扰其恶意软件扫描，则 GuardDuty 恶意软件防护可能需要将副本 Amazon EBS 卷保留超过 24 小时。发生这种情况时，GuardDuty 恶意软件防护会将副本 Amazon EBS 卷保留最多七天，以留出服务时间来分检和解决中断或连接问题。在中断或故障得到解决之后或者延长保留期结束时，GuardDuty 恶意软件防护将会删除副本 Amazon EBS 卷。"
    },
    {
        "query":"如果单个 Amazon EC2 实例或容器工作负载有多个 GuardDuty 检测结果指示可能存在恶意软件，是否将发起多次恶意软件扫描？",
        "intention":"知识问答",
        "reply":"不，GuardDuty 仅根据挂载到可能受影响的 Amazon EC2 实例或容器工作负载的 EBS 卷的快照扫描副本，每 24 小时一次。如果自从上次扫描以来还不到 24 个小时，即使 GuardDuty 生成了多个符合恶意软件扫描触发条件的检测结果，也不会再发起扫描。如果 GuardDuty 在离上次恶意软件扫描 24 小时之后生成符合条件的检测结果，GuardDuty Malware Protection 将会为该工作负载发起新恶意软件扫描。"
    },
    {
        "query":"如果禁用 GuardDuty，是否也必须禁用 Malware Protection 功能？",
        "intention":"知识问答",
        "reply":"不，禁用 GuardDuty 服务还将禁用 Malware Protection 功能。"
    },
    {
        "query":"GuardDuty RDS Protection 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"只需在 GuardDuty 控制台中执行一项操作即可启用 GuardDuty RDS Protection，无需手动部署代理，无需激活数据来源，也无需配置权限。GuardDuty RDS Protection 使用定制的 ML 模型，首先分析和剖析对现有和新 Amazon Aurora 数据库的登录尝试。当识别出可疑行为或已知恶意行为者的尝试时，GuardDuty 会向 GuardDuty 和 Amazon Relational Database Service (RDS) 控制台、Security Hub 和 Amazon EventBridge 发布可操作的安全调查结果，允许与现有安全事件管理或工作流程系统集成。 详细了解 [GuardDuty RDS Protection 如何使用 RDS 登录活动监控](https://docs.aws.amazon.com/guardduty/latest/ug/rds-protection.html#understanding-how-rds-pro-works)。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，我该如何开始对 Aurora 数据库进行威胁检测？",
        "intention":"知识问答",
        "reply":"对于当前 GuardDuty 账户，可以从 RDS 保护页面上的 GuardDuty 控制台激活该功能，也可以通过 API 激活该功能。 详细了解 [GuardDuty RDS Protection](https://docs.aws.amazon.com/guardduty/latest/ug/rds-protection.html)。"
    },
    {
        "query":"如果我是 GuardDuty 的新用户，我的账户是否默认启用 Aurora 数据库的威胁检测？",
        "intention":"知识问答",
        "reply":"可以。默认情况下，通过控制台或 API 激活 GuardDuty 的任何新账户也将启用 RDS Protection。使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户不会打开 RDS Protection，除非打开了“RDS 自动启用”选项。"
    },
    {
        "query":"是否可以在不激活完整 GuardDuty 服务（包括分析 Amazon Virtual Private Cloud (VPC) 流日志、DNS 查询日志和 AWS CloudTrail 管理事件）的情况下使用 GuardDuty RDS Protection？",
        "intention":"知识问答",
        "reply":"不可以，必须启用 GuardDuty 服务才能使用 GuardDuty RDS Protection。\n\n问：GuardDuty RDS Protection 是否在目前提供 GuardDuty 的所有区域提供？\n有关提供 RDS Protection 的区域的完整列表，请访问[特定区域的功能可用性](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_regions.html#gd-regional-feature-availability)。"
    },
    {
        "query":"GuardDuty RDS Protection 支持哪些 Amazon Aurora 版本？",
        "intention":"知识问答",
        "reply":"请参阅[受支持的 Amazon Aurora 数据库版本](https://docs.aws.amazon.com/guardduty/latest/ug/rds-protection.html#rds-pro-supported-db)的列表。"
    },
    {
        "query":"使用 GuardDuty RDS Protection 会影响运行 Aurora 数据库的性能或成本吗？",
        "intention":"知识问答",
        "reply":"不会，Aurora 数据库的 GuardDuty 威胁检测经过设计，不会对您的 Amazon Aurora 数据库产生性能、可用性或成本影响。"
    },
    {
        "query":"Amazon GuardDuty Lambda Protection 如何运作？",
        "intention":"知识问答",
        "reply":"GuardDuty Lambda Protection 从您的无服务器工作负载开始持续监控网络活动，从 VPC 流日志开始检测威胁，例如被恶意改用于未经授权的加密货币挖矿的 Lambda 函数，或与已知威胁参与者服务器通信的受损 Lambda 函数。在 GuardDuty 控制台中只需几个步骤即可启用 GuardDuty Lambda Protection，使用 AWS Organizations 可以集中为组织中的所有现有和新账户启用该功能。启用后，它会自动开始监控来自账户中所有现有和新的 Lambda 函数的网络活动数据。"
    },
    {
        "query":"如果我目前正在使用 GuardDuty，如何开始使用 GuardDuty Lambda Protection？",
        "intention":"知识问答",
        "reply":"对于当前 GuardDuty 账户，可以从 Lambda Protection 页面上的 GuardDuty 控制台激活该功能，也可以通过 API 激活该功能。[详细了解 GuardDuty Lambda Protection](https://docs.aws.amazon.com/guardduty/latest/ug/lambda-protection.html)。"
    },
    {
        "query":"如果我是 GuardDuty 的新用户，默认情况下我的账户是否启用了 GuardDuty Lambda Protection？",
        "intention":"知识问答",
        "reply":"是的。默认情况下，通过控制台或 API 激活 GuardDuty 的任何新账户也将启用 Lambda Protection。使用 AWS Organizations 自动启用功能创建的新 GuardDuty 账户不会打开 Lambda Protection，除非打开了“Lambda 自动启用”选项。"
    },
    {
        "query":"GuardDuty Lambda Protection 是否在目前提供 GuardDuty 的所有区域提供？",
        "intention":"知识问答",
        "reply":"有关提供 Lambda Protection 的区域的完整列表，请访问[特定区域的功能可用性](https://docs.aws.amazon.com/guardduty/latest/ug/guardduty_regions.html#gd-regional-feature-availability)。"
    },
    {
        "query":"使用 GuardDuty Lambda Protection 会影响运行 Lambda 工作负载的性能或成本吗？",
        "intention":"知识问答",
        "reply":"不会，按照设计，GuardDuty Lambda Protection 不会对 Lambda 工作负载造成性能、可用性或成本影响。\n请参阅定价示例和免费试用详细信息\n获得免费试用 Amazon GuardDuty 的机会。\n在 AWS 控制台中开始使用 Amazon GuardDuty。"
    },
    {
        "query":"什么是 IAM 策略模拟器，我应在何时使用？ IAM 策略模拟器会评估您选择的策略并确定您指定的每个操作的有效权限。使用策略模拟器对基于身份和基于资源的策略、IAM 权限边界和 SCP 进行测试和故障排除。有关更多信息，请参阅使用 IAM 策略模拟器测试 IAM 策略。",
        "intention":"知识问答",
        "reply":"了解如何开始使用 IAM"
    },
    {
        "query":"什么是 AWS Service Catalog？",
        "intention":"知识问答",
        "reply":"利用 AWS Service Catalog，IT 管理员可以创建、管理和向最终用户分发已批准的产品目录，然后，最终用户可以在个性化的门户中访问他们所需的产品。管理员可以控制哪些用户具有各种产品的访问权限，从而强制遵守组织的业务策略。管理员还可以设置已被接受的角色，以便最终用户只需具有 IAM 访问权限即可访问 AWS Service Catalog 来部署获批资源。AWS Service Catalog 可让您的组织获益于灵活性的提高和成本的降低，因为最终用户从您控制的目录中只能找到和启动他们所需的产品。"
    },
    {
        "query":"哪些用户应使用 AWS Service Catalog？",
        "intention":"知识问答",
        "reply":"AWS Service Catalog 面向需要使策略集中化的组织、IT 团队和托管服务提供商 (MSP)。它允许 IT 管理员发布和管理 AWS 资源和服务。对于大型组织，它可以提供为数以千计的用户预置云资源的标准方法。AWS Service Catalo 同样也适合小型团队，使一线开发管理员可以提供和维护标准开发/测试环境。"
    },
    {
        "query":"如何开始使用 AWS Service Catalog？",
        "intention":"知识问答",
        "reply":"在 AWS 管理控制台中，选择“管理工具”中的“AWS Service Catalog”。在 AWS Service Catalog 控制台中，管理员只需单击几下便可以创建产品组合、添加产品以及向用户授予使用产品的权限。最终用户登录到 AWS Service Catalog 控制台后，可以看到并启动管理员为他们创建的产品。"
    },
    {
        "query":"最终用户可以利用 AWS Service Catalog 执行哪些之前无法执行的操作？",
        "intention":"知识问答",
        "reply":"最终用户可以在一个简单的门户中找到和启动符合组织政策和预算限制的产品。"
    },
    {
        "query":"什么是产品组合？",
        "intention":"知识问答",
        "reply":"产品组合是产品及配置信息的集合，配置信息确定了谁能够使用这些产品和如何使用。管理员可以为组织内的每类用户都创建一个自定义产品组合，并选择性授予相应组合的访问权限。管理员向组合中添加新版本的产品时，该版本可自动供当前的所有产品组合用户使用。同一个产品可以包含在多个产品组合中。管理员还可以与其他 AWS 账户共享产品组合，并允许这些账户的管理员通过应用附加约束扩展产品组合。通过使用产品组合、权限、共享和限制，管理员可以确保用户所启动的产品经过正确配置，符合组织的需要。"
    },
    {
        "query":"AWS Service Catalog 是否为区域性服务？",
        "intention":"知识问答",
        "reply":"是。AWS Service Catalog 是完全区域化的服务，因此，您可以控制数据所存储的区域。产品组合和产品是需要按区域进行创建的区域构造，并且仅在其创建区域内可见/可用。"
    },
    {
        "query":"AWS Service Catalog 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"要查看受支持的 AWS 区域的完整列表，请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"是否提供 API？ 我能否通过 CLI 访问 AWS Service Catalog？",
        "intention":"知识问答",
        "reply":"能，API 可以通过 CLI 提供和启用。您可以执行从 Service Catalog 项目的管理到预置和终止的各项操作。您可以在 [AWS Service Catalog 文档](https://aws.amazon.com/cn/documentation/servicecatalog/)中找到更多信息，或下载最新的 [AWS 软件开发工具包或 CLI](https://aws.amazon.com/cn/tools/)。"
    },
    {
        "query":"我可以在不使用公有 IP 的情况下，从 Amazon Virtual Private Cloud (VPC) 对 AWS Service Catalog API 进行私有访问吗？",
        "intention":"知识问答",
        "reply":"可以，您可以通过创建 VPC 终端节点来实现从 Amazon Virtual Private Cloud (VPC) 对 AWS Service Catalog API 进行私有访问。借助 VPC 终端节点，VPC 和 AWS Service Catalog 之间的路由将由 AWS 网络处理，而无需 Internet 网关、NAT 网关或 VPN 连接。AWS Service Catalog 所使用的最新一代 VPC 终端节点由 AWS PrivateLink 提供支持。AWS PrivateLink 是一种通过使用 VPC 中带有私有 IP 的弹性网络接口来支持各 AWS 服务之间的私有连接的 AWS 技术。要了解有关 AWS PrivateLink 的更多信息，请访问 [AWS PrivateLink 文档](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html#what-is-privatelink)。"
    },
    {
        "query":"AWS Direct Connect 是否提供服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"是。如果客户的月度正常运行时间百分比在任何账单周期内低于我们的服务承诺，则 [AWS Service Catalog SLA](https://aws.amazon.com/servicecatalog/sla/) 将提供服务积分。"
    },
    {
        "query":"如何创建产品组合？",
        "intention":"知识问答",
        "reply":"在 AWS Service Catalog 控制台中创建产品组合。对于每个产品组合，您需要指定名称、说明和拥有者。"
    },
    {
        "query":"如何创建产品？",
        "intention":"知识问答",
        "reply":"每个 Service Catalog 产品都基于基础设施即代码 (IaC) 模板。您可以使用 CloudFormation 模板或 Terraform 配置（单个 tar.gz 文件）。您可以通过 AWS Service Catalog 控制台创建产品，方法是上传 IaC 模板，提供指向存储模板的 S3 存储桶的链接，或者连接到存储模板的外部 Git 存储库。创建产品时，您可以向产品列示内容提供其他信息，包括详细的产品说明、版本信息、支持信息和标记。"
    },
    {
        "query":"为什么要对产品组合使用标记？",
        "intention":"知识问答",
        "reply":"标记有助于识别和分类最终用户预置的 AWS 资源。您还可以在 AWS Identity and Access Management (IAM) 策略中使用标记，以允许或拒绝访问 IAM 用户、组和角色，或限制 IAM 用户、组和角色可以执行的操作。向产品组合中添加标记时，标记应用于从组合中的产品预置的所有资源实例。"
    },
    {
        "query":"如何向我的用户提供产品组合？",
        "intention":"知识问答",
        "reply":"您发布自己创建的或与您共享的产品组合，使其可供 AWS 账户中 IAM 用户使用。要发布产品组合，请从 AWS Service Catalog 控制台，导航到产品组合详细信息页面，然后将 IAM 用户、组或角色添加到产品组合中。将用户添加到某个产品组合后，这些用户可以浏览并启动其中的任何产品。通常，可以创建包含不同产品并针对特定类型的最终用户自定义访问权限的产品组合。例如，用于开发团队的产品组合包含的产品可能不同于面向销售和营销团队的产品组合。单个产品可以通过配置不同的访问权限和预置策略发布到多个产品组合。"
    },
    {
        "query":"是否可以与其他 AWS 账户共享我的产品组合？",
        "intention":"知识问答",
        "reply":"是。您可以与一个或多个其他 AWS 账户中的用户共享产品组合。与其他 AWS 账户共享产品组合时，您保留产品组合的所有权和控制权。只有您可以执行更改，如添加新产品或更新产品。您还可以随时“取消共享”您的产品组合，并且只有您可以执行此操作。当前正在使用的任何产品或堆栈将继续运行，直到堆栈所有者决定将其终止。\n要共享产品组合，应指定要与其共享的账户 ID，然后向此账户发送产品组合的 Amazon 资源编号 (ARN)。该账户的所有者可以创建此共享组合的链接，然后从该账户向产品组合分配 IAM 用户。为了便于最终用户找到，您可以创建产品组合的目录。"
    },
    {
        "query":"是否可以通过现有的 Amazon EC2 AMI 创建产品？",
        "intention":"知识问答",
        "reply":"是。您可以使用现有 Amazon EC2 AMI，通过将其打包到 AWS CloudFormation 模板中来创建产品。"
    },
    {
        "query":"我是否可以使用 AWS Marketplace 中的产品？",
        "intention":"知识问答",
        "reply":"是。您可以订阅 AWS Marketplace 中的产品，并使用“复制到 Service Catalog”操作将 Marketplace 产品直接复制到 Service Catalog。您还可以针对相应产品使用 Amazon EC2 AMI 来创建 AWS Service Catalog 产品。为此，您需要将订阅的产品打包到 AWS CloudFormation 模板中。有关如何复制或打包您的 AWS Marketplace 产品的更多详细信息，请[单击此处](http://docs.aws.amazon.com/servicecatalog/latest/adminguide/catalogs_marketplace-products.html)。"
    },
    {
        "query":"如何控制对产品组合和产品的访问？",
        "intention":"知识问答",
        "reply":"要控制对产品组合和产品的访问，需要在产品组合详细信息页面分配 IAM 用户、组或角色。通过提供访问权限，用户可以在 AWS Service Catalog 控制台中看到他们可以使用的产品。"
    },
    {
        "query":"我是否可以提供新版本的产品？",
        "intention":"知识问答",
        "reply":"是。您可以按照创建新产品的方式创建新产品版本。新产品版本发布到产品组合中后，最终用户可以选择启动新版本。他们还可以选择更新正在运行的堆栈以使用此新版本。AWS Service Catalog 不会在有更新可用时自动更新正在使用的产品。"
    },
    {
        "query":"我是否可以提供产品并保留对关联 AWS 资源的完全控制？",
        "intention":"知识问答",
        "reply":"是。您具有用于预置产品的 AWS 账户和角色的完全控制权。要预置 AWS 资源，可以使用用户的 IAM 访问权限或预定义的 IAM 角色。要保留 AWS 资源的完全控制权，需要在产品级别指定具体的 IAM 角色。AWS Service Catalog 使用角色预置堆栈中的资源。"
    },
    {
        "query":"我是否可以限制用户能够预置的 AWS 资源？",
        "intention":"知识问答",
        "reply":"是。您可以定义规则，限制用户在启动产品时输入的参数值。 这些值称为模板约束，因为它们约束部署产品的 AWS CloudFormation 模板的方式。您可以使用简单的编辑器创建模板约束，然后将其应用到各个产品。\nAWS Service Catalog 在预置新产品或更新正在使用的产品时应用约束。在应用到组合和产品的所有约束中，它始终应用限制性最强的约束。例如，请考虑下面一种情况：产品允许启动所有 EC2 实例且组合具有两项约束：一项允许启动所有非 GPU 类型的 EC2 实例，另一项仅允许启动 t1.micro 和 m1.small EC2 实例。对于此情况，AWS Service Catalog 应用限制性更强的第二项约束（t1.micro 和 m1.small）。目前，Terraform 配置不支持模板约束。"
    },
    {
        "query":"我能否在 Service Catalog 中使用 YAML 语言 CloudFormation 模板？",
        "intention":"知识问答",
        "reply":"可以，目前我们同时支持 JSON 和 YAML 语言模板。"
    },
    {
        "query":"我可以将 ServiceNow 和 Jira Service Desk 实例连接到 AWS Service Catalog 吗？",
        "intention":"知识问答",
        "reply":"可以。适用于 ServiceNow 和 Jira Service Desk 的 AWS Service Management Connector（以前称为 AWS Service Catalog Connector）提供 ServiceNow 和 Jira Service Desk 项目的集成功能。这简化了 ServiceNow 和 Jira Service Desk 管理员的云配置和资源管理，并使 ServiceNow 用户更轻松地请求 AWS 产品，该产品可以是管理员希望可用于在 AWS 上进行部署的任何 IT 服务。\nServiceNow 和 Jira Service Desk 管理员可以将连接器配置为与现有或新的 AWS 账户和角色一起使用。ServiceNow 和 Jira Service Desk 用户可以浏览和请求管理员批准的 AWS 产品。您还可以查看有关预置产品的配置项目详细信息，并在 ServiceNow 和 Jira Service Desk 中执行 AWS Systems Manager 自动化文档。这简化了针对 ServiceNow 和 Jira Service Desk 用户的 AWS 产品请求操作，并为 ServiceNow 和 Jira Service Desk 管理员提供了对 AWS 产品的管理和监督。\n适用于 ServiceNow 的 AWS Service Management Connector 在 [ServiceNow Store](https://store.servicenow.com/sn_appstore_store.do#!/store/application/f0b117a3db32320093a7d7a0cf961912/) 中免费提供。已推出 AWS Service Catalog 的所有 [AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)均已正式提供这项新功能。有关更多信息，请访问[文档](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/integrations-servicenow.html)。\n[Atlassian Marketplace](https://marketplace.atlassian.com/1221283) 免费提供适用于 Jira Service Desk 的 AWS Service Management Connector。已推出 AWS Service Catalog 的所有 [AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)均已正式提供这项新功能。有关更多信息，请访问[文档](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/integrations-jiraservicedesk.html)。"
    },
    {
        "query":"如何了解哪些产品可用？",
        "intention":"知识问答",
        "reply":"要查看哪些产品可用，请登录 AWS Service Catalog 控制台，搜索门户以查找满足您需要的产品，或导航到完整的产品列表页面。您可以通过排序查找所需的产品。\n对于每个产品，您可以查看产品详细信息页面，其中显示了产品的信息，包括版本、产品是否有可用的更新版、说明、支持信息以及产品关联的标记。产品详细信息页面可能还会指出预置此产品是使用您的访问权限 (Self) 还是使用管理员指定的角色（角色 ARN）。"
    },
    {
        "query":"如何部署产品？",
        "intention":"知识问答",
        "reply":"在门户中找到满足要求的产品后，选择“启动”。您需要回答有关您计划如何使用产品的一组问题。问题可能关于您的业务需求或基础设施需求（如“什么 Amazon EC2 实例类型？”）。提供所需信息后，您将在 AWS Service Catalog 控制台中看到此产品。预置此产品时，您将看到其状态为“正在进行”。 预置完成后，您将看到“完成”和诸如终端节点或 Amazon 资源名称 (ARN) 之类的信息，您可以使用这些信息访问该产品。"
    },
    {
        "query":"我是否可以查看自己正在使用什么产品？",
        "intention":"知识问答",
        "reply":"是。您可以在 AWS Service Catalog 控制台中查看您正在使用什么产品。您可以看到正在使用的所有堆栈，以及用于创建它们的产品版本。"
    },
    {
        "query":"有新版本可用时，我如何更新我的产品？",
        "intention":"知识问答",
        "reply":"产品发布新版本时，您可以使用 Update Stack 命令来使用新版本。如果您当前使用的产品有更新，该产品会继续运行，直到您将其关闭，此时您才可以选择使用新版本。"
    },
    {
        "query":"我应该如何监控产品的运行状况？",
        "intention":"知识问答",
        "reply":"您可以在 AWS Service Catalog 控制台中查看您正在使用的产品及其运行状况。"
    },
    {
        "query":"什么是适用于 Terraform 开源的 AWS Service Catalog 支持？",
        "intention":"知识问答",
        "reply":"使用 Terraform 开源的客户可以借助 AWS Service Catalog 在 AWS 中为其最终用户提供自助配置和管理。中央 IT 部门可以使用单一工具在 AWS 中大规模组织、管理和分发他们的 Terraform 配置。他们可以访问 AWS Service Catalog 的关键功能，包括对标准化和预先批准的模板进行编目、访问控制、配置期间的最低权限、版本控制、与数千个 AWS 账户共享以及标记。最终用户只需查看他们有权访问的产品和版本列表，即可通过单个操作进行部署。\n首先，使用 AWS 提供的 Terraform 参考引擎来安装和配置 Terraform 开源引擎与 AWS Service Catalog 配合使用所需的代码和基础设施。一次性设置仅需几分钟。  \n 要了解如何使用 AWS Service Catalog 编目、管理、共享和部署 Terraform 产品，请阅读我们的[文档](https://docs.aws.amazon.com/servicecatalog/latest/adminguide/introduction.html)。"
    },
    {
        "query":"哪些用户应使用适用于 Terraform 的 AWS Service Catalog 支持？",
        "intention":"知识问答",
        "reply":"如果 Terraform 开源是您的首选 IaC 工具，则您可以使用 Service Catalog 为团队提供 Terraform 配置自助配置。如果您在不同的团队或应用场景中混合使用 CloudFormation 和 Terraform 配置，那么现在可以使用 AWS Service Catalog 作为对两者进行编目和共享的单一工具。对于您的最终用户，AWS Service Catalog 提供了一个易于使用的通用界面，无论采用何种 IaC 技术，都可以查看和预置资源。"
    },
    {
        "query":"如何开始使用适用于 Terraform 开源的 AWS Service Catalog 支持？",
        "intention":"知识问答",
        "reply":"要将 AWS Service Catalog 与 Terraform 开源结合使用，您需要在其中一个账户中设置 Terraform 开源引擎。通过使用 AWS 提供的 Terraform 参考引擎创建 Terraform 开源引擎，该引擎将安装和配置 Terraform 开源引擎与 AWS Service Catalog 配合使用所需的代码和基础设施。完成一次性设置（只需几分钟）后，您就可以开始在 AWS Service Catalog 中创建 Terraform 开源类型产品了。"
    },
    {
        "query":"我能否让多个 AWS 账户使用单个集中式 TFOS 引擎预置 Terraform 资源？",
        "intention":"知识问答",
        "reply":"可以。AWS Service Catalog 支持“中心和分支”模型，在该模型下，产品在单个中央账户中定义，然后可以与数千个 AWS 账户共享。对于 Terraform，您可以安装自己的 TFOS 引擎并在这个中心 Hub 账户中创建自己的 Terraform 产品。然后，您可以与分支账户共享这些产品，并允许访问这些账户中的 IAM 角色/用户/群组。请注意，您需要在每个账户中定义具有足够权限的启动角色。"
    },
    {
        "query":"适用于 Terraform 开源的 AWS Service Catalog 支持是托管服务吗？",
        "intention":"知识问答",
        "reply":"不完全是。AWS 支持对 Terraform 产品的编目、共享和最终用户访问。您负责确保您的 TFOS 环境已准备就绪并与 AWS Service Catalog 完美集成。您还需要定义一个启动角色，该角色有权配置和标记与 Terraform 产品关联的所有资源。"
    },
    {
        "query":"我能否将 AWS Service Catalog 连接到存储我的 Terraform 配置的源代码存储库？",
        "intention":"知识问答",
        "reply":"可以。AWS Service Catalog 允许您将产品同步到通过 GitHub、GitHub Enterprise 或 Bitbucket 管理的模板文件。无论选择哪个存储库，模板文件格式仍然需要是在 Tar 中归档并在 Gzip 中压缩的单个文件。"
    },
    {
        "query":"AWS Service Catalog 如何管理我的 Terraform 开源产品状态文件？",
        "intention":"知识问答",
        "reply":"每个 Terraform 开源产品都有一个状态文件，该文件存储在 AWS S3 存储桶中 Terraform 开源引擎的 AWS 账户中。AWS Service Catalog 管理员将看到状态文件列表，但无法读取或写入其内容。只有您的 Terraform 开源引擎才能读取和写入状态文件的内容。"
    },
    {
        "query":"什么是 AWS Service Catalog AppRegistry？",
        "intention":"知识问答",
        "reply":"AWS Service Catalog AppRegistry 使组织可以了解其 AWS 资源的应用程序上下文。AppRegistry 提供一个信息存储库，描述您在企业中使用的应用程序和相关资源。"
    },
    {
        "query":"哪些用户应使用 AWS Service Catalog AppRegistry？",
        "intention":"知识问答",
        "reply":"AWS Service Catalog AppRegistry 是为需要在其 AWS 环境中拥有应用程序的单个最新定义的组织而开发的。"
    },
    {
        "query":"什么是应用程序？",
        "intention":"知识问答",
        "reply":"AWS Service Catalog AppRegistry 使您可以定义应用程序，包括名称、描述、关联的 CloudFormation 堆栈以及通过属性组表示的应用程序元数据。关联的 CloudFormation 堆栈表示应用程序所需的所有资源。这可能是单个环境中所需的基础设施，也可能包括支持所有环境中的应用程序的代码存储库、管道和 IAM 资源。现有或新的 CloudFormation 堆栈都可以与应用程序关联。通过包括应用程序与堆栈的 CloudFormation 模板的关联，可以在预置时将新堆栈关联到应用程序。"
    },
    {
        "query":"什么是属性组？",
        "intention":"知识问答",
        "reply":"属性组包含对您的企业非常重要的应用程序元数据。属性组包括开放 JSON 模式，使您可以灵活地捕获复杂的企业元数据。应用程序属性可能包括元数据，例如应用程序安全分类、组织所有权、应用程序类型、成本中心和支持信息。构建者将属性组与其应用程序关联。在更新属性组时，这些更新将自动反映在与属性组关联的所有应用程序中。"
    },
    {
        "query":"AWS Service Catalog 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"要查看受支持的 AWS 区域的完整列表，请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"是否提供 API？ 我能否通过 CLI 访问 AWS Service Catalog AppRegistry？",
        "intention":"知识问答",
        "reply":"是的，可以使用全套 API 和 CLI 操作。\n了解有关 AWS Service Catalog 定价的更多信息"
    },
    {
        "query":"什么是 AWS Lambda？",
        "intention":"知识问答",
        "reply":"通过 AWS Lambda，无需预置或管理服务器即可运行代码。您只需按使用的计算时间付费 – 代码未运行时不产生费用。借助 Lambda，您几乎可以为任何类型的应用程序或后端服务运行代码，而且完全无需管理。只需上传您的代码，Lambda 会处理运行和扩展高可用性代码所需的一切工作。您可以将您的代码设置为自动从其他 AWS 服务触发，或者直接从任何 Web 或移动应用程序调用。"
    },
    {
        "query":"什么是无服务器计算？",
        "intention":"知识问答",
        "reply":"[无服务器计算](https://aws.amazon.com/cn/serverless/)让您可以在不考虑服务器的情况下构建并运行应用程序和服务。使用无服务器计算，您的应用程序仍在服务器上运行，但所有服务器管理工作均由 AWS 负责。无服务器计算的核心是 AWS Lambda，这项服务可使您无需预置或管理服务器即可运行代码。"
    },
    {
        "query":"哪些事件可以触发 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"有关事件源的完整列表，请参阅我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/intro-core-components.html#intro-core-components-event-sources)。"
    },
    {
        "query":"什么时候应该使用 AWS Lambda？什么时候应该使用 Amazon EC2？",
        "intention":"知识问答",
        "reply":"Amazon Web Services 提供一组计算服务以满足各种需求。\n[Amazon EC2](https://aws.amazon.com/cn/ec2/) 具有范围广泛的实例类型以及自定义操作系统、网络和安全设置以及整个软件堆栈的选项，可提供灵活性，从而让您能够将现有的应用程序轻松迁移到云中。使用 Amazon EC2，您将负责预置容量、监控服务器队列的运行状况和性能，并设计容错性和可扩展性。[AWS Elastic Beanstalk](https://aws.amazon.com/cn/elasticbeanstalk/) 提供易用的服务，供您部署和扩展 Web 应用程序，您可以在其中保留对底层 EC2 实例的所有权和完整控制权。[Amazon EC2 Container Service](https://aws.amazon.com/cn/ecs/) 是一项可扩展的管理服务，支持 Docker 容器，允许您轻松地在 Amazon EC2 实例的托管集群上运行分布式应用程序。\nAWS Lambda 可用于依照对事件的响应轻松执行代码，如 Amazon S3 存储桶的更改、Amazon DynamoDB 表的更新或您的应用程序或设备生成的自定义事件。利用 Lambda，您不必预置您自己的实例；Lambda 会代您执行所有的运行和管理活动，包括容量预置、监控服务器队列运行状况、向底层计算资源应用安全补丁、部署您的代码、在前端运行 Web 服务以及监控和记录您的代码。AWS Lambda 为您的代码提供轻松的扩展和高可用性，从而无需您做额外努力。"
    },
    {
        "query":"什么类型的代码可在 AWS Lambda 上运行？",
        "intention":"知识问答",
        "reply":"AWS Lambda 提供了一种简单的方式来完成云中的许多活动。例如，您可以使用 AWS Lambda 构建以下内容：可以检索并转换 Amazon DynamoDB 中数据的移动后端，当对象上传到 Amazon S3 以后对其进行压缩或转换的处理程序，用于任意 Amazon Web Service 的 API 调用的审计和报告功能，使用 Amazon Kinesis 进行的流数据免服务器处理。"
    },
    {
        "query":"AWS Lambda 支持哪些语言？",
        "intention":"知识问答",
        "reply":"AWS Lambda 原生支持 Java、Go、PowerShell、Node.js、C＃、Python 和 Ruby 代码，并提供 Runtime API，允许您使用任何其他编程语言来编写函数。有关使用 [Node.js](http://docs.aws.amazon.com/lambda/latest/dg/authoring-function-in-nodejs.html)、[Python](http://docs.aws.amazon.com/lambda/latest/dg/python-lambda.html)、[Java](http://docs.aws.amazon.com/lambda/latest/dg/java-lambda.html)、[Ruby](https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html)、[C#](http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html)、[Go](https://docs.aws.amazon.com/lambda/latest/dg/go-programming-model.html) 和 [PowerShell](https://docs.aws.amazon.com/lambda/latest/dg/powershell-programming-model.html) 的信息，请参阅我们的文档。"
    },
    {
        "query":"能否访问 AWS Lambda 运行所在的基础设施？",
        "intention":"知识问答",
        "reply":"不能。AWS Lambda 会代您运行计算基础设施，从而执行运行状况检查、应用安全补丁和执行其他例行维护。"
    },
    {
        "query":"AWS Lambda 如何隔离我的代码？",
        "intention":"知识问答",
        "reply":"每个 AWS Lambda 函数都运行在其自己的隔离环境中，有其自己的资源和文件系统视图。AWS Lambda 使用与 Amazon EC2 相同的技术在基础设施和执行级别上提供安全性和隔离。"
    },
    {
        "query":"AWS Lambda 如何保护我的代码安全？",
        "intention":"知识问答",
        "reply":"AWS Lambda 在 Amazon S3 中存储代码并对其进行静态加密。AWS Lambda 在使用您的代码时执行额外的完整性检查。"
    },
    {
        "query":"哪些 AWS 区域提供 AWS Lambda 服务？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 全球基础设施区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"什么是 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您在 AWS Lambda 上运行的代码以“Lambda 函数”上传。每个函数都有相关的配置信息，如其名称、描述、入口点和资源要求。代码必须以“无状态”样式编写，即应假设与底层计算基础设施无密切关系。本地文件系统访问、子过程和类似的项目可能不会超出请求的使用寿命，且任何持续状态都应存储在 Amazon S3、Amazon DynamoDB、Amazon EFS 或另一个可用 Internet 的存储服务中。Lambda 函数可包含库，甚至是本机库。"
    },
    {
        "query":"AWS Lambda 是否会重复使用函数实例？",
        "intention":"知识问答",
        "reply":"为了提高性能，AWS Lambda 可以选择保留您的函数实例，将其再用于服务后续请求，而不是创建一个新副本。要了解有关 Lambda 如何重复使用函数实例的更多信息，请访问我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/lambda-introduction.html)。您的代码不应假设此操作总是发生。"
    },
    {
        "query":"如果需要在磁盘上为 AWS Lambda 函数留下暂存空间，会发生什么？",
        "intention":"知识问答",
        "reply":"您可以为每个 Lambda 函数配置其自己的短暂存储（介于 512MB 与 10240MB 之间，以 1MB 为增量）。短暂存储在每个函数的 /tmp 目录中均可使用。\n每个函数都能免费使用 512MB 的存储空间。使用超过 512MB 的短暂存储配置函数时，将会根据配置的存储量和函数运行的时间计费，以 1 毫秒为增量来计量。相比之下，在美国东部（俄亥俄）区域，AWS Fargate 短暂存储价格为每小时每 GB 0.000111 美元，或每月每 GB 0.08 美元。美国东部（俄亥俄）的 Amazon EBS gp3 存储卷定价为每月每 GB 0.08 美元。AWS Lambda 短暂存储定价为每秒每 GB 0.0000000309 美元，或每小时每 GB 0.000111 美元和每月每 GB 0.08 美元。要了解更多信息，请参阅 [AWS Lambda 定价](https://aws.amazon.com/cn/lambda/pricing/)。"
    },
    {
        "query":"如何配置我的应用程序以使用 AWS Lambda 短暂存储？",
        "intention":"知识问答",
        "reply":"您可以在函数创建或更新期间，使用 AWS Lambda 控制台、AWS Lambda API 或 AWS CloudFormation 模板为每个 Lambda 函数配置其自己的短暂存储（介于 512MB 与 10240MB 之间，以 1MB 为增量）。"
    },
    {
        "query":"AWS Lambda 短暂存储是否加密？",
        "intention":"知识问答",
        "reply":"是。存储在短暂存储中的所有数据都使用 AWS 管理的密钥进行静态加密。"
    },
    {
        "query":"可以使用哪些指标来监控我的 AWS Lambda 短暂存储使用量？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CloudWatch Lambda Insight 指标来监控短暂存储使用量。要了解详情，请参阅 AWS CloudWatch Lambda Insights [文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Lambda-Insights-metrics.html)。"
    },
    {
        "query":"什么时候应该为我的无服务器应用程序使用 Amazon S3、Amazon EFS 或 AWS Lambda 短暂存储？",
        "intention":"知识问答",
        "reply":"如果您的应用程序需要耐用的持久性存储，请考虑使用 Amazon S3 或 Amazon EFS。如果您的应用程序需要在单一函数调用中存储代码所需的数据，请考虑使用 AWS Lambda 短暂存储作为暂时性缓存。要详细了解，请参阅[在 Web 应用程序中选择 AWS Lambda 数据存储选项](https://aws.amazon.com/blogs/compute/choosing-between-aws-lambda-data-storage-options-in-web-apps/)。"
    },
    {
        "query":"在为我的函数启用预置并发时是否可以使用短暂存储？",
        "intention":"知识问答",
        "reply":"是。但是，如果您的应用程序需要持久性存储，请考虑使用 Amazon EFS 或 Amazon S3。当您为函数启用预置并发时，函数的[初始化代码](https://docs.aws.amazon.com/lambda/latest/dg/foundation-progmodel.html)会在分配期间和每隔几个小时运行一次，因为执行中的函数实例会被回收。您可以在实例处理请求后的日志和[跟踪](https://docs.aws.amazon.com/lambda/latest/dg/services-xray.html)中查看初始化时间。但是，即使实例从不处理请求，也会对初始化计费。此预置并发初始化行为可能会影响您的函数与存储在短暂存储中的数据的交互方式，即使您的函数不处理请求也是如此。有关预置并发的详情，请参阅相关[文档](https://docs.aws.amazon.com/lambda/latest/dg/provisioned-concurrency.html)。"
    },
    {
        "query":"如何配置我的应用程序以使用 AWS Lambda 短暂存储？",
        "intention":"知识问答",
        "reply":"您可以在函数创建或更新期间，使用 AWS Lambda 控制台、AWS Lambda API 或 AWS CloudFormation 模板为每个 Lambda 函数配置其自己的短暂存储（介于 512MB 与 10240MB 之间，以 1MB 为增量）。"
    },
    {
        "query":"AWS Lambda 短暂存储是否加密？",
        "intention":"知识问答",
        "reply":"是。存储在短暂存储中的所有数据都使用 AWS 管理的密钥进行静态加密。"
    },
    {
        "query":"可以使用哪些指标来监控我的 AWS Lambda 短暂存储使用量？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CloudWatch Lambda Insight 指标来监控短暂存储使用量。要了解详情，请参阅 AWS CloudWatch Lambda Insights [文档](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Lambda-Insights-metrics.html)。"
    },
    {
        "query":"AWS Lambda 函数为什么必须是无状态的？",
        "intention":"知识问答",
        "reply":"保持函数的无状态性可使 AWS Lambda 按需要尽可能多地启动函数副本，从而扩展到传入事件的速率。由于 AWS Lambda 的编程模式是无状态的，因此您的代码可以通过调用其他 Web 服务，如 Amazon S3 或 Amazon DynamoDB，来访问有状态的数据。"
    },
    {
        "query":"能否在 AWS Lambda 函数代码中使用线程和进程？",
        "intention":"知识问答",
        "reply":"是。AWS Lambda 可使您使用正常的语言和操作系统功能，如创建额外的线程和进程。分配至 Lambda 函数的资源，包括内存、执行时间、磁盘和网络使用，都必须在其使用的所有线程/进程中进行共享。可以使用 Amazon Linux 支持的任意语言启动进程。"
    },
    {
        "query":"哪些限制适用于 AWS Lambda 函数代码？",
        "intention":"知识问答",
        "reply":"Lambda 尝试尽可能不对正常的语言和操作系统活动施加限制，但有些活动仍被禁用：入站网络连接被 AWS Lambda 阻止；对于出站连接，只支持 TCP/IP 和 UDP/IP 套接字；ptrace（调试）系统调用受到限制。TCP 端口 25 流量同样受到阻止，这是一项反垃圾邮件措施。"
    },
    {
        "query":"如何使用 Lambda 控制台创建 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"如果您正在使用 Node.js 或 Python，则可以使用 AWS Lambda 控制台中的代码编辑器来编写函数代码，该编辑器支持编写和测试函数，并在类似 IDE 的稳健环境中查看函数执行的结果。[前往控制台以开始](https://console.aws.amazon.com/lambda/home?region=us-east-1)。\n您也可以将代码（以及任何依赖库）打包为 ZIP 并使用 AWS Lambda 控制台从您的本地环境上传或指定 ZIP 文件所在的 Amazon S3 位置。上传的内容不得超过 50MB（压缩后）。您可以使用 AWS Eclipse 插件以 Java 编写和部署 Lambda 函数。您可以使用 Visual Studio 插件以 C# 和 Node.js 编写和部署 Lambda 函数。"
    },
    {
        "query":"如何使用 Lambda CLI 创建 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以将代码（以及任何依赖库）打包为 ZIP 并使用 AWS CLI 从您的本地环境上传或指定 ZIP 文件所在的 Amazon S3 位置。上传的内容不得超过 50MB（压缩后）。请访问 [Lambda 入门指南](http://docs.aws.amazon.com/lambda/latest/dg/getting-started.html)以开始使用。"
    },
    {
        "query":"AWS Lambda 是否支持环境变量？",
        "intention":"知识问答",
        "reply":"是。使用 AWS Lambda 控制台、命令行界面或软件开发工具包，即可轻松创建和修改环境变量。要了解有关环境变量的更多信息，请参阅该[文档](http://docs.aws.amazon.com/lambda/latest/dg/env_variables.html)。"
    },
    {
        "query":"能否在环境变量中存储敏感信息？",
        "intention":"知识问答",
        "reply":"对于敏感信息（如数据库密码），我们建议您使用 [AWS Key Management Service](http://docs.aws.amazon.com/kms/latest/developerguide/overview.html) 进行客户端加密并将生成的值作为密文存储在您的环境变量中。您需要在 AWS Lambda 函数代码中包含逻辑才能解密这些值。"
    },
    {
        "query":"如何管理我的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Lambda 控制台中的控制面板轻松列出、删除、更新和监控 Lambda 函数。您还可以使用 AWS CLI 和 AWS 软件开发工具包来管理 Lambda 函数。请访问 [Lambda 开发人员指南](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html)了解更多信息。"
    },
    {
        "query":"能否跨函数共享代码？",
        "intention":"知识问答",
        "reply":"可以，您可以将任何代码（框架、软件开发工具包、库等）打包为 [Lambda Layer](https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html)，并在多个函数之间轻松进行管理和共享。"
    },
    {
        "query":"如何监控 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"AWS Lambda 会通过 Amazon CloudWatch 报告实时指标，代您自动监控 Lambda 函数，指标包括请求总数、账户级别和函数级别并发使用情况、延迟、出错率和请求调用。通过 Amazon CloudWatch 控制台或 AWS Lambda 控制台，可以查看每一个 Lambda 函数的统计信息。您还可以在 Lambda 函数中调用第三方监控 API。\n请访问[排查 CloudWatch 指标问题](http://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions.html)了解更多信息。使用 Lambda 的内建指标会依照 AWS Lambda 的标准费率计费。"
    },
    {
        "query":"如何解决 AWS Lambda 函数的故障？",
        "intention":"知识问答",
        "reply":"AWS Lambda 与 Amazon CloudWatch logs 自动集成，对每个 Lambda 函数创建一个日志组并提供基本的应用程序生命周期事件日志条目，包括记录该函数每次使用时所消耗的资源。您可以轻松将额外的日志语句插入到代码中。您还可以在 Lambda 函数中调用第三方日志记录 API。请访问[排查 Lambda 函数问题](http://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions.html)了解更多信息。将按照 Amazon CloudWatch Logs 费率计费。"
    },
    {
        "query":"如何扩展 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您不必扩展 Lambda 函数，AWS Lambda 会代您自动执行扩展。每当接收到您的函数的事件通知时，AWS Lambda 会在其计算队列中快速定位空闲容量并运行您的代码。由于您的代码是无状态的，AWS Lambda 可以在需要时尽可能多地启动实例副本，而不会发生冗长的部署和配置延迟。函数的扩展方面没有基本限制。AWS Lambda 将动态分配容量以匹配传入事件的速率。"
    },
    {
        "query":"如何将计算资源分配至 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"在 AWS Lambda 资源模型中，您可以选择想要为函数分配的内存量，并按 CPU 功率和其他资源的比例进行分配。例如，选择 256MB 的内存时，分配至您的 Lambda 函数的 CPU 功率约是请求 128MB 内存时的两倍，并且是选择 512MB 内存时的一半。要了解更多信息，请参阅我们的[功能配置文档](https://docs.aws.amazon.com/lambda/latest/dg/resource-model.html)。  \n   \n 您可以将内存从 128MB 设置为 10,240MB。"
    },
    {
        "query":"应何时使用内存超过 3008 MB 的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"运行内存或计算密集型工作负载的客户现在可以使用更多内存执行其功能。更大的内存功能可帮助多线程应用程序更快地运行，使其成为数据和计算密集型应用程序（如机器学习、批处理和 ETL 作业、财务建模、基因组学、HPC 和媒体处理）的理想选择。"
    },
    {
        "query":"AWS Lambda 函数的执行需要多长时间？",
        "intention":"知识问答",
        "reply":"AWS Lambda 函数可以配置为每次执行最长运行 15 分钟。您可以将超时设置为 1 秒到 15 分钟之间的任何值。"
    },
    {
        "query":"使用 AWS Lambda 函数将如何付费？",
        "intention":"知识问答",
        "reply":"AWS Lambda 按使用量收费。请参阅 [AWS Lambda 定价页面](https://aws.amazon.com/cn/lambda/pricing/)，以了解详细信息。"
    },
    {
        "query":"我能否通过 Compute Savings Plan 节省 AWS Lambda 成本？",
        "intention":"知识问答",
        "reply":"可以。除了节省 Amazon EC2 和 AWS Fargate 成本之外，您还可以使用 Compute Savings Plans 节省 AWS Lambda 成本。Compute Savings Plans 可提供高达 17% 的持续时间、预置并发和持续时间（预置并发）折扣。Compute Savings Plans 不会在 Lambda 账单中提供请求折扣。但是，Compute Savings Plans 承付额将按常规费率应用至请求。"
    },
    {
        "query":"AWS Lambda 是否支持版本控制？",
        "intention":"知识问答",
        "reply":"是。默认情况下，每个 AWS Lambda 函数拥有一个当前版本的代码。Lambda 函数客户端可调用特定的版本或获取最新的实施。请阅读我们有关 [Lambda 函数版本控制](http://docs.aws.amazon.com/lambda/latest/dg/versioning-aliases.html)的文档。"
    },
    {
        "query":"上传代码后，AWS Lambda 函数需要准备多久进行调用？",
        "intention":"知识问答",
        "reply":"部署时间根据代码大小的不同而不同，但 AWS Lambda 函数一般在上传后几秒钟内就能做好调用准备。"
    },
    {
        "query":"我能否使用自己的支持的库版本？",
        "intention":"知识问答",
        "reply":"是。您可以在其中包含自己的代码库的副本（包括 AWS 软件开发工具包），以使用除 AWS Lambda 所提供的默认版本之外的版本。"
    },
    {
        "query":"分层定价如何运作？",
        "intention":"知识问答",
        "reply":"AWS Lambda 为超过特定阈值的每月按需函数持续时间，提供优惠的定价层。分层定价适用于在 x86 和 Arm 架构上运行的函数。Lambda 定价层适用于账户内，同一区域中采用相同架构（分别为 x86 或 Arm）所运行函数的每月累积按需持续时间。如果您在 AWS Organizations 中使用整合计费，则定价层将适用于跨组织的所有账户，在相同区域，采用相同架构运行的函数的每月累计持续时间。例如，如果您在美国东部（俄亥俄州）区域运行 x86 Lambda 函数，您将为在该区域前 60 亿 GB 秒/月的每 GB 秒支付 0.0000166667 美元，为后 90 亿 GB 秒/月的每 GB 秒支付 0.0000150000 美元，并为每月超过 150 亿 GB 秒/月的每 GB 秒支付 0.0000133334 美元。请求、预配置并发和预配置并发持续时间的定价保持不变。有关更多信息，请参阅 [AWS Lambda 定价](https://aws.amazon.com/lambda/pricing/)。"
    },
    {
        "query":"我是否可以同时利用分层定价和 Compute Savings Plans？",
        "intention":"知识问答",
        "reply":"是。属于您每小时节省计划承诺内的 Lambda 使用量是按[适用的 CSP 费率和折扣](https://aws.amazon.com/cn/savingsplans/compute-pricing/)计费。此承诺未涵盖的剩余使用量将按照您的每月累计函数持续时间所属级别对应的费率进行计费。"
    },
    {
        "query":"什么是事件源？",
        "intention":"知识问答",
        "reply":"事件源是 AWS 服务或开发人员创建的应用程序，用于生成可触发 AWS Lambda 函数使其运行的事件。有些服务通过直接调用云函数（例如 Amazon S3）向 Lambda 发布这些事件。Lambda 也可以在未向 Lambda 发布事件的其他服务中轮询资源。例如，Lambda 可以从 Amazon Kinesis 流或 Amazon SQS 队列中轮询记录，然后针对获得的每条消息执行 Lambda 函数。\n通过登录到 Amazon S3 并使用 S3 存储桶通知，就可将 AWS CloudTrail 等其他很多服务用作触发 AWS Lambda 函数的事件源。"
    },
    {
        "query":"哪些事件源可用于 AWS Lambda？",
        "intention":"知识问答",
        "reply":"有关事件源的完整列表，请参阅我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/intro-core-components.html#intro-core-components-event-sources)。"
    },
    {
        "query":"事件在 AWS Lambda 中如何表示？",
        "intention":"知识问答",
        "reply":"事件以事件输入参数的形式传输到 Lambda 函数中。对于事件在其中批量到达的事件源，如 Amazon SQS、Amazon Kinesis 和 Amazon DynamoDB Streams，根据您请求的批量大小，事件参数可能在单次调用中就包含多个事件。要了解 Amazon S3 事件通知的更多信息，请访问[配置 Amazon S3 事件通知](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)。要了解有关 Amazon DynamoDB Streams 的更多信息，请访问 [DynamoDB 流开发人员指南](http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html)。要了解有关使用 Amazon SNS 调用 Lambda 函数的更多信息，请访问 [Amazon SNS 开发人员指南](http://docs.aws.amazon.com/sns/latest/dg/sns-lambda.html)。有关 Amazon Cognito 事件的更多信息，请访问 [Amazon Cognito](https://aws.amazon.com/cn/cognito/)。有关 AWS CloudTrail 日志和跨 AWS 服务审计 API 调用的更多信息，请参阅 [AWS CloudTrail](https://aws.amazon.com/cn/cloudtrail/)。"
    },
    {
        "query":"如何使用 AWS Lambda 函数对 Amazon S3 存储桶中的更改作出响应？",
        "intention":"知识问答",
        "reply":"您可以从 AWS Lambda 控制台中选择一个函数并将其与 Amazon S3 存储桶中的通知关联起来。或者，您可以使用 Amazon S3 控制台并配置存储桶的通知以发送到您的 AWS Lambda 函数。还可通过 AWS 软件开发工具包和 CLI 实现这一功能。"
    },
    {
        "query":"如何使用 AWS Lambda 函数对 Amazon DynamoDB 表中的更新作出响应？",
        "intention":"知识问答",
        "reply":"通过将 Lambda 函数订阅到与 DynamoDB 表格相关联的 DynamoDB 流，您可以对 DynamoDB 表格更新触发 Lambda 函数。您可以使用 Amazon DynamoDB 控制台、AWS Lambda 控制台或 Lambda 的 registerEventSource API 将 DynamoDB 流与 Lambda 函数关联起来。"
    },
    {
        "query":"如何使用 AWS Lambda 函数处理 Amazon Kinesis 流中的记录？",
        "intention":"知识问答",
        "reply":"您可以从 AWS Lambda 控制台中选择一个 Lambda 函数并将其与属于相同账户的 Amazon Kinesis 流进行关联。还可通过 AWS 软件开发工具包和 CLI 实现这一功能。"
    },
    {
        "query":"AWS Lambda 如何处理来自 Amazon Kinesis 流和 Amazon DynamoDB 流的数据？",
        "intention":"知识问答",
        "reply":"发送到您的 AWS Lambda 函数的 Amazon Kinesis 和 DynamoDB 流记录将根据分片进行严格序列化。这意味着，如果您将两个记录放在同一个分片中，则 Lambda 保证将首先通过第一条记录来调用您的 Lambda 函数，然后再通过第二条记录来调用。如果第一条记录的调用超时，或者遇到任何其他错误，则 Lambda 将重试直至其成功（或者记录达到其 24 小时过期时间），然后才会对下一条记录采取操作。无法保证不同分片之间记录的排序，并且每个分片的处理是平行进行的。"
    },
    {
        "query":"为了满足我的分析需求，我应该如何在 AWS Lambda 和 Amazon Kinesis Data Analytics 之间进行选择？",
        "intention":"知识问答",
        "reply":"AWS Lambda 允许您在短时间内（最多不超过 15 分钟），在单个逻辑分区（如一个分片）上对 Amazon Kinesis 或 Amazon DynamoDB Streams 中的数据执行基于时间的聚合（如计数、最大值、总和、平均值等）。这使您可以选择为基于事件的应用程序轻松设置简单的分析，而不会增加架构的复杂性，因为您的业务和分析逻辑可以位于同一个函数中。Lambda 允许根据事件时间戳，在最多 15 分钟的滚动窗口内进行聚合。[Amazon Kinesis Data Analytics](https://aws.amazon.com/cn/kinesis/data-analytics/) 允许您构建更复杂的分析应用程序，以支持灵活的处理选择和强大的容错能力，只需进行一次精确的处理，而不会重复，并且可以跨多个逻辑分区对整个数据流执行分析。借助 KDA，您可以使用事件时间或处理时间分析多种类型的聚合窗口（滚动窗口、交错窗口、滑动窗口、会话窗口）中的数据。\n|  | AWS Lambda | Amazon KDA |\n| --- | --- | --- |\n| 滚动窗口 | 是 | 是 |\n| 交错窗口 | 否 | 是 |\n| 滑动窗口 | 否 | 是 |\n| 会话窗口 | 否 | 是 |\n| 丰富 | 否 | 是 |\n| 联合输入表和参考表 | 否 | 是 |\n| 拆分输入流 | 否 | 是 |\n| 一次处理 | 否 | 是 |\n| 最大时间窗口 | 15 分钟 | 没有限制 |\n| 聚合范围 | 分区/分片 | 流 |\n| 时间语义 | 事件时间 | 事件时间、处理时间 |"
    },
    {
        "query":"如何使用 AWS Lambda 函数响应 Amazon Simple Notification Service (SNS) 发出的通知？",
        "intention":"知识问答",
        "reply":"您可以从 AWS Lambda 控制台中选择一个 Lambda 函数并将其与 Amazon SNS 主题进行关联。还可通过 AWS 软件开发工具包和 CLI 实现这一功能。"
    },
    {
        "query":"如何使用 AWS Lambda 函数响应 Amazon Simple Email Service (SES) 发送的电子邮件？",
        "intention":"知识问答",
        "reply":"在 Amazon SES 控制台中，您可以设置接收规则，以使 Amazon SES 将消息交付到 AWS Lambda 函数。还可通过 AWS 软件开发工具包和 CLI 实现这一功能。"
    },
    {
        "query":"如何使用 AWS Lambda 函数响应 Amazon CloudWatch 警报？",
        "intention":"知识问答",
        "reply":"首先应配置警报，使其发送 Amazon SNS 通知。然后从 AWS Lambda 控制台中选择一个 Lambda 函数并将其与 Amazon SNS 主题进行关联。请参阅 [Amazon CloudWatch 开发人员指南](http://docs.aws.amazon.com/AmazonCloudWatch/latest/DeveloperGuide/WhatIsCloudWatch.html)，了解有关设置 Amazon CloudWatch 警报的更多信息。"
    },
    {
        "query":"如何使用 AWS Lambda 函数响应由 Amazon Cognito 管理的用户或设备数据的变更？",
        "intention":"知识问答",
        "reply":"您可以从 AWS Lambda 控制台中选择一个函数，当与 [Amazon Cognito](https://aws.amazon.com/cn/cognito/) 身份池关联的任何数据集进行同步时，触发这个函数。还可通过 AWS 软件开发工具包和 CLI 实现这一功能。请访问 Amazon Cognito，了解有关使用 Amazon Cognito 在用户设备间共享和同步数据的更多信息。"
    },
    {
        "query":"应用程序如何直接触发 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS Lambda 的调用 API 使用自定义事件调用 Lambda 函数。只有该函数的所有者或获得该所有者授权的另一个 AWS 账户才能调用该函数。请访问 [Lambda 开发人员指南](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html)了解更多信息。"
    },
    {
        "query":"调用 AWS Lambda 函数响应事件的延迟如何？",
        "intention":"知识问答",
        "reply":"AWS Lambda 经过专门设计，可在数毫秒内处理事件。当 Lambda 函数创建、更新后，或如果最近未使用函数，延迟都将立即升高。"
    },
    {
        "query":"如何使用 AWS Lambda 创建移动后端？",
        "intention":"知识问答",
        "reply":"上传需要 AWS Lambda 执行的代码，然后使用 AWS 移动软件开发工具包中的 AWS Lambda 软件开发工具包从移动应用程序中对其进行调用。您可以进行直接（同步）调用来检索或实时查看数据，也可以进行异步调用。您还可以使用 Amazon API Gateway 定义自定义 API，并通过兼容 REST 的任何客户端调用您的 Lambda 函数。要了解有关 AWS 移动软件开发工具包的更多信息，请访问 [AWS 移动软件开发工具包](https://aws.amazon.com/cn/mobile/sdk/)页面。要了解有关 Amazon API Gateway 的更多信息，请访问 [Amazon API Gateway](https://aws.amazon.com/cn/api-gateway/) 页面。"
    },
    {
        "query":"如何通过 HTTPS 调用 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"通过使用 Amazon API Gateway 定义自定义的 RESTful API，您可以通过 HTTPS 调用 Lambda 函数。这为您的函数提供了终端节点，这些函数可以响应 GET、PUT 和 POST 等 REST 调用。了解有关通过 Amazon API Gateway 使用 AWS Lambda 的更多信息。"
    },
    {
        "query":"AWS Lambda 函数如何根据发起请求的设备和应用程序对其行为进行自定义？",
        "intention":"知识问答",
        "reply":"当通过 AWS 移动软件开发工具包进行调用时，AWS Lambda 函数能自动通过“context”对象深入了解发起调用的设备和应用程序。"
    },
    {
        "query":"AWS Lambda 函数如何根据应用程序最终用户的身份对其行为进行个性化设置？",
        "intention":"知识问答",
        "reply":"当应用程序使用 Amazon Cognito 身份时，最终用户可以使用各种公共登录供应商（包括 Amazon、Facebook、Google）及其他 OpenID Connect 兼容服务来对其进行验证。之后用户身份会自动加密并以 Amazon Cognito Id 的形式呈送给 Lambda 函数，同时允许其访问 Amazon Cognito 中的用户数据，或作为密钥储存和检索 Amazon DynamoDB 或其他 Web 服务中的数据。"
    },
    {
        "query":"如何使用 AWS Lambda 创建 Alexa 技能？",
        "intention":"知识问答",
        "reply":"AWS Lambda 与 Alexa 技能套件集成，后者是一个自助 API、工具、文档和代码示例集合，让您能够为 Alexa 轻松创建以语音为主的能力（或“技能”）。您只需为要创建的新 Alexa 技能上传 Lambda 函数代码，AWS Lambda 将完成剩余工作，包括执行代码以响应 Alexa 语音交互，并代表您自动管理计算资源。有关更多详细信息，请阅读 Alexa 技能套件文档。"
    },
    {
        "query":"如果函数在处理事件时发生故障会怎么样？",
        "intention":"知识问答",
        "reply":"对于 Amazon S3 存储桶通知和自定义事件，AWS Lambda 会在您的代码发生错误条件或您超出服务或资源限制时尝试执行您的函数三次。  \n   \n 对于 AWS Lambda 代您轮询的有序事件源，如 Amazon DynamoDB 流和 Amazon Kinesis Streams，Lambda 将在发生开发人员代码错误时继续尝试执行，直到该数据过期为止。您可以通过 Amazon Kinesis 和 Amazon DynamoDB 控制台以及 AWS Lambda 为您的函数生成的 Amazon CloudWatch 指标监控进展情况。您还可以根据出错率或执行限制的频率来设置 Amazon CloudWatch 警报。"
    },
    {
        "query":"什么是无服务器应用程序？",
        "intention":"知识问答",
        "reply":"基于 Lambda 的应用程序（也称为无服务器应用程序）由通过事件触发的函数组成。典型的无服务器应用程序包含一个或多个通过事件（如向 Amazon S3 上传对象、Amazon SNS 通知或 API 操作）触发的函数。这些函数既可独立运行，也能利用其他资源（如 DynamoDB 表或 Amazon S3 存储桶）。最基本的无服务器应用程序仅包含一个函数。"
    },
    {
        "query":"如何部署和管理无服务器应用程序？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 无服务器应用程序模型 (AWS SAM) 部署和管理无服务器应用程序。AWS SAM 是一项规范，其中规定了在 AWS 上表达无服务器应用程序的规则。该规范当前与 AWS CloudFormation 使用的语法相同，因此本身就在 AWS CloudFormation 中作为一组资源类型（被称作“无服务器资源”）受支持。得力于这些资源，AWS 客户能够更轻松地使用 CloudFormation 通过现有 CloudFormation API 配置和部署无服务器应用程序。"
    },
    {
        "query":"如何发现 AWS 社区开发的现有无服务器应用程序？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Serverless Application Repository](https://aws.amazon.com/cn/serverless/serverlessrepo/) 从 AWS 社区的开发人员、公司和合作伙伴发布的无服务器应用程序集合中进行选择。找到应用程序后，您可以直接从 [Lambda 控制台](https://console.aws.amazon.com/lambda/home?region=us-east-1)配置和部署该应用程序。"
    },
    {
        "query":"如何自动部署无服务器应用程序？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS CodePipeline 和 AWS CodeDeploy 自动执行无服务器应用程序的发布过程。CodePipeline 是一项持续交付服务，借助该服务，您能够为发布无服务器应用程序所需的步骤构建模型、使之可视化并自动执行这些步骤。CodeDeploy 为基于 Lambda 的应用程序提供了部署自动化引擎。您可以使用 CodeDeploy 根据既定最佳实践方法（如 Canary 和线性部署）编排部署，帮助您建立必要的防护以验证新部署的代码是否安全、稳定并已经准备好完全发布到生产环境。\n要了解有关无服务器 CI/CD 的更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/automating-deployment.html)。"
    },
    {
        "query":"如何开始构建无服务器应用程序？",
        "intention":"知识问答",
        "reply":"首先，请访问 AWS Lambda 控制台，并下载我们的蓝图之一。您下载的文件将包含一份 AWS SAM 文件（定义了您应用程序中的 AWS 资源）和一份 .ZIP 文件（包含您函数的代码）。然后，您可以使用 AWS CloudFormation 命令打包和部署刚下载的无服务器应用程序。有关更多详细信息，请访问我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/deploying-lambda-apps.html)。"
    },
    {
        "query":"如何协调多个 AWS Lambda 函数之间的调用？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS Step Functions](https://aws.amazon.com/cn/step-functions/) 以特定顺序来协调一系列 AWS Lambda 函数。您可以按顺序调用多个 Lambda 函数，然后将一个函数的输出传递到另一个函数，也可以进行并行调用，Step Functions 将在执行期间为您保持状态。"
    },
    {
        "query":"如何排除无服务器应用程序的故障？",
        "intention":"知识问答",
        "reply":"您可以启用 Lambda 函数利用 [AWS X-Ray](https://aws.amazon.com/cn/xray/) 进行跟踪的功能，方式为将 X-Ray 的权限添加到 Lambda 函数的执行角色，然后将函数的“跟踪模式”更改为“激活”。 针对 Lambda 函数启用 X-Ray 之后，AWS Lambda 会将调用函数产生的 Lambda 服务开销方面的跟踪信息发送到 X-Ray。这样，您就能了解 Lambda 服务开销、函数启动时间和函数执行时间等信息。此外，您还可以将 X-Ray 开发工具包纳入 Lambda 部署程序包中，以便创建自己的跟踪段、为跟踪添加注释或者查看从 Lambda 函数进行的下游调用的跟踪段。X-Ray 开发工具包目前支持 Node.js 和 Java。请访问[对基于 Lambda 的应用程序进行故障排除](http://docs.aws.amazon.com/lambda/latest/dg/lambda-x-ray.html)了解更多信息。我们会按 AWS X-Ray 的费率收取费用。"
    },
    {
        "query":"我可以构建连接到关系数据库的无服务器应用程序吗？",
        "intention":"知识问答",
        "reply":"可以。您可以构建高度可扩展、安全、基于 Lambda 的无服务器应用程序，这些应用程序使用 [Amazon RDS 代理](https://aws.amazon.com/cn/rds/proxy/)（一种高度可用的数据库代理）连接到关系数据库，该代理可管理与关系数据库的数千个并发连接。当前，RDS 代理支持 MySQL 和 Aurora 数据库。您可以通过 Amazon RDS 控制台或 AWS Lambda 控制台开始使用 RDS 代理。使用 RDS 代理中完全托管的连接池的无服务器应用程序将根据 [RDS 代理定价](https://aws.amazon.com/cn/rds/proxy/pricing/)进行计费。"
    },
    {
        "query":"AWS SAM 如何获得许可证？",
        "intention":"知识问答",
        "reply":"该规范在 Apache 2.0 下是开源性质的，允许您及他人采用构建、部署、监控和管理工具以及通过商业版许可证将 AWS SAM 融合到这些工具中。您可以在[此处](https://github.com/awslabs/serverless-application-specification)访问 GitHub 上的 AWS SAM 存储库。"
    },
    {
        "query":"什么是 AWS Lambda 的容器映像支持？",
        "intention":"知识问答",
        "reply":"AWS Lambda 现在让您能够将函数打包并部署为容器映射。客户可以利用容器工具的灵活性和熟悉度，以及 AWS Lambda 的敏捷性和操作简单性来构建应用程序。"
    },
    {
        "query":"如何使用 AWS Lambda 的容器映像支持？",
        "intention":"知识问答",
        "reply":"您可以从 AWS 提供的 Lambda 基本映像开始，也可以使用首选的社区或私有企业映像之一。然后，只需使用 Docker CLI 生成映像，上传到 Amazon ECR，再使用所有熟悉的 Lambda 接口和工具（例如 AWS 管理控制台、AWS CLI、AWS SDK、AWS SAM 和 AWS CloudFormation）创建函数。"
    },
    {
        "query":"支持哪些容器映像类型？",
        "intention":"知识问答",
        "reply":"除了 Lambda 提供的映像外，您还可以将第三方 Linux 基础映像（如 Alpine 或 Debian）部署到 Lambda。AWS Lambda 将支持基于以下映像清单格式的所有映像：Docker Image Manifest V2 Schema 2（与 Docker 1.10 及更高版本一起使用）或 Open Container Initiative (OCI) Spec（v1.0 及更高版本）。Lambda 支持最大 10GB 的映像。"
    },
    {
        "query":"可以使用哪些基础映像？",
        "intention":"知识问答",
        "reply":"AWS Lambda 提供了客户可以扩展的各种基础映像，客户还可以使用其首选的基于 Linux 的映像，大小不超过 10GB。"
    },
    {
        "query":"可以使用哪些容器工具将函数打包和部署为容器映像？",
        "intention":"知识问答",
        "reply":"您可以使用任何容器工具，只要它支持以下容器映像清单格式之一：Docker Image Manifest V2 Schema 2（与Docker 1.10 及更高版本一起使用）或 Open Container Initiative (OCI) Specifications（v1.0 及更高版本）。例如，您可以使用本机容器工具（即 docker run、docker compose、Buildah 和 Packer）将您的函数定义为容器映像并部署到 Lambda。"
    },
    {
        "query":"作为容器映像部署的函数可以使用哪些 AWS Lambda 功能？",
        "intention":"知识问答",
        "reply":"除 Lambda 层和代码签名外，所有现有的 AWS Lambda 功能都可以与部署为容器映像的函数一起使用。部署后，AWS Lambda 会将映像视为不可变。客户可以在构建过程中使用容器层来包含依赖项。"
    },
    {
        "query":"AWS Lambda 是否会对我部署的容器映像进行修补和更新？",
        "intention":"知识问答",
        "reply":"目前不会。您的映像一旦部署到 AWS Lambda，将是不可更改的。该服务不会对映像进行修补或更新。但是，AWS Lambda 将为所有基于 Lambda 托管环境的受支持运行时发布精选基本映像。这些发布的映像将与 AWS Lambda 托管运行时的更新一起进行修补和更新。您可以从 DockerHub 或 Amazon ECR Public 中提取并使用最新的基本映像，重新构建您的容器映像，并通过 Amazon ECR 部署到 AWS Lambda。这样，您可以在将映像部署到生产中之前，构建和测试更新的映像和运行时。"
    },
    {
        "query":"使用 ZIP 存档创建的函数与使用容器映像创建的函数之间有什么不同？",
        "intention":"知识问答",
        "reply":"使用 ZIP 存档创建的函数与使用容器映像创建的函数之间有三个主要区别："
    },
    {
        "query":"定义为 zip 的函数和定义为容器映像的函数在性能上是否有差异？",
        "intention":"知识问答",
        "reply":"没有 - AWS Lambda 确保打包为容器映像的函数的性能配置文件与打包为 ZIP 存档的函数相同，包括通常亚秒级的启动时间。"
    },
    {
        "query":"什么是 Lambda Runtime Interface Emulator (RIE)？",
        "intention":"知识问答",
        "reply":"Lambda Runtime Interface Emulator 是 Lambda [Runtime API](https://docs.aws.amazon.com/lambda/latest/dg/runtimes-api.html) 的代理，它允许客户在本地测试打包为容器映像的 Lambda 函数。它是一个轻量级的 Web 服务器，可以将 HTTP 请求转换为 JSON 事件，并模拟 Lambda Runtime API。它允许您使用熟悉的工具，例如 cURL 和 Docker CLI（当测试打包为容器映像的函数时），在本地测试您的函数。它还简化了在其他计算服务上运行应用程序的过程。您可以在容器映像中包括 Lambda Runtime Interface Emulator，使其以原生方式接受 HTTP 请求，而不是部署到 Lambda 所需的 JSON 事件。该组件不会模拟 Lambda 的协调器或安全和身份验证配置。Runtime Interface Emulator 在 GitHub 上开源。在本地计算机上下载并安装 Runtime Interface Emulator，即可开始使用。"
    },
    {
        "query":"为什么在本地测试期间需要 Lambda Runtime Interface Emulator (RIE)？",
        "intention":"知识问答",
        "reply":"正在运行的 Lambda 服务中的 Lambda Runtime API 接受 JSON 事件并返回响应。Lambda Runtime Interface Emulator 允许打包成容器映像的函数在本地测试期间使用 cURL 等工具接受 HTTP 请求，并通过相同的接口在本地将它们呈现到函数中。它允许您使用 docker run 或 docker-compose up 命令在本地测试您的 lambda 应用程序。"
    },
    {
        "query":"我可以用该模拟器在本地测试哪些函数行为？",
        "intention":"知识问答",
        "reply":"您可以使用该模拟器来测试您的函数代码是否与 Lambda 环境兼容，是否成功运行并提供预期的输出。例如，您可以模拟来自不同事件源的测试事件。您还可以使用它根据 Lambda Extensions API 测试容器映像中内置的扩展和代理。"
    },
    {
        "query":"Runtime Interface Emulator (RIE) 如何帮助我在其他计算服务上运行我的 Lambda 兼容映像？",
        "intention":"知识问答",
        "reply":"客户可以将 Runtime Interface Emulator 添加为容器映像的接入点，也可以将其打包为 Sidecar，以确保容器映像现在接受 HTTP 请求而不是 JSON 事件。这简化了在其他计算服务上运行其容器映像所需的更改。客户将负责确保他们遵循所选环境的所有安全性、性能和并发最佳实践。RIE 已预先打包到 AWS Lambda 提供的映像中，并在 AWS SAM CLI 中默认可用。基础映像提供商可以使用[文档](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)为其基础映像提供相同的体验。"
    },
    {
        "query":"如何将现有的容器化应用程序部署到 AWS Lambda？",
        "intention":"知识问答",
        "reply":"如果满足以下要求，则可以将容器化应用程序部署到 AWS Lambda："
    },
    {
        "query":"什么是 AWS Lambda 预配置并发？",
        "intention":"知识问答",
        "reply":"预配置并发使您能够更好地控制无服务器应用程序的性能。启用后，预配置并发将使函数保持初始化状态，并准备好在两位数毫秒内进行响应。"
    },
    {
        "query":"如何设置和管理预配置并发？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台、Lambda API、AWS CLI 和 AWS CloudFormation 在函数上配置并发。利用预配置并发功能的最简单方法是使用 AWS Auto Scaling。您可以使用 Application Auto Scaling 来配置计划，或者让 Auto Scaling 随着需求的变化自动实时调整预配置并发量。有关预配置并发的更多信息，请参阅[文档](https://docs.aws.amazon.com/lambda/latest/dg/configuration-concurrency.html )。"
    },
    {
        "query":"如果要使用预配置并发，是否需要更改代码？",
        "intention":"知识问答",
        "reply":"您无需对代码进行任何更改即可使用预配置并发。它可以与所有现有函数和运行时无缝地协同工作。使用预配置并发时，Lambda 的调用和执行模型没有任何变化。"
    },
    {
        "query":"我应何时使用预配置并发？",
        "intention":"知识问答",
        "reply":"预配置并发是构建延迟敏感型应用程序（例如 Web 或移动后端、同步调用的 API 和交互式微服务）的理想选择。您可以根据应用程序的独特需求轻松配置适当的并发量。您可以在需求量高时增加并发量，或在需求减少时降低并发量，或者完全关闭它。"
    },
    {
        "query":"如果函数收到的调用超过配置的预配置并发量，会怎么样？",
        "intention":"知识问答",
        "reply":"如果函数的并发达到配置的并发量，则该函数的后续调用将具有常规 Lambda 函数的延迟和缩放特性。您可以将函数限制为仅扩展到配置的并发量。这样做可以防止函数超出配置的并发量。当需求超过预期数量时，此机制可以防止应用程序发生意外变化。"
    },
    {
        "query":"什么是由 Graviton 2 处理器提供支持的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"AWS Lambda 能让您在 x86 架构或 Arm 架构的处理器上运行您的函数。AWS Graviton2 处理器由 Amazon Web Services 使用 64 位 Arm Neoverse 内核定制而成，为您的云工作负载提供更好的性价比。客户同样能够获得 AWS Lambda 所带来的益处，例如在无需预置或管理服务器的情况下运行代码、弹性伸缩、高可用性，以及按实际用量支付资源费用。"
    },
    {
        "query":"我为什么要使用由 Graviton 2 处理器提供支持的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"由 Graviton2 提供支持的 AWS Lambda 采用由 AWS 设计的 Arm 处理器架构，致力于性价比提升 34%（相较于在 x86 处理器上运行的函数），并适用于多种无服务器工作负载，例如 Web 和移动后端、数据以及流式传输处理。Graviton2 函数拥有更低的延迟、性价比提升高达 19%、成本可降低 20%，且拥有 AWS 中当前最高的能效，能够为任务关键型无服务器应用程序提供支持。客户能够配置现有及新函数，以搭配 Graviton2 处理器。他们能够将在 Graviton2 上运行的函数部署为 zip 格式文件或容器镜像。"
    },
    {
        "query":"我要如何配置函数以使其在 Graviton2 处理器上运行？",
        "intention":"知识问答",
        "reply":"您可以通过将函数的架构标志设置为“arm64”，从而借助 AWS 管理控制台、AWS Lambda API、AWS CLI 和 AWS CloudFormation 来配置函数，使其在 Graviton2 上运行。"
    },
    {
        "query":"我要如何使用由 Graviton2 处理器提供支持的函数部署我的应用程序？",
        "intention":"知识问答",
        "reply":"基于 x86 的函数与基于 Arm 的函数操作之间没有区别。只需将您的代码通过 AWS 管理控制台、zip 格式文件或容器镜像上载，随后 AWS Lambda 将在触发时自动运行您的代码，而无需您进行预置或管理基础设施。"
    },
    {
        "query":"应用程序能够同时使用由 Graviton2 处理器和 x86 处理器提供支持的函数吗？",
        "intention":"知识问答",
        "reply":"应用程序可以同时包含在两种架构上运行的函数。AWS Lambda 使您可以更换函数当前版本的架构（“x86\\_64”或“arm64”）。当您创建了函数的特定版本后，架构将无法更改。"
    },
    {
        "query":"AWS Lambda 是否支持多架构容器镜像？",
        "intention":"知识问答",
        "reply":"不支持。每个函数版本只能使用单一容器镜像。"
    },
    {
        "query":"我能否针对由 AWS Graviton2 处理器支持的函数创建 AWS Lambda 层？",
        "intention":"知识问答",
        "reply":"可以。您可以针对“x86\\_64”或“arm64”可兼容架构创建层及扩展。适用于函数与层的默认架构为“x86\\_64”。"
    },
    {
        "query":"在 Graviton2 处理器上运行的 Lambda 函数支持哪种语言和运行时？",
        "intention":"知识问答",
        "reply":"在启动时，客户可以使用 Python、Node.js、Java、Ruby、Net Core、Custom Runtime (provided.al2) 和 OCI Base 镜像。要了解更多信息，请参阅 [AWS Lambda 运行时](https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html)。"
    },
    {
        "query":"由 AWS Graviton 2 处理器提供支持的 AWS Lambda 函数的定价策略是什么？ AWS Lambda 免费套餐适用于由 Graviton2 支持的函数吗？",
        "intention":"知识问答",
        "reply":"AWS Graviton2 处理器支持的 AWS Lambda 函数相较基于 x86 的 Lambda 函数价格低 20%。Lambda 免费套餐适用于由基于 x86 和 Arm 架构支持的 AWS Lambda 函数。"
    },
    {
        "query":"是在 Graviton2 处理器还是 x86 处理器上运行我的函数，我该如何选择？",
        "intention":"知识问答",
        "reply":"需要根据工作负载的情况具体分析，我们建议客户先行测试自己的函数，以确定可能带来的性价比提升。为此，我们建议使用 [AWS Lambda Power Tuning](https://github.com/alexcasalboni/aws-lambda-power-tuning) 工具。我们建议先从 Web 和移动后端、数据以及流式传输处理开始，以测试您的工作负载，了解是否存在提升性价比的可能。"
    },
    {
        "query":"我是否需要一个基于 Arm 的开发机器以在本地创建、构建并测试由 Graviton2 处理器支持的函数？",
        "intention":"知识问答",
        "reply":"Python、Java 及 Node 等解释语言通常不需要重新编译，除非您的代码参考库使用的架构包含特别组件。在这种情况下，您需要针对 arm64 提供库。有关更多详细信息，请参阅 [AWS Graviton 入门](https://github.com/aws/aws-graviton-getting-started)页面。非解释语言将需要您编译代码以适用于 arm64。但更多的现代编译者将生成适用于 arm64 的编译后代码，您需要将其部署到基于 arm 的环境进行测试。要了解有关使用 Graviton2 支持的 Lambda 函数的详情，请参阅[文档](https://docs.aws.amazon.com/lambda/latest/dg/foundation-arch.html)。"
    },
    {
        "query":"什么是 Amazon EFS for AWS Lambda？",
        "intention":"知识问答",
        "reply":"借助 Amazon Elastic File System (Amazon EFS) for AWS Lambda，客户可以使用完全托管的弹性 NFS 文件系统以几乎任意规模安全地读取、写入持久和存储大量数据，该系统可以按需扩展，而无需进行预置或容量管理。此前，开发人员在其函数中添加了代码，将数据从 S3 或数据库下载到本地临时存储，限值为 512MB。使用 EFS for Lambda，开发人员不需要编写代码就可以将数据下载到临时存储中进行处理。"
    },
    {
        "query":"如何设置 Amazon EFS for Lambda？",
        "intention":"知识问答",
        "reply":"开发人员可以使用控制台、CLI 或开发工具包通过 [EFS 访问点](https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html)轻松地将现有 EFS 文件系统连接到 Lambda 函数。首次调用该函数时，文件系统将自动安装并可供函数代码使用。有关更多信息，请参阅本文档。"
    },
    {
        "query":"在使用 Amazon EFS 文件系统之前，是否需要使用 VPC 设置配置函数？",
        "intention":"知识问答",
        "reply":"是。Amazon EFS 的安装目标与 VPC 中的子网相关。需要配置 AWS Lambda 函数才能访问该 VPC。  \n   \n 问：谁应该使用 Amazon EFS for Lambda？\nEFS for Lambda 非常适合于构建机器学习应用程序或加载大型参考文件或模型、处理或备份大量数据、托管 Web 内容或开发内部构建系统。客户还可以使用 EFS for Lambda 在有状态的微服务架构中、 在 Step Functions 工作流中或在无服务器应用程序与基于实例或容器的应用程序之间共享文件时保持调用之间的状态。"
    },
    {
        "query":"我的数据在传输过程中会被加密吗？",
        "intention":"知识问答",
        "reply":"是。动态数据加密是按照行业标准传输层安全性 (TLS) 1.2 来加密 AWS Lambda 函数和 Amazon EFS 文件系统之间发送的数据。"
    },
    {
        "query":"我的数据在静态时会被加密吗？",
        "intention":"知识问答",
        "reply":"客户可以预置 Amazon EFS 以加密静态数据。数据在静态时以透明的方式加密，在读取时以透明的方式解密，因此您无需修改应用程序。加密密钥由 AWS Key Management Service (KMS) 托管，无需构建和维护安全的密钥管理基础设施。"
    },
    {
        "query":"可以将多个 Amazon EFS 文件系统与 AWS Lambda 函数关联吗？",
        "intention":"知识问答",
        "reply":"不可以。每个 Lambda 函数将能够访问一个 EFS 文件系统。"
    },
    {
        "query":"可以跨多重函数、容器和实例使用同一个 Amazon EFS 文件系统吗？",
        "intention":"知识问答",
        "reply":"可以。Amazon EFS 支持 Lambda 函数、 ECS 和 Fargate 容器以及 EC2 实例。您可以共享同一文件系统，并使用 IAM 策略和访问点来控制有权访问的每个函数、容器或实例。"
    },
    {
        "query":"什么是 AWS Lambda 扩展程序？",
        "intention":"知识问答",
        "reply":"借助 AWS Lambda 扩展程序，您可以将 AWS Lambda 与您喜欢的监控、可观测性、安全性和监管工具集成。扩展程序让您和您的首选工具供应商能够了解 Lambda 的生命周期，并进一步深入集成到 Lambda 执行环境中。"
    },
    {
        "query":"Lambda 扩展程序的工作原理是什么？",
        "intention":"知识问答",
        "reply":"扩展程序是在 Lambda 的执行环境（也就是执行您函数代码的环境）中运行的配套进程。此外，您可以在函数调用之外运行（即，它们在函数初始化之前启动，与函数并行运行），可以在函数执行完成之后运行，也可以在 Lambda 服务关闭执行环境之前运行。"
    },
    {
        "query":"Lambda 扩展程序有哪些用途？",
        "intention":"知识问答",
        "reply":"您可以将扩展程序用于由 AWS 和以下合作伙伴提供的常用监控、可观测性、安全性和监管工具：AppDynamics、Coralogix、Datadog、Dynatrace、Epsagon、HashiCorp、Honeycomb、Imperva、Lumigo、Check Point CloudGuard、New Relic、Thundra、Splunk、Sentry、Site24x7、Sumo Logic、AWS AppConfig、Amazon CodeGuru Profiler、Amazon CloudWatch Lambda Insights、AWS Distro for OpenTelemetry。要了解有关扩展程序的更多信息，请访问[发布博客文章](https://aws.amazon.com/blogs/aws/getting-started-with-using-your-favorite-operational-tools-on-aws-lambda-extensions-are-now-generally-available/)。"
    },
    {
        "query":"如何设置和管理 Lambda 扩展程序？",
        "intention":"知识问答",
        "reply":"您可以通过控制台、CLI 或 CloudFormation、AWS Serverless Application Model 以及 Terraform 等基础设施即代码工具在一个或多个 Lambda 函数上使用分层来部署扩展程序。要开始使用，[请参阅文档](https://docs.aws.amazon.com/lambda/latest/dg/using-extensions.html)。"
    },
    {
        "query":"可以将 AWS Lambda 扩展程序与哪些运行时配合使用？",
        "intention":"知识问答",
        "reply":"您可以在[此处](https://docs.aws.amazon.com/lambda/latest/dg/using-extensions.html)查看支持扩展程序的运行时列表。"
    },
    {
        "query":"扩展程序是否计入部署程序包限制？",
        "intention":"知识问答",
        "reply":"是，函数和所有扩展程序解压后的总大小不得超过解压后的部署程序包大小限制，即 250MB。"
    },
    {
        "query":"使用扩展程序是否会影响性能？",
        "intention":"知识问答",
        "reply":"扩展程序可能会影响函数的性能，因为它们与函数共用 CPU、内存和存储等资源，而且扩展程序是在函数代码之前初始化的。例如，如果扩展程序执行计算密集型操作，那么您可能会发现函数的执行时间增加，这是因为扩展程序和函数代码共用相同的 CPU 资源。Lambda 根据您选择的内存设置，按比例分配 CPU 计算能力，因此您会发现当使用更低的内存设置时，执行和初始化持续时间会延长，因为更多的进程会争抢有限的 CPU 资源。\n您可以使用 *PostRuntimeExecutionDuration* 指标来衡量在函数执行之后扩展程序花费的额外时间，并且可以使用 MaxMemoryUsed 指标来衡量使用的内存的增长情况。要了解某个特定扩展程序的影响，您还可以使用持续时间指标。目前，函数执行响应会在函数执行和扩展程序执行完成后返回。请参阅 [Lambda 开发人员文档](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)，了解更多信息。"
    },
    {
        "query":"使用 Lambda 扩展程序如何付费？",
        "intention":"知识问答",
        "reply":"扩展程序的计费方式与 Lambda 函数相同。使用带有扩展程序的 Lambda 函数时，您需要为使用的请求以及用于运行代码和所有扩展程序的总计算时间（以 1 毫秒为增量）付费。您需要根据当前的 Lambda 持续时间定价为计算时间付费。要了解更多信息，请参阅 [AWS Lambda 定价](https://aws.amazon.com/cn/lambda/pricing/)。\nLambda 生命周期分为三个不同的阶段：“init”阶段，AWS Lambda 将函数、依赖项和扩展程序初始化；“invoke”阶段，Lambda 执行函数和扩展程序代码以便响应触发器；“shut down”阶段，函数执行完成，但扩展程序代码仍在执行并可能持续最多两秒钟时间。您需要为用于在 Lambda 生命周期的所有三个阶段运行您的扩展程序代码的计算时间付费。要了解有关 Lambda 生命周期的更多信息，请参阅有关 Lambda 执行环境的文档。\n安装扩展程序无需额外付费，但使用合作伙伴的产品可能需要付费。请前往相关合作伙伴网站了解详细信息。"
    },
    {
        "query":"我是否可以创建自己的自定义 Lambda 扩展程序？",
        "intention":"知识问答",
        "reply":"可以，您可以使用 AWS Lambda Runtime Extensions API 进行创建。访问文档了解更多信息。"
    },
    {
        "query":"启用预置并发后，扩展程序如何工作？",
        "intention":"知识问答",
        "reply":"预置并发将函数保持在初始化状态，并准备好在一百毫秒内进行响应。启用后，预置并发还会将扩展程序初始化并让扩展程序准备好与函数代码一起执行。"
    },
    {
        "query":"扩展程序有哪些权限？",
        "intention":"知识问答",
        "reply":"由于扩展程序的执行环境与 Lambda 函数相同，扩展程序可以使用与函数相同的资源，并且与函数共享权限。因此它们共享凭证、角色和环境变量。扩展程序拥有对函数代码的只读访问权限，并且可以在 /tmp 中进行读写。"
    },
    {
        "query":"什么是 AWS Lambda Telemetry API？",
        "intention":"知识问答",
        "reply":"AWS Lambda Telemetry API 使您能够使用扩展程序直接从 Lambda 捕获增强的监控和可观测性数据，并将其发送到您选择的目的地。"
    },
    {
        "query":"Telemetry API 是如何工作的？",
        "intention":"知识问答",
        "reply":"Lambda 服务自动捕获遥测数据并将其流式传输到 Amazon CloudWatch 和 AWS X-Ray。Telemetry API 为扩展提供了一个简单的 HTTP 或 TCP 接口，以接收相同的遥测数据以及 Lambda 执行环境生命周期事件和函数调用级指标。扩展程序可以使用 Telemetry API 直接从 Lambda 使用这些遥测流，然后进行处理、筛选并将它们发送到任何首选目的地。"
    },
    {
        "query":"如何开始使用 Telemetry API？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Lambda 控制台、AWS CLI 或基础设施即代码工具（例如 AWS CloudFormation、AWS Serverless Application Model (SAM) 和 Terraform）为您的 Lambda 函数部署启用 Telemetry API 的扩展程序。无需更改代码即可将支持 Telemetry API 的扩展与您的 Lambda 函数一起使用。只需将您选择的工具提供商的扩展添加到您的 Lambda 函数。 要开始使用来自 APN 合作伙伴的扩展，请点击[发布博客文章](https://aws.amazon.com/blogs/compute/introducing-the-aws-lambda-telemetry-api/)中提供的链接。您还可以生成自己的使用 Telemetry API 的扩展。请访问 [AWS Lambda 开发人员指南](https://docs.aws.amazon.com/lambda/latest/dg/telemetry-api.html)了解操作方法。"
    },
    {
        "query":"使用 Telemetry API 是否会影响性能？",
        "intention":"知识问答",
        "reply":"您只能在 AWS Lambda 扩展程序中使用 Telemetry API。扩展程序可能会影响函数的性能，因为它们与函数共用 CPU、内存和存储等资源。内存使用量会随 Telemetry API 订阅数量的增加而线性增加，因为每个订阅都会打开一个新的内存缓冲区来存储遥测数据。但是，您可以通过调整 Telemetry API 订阅请求中的缓冲配置来优化内存使用。我们建议扩展程序供应商发布预期的资源消耗，以便功能开发人员选择合适的扩展。请参阅您的扩展程序供应商的文档以了解使用其扩展程序的潜在性能影响。"
    },
    {
        "query":"使用 Telemetry API 是否会禁用将日志发送到 Amazon CloudWatch Logs 的功能？",
        "intention":"知识问答",
        "reply":"否。默认情况下，Lambda 服务将所有遥测数据发送到 CloudWatch Logs，而且使用 Telemetry API 不会禁用传出到 CloudWatch Logs 的功能。\n问：AWS Lambda 函数是否支持 HTTP(S) 终端节点？\n是。您可以使用函数 URL、可使用浏览器、curl 及任何 HTTP 客户端调用的内置 HTTPS 终端节点配置 Lambda 函数。函数 URL 是开始构建 HTTPS 可访问函数的简单方法。\n问：如何为我的函数配置 Lambda 函数 URL？\n您可以通过 AWS 管理控制台、AWS Lambda API、AWS CLI、AWS CloudFormation 和 AWS Serverless Application Model 配置函数 URL。可以在函数的 $LATEST 非限定版本或任何函数别名上启用函数 URL。要了解有关配置函数 URL 的更多信息，[请参阅文档](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)。\n问：如何保护 Lambda 函数 URL？\n默认情况下，Lambda 函数 URL 受 IAM 授权保护。您可以选择禁用 IAM 授权以创建公有终端节点，或者如果您计划实施自定义授权作为函数业务逻辑的一部分。\n问：如何使用 Lambda 函数 URL 调用我的函数？\n您可以轻松从 Web 浏览器调用函数，方法是导航到 Lambda URL、使用 HTTP 库从客户端应用程序的代码或使用 curl 从命令行进行调用。\n问：Lambda 函数 URL 是否适用于函数版本和别名？\n是。可以在函数或函数别名上启用 Lambda 函数 URL。如果未指定别名，则默认情况下 URL 将指向 $LATEST。函数 URL 不能针对单独的函数版本。\n问：我可以为 Lambda 函数 URL 启用自定义域吗？\n函数 URL 目前不支持自定义域名。您可以将自定义域与函数 URL 一起使用，方法是通过创建 Amazon CloudFront 分配和 CNAME 来将自定义域映射到 CloudFront 分配名称。然后，将要路由到函数 URL 的 CloudFront 分配域名映射为源。\n问：Lambda 函数 URL 是否可用于调用 VPC 中的函数吗？\n是，函数 URL 可用于调用 VPC 中的 Lambda 函数。\n问：使用 Lambda 函数 URL 的定价是多少？\n使用函数 URL 不产生任何额外费用。您只需支付 AWS Lambda 的标准价格。要了解更多信息，请参阅 [AWS Lambda 定价](https://aws.amazon.com/cn/lambda/pricing/)。"
    },
    {
        "query":"什么是 Lambda@Edge？",
        "intention":"知识问答",
        "reply":"使用 [Lambda@Edge](https://aws.amazon.com/cn/lambda/edge/)，您可以在全球的 AWS 站点运行代码，而无需预置或管理服务器，从而以最低的网络延迟响应最终用户。您只需将 Node.js 或 Python 代码上传到 AWS Lambda，然后配置要触发的函数，用于响应 [Amazon CloudFront](https://aws.amazon.com/cn/cloudfront/) 请求（即，发出查看器请求，向原点转发请求或从原点接收到请求时以及刚好在响应最终用户之前）。当收到内容请求后，代码即可开始在全球的 AWS 站点执行，并按照全球的 CloudFront 请求量进行扩展。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html)。"
    },
    {
        "query":"如何使用 Lambda@Edge？",
        "intention":"知识问答",
        "reply":"要使用 Lambda@Edge，您仅需将代码上传到 AWS Lambda，然后关联要触发的函数版本，用于响应 Amazon CloudFront 请求。您的代码必须符合 Lambda@Edge 服务限制。目前，Lambda@Edge 支持使用 Node.js 和 Python 进行 CloudFront 事件的全局调用。有关更多信息，请参阅我们的[文档](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/lambda-at-the-edge.html)。"
    },
    {
        "query":"应该在何时使用 Lambda@Edge？",
        "intention":"知识问答",
        "reply":"Lambda@Edge 针对最终查看器在全球范围内分布的延迟敏感型使用案例进行了优化。您可以在 CloudFront 边缘站点、函数和请求中查看制定决策所需的全部信息。这意味着，对于那些您需要决定如何基于用户特征（例如，位置、客户端设备等）提供内容的使用案例，您现在可以从距离用户较近的位置执行和处理，而无需重新路由到集中式服务器。"
    },
    {
        "query":"能否部署现有的 Lambda 函数进行全局调用？",
        "intention":"知识问答",
        "reply":"如果函数满足 Lambda@Edge 服务要求和限制，则可以将现有的 Lambda 函数与 CloudFront 事件关联，进行全局调用。有关如何更新函数属性的更多信息，请参阅[此处](http://docs.aws.amazon.com/lambda/latest/dg/API_UpdateFunctionConfiguration.html)。"
    },
    {
        "query":"哪些 Amazon CloudFront 事件可用于触发我的函数？",
        "intention":"知识问答",
        "reply":"在响应以下 Amazon CloudFront 事件时，会自动触发您的函数："
    },
    {
        "query":"使用 AWS Lambda@Edge 与在 Amazon API Gateway 之后使用 AWS Lambda 有何区别？",
        "intention":"知识问答",
        "reply":"区别在于 API Gateway 和 Lambda 是区域性服务。使用 [Lambda@Edge](https://aws.amazon.com/lambda/edge/) 和 [Amazon CloudFront](https://aws.amazon.com/cloudfront/)，您可以根据最终查看器所在的位置跨多个 AWS 位置执行逻辑。"
    },
    {
        "query":"AWS Lambda 函数的可用性如何？",
        "intention":"知识问答",
        "reply":"AWS Lambda 旨在通过复制和冗余来向服务本身和其操作的 Lambda 函数提供高可用性。二者皆无维护窗口期或计划停机时间。"
    },
    {
        "query":"改动代码或配置时，AWS Lambda 函数是否还可以使用？",
        "intention":"知识问答",
        "reply":"是。当您更新 Lambda 函数时，会有一个短暂的时间段，通常不到 1 分钟，在这期间请求将由旧版本函数或新版本函数实现。"
    },
    {
        "query":"对于一次可以执行的 AWS Lambda 函数的数量有没有限制？",
        "intention":"知识问答",
        "reply":"没有，AWS Lambda 采用的设计可以支持大量函数实例并行运行。但是，AWS Lambda 对每个区域的每个账户的并发执行次数具有默认安全限制（请访问[此处](http://docs.aws.amazon.com/lambda/latest/dg/concurrent-executions.html#concurrent-execution-safety-limit)了解有关默认安全限制数量的信息）。您还可以控制各个 AWS Lambda 函数的最大并发执行次数，并且您可以使用这项功能为关键函数保留一部分账户并发限制或下游资源流量速率上限。  \n   \n 如果您想申请提高限制，可以访问我们的[支持中心](https://aws.amazon.com/support)，单击“Open a new case”，然后发出服务限制提升请求。"
    },
    {
        "query":"如果账户超出并发执行默认限制数量会怎么样？",
        "intention":"知识问答",
        "reply":"如果超出限制，同步调用的 AWS Lambda 函数会返回一条限制错误信息（429 错误代码）。异步调用的 Lambda 函数可以承受一定范围内的流量突增大约 15 到 30 分钟，之后再进来的事件将会以限制为理由遭到拒绝。如果调用的 Lambda 函数是用于响应 Amazon S3 事件，则被 AWS Lambda 拒绝的事件可能被 S3 保留 24 小时并在此期间反复重试。Amazon Kinesis Streams 和 Amazon DynamoDB 流中的事件会反复重试，直到 Lambda 函数成功或数据过期。Amazon Kinesis 和 Amazon DynamoDB 流会将数据保留 24 小时。"
    },
    {
        "query":"默认的数量限制是否在函数级别应用？",
        "intention":"知识问答",
        "reply":"否，默认的数量限制只在账户级别应用。"
    },
    {
        "query":"如果 Lambda 函数在处理事件时发生故障会怎么样？",
        "intention":"知识问答",
        "reply":"如遇故障，进行同步调用的 Lambda 函数会返回异常信息。异步调用的 Lambda 函数将至少重试 3 次。Amazon Kinesis Streams 和 Amazon DynamoDB 流中的事件会反复重试，直到 Lambda 函数成功或数据过期。Kinesis 和 DynamoDB 流会至少保留数据 24 个小时。"
    },
    {
        "query":"如果 Lambda 函数调用用尽了策略规定的次数会怎么样？",
        "intention":"知识问答",
        "reply":"当超过策略针对异步调用规定的重试次数时，您可以配置一个放置此事件的“死信队列”(DLQ)；如果尚未配置 DLQ，此事件可能会被拒绝。当超过策略针对基于流的调用规定的重试次数时，数据可能已失效，因此已被拒绝。"
    },
    {
        "query":"可以将哪些资源配置为 Lambda 函数的死信队列？",
        "intention":"知识问答",
        "reply":"您可以将 Amazon SQS 队列或 Amazon SNS 主题配置为您的死信队列。"
    },
    {
        "query":"如何允许 AWS Lambda 函数访问其他 AWS 资源？",
        "intention":"知识问答",
        "reply":"您可以使用 IAM 角色授予 Lambda 函数相应的权限，以访问其他资源。AWS Lambda 在执行您的 Lambda 函数的同时承担该角色，因此您可以对该服务可使用的 AWS 资源保持完整、安全的控制。请访问[设置 AWS Lambda](http://docs.aws.amazon.com/lambda/latest/dg/setting-up.html) 了解有关角色的更多信息。"
    },
    {
        "query":"如何控制哪些 Amazon S3 存储桶可以调用哪些 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"当您配置 Amazon S3 存储桶向 AWS Lambda 函数发送消息时，将创建一条资源策略规则用于权限授予。请访问 [Lambda 开发人员指南](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html)，了解有关 Lambda 函数的资源策略和访问控制的更多信息。"
    },
    {
        "query":"如何控制 AWS Lambda 函数可以轮询哪种 Amazon DynamoDB 表或 Amazon Kinesis 流？",
        "intention":"知识问答",
        "reply":"对访问控制的管理通过 Lambda 函数的角色实现。分配给 Lambda 函数的角色同时决定了 AWS Lambda 可以代表其进行轮询的资源。请访问 [Lambda 开发人员指南](http://docs.aws.amazon.com/lambda/latest/dg/welcome.html)了解更多信息。"
    },
    {
        "query":"如何控制 AWS Lambda 函数可以轮询的 Amazon SQS 队列？",
        "intention":"知识问答",
        "reply":"您可以用 Lambda 函数的角色或队列本身的资源策略设置来进行访问控制。 如果两种方式同时存在，那么系统会应用限制性更高的权限设置。"
    },
    {
        "query":"是否可以使用 AWS Lambda 函数访问 Amazon VPC 后端的资源？",
        "intention":"知识问答",
        "reply":"是。您可以访问 Amazon VPC 后端的资源。"
    },
    {
        "query":"如何启用和禁用针对 Lambda 函数的 VPC 支持？",
        "intention":"知识问答",
        "reply":"要启用 VPC 支持，您需要在单个 VPC 中指定一个或多个子网，并在配置函数时指定安全组。要禁用 VPC 支持，您需要更新函数配置并为子网和安全组指定空列表。您可以使用 AWS API、CLI 或 AWS Lambda 管理控制台更改这些设置。"
    },
    {
        "query":"一个 Lambda 函数是否可以访问多个 VPC？",
        "intention":"知识问答",
        "reply":"否，Lambda 函数只能访问一个 VPC。如果指定多个子网，则所有子网都必须位于同一个 VPC 中。您可以通过在 VPC 之间建立对等连接来连接到其他 VPC。"
    },
    {
        "query":"一个 VPC 中的 Lambda 函数是否还能够访问 Internet 和 AWS 服务终端节点？",
        "intention":"知识问答",
        "reply":"在默认配置下，配置为可访问特定 VPC 中资源的 Lambda 函数将无法访问 Internet。如果您需要访问外部终端节点，则需要在 VPC 中创建 [NAT](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-nat-gateway.html)，以转发相应流量并将安全组配置为允许这些出站流量。"
    },
    {
        "query":"什么是 AWS Lambda 的代码签名？",
        "intention":"知识问答",
        "reply":"AWS Lambda 的代码签名提供了信任和完整性控件，使您可以验证只有来自经批准的开发人员的未经修改的代码才会部署在您的 Lambda 函数中。您可以使用完全托管代码签名服务 [AWS Signer](https://docs.aws.amazon.com/signer/latest/developerguide/Welcome.html) 对代码构件进行数字签名，并配置 Lambda 函数以在部署时验证签名。AWS Lambda 的代码签名目前仅适用于打包为 ZIP 存档的函数。"
    },
    {
        "query":"如何创建经过数字签名的代码构件？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS Signer 控制台、Signer API、SAM CLI 或 AWS CLI 使用 [Signing Profile](https://docs.aws.amazon.com/signer/latest/api/API_SigningProfile.html)（签名配置文件）创建数字签名的代码构件。要了解更多信息，请参见 [AWS Signer 的文档](https://docs.aws.amazon.com/signer/latest/api/Welcome.html)。"
    },
    {
        "query":"如何配置 Lambda 函数以启用代码签名？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台、Lambda API、AWS CLI、AWS CloudFormation 和 AWS SAM 创建代码签名配置来启用代码签名。代码签名配置可帮助您指定经批准的签名配置文件，并配置在签名检查失败时是警告还是拒绝部署。代码签名配置可以附加到单个 Lambda 函数，以启用代码签名功能。此类函数现在会在部署时开始验证签名。"
    },
    {
        "query":"AWS Lambda 会在部署时执行哪些签名检查？",
        "intention":"知识问答",
        "reply":"AWS Lambda 可在部署时执行以下签名检查：\n• 签名损坏 - 如果代码构件在签名后被更改，则会发生这种情况。  \n • 签名不匹配 - 如果代码构件由未经批准的签名配置文件签名，则会发生这种情况。  \n • 过期签名 - 如果签名超过了配置的有效期，则会发生这种情况。  \n • 撤销签名 - 如果签名配置文件拥有者撤销了签名作业，则会发生这种情况。\n要了解更多信息，请参阅 [AWS Lambda 文档](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html)。"
    },
    {
        "query":"是否可以为现有函数启用代码签名？",
        "intention":"知识问答",
        "reply":"是，您可以通过将代码签名配置附加到函数中，为现有函数启用代码签名。您可以使用 AWS Lambda 控制台、Lambda API、AWS CLI、AWS CloudFormation 和 AWS SAM 进行此操作。"
    },
    {
        "query":"如何使用 Java 代码编译 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以使用 Maven 或 Gradle 等标准工具编译 Lambda 函数。构建过程应模拟编译任何 Java 代码的同一构建过程，这取决于 AWS 开发工具包。在源文件上运行您的 Java 编译器工具并在类路径上包含 AWS 开发工具包 1.9 或更高版本，以延续依赖性。有关更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/java-lambda.html)。"
    },
    {
        "query":"Lambda 用于执行函数的 JVM 环境是什么？",
        "intention":"知识问答",
        "reply":"Lambda 提供 openjdk 1.8 的 Amazon Linux 版本。"
    },
    {
        "query":"能否将程序包与 AWS Lambda 配合使用？",
        "intention":"知识问答",
        "reply":"是。您可以使用 NPM 程序包和自定义的程序包。单击[此处](https://aws.amazon.com/blogs/compute/nodejs-packages-in-lambda/)了解更多信息。"
    },
    {
        "query":"能否使用以 Node.js 编写的 AWS Lambda 函数执行其他程序？",
        "intention":"知识问答",
        "reply":"是。Lambda 的内建沙盒可以让您运行批处理（“shell”）脚本、其他语言运行时、实用程序例程和可执行文件。单击[此处](https://aws.amazon.com/blogs/compute/running-executables-in-aws-lambda/)了解更多信息。"
    },
    {
        "query":"是否可以使用带有以 Node.js 编写的 AWS Lambda 函数的本机模块？",
        "intention":"知识问答",
        "reply":"是。您上传的 ZIP 文件可以包含任何静态连接的本机模块，动态连接的模块同样如此，动态模块用指向您的 Lambda 函数根目录的根路径编译。单击[此处](https://aws.amazon.com/blogs/compute/nodejs-packages-in-lambda/)了解更多信息。"
    },
    {
        "query":"能否使用以 Node.js 编写的 AWS Lambda 执行二进制？",
        "intention":"知识问答",
        "reply":"是。您可以使用 Node.js 的 child\\_process 命令来执行您在函数中包含的二进制文件或任何向函数开放的 Amazon Linux 中的可执行文件。另外，还有多个打包命令行二进制代码的 NPM 程序包，如 node-ffmpeg。[单击此处](https://aws.amazon.com/blogs/compute/running-executables-in-aws-lambda/)了解更多信息。"
    },
    {
        "query":"如何部署以 Node.js 编写的 AWS Lambda 函数代码？",
        "intention":"知识问答",
        "reply":"要部署以 Node.js 编写的 Lambda 函数，仅需将您的 Javascript 代码和依赖库打包为 ZIP。您可以从本地环境上传 ZIP，或指定 ZIP 文件所在的 Amazon S3 位置。有关更多详细信息，请参阅我们的[文档](http://docs.aws.amazon.com/lambda/latest/dg/authoring-function-in-nodejs.html)。"
    },
    {
        "query":"能否将 Python 程序包与 AWS Lambda 配合使用？",
        "intention":"知识问答",
        "reply":"是。您可以使用 pip 安装所需的任意 Python 程序包。"
    },
    {
        "query":"如何打包和部署以 C# 编写的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"您可以使用 Visual Studio IDE 通过在“Solution Explorer”中选择“Publish to AWS Lambda”来创建 C# Lambda 函数。或者，您还可以在安装 [# Lambda CLI 工具补丁] 的 dotnet CLI 上直接运行“dotnet lambda publish”命令，这将会创建 C# 源代码的 ZIP、所有的 NuGet 依赖项以及您自己发布的 DLL 程序集，并使用运行时参数“dotnetcore1.0”自动将其上传到 AWS Lambda。"
    },
    {
        "query":"如何部署以 PowerShell 编写的 AWS Lambda 函数代码？",
        "intention":"知识问答",
        "reply":"PowerShell Lambda 部署包是一个 ZIP 文件，其中包含 PowerShell 脚本、PowerShell 脚本所需的 PowerShell 模块以及托管 PowerShell Core 所需的程序集。然后，您可以使用可从 [PowerShell 库](https://www.powershellgallery.com/packages/AWSLambdaPSCore/1.1.0.0)安装的 *AWSLambdaPSCore* PowerShell 模块来创建 PowerShell Lambda 部署包。"
    },
    {
        "query":"如何打包和部署以 Go 编写的 AWS Lambda 函数？",
        "intention":"知识问答",
        "reply":"通过 AWS CLI 或 Lambda 控制台以 ZIP 文件的形式上传 Go 可执行项目并选择 go1.x 运行时。通过 Lambda，您可以使用 Go 的原生工具构建并打包代码。有关更多详细信息，请参阅我们的[文档](https://docs.aws.amazon.com/lambda/latest/dg/go-programming-model.html)。"
    },
    {
        "query":"如何部署以 Ruby 编写的 AWS Lambda 函数代码？",
        "intention":"知识问答",
        "reply":"要部署以 Ruby 编写的 Lambda 函数，请将您的 Ruby 代码和 Gem 打包为 ZIP。您可以从本地环境上传 ZIP，或指定 ZIP 文件所在的 Amazon S3 位置。"
    },
    {
        "query":"AWS Lambda 支持哪些版本的 Amazon Linux、Node.js、Python、JDK、.NET Core、开发工具包及其他库？",
        "intention":"知识问答",
        "reply":"您可以单击[此处](http://docs.aws.amazon.com/lambda/latest/dg/current-supported-versions.html)查看受支持的版本列表。"
    },
    {
        "query":"能否更改 Amazon Linux 版本或任何语言运行时？",
        "intention":"知识问答",
        "reply":"不能。AWS Lambda 向该服务的所有用户提供单一版本的操作系统和托管语言运行时。您可以在 Lambda 中使用[您自己的语言运行时](https://docs.aws.amazon.com/lambda/latest/dg/runtimes-custom.html)。"
    },
    {
        "query":"如何记录和审计对 AWS Lambda API 进行的调用？",
        "intention":"知识问答",
        "reply":"AWS Lambda 与 AWS CloudTrail 集成。AWS CloudTrail 可以记录日志文件并将其提供给 Amazon S3 存储桶，用于说明账户的 API 使用情况。"
    },
    {
        "query":"如何协调多个 Lambda 函数之间的调用？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon Step Functions 来协调多个 Lambda 函数之间的调用。您可以按顺序调用多个 Lambda 函数，然后将一个函数的输出传递到另一个函数，也可以进行并行调用。请参阅我们的[文档](http://docs.aws.amazon.com/step-functions/latest/dg/hello-lambda.html)了解更多详细信息。"
    },
    {
        "query":"AWS Lambda 是否支持高级矢量扩展 2 (AVX2)？",
        "intention":"知识问答",
        "reply":"是，AWS Lambda 支持高级矢量扩展 2 (AVX2) 指令集。要了解有关如何针对此指令集编译应用程序代码以提高性能的更多信息，请访问 [AWS Lambda 开发人员文档](https://docs.aws.amazon.com/lambda/latest/dg/runtimes-avx2.html)。\n了解有关 AWS Lambda 定价的更多信息"
    },
    {
        "query":"什么是 AWS IoT Core？",
        "intention":"知识问答",
        "reply":"AWS IoT Core 是一款托管的云平台，让互联设备可以轻松安全地与云应用程序及其他设备交互。AWS IoT Core 可以支持数十亿台设备和数万亿条消息，并且可以对这些消息进行处理并将其安全可靠地路由至 AWS 终端节点和其他设备。借助 AWS IoT Core，您的应用程序可以随时跟踪所有设备并与其通信，即使这些设备未处于连接状态也不例外。"
    },
    {
        "query":"AWS IoT Core 提供哪些功能？",
        "intention":"知识问答",
        "reply":"实现设备与 AWS 云之间的连接。 首先，借助 AWS IoT Core，您能以安全、低延迟和低开销的方式与互联设备通信。通信可扩展到您所需的任意数量的设备。AWS IoT Core 支持标准通信协议（目前支持 HTTP、MQTT、WebSockets 和 LoRaWAN）。可使用 TLS 来确保通信安全。\n处理互联设备发出的数据。其次，借助 AWS IoT Core，您可以持续接收、筛选、转换和路由从互联设备流式传输的数据。您可以根据这些数据执行操作，并进行路由以做进一步处理和分析。\n与互联设备交互的应用程序。最后，AWS IoT Core 可以加快 IoT 应用程序的开发。对于运行在云中和移动设备上的应用程序来说，它是一个易于使用的接口，用于访问互联设备发出的数据，并将数据和命令发回设备。"
    },
    {
        "query":"AWS IoT Core 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"互联设备（如传感器、执行器、嵌入式设备、智能设备和可穿戴设备）通过 HTTPS、WebSockets、安全 MQTT 或 LoRaWAN 连接到 AWS IoT Core。AWS IoT Core 内含设备网关，可在互联设备与您的云和移动应用程序之间建立安全、低延迟、低开销的双向通信。\n此外，AWS IoT Core 还包含规则引擎，可对互联设备发送的数据进行持续处理。您可以配置规则以筛选和转换数据。此外，您还可以配置规则来将数据路由到其他 AWS 产品（如 DynamoDB、Kinesis、Lambda、SNS、SQS、CloudWatch 和内置 Kibana 集成的 Elasticsearch Service）及非 AWS 产品，通过 Lambda 做进一步的处理、存储或分析。\n它还提供了一个注册表，以供您注册和跟踪连接到 AWS IoT Core 的设备或未来可能要连接的设备。AWS IoT Core 中的设备影子让云和移动应用程序可以查询设备发送的数据，并通过简单的 REST API 向设备发送命令，同时将与设备的底层通信交给 IoT Core 处理。设备影子向设备提供了统一的接口（即使它们使用应用程序不兼容的某个 IoT 通信和安全协议时也是如此），加速了应用程序的开发。此外，设备影子还能通过以下方式加速应用程序的开发：向设备提供始终可用的接口，即使互联设备受到连接间歇中断、带宽有限、计算能力有限或电力有限等制约。\n安全地与 AWS IoT Core 通信。该服务要求其所有客户端（互联设备、服务器应用程序、移动应用程序或人类用户）使用强身份验证（X.509 证书、AWS IAM 凭证或经由 AWS Cognito 的第三方身份验证）。所有通信均经过加密。此外，AWS IoT Core 还提供了精细的授权，以隔离和保护已验证客户端之间的通信。"
    },
    {
        "query":"什么是 2lemetry 以及它与 AWS IoT 有何关联？",
        "intention":"知识问答",
        "reply":"AWS 在 2015 年收购了 2lemetry，并获得了他们为 AWS IoT Core 提供 MQTT Message Broker 和 Rules Engine 等基本元素的能力。\n![](//d1.awsstatic.com/IoT/Logo%20for%202lemetry.d37010aba9aad43fb2957638f6c236edb83c022c.png)"
    },
    {
        "query":"哪些 AWS 区域提供 AWS IoT Core 服务？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解当前提供 AWS IoT Core 服务的区域列表。\n不管您身处哪个地理位置，只要您能够访问上述 AWS 区域之一，即可使用 AWS IoT Core。"
    },
    {
        "query":"如何开始使用 AWS IoT Core？",
        "intention":"知识问答",
        "reply":"请使用 AWS IoT 控制台或参阅开发人员指南的[快速入门](http://docs.aws.amazon.com/iot/latest/developerguide/what-is-aws-iot.html)部分，以在数分钟内开始试用 AWS IoT Core。\n另请参阅由我们合作伙伴提供、AWS 给予支持的[初学者工具包](https://aws.amazon.com/cn/iot-core/getting-started/)。\n有关更多信息，请参阅 [AWS IoT Core 文档](http://docs.aws.amazon.com/iot/latest/developerguide/what-is-aws-iot.html)。"
    },
    {
        "query":"AWS IoT 控制台支持哪些语言？",
        "intention":"知识问答",
        "reply":"​AWS IoT 控制台支持英语、法语、日语、韩语、简体中文、德语、葡萄牙语、西班牙语、意大利语和繁体中文。"
    },
    {
        "query":"如何切换控制台语言？",
        "intention":"知识问答",
        "reply":"单击控制台左下角的语言即可选择语言。不同 AWS 产品的控制台将始终选用一种语言。"
    },
    {
        "query":"访问 AWS IoT Core 的途径有哪些？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS 管理控制台](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fiot%2Fhome%3Fstate%3DhashArgs%2523%26isauthcode%3Dtrue&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Ficebreaker&forceMobileApp=0)、[AWS 开发工具包](https://aws.amazon.com/tools/)、AWS CLI 和 AWS IoT Core API 访问。互联设备可以使用 [AWS IoT 设备开发工具包](https://aws.amazon.com/iot-platform/sdk/)，以简化与 AWS IoT Core 设备的通信。\nAWS IoT Core API 和命令主要分为控制平面操作和数据层面操作。控制平面操作让您能够执行配置安全性、注册设备、配置数据路由规则、设置日志记录等任务。数据层面操作让您能够以低延迟和高吞吐率的方式将互联设备的数据大规模传输到 AWS IoT Core。"
    },
    {
        "query":"AWS IoT Core 支持哪些通信和身份验证协议？",
        "intention":"知识问答",
        "reply":"对于控制层面操作，AWS IoT Core 支持 HTTPS。对于数据层面操作，AWS IoT Core 支持 HTTPS、WebSockets 及安全 [MQTT](http://mqtt.org/)（一种常用于 IoT 场景的协议）。\n发送到 AWS IoT Core 的 HTTPS 和 WebSockets 请求使用 AWS IAM 或 AWS Cognito 进行身份验证，这两者均支持 AWS SigV4 身份验证。如果您使用的是 AWS SDK 或 AWS CLI，系统会在后台为您处理 SigV4 身份验证。HTTPS 请求还可以使用 X.509 证书进行身份验证。发送到 AWS IoT Core 的 MQTT 消息使用 X.509 证书进行身份验证。\n借助 AWS IoT Core，您可以使用 AWS IoT Core 生成的证书以及由您的首选证书颁发机构 (CA) 签署的证书。"
    },
    {
        "query":"未直接连接互联网的设备能访问 AWS IoT Core 吗？",
        "intention":"知识问答",
        "reply":"可以通过实体插座连接。连接私有 IP 网络的设备和使用非 IP 射频协议的设备（如 ZigBee 或蓝牙 LE）只要有实体插座作为其与 AWS IoT Core 之间的中介，就可以访问 AWS IoT Core 并进行安全地通信。"
    },
    {
        "query":"应用程序应如何访问 AWS IoT Core？",
        "intention":"知识问答",
        "reply":"连接 AWS IoT Core 的应用程序大体上分为两类：1. 配套应用程序；2. 服务器应用程序。配套应用程序是指移动或客户端侧的浏览器应用程序，它们通过云与互联设备交互。能够使消费者远程解锁消费者居所中智能锁的移动应用程序就是配套应用程序的一个示例。服务器应用程序旨在同时监测和控制大量互联设备。在地图上实时绘制数千辆卡车的车队管理网站就是服务器应用程序的一个示例。\nAWS IoT Core 使配套应用程序和服务器应用程序能够通过统一的 RESTful API 访问互联设备。此外，应用程序也可选择使用发布/订阅方式与互联设备直接通信。\n通常，配套应用程序使用最终用户身份（由您自己的身份存储或 Facebook、[Login with Amazon](https://login.amazon.com/) 等第三方身份提供商管理）进行身份验证。对于配套应用程序，可以使用 Amazon Cognito（与多个身份提供商集成）。可以授权 Cognito 身份以访问 AWS IoT Core，且可将其访问范围限制为与其相关的资源。例如，作为一家互联洗衣机制造商，您可以授权消费者访问属于其各自洗衣机的 AWS IoT Core 信息。\n服务器应用程序（如运行在 Amazon EC2 上的地图应用程序）可使用 IAM 角色访问 AWS IoT Core。"
    },
    {
        "query":"我能否获取从我的账户发起的 AWS IoT Core API 调用的历史记录，用于安全分析和操作故障排除？",
        "intention":"知识问答",
        "reply":"可以。要获取从您的账户发起的 AWS IoT Core API 调用的历史记录，您只需在 AWS 管理控制台中打开 CloudTrail 即可。"
    },
    {
        "query":"如何发送反馈？",
        "intention":"知识问答",
        "reply":"要发送反馈，请单击控制台页脚工具栏中的“反馈”链接。"
    },
    {
        "query":"什么是设备网关？",
        "intention":"知识问答",
        "reply":"设备网关构成了互联设备与云功能（如 规则引擎、设备影子以及其他 AWS 和第三方服务）之间的通信骨干。\n设备网关支持发布/订阅消息收发模式，能够实现可扩展、低延迟和低开销的通信。它对于预计会有数十亿设备进行低延迟频繁通信的 IoT 场景尤为有用。发布/订阅模式是指：客户端在称作“主题”的逻辑通信频道上发布消息，客户端订阅主题接收消息。设备网关可促成发布者与订阅者之间的通信。传统上，组织要使用发布/订阅模型，就必须调配、操作、扩展和维护自己的服务器来作为设备网关。AWS IoT Core 提供了设备网关，消除了这一障碍。\n该设备网关可根据您的使用情况自动扩展，不会给您带来任何运营开销。AWS IoT Core 支持与设备网关的安全通信、AWS 账户级隔离以及 AWS 账户内的精细授权。目前，该设备网关支持通过 MQTT 和 WebSockets 进行发布和订阅，以及通过 HTTPS 进行发布。"
    },
    {
        "query":"什么是 MQTT？",
        "intention":"知识问答",
        "reply":"[MQTT](http://mqtt.org/) 是一种轻量级的发布/订阅协议，旨在最大限度地降低网络带宽和设备资源要求。此外，MQTT 还支持使用 TLS 进行安全通信。MQTT 常用在 IoT 用例中。MQTT v3.1.1 是一种 OASIS 标准， 设备网关支持大部分 MQTT 规范。"
    },
    {
        "query":"什么是规则引擎？",
        "intention":"知识问答",
        "reply":"规则引擎可对来自连接到 AWS IoT Core 的设备的入站数据进行连续处理。您可以使用直观的类 SQL 语法在规则引擎中配置规则，以自动过滤和转换入站数据。您可以进一步配置规则，将数据从 AWS IoT Core 路由到多个其他 AWS 产品及您自己的第三方服务。\n下面给出了少量规则用例："
    },
    {
        "query":"如何定义和触发规则？",
        "intention":"知识问答",
        "reply":"AWS IoT Core 规则包含两大部分：\nSQL 语句：指定要应用规则的发布/订阅主题、要执行的数据转换（如有的话）以及执行规则的条件。该规则应用到在指定主题上发布的每一条消息。\n操作列表：定义规则执行时（即：当传入消息匹配规则中指定的条件时）要采取的操作。\n规则定义使用基于 JSON 的架构。您可以直接编辑 JSON，或使用 AWS 管理控制台中的规则编辑器。\n下面是一个规则示例，当温度高于 50 时，它将来自传感器的温度数据保存到 DynamoDB 中：\n本示例中的传感器在其位于“iot/tempSensors/”下的主题中发布消息。规则的第一行定义了一条查询“iot/tempSensors/#”主题的 SQL SELECT 语句。它包含一条 WHERE 子句：提取消息有效载荷中“temp”字段的值并检查其是否满足“高于 50”的条件。如果满足条件，则将数据存储在指定的 DynamoDB 表中。本示例使用内置功能完成遍历消息有效载荷和获取当前时间等任务。"
    },
    {
        "query":"哪里可以了解有关规则的更多信息？",
        "intention":"知识问答",
        "reply":"有关规则的更多信息，请参阅 [Core 规则文档](http://docs.aws.amazon.com/iot/latest/developerguide/iot-rules.html)"
    },
    {
        "query":"什么是注册表？它有什么用？",
        "intention":"知识问答",
        "reply":"IoT 涵盖使用少量任务关键型设备到采用大量设备的场景。注册表让您能够组织和跟踪这些设备。您可以在注册表中维护连接 AWS IoT Core 的每个设备的逻辑句柄。注册表中的每个设备都能被唯一标识，且可拥有元数据，如型号、支持联系方式、与之关联的证书等。您可以基于元数据在注册表中搜索互联设备。"
    },
    {
        "query":"什么是 Thing Type？",
        "intention":"知识问答",
        "reply":"Thing Type 通过定义同类设备的一般特征，帮助您高效管理设备目录。此外，与一种 Thing Type 相关的每个 Thing 目前拥有多达 50 个属性，其中包括 3 个可搜索属性。"
    },
    {
        "query":"什么是简化的权限管理？",
        "intention":"知识问答",
        "reply":"借助该功能，您可以通过使用引用注册表或 X.509 证书属性的变量来轻松管理大量设备的权限策略。“注册表”和“证书”属性与设备策略的集成具有以下优点："
    },
    {
        "query":"什么是设备影子？",
        "intention":"知识问答",
        "reply":"设备影子使得云和移动应用程序能够轻松地与 AWS IoT Core 中注册的互联设备交互。AWS IoT Core 中的设备影子包含互联设备的属性。您可以定义适合您用例的任意属性集。例如，对于智能灯泡，您可以定义“on-or-off”、“color”和“brightness”等作为属性。然后由互联设备报告这些属性的实际值（存储在设备影子中）。应用程序可使用 AWS IoT Core 提供的 RESTful API 轻松地获取和更新这些属性。AWS IoT Core 和设备开发工具包负责在互联设备与其在 AWS IoT Core 中的设备影子间同步属性值。"
    },
    {
        "query":"我必须使用注册表和设备影子吗？",
        "intention":"知识问答",
        "reply":"您可以让应用程序使用 AWS IoT Core 中的设备网关和/或规则引擎直接与互联设备通信。但我们建议您使用注册表和设备影子，因为它们提供了更丰富和更结构化的开发和管理体验，让您能够将精力放在要为客户创造的独特价值上，而不是纠缠于互联设备与云之间的底层通信和同步上。"
    },
    {
        "query":"哪里可以了解有关注册表和设备影子的更多信息？",
        "intention":"知识问答",
        "reply":"有关注册表的更多信息，请查阅[注册表文档](https://docs.aws.amazon.com/iot/latest/developerguide/thing-registry.html)。有关设备影子的更多信息，请查阅[设备影子文档](https://docs.aws.amazon.com/iot/latest/developerguide/iot-thing-shadows.html)。"
    },
    {
        "query":"我能在 AWS IoT Core 中配置精细的授权操作吗？",
        "intention":"知识问答",
        "reply":"可以。与其他 AWS 产品类似，在 AWS IoT Core 中，您可以精细控制授权每个身份调用的 API 操作集。此外，您还能精细控制身份可发布或订阅的发布/订阅主题，以及身份可访问的注册表中的设备和设备影子。"
    },
    {
        "query":"哪里可以了解有关 AWS IoT Core 中安全性和访问控制的更多信息？",
        "intention":"知识问答",
        "reply":"有关更多信息，请参阅 [AWS IoT Core 安全性和身份](http://docs.aws.amazon.com/iot/latest/developerguide/iot-security-identity.html)。"
    },
    {
        "query":"什么是证书的即时注册？",
        "intention":"知识问答",
        "reply":"设备证书的即时注册 (JITR) 通过简化使用 AWS IoT Core 注册设备的流程，在 2016 年 4 月发布的“使用自己的证书”功能的基础上进行了扩展。在支持 JITR 之前，设备注册流程需要两个步骤：第一步，将证书颁发机构 (CA) 证书注册到 AWS IoT Core；第二步，单独注册 CA 签发的设备证书。现在，借助 JITR，您可以在设备首次连接至 AWS IoT Core 时，通过自动注册设备证书来完成第二步。这样可节约注册设备证书所用的时间，且可使设备在制造过程中保持离线状态。要进一步自动执行 IoT 设备预置，您可以使用 Lambda 操作创建一个 AWS IoT Core 规则，激活证书并添加策略。有关更多信息，请访问 AWS 上的物联网博客或[开发人员文档](http://docs.aws.amazon.com/iot/latest/developerguide/what-is-aws-iot.html)。"
    },
    {
        "query":"什么是 AWS IoT 设备 SDK？",
        "intention":"知识问答",
        "reply":"AWS IoT 设备 SDK 能够简化和加快运行在互联设备（微控制器、传感器、执行器、智能设备、可穿戴设备等）上的代码的部署。首先，设备可以借助该设备 SDK 优化内存、功耗和网络带宽占用。同时，设备 SDK 可通过内置的 TLS、WebSockets 和 MQTT 支持实现高度安全、低延迟和低开销的通信。此外，设备 SDK 还支持更高级别的抽象（如同步设备与其在 AWS IoT Core 中的设备影子的状态），以加快 IoT 应用程序的部署。\nAWS IoT 设备 SDK 是开源项目，免费提供。有关更多信息，请访问我们的[设备开发工具包](https://aws.amazon.com/iot-platform/sdk/) 页面。"
    },
    {
        "query":"AWS IoT 设备 SDK 支持哪些编程语言和硬件平台？",
        "intention":"知识问答",
        "reply":"目前，AWS 提供了适用于 C、Node.js 语言及 Arduino Yún 平台的 AWS IoT 设备 SDK。\n此外，有多个硬件制造商与 AWS 建立了合作伙伴关系，以使 AWS IoT 设备 SDK 能够在其各自的平台上运行。有关这些硬件平台的更多信息，请访问我们的[入门页面](https://aws.amazon.com/cn/iot-core/getting-started/)。\n最后，AWS IoT 设备 SDK 是开源的。您可以将它们移植到您选择的语言和硬件平台（如果它们尚未获得支持的话）。"
    },
    {
        "query":"我该使用 AWS IoT 设备开发工具包还是 AWS 软件开发工具包？",
        "intention":"知识问答",
        "reply":"AWS IoT 设备 SDK 是对 AWS SDK 的补充。一方面，IoT 项目通常涉及在微控制器及其他资源有限设备上运行的代码。另一方面，IoT 项目还常常包含在云和移动设备上运行的与微控制器/资源有限设备交互的应用程序。AWS IoT 设备 SDK 旨在于微控制器/资源有限设备上使用，而 AWS SDK 旨在用于云和移动应用程序。\n有关 AWS IoT 设备开发工具包的更多信息，请参阅 [AWS 设备开发工具包](http://docs.aws.amazon.com/iot/latest/developerguide/iot-sdks.html)。"
    },
    {
        "query":"AWS IoT Core 是否包含在 AWS 免费套餐中？",
        "intention":"知识问答",
        "reply":"可以。请访问我们的[定价页面](https://aws.amazon.com/cn/iot-core/pricing/)了解更多信息。"
    },
    {
        "query":"什么是 AWS IoT Core SLA？",
        "intention":"知识问答",
        "reply":"AWS IoT Core SLA 规定，如果 AWS IoT Core 的月度正常运行时间百分比低于 99.9%，您将有资格获得 AWS IoT Core 提供的可用于部分月度服务费的积分。\n如需 SLA 的所有条款与条件的完整详细信息，以及如何提交申请的详细信息，请参阅 [AWS IoT Core SLA](https://aws.amazon.com/cn/iot-core/sla/) 详细信息页面。"
    },
    {
        "query":"为什么我应该使用适用于 AWS IoT 的 AWS 集成？",
        "intention":"知识问答",
        "reply":"直到现在，要生产 Alexa 内置设备，设备内存至少应为 50MB RAM，而且计算单元最低为 ARM Cortex“A”级微处理器，这样就会增加工程物料清单 (eBOM) 并提高制造商建议售价 (MSRP)。此外，在设备上检索、缓冲、解码和混合音频可能也很复杂且很耗时。因为生产成本和复杂性都较高，所以设备制造商难以在资源受限的 IoT 设备凭借差异化的语音体验打开市场。\nAVS 集成通过将计算和内存密集型工作负载分摊到云上，使 Alexa 的内置成本降低了 50%。这样降低了在设备上集成 AVS 的硬件要求（从 50MB 降到 1MB RAM，从 ARM Cortex“A”类微处理器降到 ARM Cortex“M”类微控制器），并将 Alexa 引入到广泛使用的产品中，例如电灯开关、恒温器和小家电。除简化的设备端 AVS 集成外，使用 AVS 集成的设备制造商还可以通过可扩展的 AWS IoT Core 基础设施实现简单且经济高效的持续设备维护和管理、增强的设备安全性和分析服务。\n随着新类别的低价 Alexa 内置设备在市场上推出，最终用户现在可以在家、办公室或酒店房间的新区域体验 Alexa，获得真实环境体验，在那里他们可以直接与周围环境对话，而不是与 Alexa 系列设备对话。"
    },
    {
        "query":"我该如何使用 Alexa Voice Service (AVS) 集成？",
        "intention":"知识问答",
        "reply":"了解如何通过[适用于 AWS IoT Core 的 AVS 集成入门指南](https://docs.aws.amazon.com/iot/latest/developerguide/avs-integration-aws-iot.html)创建低成本的 Alexa 内置设备。"
    },
    {
        "query":"适用于 IoT 的 AVS 与传统 AVS 有何区别？",
        "intention":"知识问答",
        "reply":"AVS 集成支持设备仲裁、对话、多向对话、计时器、警报、提醒、Flash 简报、例程、Alexa 公告、电子书和技能。不支持高质量的音乐播放、全家庭音频、Alexa 通话、Spotify、蓝牙和丰富的多模式显示。"
    },
    {
        "query":"我可以用 AVS 构建哪些类型的设备？",
        "intention":"知识问答",
        "reply":"对于生产低成本、资源受限的设备（包括电灯开关、灯泡、家用集线器、家用电器等）的设备制造商来说，适用于 AWS IoT 的 AVS 集成是个绝佳的解决方案，可以让客户直接使用唤醒词“Alexa”与这些产品对话，并立即收到语音回复和内容。这些设备将内置麦克风和扬声器，能够播放对话、提醒和新闻，但不足以支持高质量的音乐播放。若设备制造商希望使用更丰富的 Alexa 音乐播放功能（例如高保真度 [＞128kbps] 的音乐流、Spotify、多个扬声器上的同步音乐流），应继续使用现有的 Alexa 内置解决方案来构建这些设备。"
    },
    {
        "query":"我可以使用适用于 AWS IoT Core 的 AVS 集成来获得 Alexa 内置徽章吗？",
        "intention":"知识问答",
        "reply":"与其他 Alexa 内置产品类似，使用 AVS 集成构建的产品将需要通过 Alexa Voice Service 产品认证流程（包括 Amazon 管理的安全测试、声学性能、用户体验和功能测试），以获得 Amazon 认证的 Alexa 内置徽章。"
    },
    {
        "query":"哪些 AWS 区域已推出适用于 IoT Core 的 AVS 集成？",
        "intention":"知识问答",
        "reply":"除中国（北京和宁夏）、亚太地区（香港）和中东（巴林）外，其他所有 AWS 区域都已推出适用于 AWS IoT Core 的 AVS 集成功能。请参阅 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)了解当前提供 AWS IoT Core 服务的区域列表。"
    },
    {
        "query":"如果适用于 LoRaWAN 的 AWS IoT Core 要求提供基站源代码，我在哪里可以找到它？",
        "intention":"知识问答",
        "reply":"Semtech 通过其 Github 存储库维护和分发基站软件。"
    },
    {
        "query":"AWS IoT Core 和客户分别拥有和管理哪些私有 LoRaWAN 网络组件？",
        "intention":"知识问答",
        "reply":"设备：您拥有所选的 LoRaWAN 设备并将其连接到 AWS IoT Core。您可以购买任何符合 LoRa 1.0.3 或 1.1 规范的 LoRa 设备或传感器（无需开发或更新软件）。\n网关：您拥有所选的 LoRaWAN 网关并将其连接到 AWS IoT Core。AWS IoT Core 提供两种选择：您可以轻松地从 Amazon Partner Device Catalog 中选择并购买符合 AWS 条件的网关，该网关可随时与 AWS IoT Core 连接。或者，您可以通过将闲置（旧版）或现成（例如 Raspberry Pi）网关的固件更新为支持开源基站协议来进行连接。您可以在我们的入门指南中找到更新固件的说明。\nLoRaWAN 网络服务器 (LNS)：AWS IoT Core 拥有并提供完全托管的 LNS。在 AWS IoT 控制台上执行几个简单的步骤就可以注册所选硬件并显示来自已连接的 LoRaWAN 设备的消息。\n云应用程序：您拥有并开发自己的云应用程序。将设备连接到 AWS IoT Core 之后，您可以通过将设备消息路由到 AWS 服务来开始开发应用程序或解决方案。\n网络管理：AWS IoT Core 提供客户使用和配置以运行其 LoRaWAN 网络的网络管理功能。通过使用 AWS IoT 管理控制台，您可以查询已连接/已断开连接的设备和网关、设备流量属性以及收到的最后一条消息的网关统计信息。此外，您还可以通过使用 API 来远程更新 LoRaWAN 网关固件。  \n   \n LoRaWAN 是经 LoRa 联盟许可使用的商标。"
    },
    {
        "query":"谁应该使用 Device Advisor？",
        "intention":"知识问答",
        "reply":"设备制造商的开发人员应使用 [Device Advisor](https://aws.amazon.com/cn/iot-core/device-advisor/) 在预先构建的测试场景下测试其设备，以验证其是否能安全可靠地连接到 AWS IoT Core。Device Advisor 在 AWS 云中提供了一个测试端点，设备制造商可以立即使用它们来测试其设备，从而节省开发和测试的时间和成本。测试设置还为每个测试提供了详细的日志，从而可以更快地排除设备软件问题。Device Advisor 还为复杂的测试场景提供测试覆盖范围，使客户能够在其设备软件开发过程中发现并解决问题。这样可以提高部署后设备群的性能可靠性并降低其维护成本。\n此外，借助 IoT Device Advisor，硬件合作伙伴可以对他们的设备进行自我测试、下载已签名的认证报告并将报告提交给 APN，以使其设备列入 [AWS Partner Device Catalog](https://devices.amazonaws.com/) 中。"
    },
    {
        "query":"如何使用 Device Advisor？",
        "intention":"知识问答",
        "reply":"任何设计为可连接到 AWS IoT Core 的设备都可以利用 Device Advisor。设备制造商的开发人员可以从 AWS IoT Core 控制台或通过使用 AWS 开发工具包访问 Device Advisor。当开发人员准备好测试其设备后，他们可以在 AWS IoT Core 中注册设备并通过 Device Advisor 终端节点配置设备软件。然后，他们在 IoT Core 控制台中简单单击几下即可选择和执行预构建的测试，并立即获取测试结果以及详细的日志。"
    },
    {
        "query":"Device Advisor 提供了哪些测试？",
        "intention":"知识问答",
        "reply":"有关支持的预建测试的详细信息，请参见 [Device Advisor](https://docs.aws.amazon.com/iot/latest/developerguide/device-advisor.html) 中的“测试用例”部分。"
    },
    {
        "query":"什么是 AWS CloudHSM？",
        "intention":"知识问答",
        "reply":"AWS CloudHSM 服务通过在 AWS 云中使用专用的硬件安全模块 (HSM) 实例，帮助您满足企业、合同和监管合规性要求，以确保数据安全。AWS 和 AWS Marketplace 合作伙伴为保护 AWS 平台中的敏感数据提供了多种解决方案，但对于某些受管理加密密钥合同或监管要求约束的应用程序和数据，可能有必要提供额外的保护。CloudHSM 可补充现有的数据保护解决方案，让您可以在 HSM 内保护您的加密密钥，HSM 依据安全密钥管理的政府标准进行设计并经过验证。借助 CloudHSM，您可以安全地生成、存储和管理用于数据加密的加密密钥，使其只能由您访问。"
    },
    {
        "query":"什么是硬件安全模块 (HSM)？",
        "intention":"知识问答",
        "reply":"硬件安全模块 (HSM) 可在防篡改的硬件设备中提供安全密钥存储和加密操作。HSM 设计可以安全地存储和使用加密密钥材料，而不会使其暴露于硬件的加密边界之外。"
    },
    {
        "query":"CloudHSM 有何用途？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudHSM 服务支持各种适用案例和应用程序，例如，数据库加密、数字权限管理 (DRM)、公有密钥基础设施 (PKI)、身份验证和授权、文档签名和事务处理。"
    },
    {
        "query":"CloudHSM 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"使用 AWS CloudHSM 服务时，您需要创建 CloudHSM 集群。集群可以包含多个 HSM，它们分布在一个区域的多个可用区中。集群中的 HSM 会自动同步并进行负载均衡。您可获得对您的集群中每个 HSM 的专用单租户访问权限。每个 HSM 在 Amazon Virtual Private Cloud (VPC) 中都显示为网络资源。向集群中添加 HSM 或将其从中删除只需调用 AWS CloudHSM API（或在命令行上使用 AWS CLI）即可完成。创建和初始化 CloudHSM 集群后，您可以在 EC2 实例上配置一个客户端，以允许您的应用程序通过经过身份验证的安全网络连接使用该集群。\n该服务将自动监控您的 HSM 的运行状况，但 AWS 人员不会访问您的密钥或数据。您的应用程序将标准的加密 API 与应用程序实例上安装的 HSM 客户端软件配合使用，以向 HSM 发送加密请求。客户端软件可维护通向集群中所有 HSM 的安全通道，并在此通道上发送请求，而 HSM 执行相关操作并通过该安全通道返回结果。然后，客户端通过加密 API 将结果返回到应用程序。"
    },
    {
        "query":"目前，我没有 VPC。我还可以使用 AWS CloudHSM 吗？",
        "intention":"知识问答",
        "reply":"不可以。为了保护 AWS CloudHSM 并将其与其他亚马逊客户隔离，您必须在 Amazon VPC 内部预置 CloudHSM。创建 VPC 很容易。有关更多信息，请参阅 [VPC 入门指南](http://docs.aws.amazon.com/AmazonVPC/latest/GettingStartedGuide/ExerciseOverview.html)。"
    },
    {
        "query":"我的应用程序是否需要驻留在 CloudHSM 集群所在的 VPC 中？",
        "intention":"知识问答",
        "reply":"不需要。但您运行应用程序和 HSM 客户端的服务器或实例必须能够通过网络 (IP) 访问集群中的所有 HSM。您可以采用多种方式建立应用程序到 HSM 的网络连接，其中包括使用相同的 VPC、使用 VPC 对等、使用 VPN 连接或使用 Direct Connect。有关更多信息，请参阅 [VPC 对等指南](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/vpc-peering.html)和 [VPC 用户指南](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide)。"
    },
    {
        "query":"CloudHSM 是否能够与本地 HSM 配合使用？",
        "intention":"知识问答",
        "reply":"可以。当 CloudHSM 不能与本地 HSM 直接互操作时，您可以使用几个受支持的 RSA 密钥封装方法之一在 CloudHSM 与大多数商业化 HSM 之间安全传输可导出的密钥。"
    },
    {
        "query":"我的应用程序该如何使用 CloudHSM？",
        "intention":"知识问答",
        "reply":"我们将 CloudHSM 与很多第三方软件解决方案（如 Oracle Database 11g 和 12c，以及适用于 SSL 卸载的 Apache 和 Nginx 等 Web 服务器）进行了集成和测试。请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)，了解更多信息。\n如果您要开发自己的自定义应用程序，您的应用程序可以使用 CloudHSM 支持的标准 API，包括 PKCS#11 和 Java JCA/JCE (Java Cryptography Architecture/Java Cryptography Extensions) 或 Microsoft CAPI/CNG。请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)，获取代码示例和入门帮助。\n如果您将现有工作负载从 CloudHSM Classic 或本地 HSM 移动到 CloudHSM，可以参见我们的 [CloudHSM 迁移指南](https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/Docs/CloudHSMUpgradeGuide-latest.pdf)了解如何计划和执行您的迁移。"
    },
    {
        "query":"能否使用 CloudHSM 储存其他 AWS 产品使用的密钥或加密数据？",
        "intention":"知识问答",
        "reply":"能。您可以在与 CloudHSM 集成的应用程序中执行所有加密操作。在这种情况下，Amazon S3 或 Amazon Elastic Block Store (EBS) 等 AWS 产品将只能看到您的数据已加密。"
    },
    {
        "query":"其他 AWS 产品是否可以使用 CloudHSM 存储和管理密钥？",
        "intention":"知识问答",
        "reply":"AWS 服务与 AWS Key Management Service 集成，后者又通过 KMS 自定义密钥存储功能与 AWS CloudHSM 集成。如果要使用许多 AWS 服务（例如 EBS、S3 或 Amazon RDS）提供的服务器端加密，可以通过在 AWS KMS 中配置自定义密钥存储来实现。"
    },
    {
        "query":"CloudHSM 能否用于执行个人标识号 (PIN) 数据块转换或借记卡支付交易使用的其他加密操作？",
        "intention":"知识问答",
        "reply":"目前，CloudHSM 提供通用 HSM。日后我们可能会提供支付功能。如果您对此感兴趣，请[告知我们](https://pages.awscloud.com/cloudHSM-contact-us.html)。"
    },
    {
        "query":"如何开始使用 CloudHSM？",
        "intention":"知识问答",
        "reply":"您可以在 CloudHSM 控制台中预配置 CloudHSM 集群，也可以通过 AWS 开发工具包或 API 进行几次 API 调用来完成预配置。要了解更多信息，请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)获得入门信息，参阅 [CloudHSM 文档](https://aws.amazon.com/cn/documentation/cloudhsm/)了解关于 CloudHSM API 的信息，或访问“Amazon Web Services 工具”页面了解有关软件开发工具包的更多信息。"
    },
    {
        "query":"如何终止 CloudHSM 服务？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudHSM 控制台、API 或开发工具包删除 HSM，以停止使用该服务。有关更多说明，请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)。"
    },
    {
        "query":"CloudHSM 服务是否提供免费套餐？",
        "intention":"知识问答",
        "reply":"不。CloudHSM 不提供免费套餐。"
    },
    {
        "query":"您是否为 CloudHSM 提供预留实例定价？",
        "intention":"知识问答",
        "reply":"不，我们不为 CloudHSM 提供预留实例定价。"
    },
    {
        "query":"使用 CloudHSM 有前提条件吗？",
        "intention":"知识问答",
        "reply":"有。要开始使用 CloudHSM，您需要满足几个前提条件，包括在想使用 CloudHSM 服务的区域提供 Virtual Private Cloud (VPC)。有关更多信息，请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)。"
    },
    {
        "query":"我是否需要在自己的 HSM 上管理固件？",
        "intention":"知识问答",
        "reply":"不需要。AWS 会在硬件上管理固件。固件由第三方维护，并且每个固件都必须由 NIST 进行 FIPS 140-2 第 3 级合规性评估。只有由 FIPS 密钥加密签署的固件（AWS 对其无访问权限）才符合安装条件。"
    },
    {
        "query":"我的 CloudHSM 集群中应该有多少个 HSM？",
        "intention":"知识问答",
        "reply":"无论哪种生产工作负载，AWS 都强烈建议您使用位于两个不同可用区中的至少两个 HSM。对于关键任务型工作负载，我们建议您使用位于至少两个不同可用区中的至少三个 HSM。CloudHSM 客户端将自动处理所有 HSM 故障，并以透明方式实现两个或两个以上的 HSM 到应用程序的负载均衡。"
    },
    {
        "query":"密钥的持久性由谁负责？",
        "intention":"知识问答",
        "reply":"AWS 每天会对 CloudHSM 集群自动执行加密的备份，并在集群生命周期事件（如添加或删除 HSM）发生时进行额外备份。在备份间隔的 24 小时时段内，您需全权负责创建或导入集群中的密钥材料的持久性。我们强烈建议您将创建的所有密钥同步至位于两个不同可用区中的至少两个 HSM 中，以确保密钥的持久性。请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)，了解有关密钥同步验证的更多详细信息。"
    },
    {
        "query":"如何设置高可用性 (HA) 配置？",
        "intention":"知识问答",
        "reply":"当您的 CloudHSM 集群中拥有至少两个 HSM 时，系统会自动提供高可用性。无需其他配置。如果集群中的一个 HSM 出现故障，系统会自动将其替换，并更新所有客户端以反映新配置，而无需中断任何处理过程。其他 HSM 可通过 AWS API 或开发工具包添加到集群中，从而在不中断应用程序的情况下提高可用性。"
    },
    {
        "query":"CloudHSM 集群中可以包含多少个 HSM？",
        "intention":"知识问答",
        "reply":"一个 CloudHSM 集群最多可以包含 28 个 HSM，具体取决于账户服务限制。您可以在我们的[在线文档](https://docs.aws.amazon.com/cloudhsm/latest/userguide/limits.html)中了解有关服务限制级如何请求提高限制的更多信息。"
    },
    {
        "query":"是否可以备份 CloudHSM 中的内容？",
        "intention":"知识问答",
        "reply":"AWS 每天对 CloudHSM 集群进行备份。只要密钥的生成方式并非“不可导出”，您也可将其导出（“打包”）集群并存储在本地。"
    },
    {
        "query":"有适用于 CloudHSM 的 SLA 吗？",
        "intention":"知识问答",
        "reply":"有，您可以在[此处](https://aws.amazon.com/cloudhsm/sla/)找到适用于 AWS CloudHSM 的服务等级协议（SLA）。"
    },
    {
        "query":"我是否与其他 AWS 客户共享我的 CloudHSM？",
        "intention":"知识问答",
        "reply":"不可以。作为服务的一部分，您获得对 HSM 的单租户访问权限。您可以将底层硬件与其他客户共享，但 HSM 仅限您自己访问。"
    },
    {
        "query":"在没有加密密钥访问权限的情况下，AWS 如何管理 HSM？",
        "intention":"知识问答",
        "reply":"CloudHSM 在设计之初就考虑到了责任分离和基于角色的访问控制。AWS 拥有对 HSM 的有限凭证，让我们能够监控和维护 HSM 的运行状况和可用性，获取加密的备份，提取审核日志并将其发布到您的 CloudWatch Logs 中。AWS 不能访问 CloudHSM 集群内的任何密钥或数据，且不能执行 [HSM 设备用户](https://docs.aws.amazon.com/cloudhsm/latest/userguide/hsm-users.html#appliance-user)允许的操作之外的任何操作。\n请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)，了解有关责任分离及各类用户拥有的 HSM 功能的更多信息。"
    },
    {
        "query":"能否监控我的 HSM？",
        "intention":"知识问答",
        "reply":"有。CloudHSM 针对 CloudHSM 集群和各个 HSM 发布了多个 CloudWatch 指标。您可以使用 AWS CloudWatch 控制台、API 或开发工具包获取这些指标或针对其发布警报。"
    },
    {
        "query":"CloudHSM 的“熵源”（随机源）是什么？",
        "intention":"知识问答",
        "reply":"每个 HSM 都拥有一个经 FIPS 验证的 确定性随机数生成器 (DRBG)，该生成器在由符合 SP800-90B 的 HSM 硬件模块中的真随机数生成器 (TRNG) 的基础上形成。这是一种高质量熵源，每秒可为每个 HSM 生成 20Mb 熵。"
    },
    {
        "query":"如果有人擅自改动 HSM 硬件会怎样？",
        "intention":"知识问答",
        "reply":"CloudHSM 具有物理和逻辑篡改检测和响应机制，可触发硬件的密钥删除（清零）。该硬件可以在物理屏障被突破后有效检测篡改行为。HSM 还可免受暴力登录攻击。在尝试使用加密员 (CO) 凭证访问 HSM 失败一定次数后，HSM 会锁定 CO。同样地，在尝试使用加密用户 (CU) 凭证访问 HSM 失败一定次数后，用户即会被锁定，必须由 CO 解锁。"
    },
    {
        "query":"发生故障时会怎样？",
        "intention":"知识问答",
        "reply":"Amazon 会监控和维护 HSM 和网络的可用性和错误状况。如果 HSM 发生故障或网络连接中断，系统即会自动替换该 HSM。您可以使用 CloudHSM API、软件开发工具包或 CLI 工具检查单个 HSM 的运行状况，还可以使用 [AWS 产品运行状况控制面板](http://status.aws.amazon.com/)随时检查服务的整体运行状况。"
    },
    {
        "query":"如果单个 HSM 出现故障，我的密钥会丢失吗？",
        "intention":"知识问答",
        "reply":"如果您的 CloudHSM 集群只有一个 HSM，就有可能会丢失您在最新的日程备份后创建的密钥。有两个或多个 HSM（理想情况下，在单独的可用区中）的 CloudHSM 集群将不会在单一 HSM 出现故障时丢失密钥。请参阅我们的[最佳实践](https://docs.aws.amazon.com/cloudhsm/latest/userguide/best-practices.html)了解更多信息。"
    },
    {
        "query":"如果我的 HSM 凭证丢失，Amazon 是否可以恢复我的密钥？",
        "intention":"知识问答",
        "reply":"不可以。Amazon 不能访问您的密钥或凭证，因此在您丢失凭证时无法恢复您的密钥。"
    },
    {
        "query":"我如何确定自己可以信任 CloudHSM ？",
        "intention":"知识问答",
        "reply":"CloudHSM 是在经联邦信息处理标准 (FIPS) 140-2 第 3 级验证的硬件的基础之上构建而成。要了解 CloudHSM 所使用硬件的 FIPS 140-2 安全配置文件及其运行的固件，可以访问我们的[合规性页面](https://docs.aws.amazon.com/cloudhsm/latest/userguide/fips-validation.html)。"
    },
    {
        "query":"CloudHSM 服务是否支持 FIPS 140-2 第 3 级？",
        "intention":"知识问答",
        "reply":"支持。CloudHSM 提供经 FIPS 140-2 第 3 级验证的 HSM。可以遵循 [CloudHSM 用户指南](https://aws.amazon.com/documentation/cloudhsm/)中[验证 HSM 的真实性](https://docs.aws.amazon.com/cloudhsm/latest/userguide/verify-hsm-identity.html)部分下的过程，以确认上一个问题中描述的 NIST 安全策略中指定的相同型号硬件上是否拥有真实的 HSM。"
    },
    {
        "query":"如何在 FIPS 140-2 模式下运行 CloudHSM？",
        "intention":"知识问答",
        "reply":"CloudHSM 始终处于 FIPS 140-2 模式中。这一点可以使用 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)中提及的 CLI 工具并运行 getHsmInfo 命令进行验证，这一操作将指明 FIPS 模式状态。"
    },
    {
        "query":"我是否可以获取从我的账户发起的所有 CloudHSM API 调用的历史记录？",
        "intention":"知识问答",
        "reply":"可以。[AWS CloudTrail](https://aws.amazon.com/cn/cloudtrail/) 会记录账户发起的 AWS API 调用。由 CloudTrail 生成的 AWS API 调用历史记录让您可以执行安全分析、资源变更追踪以及合规性审计。有关 CloudTrail 的更多信息，请参阅 CloudTrail 主页，可通过 [CloudTrail 的 AWS 管理控制台](https://console.aws.amazon.com/cloudtrail/home)将其打开。"
    },
    {
        "query":"哪些事件未记录在 CloudTrail 中？",
        "intention":"知识问答",
        "reply":"CloudTrail 不包含任何 HSM 设备或访问日志。系统直接通过 CloudWatch Logs 将这些日志提供给您的 AWS 账户。有关更多详细信息，请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)。"
    },
    {
        "query":"哪些 AWS 合规性计划包含 CloudHSM？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 合规性](https://aws.amazon.com/cn/compliance/)站点，了解有关包含 CloudHSM 的合规性计划的更多信息。与其他 AWS 产品不同，关于 CloudHSM 的合规性要求通常直接由硬件的 FIPS 140-2 第 3 级验证本身满足，而不是作为独立审核计划的一部分满足。"
    },
    {
        "query":"为什么 FIPS 140-2 第 3 级至关重要？",
        "intention":"知识问答",
        "reply":"FIPS 140-2 第 3 级是某些使用案例（包括文档签名、付款，或作为 SSL 证书的公有证书颁发机构运营）的要求。"
    },
    {
        "query":"我该如何请求将 CloudHSM 的合规性报告纳入范围？",
        "intention":"知识问答",
        "reply":"要了解 CloudHSM 涵盖哪些合规性报告，查阅 [AWS 按合规性计划提供的范围内服务](https://aws.amazon.com/compliance/services-in-scope/)上的数据。要创建免费、自助的按需合规性报告，使用 [AWS Artifact](https://aws.amazon.com/cn/artifact/)。\n如果您仅对 CloudHSM 提供的 FIPS 对 HSM 的验证感兴趣，请参阅 [FIPS 验证](https://docs.aws.amazon.com/cloudhsm/latest/userguide/fips-validation.html)。"
    },
    {
        "query":"CloudHSM 每秒可执行多少个加密操作？",
        "intention":"知识问答",
        "reply":"AWS CloudHSM 集群的性能因特定工作负载而异。下表显示了在 EC2 实例上运行的常见加密算法的大致性能。为了提高性能，您可以向集群添加更多 HSM 实例。性能可能因配置、数据大小和 EC2 实例上的额外应用程序负载而异。我们鼓励对您的应用程序进行负载测试以确定扩展需求。\n|  |  |  |  |\n| --- | --- | --- | --- |\n| 操作 | 双 HSM 集群 [1] | 三 HSM 集群 [2] | 六 HSM 集群 [3] |\n| RSA 2048 位标志 | 2000 次操作/秒 | 3000 次操作/秒 | 5000 次操作/秒 |\n| EC p256 标志 | 500 次操作/秒 | 750 次操作/秒 | 1500 次操作/秒 |\n有关更多详细信息，请参阅 AWS CloudHSM 用户指南中的[性能页面](https://docs.aws.amazon.com/cloudhsm/latest/userguide/performance.html)。\n[1]：一个双 HSM 集群，Java 多线程应用程序在一个 [c4.large](https://aws.amazon.com/ec2/instance-types/) EC2 实例上运行，一个 HSM 与 EC2 实例位于同一个可用区。\n[2]：一个三 HSM 集群，Java 多线程应用程序在一个 [c4.large](https://aws.amazon.com/ec2/instance-types/) EC2 实例上运行，一个 HSM 与 EC2 实例位于同一个可用区。\n[3]：一个六 HSM 集群，Java 多线程应用程序在一个 [c4.large](https://aws.amazon.com/ec2/instance-types/) EC2 实例上运行，两个 HSM 与 EC2 实例位于同一个可用区。"
    },
    {
        "query":"CloudHSM 集群上可以存储多少个密钥？",
        "intention":"知识问答",
        "reply":"CloudHSM 集群最多可以存储 3300 个任意类型、任意大小的密钥。"
    },
    {
        "query":"CloudHSM 是否支持 Amazon RDS Oracle TDE？",
        "intention":"知识问答",
        "reply":"不能直接这样使用。您应该使用带有自定义密钥存储的 AWS Key Management Service，通过在 AWS CloudHSM 集群中生成和存储的密钥来保护 Amazon RDS 数据。"
    },
    {
        "query":"我是否能将 CloudHSM 用作其他软件的可信根？",
        "intention":"知识问答",
        "reply":"[多个第三方供应商](https://docs.aws.amazon.com/cloudhsm/latest/userguide/other-integrations.html) 支持将 AWS CloudHSM 用作可信根。这意味着，您在 CloudHSM 集群中创建并存储底层密钥时可以利用您选择的软件解决方案。"
    },
    {
        "query":"什么是 CloudHSM 客户端？",
        "intention":"知识问答",
        "reply":"CloudHSM 是 AWS 提供的一款软件包，让您和您的应用程序能够与 CloudHSM 集群交互。"
    },
    {
        "query":"CloudHSM 客户端是否向 AWS 授予了对我的 CloudHSM 集群的访问权限？",
        "intention":"知识问答",
        "reply":"没有。该客户端和您的 HSM 之间的所有通信都进行了端到端加密。AWS 无法查看或拦截这些通信，也无法查看您的集群访问凭证。"
    },
    {
        "query":"什么是 CloudHSM 命令行界面 (CLI) 工具？",
        "intention":"知识问答",
        "reply":"CloudHSM 客户端配有一套 CLI 工具，让您能够从命令行管理和使用 HSM。目前支持 Linux 和 Microsoft Windows。我们还计划支持 Apple macOS。这些工具在 CloudHSM 客户端所在的相同软件包中提供。"
    },
    {
        "query":"如何下载并开始使用 CloudHSM 命令行界面工具？",
        "intention":"知识问答",
        "reply":"有关说明，请参阅 [CloudHSM 用户指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/)"
    },
    {
        "query":"CloudHSM CLI 工具是否为 AWS 提供了访问 HSM 内容的权限？",
        "intention":"知识问答",
        "reply":"没有。CloudHSM 工具可使用 CloudHSM 客户端通过经手动验证的安全通道，与您的 CloudHSM 集群直接通信。AWS 无法观察客户端、工具和 HSM 之间的任何通信，因为通信是端到端加密的。"
    },
    {
        "query":"我可以在哪些操作系统上使用 CloudHSM 客户端和 CLI 工具？",
        "intention":"知识问答",
        "reply":"支持操作系统的完整列表见我们的[在线文档](https://docs.aws.amazon.com/cloudhsm/latest/userguide/client-supported-platforms.html)。"
    },
    {
        "query":"使用 CloudHSM 命令行界面工具有哪些网络连接要求？",
        "intention":"知识问答",
        "reply":"您运行 CloudHSM 客户端和/或使用 CLI 工具所在的主机必须能够通过网络访问 CloudHSM 集群中的所有 HSM。"
    },
    {
        "query":"我可以使用 CloudHSM API 和软件开发工具包做什么？",
        "intention":"知识问答",
        "reply":"您可以创建、修改、删除和获取 CloudHSM 集群与 HSM 的状态。您可以使用 AWS CloudHSM API 执行的操作限于 AWS 通过其受限的访问权限可执行的操作。API 无法访问 HSM 的内容，也无法修改任何用户、策略或其他设置。要了解更多信息，请参阅 [CloudHSM 文档](https://aws.amazon.com/cn/documentation/cloudhsm/)了解有关 API 的信息，或访问 [Amazon Web Services 工具](https://aws.amazon.com/cn/tools/)页面了解有关软件开发工具包的更多信息。"
    },
    {
        "query":"我应该如何规划向 AWS CloudHSM 的迁移？",
        "intention":"知识问答",
        "reply":"首先，确保 [CloudHSM](https://docs.aws.amazon.com/cloudhsm/latest/userguide/pkcs11-library.html) 支持您所需的算法和模型。如果需要，可以请您的客户经理向我们提交功能请求。然后是确定您的密钥轮换策略。有关常见使用案例的建议，请参阅下一个问答。我们还发布了深入的 [CloudHSM 迁移指南](https://s3.amazonaws.com/cloudhsmv2-software/CloudHsmClient/Docs/CloudHSMUpgradeGuide-latest.pdf)。您现在可以随时[开始使用](https://docs.aws.amazon.com/cloudhsm/latest/userguide/getting-started.html) CloudHSM。"
    },
    {
        "query":"如何轮换我的密钥？",
        "intention":"知识问答",
        "reply":"您的轮换策略取决于应用程序的类型。常见示例如下："
    },
    {
        "query":"AWS CloudHSM 是否具有计划的维护时段？",
        "intention":"知识问答",
        "reply":"否，但 AWS 可能需要在进行必要的升级或硬件发生故障时执行维护。如果有任何影响，我们将尽力通过 Personal Health Dashboard 提前通知您。\n请注意，架构集群以获得高可用性是您的责任。AWS 强烈建议您使用在不同可用区中含有两个或更多 HSM 的 CloudHSM 集群。您可以在我们的[在线文档](https://docs.aws.amazon.com/cloudhsm/latest/userguide/best-practices.html)中了解有关建议最佳实践的更多信息。"
    },
    {
        "query":"我在使用 CloudHSM 时遇到问题。我该怎么办？",
        "intention":"知识问答",
        "reply":"您可以在我们的[故障排除指南](https://docs.aws.amazon.com/cloudhsm/latest/userguide/troubleshooting.html)中找到常见问题的解决方案。如果您仍然遇到问题，请联系 [AWS Support](https://console.aws.amazon.com/support/home)。"
    },
    {
        "query":"Amazon Augmented AI (Amazon A2I) 是什么？",
        "intention":"知识问答",
        "reply":"Amazon Augmented AI (Amazon A2I) 是一种服务，可轻松构建人工审核 ML 预测所需的工作流。Amazon A2I 为所有开发人员带来人工审核，消除了与构建人工审核系统或管理大量人工审核人员相关的千篇一律的繁重工作。"
    },
    {
        "query":"为什么使用 Amazon A2I？",
        "intention":"知识问答",
        "reply":"许多机器学习应用程序都要求对低置信度预测进行人工审核，以确保结果正确无误。例如，在某些情况下，由于扫描质量差或手写字迹潦草，从扫描的按揭申请表格中提取信息可能需要人工审核。但是，构建人工审核系统既费时又成本高昂，因为它涉及实施复杂的流程或“工作流”，编写自定义软件来管理审核任务和结果，而且在许多情况下，还需要管理大量审核人员。\nAmazon A2I 可轻松构建和管理机器学习应用程序的人工审核。Amazon A2I 为常见机器学习用例提供内置的人工审核工作流，例如内容审核和文档中的文本提取，这可以轻松地审核 Amazon Rekognition 和 Amazon Textract 的预测。您还可以为基于 Amazon SageMaker 或任何其他工具构建的 ML 模型创建自己的工作流。借助 Amazon A2I，当模型无法进行高置信度预测或持续审计其预测时，您可以允许人工审核人员介入。"
    },
    {
        "query":"如何开始使用 Amazon A2I？",
        "intention":"知识问答",
        "reply":"Amazon A2I 提供托管体验，您可以通过几个简单步骤设置整个人工审核工作流。要开始使用 Amazon A2I，请登录 AWS 控制台，然后导航至 Amazon SageMaker 控制台。在此处，选择 Augmented AI 下的人工审核工作流。首先，作为人类审核工作流的一部分，您提供一个指向 S3 存储桶的指针，该存储桶应存储审核结果。接下来，选择适当的任务类型并定义应触发人工审核的条件。Amazon A2I 提供预构建的工作流，您只需输入几个选项，并提供相关说明，供人工审核人员参考咦审核您的对象。或者，您可以创建自己的自定义工作流并使用自己的自定义审核模板。创建工作流后，可以使用为此工作流生成的唯一标识符直接在应用程序中使用该工作流。"
    },
    {
        "query":"如何决定需发送哪些对象以进行人工审核？",
        "intention":"知识问答",
        "reply":"使用 A2I，您可以定义业务问题的可接受预测置信度。您可以定义机器学习预测的业务规则，根据这些规则触发人工审核。对于 Amazon Rekognition 图片审核任务，您可以使用 Amazon Rekognition 为其输出的每个标签提供的置信度得分来触发人工审核。对于 Amazon Textract 任务，当特定的表单密钥缺失或表单密钥检测置信度较低时，您可以触发人工审核。如果在对文本中的所有表单密钥进行评估后，置信度低于任何表单密钥所需的阈值，您也可以触发人工审核。对于您自己的自定义工作流，您可以在 AWS Lambda 中或直接在客户端应用程序中编写业务条件代码。"
    },
    {
        "query":"我如何使用 Amazon A2I 访问人力？",
        "intention":"知识问答",
        "reply":"在 Amazon A2I，有三种人力选项可供您选择：(1) Amazon Mechanical Turk；(2) 来自 AWS Marketplace 的可用第三方数据标记服务提供商；以及 (3) 您自己的员工。查看 [Amazon A2I 开发人员指南](https://docs.aws.amazon.com/sagemaker/latest/dg/use-augmented-ai-a2i-human-review-loops.html)了解更多信息。"
    },
    {
        "query":"哪些 AWS 区域提供 Amazon A2I？",
        "intention":"知识问答",
        "reply":"[AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)列出了当前已推出 Amazon A2I 的所有 AWS 区域。"
    },
    {
        "query":"Amazon Augmented AI 第三方服务提供商是否可能处理客户的保密数据？",
        "intention":"知识问答",
        "reply":"是的，Amazon Augmented AI 服务提供商可能会处理客户的保密数据。AWS 客户与第三方服务提供商之间的标准服务协议包括了保护您的保密信息的条款。在与服务提供商共享任何保密信息之前，请仔细阅读这些条款。这些条款位于 [AWS Marketplace](https://aws.amazon.com/marketplace/b/2649399011?ref_=header_nav_category_2649399011) 上的服务提供商列示内容页。"
    },
    {
        "query":"我正在通过 AWS Marketplace 与第三方服务提供商合作。服务提供商推出了哪些应变措施来应对 COVID-19 疫情的影响？",
        "intention":"知识问答",
        "reply":"由于 COVID-19 疫情的影响愈演愈烈，一些服务提供商决定暂时实施远程工作政策，以保护其员工的健康和安全。在此期间，以下常见问题中提到的包括 SOC 2 合规性和其他安全控制措施在内的安全标准可能不适用于受影响的服务提供商。受影响的服务提供商已更新其 AWS Marketplace 列示内容以反映此变化，并且不会在未得到客户明确同意的情况下通过远程工作环境处理客户数据。"
    },
    {
        "query":"Amazon Augmented AI 第三方服务提供商需要满足哪些安全标准？",
        "intention":"知识问答",
        "reply":"人工审核服务提供商每年都需要通过 SOC 2 合规性和认证。SOC 2 报告基于美国注册会计师协会 (AICPA) 的信托服务标准——安全性、可用性、处理完整性、机密性和隐私性对服务提供商的控制环境进行说明。\n除了 SOC 2 之外，服务提供商还需要维护额外的安全控制，以保持客户数据的安全。\n技术控制：  \n 服务提供商需要利用适当的软件来阻止从系统中下载或复制文件/数据的任何尝试及防止对其系统的未授权访问。服务提供商还需要禁止其员工在服务提供商的安全环境之外存储或复制与客户任务相关的数据。\n网络安全控制：  \n 服务提供商必须禁止对客户任务相关数据的远程访问。此外，服务提供商的网络也应屏蔽点对点文件共享软件。\n员工控制：  \n 服务提供商需要确保与其员工签订保密协议 (NDA)。服务提供商必须采纳严格的政策以防止员工将客户任务相关的数据复制或移动到服务提供商的安全环境之外，包括建立有关纸质、USB、手机或其他介质的控制措施。\n物理访问控制：  \n 服务提供商需要建立物理访问控制措施，以防其生产场所受到未经授权访问。这可能包括生物特征身份验证、员工工作证、保安人员对员工的肉眼检查等。"
    },
    {
        "query":"AWS 如何帮助确保服务提供商符合这些安全标准？",
        "intention":"知识问答",
        "reply":"AWS 要求服务提供商在上市前提供 SOC 2 认证报告并确认：\n真实性（服务提供商的审计师是否获得 AICPA 认证）；\n报告期间（SOC 2 认证有效期）；以及\n生产场所验证（服务提供商员工处理 Amazon Augmented AI 任务所在的物理场所）。"
    },
    {
        "query":"服务提供商安全标准的审查频率如何？",
        "intention":"知识问答",
        "reply":"每位服务提供商的安全性标准每年审核一次，以确保他们满足强制性要求。"
    },
    {
        "query":"AWS 的审核是否有任何例外？",
        "intention":"知识问答",
        "reply":"没有。如果服务提供商不满足安全标准，则他们的列示内容将从 [AWS Marketplace](https://aws.amazon.com/marketplace/b/2649399011?ref_=header_nav_category_2649399011) 中移除。对列示内容的移除将在 24 小时内完成，且所有受影响的客户都将收到电子邮件通知。"
    },
    {
        "query":"如果服务提供商通过多个生产场所提供人工审核服务，是否所有场所都需要经过审核过程？",
        "intention":"知识问答",
        "reply":"是，所有场所都需要符合所需的安全标准。"
    },
    {
        "query":"如果服务提供商生产场所发生未经授权访问，会发生什么？",
        "intention":"知识问答",
        "reply":"服务提供商将在实际检测到或者怀疑发生任何未经授权的客户信息访问、收集、获取、使用、传输、披露、损坏或丢失情况的 24 小时内通知 AWS 和受影响的客户。服务提供商将立即处理每一个安全事件并向 AWS 和受影响的客户提供说明内部调查的书面详细信息。"
    },
    {
        "query":"我的数据存储在哪里？",
        "intention":"知识问答",
        "reply":"创建 Amazon S3 存储桶时，您可以指定一个 AWS 区域。对于 S3 Standard、S3 Standard-IA、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类，您的对象会自动存储在至少三个可用区（AZ）中的多个设备上。 可用区与任何其他可用区都间隔一定距离，不过彼此都在 100 公里（60 英里）以内。存储在 S3 One Zone-IA 存储类中的对象将以冗余方式存储在您选择的 AWS 区域的单个可用区中。对于 S3 on Outposts，您的数据将存储在 Outpost 本地环境中，除非您手动选择将该数据传输到 AWS 区域。请参阅 [AWS 区域性服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 Amazon S3 服务在不同 AWS 区域的具体提供情况。"
    },
    {
        "query":"什么是 AWS 区域？",
        "intention":"知识问答",
        "reply":"[AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regions_az/)是世界各地的 AWS 集群数据中心的物理位置。  区域内的每组逻辑数据中心称为可用区（AZ）。每个 AWS 区域由一个地理区域内的至少三个隔离的且在物理上分隔的可用区组成。 与其他通常将区域定义为一个数据中心的云提供商不同的是，为每个 AWS 区域设计多个可用区可为客户提供优势。每个可用区都有独立的电力、冷却和物理安全性，并通过冗余的超低延迟网络连接。"
    },
    {
        "query":"什么是 AWS 可用区（AZ）？",
        "intention":"知识问答",
        "reply":"[可用区（AZ）](https://aws.amazon.com/cn/about-aws/global-infrastructure/regions_az/)是指 AWS 区域中一个或多个具有冗余电源、联网和连接的离散数据中心。可用区让客户能够运行在可用性、容错能力和可扩展性方面比单个数据中心更强的生产应用程序和数据库。一个 AWS 区域中的所有可用区都通过高带宽、低延迟网络与完全冗余的专用城域光纤互连，为可用区之间提供高吞吐量和低延迟的联网。\nAmazon S3 Standard、S3 Standard-Infrequent Access、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类在至少三个可用区中复制数据，以免整个可用区丢失。在公开提供的可用区不足 3 个的区域中，这种情况仍然存在。存储在这些存储类中的对象可从单个 AWS 区域的所有可用区进行访问。\nAmazon S3 单区 – IA 存储类在单个可用区内复制数据。存储在 S3 One Zone-IA 中的数据对由于地震、火灾和洪水等灾难导致的可用区的物理损失不具有弹性。"
    },
    {
        "query":"如何确定将数据存储在哪个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"需要基于您的特定应用程序考虑多个因素。例如，您可能希望将数据存储在靠近客户、数据中心或其他 AWS 资源的区域中，以减少数据访问延迟。您也可能希望将数据存储在远离其他运营的区域中，以实现地理位置冗余和灾难恢复目的。您还应该考虑可让您满足特定法律和法规要求和/或降低存储成本的区域 – 您可以选择价格较低的区域以节省开支。有关 S3 定价的信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"Amazon S3 在全球哪些地区提供？",
        "intention":"知识问答",
        "reply":"Amazon S3 在全球所有 AWS 区域中提供，无论您身处何地，都可以使用 Amazon S3。您只需决定要将 Amazon S3 数据存储在哪个 AWS 区域中即可。请参阅 [AWS 区域服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，获取当前提供 S3 的 AWS 区域的列表。"
    },
    {
        "query":"如果我使用其他 AWS 账户访问 Amazon S3 存储桶，应该如何付费？",
        "intention":"知识问答",
        "reply":"当您使用其他 AWS 账户访问存储时，我们将按正常 Amazon S3 定价收费。或者，您也可以选择将存储桶配置为申请方付款存储桶，在这种情况下，将由申请方支付 Amazon S3 数据的相关申请和下载费用。\n有关申请方付款存储桶配置的更多信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html)。"
    },
    {
        "query":"什么是 IPv6？",
        "intention":"知识问答",
        "reply":"连接到 Internet 的每个服务器和设备都必须具有一个唯一地址。Internet 协议版本 4 (IPv4) 是原始的 32 位寻址方案。但是，Internet 的持续发展意味着所有可用的 IPv4 地址都将随着时间而被用尽。Internet 协议版本 6 (IPv6) 是寻址机制，设计用以克服 IPv4 的全球地址限制。"
    },
    {
        "query":"IPv6 可以用来做什么？",
        "intention":"知识问答",
        "reply":"使用适用于 Amazon S3 的 IPv6 支持，应用程序无需任何 IPv6 到 IPv4 转换软件或系统即可连接到 Amazon S3。您可以满足合规性要求，更轻松地与基于 IPv6 的现有本地应用程序集成，并且无需购买昂贵的联网设备来处理地址转换。您还可以借助 IPv6 地址利用 IAM 策略和存储桶策略中现有的源地址筛选功能，扩大您的选择范围以确保应用程序与 Amazon S3 安全交互。"
    },
    {
        "query":"如何在 Amazon S3 上开始使用 IPv6？",
        "intention":"知识问答",
        "reply":"首先，您可以将应用程序指向 [Amazon S3 的“双堆栈”端点](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)，该端点同时支持通过 IPv4 和 IPv6 访问。在大多数情况下，无需进一步配置即可通过 IPv6 进行访问，因为大多数网络客户端倾向于默认使用 IPv6 地址。 因使用 IPv6 受到影响的应用程序可以随时切换回仅支持 IPv4 的标准端点。支持在所有商业 AWS 区域将 IPv6 用于 Amazon S3，包括 AWS GovCloud（美国）区域、由光环新网运行的 Amazon Web Services 中国（北京）区域、由宁夏西云数据运行的 Amazon Web Services 中国（宁夏）区域。"
    },
    {
        "query":"使用 IPv6 时，Amazon S3 的性能是否会出现变化？",
        "intention":"知识问答",
        "reply":"不会，不论是使用 IPv4 还是 IPv6，Amazon S3 的性能都相同。"
    },
    {
        "query":"什么是 Amazon S3 事件通知？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)功能在 S3 存储桶中发生某些事件时接收通知，例如 PUT、POST、COPY 和 DELETE 事件。您可以将通知发布到 [Amazon EventBridge](https://aws.amazon.com/cn/eventbridge/)、[Amazon SNS](https://aws.amazon.com/cn/sns/)、[Amazon SQS](https://aws.amazon.com/cn/sqs/)，或直接发布到 [AWS Lambda](https://aws.amazon.com/cn/lambda/)。"
    },
    {
        "query":"我可以用 Amazon S3 事件通知做什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 事件通知可让您运行工作流、发送提醒或执行其他操作来响应 S3 中存储对象的更改。您可以使用 S3 事件通知来设置触发器以执行各种操作，包括在上传媒体文件时对其执行转码、在数据文件可用时对其进行处理以及将 S3 对象与其他数据存储同步。您还可以根据对象名前缀和后缀来设置事件通知。例如，您可以选择接收以 “images/” 开头的对象名称的通知。"
    },
    {
        "query":"Amazon S3 事件通知中包含什么？",
        "intention":"知识问答",
        "reply":"有关 Amazon S3 事件通知消息中包含的信息的详细说明，请参阅[配置 Amazon S3 事件通知文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)。"
    },
    {
        "query":"如何设置 Amazon S3 事件通知？",
        "intention":"知识问答",
        "reply":"关于如何配置事件通知的详细描述，请参阅[配置 Amazon S3 事件通知文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)。您可以在 [Amazon SNS 文档](http://docs.aws.amazon.com/sns/latest/dg/welcome.html)和 [Amazon SQS 文档](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)中了解有关 AWS 消息收发服务的更多信息。"
    },
    {
        "query":"什么是 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"[Amazon S3 Transfer Acceleration](https://aws.amazon.com/cn/s3/transfer-acceleration/) 可在客户与您的 Amazon S3 存储桶之间创建快速、轻松、安全的远距离文件传输。S3 Transfer Acceleration 利用了 Amazon CloudFront 遍布全球的 [AWS 边缘站点](https://aws.amazon.com/cn/hybrid/)。数据到达某个 AWS 边缘站点时，即被通过优化的网络路径路由至您的 Amazon S3 存储桶。"
    },
    {
        "query":"如何开始使用 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"要开始使用 S3 Transfer Acceleration，请使用 [Amazon S3 控制台](https://s3.console.aws.amazon.com/s3/home)、Amazon S3 API 或 AWS CLI 在 S3 存储桶上[启用 S3 Transfer Acceleration](http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-getting-started)。启用 S3 Transfer Acceleration 后，您可以将 Amazon S3 PUT 和 GET 请求指向 s3-accelerate 端点的域名。您的数据传输应用程序必须使用以下两种终端节点类型中的一种，以访问用于更快的数据传输的存储桶：“双堆栈”终端节点的 .s3-accelerate.amazonaws.com 或 .s3-accelerate.dualstack.amazonaws.com。如果您想要使用标准数据传输，可以继续使用常规终端节点。\n对于支持 S3 Transfer Acceleration 的存储桶有一定限制。有关详细信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-requirements)。"
    },
    {
        "query":"S3 Transfer Acceleration 有多快？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 可帮助您充分利用带宽，最大限度地降低距离对吞吐量的影响。无论客户位于何方，S3 Transfer Acceleration 都能确保数据快速、稳定地传输到 Amazon S3。加速的幅度主要取决于您的可用带宽、源和目标之间的距离以及网络路径上的数据包丢失率。通常，源和目标之间的距离越远、可用带宽越多和/或对象大小越大，加速的幅度越大。\n一位客户的测量结果是：从分布在美国、欧洲和部分亚洲地区的全球用户群向亚太地区（悉尼）的存储桶摄入 300MB 的文件，平均传输时间可以缩短 50%。而另一位客户观察到，从东南亚和澳大利亚的用户向美国东部（弗吉尼亚州北部）的 S3 存储桶上传 250MB 文件（分成 50MB 大小的几个部分）时，性能提升超过 500%。\n访问 [S3 Transfer Acceleration 速度比较工具](http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html)，预览您所在位置能获得的性能提升！"
    },
    {
        "query":"谁应该使用 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 旨在优化从世界各地向 S3 存储桶传输数据的速度。如果您从多个分散的地点向一个集中的存储桶上传数据，或者如果您经常需要跨各大洲传输 GB 或 TB 级的数据，使用 S3 Transfer Acceleration 节约的数据传输时间可以达到数小时或者数天。"
    },
    {
        "query":"S3 Transfer Acceleration 的安全性如何？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 的安全性与 Amazon S3 的常规传输相同。同样支持所有 Amazon S3 安全功能，例如基于客户端的 IP 地址来限制访问。S3 Transfer Acceleration 与客户端通过标准 TCP 通信，无需更改防火墙。[AWS 边缘站点](https://aws.amazon.com/cn/hybrid/)不会存储任何数据。"
    },
    {
        "query":"如果 S3 Transfer Acceleration 的传输速度不及常规 Amazon S3，怎么办？",
        "intention":"知识问答",
        "reply":"每当您使用 S3 Transfer Acceleration 上传对象时，我们都会检查 S3 Transfer Acceleration 的传输速度是否有可能比常规 Amazon S3 传输更快。在将同一对象传输到同一目标 AWS 区域时，如果我们确定 S3 Transfer Acceleration 的传输速度不会快于常规 Amazon S3，那么对于此次使用 S3 Transfer Acceleration 进行的传输，我们将不会收取任何费用，并且可能会绕过该次上传的 S3 Transfer Acceleration 系统。"
    },
    {
        "query":"我可以对分段上传使用 S3 Transfer Acceleration 吗？",
        "intention":"知识问答",
        "reply":"可以，S3 Transfer Acceleration 支持所有存储桶级别的功能，包括分段上传。"
    },
    {
        "query":"在 S3 Transfer Acceleration 和 Amazon CloudFront 的 PUT/POST 之间，我应该如何选择？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 优化了 TCP 协议，并在客户端与 S3 存储桶之间添加了更多智能，因此如果需要更高的吞吐量，S3 Transfer Acceleration 就是更好的选择。如果您的对象小于 1GB，或者如果数据集小于 1GB，则应该考虑使用 Amazon CloudFront 的 PUT/POST 命令来优化性能。"
    },
    {
        "query":"在 S3 Transfer Acceleration 和 AWS Snow Family（Snowball、Snowball Edge 和 Snowmobile）之间，我应该如何选择？",
        "intention":"知识问答",
        "reply":"要一次性移动大批量数据，[AWS Snow Family](https://aws.amazon.com/cn/snow/) 就是客户的理想选择。AWS Snowball 的周转时间通常为 5-7 天。一般来说，通过一条充分利用的 1Gbps 线路，S3 Transfer Acceleration 在同样的时间期限内最多可以传输 75TB 数据。总之，如果通过 Internet 传输所需的时间超过一个星期，或者如果需要反复传输任务且可用带宽超过 25Mbps，S3 Transfer Acceleration 就是不错的选择。另一个选择是同时使用两者：利用一个 AWS Snowball（或一系列 AWS Snowball）执行最初繁重的传输任务，然后利用 S3 Transfer Acceleration 传输递增的日常变更。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为 AWS Direct Connect 的补充吗？",
        "intention":"知识问答",
        "reply":"如果客户拥有专用联网要求或者能访问 AWS Direct Connect 交换点，[AWS Direct Connect](https://aws.amazon.com/cn/directconnect/) 就是不错的选择。S3 Transfer Acceleration 最适合从分散的客户位置通过公共 Internet 提交数据，或者是由于网络条件不断变化而造成吞吐量较低的情况。有些 AWS Direct Connect 客户使用 S3 Transfer Acceleration 帮助远程办公室传输数据，因为远程办公室的 Internet 性能可能会比较差。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为 AWS Storage Gateway 或第三方网关的补充吗？",
        "intention":"知识问答",
        "reply":"您可以受益于在第三方网关中配置存储桶目标以使用 S3 Transfer Acceleration 端点域。\n请访问 [Storage Gateway 常见问题的“文件”部分](https://aws.amazon.com/cn/storagegateway/faqs/#file)，详细了解 AWS 实施。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为第三方集成软件的补充吗？",
        "intention":"知识问答",
        "reply":"是。直接连接到 Amazon S3 的软件包在将任务发送到 Amazon S3 时可以利用 S3 Transfer Acceleration。\n[了解有关存储合作伙伴解决方案的更多信息 »](https://aws.amazon.com/cn/backup-recovery/partner-solutions/)"
    },
    {
        "query":"S3 Transfer Acceleration 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"符合，AWS 已对其 [HIPAA 合规性计划](https://aws.amazon.com/cn/compliance/hipaa-compliance/)进行扩展，其中已将 S3 Transfer Acceleration 作为一项符合 HIPAA 要求的服务包括进来。如果您已与 AWS 签订商业合伙协议（BAA），则可以使用 S3 Transfer Acceleration 在您的客户端和 Amazon S3 存储桶之间快速、轻松且安全地远距离传输文件，包括受保护健康信息（PHI）。\n[S3 访问点](https://aws.amazon.com/cn/s3/faqs#S3_Access_Points)"
    },
    {
        "query":"数据在 Amazon S3 中的安全性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 本身是非常安全的。 在创建时，只有您可以访问自己所创建的 Amazon S3 存储桶，而且您可以完全控制哪些人员拥有您的数据的访问权限。Amazon S3 支持用户身份验证，以控制对数据的访问。您可以使用各种访问控制机制，例如存储桶策略，选择性地向用户和用户组授予权限。Amazon S3 控制台会突出显示您可公开访问的存储桶，注明公开可访问性的来源，并且还会在您的存储桶策略或存储桶 ACL 发生的更改从而将使您的存储桶可公开访问时，向您发出警告。 您应该为不希望公开访问的所有账户和存储桶启用 [Amazon S3 屏蔽公共访问权限](https://aws.amazon.com/cn/s3/features/block-public-access/)。 默认情况下，所有新存储桶都开启了“屏蔽公共访问权限”。\n您可以使用 HTTPS 协议，通过 SSL 端点安全地向 Amazon S3 上传或从中下载数据。[Amazon S3 会自动加密上传到您的存储桶的所有对象（截至 2023 年 1 月 5 日）](https://aws.amazon.com/blogs/aws/amazon-s3-encrypts-new-objects-by-default/)。或者，您可以使用自己的加密库，在将数据存储到 Amazon S3 之前对数据进行加密。\n有关 AWS 上的安全性的更多信息，请参阅 [AWS 安全性页面](https://aws.amazon.com/cn/security/)，要了解 S3 安全性信息，请访问 [S3 安全性页面](https://aws.amazon.com/cn/s3/security/)和 [S3 安全性最佳实践指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html)。"
    },
    {
        "query":"如何控制对存储在 Amazon S3 中的数据的访问？",
        "intention":"知识问答",
        "reply":"客户可以使用一系列机制来控制对 Amazon S3 资源的访问，包括 AWS Identity and Access Management (IAM) 策略、存储桶策略、访问点策略、访问控制列表（ACL）、查询字符串身份验证、Amazon Virtual Private Cloud (Amazon VPC) 端点策略、AWS Organizations 中的服务控制策略（SCP）和 Amazon S3 阻止公有访问。\nIAM  \n IAM 让拥有多名员工的企业能够使用一个 AWS 账户创建和管理多个用户。使用 IAM 策略，公司可向 IAM 用户授予对 Amazon S3 存储桶或对象的精细控制权，同时保留对用户执行的所有操作的完全控制。\n存储桶和访问点策略  \n 使用存储桶策略和访问点策略，客户可以定义广泛适用于其 Amazon S3 资源的所有请求的规则，例如为 Amazon S3 资源的子集授予写入权限。客户还可以基于请求的某种特征（例如 HTTP 引用站点和 IP 地址）来限制访问。\nACL  \n Amazon S3 支持 S3 的原始访问控制方法，也就是访问控制列表（ACL）。通过 ACL，客户可为特定用户授予对单个存储桶或数据对象的特定权限（例如读取、写入、完全控制）。针对倾向于完全使用访问控制策略的客户，Amazon S3 提供 [S3 对象所有权](https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html)功能以禁用 ACL。 在迁移到基于 IAM 的存储桶策略时，您可以在启用 S3 对象所有权之前使用 S3 清单来查看存储桶中的 ACL 使用情况。\n查询字符串身份验证  \n 借助查询字符串身份验证，客户可以为 Amazon S3 对象创建一个仅在有限时间内有效的 URL。有关 Amazon S3 中可用的各种访问控制策略的更多信息，请参阅 [访问控制文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-access-control.html)。\nAmazon VPC  \n 当客户创建 Amazon VPC 终端节点时，他们可以为其附加终端节点策略，以控制对与其连接的 Amazon S3 资源的访问权限。客户还可以[使用 Amazon S3 存储桶策略来控制从哪些特定的端点或特定的 VPC 访问存储桶](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-access.html)。\n服务控制策略  \n [服务控制策略 (SCP)](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html) 是 AWS Organizations 策略的一种类型，客户可以在其企业中用它来管理权限。SCP 提供对企业中所有账户最大可用权限的集中控制。借助 SCP，客户可以确保其账户始终符合企业的访问控制指导原则。\nS3 阻止公有访问  \n [Amazon S3 屏蔽公共访问权限](https://aws.amazon.com/cn/s3/features/block-public-access/)提供访问点、存储桶和账户设置，以帮助客户管理对 Amazon S3 资源的公有访问。使用 S3 屏蔽公共访问权限，账户管理员和存储桶拥有者可以轻松设置集中式控制，以限制对其 Amazon S3 资源的公共访问，无论这些资源采用何种创建方式。 作为安全最佳实践，所有新的存储桶均默认启用“屏蔽公共访问权限”。\n参阅 [AWS IAM 文档](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_resource-based)以了解关于策略和权限的更多信息。"
    },
    {
        "query":"Amazon S3 是否支持数据访问审计？",
        "intention":"知识问答",
        "reply":"支持。客户可以选择配置 Amazon S3 存储桶，为所有针对该存储桶的请求创建访问日志记录。或者，需要在日志中捕获 IAM/用户身份信息的客户也可以配置 [AWS CloudTrail 数据事件](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html)。\n这些访问日志记录可用于审计用途，其中包含有关请求的详细信息，例如请求类型、请求中指定的资源、处理请求的时间和日期。"
    },
    {
        "query":"对存储在 Amazon S3 中的数据进行加密时，可以使用哪些选项？",
        "intention":"知识问答",
        "reply":"Amazon S3 会加密上传到任何存储桶的所有新数据。[Amazon S3 将 S3 托管的服务器端加密（SSE-S3）应用为所有对象上传的基本加密级别（截至 2023 年 1 月 5 日）](https://aws.amazon.com/blogs/aws/amazon-s3-encrypts-new-objects-by-default/)。SSE-S3 提供了一种完全托管的解决方案，Amazon 通过其使用多个安全层处理密钥管理和密钥保护问题。如果您希望 Amazon 管理您的密钥，则应继续使用 SSE-S3。此外，您也可以选择使用 SSE-C、SSE-KMS、DSSE-KMS 或客户端库（例如 [Amazon S3 加密客户端](http://docs.amazonwebservices.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/AmazonS3EncryptionClient.html)）对数据进行加密。 每个选项都可以将敏感的数据以静态方式存储在 Amazon S3 中。\nSSE-C 允许 Amazon S3 执行对象的加密和解密，同时让您保留对加密密钥的控制。借助 SSE-C，您无需实施或使用客户端库来对 Amazon S3 中储存的对象执行加密和解密，但是需要对您发送到 Amazon S3 中执行对象加密和解密操作的密钥进行管理。如果您希望保留自己的加密密钥而不想实施或使用客户端加密库时，请使用 SSE-C。\nSSE-KMS 允许 [AWS Key Management Service](https://aws.amazon.com/cn/kms/) (AWS KMS) 管理您的加密密钥。使用 AWS KMS 管理您的密钥有几项额外的益处。利用 AWS KMS，会设置几个单独的 KMS 密钥使用权限，从而提供额外的控制层并防止 Amazon S3 中存储的对象遭到未授权访问。AWS KMS 提供审计跟踪记录，因此您能看到谁使用了您的密钥在何时访问了哪些对象，还能查看用户在没有解密数据的权限下所作的访问数据失败尝试次数。同时，AWS KMS 还提供额外的安全控制，从而支持客户努力符合 PCI-DSS、HIPAA/HITECH 和 FedRAMP 行业要求。\nDSSE-KMS 简化了对数据应用两层加密的过程，无需投资客户端加密所需的基础设施。每层加密都采用 256 位高级加密标准的不同实施结合 Galois Counter Mode（AES-GCM）算法，并且经过审查，可用于绝密工作负载。DSSE-KMS 使用 AWS KMS 生成数据密钥，并通过 AWS KMS 管理您的加密密钥。利用 AWS KMS，会设置几个单独的 KMS 密钥使用权限，从而提供额外的控制层并防止 Amazon S3 中存储的对象遭到未授权访问。AWS KMS 提供审计跟踪记录，因此您能看到谁使用了您的密钥在何时访问了哪些对象，还能查看用户在没有解密数据的权限下所作的访问数据失败尝试次数。同时，AWS KMS 还提供额外的安全控制，从而支持客户努力符合 PCI-DSS、HIPAA/HITECH 和 FedRAMP 行业要求。\n使用加密客户端库时，您保有对密钥的控制权并使用您选择的加密库对对象客户端进行加密和解密。一些客户倾向于对加密和解密对象拥有端到端的控制权；这样一来，只有经过加密的对象才会通过互联网传输到 Amazon S3。如果您想掌握对加密密钥的控制权，应该使用客户端库，这样便可实施或使用客户端加密库，同时在将对象传输到 Amazon S3 进行储存之前需要对其进行加密。\n有关使用 Amazon S3 SSE-S3、SSE-C 或 SSE-KMS 的更多信息，请参阅[使用加密文档保护数据](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingEncryption.html)。"
    },
    {
        "query":"使用 Amazon S3 时，能否遵守欧盟数据隐私法规？",
        "intention":"知识问答",
        "reply":"客户可以选择使用欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、欧洲地区（米兰）、欧洲（西班牙）、欧洲地区（伦敦）或欧洲（苏黎世）地区将所有数据存储在欧洲。您还可以使用 [Amazon S3 on Outposts](https://aws.amazon.com/cn/s3/outposts/) 将所有数据本地保留在 AWS Outpost，并且可以选择在 AWS Outposts 之间传输数据或将数据传输到 AWS 区域。您有责任确保自己遵守欧盟隐私法律。查看 [AWS 通用数据保护条例（GDPR）中心](https://aws.amazon.com/cn/compliance/gdpr-center/)和 [AWS 数据隐私中心](https://aws.amazon.com/cn/compliance/data-privacy/)，了解更多信息。 如果有更具体的位置要求或者其他数据隐私法规要求您将数据保存在没有 AWS 区域的位置，您可以使用 S3 on Outposts。"
    },
    {
        "query":"什么是 Amazon S3 的 Amazon VPC 端点？",
        "intention":"知识问答",
        "reply":"Amazon S3 的 Amazon VPC 端点是 VPC 内的逻辑实体，允许通过 [AWS 全局网络](https://aws.amazon.com/cn/about-aws/global-infrastructure/global_network/)连接到 S3。S3 有两种类型的 VPC 端点 – 网关 VPC 端点和接口 VPC 端点。网关端点是您在路由表中指定的网关，用于通过 AWS 网络从 VPC 访问 S3。接口端点通过私有 IP 将请求从您的 VPC 内部、本地或其他 AWS 区域路由到 S3，从而扩展网关端点的功能。有关更多信息，请访问[适用于 Amazon S3 的 AWS PrivateLink 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"能否允许从特定 Amazon VPC 端点访问我的 Amazon S3 存储桶？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 存储桶策略，限制从特定 Amazon VPC 终端节点或一系列终端节点访问您的存储桶。S3 存储桶策略现在支持 aws:sourceVpce 条件，您可以利用此条件来限制访问。有关更多详细信息和示例策略，请参阅 [S3 文档的网关端点](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html)。"
    },
    {
        "query":"什么是适用于 Amazon S3 的 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"适用于 S3 的 AWS PrivateLink 在 Amazon S3 与本地之间提供私有连接。您可以在 VPC 中为 S3 预置接口 VPC 端点，以通过 AWS Direct Connect 或 AWS VPN 将本地应用程序直接连接到 S3。您不再需要使用公有 IP、更改防火墙规则，或配置互联网网关以从本地访问 S3。访问[适用于 S3 的 AWS PrivateLink 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)，了解更多信息。"
    },
    {
        "query":"如何开始使用适用于 S3 的接口 VPC 端点？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS VPC 管理控制台、AWS 命令行界面（AWS CLI）、AWS SDK 或 API 创建接口 VPC 端点。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"我应何时选择网关 VPC 端点，而不是基于 AWS PrivateLink 的接口 VPC 端点？",
        "intention":"知识问答",
        "reply":"AWS 建议您使用接口 VPC 端点从本地或另一个 AWS 区域中的 VPC 访问 S3。对于要从与 S3 相同的 AWS 区域中的 VPC 访问 S3 的资源，我们建议使用网关 VPC 端点，因为这不会收取费用。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"我可以在同一个 VPC 中同时使用适用于 S3 的接口终端节点和网关终端节点吗？",
        "intention":"知识问答",
        "reply":"可以。如果您已经有网关 VPC 端点，请在 VPC 中创建接口 VPC 端点，并以 VPC 端点特定的端点名称更新客户端应用程序。例如，如果您接口端点的 VPC 端点 ID 在 us-east-1 区域中为 vpce-0fe5b17a0707d6abc-29p5708s，则特定于端点的 DNS 名称将为 vpce-0fe5b17a0707d6abc-29p5708s.s3.us-east-1.vpce.amazonaws.com。在这种情况下，仅针对 VPC 端点特定名称的请求将通过接口 VPC 端点路由到 S3，而所有其他请求将继续通过网关 VPC 端点路由。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"什么是 Amazon Macie，我如何使用它保护数据的安全？",
        "intention":"知识问答",
        "reply":"[Amazon Macie](https://aws.amazon.com/cn/macie/) 是一种支持 AI 技术的安全服务，可以帮助您通过自动发现、分类和保护存储在 Amazon S3 中的敏感数据来防止数据丢失。Amazon Macie 使用机器学习来识别敏感数据（例如，个人身份信息（PII）或知识产权），分配业务价值，提供此数据的存储位置信息及其在组织中的使用方式信息。Amazon Macie 可持续监控数据访问活动异常，并在检测到未经授权的访问或意外数据泄漏风险时发出警报。\n您可以使用 Amazon Macie 通过持续监控数据和账户凭证来防范安全威胁。Amazon Macie 为您提供一种自动化和低接触的方式来发现和分类业务数据。它通过模板化的 Lambda 函数进行控制，可在发现可疑行为或对实体或第三方应用程序进行未经授权的数据访问时撤销访问或触发密码重置策略。发出警报时，您可以使用 Amazon Macie 进行事件响应，并使用 Amazon CloudWatch Events 迅速采取行动，保护您的数据。有关更多信息，请访问 [Amazon Macie 文档](https://docs.aws.amazon.com/macie/latest/user/what-is-macie.html)。"
    },
    {
        "query":"什么是 IAM Access Analyzer for Amazon S3，它的工作原理是什么？",
        "intention":"知识问答",
        "reply":"[Access Analyzer for S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-analyzer.html) 功能可帮助您在为 S3 存储桶和访问点设置、验证和优化策略时简化权限管理。 Access Analyzer for S3 可监控您的现有访问策略，以验证它们是否仅提供对 S3 资源的必要访问权限。Access Analyzer for S3 会评估您的存储桶访问策略，并帮助您发现并快速更改不需要访问的存储桶。\n当您有一个存储桶配置为允许访问互联网上的任何人访问或与其他 AWS 账户共享时，Access Analyzer for S3 会向您发出警报。您可以获得有关公有或共享访问的来源和级别的*结果*。例如，如果通过访问控制列表或存储桶策略提供不必要的读取或写入访问权限，则 Access Analyzer for S3 会主动通知您。通过这些结果，您可以立即设置或还原所需的访问策略。\n在查看显示对存储桶的潜在共享访问权限的结果时，只需单击 S3 控制台，即可[阻止对存储桶的公共访问](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html)。您还可以向下钻取到存储桶级别权限设置，以配置精细访问。 出于审核目的，您可将 Access Analyzer for S3 的结果下载为 CSV 报告。\n此外，S3 控制台可以在您编写 S3 策略时报告 IAM Access Analyzer 中的安全警告、错误和建议。该控制台将会自动运行 100 多项策略检查，以验证您的策略。这些检查可以为您节约时间，指导您解决错误，并帮助您应用安全最佳实践。\n有关更多信息，请访问 [IAM Access Analyzer 文档](https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html)。"
    },
    {
        "query":"什么是 Amazon S3 接入点？",
        "intention":"知识问答",
        "reply":"现在，客户会使用单个存储桶策略管理对其 S3 存储桶的访问，该策略控制着不同权限级别的数百种应用程序。\nAmazon S3 访问点简化了大规模管理使用 S3 上共享数据集的应用程序的数据访问的过程。利用 S3 访问点，您现在可以在每个存储桶中轻松创建数百个访问点，这代表着预置共享数据集的一种新方法。访问点提供进入存储桶的自定义路径，具有唯一的主机名和访问策略，可对通过相应访问点发出的请求执行特定的权限和网络控制。S3 访问点可以与同一账户或另一个受信任账户中的存储桶相关联。通过访问 [S3 访问点页面](https://aws.amazon.com/cn/s3/features/access-points/)和[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points.html)了解更多信息。"
    },
    {
        "query":"为什么应该使用访问点？",
        "intention":"知识问答",
        "reply":"S3 访问点简化了对 S3 上共享数据集的数据访问的管理过程。您不再需要使用数以百计的需要编写、读取、跟踪和审计的不同权限规则来管理单个复杂的存储桶策略。借助 S3 访问点，您可以创建访问点或将权限委托给受信任的账户，以在您的存储桶上创建跨账户访问点。这允许使用针对特定应用程序定制的策略访问共享数据集。\n使用访问点，您可以针对需要访问共享数据集的每个应用程序，将一个大型存储桶策略分解为多个单独的离散访问点策略。这样可以更轻松地集中精力为应用程序制定正确的访问策略，而不必担心打断共享数据集中任何其他应用程序正在执行的操作。您还可以创建服务控制策略 (SCP)，并要求将所有访问点都限制在 Virtual Private Cloud (VPC) 中，从而通过防火墙将数据隔离在专用网络中。"
    },
    {
        "query":"S3 访问点的工作原理是什么？",
        "intention":"知识问答",
        "reply":"每个 S3 访问点都配置有特定于用例或应用程序的访问策略，一个存储桶可以有数千个访问点。例如，您可以为 S3 存储桶创建一个访问点，为数据湖的用户或应用程序组授予访问权限。访问点可以支持单个用户或应用程序，也可以支持账户内部或跨账户的一组用户或应用程序，因此可以对每个访问点进行单独管理。\n此外，您可以将权限委托给受信任的账户，以在您的存储桶上创建跨账户访问点。在您获得存储桶拥有者的许可之前，跨账户访问点不会授予对数据的访问权限。  存储桶拥有者始终保留对数据的最终控制权，并且必须更新存储桶策略以授权来自跨账户访问点的请求。请访问[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-policies.html)以获取示例存储桶策略。\n每个访问点都与一个存储桶相关联，并包含一个网络源站控件和一个阻止公共访问控件。您可以创建带有网络源站控件的访问点，该控件仅允许从您的 Virtual Private Cloud（AWS 云的逻辑隔离部分）进行存储访问。您还可以创建一个访问点，将访问点策略配置为仅允许访问具有指定前缀的对象或具有特定标签的对象。\n您可以使用两种方式之一通过访问点访问共享存储桶中的数据。对于 S3 对象操作，您可以使用访问点 [ARN](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) 代替存储桶名称。对于要求存储桶名称使用标准 S3 存储桶名称格式的请求，您可以使用访问点别名。S3 访问点的别名是自动生成的，并且可以在您使用存储桶名称进行数据访问的任何位置与 S3 存储桶名称互换。每次为存储桶创建访问点时，S3 都会自动生成一个新的访问点别名。对于全套可兼容操作和 AWS 服务，请访问 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-usage-examples.html)。"
    },
    {
        "query":"是否有访问点数量创建限额？",
        "intention":"知识问答",
        "reply":"默认情况下，您可以在账户和跨账户的存储桶上为每个账户的每个区域创建 10000 个访问点。与 S3 存储桶不同的是，对于每个 AWS 账户的访问点数量没有硬性限制。请访问 [AWS 服务限额](https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html)以申请提高此限额。"
    },
    {
        "query":"在使用访问点时，如何对请求进行授权？",
        "intention":"知识问答",
        "reply":"S3 访问点有其自己的 IAM 访问点策略。您可以使用访问点 ARN 作为资源，像编写存储桶策略一样编写访问点策略。访问点策略可以授权或限制访问通过访问点请求的 S3 数据。Amazon S3 会评估所有相关策略，包括关于用户、存储桶、访问点和 VPC 终端节点的策略，以及服务控制策略和访问控制列表，以决定是否要授权请求。"
    },
    {
        "query":"如何编写访问点策略？",
        "intention":"知识问答",
        "reply":"您可以使用策略文档中管理权限和访问点 ARN 的 IAM 规则编写访问点策略，就像编写存储桶策略一样。"
    },
    {
        "query":"在访问点上限制使用网络源站控件的特定 VPC 访问权限与限制使用存储桶策略的 VPC 访问权限有什么区别？",
        "intention":"知识问答",
        "reply":"您可以继续使用存储桶策略来限制对指定 VPC 的存储桶访问权限。访问点提供更简单可审核的方式，以便通过 API 控件将共享数据集中的全部数据或数据子集锁定到所在组织全部应用程序的仅限 VPC 流量。您可以使用 AWS Organizations 服务控制策略 (SCP) 强制将在您的组织中创建的任何访问点的“网络源站控件”API 参数值设置为 “vpc”。然后，任何创建的新访问点会自动将数据访问限制为仅限 VPC 流量。您无需其他访问策略来确保仅处理来自指定 VPC 的数据请求。"
    },
    {
        "query":"我可以在所在组织内为所有访问点实施“无 Internet 数据访问”策略吗？",
        "intention":"知识问答",
        "reply":"是。要为组织内的所有访问点实施“无 Internet 数据访问”策略，您要确保所有访问点都仅支持 VPC 访问。要做到这一点，您将需要编写 AWS SCP，而且该 SCP 仅支持 create\\_access\\_point() API 中的“网络源站控件”参数的值为“vpc”。如果您在之前创建过任何面向 Internet 的访问点，它们可以被移除。您还需要在每个存储桶中修改存储桶策略，以便进一步限制 Internet 通过存储桶主机名直接访问您的存储桶。由于其他 AWS 服务可能直接访问您的存储桶，因此确保将访问权限设置为允许您想要的 AWS 服务，您可以通过修改策略，允许这些 AWS 服务进行访问。参阅 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-vpc.html)以查看操作示例。"
    },
    {
        "query":"我可以完全禁用使用存储桶主机名直接访问存储桶吗？",
        "intention":"知识问答",
        "reply":"目前不可以，但您可以附加存储桶策略以拒绝并非通过访问点发出的请求。参阅 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-policies.html)以了解更多详细信息。"
    },
    {
        "query":"我可以替换或移除存储桶上的访问点吗？",
        "intention":"知识问答",
        "reply":"是。如果您移除某个访问点，任何通过其他访问点和存储桶主机名对关联存储桶的访问都会被中断。"
    },
    {
        "query":"Amazon S3 访问点的成本为多少？",
        "intention":"知识问答",
        "reply":"访问点和使用访问点的存储桶不会产生额外成本。一般的 Amazon S3 请求费率同样适用。"
    },
    {
        "query":"如何开始使用 S3 访问点？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台、AWS 命令行界面（CLI）、应用程序编程接口（API）和 AWS 软件开发工具包（SDK）客户端，在新存储桶以及现有存储桶上创建 S3 访问点。要了解与 S3 访问点相关的更多信息，请访问[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points.html)。"
    },
    {
        "query":"Amazon S3 的持久性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard、S3 Standard–IA、S3 Intelligent-Tiering、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 的设计均可在给定年份提供 99.999999999%（11 个 9）的对象数据持久性。这种持久性水平对应的平均每年对象损失率预计为 0.000000001%。例如，如果您使用 Amazon S3 存储 10000000 个对象，则预期平均每 10000 年发生一次对象丢失。S3 on Outposts 旨在持久冗余地在 Outpost 上的多个设备和服务器中存储数据。此外，Amazon S3 Standard、S3 Standard-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 的设计还可在整个 S3 可用区丢失的情况下保留数据。\n对于任何环境，最佳实践都是做好备份，并做好防范恶意或意外删除的保护措施。对于 S3 数据，最佳实践包括安全访问权限、跨区域复制、版本控制和定期测试的有效备份。"
    },
    {
        "query":"Amazon S3 的设计如何达到 99.999999999% 的持久性？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard、S3 Standard-IA、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类会将您的对象以冗余方式存储在一个 Amazon S3 区域内至少三个可用区 (AZ) 中的多个设备上，然后才会返回 SUCCESS。而 S3 One Zone-IA 存储类会以冗余方式将数据存储在单个可用区中的多个设备上。这些服务旨在通过快速检测和修复任何丢失的冗余，来抵御同时发生的设备故障，并且它们还可使用校验和来定期验证数据的完整性。"
    },
    {
        "query":"Amazon S3 在数据完整性检查中支持哪些校验和？",
        "intention":"知识问答",
        "reply":"Amazon S3 结合使用 Content-MD5 校验和、安全哈希算法 (SHA) 和循环冗余检验 (CRC) 来验证数据完整性。Amazon S3 在空闲时对数据执行这些校验和检测，并使用冗余数据修复任何不一致。此外，S3 还会在存储或检索数据时对所有网络流量计算校验和，以检测数据包是否改动。您可以从四种受支持的校验和算法中进行选择，以便对您的上传和下载请求进行数据完整性检查。您可以选择 SHA-1、SHA-256、CRC32 或 CRC32C 校验和算法，具体取决于您的应用程序需求。您可以在存储或检索 S3 中的数据时自动计算和验证校验和，并且可以随时使用 GetObjectAttributes S3 API 或 S3 清单报告访问校验和信息。在您将数据流式传输到 S3 时计算校验和可以为您节省时间，因为您可以在一次操作中同时验证和传输数据，而无需执行两个连续的操作。在数据验证中使用校验和是检查数据持久性的最佳实践，这些功能提高了性能并降低了相应操作的成本。"
    },
    {
        "query":"什么是版本控制？",
        "intention":"知识问答",
        "reply":"通过版本控制，您可以保留、提取和恢复存储在 Amazon S3 存储桶中的每个数据对象的每个版本。一旦您为存储桶启用版本控制，Amazon S3 将在您每次执行 PUT、POST、COPY 或 DELETE 操作时保留现有数据对象。默认情况下，GET 请求将提取最近写入的版本。可通过在请求中指定版本，提取已覆盖数据对象或已删除数据对象的旧版本。"
    },
    {
        "query":"为什么应该使用版本控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 为客户提供具有高持久性的存储基础设施。版本控制可在客户意外覆盖或删除数据对象的情况下提供一种恢复手段，从而提供另一层保护。这使您能够从无意用户操作或应用程序故障中轻松恢复。您还可将版本控制用于数据保留和存档。"
    },
    {
        "query":"如何开始使用版本控制？",
        "intention":"知识问答",
        "reply":"您可以通过在 Amazon S3 存储桶上启用相应设置，来开始使用版本控制。有关如何启用版本控制的更多信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html)。"
    },
    {
        "query":"版本控制如何防止对象被意外删除？",
        "intention":"知识问答",
        "reply":"当用户对某个对象执行 DELETE 操作时，后续的简单（不受版本控制）请求将不再检索该对象。但是，该数据对象的所有版本将继续保留在您的 Amazon S3 存储桶中，可以提取或恢复。只有 Amazon S3 存储桶的拥有者才能永久删除某个版本。您可以设置[生命周期规则](http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)来管理生命周期和存储对象的多个版本的成本。"
    },
    {
        "query":"是否可以在 Amazon S3 对象上设置垃圾桶、回收站或回滚时段以从删除和覆盖项中恢复？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon S3 生命周期规则](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)和 [S3 版本控制](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html)来实施 S3 对象的回滚时段。例如，借助启用了版本控制的存储桶，您可以设置一条规则，将以前的所有版本归档到成本较低的 S3 Glacier Flexible Retrieval 存储类，并在 100 天后删除它们，从而给您 100 天的时间来回滚对数据的任何更改，同时降低存储成本。此外，您也可以通过在 5 天后以及至少有 2 个较新版本的对象时删除旧（非当前）版本的对象来节约成本。您可以根据成本优化需要更改天数或更新版本的数量。这使您可以在需要时保留其他版本的对象，但通过在一段时间后转换或删除它们来节约成本。"
    },
    {
        "query":"如何确保我保留的版本得到最大保护？",
        "intention":"知识问答",
        "reply":"版本控制的[多重身份验证（MFA）](https://aws.amazon.com/cn/mfa/)可使用删除功能来增添一层安全性。默认情况下，对您的 Amazon S3 存储桶的所有请求都需要您的 AWS 账户证书。如果您在 Amazon S3 存储桶上利用 MFA Delete 功能启用了版本控制，则需要以下两种形式的身份验证才能永久删除数据对象的某个版本：您的 AWS 账户凭证、来自您拥有的身份验证设备的有效六位代码和序列号。要了解有关利用 MFA Delete 功能启用版本控制的更多信息，包括如何购买和激活身份验证设备，请参阅 [Amazon S3 文档](http://docs.amazonwebservices.com/AmazonS3/latest/dev/Versioning.html)。"
    },
    {
        "query":"什么是 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"S3 Intelligent-Tiering 是首个云存储，它可以根据访问频率自动将数据移至最经济实惠的访问层，从而自动在细粒度对象级别降低您的存储成本，并且不会产生性能影响、检索费用或运营开销。S3 Intelligent-Tiering 可以为频繁、不频繁和归档即时访问层中的频繁、不频繁以及很少访问的数据提供毫秒级延迟和提高吞吐量性能。每月只需支付少量的对象监控和自动化费用，S3 Intelligent-Tiering 即可监控访问模式并将对象从一个访问层自动移动到另一个访问层。S3 Intelligent-Tiering 没有任何检索费用，因此在访问模式发生变化时存储账单不会意外增加。\n现在，您可以通过虚拟方式将 S3 Intelligent-Tiering 用作任何工作负载（尤其是数据湖、数据分析、机器学习、新应用程序和用户生成的内容）的默认存储类。"
    },
    {
        "query":"S3 Intelligent-Tiering 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 Intelligent-Tiering 存储类旨在通过当访问模式改变时自动将数据移动到最具成本效益的访问层来优化存储成本。每月只需支付少量的对象监控和自动化费用，S3 Intelligent-Tiering 即可监控访问模式并自动将连续 30 天未被访问的对象移动到不频繁访问层，最多可节省 40% 的存储成本。在连续 90 天未访问以后，对象会被移动到归档即时访问层以最多节省 68% 的存储成本。性能不会受到影响，而且 S3 Intelligent-Tiering 没有检索费用。如果之后访问了不频繁访问层或归档即时访问层中的对象，则其会被自动移回频繁访问层。\n要为可异步访问的数据实现最低存储成本，您可以选择激活其他归档功能。在您启用一个或两个异步归档访问层后，S3 Intelligent-Tiering 会将至少 90 天未被访问的对象移动到归档访问层，以节省高达 71% 的成本，然后在 180 天无访问后，将其移动到深度归档访问层，以便为很少访问的对象实现高达 95% 的节省。如果可选归档或深度访问层当中的对象在之后被还原，它将被移回到频繁访问层，而且在可以检索前，您必须先使用 RestoreObject 还原该对象。有关恢复归档对象的信息，请参阅[恢复归档对象](https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects.html)。S3 Intelligent-Tiering 没有检索费用。在 S3 Intelligent-Tiering 存储类中的访问层之间移动对象时，不会产生额外的分层或生命周期费用。  \n   \n S3 Intelligent-Tiering 没有最小对象大小，但小于 128KB 的对象没有资格进行自动分层。这些较小的对象可以存储在 S3 Intelligent-Tiering 中，但将始终按频繁访问层费率收费，不收取监控和自动化费用。\n如果您想要将 S3 Intelligent-Tiering 标准化为新创建数据的默认存储类，则可以通过在 [S3 PUT API 请求标头](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-object.html)上指定 INTELLIGENT-TIERING 来修改应用程序。S3 Intelligent-Tiering 旨在提供 99.9% 的可用性和 99.999999999% 的持久性，并自动提供与 S3 Standard 相同的低延迟和高吞吐量性能。您可以使用 AWS Cost Explorer 来评估使用归档即时访问层所能实现的节省。"
    },
    {
        "query":"为什么应选择使用 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"现在，您可以通过虚拟方式将 S3 Intelligent-Tiering 用作任何工作负载（尤其是数据湖、数据分析、机器学习、新应用程序和用户生成的内容）的默认存储类。S3 Intelligent-Tiering 是首个云存储，它可以根据访问频率自动将数据移至最经济实惠的访问层，从而自动在细粒度对象级别降低您的存储成本，并且不会产生性能影响、检索费用或运营开销。如果您有访问模式未知或不断变化的数据，包括数据湖、数据分析和新应用程序，我们建议使用 S3 Intelligent-Tiering。如果您有不需要立即检索的数据，我们建议激活深度归档访问层，因此您只需要为可能长时间很少访问的数据支付每 TB 每月 1 USD。S3 Intelligent-Tiering 适用于访问模式未知或不断变化的数据。在使用 S3 Intelligent-Tiering 存储类时不会产生检索费用。"
    },
    {
        "query":"S3 Intelligent-Tiering 可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 Intelligent-Tiering 会自动优化您的存储成本，而不会影响您的性能。S3 Intelligent-Tiering 的频繁、不频繁和归档即时访问层提供毫秒级延迟和高吞吐量性能。"
    },
    {
        "query":"S3 Intelligent-Tiering 的持久性和可用性如何？",
        "intention":"知识问答",
        "reply":"与 S3 Standard 存储类相同，S3 Intelligent-Tiering 专为 99.999999999% 的持久性而设计。S3 Intelligent-Tiering 设计用于提供 99.9% 的可用性，并附带[服务等级协议](https://aws.amazon.com/cn/s3/sla/)，当在任意账单周期内的可用性低于我们的服务承诺时，还可提供服务积分。"
    },
    {
        "query":"如何将数据存入 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"有两种方式可以将数据存入 S3 Intelligent-Tiering。可以通过指定 x-amz-存储类标头中的 INTELLIGENT\\_TIERING 来直接放入 S3 Intelligent-Tiering 中，也可以设置生命周期策略以将对象从 S3 Standard 或 S3 Standard-IA 转换到 S3 INTELLIGENT\\_TIERING。\nS3 Intelligent-Tiering 是如何收费的？\nS3 Intelligent-Tiering 会向您收取月度存储费用、请求和数据传输费用，还会对每个对象的监控和自动化向您收取很少的月服务费。S3 Intelligent-Tiering 存储类自动将对象存储在三个访问层中：按 S3 Standard 存储费率定价的频繁访问层、按 S3 Standard-Infrequent Access 存储费率定价的不频繁访问层，以及按 S3 Glacier Instant Retrieval 存储费率定价的归档即时访问层。S3 Intelligent-Tiering 还有两个专为异步访问设计的可选归档层，按 S3 Glacier Flexible Retrieval 存储费率定价的归档访问层和按 S3 Glacier Deep Archive 存储费率定价的深层归档访问层。  \n   \n 对于小额监控和自动化费用，S3 Intelligent-Tiering 会监控访问模式并自动移动对象到低延迟、高吞吐量访问层，以及两个可选异步归档访问层，客户可以借此在云中为可异步访问的数据实现最低存储成本。  \n   \n S3 Intelligent-Tiering 没有最小可计费对象大小，但小于 128KB 的对象没有资格进行自动分层。 这些小型对象将不受监控，并将始终按频繁访问层费率收费，没有监控和自动化费用。对于在 S3 Intelligent-Tiering 中归档到归档访问层或深度归档访问层的每个对象，Amazon S3 为对象名称和其他元数据使用 8KB 的存储空间（按 S3 Standard 存储费率计费），为索引和相关元数据使用 32KB 的存储空间（按 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储费率计费）。"
    },
    {
        "query":"如何激活 S3 Intelligent-Tiering 归档访问层？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 API、CLI 或 S3 管理控制台创建存储桶、前缀或对象标签级别配置，从而激活存档访问层和深度存档访问层。如果您的对象可以被应用程序异步访问，则仅应激活一个或两个存档访问层。  \n   \n 问：是否可以延长在 S3 Intelligent-Tiering 存储类中存档对象之前的访问时间？\n可以。在存储桶、前缀或对象标签级别配置中，您可以延长在 S3 Intelligent-Tiering 中归档对象的最后访问时间。启用该功能后，默认情况下，最少连续 90 天未访问的对象将自动移动到归档访问层中，而跳过归档即时访问层。最少连续 180 天未访问的对象将自动移动到深度归档访问层中。对于在 S3 Intelligent-Tiering 中自动存档前最后一次访问之后的连续天数默认配置，最多可以延长 2 年。"
    },
    {
        "query":"如何从 S3 Intelligent-Tiering 存储类的存档访问层或深度存档访问层中获取对象？",
        "intention":"知识问答",
        "reply":"要访问存档或深度存档访问层中的对象，您需要发出“还原”请求，该对象将开始移回到频繁访问层，所有对象都存储在 S3 Intelligent-Tiering 存储类中。存档访问层中的对象将在 3-5 小时内移至频繁访问层，深度存档访问层中的对象将 12 小时内移至频繁访问层。一旦对象位于频繁访问层中，您就可以发出 GET 请求以检索对象。"
    },
    {
        "query":"如何知道我的对象存储在哪个 S3 Intelligent-Tiering 访问层中？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 清单来针对存储在 S3 Intelligent-Tiering 存储类中的对象的访问层生成报告。Amazon S3 清单提供 CSV、ORC 或 Parquet 输出文件，从而每日或每周为 S3 存储桶或共享前缀列出您的对象及其相应的元数据。您还可以对您的对象提出 HEAD 请求，以报告 S3 Intelligent-Tiering 归档访问层。"
    },
    {
        "query":"是否可以将对象的生命周期从 S3 Intelligent-Tiering 转换到其他存储类？",
        "intention":"知识问答",
        "reply":"是。您可以将对象的生命周期从 S3 Intelligent-Tiering 频繁访问、不频繁和归档即时访问层转换到 S3 One-Zone Infrequent Access、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive。此外，您可以将对象的生命周期从 S3 Intelligent-Tiering 可选归档访问层转换到 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive，从 S3 Intelligent-Tiering 深度归档访问层转换到 S3 Glacier Deep Archive。"
    },
    {
        "query":"S3 Intelligent-Tiering 是否有最短期限？",
        "intention":"知识问答",
        "reply":"没有。S3 Intelligent-Tiering 存储类没有最短存储期限。"
    },
    {
        "query":"S3 Intelligent-Tiering 是否有最小可计费对象大小限制？",
        "intention":"知识问答",
        "reply":"没有。S3 Intelligent-Tiering 存储类没有最小可计费对象大小，但小于 128KB 的对象没有资格进行自动分层。这些较小的对象将始终按频繁访问层费率收费，没有监控和自动化费用。对于在 S3 Intelligent-Tiering 中归档到可选的归档访问层或深度归档访问层的每个对象，Amazon S3 为对象名称和其他元数据使用 8KB 的存储空间（按 S3 Standard 存储费率计费），为索引和相关元数据使用 32KB 的存储空间（按 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储费率计费）。如需更多详细信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"什么是 S3 Standard？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard 为频繁访问的数据（通常每个月一次以上）提供具有毫秒级访问延迟和高吞吐量性能的持久性存储。S3 Standard 专为性能敏感型使用案例而设计，如数据湖、云原生应用程序、动态网站、内容分发、移动和游戏应用程序、分析和机器学习模型。S3 Standard 的设计可以在指定年度内跨多个可用区实现 99.99% 的数据可用性和 99.999999999％ 的对象持久性。您可以使用 S3 生命周期策略来控制数据在 S3 Standard 和较低成本存储类之间转移的具体时间，而不对应用程序做任何更改。"
    },
    {
        "query":"为什么应选择使用 S3 Standard？",
        "intention":"知识问答",
        "reply":"S3 Standard 非常适用于最频繁访问或修改的数据，这些数据要求以毫秒级且高吞吐量性能进行访问。由于不会产生检索费用，因此 S3 Standard 是经常读取或写入数据的理想选择。S3 Standard 针对各种用例进行了优化，包括数据湖、云原生应用程序、动态网站、内容分发、移动和游戏应用程序以及分析。"
    },
    {
        "query":"什么是 S3 Standard-Infrequent Access？",
        "intention":"知识问答",
        "reply":"S3 Standard-Infrequent Access (S3 Standard-IA) 是一种 Amazon S3 存储类，用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 提供了 Amazon S3 Standard 存储类的高持久性、高吞吐量和低延迟，每 GB 存储价格和每 GB 检索费用都比较低。成本较低且性能出色使得 S3 Standard-IA 成为长期存储和备份的理想选择，也非常适用于灾难恢复的数据存储。S3 Standard-IA 存储类是在对象级别进行设置的，并且可以与 S3 Standard 或 S3 One Zone-IA 存储类存在于同一个存储桶中，从而让您可以使用 S3 生命周期策略在存储类之间自动转移对象，而无需更改任何应用程序。"
    },
    {
        "query":"为什么应选择使用 S3 Standard-IA？",
        "intention":"知识问答",
        "reply":"S3 Standard-IA 适用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 非常适合长期文件存储、较旧的同步和共享存储以及其他老化数据。"
    },
    {
        "query":"S3 Standard-IA 可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 Standard-IA 提供与 S3 Standard 存储类相同的延迟和高吞吐量性能。"
    },
    {
        "query":"如何将数据存入 S3 Standard-IA？",
        "intention":"知识问答",
        "reply":"有两种方式可以将数据存入 S3 Standard-IA。通过在 x-amz-storage-class 标头中指定 STANDARD\\_IA，您可以通过 PUT 操作直接将数据放入 S3 Standard-IA。您还可以设置生命周期策略，将对象从 S3 Standard 转移到 S3 Standard-IA 存储类。"
    },
    {
        "query":"是否可以将 S3 Standard-IA 中的对象分层到 S3 One Zone-IA 或 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"是。除了使用生命周期策略将对象从 S3 Standard 迁移到 S3 Standard-IA 之外，您还可以将生命周期策略设置为将 S3 Standard-IA 的对象分层到 S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类。"
    },
    {
        "query":"什么是 S3 单区 – IA 存储类？",
        "intention":"知识问答",
        "reply":"S3 单区 – IA 存储类是一个 Amazon S3 存储类，让客户可以选择将对象存储在单个可用区中。S3 One Zone-IA 存储以冗余方式将数据存储在单个可用区内，这种存储的成本比地理上冗余的 S3 Standard-IA 存储的成本低 20%，而后者是以冗余方式将数据存储在多个地理上分离的可用区内。\nS3 One Zone-IA 提供 99% 的可用性 SLA，并且在可用区内的持久性还能够达到 99.999999999%。然而，S3 One Zone-IA 存储类中的数据对整个可用区的物理损失不具有弹性。\nS3 One Zone-IA 存储提供与 S3 Standard 和 S3 Standard-IA 相同的 Amazon S3 功能，用户可以通过 Amazon S3 API、CLI 和控制台使用这种存储类。S3 One Zone-IA 存储类是在对象级别进行设置的，并且可以和 S3 Standard 和 S3 Standard-IA 标准存储类存在于同一个存储桶中。您可以使用 S3 生命周期策略在存储类之间自动转移对象，而无需更改任何应用程序。"
    },
    {
        "query":"S3 单区 – IA 存储类最适合用于哪些使用案例？",
        "intention":"知识问答",
        "reply":"客户将 S3 单区 – IA 存储类用于访问频率较低的存储，如备份副本、灾难恢复副本或其他易于重新创建的数据。"
    },
    {
        "query":"S3 单区 – IA 存储类可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 One Zone-IA 存储类可提供与 S3 Standard 和 S3 Standard-Infrequent Access 存储类的相同的延迟和吞吐量性能。"
    },
    {
        "query":"S3 One Zone-IA 存储类的持久性如何？",
        "intention":"知识问答",
        "reply":"S3 One Zone-IA 存储类在一个可用区内的持久性可达到 99.999999999%。然而，S3 One Zone-IA 存储类中的数据对可用区的可用性损失或物理损失不具有弹性。相比之下，S3 Standard、S3 Intelligent-Tiering、S3 Standard-Infrequent Access 和 S3 Glacier 存储类能够承受住可用性下降或可用区毁坏的情况。S3 One Zone-IA 可以提供与大多数现代物理数据中心相当或更高的持久性和可用性，同时还提供存储弹性和 Amazon S3 功能集的额外优势。"
    },
    {
        "query":"S3 One Zone-IA 中的“区域”与 AWS 可用区是否一样？",
        "intention":"知识问答",
        "reply":"是。每个 AWS 区域都是一个独立的地理区域。每个区域都有多个相互隔离的位置，称为可用区。Amazon S3 One Zone-IA 存储类使用区域内的单个 AWS 可用区。"
    },
    {
        "query":"通过使用 S3 One Zone-IA，我将放弃多少灾难恢复保护能力？",
        "intention":"知识问答",
        "reply":"每个可用区均使用冗余电源和联网。在 AWS 区域内，可用区位于不同的冲积平原和地震断裂带，并且在地理位置上是分离的，以避免受到火灾的影响。S3 Standard 和 S3 Standard-IA 存储类通过以冗余方式将数据存储在多个可用区来避免受到这类灾难的影响。S3 单区 – IA 对可用区内的设备故障提供保护，但数据对于因地震和洪水等灾难造成的可用区物理损失不具有弹性。使用 S3 One Zone-IA、S3 Standard 和 S3 Standard-IA 选项，您可以选择最符合您的存储持久性和可用性要求的存储类。"
    },
    {
        "query":"什么是 Amazon S3 Glacier Instant Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 存储类为很少访问且需要毫秒级检索速度的长期数据提供最低成本的存储。S3 Glacier Instant Retrieval 可提供对归档存储的最快访问，并且与 S3 Standard 和 S3 Standard-IA 存储类具有相同的吞吐量和毫秒级访问速度。通过跨至少三个物理分离的 AWS 可用区冗余存储数据，S3 Glacier Instant Retrieval 旨在实现 99.999999999%（11 个 9）的数据持久性和 99.9% 的可用性。"
    },
    {
        "query":"为什么应选择使用 S3 Glacier Instant Retrieval？",
        "intention":"知识问答",
        "reply":"如果您有很少访问的数据，而且要求毫秒级延迟，则 S3 Glacier Instant Retrieval 是您的理想选择。若您想要和 S3 Standard-IA 相同的低延迟和高吞吐量性能，但存储数据的访问频率低于 S3 Standard-IA，那么它就非常适合您，因为它的存储价格降低，而数据访问成本稍高。"
    },
    {
        "query":"S3 Glacier Instant Retrieval 的可用性和持久性如何？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 专为实现与 S3 Standard-IA 相同的 99.999999999%（11 个 9）持久性和 99.9 可用性而设计，它具有服务等级协议，可在任何计费周期内的可用性低于 99% 时提供服务积分。"
    },
    {
        "query":"S3 Glacier Instant Retrieval 提供怎样的性能？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 提供与 S3 Standard 和 S3 Standard-IA 存储类相同的毫秒级延迟和高吞吐量性能。有别于专为异步访问设计的 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类，您不需要在访问存储于 S3 Glacier Instant Retrieval 的对象前发出 Restore 请求。"
    },
    {
        "query":"如何将我的数据存入 S3 Glacier Instant Retrieval？",
        "intention":"知识问答",
        "reply":"将数据存入 S3 Glacier Instant Retrieval 的方式有两种。您可以通过指定 x-amz-storage-class 标头中的 GLACIER\\_IR 来直接放入 S3 Glacier Instant Retrieval 中，也可以设置 S3 生命周期策略以将对象从 S3 Standard 或 S3 Standard-IA 转移到 S3 Glacier Instant Retrieval。"
    },
    {
        "query":"什么是 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Flexible Retrieval 存储类为每年访问 1-2 次且异步检索的归档数据提供低成本存储，成本最多降低 10%（相比 S3 Glacier Instant Retrieval），以及免费批量检索。对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用案例，S3 Glacier Flexible Retrieval（原 S3 Glacier）是理想的存储类。S3 Glacier Flexible Retrieval 提供最灵活的检索选项，可以平衡成本与访问时间（从几分钟到几小时不等），并且可批量检索。它是备份、灾难恢复、离线数据存储需求的理想解决方案，并且还非常适合于偶尔需要在几分中内检索部分数据而您不想担心成本的情况。通过跨多个物理分离的 AWS 可用区冗余存储数据，S3 Glacier Flexible Retrieval 旨在实现 99.999999999%（11 个 9）的数据持久性和 99.99% 的可用性。"
    },
    {
        "query":"为什么应选择使用 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用案例，S3 Glacier Flexible Retrieval（原 S3 Glacier）是理想的存储类。S3 Glacier Flexible Retrieval 提供最灵活的检索选项，可以平衡成本与访问时间（从几分钟到几小时不等），并且可批量检索。它是备份、灾难恢复、离线数据存储需求的理想解决方案，并且还非常适合于偶尔需要在几分中内检索部分数据而您不想担心数据检索成本的情况。"
    },
    {
        "query":"如何将我的数据存入 S3 Glacier Flexible Retrieval？",
        "intention":"知识问答",
        "reply":"将数据存入 S3 Glacier Flexible Retrieval 的方式有两种。通过在 x-amz-storage-class 标头中指定 GLACIER，您可以直接将数据放入 S3 Glacier Flexible Retrieval。您还可以使用 [S3 生命周期](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)规则基于对象的使用年限在适用于活动数据的任何 S3 存储类（S3 Standard、S3 Intelligent-Tiering、S3 Standard-IA、S3 One Zone-IA 和 S3 Glacier Instant Retrieval）与 Amazon S3 Glacier Flexible Retrieval 之间传输数据。使用 Amazon S3 管理控制台、AWS 开发工具包或 Amazon S3 API 来直接放入 Amazon S3 Glacier 或定义归档规则。  \n   \n 注：S3 Glacier Flexible Retrieval（原 S3 Glacier）还可以通过原始直接 Glacier API 和 Amazon S3 Glacier 管理控制台提供。为了获取增强体验和完整 S3 功能集的访问权限，包括生命周期管理、S3 复制、S3 Storage Lens 等，我们建议通过 S3 API 和 S3 管理控制台来使用 S3 Glacier 功能。"
    },
    {
        "query":"如何检索归档在 S3 Glacier Flexible Retrieval 中的对象？对象还原时我会收到通知吗？",
        "intention":"知识问答",
        "reply":"归档在 S3 Glacier Flexible Retrieval 中的对象可以异步访问。要检索存储在 S3 Glacier Flexible Retrieval 中的数据，您需要使用 Amazon S3 API 或 Amazon S3 控制台启动检索请求。检索请求会在 S3 Standard 存储类中创建数据的临时副本，同时已归档数据将原封不动地保留在 S3 Glacier Flexible Retrieval 中。您可以以天为单位指定将临时副本存储在 Amazon S3 上的时间。然后，可以通过 Amazon S3 GET 从 S3 中请求访问已归档对象的临时副本。\n通过还原通知，您现在可在从 S3 Glacier Flexible Retrieval 成功还原对象并且临时副本可供您使用时使用 [S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)通知您。存储桶拥有者（或 [IAM](https://aws.amazon.com/cn/iam/) 策略允许的其他人）可以安排将通知发送到 [Amazon Simple Queue Service (SQS)](https://aws.amazon.com/cn/sqs/) 或 [Amazon Simple Notification Service (SNS)](https://aws.amazon.com/cn/sns/)。通知也可传送到 [AWS Lambda](https://aws.amazon.com/cn/lambda/)，由 Lambda 函数进行处理。"
    },
    {
        "query":"恢复归档在 Amazon S3 Glacier Flexible Retrieval 中的对象需要多长时间？",
        "intention":"知识问答",
        "reply":"处理检索任务时，Amazon S3 首先从 S3 Glacier Flexible Retrieval 检索请求的数据，然后在 Amazon S3 中创建所请求数据的临时副本。这通常需要几分钟时间。请求的访问时间取决于您选择的检索选项：加急、标准或批量检索。除了最大的对象 (250MB+) 以外，对于使用加急检索方式访问的所有数据，通常在 1-5 分钟内即可使用。使用标准检索方式检索的对象通常在 3-5 小时内完成。批量检索通常在 5-12 小时内完成，而且是免费的。有关 S3 Glacier Flexible Retrieval 选项的更多信息，请参阅《S3 用户指南》中的[恢复归档的对象](https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects.html)。\n使用 S3 Glacier 存储类预置容量单位，您可以为给定月份支付固定的预付费用，以确保获得从 S3 Glacier Flexible Retrieval 进行加急检索所需的检索容量。您每月可以购买 2 个预置容量单位，从而增加可以检索的数据量。每单位容量可确保每 5 分钟内至少可执行 3 次加急检索，并提供最高达 150MB/s 的检索吞吐量。如果您的工作负载需要在几分钟内对数据子集进行高度可靠且可预测的访问，那么您应该购买预置检索容量。如果没有预置容量，在高需求期间，可能不会接受加快检索。如果您在任何情况下需要访问加速检索，我们建议您购买预置的检索容量。\n您可以使用 Amazon S3 控制台、[购买预置容量](https://docs.aws.amazon.com/amazonglacier/latest/dev/api-PurchaseProvisionedCapacity.html) REST API、AWS 开发工具包或 AWS CLI 购买预置容量。预置容量单位从购买日期和时间（即开始日期）开始，持续一个月。单位在到期日期时过期，该日期恰好是开始日期后的一个月，精确到秒钟。有关预置容量定价信息，请参阅 [Amazon S3 定价](https://aws.amazon.com/s3/pricing/)。"
    },
    {
        "query":"从 Amazon S3 Glacier Flexible Retrieval 检索数据的成本是多少？",
        "intention":"知识问答",
        "reply":"从 S3 Glacier Flexible Retrieval 检索数据的方式有三种：加急、标准和批量检索。加急和标准方式具有不同的每 GB 检索费和每请求费（即，您需要为针对 Amazon S3 对象的请求付费）。从 S3 Glacier Flexible Retrieval 进行批量检索是免费的。有关不同 AWS 区域的 S3 Glacier 定价的详细信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"支持 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类的后端基础设施是什么？",
        "intention":"知识问答",
        "reply":"我们更倾向于关注客户在性能、持久性、可用性和安全性方面的结果。但是，我们的客户经常会提出这个问题。我们使用各种不同技术，让我们可以将我们的价格报给客户。我们的服务是使用常见数据存储技术构建的，这些技术使用 AWS 开发的软件专门组装到特别定制、成本优化的系统中。我们能够优化输入和输出次序，因此 S3 Glacier 存储类可最大限度地提高访问底层存储的效率。"
    },
    {
        "query":"什么是 Amazon S3 Glacier Deep Archive 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 是一种 [Amazon S3 存储类](https://aws.amazon.com/cn/s3/storage-classes/)，这为长期保存每年访问一两次的数据提供了安全、持久的对象存储。S3 Glacier Deep Archive 的云存储成本最低，每月每 GB 仅 0.00099 USD（不到 0.1 美分，或每月每 TB 约 1 USD）起，远低于存储和维护本地磁带库或异地归档数据的价格。"
    },
    {
        "query":"S3 Glacier Deep Archive 存储类最适用于哪些使用案例？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 是一种理想的存储类，可以为公司最重要的数据资产提供离线保护，或者在根据公司政策、合同或监管合规性要求需要长期保留数据时提供离线保护。客户发现 S3 Glacier Deep Archive 是一个非常有吸引力的选择，可用来保护核心知识产权、金融和医疗记录、研究结果、法律文件、地震勘探研究和长期备份的，特别是在金融服务、医疗、石油和天然气以及公共部门等监管严格的行业。此外，还有一些企业希望保留核心知识产权的备份副本，比如媒体和娱乐公司。通常，使用 S3 Glacier Deep Archive 的客户可以减少或停止使用本地磁带库和本地之外的磁带归档服务。"
    },
    {
        "query":"S3 Glacier Deep Archive 存储类和 S3 Glacier Instant Retrieval 及 S3 Glacier Flexible Retrieval 存储类有何区别？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 扩充了我们的数据归档产品，使您能够根据存储和检索成本以及检索时间选择最佳的存储类别。当需要以毫秒级延迟访问低成本归档数据时，您可以选择 S3 Glacier Instant Retrieval 存储类。对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用场景，请选择 S3 Glacier Flexible Retrieval（原 S3 Glacier），它可在几分钟内检索，也可以在 5-12 小时内进行免费批量检索。相比之下，S3 Glacier Deep Archive 专门用于不太可能访问但仍然需要长期持久存储的较冷数据。S3 Glacier Deep Archive 的费用比 S3 Glacier Flexible Retrieval 低 75%，并可在 12 小时内，使用标准检索速度提供检索。您还可以通过选择批量检索来降低检索成本，批量检索将在 48 小时内返回数据。"
    },
    {
        "query":"如何开始使用 S3 Glacier Deep Archive？",
        "intention":"知识问答",
        "reply":"在 S3 Glacier Deep Archive 中存储数据的最简单方法是使用 S3 API 直接上传数据。只需指定“S3 Glacier Deep Archive”作为存储类。您可以利用 AWS 管理控制台、S3 REST API、AWS 开发工具包或 AWS 命令行界面来完成该指定操作。\n您还可以通过使用 S3 Lifecycle 来创建迁移数据的策略，以此开始使用 S3 Glacier Deep Archive，S3 Lifecycle 提供了定义对象生命周期和降低存储成本的能力。可以设置这些策略，以便根据对象的使用年限将对象迁移到 S3 Glacier Deep Archive 上。您可以为 S3 存储桶或特定前缀指定策略。生命周期转换按 S3 Glacier Deep Archive 上传价格计费。\n磁带网关是 AWS Storage Gateway 的一个基于云的虚拟磁带库功能，现与 S3 Glacier Deep Archive 结合在一起，使您可以将基于虚拟磁带的长期备份和归档存储在 S3 Glacier Deep Archive 中，从而为云中的这些数据提供最低的存储成本。首先，使用 AWS Storage Gateway 控制台或 API 创建一个新的虚拟磁带，并将归档存储目标设置为 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive。当备份应用程序弹出磁带时，磁带将归档到选定的存储目标中。"
    },
    {
        "query":"将数据从现有的磁带存档迁移到 S3 Glacier Deep Archive 上，您有何建议?",
        "intention":"知识问答",
        "reply":"有多种方法可以将数据从现有磁带存档迁移到 S3 Glacier Deep Archive。您可以使用 AWS Tape Gateway，以便通过虚拟磁带库 (VTL) 接口与现有备份应用程序集成。此接口可以将虚拟磁带提供给备份应用程序。以上操作可以立即将数据存储在 Amazon S3、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive。\n您还可以使用 AWS Snowball 或 Snowmobile 迁移数据。Snowball 和 Snowmobile 可使用能确保传输安全的物理存储设备，加快 TB 到 PB 级数据迁入和迁出 AWS 的速度。使用 Snowball 和 Snowmobile 有助于解决进行大规模数据传输时会遇到的难题，包括网络费用高、传输时间长和安全问题。\n最后，您可以使用 AWS Direct Connect 来建立从本地到 AWS 的专用网络连接。在许多情况下，Direct Connect 可以降低网络成本，增加带宽吞吐量，并提供比基于互联网的连接更一致的网络体验。"
    },
    {
        "query":"如何检索存储在 S3 Glacier Deep Archive 中的对象？",
        "intention":"知识问答",
        "reply":"要检索存储在 S3 Glacier Deep Archive 中的数据，请使用 Amazon S3 API 或 Amazon S3 管理控制台提出“恢复”请求。“还原”会在 S3 Standard 存储类中创建数据的临时副本，同时使 S3 Glacier Deep Archive 中的已归档数据保持完整。您可以以天为单位指定将临时副本存储在 S3 上的时间。然后，可以通过 Amazon S3 GET 从 S3 中请求访问已归档对象的临时副本。\n还原一个存档对象时，您可以在请求正文的 Tier 元素中指定以下一个选项：标准为默认层并允许您在 12 小时内访问您存档的任何对象，Bulk 允许您检索大量数据，甚至是 PB 级的数据，而且成本低廉，通常在 48 小时内就可以完成。"
    },
    {
        "query":"S3 Glacier Deep Archive 使用情况将如何显示在我的 AWS 账单上和 AWS 成本管理工具中？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 使用情况和成本将在您的每月 AWS 账单上显示为一个独立的服务行项目，与 Amazon S3 使用情况和成本分开。但是，如果您正在使用 AWS 成本管理工具，S3 Glacier Deep Archive 使用情况和成本将包括在您的每月详细开支报表中的 Amazon S3 使用情况和成本下，并且不会细分为单独的服务行项目。"
    },
    {
        "query":"S3 Glacier Deep Archive 如何与其他 AWS 服务相集成？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 集成了 Amazon S3 功能，包括 S3 对象标记、S3 生命周期策略、S3 对象锁定和 S3 复制。通过 S3 存储管理功能，您可以使用单个 Amazon S3 存储桶存储 S3 Glacier Deep Archive、S3 Standard、S3 Standard-IA、S3 One Zone-IA 和 S3 Glacier Flexible Retrieval 数据的混合体。这让存储管理员可以基于数据和数据访问模式的性质做出决策。客户可以使用 Amazon S3 生命周期策略将老化的数据自动迁移到成本较低的存储类，也可以使用 S3 跨区域复制或同区域复制策略将数据复制到同一区域或其他区域。\nAWS Storage Gateway 服务可将磁带网关与 S3 Glacier Deep Archive 存储类集成，这样您就可以将虚拟磁带存储在成本最低的 Amazon S3 存储类中，从而将在云中存储长期数据的每月成本降低 75%。使用此功能，磁带网关支持将您的新虚拟磁带直接归档到 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive，从而帮助您满足备份、归档和恢复要求。磁带网关可帮助您将基于磁带的备份移动到 AWS，而无需对现有备份工作流程进行任何更改。磁带网关支持大多数领先的备份应用程序，例如 Veritas、Veeam、Commvault、Dell EMC NetWorker、IBM Spectrum Protect（在 Windows OS 上）和 Microsoft Data Protection Manager。"
    },
    {
        "query":"什么是 Amazon S3 on Outposts？",
        "intention":"知识问答",
        "reply":"Amazon S3 on Outposts 使用 S3 API 和您目前在 AWS 中使用的功能在您的本地环境中提供对象存储。AWS Outposts 是一项完全托管式服务，可将 AWS 基础设施、AWS 服务、API 和工具扩展到几乎任何数据中心、主机托管空间或本地设施。使用 S3 on Outposts，您可以在将数据移动到 AWS 区域之前安全地处理和存储在本地生成的客户数据，针对在本地运行的应用程序在本地访问数据，或者对于所处位置有数据驻留要求的公司或监管行业公司将数据存储在 Outpost 中。要了解有关 S3 on Outposts 的更多信息，请访问[概览页面](https://aws.amazon.com/cn/s3/outposts/)。\n[S3 对象标签](https://aws.amazon.com/cn/s3/faqs#S3_Object_Tags) | [S3 清单](https://aws.amazon.com/cn/s3/faqs#S3_Inventory) | [S3 批量操作](https://aws.amazon.com/cn/s3/faqs#S3_Batch_Operations) | [S3 对象锁定](https://aws.amazon.com/cn/s3/faqs#S3_Object_Lock) | [S3 CloudWatch 指标](https://aws.amazon.com/cn/s3/faqs#S3_CloudWatch_Metrics) | [S3 生命周期管理](https://aws.amazon.com/cn/s3/faqs#S3_Lifecycle_Management)"
    },
    {
        "query":"什么是 S3 对象标签？",
        "intention":"知识问答",
        "reply":"S3 对象标签是应用于 S3 对象的键/值对，在该对象的生命周期内可以随时创建、更新或删除。借助这些标签，您将能够创建 Identity and Access Management (IAM) 策略，设置 S3 生命周期策略以及自定义存储指标。然后，可以使用这些对象级标签管理后台中存储类别与过期对象之间的转换。 上传新对象时，您可以向其添加标签，也可以向现有对象添加标签。每个 S3 对象最多可添加 10 个标签，您可以使用 AWS 管理控制台、REST API、AWS CLI 或 AWS SDK 添加对象标签。\n如需了解更多信息，请访问 [S3 对象标签用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html)。"
    },
    {
        "query":"为何应使用对象标签？",
        "intention":"知识问答",
        "reply":"借助对象标签这一工具，您可以简化 S3 存储的管理。使用此工具能够在对象的生命周期内随时创建、更新和删除标签，从而使您的存储能够满足您业务的需求。借助这些标签，您可以控制对标记有特殊键值对的对象的访问，从而能够进一步保护机密数据，使之仅供选定组或用户访问。 对象标签也可用于标记属于特定项目或业务单元的对象，它可与 S3 生命周期策略结合使用来管理到其他存储类（S3 Standard-IA、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive）的转移或与 S3 复制功能结合使用来选择性地复制 AWS 区域之间的数据。"
    },
    {
        "query":"如何更新对象上的对象标签？",
        "intention":"知识问答",
        "reply":"在 S3 对象的生命周期内，您可以随时更改对象标签，您可以使用 AWS 管理控制台、REST API、AWS CLI 或 AWS 开发工具包更改对象标签。请注意，在 AWS 管理控制台之外进行的所有更改均是对整个标签集合进行的更改。如果某个特定对象关联了 5 个标签，您要为其添加第 6 个标签，那么您需要在该请求中包括最初的 5 个标签。"
    },
    {
        "query":"如何开始使用存储类分析？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或 S3 PUT 存储桶分析 API 配置存储类分析策略，以识别不频繁访问的存储，这些存储可转换到 S3 Standard-IA 或 S3 One Zone-IA 存储类或归档到 S3 Glacier 存储类。您可以导航至 S3 控制台中的 “Management”（管理）选项卡来管理存储类分析、S3 清单和 S3 CloudWatch 指标。"
    },
    {
        "query":"什么是 S3 清单？",
        "intention":"知识问答",
        "reply":"S3 清单报告可为 Amazon S3 的同步列表 API 提供预定的替代方案。您可以通过配置 S3 清单，针对 S3 存储桶或前缀每日或每周提供一次您的对象及其对应元数据的 CSV、 ORC 或 Parquet 文件输出。您可以使用 S3 清单简化并加快业务工作流和大数据作业。您还可以使用 S3 清单验证对象的加密和复制状态是否符合业务、合规性和法规要求。 [通过 Amazon S3 清单用户指南了解更多信息](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)。"
    },
    {
        "query":"如何开始使用 S3 清单？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或 PUT Bucket Inventory Configuration API，为您 S3 存储桶中的所有对象或某个共享前缀下的对象子集配置每日或每周清单报告。在配置过程中，您可以指定 S3 清单报告的目标 S3 存储桶、输出文件的格式（CSV、ORC 或 Parquet）以及您的业务应用程序所需的具体对象元数据，例如：对象名称、大小、上次修改日期、存储类、版本 ID、删除标记、非当前版本标记、分段上传标记、复制状态或加密状态。 您可以将 S3 清单用作应用程序工作流或大数据任务的直接输入。您还可以使用 Amazon Athena、Amazon Redshift Spectrum 及其他工具（例如，Presto、Hive 和 Spark）通过标准 SQL 语言查询 S3 清单。\n通过 [Amazon S3 清单用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)了解更多信息。"
    },
    {
        "query":"什么是 S3 批量操作？",
        "intention":"知识问答",
        "reply":"S3 批量操作是一种功能，您可以使用该功能跨多个对象自动执行单个操作（如复制对象或执行 AWS Lambda 函数）。使用 S3 批量操作，只需在 S3 控制台中单击几次或使用单个 API 请求，即可更改数十亿个对象，而不必为存储管理应用程序编写自定义应用程序代码或运行计算集群。S3 批量操作不仅跨许多对象管理存储操作，还管理重试、显示进度、提供通知、提供完成报告并将在您的目标对象上执行的所有操作的事件发送到 AWS CloudTrail。可从 S3 控制台或通过 AWS CLI 和开发工具包来使用 S3 批量操作。\n要了解更多信息，请访问 [S3 批量操作页面](https://aws.amazon.com/cn/s3/features/batch-operations/)或[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops.html)。"
    },
    {
        "query":"如何开始使用 S3 批量操作？",
        "intention":"知识问答",
        "reply":"您可以通过进入 Amazon S3 控制台或使用 AWS CLI 或开发工具包来开始使用 S3 批量操作创建第一个 S3 批量操作任务。S3 批量操作任务包括要处理的对象的列表和要执行的操作的类型（请参阅[可用操作的完整列表](https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops-operations.html)）。首先选择 S3 清单报告或提供您自己的、S3 批量操作要处理的对象的自定义列表。S3 清单报告是列出了 S3 存储桶或前缀中存储的所有对象的文件。接下来，从 S3 批量操作支持的一组 S3 操作中进行选择，例如替换标签集、更改 ACL、将存储从一个存储桶复制到另一个存储桶或启动从 S3 Glacier Flexible Retrieval 到 S3 Standard 存储类的还原。然后，您可以使用特定参数自定义 S3 批量操作任务，例如标签值、ACL 被授权者和还原持续时间。为了进一步自定义存储操作，您可以编写自己的 Lambda 函数并用 S3 批量操作调用该代码。\n创建 S3 批量操作作业后，它将处理对象列表，并在需要时将作业发送到“等待确认”状态。确认作业详细信息后，S3 批量操作将开始执行您指定的操作。您可以通过编程方式或通过 S3 控制台查看任务进度、接收完成通知并查看列出已对存储所做更改明细的完成报告。\n如果您有兴趣了解有关 S3 批量操作的更多信息，[请观看教程视频](https://aws.amazon.com/cn/s3/s3batchoperations-videos/)并[查看此文档](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/batch-ops.html)。"
    },
    {
        "query":"什么是 Amazon S3 对象锁定？",
        "intention":"知识问答",
        "reply":"Amazon S3 对象锁定是 Amazon S3 的一项功能，可以在固定的时间内或无限期地阻止删除或覆盖对象版本，让您能够通过实施保留策略来进一步保护数据或满足监管要求。您可将工作负载从现有的“一次写入，多次读取”(WORM) 系统迁移到 Amazon S3，并在对象级别或存储桶级别配置 S3 对象锁定，防止在预定义的保留到期日期或无限期（依法保留日期）之前删除对象版本。无论对象版本在哪个存储类中，S3 对象锁定保护都将保留，并且会在存储类之间的整个 S3 生命周期转换期间保留。\n仅当法规要求规定您的数据必须能够防蠕虫时，或者您希望在 Amazon S3 中为数据额外添加一层保护时，才应使用 S3 对象锁定。S3 对象锁定可以帮助您满足规定数据应以不可变格式存储的法规要求，还可保护 Amazon S3 中的数据，使其免遭意外或恶意删除。\n如需了解更多信息，请访问 [S3 对象锁定用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html)。"
    },
    {
        "query":"Amazon S3 对象锁定的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 对象锁定阻止在指定的保留期间内删除对象版本，或者无限期地删除对象版本，直到依法保留被移除。使用 S3 对象锁定，您能够确保对象版本在应用 WORM 保护期间保持不可变。可通过使用 AWS 开发工具包、CLI、REST API 或 S3 管理控制台为对象版本分配保留到期日期或依法保留日期来应用 WORM 保护。可在 PUT 请求内应用保留设置，或在创建对象后对现有对象应用这些设置。\n“保留到期日期”定义对象版本将保持不变的时间长度。为对象分配“保留到期日期”后，在保留到期日期之前将无法修改或删除该对象版本。如果用户在“保留到期日期”之前尝试删除对象，操作将被拒绝。\n或者，您也可以通过应用依法保留来使对象不可变。依法保留阻止对象版本被无限期地修改或删除，直到它被明确移除。为了施加和删除依法保留，您的 AWS 账户必须拥有 PutObjectLegalHold 操作的写入权限。依法保留可以应用于启用了 S3 对象锁定的存储桶中的任何对象，无论该对象当前是否在 WORM 保护的保留期内。\nS3 对象锁定可以在两种模式之一中配置。在监管模式中部署时，具有特定 IAM 权限的 AWS 账户可以从对象版本上移除 WORM 保护。如果您需要更强的不变性以遵守法规，可以使用合规模式。在合规模式中，任何用户都不能移除 WORM 保护，包括根账户。\n问：哪些 AWS 电子存储服务已基于金融服务法规进行了评估？\n对于金融服务行业中的客户，S3 对象锁定为必须以不可删除且不可重写的格式保留记录以满足 SEC Rule 17a-4(f)、FINRA Rule 4511 或 CFTC Regulation 1.31 的法规要求的证券经纪商提供了附加支持。您可以轻松地指定记录保留时间范围来以原始形式将法规存档保留所需的一段时间，还可以实施依法保留以无限期地保留数据，直到撤销保留。"
    },
    {
        "query":"哪些 AWS 文档支持有关通知监管机构的 SEC 17a-4(f)(2)(i) 和 CFTC 1.31(c) 要求？",
        "intention":"知识问答",
        "reply":"在使用 Amazon S3 进行电子存储之前，向监管机构或所选的“指定审查机关 (DEA)”发送通知，同时提供一份 [Cohasset 评估](https://d1.awsstatic.com/r2018/b/S3-Object-Lock/Amazon-S3-Compliance-Assessment.pdf)副本。针对这些要求，AWS 不可作为指定的第三方 (D3P)。请务必选择 D3P，并将此信息添加到发送给 DEA 的通知中。"
    },
    {
        "query":"如何开始使用 S3 CloudWatch 指标？",
        "intention":"知识问答",
        "reply":"使用 AWS 管理控制台，可在 1 分钟内为您的 S3 存储桶生成 CloudWatch 请求指标，或使用前缀或对象标签配置指标的筛选条件，或访问点。此外，还可以通过调用 S3 PUT Bucket Metrics API 来启用 S3 存储指标的发布并对其进行配置。 CloudWatch 请求指标在启用后的 15 分钟内即可在 CloudWatch 中使用。CloudWatch 存储指标默认情况下针对所有存储桶启用，且每天报告一次。了解有关 [Amazon S3 的 Amazon CloudWatch 指标](https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudwatch-monitoring.html)的更多信息。"
    },
    {
        "query":"我可以对我的存储指标设置哪些警报？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch 对任何存储指标数量、计时器或等级设置阈值，当值达到此阈值时，就触发相应操作。例如，您对 4xx 错误响应的百分比设置一个阈值，当值超出此阈值至少 3 个数据点时，就触发 CloudWatch 警报以提醒 DevOps 工程师。"
    },
    {
        "query":"什么是 S3 生命周期管理？",
        "intention":"知识问答",
        "reply":"S3 生命周期管理可以通过预定义的策略定义对象的生命周期，并降低您的存储成本。您可以设置生命周期转换策略，以根据数据的使用年限自动将存储在 S3 Standard 存储类中的对象迁移到 S3 Standard-IA、S3 One Zone-IA 和/或 S3 Glacier 存储类。基于对象的使用年限，您还可以设置生命周期过期策略，将对象自动移除。您可以设置分段上传过期策略，根据上传的存储时间，使未完成的分段上传过期。\n如需了解更多信息，请访问 [S3 生命周期用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)。"
    },
    {
        "query":"如何制定 S3 生命周期管理策略？",
        "intention":"知识问答",
        "reply":"您可以在 AWS 管理控制台、S3 REST API、AWS 开发工具包或 AWS 命令行界面 (CLI) 中设置和管理生命周期策略。您可以在前缀或存储桶级别指定策略。"
    },
    {
        "query":"如何利用 Amazon S3 生命周期管理来帮助降低 Amazon S3 存储成本？",
        "intention":"知识问答",
        "reply":"利用 Amazon S3 生命周期策略，您可以将对象配置为从 S3 Standard 存储类迁移到 S3 Standard-IA 或 S3 One Zone-IA 并/或归档到 S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive 存储类。  \n   \n 您还可以指定一个 S3 生命周期策略，在特定时间段后删除对象。您可以利用此策略驱动的自动化操作来快速而轻松地降低存储成本并节省时间。在每个规则中，您都可以指定前缀、时间段、转移到 S3 Standard-IA、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval、S3 Glacier Deep Archive 和/或过期日期。例如，您可以创建一个规则，规定将带有常见前缀 “logs/” 且创建后已有 30 天的所有对象归档到 S3 Glacier Flexible Retrieval，并且这些对象将于创建之日起的 365 天后失效。  \n   \n 您还可以创建单独的规则，规定仅带有前缀 “backups/” 且已创建 90 天的所有对象将失效。S3 生命周期策略对现有的和新的 S3 对象都适用，可帮助您针对 S3 中存储的所有当前数据和任何新数据优化存储、最大限度地节省成本，而无需耗时的手动数据检查和迁移。  \n   \n 在生命周期规则内，前缀字段用于识别服从该规则的数据对象。要将规则应用于单个数据对象，请指定键名称。要将规则应用于一组数据对象，请指定它们的共同前缀（例如“logs/”）。您可以指定迁移操作和过期操作以存档或删除数据对象。关于时间期限，您可以指定一个创建日期（如 2015 年 1 月 31 日）或自创建之日算起的天数（如 30 天），以便在此日期或超过此天数后将数据对象存档或删除。您可为不同前缀创建多条规则。"
    },
    {
        "query":"为什么要使用 S3 生命周期策略让未完成的分段上传过期？",
        "intention":"知识问答",
        "reply":"使用 S3 生命周期策略让未完成的分段上传过期，可通过限制未完成的分段上传的存储时间，帮助您节省成本。例如，如果您的应用程序上传了若干分段对象部分，但从未提交，那么您仍然需要为其存储付费。此策略可在预定义的天数后自动移除未完成的分段上传及其相关存储，从而降低您的 S3 存储费用。\n[了解有关使用 S3 生命周期让未完成的分段上传过期的更多信息 »](http://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-lifecycle-config)"
    },
    {
        "query":"是否可以设置 Amazon S3 事件通知，以便在 S3 生命周期转移对象或使对象过期时发送通知？",
        "intention":"知识问答",
        "reply":"是，您可以设置 [Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)，以便在 S3 生命周期转移对象或使对象过期时通知您。例如，您可以在 S3 生命周期移动对象到不同 S3 存储类或使对象过期时发送 S3 事件通知到 Amazon SNS 主题、Amazon SQS 队列或 AWS Lambda 函数。"
    },
    {
        "query":"哪些功能可用于分析我的 Amazon S3 存储使用情况？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 提供了对对象存储使用情况和活动趋势的组织范围可见性，并提出了可行的建议，以优化成本并应用数据保护最佳实践。S3 存储类分析使您可以跨对象监控访问模式，以帮助您决定何时将数据转换为正确的存储类，从而优化成本。然后，您可以使用此信息来配置进行数据传输的 S3 生命周期策略。Amazon S3 清单针对 S3 存储桶或前缀每日或每周提供一次对象及其对应元数据的报告。该报告通过验证对象的加密和复制状态，来帮助满足业务、合规和监管需求。"
    },
    {
        "query":"什么是 Amazon S3 Storage Lens？",
        "intention":"知识问答",
        "reply":"Amazon S3 Storage Lens 提供了对对象存储使用量和活动趋势的组织范围可见性，以及可行的建议，以优化成本并应用数据保护的最佳实践。Storage Lens 提供了一个交互式控制面板，其中包含组织中数十或数百个账户的对象存储使用情况和活动的单一视图，并可以通过向下钻取在多个聚合级别生成见解。这包含字节、对象计数、请求等指标，以及详细描述 S3 功能使用率的指标，例如加密对象计数和 S3 生命周期规则计数。S3 Storage Lens 还提供符合实际情况的建议，以找到降低存储成本的方法，并在数十个或数百个账户和存储桶之间应用数据保护方面的最佳实践。S3 Storage Lens 免费指标默认为所有 Amazon S3 用户启用。如果您想充分利用 S3 Storage Lens，则可以激活高级指标和建议。如需了解更多信息，请访问 [S3 Storage Lens 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html)。"
    },
    {
        "query":"S3 Storage Lens 如何运作？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 每日汇总您的存储使用情况和活动指标，在 S3 Storage Lens 交互式控制面板上可视化显示，或以 CSV 或 Parquet 文件格式导出指标。在账户级别自动为您创建一个默认控制面板，您可以选择创建其他自定义控制面板。S3 Storage Lens 控制面板的范围可以限定为您的 AWS 组织或特定账户、区域、存储桶，甚至前缀级别（适用于 S3 Storage Lens 高级指标）。配置控制面板时，您可以使用默认指标选择，或升级以接收额外费用的 35 个额外指标和建议。此外，S3 Storage Lens 还会根据控制面板中的存储指标情况提供建议，以便您可以采取行动以根据指标优化存储。"
    },
    {
        "query":"使用 S3 Storage Lens 指标可以回答哪些关键问题？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 控制面板围绕四种主要类型的问题进行组织，这些问题可以回答有关您的存储的问题。使用“摘要”筛选器，可以探索与总体存储使用情况和活动趋势相关的最高级别问题。例如，“我的总体字节计数和请求计数是如何随时间快速增长的？” 通过“成本优化”筛选器，您可以探索与降低存储成本相关的问题，例如，“我是否可以通过保留较少的非当前版本来节省资金？” 通过“数据保护”和“访问管理”筛选器，您可以回答有关保护数据的问题，例如，“我的存储是否受到保护，不会被意外或故意删除？” 最后，通过“性能”和“事件”筛选器，您可以探索提高工作流性能的方法。这些问题中的每一个都代表可能导致向下钻取分析的第一层查询。"
    },
    {
        "query":"S3 Storage Lens 提供了哪些指标？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 包含 60 多个指标，分为免费指标和高级指标（需额外付费）。在免费指标中，您会收到用于分析使用情况的指标（基于对象的每日快照），这些指标分为成本优化、数据保护、访问管理、性能和事件类别。在高级指标中，您会收到与活动相关的指标（例如请求计数）、更深入的成本优化（例如 S3 生命周期规则计数）、额外的数据保护（例如 S3 复制规则计数）和详细的状态代码（例如 403 授权错误）。此外，还可以通过组合任何基本指标来提供派生指标。例如，“检索率”是通过将“下载字节数”除以“总存储量”计算得出的指标。 若要查看指标的完整列表，请访问 [S3 Storage Lens 文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage_lens.html)。"
    },
    {
        "query":"我的控制面板配置选项是什么？",
        "intention":"知识问答",
        "reply":"为您的整个账户提供自动配置的默认控制面板，您可以选择创建其他自定义控制面板，限于您的 AWS 组织、特定区域或账户中的存储桶。您可以设置多个自定义控制面板，如果您需要在存储分析中进行一些逻辑分离，例如对存储桶进行分段以代表各种内部团队，这将非常有用。默认情况下，您的控制面板会接收 S3 Storage Lens 免费指标，但您可以选择升级接收 S3 Storage Lens 高级指标和建议（需额外付费）。S3 Storage Lens 高级指标有 6 个不同的选项：活动指标、高级成本优化指标、高级数据保护指标、详细状态代码指标、前缀聚合和 CloudWatch 发布。此外，您可以为每个控制面板启用指标导出，还可以选择指定目标存储桶和加密类型。"
    },
    {
        "query":"S3 Storage Lens 中有多少历史数据可用？",
        "intention":"知识问答",
        "reply":"对于交互式控制面板中显示的指标，Storage Lens 免费指标保留 14 天的历史数据，Storage Lens 高级指标（额外收费）则保留 15 个月的历史数据。对于可选的指标导出，您可以配置您想要的任何保留期，并且将按标准 S3 存储收费。"
    },
    {
        "query":"S3 Storage Lens 与 S3 Inventory 有什么区别？",
        "intention":"知识问答",
        "reply":"S3 清单针对 S3 存储桶或共享前缀提供对象及其相应元数据的列表，可用于执行存储的对象级分析。S3 Storage Lens 提供按组织、账户、区域、存储类、存储桶和前缀级聚合的指标，可以使组织范围内的存储可见性得到改善。"
    },
    {
        "query":"S3 Storage Lens 和 S3 存储类分析 (SCA) 之间的区别是什么？",
        "intention":"知识问答",
        "reply":"S3 存储类分析通过根据过去 30 至 90 天的单个存储桶/前缀/标签内的对象级访问模式创建对象年龄组，为最佳存储类提供建议。S3 Storage Lens 提供有关提高成本效率和应用数据保护最佳实践的方法的日常组织级建议，以及按账户、区域、存储类、存储桶或前缀（可用于 S3 Storage Lens 高级指标）的额外细化建议。"
    },
    {
        "query":"什么是存储类分析？",
        "intention":"知识问答",
        "reply":"使用存储类分析，您可以分析存储访问模式，以确定适合您的存储的最佳存储类。这一 S3 功能可自动识别不频繁访问模式，从而帮助您将存储转换为 S3 Standard-IA。您可以配置存储类分析策略来监视整个存储桶、前缀或对象标签。在观察到不频繁访问模式后，您可以根据结果轻松地创建新的 S3 生命周期策略。存储类分析还以可视化方式在 AWS 管理控制台上提供您每天的存储使用情况，您还可以将报告导出至 S3 存储桶，以便使用所选的 Amazon QuickSight 等商业智能工具进行分析。\n要想了解更多信息并开始使用，请访问 [S3 存储类分析用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/analytics-storage-class.html)。"
    },
    {
        "query":"存储类分析多久更新一次？",
        "intention":"知识问答",
        "reply":"存储类分析在 S3 管理控制台中每天更新，但对存储类转换的最初建议在 30 天后提供。"
    },
    {
        "query":"什么是“随时查询”功能？",
        "intention":"知识问答",
        "reply":"Amazon S3 允许客户对存储数据运行复杂的查询，无需将数据移动到独立的分析平台。随时查询 Amazon S3 数据的功能可以大大提升性能，降低利用 S3 作为数据湖的分析解决方案的成本。S3 提供多种随时查询选项，包括 S3 Select、Amazon Athena 和 Amazon Redshift Spectrum，使您能够从中选择最适合您的使用案例的选项。您甚至可以将 Amazon S3 Select 与 AWS Lambda 搭配使用，来构建无服务器应用程序，此类应用程序可有效利用 S3 Select 提供的随时处理功能。"
    },
    {
        "query":"什么是 S3 Select？",
        "intention":"知识问答",
        "reply":"S3 Select 是 Amazon S3 的一项功能，可以使用简单的 SQL 表达式轻松地从对象的内容中检索特定数据，而无需检索整个对象。S3 Select 简化了扫描对象内容并将其筛选成更小且具有针对性的数据集的流程，并将这一性能提升高达 400%。借助 S3 Select，您还可以对 Amazon S3 中的日志文件执行操作调查，无需操作或管理计算集群。\n您可以使用 S3 Select 通过 SQL 子句（如 SELECT 和 WHERE）从以 CSV、JSON 或 Apache Parquet 格式存储的对象中检索一部分数据。此方法也适用于通过 GZIP 或 BZIP2 压缩的对象（仅对于 CSV 和 JSON 对象）和服务器端加密对象。\n您可以将 S3 Select 与 AWS Lambda 结合使用来构建无服务器应用程序，此类应用程序可使用 S3 Select 有效且轻松地检索 Amazon S3 中的数据，而不是检索和处理整个对象。您也可以将 S3 Select 与大数据框架（例如 Presto、Apache Hive 和 Apache Spark）结合使用，来扫描和筛选 Amazon S3 中的数据。\n如需了解更多信息，请访问  [S3 Select 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html)。"
    },
    {
        "query":"什么是 Amazon Athena？",
        "intention":"知识问答",
        "reply":"Amazon Athena 是一项交互式查询服务，让您能够轻松[使用标准 SQL 查询分析 Amazon S3 中的数据](https://aws.amazon.com/cn/athena/)。Athena 是无服务器式服务，因此您无需设置或管理基础设施即可马上开始分析数据。您甚至无需将数据加载到 Athena 中，因为它可以直接处理所有 S3 存储类中存储的数据。要开始使用，您只需登录到 Athena 管理控制台，定义架构，然后开始查询即可。Amazon Athena 使用 Presto 并为标准 SQL 提供了完整的支持，可处理 CSV、JSON、ORC、Apache Parquet 和 Avro 等各种标准数据格式。Athena 不仅是快速、临时查询的理想选择，可与 Amazon QuickSight 集成轻松实现可视化，而且还能处理复杂的分析，包括大型联接、窗口函数和数组。"
    },
    {
        "query":"什么是 Amazon Redshift Spectrum？",
        "intention":"知识问答",
        "reply":"Amazon Redshift Spectrum 是 Amazon Redshift 的一项功能，借助这项功能，您可以对 [Amazon S3 中的 EB 级非结构化数据运行查询](https://aws.amazon.com/cn/redshift/features/)，而无需执行加载或 ETL 操作。当您发布查询时，查询会进入 Amazon Redshift SQL 终端节点，该终端节点会生成查询方案并对其进行优化。Amazon Redshift 会确定哪些数据存储在本地以及哪些数据存储在 Amazon S3 中，然后生成一种方案来尽可能减少需要读取的 Amazon S3 数据量，从共享资源池中请求 Redshift Spectrum 工作线程来读取和处理 Amazon S3 中的数据。\nRedshift Spectrum 可根据需要扩展到数千个实例，因此，无论数据大小如何，查询都会快速运行。而且，您可以像现在针对 Amazon Redshift 查询所做的一样，针对 Amazon S3 数据使用完全相同的 SQL，并可使用相同的商业智能工具连接到同一 Amazon Redshift 终端节点。Redshift Spectrum 可以实现单独的存储和计算，从而让您能够逐一单独扩展。您可以根据需要设置多个 Amazon Redshift 群集来查询 Amazon S3 数据湖，从而提供高可用性和无限制的并发度。借助 Redshift Spectrum，您可以灵活地将数据以您想要的格式存储在您想要的位置，并在需要时即时用于处理。\n[S3 复制时间控制](https://aws.amazon.com/cn/s3/faqs#S3_Replication_Time_Control) | [S3 多区域访问点](https://aws.amazon.com/cn/s3/faqs#S3_Multi-Region_Access_Points)"
    },
    {
        "query":"什么是 Amazon S3 复制？",
        "intention":"知识问答",
        "reply":"[Amazon S3 复制](https://aws.amazon.com/cn/s3/features/replication/)支持跨 Amazon S3 存储桶自动以异步方式复制对象。配置为用于对象复制的存储桶可以由相同的 AWS 账户拥有，也可以由不同的 AWS 账户拥有。您可以将写入存储桶的新对象复制到不同 AWS 区域之间（S3 跨区域复制）或同一 AWS 区域内（S3 同区域复制）的一个或多个目标存储桶。您还可以复制现有存储桶内容（S3 批量复制），包括现有对象、之前复制失败的对象以及从其他源复制的对象。要了解更多信息，请访问 [S3 复制用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html)。"
    },
    {
        "query":"什么是 Amazon S3 跨区域复制 (CRR)？",
        "intention":"知识问答",
        "reply":"CRR 是 Amazon S3 的一项功能，可在不同 AWS 区域的存储桶之间自动复制数据。利用 CRR，您可以使用 S3 对象标签设置存储桶级别、共享前缀级别或对象级别的复制。您可以使用 CRR 在不同的地理区域中提供低延迟的数据访问。如果您需要遵循将数据副本存储在相距数百公里的不同地点的合规性要求，CRR 还可以帮助您达成这一目标。您可以使用 CRR 更改复制对象的账户所有权，以防数据意外删除。 要了解更多信息，请访问 [S3 CRR 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html#crr-scenario)。"
    },
    {
        "query":"什么是 Amazon S3 同区域复制（SRR）？",
        "intention":"知识问答",
        "reply":"SRR 是 Amazon S3 的一项功能，可在同一 AWS 区域内的存储桶之间自动复制数据。利用 SRR，您可以使用 S3 对象标签设置存储桶级别、共享前缀级别或对象级别的复制。您可以使用 SRR 在相同 AWS 区域内创建数据的一个或多个副本。SRR 可在原始数据所在的区域内将数据副本保存在单独的 AWS 账户中，从而帮助您获得数据主权并满足合规性要求。您可以使用 SRR 更改复制对象的账户所有权，以防数据意外删除。您也可以使用 SRR 轻松汇总来自不同 S3 存储桶的日志以进行区域内处理，或配置测试环境与开发环境之间的实时复制。要了解更多信息，请访问 [S3 SRR 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html#srr-scenario)。"
    },
    {
        "query":"如何启用 Amazon S3 复制（跨区域复制和同区域复制）功能？",
        "intention":"知识问答",
        "reply":"您可以使用 S3 对象标签在 S3 存储桶级别、共享前缀级别或对象级别配置 Amazon S3 复制（CRR 和 SRR）功能。在同一或不同 AWS 区域中指定目标存储桶用于复制，这样就可以在源存储桶上添加复制配置。\n您可以使用 S3 控制台、API、AWS CLI、AWS SDK 或 AWS CloudFormation 来启用复制。要启用复制功能，必须对源存储桶和目标存储桶都启用版本控制功能。要了解更多信息，请访问 Amazon S3 文档中的[S3 复制功能设置概览](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"如何使用 S3 批量复制？",
        "intention":"知识问答",
        "reply":"您首先需要在存储桶级别启用 S3 复制。请参考上一个问题以了解如何执行此操作。然后，您可以在创建新的复制配置、从复制配置页面或从 S3 Batch Operations Create Job（S3 批量操作创建作业）页面更改复制规则中的复制目标后，在 S3 控制台中启动 S3 批量复制作业。或者，您可以通过 AWS CLI 或 SDK 启动 S3 批量复制作业。要了解更多信息，请访问 Amazon S3 文档中的 [S3 复制](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"我可以对 S3 生命周期规则使用 S3 复制功能吗？",
        "intention":"知识问答",
        "reply":"借助 S3 复制功能，您可以制定复制规则，将对象复制到同一区域或其他区域中的另一个存储类中。您无法复制生命周期操作，如果您希望对源存储桶和目标存储桶应用相同的生命周期配置，那么请在两个存储桶上启用相同的生命周期配置。\n例如，您可以配置生命周期规则，将数据从 S3 Standard 存储类迁移到 S3 Standard-IA 或 S3 One Zone-IA 存储类，或将数据归档到目标存储桶上的 S3 Glacier 存储类。\n如果您为目标存储桶配置了 S3 生命周期，我们建议在批量复制作业处于活跃状态时禁用生命周期规则，以保持源存储桶和目标存储桶中对象的非当前版本和当前版本之间的奇偶校验。  \n   \n 有关生命周期配置的更多信息，请参阅 [S3 复制文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-and-other-bucket-configs.html)。"
    },
    {
        "query":"我可以跨 AWS 账户使用复制功能来防止恶意或意外删除吗？",
        "intention":"知识问答",
        "reply":"是的，对于 CRR 和 SRR，您可以跨 AWS 账户设置复制功能，将复制的数据存储在目标区域的不同账户中。您可以在复制配置中使用所有权覆盖来维护源和目标之间的不同所有权堆栈，并将目标账户所有权授予复制的存储。"
    },
    {
        "query":"如果使用跨区域复制，对象标签也会复制吗？",
        "intention":"知识问答",
        "reply":"使用跨区域复制可以跨 AWS 区域复制对象标签。已启用跨区域复制的用户需要具有新的权限才能复制标签。有关设置跨区域复制的更多信息，请访问 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html)中的[如何设置跨区域复制](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr-how-setup.html)。"
    },
    {
        "query":"是否可以将删除标记从一个存储桶复制到另一个存储桶？",
        "intention":"知识问答",
        "reply":"可以，如果在复制配置中启用了删除标记复制，则可以将删除标记从源位置复制到目标位置。复制删除标记时，Amazon S3 将表现为在两个存储桶中都删除了对象。您可以为新的或现有的复制规则启用删除标记复制。您可以使用基于前缀的复制规则将删除标记复制应用于整个存储桶或具有特定前缀的 Amazon S3 对象。Amazon S3 复制不支持基于对象标签的复制规则的删除标记复制。要了解有关启用删除标记复制的更多信息，请参阅[将删除标记从一个存储桶复制到另一个存储桶](https://docs.aws.amazon.com/AmazonS3/latest/dev/delete-marker-replication.html)。"
    },
    {
        "query":"我可以将数据从其他 AWS 区域复制到中国区域吗？ 客户可以将数据从一个中国区域存储桶复制到中国之外的区域吗？",
        "intention":"知识问答",
        "reply":"不能，目前不支持在 AWS 中国区域和中国之外的 AWS 区域使用 Amazon S3 复制。您只能在中国区域内复制。"
    },
    {
        "query":"我可以复制现有对象吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 S3 复制，以在存储桶之间复制现有数据。要了解详情，请访问 [S3 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html)。"
    },
    {
        "query":"如果对象最初无法复制，我可以重新尝试复制吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 S3 批量复制来重新复制最初无法复制的对象。要了解详情，请访问 [S3 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html)。"
    },
    {
        "query":"S3 复制支持的加密类型有哪些？",
        "intention":"知识问答",
        "reply":"S3 复制支持 S3 提供的所有加密类型。S3 提供服务器端加密和客户端加密 — 前者要求 S3 为您加密对象，后者时用于在数据上传到 S3 之前在客户端对数据进行加密。对于服务器端加密，S3 提供了三种加密方式：使用 Amazon S3 托管密钥的服务器端加密（SSE-S3），使用存储在 AWS 密钥管理服务的 KMS 密钥的服务器端加密（SSE-KMS），以及使用客户提供的密钥的服务器端加密（SSE-C）。关于这些加密类型及其工作原理的详细信息，请访问[详细说明加密使用的 S3 文档。](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingEncryption.html)"
    },
    {
        "query":"跨账户数据复制如何定价？",
        "intention":"知识问答",
        "reply":"借助 S3 复制，您可以配置源存储桶和目标存储桶归不同 AWS 账户所有的跨账户复制。不包括 S3 存储和适用的检索费用，在使用 S3 复制时，客户需要支付复制 PUT 请求和从 S3 到目标区域的区域间数据传出费用。如果您在复制规则上启用了 S3 复制时间控制 (S3 RTC)，您将看到与 S3 RTC 特定相关的不同数据传出和复制 PUT 请求费用。对于跨账户复制，源账户支付所有数据传输（S3 RTC 和 S3 CRR）的费用，目标账户支付复制 PUT 请求的费用。数据传输费仅适用于 S3 跨区域复制（S3 CRR）和 S3 复制时间控制（S3 RTC），S3 同区域复制（S3 SRR）不产生数据传输费。\n如果您使用 S3 批量复制跨账户复制对象，除了复制 PUT 请求和数据传输 OUT 费用外，您还将产生 S3 分批操作费用（请注意，S3 RTC 不适用于批量复制）。分批操作费用包括作业和对象费用，分别基于作业数量和处理的对象数量。此外，如果您选择使用 Amazon S3 生成的清单，您将根据源存储桶中的对象数量产生清单费用。  \n   \n 访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)了解关于 S3 复制定价的更多详细信息。"
    },
    {
        "query":"什么是 Amazon S3 复制时间控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制提供可预测的复制性能，并帮助您满足合规或业务需求。S3 复制时间控制旨在实现数秒内复制大多数对象，15 分钟内复制 99.99% 的对象。S3 复制时间控制由[服务等级协议](https://aws.amazon.com/cn/s3/sla-rtc/)（SLA）承诺提供支持，在任何计费月份中，对于每个复制区域，99.9% 的对象将在 15 分钟内复制。复制时间适用于所有 S3 复制功能。要了解更多信息，请访问[复制文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html)。"
    },
    {
        "query":"如何启用 Amazon S3 复制时间控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制作为每个复制规则的一个选项启用。您可以使用 S3 复制时间控制创建新的 S3 复制策略，或者在现有策略上启用该功能。您可以使用 S3 控制台、API、AWS CLI、AWS SDK 或 AWS CloudFormation 来配置复制。要了解更多信息，请访问《Amazon S3 开发人员指南》中的[设置复制功能概述](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"我可以使用 S3 复制时间控制在中国区域内部和区域之间进行数据复制吗？",
        "intention":"知识问答",
        "reply":"是的，您可以启用 Amazon S3 复制时间控制，在 AWS 中国（宁夏）和中国（北京）区域内部和其之间进行数据复制。"
    },
    {
        "query":"什么是 Amazon S3 复制指标和事件？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制在 Amazon S3 控制台和 Amazon CloudWatch 中提供了四个详细指标：待处理操作、待处理字节、复制延迟和操作复制失败。您可以使用这些指标监控待复制操作总数和待复制对象的大小、源存储段和目标存储段之间的复制延迟以及每条复制规则中未成功复制的操作数。此外，您可以设置 *s3:Replication* 类型的 Amazon S3 事件通知，以获取有关复制失败的对象和失败原因的更多信息。我们建议使用 [Amazon S3 复制失败原因](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-failure-codes.html)快速诊断错误并进行修复，然后使用 S3 批量复制重新复制失败的对象。最后，如果您启用了 S3 Replication Time Control (S3 RTC)，您将在复制一个对象的时间超过 15 分钟时收到 S3 事件通知，并在该对象成功复制到其目的地时收到另一条通知。"
    },
    {
        "query":"如何启用 Amazon S3 复制指标和事件？",
        "intention":"知识问答",
        "reply":"可以为每个新的复制规则或现有复制规则启用 Amazon S3 复制指标和事件，默认情况下，已为 S3 复制时间控制启用的规则启用它们。您可以通过 Amazon S3 控制台和 Amazon CloudWatch 访问 S3 复制指标。与其他 Amazon S3 事件一样，S3 复制事件可以通过 Amazon Simple Queue Service (Amazon SQS)、Amazon Simple Notiﬁcation Service (Amazon SNS) 或 AWS Lambda 获得。要了解更多信息，请访问《Amazon S3 开发人员指南》中的[使用复制指标监控进度和 Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-metrics.html)。"
    },
    {
        "query":"失败操作复制指标显示了哪些信息？",
        "intention":"知识问答",
        "reply":"失败操作复制指标将显示特定复制规则每分钟复制失败的操作总数。该指标将每分钟刷新一次，对每个失败的操作发出 +1，对成功的操作发出 0，如果在该分钟内没有执行任何复制操作，则不发出任何指标。每当操作未能成功复制时，都会发出此指标。"
    },
    {
        "query":"我能否使用 Amazon S3 复制指标和事件来跟踪 S3 批量复制？",
        "intention":"知识问答",
        "reply":"您无法使用待处理字节、待处理操作和复制延迟等指标来跟踪 S3 批量复制进度。但是，您可以使用失败操作复制指标来监控无法通过 S3 批量复制成功复制的现有对象。此外，您还可以使用 S3 批量操作完成报告来跟踪通过 S3 批量复制的对象。"
    },
    {
        "query":"Amazon S3 复制指标在哪里发布？",
        "intention":"知识问答",
        "reply":"待处理字节、待处理操作和复制延迟指标在源 AWS 账户和目标 AWS 区域中发布。但是，失败操作复制指标在源 AWS 账户和源 AWS 区域，而不是目标 AWS 区域发布。造成这种情况的主要原因有两个。首先，如果在目标区域发布失败操作复制指标，则在目标存储桶配置错误时，客户将看不到该指标。例如，如果客户在复制配置中错误地键入了目标存储桶名称，并且由于未找到目标存储桶而复制失败，则客户将无法看到此指标的任何值，因为找不到目标存储桶时，目标区域将是未知的。其次，如果客户要复制到可选择加入的目标区域，例如香港或巴林，则在复制失败的情况下，如果源账户未选择加入目标区域，则客户将看不到任何指标。"
    },
    {
        "query":"什么是 Amazon S3 复制时间控制服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制旨在实现 15 分钟内复制 99.99% 的对象，由服务等级协议提供支持。如果在每月计费周期中，每个复制区域对 15 分钟内复制的对象少于 99.9%，那么 S3 RTC SLA 将针对任何复制时间超过 15 分钟的对象提供服务积分。服务积分包括与不符合 SLA 的对象相关的所有相关复制费用百分比，包括 RTC 费用、复制带宽和请求费用，以及在受影响的每月计费周期中与将副本存储在目标区域相关的成本。要了解详情，请阅读 [S3 复制时间控制 SLA](https://aws.amazon.com/cn/s3/sla-rtc/)。"
    },
    {
        "query":"S3 复制和 S3 复制时间控制的定价是多少？",
        "intention":"知识问答",
        "reply":"对于 S3 复制（跨区域复制和同区域复制），您需要为所选目标 S3 存储类中的存储支付 S3 费用，还要支付主副本、复制 PUT 请求的存储费用以及适用的不频繁访问存储检索费用。对于 CRR，您还需要支付从 S3 到目标区域的区域间数据传出费用。 S3 复制指标的费率与 Amazon CloudWatch 自定义指标费率相同。此外，当您使用 S3 复制时间控制时，您还需要支付复制时间控制数据传输费。有关更多信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。\n如果源对象是通过分段上传功能上传的，则使用相同数量的段和段大小进行复制。例如，通过分段上传功能上传的 100GB 对象（800 个段，每段 128MB）在复制时会产生与 802 个请求（800 个上传段请求 + 1 个初始分段上传请求 + 1 个完成分段上传请求）关联的请求成本。您会产生 0.00401 USD（802 个请求 x 0.005 USD/1000 个请求）的请求费用和（如果在不同的 AWS 区域之间进行复制）2.00 USD（0.020 USD/GB 传输 x 100GB）的区域间数据传输费用。复制后，该 100GB 数据会产生基于目标区域的存储费用。"
    },
    {
        "query":"什么是 S3 多区域访问点？",
        "intention":"知识问答",
        "reply":"在访问跨多个 AWS 区域复制的数据集时，[Amazon S3 多区域访问点](https://aws.amazon.com/cn/s3/features/multi-region-access-points/)可将性能提高多达 60%。基于 AWS Global Accelerator，S3 多区域接入点会考虑网络拥塞和请求应用程序的位置等因素，通过 AWS 网络将您的请求动态路由到数据的最低延迟副本。这种自动路由允许您利用 AWS 的全球基础设施，同时保持简单的应用程序架构。"
    },
    {
        "query":"为什么应该使用 S3 多区域访问点？",
        "intention":"知识问答",
        "reply":"S3 多区域访问点可加速并简化多区域应用程序的存储。通过将 S3 请求动态路由到复制数据集，S3 多区域访问点减少了请求延迟，使应用程序运行速度提高 60%。S3 多区域访问点还可以帮助您构建弹性多区域和多账户应用程序，这些应用程序可以更好地防范意外或未经授权的数据删除。借助 S3 多区域访问点，您还可利用 AWS 的全球基础设施，同时为应用程序保持与区域无关的简单架构。"
    },
    {
        "query":"S3 多区域访问点的工作原理是什么？",
        "intention":"知识问答",
        "reply":"多区域访问点将客户端请求动态路由到一个或多个底层 S3 存储桶。您可以将多区域访问点配置为每个 AWS 区域（最多 20 个 AWS 区域）跨一个存储桶进行路由。创建多区域访问点时，S3 会自动生成与 DNS 兼容的名称。此名称将用作客户端可以使用的全局端点。当客户端向该端点发出请求时，S3 会将这些请求动态路由到多区域访问点配置中指定的一个底层存储桶。 基于互联网的请求被载入 AWS 全球网络，以避免互联网上的网段拥塞，从而减少网络延迟和抖动，同时提高性能。基于 AWS Global Accelerator，通过互联网访问 S3 的应用程序可以通过 S3 多区域访问点将性能进一步提高多达 60%。\n要直接控制此路由，您可以在主动-主动或主动-被动配置中运行 S3 多区域访问点。在主动-被动配置中，您可以使用 S3 多区域访问点失效转移控制来启动失效转移，以在几分钟内将 S3 数据访问请求流量转移到所选的备用 AWS 区域和账户。\n在主动-主动配置中，S3 多区域访问点会考虑网络拥塞和请求应用程序的位置等因素，通过 AWS 网络将您的请求动态路由到最近的数据副本。S3 多区域访问点会将您的请求路由到离您的客户端最近的 AWS 位置，然后通过全球私有 AWS 网络路由到 S3。\n在任何一种配置中，S3 多区域访问点都允许您利用 AWS 的全球基础设施，同时保持简单的应用程序架构。"
    },
    {
        "query":"S3 多区域访问点失效转移控制的工作原理是什么？",
        "intention":"知识问答",
        "reply":"默认情况下，S3 多区域访问点根据主动-主动配置中的网络延迟将请求路由到离客户端最近的底层存储桶。例如，您可以在美国东部（弗吉尼亚州北部）和亚太地区（孟买）配置一个具有底层存储桶的多区域访问点。通过此配置，您在北美的客户端将路由到美国东部（弗吉尼亚州北部），而您在亚洲的客户将路由到亚太地区（孟买）。这降低了对 S3 请求的延迟，提高了应用程序的性能。如果您更喜欢主动-被动配置，则所有 S3 数据请求流量都可以通过 S3 多区域访问点路由到作为活动区域的美国东部（弗吉尼亚州北部），并且不会将任何流量路由到亚太地区（孟买）。如果需要按计划或在计划外将所有 S3 数据请求流量失效转移到亚太地区（孟买），您可以启动失效转移，在几分钟内即可切换到亚太地区（孟买）并将其作为新的活动区域。美国东部（弗吉尼亚州北部）正在进行的任何现有上传或下载都将继续完成，并且通过 S3 多区域访问点的所有新 S3 数据请求流量将路由到亚太地区（孟买）。"
    },
    {
        "query":"S3 传输加速与 S3 多区域访问点有何不同？",
        "intention":"知识问答",
        "reply":"S3 多区域访问点和 S3 传输加速提供类似的性能优势。 您可以使用 S3 Transfer Acceleration 来加速使用 AWS 全球网络与 Amazon S3 之间的内容传输。S3 Transfer Accelerator 可以帮助加速较大对象与单个 Amazon S3 存储桶之间的远距离传输。借助 S3 多区域访问点，您可以使用 AWS 全球网络执行类似的加速传输，但跨多个 AWS 区域中的许多 S3 存储桶，以处理进出 S3 的基于互联网、基于 VPC 和本地的请求。 当您将 S3 多区域访问点与 S3 Cross Replication 结合使用时，您将为 S3 多区域访问点提供将您的请求动态路由到来自多个位置的客户端的应用程序的最低延迟数据副本的功能。"
    },
    {
        "query":"如何开始使用 S3 多区域访问点和失效转移控制？",
        "intention":"知识问答",
        "reply":"S3 控制台提供了一个简单的引导式工作流程，只需三个简单的步骤即可快速设置在 S3 上运行多区域存储所需的一切。首先，创建一个 Amazon S3 多区域访问点端点并指定您要在其间进行复制和失效转移的 AWS 区域。通过输入创建时拥有多个 AWS 账户的账户 ID，您可以将多个 AWS 账户中的存储桶添加到新的 S3 多区域访问点。其次，对于 S3 多区域访问点端点后面的每个 AWS 区域和 S3 存储桶，指定它们的路由状态是主动还是被动，其中主动 AWS 区域可以接受 S3 数据请求流量，被动区域在您启动失效转移之前不会被路由。第三，配置您的 S3 Cross-Region Replication 规则来同步你在不同区域和/或账户之间的 S3然后，您可以随时在 AWS 区域之间启动失效转移，以转移您的 S3 数据请求并监控您的 S3 流量转移到 Amazon CloudWatch 中的新活动 AWS 区域。或者，您也可以使用 AWS CloudFormation 自动配置多区域存储。CloudFormation 支持在 S3 上设置多区域存储所需的所有构建数据块，包括 S3 多区域访问点，允许您在 S3 控制台之外自动执行可重复的设置过程。"
    },
    {
        "query":"什么是 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"借助 S3 Object Lambda，您能够将自己的代码添加到 S3 GET、LIST 和 HEAD 请求中，以便在数据返回到应用程序时修改和处理数据。您可以使用自定义代码来修改 S3 GET 请求返回的数据，以便实施筛选行、动态调整图像大小、隐去机密数据等操作。您还可以使用 S3 Object Lambda 来修改 S3 LIST 请求的输出，以创建存储桶中对象的自定义视图，并使用 S3 HEAD 请求修改对象元数据（如对象名称和大小）。S3 Object Lambda 可以帮助您轻松满足任何应用程序的独特数据格式要求，而无需构建和运行额外的基础设施（例如代理层），也不必创建和维护数据的多个衍生副本。S3 Object Lambda 使用 AWS Lambda 函数自动处理标准 S3 GET、LIST 或 HEAD 请求的输出。AWS Lambda 是一种无服务器计算服务，无需管理底层计算资源，即可运行客户定义的代码。\n只需在 AWS 管理控制台中单击几下，即可配置 Lambda 函数并将其附加到 S3 Object Lambda 服务访问点。此后，S3 将自动调用 Lambda 函数来处理通过 S3 Object Lambda 端点检索到的任何数据，并将转换后的结果返回应用程序。您可以编写和执行自己的自定义 Lambda 函数，根据您的特定使用案例定制 S3 Object Lambda 的数据转换。\n可以通过 S3 管理控制台、开发工具包或 API 来开始使用 S3 Object Lambda。如需了解更多信息，请访问 [S3 Object Lambda 页面，](http://aws.amazon.com/s3/features/object-lambda)或 S3 Object Lambda [用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"为何应使用 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"如果您想通过 S3 GET、LIST 或 HEAD 请求内联处理数据，则应使用 S3 Object Lambda。您可以使用 S3 Object Lambda 在多个应用程序间共享数据的单个副本，这样既无需构建和运行自定义处理基础设施，也无需存储数据的衍生副本。例如，使用 S3 Object Lambda 处理 S3 GET 请求后，您可以对敏感数据设置掩码以满足合规性要求、重组原始数据以便其与机器学习应用程序兼容、筛选数据以限制对 S3 对象中特定内容的访问，或满足各种其他使用案例需求。您可以使用 S3 Object Lambda 来丰富对象列表，方法是查询包含额外对象元数据的外部索引，筛选和屏蔽对象列表以只包含具有特定对象标签的对象，或者向对象列表中的所有对象名称添加文件扩展名。例如，如果您有一个包含多个离散数据集的 S3桶，您可以使用 S3 Object Lambda 来根据请求者筛选 S3 LIST 响应。\n只需在 Amazon S3 管理控制台中单击几下即可设置 S3 Object Lambda。请参阅[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)，了解更多信息。"
    },
    {
        "query":"S3 Object Lambda 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 使用您指定的 Lambda 函数来处理 GET、LIST 和 HEAD 请求的输出。对某个 Lambda 函数进行定义（以处理请求的数据）后，可以将该函数附加到 S3 Object Lambda 访问点。通过 S3 Object Lambda 访问点发出的 S3 GET、LIST 和 HEAD 请求现在将调用指定的 Lambda 函数。然后，Lambda 将获取客户端请求的 S3 对象并处理该对象。处理完成后，Lambda 会将处理过的对象流式传输回调用客户端。请参阅 S3 Object Lambda [用户指南，了解更多信息](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"如何开始使用 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 可以通过多种方式进行设置。您可以通过导航到 Object Lambda Access Point（Object Lambda 访问点）选项卡，在 S3 控制台中设置 S3 Object Lambda。接下来，创建一个 S3 Object Lambda 访问点（您想要 S3 针对 GET、LIST 和 HEAD 请求执行的 Lambda 函数）和一个支持的 S3 访问点。向所有资源授予与 Object Lambda 交互的权限。最后，更新您的开发工具包和应用程序，以便通过新的 S3 Object Lambda 访问点使用您选择的语言开发工具包从 S3 检索数据。 在发出请求时，您可以使用 S3 对象 Lambda 访问点的别名。S3 对象 Lambda 访问点的别名将自动生成，而且对于通过 S3 对象 Lambda 访问的数据，这些别名可以与 S3 存储桶名称互换。对于现有的 S3 对象 Lambda 访问点，别名将自动分配并随时可供使用。[AWS 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-writing-lambda.html)中提供了 Lambda 函数实施的示例，可以帮助您开始使用。\n您还可以使用 AWS CloudFormation 来自动化您的 S3 Object Lambda 配置。使用 AWS CloudFormation 模板时，账户中部署的 Lambda 函数会将 S3 对象传回请求客户端或应用程序，而不进行任何更改。您可以添加自定义代码，以便在数据返回到应用程序时修改和处理数据。要了解更多信息，请访问《S3 Object Lambda [用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)》。"
    },
    {
        "query":"我可以使用 S3 Object Lambda 执行哪些类型的操作？",
        "intention":"知识问答",
        "reply":"可以使用 S3 Object Lambda 执行 Lambda 函数中支持的任何操作。这为您处理请求提供了各种可用选项。您可以使用自己的 Lambda 函数来针对 GET、LIST 和 HEAD 请求运行自定义计算，从而根据应用程序的需要灵活处理数据。Lambda 处理时间最多不得超过 60 秒。有关更多详细信息，请参阅 [S3 Object Lambda 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"S3 Object Lambda 支持哪些 S3 请求类型？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 支持 GET、LIST 和 HEAD 请求。对 S3 Object Lambda 访问点发出的任何其他 S3 API 调用都将返回标准 S3 API 响应。如需了解有关 S3 Object Lambda 的更多信息，请参阅[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"S3 Object Lambda 函数失败时会发生什么情况？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 函数失败时，您将收到请求响应，响应中会说明失败详情。与 Lambda 函数的其他调用一样，AWS 还可以代表您自动监控函数，通过 Amazon CloudWatch 报告指标。为了帮助您排查失败问题，Lambda 会记录函数处理的所有请求，并将由代码生成的日志自动存储在 Amazon CloudWatch Logs 中。有关访问 AWS Lambda 的 CloudWatch 日志的更多信息，请访问 [CloudWatch 文档](https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html)。"
    },
    {
        "query":"S3 Object Lambda 是否会影响 S3 可用性 SLA 或 S3 持久性？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 可以连接 Amazon S3、AWS Lambda，也可以连接您选择的其他 AWS 服务，以交付与请求应用程序相关的对象。与 S3 Object Lambda 结合使用的所有 AWS 服务将继续受其各自服务等级协议 (SLA) 的管控。例如，如有任何 AWS 服务不遵守其服务承诺，您将有资格获得该服务的 SLA 中记录的服务积分。创建 S3 Object Lambda 访问点不会影响对象的持久性。不过，S3 Object Lambda 会调用您指定的 AWS Lambda 函数，而且您必须确保指定的 Lambda 函数正确并适用。请[在此处查看最新的 Amazon S3 SLA](https://aws.amazon.com/s3/sla/)。"
    },
    {
        "query":"S3 Object Lambda 的成本是多少？",
        "intention":"知识问答",
        "reply":"使用 S3 Object Lambda 时，对于通过 S3 Object Lambda 返回的每 GB 数据，您需按 GB 支付费用。您还需要为基于请求类型（GET、LIST 和 HEAD 请求）的请求付费，并在您指定的函数运行以处理请求的数据时收取 AWS Lambda 计算费用。如需查看定价详细信息和示例，请参阅 [S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。\n[区域](https://aws.amazon.com/cn/s3/faqs#AWS_Regions) | [账单](https://aws.amazon.com/cn/s3/faqs#Billing) | [Amazon S3 和 IPv6](https://aws.amazon.com/cn/s3/faqs#Amazon_S3_and_IPv6) | [S3 事件通知](https://aws.amazon.com/cn/s3/faqs#S3_Event_Notifications) | [Amazon S3 Transfer Acceleration](https://aws.amazon.com/cn/s3/faqs#Amazon_S3_Transfer_Acceleration)"
    },
    {
        "query":"什么是 Amazon S3？",
        "intention":"知识问答",
        "reply":"Amazon S3 是专为从任意位置存储和检索任意数量的数据而构建的对象存储。S3 是一种简单的存储服务，以极低的成本提供行业领先的耐久性、可用性、性能、安全性和几乎无限的可扩展性。"
    },
    {
        "query":"Amazon S3 可以用来做什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 提供一个简单的 Web 服务界面，使用该界面，您可以随时在任何位置存储和检索任意数量的数据。使用此服务，您可以轻松构建使用原生云存储的应用程序。由于 Amazon S3 具有高度可扩展性，且您只需为实际用量付费，您可以从较小用量起步，并根据需要扩展应用程序，而不影响性能或可靠性。\nAmazon S3 的设计还具有很高的灵活性。存储您需要的任意类型和任意数量的数据；读取相同数据一百万次，或者仅在紧急灾难恢复时读取；构建简单的 FTP 应用程序或复杂的 Web 应用程序，例如 Amazon.com 零售网站。Amazon S3 让您能够腾出时间专注于创新，而不是花时间考虑如何存储数据。"
    },
    {
        "query":"如何开始使用 Amazon S3？",
        "intention":"知识问答",
        "reply":"要注册 Amazon S3，请访问 [S3 控制台](https://s3.console.aws.amazon.com/s3/home)。要访问此服务，您必须拥有 Amazon Web Services 账户。如果还没有账户，在您开始 Amazon S3 注册过程时，系统将会提示您创建账户。注册后，参考 [Amazon S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)，查看 [S3 入门资料](https://aws.amazon.com/cn/s3/getting-started/)，并在[资源中心](http://docs.aws.amazon.com/AmazonS3/latest/API/RelatedResources.html)查看其他资源以开始使用 Amazon S3。"
    },
    {
        "query":"我可以使用 Amazon S3 解决哪些本地解决方案无法解决的问题？",
        "intention":"知识问答",
        "reply":"Amazon S3 让您可以充分利用 Amazon 自身的规模优势，而无需前期投资，也不会影响性能。通过使用 Amazon S3，可以经济、简单地确保您的数据可快速访问、始终可用且安全。"
    },
    {
        "query":"在 Amazon S3 中可以存储什么类型的数据？￼",
        "intention":"知识问答",
        "reply":"您几乎可以存储任何格式、任何类型的数据。请参阅 [Amazon Web Services 许可协议](https://aws.amazon.com/cn/agreement/)，了解详细信息。"
    },
    {
        "query":"在 Amazon S3 中可以存储多少数据？￼",
        "intention":"知识问答",
        "reply":"您可以在 Amazon S3 中存储的总数据容量和对象个数不受限制。各个 Amazon S3 对象的大小范围可以从最小 0 字节到最大 5TB。可在单个 PUT 中上传的最大数据对象为 5GB。对于大于 100MB 的对象，客户应该考虑使用[分段上传](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html)功能。"
    },
    {
        "query":"我是否可以拥有在不同存储类具有不同对象的存储桶？",
        "intention":"知识问答",
        "reply":"是，您可以拥有在 S3 Standard、S3 Intelligent-Tiering、S3 Standard-IA、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类具有不同对象的 S3 存储桶。"
    },
    {
        "query":"Amazon 如何处理我在 Amazon S3 中的数据？",
        "intention":"知识问答",
        "reply":"Amazon 将存储您的数据，并跟踪其相关使用情况，用于账单用途。除非法律要求，Amazon 不会出于 Amazon S3 服务之外的任何目的访问您的数据。请参阅 [Amazon Web Services 许可协议](https://aws.amazon.com/cn/agreement/)，了解详细信息。"
    },
    {
        "query":"Amazon 是否会将自己的数据存储在 Amazon S3 中？",
        "intention":"知识问答",
        "reply":"是。Amazon 内部的公司也将 Amazon S3 用于众多项目。其中很多项目都使用 Amazon S3 作为授权数据存储，并依赖它执行关键业务型操作。"
    },
    {
        "query":"Amazon S3 数据是如何组织的？",
        "intention":"知识问答",
        "reply":"Amazon S3 是基于密钥的简单数据对象存储。存储数据时，您应分配唯一数据对象密钥，此后可使用该密钥来提取数据。密钥可以是任何字符串，并且可以被构建为模拟分层属性。或者，您也可以使用 S3 对象标记来组织所有 S3 存储桶中的数据和/或前缀。"
    },
    {
        "query":"如何与 Amazon S3 连接？",
        "intention":"知识问答",
        "reply":"Amazon S3 提供基于标准的简单 REST Web 服务接口，该接口可用于任何互联网开发工具箱。我们特意对这些操作进行了简化，以便轻松添加新的分发协议和功能层。"
    },
    {
        "query":"Amazon S3 的可靠性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 为您提供了一个快速、低成本、高度可扩展且高度可用的数据存储基础设施，Amazon 自己也使用该基础设施来运行其全球网站网络。S3 Standard 存储类的设计可实现 99.99% 的可用性，S3 Standard-IA 存储类、S3 Intelligent-Tiering 存储类和 S3 Glacier Instant Retrieval 存储类的设计可实现 99.9% 的可用性，S3 One Zone-IA 存储类的设计可实现 99.5% 的可用性，而 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 类的设计可实现 99.99% 的可用性和 99.9% 的 SLA。所有这些存储类均受 [Amazon S3 服务等级协议](https://aws.amazon.com/cn/s3/sla/)支持。"
    },
    {
        "query":"如果来自应用程序的流量突然激增，Amazon S3 将如何执行？",
        "intention":"知识问答",
        "reply":"Amazon S3 从一开始就专为处理来自任何互联网应用程序的高流量而设计。即用即付定价模式以及无限制的容量，可以确保您的递增费用不会变化，而且您的服务也不会中断。Amazon S3 的庞大规模使得我们能够均衡地分布负载，任何应用程序都不会受到流量峰值的影响。"
    },
    {
        "query":"Amazon S3 是否提供服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"是。如果客户的月度正常运行时间百分比在任何账单周期内低于我们的服务承诺，[Amazon S3 SLA](https://aws.amazon.com/cn/s3/sla/) 将提供服务积分。"
    },
    {
        "query":"什么是适用于 Amazon S3 的一致性模型？",
        "intention":"知识问答",
        "reply":"Amazon S3 自动提供强大的写入后读取一致性，无需更改性能或可用性，无需牺牲应用程序的区域隔离性，并且无需任何额外费用。\n成功写入新对象或覆盖现有对象后，任何后续读取请求都会立即收到该对象的最新版本。S3 还为列表操作提供强大的一致性，因此在写入之后，可以立即在存储桶中执行对象列表，并反映所有更改。"
    },
    {
        "query":"为什么强大的写入后读取一致性可以帮助到我？",
        "intention":"知识问答",
        "reply":"当您需要在写入后立即读取对象时，强大的写入后读取一致性可以提供帮助 – 例如，当您经常在写入对象后立即读取和列出这些对象时。高性能计算工作负载也会受益，因为对象被覆盖然后同时多次读取时，强大的写入后读取一致性可保证最新写入是跨全部读取的读取。这些应用程序自动且立即受益于强大的写入后读取一致性。S3 的强一致性还会降低成本，因为不再需要提供强一致性的额外基础设施。"
    },
    {
        "query":"我的数据存储在哪里？",
        "intention":"知识问答",
        "reply":"创建 Amazon S3 存储桶时，您可以指定一个 AWS 区域。对于 S3 Standard、S3 Standard-IA、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类，您的对象会自动存储在至少三个可用区（AZ）中的多个设备上。 可用区与任何其他可用区都间隔一定距离，不过彼此都在 100 公里（60 英里）以内。存储在 S3 One Zone-IA 存储类中的对象将以冗余方式存储在您选择的 AWS 区域的单个可用区中。对于 S3 on Outposts，您的数据将存储在 Outpost 本地环境中，除非您手动选择将该数据传输到 AWS 区域。请参阅 [AWS 区域性服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解 Amazon S3 服务在不同 AWS 区域的具体提供情况。"
    },
    {
        "query":"什么是 AWS 区域？",
        "intention":"知识问答",
        "reply":"[AWS 区域](https://aws.amazon.com/cn/about-aws/global-infrastructure/regions_az/)是世界各地的 AWS 集群数据中心的物理位置。  区域内的每组逻辑数据中心称为可用区（AZ）。每个 AWS 区域由一个地理区域内的至少三个隔离的且在物理上分隔的可用区组成。 与其他通常将区域定义为一个数据中心的云提供商不同的是，为每个 AWS 区域设计多个可用区可为客户提供优势。每个可用区都有独立的电力、冷却和物理安全性，并通过冗余的超低延迟网络连接。"
    },
    {
        "query":"什么是 AWS 可用区（AZ）？",
        "intention":"知识问答",
        "reply":"[可用区（AZ）](https://aws.amazon.com/cn/about-aws/global-infrastructure/regions_az/)是指 AWS 区域中一个或多个具有冗余电源、联网和连接的离散数据中心。可用区让客户能够运行在可用性、容错能力和可扩展性方面比单个数据中心更强的生产应用程序和数据库。一个 AWS 区域中的所有可用区都通过高带宽、低延迟网络与完全冗余的专用城域光纤互连，为可用区之间提供高吞吐量和低延迟的联网。\nAmazon S3 Standard、S3 Standard-Infrequent Access、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类在至少三个可用区中复制数据，以免整个可用区丢失。在公开提供的可用区不足 3 个的区域中，这种情况仍然存在。存储在这些存储类中的对象可从单个 AWS 区域的所有可用区进行访问。\nAmazon S3 单区 – IA 存储类在单个可用区内复制数据。存储在 S3 One Zone-IA 中的数据对由于地震、火灾和洪水等灾难导致的可用区的物理损失不具有弹性。"
    },
    {
        "query":"如何确定将数据存储在哪个 AWS 区域中？",
        "intention":"知识问答",
        "reply":"需要基于您的特定应用程序考虑多个因素。例如，您可能希望将数据存储在靠近客户、数据中心或其他 AWS 资源的区域中，以减少数据访问延迟。您也可能希望将数据存储在远离其他运营的区域中，以实现地理位置冗余和灾难恢复目的。您还应该考虑可让您满足特定法律和法规要求和/或降低存储成本的区域 – 您可以选择价格较低的区域以节省开支。有关 S3 定价的信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"Amazon S3 在全球哪些地区提供？",
        "intention":"知识问答",
        "reply":"Amazon S3 在全球所有 AWS 区域中提供，无论您身处何地，都可以使用 Amazon S3。您只需决定要将 Amazon S3 数据存储在哪个 AWS 区域中即可。请参阅 [AWS 区域服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，获取当前提供 S3 的 AWS 区域的列表。"
    },
    {
        "query":"如果我使用其他 AWS 账户访问 Amazon S3 存储桶，应该如何付费？",
        "intention":"知识问答",
        "reply":"当您使用其他 AWS 账户访问存储时，我们将按正常 Amazon S3 定价收费。或者，您也可以选择将存储桶配置为申请方付款存储桶，在这种情况下，将由申请方支付 Amazon S3 数据的相关申请和下载费用。\n有关申请方付款存储桶配置的更多信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html)。"
    },
    {
        "query":"什么是 IPv6？",
        "intention":"知识问答",
        "reply":"连接到 Internet 的每个服务器和设备都必须具有一个唯一地址。Internet 协议版本 4 (IPv4) 是原始的 32 位寻址方案。但是，Internet 的持续发展意味着所有可用的 IPv4 地址都将随着时间而被用尽。Internet 协议版本 6 (IPv6) 是寻址机制，设计用以克服 IPv4 的全球地址限制。"
    },
    {
        "query":"IPv6 可以用来做什么？",
        "intention":"知识问答",
        "reply":"使用适用于 Amazon S3 的 IPv6 支持，应用程序无需任何 IPv6 到 IPv4 转换软件或系统即可连接到 Amazon S3。您可以满足合规性要求，更轻松地与基于 IPv6 的现有本地应用程序集成，并且无需购买昂贵的联网设备来处理地址转换。您还可以借助 IPv6 地址利用 IAM 策略和存储桶策略中现有的源地址筛选功能，扩大您的选择范围以确保应用程序与 Amazon S3 安全交互。"
    },
    {
        "query":"如何在 Amazon S3 上开始使用 IPv6？",
        "intention":"知识问答",
        "reply":"首先，您可以将应用程序指向 [Amazon S3 的“双堆栈”端点](https://docs.aws.amazon.com/AmazonS3/latest/userguide/dual-stack-endpoints.html)，该端点同时支持通过 IPv4 和 IPv6 访问。在大多数情况下，无需进一步配置即可通过 IPv6 进行访问，因为大多数网络客户端倾向于默认使用 IPv6 地址。 因使用 IPv6 受到影响的应用程序可以随时切换回仅支持 IPv4 的标准端点。支持在所有商业 AWS 区域将 IPv6 用于 Amazon S3，包括 AWS GovCloud（美国）区域、由光环新网运行的 Amazon Web Services 中国（北京）区域、由宁夏西云数据运行的 Amazon Web Services 中国（宁夏）区域。"
    },
    {
        "query":"使用 IPv6 时，Amazon S3 的性能是否会出现变化？",
        "intention":"知识问答",
        "reply":"不会，不论是使用 IPv4 还是 IPv6，Amazon S3 的性能都相同。"
    },
    {
        "query":"什么是 Amazon S3 事件通知？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)功能在 S3 存储桶中发生某些事件时接收通知，例如 PUT、POST、COPY 和 DELETE 事件。您可以将通知发布到 [Amazon EventBridge](https://aws.amazon.com/cn/eventbridge/)、[Amazon SNS](https://aws.amazon.com/cn/sns/)、[Amazon SQS](https://aws.amazon.com/cn/sqs/)，或直接发布到 [AWS Lambda](https://aws.amazon.com/cn/lambda/)。"
    },
    {
        "query":"我可以用 Amazon S3 事件通知做什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 事件通知可让您运行工作流、发送提醒或执行其他操作来响应 S3 中存储对象的更改。您可以使用 S3 事件通知来设置触发器以执行各种操作，包括在上传媒体文件时对其执行转码、在数据文件可用时对其进行处理以及将 S3 对象与其他数据存储同步。您还可以根据对象名前缀和后缀来设置事件通知。例如，您可以选择接收以 “images/” 开头的对象名称的通知。"
    },
    {
        "query":"Amazon S3 事件通知中包含什么？",
        "intention":"知识问答",
        "reply":"有关 Amazon S3 事件通知消息中包含的信息的详细说明，请参阅[配置 Amazon S3 事件通知文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)。"
    },
    {
        "query":"如何设置 Amazon S3 事件通知？",
        "intention":"知识问答",
        "reply":"关于如何配置事件通知的详细描述，请参阅[配置 Amazon S3 事件通知文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)。您可以在 [Amazon SNS 文档](http://docs.aws.amazon.com/sns/latest/dg/welcome.html)和 [Amazon SQS 文档](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)中了解有关 AWS 消息收发服务的更多信息。"
    },
    {
        "query":"什么是 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"[Amazon S3 Transfer Acceleration](https://aws.amazon.com/cn/s3/transfer-acceleration/) 可在客户与您的 Amazon S3 存储桶之间创建快速、轻松、安全的远距离文件传输。S3 Transfer Acceleration 利用了 Amazon CloudFront 遍布全球的 [AWS 边缘站点](https://aws.amazon.com/cn/hybrid/)。数据到达某个 AWS 边缘站点时，即被通过优化的网络路径路由至您的 Amazon S3 存储桶。"
    },
    {
        "query":"如何开始使用 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"要开始使用 S3 Transfer Acceleration，请使用 [Amazon S3 控制台](https://s3.console.aws.amazon.com/s3/home)、Amazon S3 API 或 AWS CLI 在 S3 存储桶上[启用 S3 Transfer Acceleration](http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-getting-started)。启用 S3 Transfer Acceleration 后，您可以将 Amazon S3 PUT 和 GET 请求指向 s3-accelerate 端点的域名。您的数据传输应用程序必须使用以下两种终端节点类型中的一种，以访问用于更快的数据传输的存储桶：“双堆栈”终端节点的 .s3-accelerate.amazonaws.com 或 .s3-accelerate.dualstack.amazonaws.com。如果您想要使用标准数据传输，可以继续使用常规终端节点。\n对于支持 S3 Transfer Acceleration 的存储桶有一定限制。有关详细信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html#transfer-acceleration-requirements)。"
    },
    {
        "query":"S3 Transfer Acceleration 有多快？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 可帮助您充分利用带宽，最大限度地降低距离对吞吐量的影响。无论客户位于何方，S3 Transfer Acceleration 都能确保数据快速、稳定地传输到 Amazon S3。加速的幅度主要取决于您的可用带宽、源和目标之间的距离以及网络路径上的数据包丢失率。通常，源和目标之间的距离越远、可用带宽越多和/或对象大小越大，加速的幅度越大。\n一位客户的测量结果是：从分布在美国、欧洲和部分亚洲地区的全球用户群向亚太地区（悉尼）的存储桶摄入 300MB 的文件，平均传输时间可以缩短 50%。而另一位客户观察到，从东南亚和澳大利亚的用户向美国东部（弗吉尼亚州北部）的 S3 存储桶上传 250MB 文件（分成 50MB 大小的几个部分）时，性能提升超过 500%。\n访问 [S3 Transfer Acceleration 速度比较工具](http://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html)，预览您所在位置能获得的性能提升！"
    },
    {
        "query":"谁应该使用 S3 Transfer Acceleration？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 旨在优化从世界各地向 S3 存储桶传输数据的速度。如果您从多个分散的地点向一个集中的存储桶上传数据，或者如果您经常需要跨各大洲传输 GB 或 TB 级的数据，使用 S3 Transfer Acceleration 节约的数据传输时间可以达到数小时或者数天。"
    },
    {
        "query":"S3 Transfer Acceleration 的安全性如何？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 的安全性与 Amazon S3 的常规传输相同。同样支持所有 Amazon S3 安全功能，例如基于客户端的 IP 地址来限制访问。S3 Transfer Acceleration 与客户端通过标准 TCP 通信，无需更改防火墙。[AWS 边缘站点](https://aws.amazon.com/cn/hybrid/)不会存储任何数据。"
    },
    {
        "query":"如果 S3 Transfer Acceleration 的传输速度不及常规 Amazon S3，怎么办？",
        "intention":"知识问答",
        "reply":"每当您使用 S3 Transfer Acceleration 上传对象时，我们都会检查 S3 Transfer Acceleration 的传输速度是否有可能比常规 Amazon S3 传输更快。在将同一对象传输到同一目标 AWS 区域时，如果我们确定 S3 Transfer Acceleration 的传输速度不会快于常规 Amazon S3，那么对于此次使用 S3 Transfer Acceleration 进行的传输，我们将不会收取任何费用，并且可能会绕过该次上传的 S3 Transfer Acceleration 系统。"
    },
    {
        "query":"我可以对分段上传使用 S3 Transfer Acceleration 吗？",
        "intention":"知识问答",
        "reply":"可以，S3 Transfer Acceleration 支持所有存储桶级别的功能，包括分段上传。"
    },
    {
        "query":"在 S3 Transfer Acceleration 和 Amazon CloudFront 的 PUT/POST 之间，我应该如何选择？",
        "intention":"知识问答",
        "reply":"S3 Transfer Acceleration 优化了 TCP 协议，并在客户端与 S3 存储桶之间添加了更多智能，因此如果需要更高的吞吐量，S3 Transfer Acceleration 就是更好的选择。如果您的对象小于 1GB，或者如果数据集小于 1GB，则应该考虑使用 Amazon CloudFront 的 PUT/POST 命令来优化性能。"
    },
    {
        "query":"在 S3 Transfer Acceleration 和 AWS Snow Family（Snowball、Snowball Edge 和 Snowmobile）之间，我应该如何选择？",
        "intention":"知识问答",
        "reply":"要一次性移动大批量数据，[AWS Snow Family](https://aws.amazon.com/cn/snow/) 就是客户的理想选择。AWS Snowball 的周转时间通常为 5-7 天。一般来说，通过一条充分利用的 1Gbps 线路，S3 Transfer Acceleration 在同样的时间期限内最多可以传输 75TB 数据。总之，如果通过 Internet 传输所需的时间超过一个星期，或者如果需要反复传输任务且可用带宽超过 25Mbps，S3 Transfer Acceleration 就是不错的选择。另一个选择是同时使用两者：利用一个 AWS Snowball（或一系列 AWS Snowball）执行最初繁重的传输任务，然后利用 S3 Transfer Acceleration 传输递增的日常变更。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为 AWS Direct Connect 的补充吗？",
        "intention":"知识问答",
        "reply":"如果客户拥有专用联网要求或者能访问 AWS Direct Connect 交换点，[AWS Direct Connect](https://aws.amazon.com/cn/directconnect/) 就是不错的选择。S3 Transfer Acceleration 最适合从分散的客户位置通过公共 Internet 提交数据，或者是由于网络条件不断变化而造成吞吐量较低的情况。有些 AWS Direct Connect 客户使用 S3 Transfer Acceleration 帮助远程办公室传输数据，因为远程办公室的 Internet 性能可能会比较差。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为 AWS Storage Gateway 或第三方网关的补充吗？",
        "intention":"知识问答",
        "reply":"您可以受益于在第三方网关中配置存储桶目标以使用 S3 Transfer Acceleration 端点域。\n请访问 [Storage Gateway 常见问题的“文件”部分](https://aws.amazon.com/cn/storagegateway/faqs/#file)，详细了解 AWS 实施。"
    },
    {
        "query":"可以使用 S3 Transfer Acceleration 作为第三方集成软件的补充吗？",
        "intention":"知识问答",
        "reply":"是。直接连接到 Amazon S3 的软件包在将任务发送到 Amazon S3 时可以利用 S3 Transfer Acceleration。\n[了解有关存储合作伙伴解决方案的更多信息 »](https://aws.amazon.com/cn/backup-recovery/partner-solutions/)"
    },
    {
        "query":"S3 Transfer Acceleration 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"符合，AWS 已对其 [HIPAA 合规性计划](https://aws.amazon.com/cn/compliance/hipaa-compliance/)进行扩展，其中已将 S3 Transfer Acceleration 作为一项符合 HIPAA 要求的服务包括进来。如果您已与 AWS 签订商业合伙协议（BAA），则可以使用 S3 Transfer Acceleration 在您的客户端和 Amazon S3 存储桶之间快速、轻松且安全地远距离传输文件，包括受保护健康信息（PHI）。\n[S3 访问点](https://aws.amazon.com/cn/s3/faqs#S3_Access_Points)"
    },
    {
        "query":"数据在 Amazon S3 中的安全性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 本身是非常安全的。 在创建时，只有您可以访问自己所创建的 Amazon S3 存储桶，而且您可以完全控制哪些人员拥有您的数据的访问权限。Amazon S3 支持用户身份验证，以控制对数据的访问。您可以使用各种访问控制机制，例如存储桶策略，选择性地向用户和用户组授予权限。Amazon S3 控制台会突出显示您可公开访问的存储桶，注明公开可访问性的来源，并且还会在您的存储桶策略或存储桶 ACL 发生的更改从而将使您的存储桶可公开访问时，向您发出警告。 您应该为不希望公开访问的所有账户和存储桶启用 [Amazon S3 屏蔽公共访问权限](https://aws.amazon.com/cn/s3/features/block-public-access/)。 默认情况下，所有新存储桶都开启了“屏蔽公共访问权限”。\n您可以使用 HTTPS 协议，通过 SSL 端点安全地向 Amazon S3 上传或从中下载数据。[Amazon S3 会自动加密上传到您的存储桶的所有对象（截至 2023 年 1 月 5 日）](https://aws.amazon.com/blogs/aws/amazon-s3-encrypts-new-objects-by-default/)。或者，您可以使用自己的加密库，在将数据存储到 Amazon S3 之前对数据进行加密。\n有关 AWS 上的安全性的更多信息，请参阅 [AWS 安全性页面](https://aws.amazon.com/cn/security/)，要了解 S3 安全性信息，请访问 [S3 安全性页面](https://aws.amazon.com/cn/s3/security/)和 [S3 安全性最佳实践指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/security-best-practices.html)。"
    },
    {
        "query":"如何控制对存储在 Amazon S3 中的数据的访问？",
        "intention":"知识问答",
        "reply":"客户可以使用一系列机制来控制对 Amazon S3 资源的访问，包括 AWS Identity and Access Management (IAM) 策略、存储桶策略、访问点策略、访问控制列表（ACL）、查询字符串身份验证、Amazon Virtual Private Cloud (Amazon VPC) 端点策略、AWS Organizations 中的服务控制策略（SCP）和 Amazon S3 阻止公有访问。\nIAM  \n IAM 让拥有多名员工的企业能够使用一个 AWS 账户创建和管理多个用户。使用 IAM 策略，公司可向 IAM 用户授予对 Amazon S3 存储桶或对象的精细控制权，同时保留对用户执行的所有操作的完全控制。\n存储桶和访问点策略  \n 使用存储桶策略和访问点策略，客户可以定义广泛适用于其 Amazon S3 资源的所有请求的规则，例如为 Amazon S3 资源的子集授予写入权限。客户还可以基于请求的某种特征（例如 HTTP 引用站点和 IP 地址）来限制访问。\nACL  \n Amazon S3 支持 S3 的原始访问控制方法，也就是访问控制列表（ACL）。通过 ACL，客户可为特定用户授予对单个存储桶或数据对象的特定权限（例如读取、写入、完全控制）。针对倾向于完全使用访问控制策略的客户，Amazon S3 提供 [S3 对象所有权](https://docs.aws.amazon.com/AmazonS3/latest/userguide/about-object-ownership.html)功能以禁用 ACL。 在迁移到基于 IAM 的存储桶策略时，您可以在启用 S3 对象所有权之前使用 S3 清单来查看存储桶中的 ACL 使用情况。\n查询字符串身份验证  \n 借助查询字符串身份验证，客户可以为 Amazon S3 对象创建一个仅在有限时间内有效的 URL。有关 Amazon S3 中可用的各种访问控制策略的更多信息，请参阅 [访问控制文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-access-control.html)。\nAmazon VPC  \n 当客户创建 Amazon VPC 终端节点时，他们可以为其附加终端节点策略，以控制对与其连接的 Amazon S3 资源的访问权限。客户还可以[使用 Amazon S3 存储桶策略来控制从哪些特定的端点或特定的 VPC 访问存储桶](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-access.html)。\n服务控制策略  \n [服务控制策略 (SCP)](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scps.html) 是 AWS Organizations 策略的一种类型，客户可以在其企业中用它来管理权限。SCP 提供对企业中所有账户最大可用权限的集中控制。借助 SCP，客户可以确保其账户始终符合企业的访问控制指导原则。\nS3 阻止公有访问  \n [Amazon S3 屏蔽公共访问权限](https://aws.amazon.com/cn/s3/features/block-public-access/)提供访问点、存储桶和账户设置，以帮助客户管理对 Amazon S3 资源的公有访问。使用 S3 屏蔽公共访问权限，账户管理员和存储桶拥有者可以轻松设置集中式控制，以限制对其 Amazon S3 资源的公共访问，无论这些资源采用何种创建方式。 作为安全最佳实践，所有新的存储桶均默认启用“屏蔽公共访问权限”。\n参阅 [AWS IAM 文档](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html#policies_resource-based)以了解关于策略和权限的更多信息。"
    },
    {
        "query":"Amazon S3 是否支持数据访问审计？",
        "intention":"知识问答",
        "reply":"支持。客户可以选择配置 Amazon S3 存储桶，为所有针对该存储桶的请求创建访问日志记录。或者，需要在日志中捕获 IAM/用户身份信息的客户也可以配置 [AWS CloudTrail 数据事件](https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-management-and-data-events-with-cloudtrail.html)。\n这些访问日志记录可用于审计用途，其中包含有关请求的详细信息，例如请求类型、请求中指定的资源、处理请求的时间和日期。"
    },
    {
        "query":"对存储在 Amazon S3 中的数据进行加密时，可以使用哪些选项？",
        "intention":"知识问答",
        "reply":"Amazon S3 会加密上传到任何存储桶的所有新数据。[Amazon S3 将 S3 托管的服务器端加密（SSE-S3）应用为所有对象上传的基本加密级别（截至 2023 年 1 月 5 日）](https://aws.amazon.com/blogs/aws/amazon-s3-encrypts-new-objects-by-default/)。SSE-S3 提供了一种完全托管的解决方案，Amazon 通过其使用多个安全层处理密钥管理和密钥保护问题。如果您希望 Amazon 管理您的密钥，则应继续使用 SSE-S3。此外，您也可以选择使用 SSE-C、SSE-KMS、DSSE-KMS 或客户端库（例如 [Amazon S3 加密客户端](http://docs.amazonwebservices.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/s3/AmazonS3EncryptionClient.html)）对数据进行加密。 每个选项都可以将敏感的数据以静态方式存储在 Amazon S3 中。\nSSE-C 允许 Amazon S3 执行对象的加密和解密，同时让您保留对加密密钥的控制。借助 SSE-C，您无需实施或使用客户端库来对 Amazon S3 中储存的对象执行加密和解密，但是需要对您发送到 Amazon S3 中执行对象加密和解密操作的密钥进行管理。如果您希望保留自己的加密密钥而不想实施或使用客户端加密库时，请使用 SSE-C。\nSSE-KMS 允许 [AWS Key Management Service](https://aws.amazon.com/cn/kms/) (AWS KMS) 管理您的加密密钥。使用 AWS KMS 管理您的密钥有几项额外的益处。利用 AWS KMS，会设置几个单独的 KMS 密钥使用权限，从而提供额外的控制层并防止 Amazon S3 中存储的对象遭到未授权访问。AWS KMS 提供审计跟踪记录，因此您能看到谁使用了您的密钥在何时访问了哪些对象，还能查看用户在没有解密数据的权限下所作的访问数据失败尝试次数。同时，AWS KMS 还提供额外的安全控制，从而支持客户努力符合 PCI-DSS、HIPAA/HITECH 和 FedRAMP 行业要求。\nDSSE-KMS 简化了对数据应用两层加密的过程，无需投资客户端加密所需的基础设施。每层加密都采用 256 位高级加密标准的不同实施结合 Galois Counter Mode（AES-GCM）算法，并且经过审查，可用于绝密工作负载。DSSE-KMS 使用 AWS KMS 生成数据密钥，并通过 AWS KMS 管理您的加密密钥。利用 AWS KMS，会设置几个单独的 KMS 密钥使用权限，从而提供额外的控制层并防止 Amazon S3 中存储的对象遭到未授权访问。AWS KMS 提供审计跟踪记录，因此您能看到谁使用了您的密钥在何时访问了哪些对象，还能查看用户在没有解密数据的权限下所作的访问数据失败尝试次数。同时，AWS KMS 还提供额外的安全控制，从而支持客户努力符合 PCI-DSS、HIPAA/HITECH 和 FedRAMP 行业要求。\n使用加密客户端库时，您保有对密钥的控制权并使用您选择的加密库对对象客户端进行加密和解密。一些客户倾向于对加密和解密对象拥有端到端的控制权；这样一来，只有经过加密的对象才会通过互联网传输到 Amazon S3。如果您想掌握对加密密钥的控制权，应该使用客户端库，这样便可实施或使用客户端加密库，同时在将对象传输到 Amazon S3 进行储存之前需要对其进行加密。\n有关使用 Amazon S3 SSE-S3、SSE-C 或 SSE-KMS 的更多信息，请参阅[使用加密文档保护数据](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingEncryption.html)。"
    },
    {
        "query":"使用 Amazon S3 时，能否遵守欧盟数据隐私法规？",
        "intention":"知识问答",
        "reply":"客户可以选择使用欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、欧洲地区（米兰）、欧洲（西班牙）、欧洲地区（伦敦）或欧洲（苏黎世）地区将所有数据存储在欧洲。您还可以使用 [Amazon S3 on Outposts](https://aws.amazon.com/cn/s3/outposts/) 将所有数据本地保留在 AWS Outpost，并且可以选择在 AWS Outposts 之间传输数据或将数据传输到 AWS 区域。您有责任确保自己遵守欧盟隐私法律。查看 [AWS 通用数据保护条例（GDPR）中心](https://aws.amazon.com/cn/compliance/gdpr-center/)和 [AWS 数据隐私中心](https://aws.amazon.com/cn/compliance/data-privacy/)，了解更多信息。 如果有更具体的位置要求或者其他数据隐私法规要求您将数据保存在没有 AWS 区域的位置，您可以使用 S3 on Outposts。"
    },
    {
        "query":"什么是 Amazon S3 的 Amazon VPC 端点？",
        "intention":"知识问答",
        "reply":"Amazon S3 的 Amazon VPC 端点是 VPC 内的逻辑实体，允许通过 [AWS 全局网络](https://aws.amazon.com/cn/about-aws/global-infrastructure/global_network/)连接到 S3。S3 有两种类型的 VPC 端点 – 网关 VPC 端点和接口 VPC 端点。网关端点是您在路由表中指定的网关，用于通过 AWS 网络从 VPC 访问 S3。接口端点通过私有 IP 将请求从您的 VPC 内部、本地或其他 AWS 区域路由到 S3，从而扩展网关端点的功能。有关更多信息，请访问[适用于 Amazon S3 的 AWS PrivateLink 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"能否允许从特定 Amazon VPC 端点访问我的 Amazon S3 存储桶？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 存储桶策略，限制从特定 Amazon VPC 终端节点或一系列终端节点访问您的存储桶。S3 存储桶策略现在支持 aws:sourceVpce 条件，您可以利用此条件来限制访问。有关更多详细信息和示例策略，请参阅 [S3 文档的网关端点](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html)。"
    },
    {
        "query":"什么是适用于 Amazon S3 的 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"适用于 S3 的 AWS PrivateLink 在 Amazon S3 与本地之间提供私有连接。您可以在 VPC 中为 S3 预置接口 VPC 端点，以通过 AWS Direct Connect 或 AWS VPN 将本地应用程序直接连接到 S3。您不再需要使用公有 IP、更改防火墙规则，或配置互联网网关以从本地访问 S3。访问[适用于 S3 的 AWS PrivateLink 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)，了解更多信息。"
    },
    {
        "query":"如何开始使用适用于 S3 的接口 VPC 端点？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS VPC 管理控制台、AWS 命令行界面（AWS CLI）、AWS SDK 或 API 创建接口 VPC 端点。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"我应何时选择网关 VPC 端点，而不是基于 AWS PrivateLink 的接口 VPC 端点？",
        "intention":"知识问答",
        "reply":"AWS 建议您使用接口 VPC 端点从本地或另一个 AWS 区域中的 VPC 访问 S3。对于要从与 S3 相同的 AWS 区域中的 VPC 访问 S3 的资源，我们建议使用网关 VPC 端点，因为这不会收取费用。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"我可以在同一个 VPC 中同时使用适用于 S3 的接口终端节点和网关终端节点吗？",
        "intention":"知识问答",
        "reply":"可以。如果您已经有网关 VPC 端点，请在 VPC 中创建接口 VPC 端点，并以 VPC 端点特定的端点名称更新客户端应用程序。例如，如果您接口端点的 VPC 端点 ID 在 us-east-1 区域中为 vpce-0fe5b17a0707d6abc-29p5708s，则特定于端点的 DNS 名称将为 vpce-0fe5b17a0707d6abc-29p5708s.s3.us-east-1.vpce.amazonaws.com。在这种情况下，仅针对 VPC 端点特定名称的请求将通过接口 VPC 端点路由到 S3，而所有其他请求将继续通过网关 VPC 端点路由。要了解更多信息，请访问[文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)。"
    },
    {
        "query":"什么是 Amazon Macie，我如何使用它保护数据的安全？",
        "intention":"知识问答",
        "reply":"[Amazon Macie](https://aws.amazon.com/cn/macie/) 是一种支持 AI 技术的安全服务，可以帮助您通过自动发现、分类和保护存储在 Amazon S3 中的敏感数据来防止数据丢失。Amazon Macie 使用机器学习来识别敏感数据（例如，个人身份信息（PII）或知识产权），分配业务价值，提供此数据的存储位置信息及其在组织中的使用方式信息。Amazon Macie 可持续监控数据访问活动异常，并在检测到未经授权的访问或意外数据泄漏风险时发出警报。\n您可以使用 Amazon Macie 通过持续监控数据和账户凭证来防范安全威胁。Amazon Macie 为您提供一种自动化和低接触的方式来发现和分类业务数据。它通过模板化的 Lambda 函数进行控制，可在发现可疑行为或对实体或第三方应用程序进行未经授权的数据访问时撤销访问或触发密码重置策略。发出警报时，您可以使用 Amazon Macie 进行事件响应，并使用 Amazon CloudWatch Events 迅速采取行动，保护您的数据。有关更多信息，请访问 [Amazon Macie 文档](https://docs.aws.amazon.com/macie/latest/user/what-is-macie.html)。"
    },
    {
        "query":"什么是 IAM Access Analyzer for Amazon S3，它的工作原理是什么？",
        "intention":"知识问答",
        "reply":"[Access Analyzer for S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-analyzer.html) 功能可帮助您在为 S3 存储桶和访问点设置、验证和优化策略时简化权限管理。 Access Analyzer for S3 可监控您的现有访问策略，以验证它们是否仅提供对 S3 资源的必要访问权限。Access Analyzer for S3 会评估您的存储桶访问策略，并帮助您发现并快速更改不需要访问的存储桶。\n当您有一个存储桶配置为允许访问互联网上的任何人访问或与其他 AWS 账户共享时，Access Analyzer for S3 会向您发出警报。您可以获得有关公有或共享访问的来源和级别的*结果*。例如，如果通过访问控制列表或存储桶策略提供不必要的读取或写入访问权限，则 Access Analyzer for S3 会主动通知您。通过这些结果，您可以立即设置或还原所需的访问策略。\n在查看显示对存储桶的潜在共享访问权限的结果时，只需单击 S3 控制台，即可[阻止对存储桶的公共访问](https://docs.aws.amazon.com/AmazonS3/latest/dev/access-control-block-public-access.html)。您还可以向下钻取到存储桶级别权限设置，以配置精细访问。 出于审核目的，您可将 Access Analyzer for S3 的结果下载为 CSV 报告。\n此外，S3 控制台可以在您编写 S3 策略时报告 IAM Access Analyzer 中的安全警告、错误和建议。该控制台将会自动运行 100 多项策略检查，以验证您的策略。这些检查可以为您节约时间，指导您解决错误，并帮助您应用安全最佳实践。\n有关更多信息，请访问 [IAM Access Analyzer 文档](https://docs.aws.amazon.com/IAM/latest/UserGuide/what-is-access-analyzer.html)。"
    },
    {
        "query":"什么是 Amazon S3 接入点？",
        "intention":"知识问答",
        "reply":"现在，客户会使用单个存储桶策略管理对其 S3 存储桶的访问，该策略控制着不同权限级别的数百种应用程序。\nAmazon S3 访问点简化了大规模管理使用 S3 上共享数据集的应用程序的数据访问的过程。利用 S3 访问点，您现在可以在每个存储桶中轻松创建数百个访问点，这代表着预置共享数据集的一种新方法。访问点提供进入存储桶的自定义路径，具有唯一的主机名和访问策略，可对通过相应访问点发出的请求执行特定的权限和网络控制。S3 访问点可以与同一账户或另一个受信任账户中的存储桶相关联。通过访问 [S3 访问点页面](https://aws.amazon.com/cn/s3/features/access-points/)和[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points.html)了解更多信息。"
    },
    {
        "query":"为什么应该使用访问点？",
        "intention":"知识问答",
        "reply":"S3 访问点简化了对 S3 上共享数据集的数据访问的管理过程。您不再需要使用数以百计的需要编写、读取、跟踪和审计的不同权限规则来管理单个复杂的存储桶策略。借助 S3 访问点，您可以创建访问点或将权限委托给受信任的账户，以在您的存储桶上创建跨账户访问点。这允许使用针对特定应用程序定制的策略访问共享数据集。\n使用访问点，您可以针对需要访问共享数据集的每个应用程序，将一个大型存储桶策略分解为多个单独的离散访问点策略。这样可以更轻松地集中精力为应用程序制定正确的访问策略，而不必担心打断共享数据集中任何其他应用程序正在执行的操作。您还可以创建服务控制策略 (SCP)，并要求将所有访问点都限制在 Virtual Private Cloud (VPC) 中，从而通过防火墙将数据隔离在专用网络中。"
    },
    {
        "query":"S3 访问点的工作原理是什么？",
        "intention":"知识问答",
        "reply":"每个 S3 访问点都配置有特定于用例或应用程序的访问策略，一个存储桶可以有数千个访问点。例如，您可以为 S3 存储桶创建一个访问点，为数据湖的用户或应用程序组授予访问权限。访问点可以支持单个用户或应用程序，也可以支持账户内部或跨账户的一组用户或应用程序，因此可以对每个访问点进行单独管理。\n此外，您可以将权限委托给受信任的账户，以在您的存储桶上创建跨账户访问点。在您获得存储桶拥有者的许可之前，跨账户访问点不会授予对数据的访问权限。  存储桶拥有者始终保留对数据的最终控制权，并且必须更新存储桶策略以授权来自跨账户访问点的请求。请访问[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-policies.html)以获取示例存储桶策略。\n每个访问点都与一个存储桶相关联，并包含一个网络源站控件和一个阻止公共访问控件。您可以创建带有网络源站控件的访问点，该控件仅允许从您的 Virtual Private Cloud（AWS 云的逻辑隔离部分）进行存储访问。您还可以创建一个访问点，将访问点策略配置为仅允许访问具有指定前缀的对象或具有特定标签的对象。\n您可以使用两种方式之一通过访问点访问共享存储桶中的数据。对于 S3 对象操作，您可以使用访问点 [ARN](https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html) 代替存储桶名称。对于要求存储桶名称使用标准 S3 存储桶名称格式的请求，您可以使用访问点别名。S3 访问点的别名是自动生成的，并且可以在您使用存储桶名称进行数据访问的任何位置与 S3 存储桶名称互换。每次为存储桶创建访问点时，S3 都会自动生成一个新的访问点别名。对于全套可兼容操作和 AWS 服务，请访问 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-usage-examples.html)。"
    },
    {
        "query":"是否有访问点数量创建限额？",
        "intention":"知识问答",
        "reply":"默认情况下，您可以在账户和跨账户的存储桶上为每个账户的每个区域创建 10000 个访问点。与 S3 存储桶不同的是，对于每个 AWS 账户的访问点数量没有硬性限制。请访问 [AWS 服务限额](https://docs.aws.amazon.com/servicequotas/latest/userguide/intro.html)以申请提高此限额。"
    },
    {
        "query":"在使用访问点时，如何对请求进行授权？",
        "intention":"知识问答",
        "reply":"S3 访问点有其自己的 IAM 访问点策略。您可以使用访问点 ARN 作为资源，像编写存储桶策略一样编写访问点策略。访问点策略可以授权或限制访问通过访问点请求的 S3 数据。Amazon S3 会评估所有相关策略，包括关于用户、存储桶、访问点和 VPC 终端节点的策略，以及服务控制策略和访问控制列表，以决定是否要授权请求。"
    },
    {
        "query":"如何编写访问点策略？",
        "intention":"知识问答",
        "reply":"您可以使用策略文档中管理权限和访问点 ARN 的 IAM 规则编写访问点策略，就像编写存储桶策略一样。"
    },
    {
        "query":"在访问点上限制使用网络源站控件的特定 VPC 访问权限与限制使用存储桶策略的 VPC 访问权限有什么区别？",
        "intention":"知识问答",
        "reply":"您可以继续使用存储桶策略来限制对指定 VPC 的存储桶访问权限。访问点提供更简单可审核的方式，以便通过 API 控件将共享数据集中的全部数据或数据子集锁定到所在组织全部应用程序的仅限 VPC 流量。您可以使用 AWS Organizations 服务控制策略 (SCP) 强制将在您的组织中创建的任何访问点的“网络源站控件”API 参数值设置为 “vpc”。然后，任何创建的新访问点会自动将数据访问限制为仅限 VPC 流量。您无需其他访问策略来确保仅处理来自指定 VPC 的数据请求。"
    },
    {
        "query":"我可以在所在组织内为所有访问点实施“无 Internet 数据访问”策略吗？",
        "intention":"知识问答",
        "reply":"是。要为组织内的所有访问点实施“无 Internet 数据访问”策略，您要确保所有访问点都仅支持 VPC 访问。要做到这一点，您将需要编写 AWS SCP，而且该 SCP 仅支持 create\\_access\\_point() API 中的“网络源站控件”参数的值为“vpc”。如果您在之前创建过任何面向 Internet 的访问点，它们可以被移除。您还需要在每个存储桶中修改存储桶策略，以便进一步限制 Internet 通过存储桶主机名直接访问您的存储桶。由于其他 AWS 服务可能直接访问您的存储桶，因此确保将访问权限设置为允许您想要的 AWS 服务，您可以通过修改策略，允许这些 AWS 服务进行访问。参阅 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-vpc.html)以查看操作示例。"
    },
    {
        "query":"我可以完全禁用使用存储桶主机名直接访问存储桶吗？",
        "intention":"知识问答",
        "reply":"目前不可以，但您可以附加存储桶策略以拒绝并非通过访问点发出的请求。参阅 [S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points-policies.html)以了解更多详细信息。"
    },
    {
        "query":"我可以替换或移除存储桶上的访问点吗？",
        "intention":"知识问答",
        "reply":"是。如果您移除某个访问点，任何通过其他访问点和存储桶主机名对关联存储桶的访问都会被中断。"
    },
    {
        "query":"Amazon S3 访问点的成本为多少？",
        "intention":"知识问答",
        "reply":"访问点和使用访问点的存储桶不会产生额外成本。一般的 Amazon S3 请求费率同样适用。"
    },
    {
        "query":"如何开始使用 S3 访问点？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 管理控制台、AWS 命令行界面（CLI）、应用程序编程接口（API）和 AWS 软件开发工具包（SDK）客户端，在新存储桶以及现有存储桶上创建 S3 访问点。要了解与 S3 访问点相关的更多信息，请访问[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-points.html)。"
    },
    {
        "query":"Amazon S3 的持久性如何？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard、S3 Standard–IA、S3 Intelligent-Tiering、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 的设计均可在给定年份提供 99.999999999%（11 个 9）的对象数据持久性。这种持久性水平对应的平均每年对象损失率预计为 0.000000001%。例如，如果您使用 Amazon S3 存储 10000000 个对象，则预期平均每 10000 年发生一次对象丢失。S3 on Outposts 旨在持久冗余地在 Outpost 上的多个设备和服务器中存储数据。此外，Amazon S3 Standard、S3 Standard-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 的设计还可在整个 S3 可用区丢失的情况下保留数据。\n对于任何环境，最佳实践都是做好备份，并做好防范恶意或意外删除的保护措施。对于 S3 数据，最佳实践包括安全访问权限、跨区域复制、版本控制和定期测试的有效备份。"
    },
    {
        "query":"Amazon S3 的设计如何达到 99.999999999% 的持久性？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard、S3 Standard-IA、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类会将您的对象以冗余方式存储在一个 Amazon S3 区域内至少三个可用区 (AZ) 中的多个设备上，然后才会返回 SUCCESS。而 S3 One Zone-IA 存储类会以冗余方式将数据存储在单个可用区中的多个设备上。这些服务旨在通过快速检测和修复任何丢失的冗余，来抵御同时发生的设备故障，并且它们还可使用校验和来定期验证数据的完整性。"
    },
    {
        "query":"Amazon S3 在数据完整性检查中支持哪些校验和？",
        "intention":"知识问答",
        "reply":"Amazon S3 结合使用 Content-MD5 校验和、安全哈希算法 (SHA) 和循环冗余检验 (CRC) 来验证数据完整性。Amazon S3 在空闲时对数据执行这些校验和检测，并使用冗余数据修复任何不一致。此外，S3 还会在存储或检索数据时对所有网络流量计算校验和，以检测数据包是否改动。您可以从四种受支持的校验和算法中进行选择，以便对您的上传和下载请求进行数据完整性检查。您可以选择 SHA-1、SHA-256、CRC32 或 CRC32C 校验和算法，具体取决于您的应用程序需求。您可以在存储或检索 S3 中的数据时自动计算和验证校验和，并且可以随时使用 GetObjectAttributes S3 API 或 S3 清单报告访问校验和信息。在您将数据流式传输到 S3 时计算校验和可以为您节省时间，因为您可以在一次操作中同时验证和传输数据，而无需执行两个连续的操作。在数据验证中使用校验和是检查数据持久性的最佳实践，这些功能提高了性能并降低了相应操作的成本。"
    },
    {
        "query":"什么是版本控制？",
        "intention":"知识问答",
        "reply":"通过版本控制，您可以保留、提取和恢复存储在 Amazon S3 存储桶中的每个数据对象的每个版本。一旦您为存储桶启用版本控制，Amazon S3 将在您每次执行 PUT、POST、COPY 或 DELETE 操作时保留现有数据对象。默认情况下，GET 请求将提取最近写入的版本。可通过在请求中指定版本，提取已覆盖数据对象或已删除数据对象的旧版本。"
    },
    {
        "query":"为什么应该使用版本控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 为客户提供具有高持久性的存储基础设施。版本控制可在客户意外覆盖或删除数据对象的情况下提供一种恢复手段，从而提供另一层保护。这使您能够从无意用户操作或应用程序故障中轻松恢复。您还可将版本控制用于数据保留和存档。"
    },
    {
        "query":"如何开始使用版本控制？",
        "intention":"知识问答",
        "reply":"您可以通过在 Amazon S3 存储桶上启用相应设置，来开始使用版本控制。有关如何启用版本控制的更多信息，请参阅 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html)。"
    },
    {
        "query":"版本控制如何防止对象被意外删除？",
        "intention":"知识问答",
        "reply":"当用户对某个对象执行 DELETE 操作时，后续的简单（不受版本控制）请求将不再检索该对象。但是，该数据对象的所有版本将继续保留在您的 Amazon S3 存储桶中，可以提取或恢复。只有 Amazon S3 存储桶的拥有者才能永久删除某个版本。您可以设置[生命周期规则](http://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)来管理生命周期和存储对象的多个版本的成本。"
    },
    {
        "query":"是否可以在 Amazon S3 对象上设置垃圾桶、回收站或回滚时段以从删除和覆盖项中恢复？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon S3 生命周期规则](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)和 [S3 版本控制](https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html)来实施 S3 对象的回滚时段。例如，借助启用了版本控制的存储桶，您可以设置一条规则，将以前的所有版本归档到成本较低的 S3 Glacier Flexible Retrieval 存储类，并在 100 天后删除它们，从而给您 100 天的时间来回滚对数据的任何更改，同时降低存储成本。此外，您也可以通过在 5 天后以及至少有 2 个较新版本的对象时删除旧（非当前）版本的对象来节约成本。您可以根据成本优化需要更改天数或更新版本的数量。这使您可以在需要时保留其他版本的对象，但通过在一段时间后转换或删除它们来节约成本。"
    },
    {
        "query":"如何确保我保留的版本得到最大保护？",
        "intention":"知识问答",
        "reply":"版本控制的[多重身份验证（MFA）](https://aws.amazon.com/cn/mfa/)可使用删除功能来增添一层安全性。默认情况下，对您的 Amazon S3 存储桶的所有请求都需要您的 AWS 账户证书。如果您在 Amazon S3 存储桶上利用 MFA Delete 功能启用了版本控制，则需要以下两种形式的身份验证才能永久删除数据对象的某个版本：您的 AWS 账户凭证、来自您拥有的身份验证设备的有效六位代码和序列号。要了解有关利用 MFA Delete 功能启用版本控制的更多信息，包括如何购买和激活身份验证设备，请参阅 [Amazon S3 文档](http://docs.amazonwebservices.com/AmazonS3/latest/dev/Versioning.html)。"
    },
    {
        "query":"什么是 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"S3 Intelligent-Tiering 是首个云存储，它可以根据访问频率自动将数据移至最经济实惠的访问层，从而自动在细粒度对象级别降低您的存储成本，并且不会产生性能影响、检索费用或运营开销。S3 Intelligent-Tiering 可以为频繁、不频繁和归档即时访问层中的频繁、不频繁以及很少访问的数据提供毫秒级延迟和提高吞吐量性能。每月只需支付少量的对象监控和自动化费用，S3 Intelligent-Tiering 即可监控访问模式并将对象从一个访问层自动移动到另一个访问层。S3 Intelligent-Tiering 没有任何检索费用，因此在访问模式发生变化时存储账单不会意外增加。\n现在，您可以通过虚拟方式将 S3 Intelligent-Tiering 用作任何工作负载（尤其是数据湖、数据分析、机器学习、新应用程序和用户生成的内容）的默认存储类。"
    },
    {
        "query":"S3 Intelligent-Tiering 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 Intelligent-Tiering 存储类旨在通过当访问模式改变时自动将数据移动到最具成本效益的访问层来优化存储成本。每月只需支付少量的对象监控和自动化费用，S3 Intelligent-Tiering 即可监控访问模式并自动将连续 30 天未被访问的对象移动到不频繁访问层，最多可节省 40% 的存储成本。在连续 90 天未访问以后，对象会被移动到归档即时访问层以最多节省 68% 的存储成本。性能不会受到影响，而且 S3 Intelligent-Tiering 没有检索费用。如果之后访问了不频繁访问层或归档即时访问层中的对象，则其会被自动移回频繁访问层。\n要为可异步访问的数据实现最低存储成本，您可以选择激活其他归档功能。在您启用一个或两个异步归档访问层后，S3 Intelligent-Tiering 会将至少 90 天未被访问的对象移动到归档访问层，以节省高达 71% 的成本，然后在 180 天无访问后，将其移动到深度归档访问层，以便为很少访问的对象实现高达 95% 的节省。如果可选归档或深度访问层当中的对象在之后被还原，它将被移回到频繁访问层，而且在可以检索前，您必须先使用 RestoreObject 还原该对象。有关恢复归档对象的信息，请参阅[恢复归档对象](https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects.html)。S3 Intelligent-Tiering 没有检索费用。在 S3 Intelligent-Tiering 存储类中的访问层之间移动对象时，不会产生额外的分层或生命周期费用。  \n   \n S3 Intelligent-Tiering 没有最小对象大小，但小于 128KB 的对象没有资格进行自动分层。这些较小的对象可以存储在 S3 Intelligent-Tiering 中，但将始终按频繁访问层费率收费，不收取监控和自动化费用。\n如果您想要将 S3 Intelligent-Tiering 标准化为新创建数据的默认存储类，则可以通过在 [S3 PUT API 请求标头](https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3api/put-object.html)上指定 INTELLIGENT-TIERING 来修改应用程序。S3 Intelligent-Tiering 旨在提供 99.9% 的可用性和 99.999999999% 的持久性，并自动提供与 S3 Standard 相同的低延迟和高吞吐量性能。您可以使用 AWS Cost Explorer 来评估使用归档即时访问层所能实现的节省。"
    },
    {
        "query":"为什么应选择使用 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"现在，您可以通过虚拟方式将 S3 Intelligent-Tiering 用作任何工作负载（尤其是数据湖、数据分析、机器学习、新应用程序和用户生成的内容）的默认存储类。S3 Intelligent-Tiering 是首个云存储，它可以根据访问频率自动将数据移至最经济实惠的访问层，从而自动在细粒度对象级别降低您的存储成本，并且不会产生性能影响、检索费用或运营开销。如果您有访问模式未知或不断变化的数据，包括数据湖、数据分析和新应用程序，我们建议使用 S3 Intelligent-Tiering。如果您有不需要立即检索的数据，我们建议激活深度归档访问层，因此您只需要为可能长时间很少访问的数据支付每 TB 每月 1 USD。S3 Intelligent-Tiering 适用于访问模式未知或不断变化的数据。在使用 S3 Intelligent-Tiering 存储类时不会产生检索费用。"
    },
    {
        "query":"S3 Intelligent-Tiering 可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 Intelligent-Tiering 会自动优化您的存储成本，而不会影响您的性能。S3 Intelligent-Tiering 的频繁、不频繁和归档即时访问层提供毫秒级延迟和高吞吐量性能。"
    },
    {
        "query":"S3 Intelligent-Tiering 的持久性和可用性如何？",
        "intention":"知识问答",
        "reply":"与 S3 Standard 存储类相同，S3 Intelligent-Tiering 专为 99.999999999% 的持久性而设计。S3 Intelligent-Tiering 设计用于提供 99.9% 的可用性，并附带[服务等级协议](https://aws.amazon.com/cn/s3/sla/)，当在任意账单周期内的可用性低于我们的服务承诺时，还可提供服务积分。"
    },
    {
        "query":"如何将数据存入 S3 Intelligent-Tiering？",
        "intention":"知识问答",
        "reply":"有两种方式可以将数据存入 S3 Intelligent-Tiering。可以通过指定 x-amz-存储类标头中的 INTELLIGENT\\_TIERING 来直接放入 S3 Intelligent-Tiering 中，也可以设置生命周期策略以将对象从 S3 Standard 或 S3 Standard-IA 转换到 S3 INTELLIGENT\\_TIERING。\nS3 Intelligent-Tiering 是如何收费的？\nS3 Intelligent-Tiering 会向您收取月度存储费用、请求和数据传输费用，还会对每个对象的监控和自动化向您收取很少的月服务费。S3 Intelligent-Tiering 存储类自动将对象存储在三个访问层中：按 S3 Standard 存储费率定价的频繁访问层、按 S3 Standard-Infrequent Access 存储费率定价的不频繁访问层，以及按 S3 Glacier Instant Retrieval 存储费率定价的归档即时访问层。S3 Intelligent-Tiering 还有两个专为异步访问设计的可选归档层，按 S3 Glacier Flexible Retrieval 存储费率定价的归档访问层和按 S3 Glacier Deep Archive 存储费率定价的深层归档访问层。  \n   \n 对于小额监控和自动化费用，S3 Intelligent-Tiering 会监控访问模式并自动移动对象到低延迟、高吞吐量访问层，以及两个可选异步归档访问层，客户可以借此在云中为可异步访问的数据实现最低存储成本。  \n   \n S3 Intelligent-Tiering 没有最小可计费对象大小，但小于 128KB 的对象没有资格进行自动分层。 这些小型对象将不受监控，并将始终按频繁访问层费率收费，没有监控和自动化费用。对于在 S3 Intelligent-Tiering 中归档到归档访问层或深度归档访问层的每个对象，Amazon S3 为对象名称和其他元数据使用 8KB 的存储空间（按 S3 Standard 存储费率计费），为索引和相关元数据使用 32KB 的存储空间（按 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储费率计费）。"
    },
    {
        "query":"如何激活 S3 Intelligent-Tiering 归档访问层？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 API、CLI 或 S3 管理控制台创建存储桶、前缀或对象标签级别配置，从而激活存档访问层和深度存档访问层。如果您的对象可以被应用程序异步访问，则仅应激活一个或两个存档访问层。  \n   \n 问：是否可以延长在 S3 Intelligent-Tiering 存储类中存档对象之前的访问时间？\n可以。在存储桶、前缀或对象标签级别配置中，您可以延长在 S3 Intelligent-Tiering 中归档对象的最后访问时间。启用该功能后，默认情况下，最少连续 90 天未访问的对象将自动移动到归档访问层中，而跳过归档即时访问层。最少连续 180 天未访问的对象将自动移动到深度归档访问层中。对于在 S3 Intelligent-Tiering 中自动存档前最后一次访问之后的连续天数默认配置，最多可以延长 2 年。"
    },
    {
        "query":"如何从 S3 Intelligent-Tiering 存储类的存档访问层或深度存档访问层中获取对象？",
        "intention":"知识问答",
        "reply":"要访问存档或深度存档访问层中的对象，您需要发出“还原”请求，该对象将开始移回到频繁访问层，所有对象都存储在 S3 Intelligent-Tiering 存储类中。存档访问层中的对象将在 3-5 小时内移至频繁访问层，深度存档访问层中的对象将 12 小时内移至频繁访问层。一旦对象位于频繁访问层中，您就可以发出 GET 请求以检索对象。"
    },
    {
        "query":"如何知道我的对象存储在哪个 S3 Intelligent-Tiering 访问层中？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon S3 清单来针对存储在 S3 Intelligent-Tiering 存储类中的对象的访问层生成报告。Amazon S3 清单提供 CSV、ORC 或 Parquet 输出文件，从而每日或每周为 S3 存储桶或共享前缀列出您的对象及其相应的元数据。您还可以对您的对象提出 HEAD 请求，以报告 S3 Intelligent-Tiering 归档访问层。"
    },
    {
        "query":"是否可以将对象的生命周期从 S3 Intelligent-Tiering 转换到其他存储类？",
        "intention":"知识问答",
        "reply":"是。您可以将对象的生命周期从 S3 Intelligent-Tiering 频繁访问、不频繁和归档即时访问层转换到 S3 One-Zone Infrequent Access、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive。此外，您可以将对象的生命周期从 S3 Intelligent-Tiering 可选归档访问层转换到 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive，从 S3 Intelligent-Tiering 深度归档访问层转换到 S3 Glacier Deep Archive。"
    },
    {
        "query":"S3 Intelligent-Tiering 是否有最短期限？",
        "intention":"知识问答",
        "reply":"没有。S3 Intelligent-Tiering 存储类没有最短存储期限。"
    },
    {
        "query":"S3 Intelligent-Tiering 是否有最小可计费对象大小限制？",
        "intention":"知识问答",
        "reply":"没有。S3 Intelligent-Tiering 存储类没有最小可计费对象大小，但小于 128KB 的对象没有资格进行自动分层。这些较小的对象将始终按频繁访问层费率收费，没有监控和自动化费用。对于在 S3 Intelligent-Tiering 中归档到可选的归档访问层或深度归档访问层的每个对象，Amazon S3 为对象名称和其他元数据使用 8KB 的存储空间（按 S3 Standard 存储费率计费），为索引和相关元数据使用 32KB 的存储空间（按 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储费率计费）。如需更多详细信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"什么是 S3 Standard？",
        "intention":"知识问答",
        "reply":"Amazon S3 Standard 为频繁访问的数据（通常每个月一次以上）提供具有毫秒级访问延迟和高吞吐量性能的持久性存储。S3 Standard 专为性能敏感型使用案例而设计，如数据湖、云原生应用程序、动态网站、内容分发、移动和游戏应用程序、分析和机器学习模型。S3 Standard 的设计可以在指定年度内跨多个可用区实现 99.99% 的数据可用性和 99.999999999％ 的对象持久性。您可以使用 S3 生命周期策略来控制数据在 S3 Standard 和较低成本存储类之间转移的具体时间，而不对应用程序做任何更改。"
    },
    {
        "query":"为什么应选择使用 S3 Standard？",
        "intention":"知识问答",
        "reply":"S3 Standard 非常适用于最频繁访问或修改的数据，这些数据要求以毫秒级且高吞吐量性能进行访问。由于不会产生检索费用，因此 S3 Standard 是经常读取或写入数据的理想选择。S3 Standard 针对各种用例进行了优化，包括数据湖、云原生应用程序、动态网站、内容分发、移动和游戏应用程序以及分析。"
    },
    {
        "query":"什么是 S3 Standard-Infrequent Access？",
        "intention":"知识问答",
        "reply":"S3 Standard-Infrequent Access (S3 Standard-IA) 是一种 Amazon S3 存储类，用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 提供了 Amazon S3 Standard 存储类的高持久性、高吞吐量和低延迟，每 GB 存储价格和每 GB 检索费用都比较低。成本较低且性能出色使得 S3 Standard-IA 成为长期存储和备份的理想选择，也非常适用于灾难恢复的数据存储。S3 Standard-IA 存储类是在对象级别进行设置的，并且可以与 S3 Standard 或 S3 One Zone-IA 存储类存在于同一个存储桶中，从而让您可以使用 S3 生命周期策略在存储类之间自动转移对象，而无需更改任何应用程序。"
    },
    {
        "query":"为什么应选择使用 S3 Standard-IA？",
        "intention":"知识问答",
        "reply":"S3 Standard-IA 适用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 非常适合长期文件存储、较旧的同步和共享存储以及其他老化数据。"
    },
    {
        "query":"S3 Standard-IA 可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 Standard-IA 提供与 S3 Standard 存储类相同的延迟和高吞吐量性能。"
    },
    {
        "query":"如何将数据存入 S3 Standard-IA？",
        "intention":"知识问答",
        "reply":"有两种方式可以将数据存入 S3 Standard-IA。通过在 x-amz-storage-class 标头中指定 STANDARD\\_IA，您可以通过 PUT 操作直接将数据放入 S3 Standard-IA。您还可以设置生命周期策略，将对象从 S3 Standard 转移到 S3 Standard-IA 存储类。"
    },
    {
        "query":"是否可以将 S3 Standard-IA 中的对象分层到 S3 One Zone-IA 或 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"是。除了使用生命周期策略将对象从 S3 Standard 迁移到 S3 Standard-IA 之外，您还可以将生命周期策略设置为将 S3 Standard-IA 的对象分层到 S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类。"
    },
    {
        "query":"什么是 S3 单区 – IA 存储类？",
        "intention":"知识问答",
        "reply":"S3 单区 – IA 存储类是一个 Amazon S3 存储类，让客户可以选择将对象存储在单个可用区中。S3 One Zone-IA 存储以冗余方式将数据存储在单个可用区内，这种存储的成本比地理上冗余的 S3 Standard-IA 存储的成本低 20%，而后者是以冗余方式将数据存储在多个地理上分离的可用区内。\nS3 One Zone-IA 提供 99% 的可用性 SLA，并且在可用区内的持久性还能够达到 99.999999999%。然而，S3 One Zone-IA 存储类中的数据对整个可用区的物理损失不具有弹性。\nS3 One Zone-IA 存储提供与 S3 Standard 和 S3 Standard-IA 相同的 Amazon S3 功能，用户可以通过 Amazon S3 API、CLI 和控制台使用这种存储类。S3 One Zone-IA 存储类是在对象级别进行设置的，并且可以和 S3 Standard 和 S3 Standard-IA 标准存储类存在于同一个存储桶中。您可以使用 S3 生命周期策略在存储类之间自动转移对象，而无需更改任何应用程序。"
    },
    {
        "query":"S3 单区 – IA 存储类最适合用于哪些使用案例？",
        "intention":"知识问答",
        "reply":"客户将 S3 单区 – IA 存储类用于访问频率较低的存储，如备份副本、灾难恢复副本或其他易于重新创建的数据。"
    },
    {
        "query":"S3 单区 – IA 存储类可提供什么样的性能？",
        "intention":"知识问答",
        "reply":"S3 One Zone-IA 存储类可提供与 S3 Standard 和 S3 Standard-Infrequent Access 存储类的相同的延迟和吞吐量性能。"
    },
    {
        "query":"S3 One Zone-IA 存储类的持久性如何？",
        "intention":"知识问答",
        "reply":"S3 One Zone-IA 存储类在一个可用区内的持久性可达到 99.999999999%。然而，S3 One Zone-IA 存储类中的数据对可用区的可用性损失或物理损失不具有弹性。相比之下，S3 Standard、S3 Intelligent-Tiering、S3 Standard-Infrequent Access 和 S3 Glacier 存储类能够承受住可用性下降或可用区毁坏的情况。S3 One Zone-IA 可以提供与大多数现代物理数据中心相当或更高的持久性和可用性，同时还提供存储弹性和 Amazon S3 功能集的额外优势。"
    },
    {
        "query":"S3 One Zone-IA 中的“区域”与 AWS 可用区是否一样？",
        "intention":"知识问答",
        "reply":"是。每个 AWS 区域都是一个独立的地理区域。每个区域都有多个相互隔离的位置，称为可用区。Amazon S3 One Zone-IA 存储类使用区域内的单个 AWS 可用区。"
    },
    {
        "query":"通过使用 S3 One Zone-IA，我将放弃多少灾难恢复保护能力？",
        "intention":"知识问答",
        "reply":"每个可用区均使用冗余电源和联网。在 AWS 区域内，可用区位于不同的冲积平原和地震断裂带，并且在地理位置上是分离的，以避免受到火灾的影响。S3 Standard 和 S3 Standard-IA 存储类通过以冗余方式将数据存储在多个可用区来避免受到这类灾难的影响。S3 单区 – IA 对可用区内的设备故障提供保护，但数据对于因地震和洪水等灾难造成的可用区物理损失不具有弹性。使用 S3 One Zone-IA、S3 Standard 和 S3 Standard-IA 选项，您可以选择最符合您的存储持久性和可用性要求的存储类。"
    },
    {
        "query":"什么是 Amazon S3 Glacier Instant Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 存储类为很少访问且需要毫秒级检索速度的长期数据提供最低成本的存储。S3 Glacier Instant Retrieval 可提供对归档存储的最快访问，并且与 S3 Standard 和 S3 Standard-IA 存储类具有相同的吞吐量和毫秒级访问速度。通过跨至少三个物理分离的 AWS 可用区冗余存储数据，S3 Glacier Instant Retrieval 旨在实现 99.999999999%（11 个 9）的数据持久性和 99.9% 的可用性。"
    },
    {
        "query":"为什么应选择使用 S3 Glacier Instant Retrieval？",
        "intention":"知识问答",
        "reply":"如果您有很少访问的数据，而且要求毫秒级延迟，则 S3 Glacier Instant Retrieval 是您的理想选择。若您想要和 S3 Standard-IA 相同的低延迟和高吞吐量性能，但存储数据的访问频率低于 S3 Standard-IA，那么它就非常适合您，因为它的存储价格降低，而数据访问成本稍高。"
    },
    {
        "query":"S3 Glacier Instant Retrieval 的可用性和持久性如何？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 专为实现与 S3 Standard-IA 相同的 99.999999999%（11 个 9）持久性和 99.9 可用性而设计，它具有服务等级协议，可在任何计费周期内的可用性低于 99% 时提供服务积分。"
    },
    {
        "query":"S3 Glacier Instant Retrieval 提供怎样的性能？",
        "intention":"知识问答",
        "reply":"S3 Glacier Instant Retrieval 提供与 S3 Standard 和 S3 Standard-IA 存储类相同的毫秒级延迟和高吞吐量性能。有别于专为异步访问设计的 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类，您不需要在访问存储于 S3 Glacier Instant Retrieval 的对象前发出 Restore 请求。"
    },
    {
        "query":"如何将我的数据存入 S3 Glacier Instant Retrieval？",
        "intention":"知识问答",
        "reply":"将数据存入 S3 Glacier Instant Retrieval 的方式有两种。您可以通过指定 x-amz-storage-class 标头中的 GLACIER\\_IR 来直接放入 S3 Glacier Instant Retrieval 中，也可以设置 S3 生命周期策略以将对象从 S3 Standard 或 S3 Standard-IA 转移到 S3 Glacier Instant Retrieval。"
    },
    {
        "query":"什么是 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Flexible Retrieval 存储类为每年访问 1-2 次且异步检索的归档数据提供低成本存储，成本最多降低 10%（相比 S3 Glacier Instant Retrieval），以及免费批量检索。对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用案例，S3 Glacier Flexible Retrieval（原 S3 Glacier）是理想的存储类。S3 Glacier Flexible Retrieval 提供最灵活的检索选项，可以平衡成本与访问时间（从几分钟到几小时不等），并且可批量检索。它是备份、灾难恢复、离线数据存储需求的理想解决方案，并且还非常适合于偶尔需要在几分中内检索部分数据而您不想担心成本的情况。通过跨多个物理分离的 AWS 可用区冗余存储数据，S3 Glacier Flexible Retrieval 旨在实现 99.999999999%（11 个 9）的数据持久性和 99.99% 的可用性。"
    },
    {
        "query":"为什么应选择使用 S3 Glacier Flexible Retrieval 存储类？",
        "intention":"知识问答",
        "reply":"对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用案例，S3 Glacier Flexible Retrieval（原 S3 Glacier）是理想的存储类。S3 Glacier Flexible Retrieval 提供最灵活的检索选项，可以平衡成本与访问时间（从几分钟到几小时不等），并且可批量检索。它是备份、灾难恢复、离线数据存储需求的理想解决方案，并且还非常适合于偶尔需要在几分中内检索部分数据而您不想担心数据检索成本的情况。"
    },
    {
        "query":"如何将我的数据存入 S3 Glacier Flexible Retrieval？",
        "intention":"知识问答",
        "reply":"将数据存入 S3 Glacier Flexible Retrieval 的方式有两种。通过在 x-amz-storage-class 标头中指定 GLACIER，您可以直接将数据放入 S3 Glacier Flexible Retrieval。您还可以使用 [S3 生命周期](https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html)规则基于对象的使用年限在适用于活动数据的任何 S3 存储类（S3 Standard、S3 Intelligent-Tiering、S3 Standard-IA、S3 One Zone-IA 和 S3 Glacier Instant Retrieval）与 Amazon S3 Glacier Flexible Retrieval 之间传输数据。使用 Amazon S3 管理控制台、AWS 开发工具包或 Amazon S3 API 来直接放入 Amazon S3 Glacier 或定义归档规则。  \n   \n 注：S3 Glacier Flexible Retrieval（原 S3 Glacier）还可以通过原始直接 Glacier API 和 Amazon S3 Glacier 管理控制台提供。为了获取增强体验和完整 S3 功能集的访问权限，包括生命周期管理、S3 复制、S3 Storage Lens 等，我们建议通过 S3 API 和 S3 管理控制台来使用 S3 Glacier 功能。"
    },
    {
        "query":"如何检索归档在 S3 Glacier Flexible Retrieval 中的对象？对象还原时我会收到通知吗？",
        "intention":"知识问答",
        "reply":"归档在 S3 Glacier Flexible Retrieval 中的对象可以异步访问。要检索存储在 S3 Glacier Flexible Retrieval 中的数据，您需要使用 Amazon S3 API 或 Amazon S3 控制台启动检索请求。检索请求会在 S3 Standard 存储类中创建数据的临时副本，同时已归档数据将原封不动地保留在 S3 Glacier Flexible Retrieval 中。您可以以天为单位指定将临时副本存储在 Amazon S3 上的时间。然后，可以通过 Amazon S3 GET 从 S3 中请求访问已归档对象的临时副本。\n通过还原通知，您现在可在从 S3 Glacier Flexible Retrieval 成功还原对象并且临时副本可供您使用时使用 [S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/dev/NotificationHowTo.html)通知您。存储桶拥有者（或 [IAM](https://aws.amazon.com/cn/iam/) 策略允许的其他人）可以安排将通知发送到 [Amazon Simple Queue Service (SQS)](https://aws.amazon.com/cn/sqs/) 或 [Amazon Simple Notification Service (SNS)](https://aws.amazon.com/cn/sns/)。通知也可传送到 [AWS Lambda](https://aws.amazon.com/cn/lambda/)，由 Lambda 函数进行处理。"
    },
    {
        "query":"恢复归档在 Amazon S3 Glacier Flexible Retrieval 中的对象需要多长时间？",
        "intention":"知识问答",
        "reply":"处理检索任务时，Amazon S3 首先从 S3 Glacier Flexible Retrieval 检索请求的数据，然后在 Amazon S3 中创建所请求数据的临时副本。这通常需要几分钟时间。请求的访问时间取决于您选择的检索选项：加急、标准或批量检索。除了最大的对象 (250MB+) 以外，对于使用加急检索方式访问的所有数据，通常在 1-5 分钟内即可使用。使用标准检索方式检索的对象通常在 3-5 小时内完成。批量检索通常在 5-12 小时内完成，而且是免费的。有关 S3 Glacier Flexible Retrieval 选项的更多信息，请参阅《S3 用户指南》中的[恢复归档的对象](https://docs.aws.amazon.com/AmazonS3/latest/userguide/restoring-objects.html)。\n使用 S3 Glacier 存储类预置容量单位，您可以为给定月份支付固定的预付费用，以确保获得从 S3 Glacier Flexible Retrieval 进行加急检索所需的检索容量。您每月可以购买 2 个预置容量单位，从而增加可以检索的数据量。每单位容量可确保每 5 分钟内至少可执行 3 次加急检索，并提供最高达 150MB/s 的检索吞吐量。如果您的工作负载需要在几分钟内对数据子集进行高度可靠且可预测的访问，那么您应该购买预置检索容量。如果没有预置容量，在高需求期间，可能不会接受加快检索。如果您在任何情况下需要访问加速检索，我们建议您购买预置的检索容量。\n您可以使用 Amazon S3 控制台、[购买预置容量](https://docs.aws.amazon.com/amazonglacier/latest/dev/api-PurchaseProvisionedCapacity.html) REST API、AWS 开发工具包或 AWS CLI 购买预置容量。预置容量单位从购买日期和时间（即开始日期）开始，持续一个月。单位在到期日期时过期，该日期恰好是开始日期后的一个月，精确到秒钟。有关预置容量定价信息，请参阅 [Amazon S3 定价](https://aws.amazon.com/s3/pricing/)。"
    },
    {
        "query":"从 Amazon S3 Glacier Flexible Retrieval 检索数据的成本是多少？",
        "intention":"知识问答",
        "reply":"从 S3 Glacier Flexible Retrieval 检索数据的方式有三种：加急、标准和批量检索。加急和标准方式具有不同的每 GB 检索费和每请求费（即，您需要为针对 Amazon S3 对象的请求付费）。从 S3 Glacier Flexible Retrieval 进行批量检索是免费的。有关不同 AWS 区域的 S3 Glacier 定价的详细信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。"
    },
    {
        "query":"支持 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类的后端基础设施是什么？",
        "intention":"知识问答",
        "reply":"我们更倾向于关注客户在性能、持久性、可用性和安全性方面的结果。但是，我们的客户经常会提出这个问题。我们使用各种不同技术，让我们可以将我们的价格报给客户。我们的服务是使用常见数据存储技术构建的，这些技术使用 AWS 开发的软件专门组装到特别定制、成本优化的系统中。我们能够优化输入和输出次序，因此 S3 Glacier 存储类可最大限度地提高访问底层存储的效率。"
    },
    {
        "query":"什么是 Amazon S3 Glacier Deep Archive 存储类？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 是一种 [Amazon S3 存储类](https://aws.amazon.com/cn/s3/storage-classes/)，这为长期保存每年访问一两次的数据提供了安全、持久的对象存储。S3 Glacier Deep Archive 的云存储成本最低，每月每 GB 仅 0.00099 USD（不到 0.1 美分，或每月每 TB 约 1 USD）起，远低于存储和维护本地磁带库或异地归档数据的价格。"
    },
    {
        "query":"S3 Glacier Deep Archive 存储类最适用于哪些使用案例？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 是一种理想的存储类，可以为公司最重要的数据资产提供离线保护，或者在根据公司政策、合同或监管合规性要求需要长期保留数据时提供离线保护。客户发现 S3 Glacier Deep Archive 是一个非常有吸引力的选择，可用来保护核心知识产权、金融和医疗记录、研究结果、法律文件、地震勘探研究和长期备份的，特别是在金融服务、医疗、石油和天然气以及公共部门等监管严格的行业。此外，还有一些企业希望保留核心知识产权的备份副本，比如媒体和娱乐公司。通常，使用 S3 Glacier Deep Archive 的客户可以减少或停止使用本地磁带库和本地之外的磁带归档服务。"
    },
    {
        "query":"S3 Glacier Deep Archive 存储类和 S3 Glacier Instant Retrieval 及 S3 Glacier Flexible Retrieval 存储类有何区别？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 扩充了我们的数据归档产品，使您能够根据存储和检索成本以及检索时间选择最佳的存储类别。当需要以毫秒级延迟访问低成本归档数据时，您可以选择 S3 Glacier Instant Retrieval 存储类。对于不需要立即访问但需要灵活地免费检索大量数据的归档数据，例如备份或灾难恢复使用场景，请选择 S3 Glacier Flexible Retrieval（原 S3 Glacier），它可在几分钟内检索，也可以在 5-12 小时内进行免费批量检索。相比之下，S3 Glacier Deep Archive 专门用于不太可能访问但仍然需要长期持久存储的较冷数据。S3 Glacier Deep Archive 的费用比 S3 Glacier Flexible Retrieval 低 75%，并可在 12 小时内，使用标准检索速度提供检索。您还可以通过选择批量检索来降低检索成本，批量检索将在 48 小时内返回数据。"
    },
    {
        "query":"如何开始使用 S3 Glacier Deep Archive？",
        "intention":"知识问答",
        "reply":"在 S3 Glacier Deep Archive 中存储数据的最简单方法是使用 S3 API 直接上传数据。只需指定“S3 Glacier Deep Archive”作为存储类。您可以利用 AWS 管理控制台、S3 REST API、AWS 开发工具包或 AWS 命令行界面来完成该指定操作。\n您还可以通过使用 S3 Lifecycle 来创建迁移数据的策略，以此开始使用 S3 Glacier Deep Archive，S3 Lifecycle 提供了定义对象生命周期和降低存储成本的能力。可以设置这些策略，以便根据对象的使用年限将对象迁移到 S3 Glacier Deep Archive 上。您可以为 S3 存储桶或特定前缀指定策略。生命周期转换按 S3 Glacier Deep Archive 上传价格计费。\n磁带网关是 AWS Storage Gateway 的一个基于云的虚拟磁带库功能，现与 S3 Glacier Deep Archive 结合在一起，使您可以将基于虚拟磁带的长期备份和归档存储在 S3 Glacier Deep Archive 中，从而为云中的这些数据提供最低的存储成本。首先，使用 AWS Storage Gateway 控制台或 API 创建一个新的虚拟磁带，并将归档存储目标设置为 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive。当备份应用程序弹出磁带时，磁带将归档到选定的存储目标中。"
    },
    {
        "query":"将数据从现有的磁带存档迁移到 S3 Glacier Deep Archive 上，您有何建议?",
        "intention":"知识问答",
        "reply":"有多种方法可以将数据从现有磁带存档迁移到 S3 Glacier Deep Archive。您可以使用 AWS Tape Gateway，以便通过虚拟磁带库 (VTL) 接口与现有备份应用程序集成。此接口可以将虚拟磁带提供给备份应用程序。以上操作可以立即将数据存储在 Amazon S3、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive。\n您还可以使用 AWS Snowball 或 Snowmobile 迁移数据。Snowball 和 Snowmobile 可使用能确保传输安全的物理存储设备，加快 TB 到 PB 级数据迁入和迁出 AWS 的速度。使用 Snowball 和 Snowmobile 有助于解决进行大规模数据传输时会遇到的难题，包括网络费用高、传输时间长和安全问题。\n最后，您可以使用 AWS Direct Connect 来建立从本地到 AWS 的专用网络连接。在许多情况下，Direct Connect 可以降低网络成本，增加带宽吞吐量，并提供比基于互联网的连接更一致的网络体验。"
    },
    {
        "query":"如何检索存储在 S3 Glacier Deep Archive 中的对象？",
        "intention":"知识问答",
        "reply":"要检索存储在 S3 Glacier Deep Archive 中的数据，请使用 Amazon S3 API 或 Amazon S3 管理控制台提出“恢复”请求。“还原”会在 S3 Standard 存储类中创建数据的临时副本，同时使 S3 Glacier Deep Archive 中的已归档数据保持完整。您可以以天为单位指定将临时副本存储在 S3 上的时间。然后，可以通过 Amazon S3 GET 从 S3 中请求访问已归档对象的临时副本。\n还原一个存档对象时，您可以在请求正文的 Tier 元素中指定以下一个选项：标准为默认层并允许您在 12 小时内访问您存档的任何对象，Bulk 允许您检索大量数据，甚至是 PB 级的数据，而且成本低廉，通常在 48 小时内就可以完成。"
    },
    {
        "query":"S3 Glacier Deep Archive 使用情况将如何显示在我的 AWS 账单上和 AWS 成本管理工具中？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 使用情况和成本将在您的每月 AWS 账单上显示为一个独立的服务行项目，与 Amazon S3 使用情况和成本分开。但是，如果您正在使用 AWS 成本管理工具，S3 Glacier Deep Archive 使用情况和成本将包括在您的每月详细开支报表中的 Amazon S3 使用情况和成本下，并且不会细分为单独的服务行项目。"
    },
    {
        "query":"S3 Glacier Deep Archive 如何与其他 AWS 服务相集成？",
        "intention":"知识问答",
        "reply":"S3 Glacier Deep Archive 集成了 Amazon S3 功能，包括 S3 对象标记、S3 生命周期策略、S3 对象锁定和 S3 复制。通过 S3 存储管理功能，您可以使用单个 Amazon S3 存储桶存储 S3 Glacier Deep Archive、S3 Standard、S3 Standard-IA、S3 One Zone-IA 和 S3 Glacier Flexible Retrieval 数据的混合体。这让存储管理员可以基于数据和数据访问模式的性质做出决策。客户可以使用 Amazon S3 生命周期策略将老化的数据自动迁移到成本较低的存储类，也可以使用 S3 跨区域复制或同区域复制策略将数据复制到同一区域或其他区域。\nAWS Storage Gateway 服务可将磁带网关与 S3 Glacier Deep Archive 存储类集成，这样您就可以将虚拟磁带存储在成本最低的 Amazon S3 存储类中，从而将在云中存储长期数据的每月成本降低 75%。使用此功能，磁带网关支持将您的新虚拟磁带直接归档到 S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive，从而帮助您满足备份、归档和恢复要求。磁带网关可帮助您将基于磁带的备份移动到 AWS，而无需对现有备份工作流程进行任何更改。磁带网关支持大多数领先的备份应用程序，例如 Veritas、Veeam、Commvault、Dell EMC NetWorker、IBM Spectrum Protect（在 Windows OS 上）和 Microsoft Data Protection Manager。"
    },
    {
        "query":"什么是 Amazon S3 on Outposts？",
        "intention":"知识问答",
        "reply":"Amazon S3 on Outposts 使用 S3 API 和您目前在 AWS 中使用的功能在您的本地环境中提供对象存储。AWS Outposts 是一项完全托管式服务，可将 AWS 基础设施、AWS 服务、API 和工具扩展到几乎任何数据中心、主机托管空间或本地设施。使用 S3 on Outposts，您可以在将数据移动到 AWS 区域之前安全地处理和存储在本地生成的客户数据，针对在本地运行的应用程序在本地访问数据，或者对于所处位置有数据驻留要求的公司或监管行业公司将数据存储在 Outpost 中。要了解有关 S3 on Outposts 的更多信息，请访问[概览页面](https://aws.amazon.com/cn/s3/outposts/)。\n[S3 对象标签](https://aws.amazon.com/cn/s3/faqs#S3_Object_Tags) | [S3 清单](https://aws.amazon.com/cn/s3/faqs#S3_Inventory) | [S3 批量操作](https://aws.amazon.com/cn/s3/faqs#S3_Batch_Operations) | [S3 对象锁定](https://aws.amazon.com/cn/s3/faqs#S3_Object_Lock) | [S3 CloudWatch 指标](https://aws.amazon.com/cn/s3/faqs#S3_CloudWatch_Metrics) | [S3 生命周期管理](https://aws.amazon.com/cn/s3/faqs#S3_Lifecycle_Management)"
    },
    {
        "query":"什么是 S3 对象标签？",
        "intention":"知识问答",
        "reply":"S3 对象标签是应用于 S3 对象的键/值对，在该对象的生命周期内可以随时创建、更新或删除。借助这些标签，您将能够创建 Identity and Access Management (IAM) 策略，设置 S3 生命周期策略以及自定义存储指标。然后，可以使用这些对象级标签管理后台中存储类别与过期对象之间的转换。 上传新对象时，您可以向其添加标签，也可以向现有对象添加标签。每个 S3 对象最多可添加 10 个标签，您可以使用 AWS 管理控制台、REST API、AWS CLI 或 AWS SDK 添加对象标签。\n如需了解更多信息，请访问 [S3 对象标签用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-tagging.html)。"
    },
    {
        "query":"为何应使用对象标签？",
        "intention":"知识问答",
        "reply":"借助对象标签这一工具，您可以简化 S3 存储的管理。使用此工具能够在对象的生命周期内随时创建、更新和删除标签，从而使您的存储能够满足您业务的需求。借助这些标签，您可以控制对标记有特殊键值对的对象的访问，从而能够进一步保护机密数据，使之仅供选定组或用户访问。 对象标签也可用于标记属于特定项目或业务单元的对象，它可与 S3 生命周期策略结合使用来管理到其他存储类（S3 Standard-IA、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive）的转移或与 S3 复制功能结合使用来选择性地复制 AWS 区域之间的数据。"
    },
    {
        "query":"如何更新对象上的对象标签？",
        "intention":"知识问答",
        "reply":"在 S3 对象的生命周期内，您可以随时更改对象标签，您可以使用 AWS 管理控制台、REST API、AWS CLI 或 AWS 开发工具包更改对象标签。请注意，在 AWS 管理控制台之外进行的所有更改均是对整个标签集合进行的更改。如果某个特定对象关联了 5 个标签，您要为其添加第 6 个标签，那么您需要在该请求中包括最初的 5 个标签。"
    },
    {
        "query":"如何开始使用存储类分析？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或 S3 PUT 存储桶分析 API 配置存储类分析策略，以识别不频繁访问的存储，这些存储可转换到 S3 Standard-IA 或 S3 One Zone-IA 存储类或归档到 S3 Glacier 存储类。您可以导航至 S3 控制台中的 “Management”（管理）选项卡来管理存储类分析、S3 清单和 S3 CloudWatch 指标。"
    },
    {
        "query":"什么是 S3 清单？",
        "intention":"知识问答",
        "reply":"S3 清单报告可为 Amazon S3 的同步列表 API 提供预定的替代方案。您可以通过配置 S3 清单，针对 S3 存储桶或前缀每日或每周提供一次您的对象及其对应元数据的 CSV、 ORC 或 Parquet 文件输出。您可以使用 S3 清单简化并加快业务工作流和大数据作业。您还可以使用 S3 清单验证对象的加密和复制状态是否符合业务、合规性和法规要求。 [通过 Amazon S3 清单用户指南了解更多信息](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)。"
    },
    {
        "query":"如何开始使用 S3 清单？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或 PUT Bucket Inventory Configuration API，为您 S3 存储桶中的所有对象或某个共享前缀下的对象子集配置每日或每周清单报告。在配置过程中，您可以指定 S3 清单报告的目标 S3 存储桶、输出文件的格式（CSV、ORC 或 Parquet）以及您的业务应用程序所需的具体对象元数据，例如：对象名称、大小、上次修改日期、存储类、版本 ID、删除标记、非当前版本标记、分段上传标记、复制状态或加密状态。 您可以将 S3 清单用作应用程序工作流或大数据任务的直接输入。您还可以使用 Amazon Athena、Amazon Redshift Spectrum 及其他工具（例如，Presto、Hive 和 Spark）通过标准 SQL 语言查询 S3 清单。\n通过 [Amazon S3 清单用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)了解更多信息。"
    },
    {
        "query":"什么是 S3 批量操作？",
        "intention":"知识问答",
        "reply":"S3 批量操作是一种功能，您可以使用该功能跨多个对象自动执行单个操作（如复制对象或执行 AWS Lambda 函数）。使用 S3 批量操作，只需在 S3 控制台中单击几次或使用单个 API 请求，即可更改数十亿个对象，而不必为存储管理应用程序编写自定义应用程序代码或运行计算集群。S3 批量操作不仅跨许多对象管理存储操作，还管理重试、显示进度、提供通知、提供完成报告并将在您的目标对象上执行的所有操作的事件发送到 AWS CloudTrail。可从 S3 控制台或通过 AWS CLI 和开发工具包来使用 S3 批量操作。\n要了解更多信息，请访问 [S3 批量操作页面](https://aws.amazon.com/cn/s3/features/batch-operations/)或[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops.html)。"
    },
    {
        "query":"如何开始使用 S3 批量操作？",
        "intention":"知识问答",
        "reply":"您可以通过进入 Amazon S3 控制台或使用 AWS CLI 或开发工具包来开始使用 S3 批量操作创建第一个 S3 批量操作任务。S3 批量操作任务包括要处理的对象的列表和要执行的操作的类型（请参阅[可用操作的完整列表](https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops-operations.html)）。首先选择 S3 清单报告或提供您自己的、S3 批量操作要处理的对象的自定义列表。S3 清单报告是列出了 S3 存储桶或前缀中存储的所有对象的文件。接下来，从 S3 批量操作支持的一组 S3 操作中进行选择，例如替换标签集、更改 ACL、将存储从一个存储桶复制到另一个存储桶或启动从 S3 Glacier Flexible Retrieval 到 S3 Standard 存储类的还原。然后，您可以使用特定参数自定义 S3 批量操作任务，例如标签值、ACL 被授权者和还原持续时间。为了进一步自定义存储操作，您可以编写自己的 Lambda 函数并用 S3 批量操作调用该代码。\n创建 S3 批量操作作业后，它将处理对象列表，并在需要时将作业发送到“等待确认”状态。确认作业详细信息后，S3 批量操作将开始执行您指定的操作。您可以通过编程方式或通过 S3 控制台查看任务进度、接收完成通知并查看列出已对存储所做更改明细的完成报告。\n如果您有兴趣了解有关 S3 批量操作的更多信息，[请观看教程视频](https://aws.amazon.com/cn/s3/s3batchoperations-videos/)并[查看此文档](https://docs.aws.amazon.com/AmazonS3/latest/user-guide/batch-ops.html)。"
    },
    {
        "query":"什么是 Amazon S3 对象锁定？",
        "intention":"知识问答",
        "reply":"Amazon S3 对象锁定是 Amazon S3 的一项功能，可以在固定的时间内或无限期地阻止删除或覆盖对象版本，让您能够通过实施保留策略来进一步保护数据或满足监管要求。您可将工作负载从现有的“一次写入，多次读取”(WORM) 系统迁移到 Amazon S3，并在对象级别或存储桶级别配置 S3 对象锁定，防止在预定义的保留到期日期或无限期（依法保留日期）之前删除对象版本。无论对象版本在哪个存储类中，S3 对象锁定保护都将保留，并且会在存储类之间的整个 S3 生命周期转换期间保留。\n仅当法规要求规定您的数据必须能够防蠕虫时，或者您希望在 Amazon S3 中为数据额外添加一层保护时，才应使用 S3 对象锁定。S3 对象锁定可以帮助您满足规定数据应以不可变格式存储的法规要求，还可保护 Amazon S3 中的数据，使其免遭意外或恶意删除。\n如需了解更多信息，请访问 [S3 对象锁定用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html)。"
    },
    {
        "query":"Amazon S3 对象锁定的工作原理是什么？",
        "intention":"知识问答",
        "reply":"Amazon S3 对象锁定阻止在指定的保留期间内删除对象版本，或者无限期地删除对象版本，直到依法保留被移除。使用 S3 对象锁定，您能够确保对象版本在应用 WORM 保护期间保持不可变。可通过使用 AWS 开发工具包、CLI、REST API 或 S3 管理控制台为对象版本分配保留到期日期或依法保留日期来应用 WORM 保护。可在 PUT 请求内应用保留设置，或在创建对象后对现有对象应用这些设置。\n“保留到期日期”定义对象版本将保持不变的时间长度。为对象分配“保留到期日期”后，在保留到期日期之前将无法修改或删除该对象版本。如果用户在“保留到期日期”之前尝试删除对象，操作将被拒绝。\n或者，您也可以通过应用依法保留来使对象不可变。依法保留阻止对象版本被无限期地修改或删除，直到它被明确移除。为了施加和删除依法保留，您的 AWS 账户必须拥有 PutObjectLegalHold 操作的写入权限。依法保留可以应用于启用了 S3 对象锁定的存储桶中的任何对象，无论该对象当前是否在 WORM 保护的保留期内。\nS3 对象锁定可以在两种模式之一中配置。在监管模式中部署时，具有特定 IAM 权限的 AWS 账户可以从对象版本上移除 WORM 保护。如果您需要更强的不变性以遵守法规，可以使用合规模式。在合规模式中，任何用户都不能移除 WORM 保护，包括根账户。\n问：哪些 AWS 电子存储服务已基于金融服务法规进行了评估？\n对于金融服务行业中的客户，S3 对象锁定为必须以不可删除且不可重写的格式保留记录以满足 SEC Rule 17a-4(f)、FINRA Rule 4511 或 CFTC Regulation 1.31 的法规要求的证券经纪商提供了附加支持。您可以轻松地指定记录保留时间范围来以原始形式将法规存档保留所需的一段时间，还可以实施依法保留以无限期地保留数据，直到撤销保留。"
    },
    {
        "query":"哪些 AWS 文档支持有关通知监管机构的 SEC 17a-4(f)(2)(i) 和 CFTC 1.31(c) 要求？",
        "intention":"知识问答",
        "reply":"在使用 Amazon S3 进行电子存储之前，向监管机构或所选的“指定审查机关 (DEA)”发送通知，同时提供一份 [Cohasset 评估](https://d1.awsstatic.com/r2018/b/S3-Object-Lock/Amazon-S3-Compliance-Assessment.pdf)副本。针对这些要求，AWS 不可作为指定的第三方 (D3P)。请务必选择 D3P，并将此信息添加到发送给 DEA 的通知中。"
    },
    {
        "query":"如何开始使用 S3 CloudWatch 指标？",
        "intention":"知识问答",
        "reply":"使用 AWS 管理控制台，可在 1 分钟内为您的 S3 存储桶生成 CloudWatch 请求指标，或使用前缀或对象标签配置指标的筛选条件，或访问点。此外，还可以通过调用 S3 PUT Bucket Metrics API 来启用 S3 存储指标的发布并对其进行配置。 CloudWatch 请求指标在启用后的 15 分钟内即可在 CloudWatch 中使用。CloudWatch 存储指标默认情况下针对所有存储桶启用，且每天报告一次。了解有关 [Amazon S3 的 Amazon CloudWatch 指标](https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudwatch-monitoring.html)的更多信息。"
    },
    {
        "query":"我可以对我的存储指标设置哪些警报？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch 对任何存储指标数量、计时器或等级设置阈值，当值达到此阈值时，就触发相应操作。例如，您对 4xx 错误响应的百分比设置一个阈值，当值超出此阈值至少 3 个数据点时，就触发 CloudWatch 警报以提醒 DevOps 工程师。"
    },
    {
        "query":"什么是 S3 生命周期管理？",
        "intention":"知识问答",
        "reply":"S3 生命周期管理可以通过预定义的策略定义对象的生命周期，并降低您的存储成本。您可以设置生命周期转换策略，以根据数据的使用年限自动将存储在 S3 Standard 存储类中的对象迁移到 S3 Standard-IA、S3 One Zone-IA 和/或 S3 Glacier 存储类。基于对象的使用年限，您还可以设置生命周期过期策略，将对象自动移除。您可以设置分段上传过期策略，根据上传的存储时间，使未完成的分段上传过期。\n如需了解更多信息，请访问 [S3 生命周期用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)。"
    },
    {
        "query":"如何制定 S3 生命周期管理策略？",
        "intention":"知识问答",
        "reply":"您可以在 AWS 管理控制台、S3 REST API、AWS 开发工具包或 AWS 命令行界面 (CLI) 中设置和管理生命周期策略。您可以在前缀或存储桶级别指定策略。"
    },
    {
        "query":"如何利用 Amazon S3 生命周期管理来帮助降低 Amazon S3 存储成本？",
        "intention":"知识问答",
        "reply":"利用 Amazon S3 生命周期策略，您可以将对象配置为从 S3 Standard 存储类迁移到 S3 Standard-IA 或 S3 One Zone-IA 并/或归档到 S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive 存储类。  \n   \n 您还可以指定一个 S3 生命周期策略，在特定时间段后删除对象。您可以利用此策略驱动的自动化操作来快速而轻松地降低存储成本并节省时间。在每个规则中，您都可以指定前缀、时间段、转移到 S3 Standard-IA、S3 One Zone-IA、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval、S3 Glacier Deep Archive 和/或过期日期。例如，您可以创建一个规则，规定将带有常见前缀 “logs/” 且创建后已有 30 天的所有对象归档到 S3 Glacier Flexible Retrieval，并且这些对象将于创建之日起的 365 天后失效。  \n   \n 您还可以创建单独的规则，规定仅带有前缀 “backups/” 且已创建 90 天的所有对象将失效。S3 生命周期策略对现有的和新的 S3 对象都适用，可帮助您针对 S3 中存储的所有当前数据和任何新数据优化存储、最大限度地节省成本，而无需耗时的手动数据检查和迁移。  \n   \n 在生命周期规则内，前缀字段用于识别服从该规则的数据对象。要将规则应用于单个数据对象，请指定键名称。要将规则应用于一组数据对象，请指定它们的共同前缀（例如“logs/”）。您可以指定迁移操作和过期操作以存档或删除数据对象。关于时间期限，您可以指定一个创建日期（如 2015 年 1 月 31 日）或自创建之日算起的天数（如 30 天），以便在此日期或超过此天数后将数据对象存档或删除。您可为不同前缀创建多条规则。"
    },
    {
        "query":"为什么要使用 S3 生命周期策略让未完成的分段上传过期？",
        "intention":"知识问答",
        "reply":"使用 S3 生命周期策略让未完成的分段上传过期，可通过限制未完成的分段上传的存储时间，帮助您节省成本。例如，如果您的应用程序上传了若干分段对象部分，但从未提交，那么您仍然需要为其存储付费。此策略可在预定义的天数后自动移除未完成的分段上传及其相关存储，从而降低您的 S3 存储费用。\n[了解有关使用 S3 生命周期让未完成的分段上传过期的更多信息 »](http://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-lifecycle-config)"
    },
    {
        "query":"是否可以设置 Amazon S3 事件通知，以便在 S3 生命周期转移对象或使对象过期时发送通知？",
        "intention":"知识问答",
        "reply":"是，您可以设置 [Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)，以便在 S3 生命周期转移对象或使对象过期时通知您。例如，您可以在 S3 生命周期移动对象到不同 S3 存储类或使对象过期时发送 S3 事件通知到 Amazon SNS 主题、Amazon SQS 队列或 AWS Lambda 函数。"
    },
    {
        "query":"哪些功能可用于分析我的 Amazon S3 存储使用情况？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 提供了对对象存储使用情况和活动趋势的组织范围可见性，并提出了可行的建议，以优化成本并应用数据保护最佳实践。S3 存储类分析使您可以跨对象监控访问模式，以帮助您决定何时将数据转换为正确的存储类，从而优化成本。然后，您可以使用此信息来配置进行数据传输的 S3 生命周期策略。Amazon S3 清单针对 S3 存储桶或前缀每日或每周提供一次对象及其对应元数据的报告。该报告通过验证对象的加密和复制状态，来帮助满足业务、合规和监管需求。"
    },
    {
        "query":"什么是 Amazon S3 Storage Lens？",
        "intention":"知识问答",
        "reply":"Amazon S3 Storage Lens 提供了对对象存储使用量和活动趋势的组织范围可见性，以及可行的建议，以优化成本并应用数据保护的最佳实践。Storage Lens 提供了一个交互式控制面板，其中包含组织中数十或数百个账户的对象存储使用情况和活动的单一视图，并可以通过向下钻取在多个聚合级别生成见解。这包含字节、对象计数、请求等指标，以及详细描述 S3 功能使用率的指标，例如加密对象计数和 S3 生命周期规则计数。S3 Storage Lens 还提供符合实际情况的建议，以找到降低存储成本的方法，并在数十个或数百个账户和存储桶之间应用数据保护方面的最佳实践。S3 Storage Lens 免费指标默认为所有 Amazon S3 用户启用。如果您想充分利用 S3 Storage Lens，则可以激活高级指标和建议。如需了解更多信息，请访问 [S3 Storage Lens 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage_lens.html)。"
    },
    {
        "query":"S3 Storage Lens 如何运作？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 每日汇总您的存储使用情况和活动指标，在 S3 Storage Lens 交互式控制面板上可视化显示，或以 CSV 或 Parquet 文件格式导出指标。在账户级别自动为您创建一个默认控制面板，您可以选择创建其他自定义控制面板。S3 Storage Lens 控制面板的范围可以限定为您的 AWS 组织或特定账户、区域、存储桶，甚至前缀级别（适用于 S3 Storage Lens 高级指标）。配置控制面板时，您可以使用默认指标选择，或升级以接收额外费用的 35 个额外指标和建议。此外，S3 Storage Lens 还会根据控制面板中的存储指标情况提供建议，以便您可以采取行动以根据指标优化存储。"
    },
    {
        "query":"使用 S3 Storage Lens 指标可以回答哪些关键问题？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 控制面板围绕四种主要类型的问题进行组织，这些问题可以回答有关您的存储的问题。使用“摘要”筛选器，可以探索与总体存储使用情况和活动趋势相关的最高级别问题。例如，“我的总体字节计数和请求计数是如何随时间快速增长的？” 通过“成本优化”筛选器，您可以探索与降低存储成本相关的问题，例如，“我是否可以通过保留较少的非当前版本来节省资金？” 通过“数据保护”和“访问管理”筛选器，您可以回答有关保护数据的问题，例如，“我的存储是否受到保护，不会被意外或故意删除？” 最后，通过“性能”和“事件”筛选器，您可以探索提高工作流性能的方法。这些问题中的每一个都代表可能导致向下钻取分析的第一层查询。"
    },
    {
        "query":"S3 Storage Lens 提供了哪些指标？",
        "intention":"知识问答",
        "reply":"S3 Storage Lens 包含 60 多个指标，分为免费指标和高级指标（需额外付费）。在免费指标中，您会收到用于分析使用情况的指标（基于对象的每日快照），这些指标分为成本优化、数据保护、访问管理、性能和事件类别。在高级指标中，您会收到与活动相关的指标（例如请求计数）、更深入的成本优化（例如 S3 生命周期规则计数）、额外的数据保护（例如 S3 复制规则计数）和详细的状态代码（例如 403 授权错误）。此外，还可以通过组合任何基本指标来提供派生指标。例如，“检索率”是通过将“下载字节数”除以“总存储量”计算得出的指标。 若要查看指标的完整列表，请访问 [S3 Storage Lens 文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage_lens.html)。"
    },
    {
        "query":"我的控制面板配置选项是什么？",
        "intention":"知识问答",
        "reply":"为您的整个账户提供自动配置的默认控制面板，您可以选择创建其他自定义控制面板，限于您的 AWS 组织、特定区域或账户中的存储桶。您可以设置多个自定义控制面板，如果您需要在存储分析中进行一些逻辑分离，例如对存储桶进行分段以代表各种内部团队，这将非常有用。默认情况下，您的控制面板会接收 S3 Storage Lens 免费指标，但您可以选择升级接收 S3 Storage Lens 高级指标和建议（需额外付费）。S3 Storage Lens 高级指标有 6 个不同的选项：活动指标、高级成本优化指标、高级数据保护指标、详细状态代码指标、前缀聚合和 CloudWatch 发布。此外，您可以为每个控制面板启用指标导出，还可以选择指定目标存储桶和加密类型。"
    },
    {
        "query":"S3 Storage Lens 中有多少历史数据可用？",
        "intention":"知识问答",
        "reply":"对于交互式控制面板中显示的指标，Storage Lens 免费指标保留 14 天的历史数据，Storage Lens 高级指标（额外收费）则保留 15 个月的历史数据。对于可选的指标导出，您可以配置您想要的任何保留期，并且将按标准 S3 存储收费。"
    },
    {
        "query":"S3 Storage Lens 与 S3 Inventory 有什么区别？",
        "intention":"知识问答",
        "reply":"S3 清单针对 S3 存储桶或共享前缀提供对象及其相应元数据的列表，可用于执行存储的对象级分析。S3 Storage Lens 提供按组织、账户、区域、存储类、存储桶和前缀级聚合的指标，可以使组织范围内的存储可见性得到改善。"
    },
    {
        "query":"S3 Storage Lens 和 S3 存储类分析 (SCA) 之间的区别是什么？",
        "intention":"知识问答",
        "reply":"S3 存储类分析通过根据过去 30 至 90 天的单个存储桶/前缀/标签内的对象级访问模式创建对象年龄组，为最佳存储类提供建议。S3 Storage Lens 提供有关提高成本效率和应用数据保护最佳实践的方法的日常组织级建议，以及按账户、区域、存储类、存储桶或前缀（可用于 S3 Storage Lens 高级指标）的额外细化建议。"
    },
    {
        "query":"什么是存储类分析？",
        "intention":"知识问答",
        "reply":"使用存储类分析，您可以分析存储访问模式，以确定适合您的存储的最佳存储类。这一 S3 功能可自动识别不频繁访问模式，从而帮助您将存储转换为 S3 Standard-IA。您可以配置存储类分析策略来监视整个存储桶、前缀或对象标签。在观察到不频繁访问模式后，您可以根据结果轻松地创建新的 S3 生命周期策略。存储类分析还以可视化方式在 AWS 管理控制台上提供您每天的存储使用情况，您还可以将报告导出至 S3 存储桶，以便使用所选的 Amazon QuickSight 等商业智能工具进行分析。\n要想了解更多信息并开始使用，请访问 [S3 存储类分析用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/analytics-storage-class.html)。"
    },
    {
        "query":"存储类分析多久更新一次？",
        "intention":"知识问答",
        "reply":"存储类分析在 S3 管理控制台中每天更新，但对存储类转换的最初建议在 30 天后提供。"
    },
    {
        "query":"什么是“随时查询”功能？",
        "intention":"知识问答",
        "reply":"Amazon S3 允许客户对存储数据运行复杂的查询，无需将数据移动到独立的分析平台。随时查询 Amazon S3 数据的功能可以大大提升性能，降低利用 S3 作为数据湖的分析解决方案的成本。S3 提供多种随时查询选项，包括 S3 Select、Amazon Athena 和 Amazon Redshift Spectrum，使您能够从中选择最适合您的使用案例的选项。您甚至可以将 Amazon S3 Select 与 AWS Lambda 搭配使用，来构建无服务器应用程序，此类应用程序可有效利用 S3 Select 提供的随时处理功能。"
    },
    {
        "query":"什么是 S3 Select？",
        "intention":"知识问答",
        "reply":"S3 Select 是 Amazon S3 的一项功能，可以使用简单的 SQL 表达式轻松地从对象的内容中检索特定数据，而无需检索整个对象。S3 Select 简化了扫描对象内容并将其筛选成更小且具有针对性的数据集的流程，并将这一性能提升高达 400%。借助 S3 Select，您还可以对 Amazon S3 中的日志文件执行操作调查，无需操作或管理计算集群。\n您可以使用 S3 Select 通过 SQL 子句（如 SELECT 和 WHERE）从以 CSV、JSON 或 Apache Parquet 格式存储的对象中检索一部分数据。此方法也适用于通过 GZIP 或 BZIP2 压缩的对象（仅对于 CSV 和 JSON 对象）和服务器端加密对象。\n您可以将 S3 Select 与 AWS Lambda 结合使用来构建无服务器应用程序，此类应用程序可使用 S3 Select 有效且轻松地检索 Amazon S3 中的数据，而不是检索和处理整个对象。您也可以将 S3 Select 与大数据框架（例如 Presto、Apache Hive 和 Apache Spark）结合使用，来扫描和筛选 Amazon S3 中的数据。\n如需了解更多信息，请访问  [S3 Select 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html)。"
    },
    {
        "query":"什么是 Amazon Athena？",
        "intention":"知识问答",
        "reply":"Amazon Athena 是一项交互式查询服务，让您能够轻松[使用标准 SQL 查询分析 Amazon S3 中的数据](https://aws.amazon.com/cn/athena/)。Athena 是无服务器式服务，因此您无需设置或管理基础设施即可马上开始分析数据。您甚至无需将数据加载到 Athena 中，因为它可以直接处理所有 S3 存储类中存储的数据。要开始使用，您只需登录到 Athena 管理控制台，定义架构，然后开始查询即可。Amazon Athena 使用 Presto 并为标准 SQL 提供了完整的支持，可处理 CSV、JSON、ORC、Apache Parquet 和 Avro 等各种标准数据格式。Athena 不仅是快速、临时查询的理想选择，可与 Amazon QuickSight 集成轻松实现可视化，而且还能处理复杂的分析，包括大型联接、窗口函数和数组。"
    },
    {
        "query":"什么是 Amazon Redshift Spectrum？",
        "intention":"知识问答",
        "reply":"Amazon Redshift Spectrum 是 Amazon Redshift 的一项功能，借助这项功能，您可以对 [Amazon S3 中的 EB 级非结构化数据运行查询](https://aws.amazon.com/cn/redshift/features/)，而无需执行加载或 ETL 操作。当您发布查询时，查询会进入 Amazon Redshift SQL 终端节点，该终端节点会生成查询方案并对其进行优化。Amazon Redshift 会确定哪些数据存储在本地以及哪些数据存储在 Amazon S3 中，然后生成一种方案来尽可能减少需要读取的 Amazon S3 数据量，从共享资源池中请求 Redshift Spectrum 工作线程来读取和处理 Amazon S3 中的数据。\nRedshift Spectrum 可根据需要扩展到数千个实例，因此，无论数据大小如何，查询都会快速运行。而且，您可以像现在针对 Amazon Redshift 查询所做的一样，针对 Amazon S3 数据使用完全相同的 SQL，并可使用相同的商业智能工具连接到同一 Amazon Redshift 终端节点。Redshift Spectrum 可以实现单独的存储和计算，从而让您能够逐一单独扩展。您可以根据需要设置多个 Amazon Redshift 群集来查询 Amazon S3 数据湖，从而提供高可用性和无限制的并发度。借助 Redshift Spectrum，您可以灵活地将数据以您想要的格式存储在您想要的位置，并在需要时即时用于处理。\n[S3 复制时间控制](https://aws.amazon.com/cn/s3/faqs#S3_Replication_Time_Control) | [S3 多区域访问点](https://aws.amazon.com/cn/s3/faqs#S3_Multi-Region_Access_Points)"
    },
    {
        "query":"什么是 Amazon S3 复制？",
        "intention":"知识问答",
        "reply":"[Amazon S3 复制](https://aws.amazon.com/cn/s3/features/replication/)支持跨 Amazon S3 存储桶自动以异步方式复制对象。配置为用于对象复制的存储桶可以由相同的 AWS 账户拥有，也可以由不同的 AWS 账户拥有。您可以将写入存储桶的新对象复制到不同 AWS 区域之间（S3 跨区域复制）或同一 AWS 区域内（S3 同区域复制）的一个或多个目标存储桶。您还可以复制现有存储桶内容（S3 批量复制），包括现有对象、之前复制失败的对象以及从其他源复制的对象。要了解更多信息，请访问 [S3 复制用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html)。"
    },
    {
        "query":"什么是 Amazon S3 跨区域复制 (CRR)？",
        "intention":"知识问答",
        "reply":"CRR 是 Amazon S3 的一项功能，可在不同 AWS 区域的存储桶之间自动复制数据。利用 CRR，您可以使用 S3 对象标签设置存储桶级别、共享前缀级别或对象级别的复制。您可以使用 CRR 在不同的地理区域中提供低延迟的数据访问。如果您需要遵循将数据副本存储在相距数百公里的不同地点的合规性要求，CRR 还可以帮助您达成这一目标。您可以使用 CRR 更改复制对象的账户所有权，以防数据意外删除。 要了解更多信息，请访问 [S3 CRR 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html#crr-scenario)。"
    },
    {
        "query":"什么是 Amazon S3 同区域复制（SRR）？",
        "intention":"知识问答",
        "reply":"SRR 是 Amazon S3 的一项功能，可在同一 AWS 区域内的存储桶之间自动复制数据。利用 SRR，您可以使用 S3 对象标签设置存储桶级别、共享前缀级别或对象级别的复制。您可以使用 SRR 在相同 AWS 区域内创建数据的一个或多个副本。SRR 可在原始数据所在的区域内将数据副本保存在单独的 AWS 账户中，从而帮助您获得数据主权并满足合规性要求。您可以使用 SRR 更改复制对象的账户所有权，以防数据意外删除。您也可以使用 SRR 轻松汇总来自不同 S3 存储桶的日志以进行区域内处理，或配置测试环境与开发环境之间的实时复制。要了解更多信息，请访问 [S3 SRR 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication.html#srr-scenario)。"
    },
    {
        "query":"如何启用 Amazon S3 复制（跨区域复制和同区域复制）功能？",
        "intention":"知识问答",
        "reply":"您可以使用 S3 对象标签在 S3 存储桶级别、共享前缀级别或对象级别配置 Amazon S3 复制（CRR 和 SRR）功能。在同一或不同 AWS 区域中指定目标存储桶用于复制，这样就可以在源存储桶上添加复制配置。\n您可以使用 S3 控制台、API、AWS CLI、AWS SDK 或 AWS CloudFormation 来启用复制。要启用复制功能，必须对源存储桶和目标存储桶都启用版本控制功能。要了解更多信息，请访问 Amazon S3 文档中的[S3 复制功能设置概览](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"如何使用 S3 批量复制？",
        "intention":"知识问答",
        "reply":"您首先需要在存储桶级别启用 S3 复制。请参考上一个问题以了解如何执行此操作。然后，您可以在创建新的复制配置、从复制配置页面或从 S3 Batch Operations Create Job（S3 批量操作创建作业）页面更改复制规则中的复制目标后，在 S3 控制台中启动 S3 批量复制作业。或者，您可以通过 AWS CLI 或 SDK 启动 S3 批量复制作业。要了解更多信息，请访问 Amazon S3 文档中的 [S3 复制](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"我可以对 S3 生命周期规则使用 S3 复制功能吗？",
        "intention":"知识问答",
        "reply":"借助 S3 复制功能，您可以制定复制规则，将对象复制到同一区域或其他区域中的另一个存储类中。您无法复制生命周期操作，如果您希望对源存储桶和目标存储桶应用相同的生命周期配置，那么请在两个存储桶上启用相同的生命周期配置。\n例如，您可以配置生命周期规则，将数据从 S3 Standard 存储类迁移到 S3 Standard-IA 或 S3 One Zone-IA 存储类，或将数据归档到目标存储桶上的 S3 Glacier 存储类。\n如果您为目标存储桶配置了 S3 生命周期，我们建议在批量复制作业处于活跃状态时禁用生命周期规则，以保持源存储桶和目标存储桶中对象的非当前版本和当前版本之间的奇偶校验。  \n   \n 有关生命周期配置的更多信息，请参阅 [S3 复制文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-and-other-bucket-configs.html)。"
    },
    {
        "query":"我可以跨 AWS 账户使用复制功能来防止恶意或意外删除吗？",
        "intention":"知识问答",
        "reply":"是的，对于 CRR 和 SRR，您可以跨 AWS 账户设置复制功能，将复制的数据存储在目标区域的不同账户中。您可以在复制配置中使用所有权覆盖来维护源和目标之间的不同所有权堆栈，并将目标账户所有权授予复制的存储。"
    },
    {
        "query":"如果使用跨区域复制，对象标签也会复制吗？",
        "intention":"知识问答",
        "reply":"使用跨区域复制可以跨 AWS 区域复制对象标签。已启用跨区域复制的用户需要具有新的权限才能复制标签。有关设置跨区域复制的更多信息，请访问 [Amazon S3 文档](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html)中的[如何设置跨区域复制](http://docs.aws.amazon.com/AmazonS3/latest/dev/crr-how-setup.html)。"
    },
    {
        "query":"是否可以将删除标记从一个存储桶复制到另一个存储桶？",
        "intention":"知识问答",
        "reply":"可以，如果在复制配置中启用了删除标记复制，则可以将删除标记从源位置复制到目标位置。复制删除标记时，Amazon S3 将表现为在两个存储桶中都删除了对象。您可以为新的或现有的复制规则启用删除标记复制。您可以使用基于前缀的复制规则将删除标记复制应用于整个存储桶或具有特定前缀的 Amazon S3 对象。Amazon S3 复制不支持基于对象标签的复制规则的删除标记复制。要了解有关启用删除标记复制的更多信息，请参阅[将删除标记从一个存储桶复制到另一个存储桶](https://docs.aws.amazon.com/AmazonS3/latest/dev/delete-marker-replication.html)。"
    },
    {
        "query":"我可以将数据从其他 AWS 区域复制到中国区域吗？ 客户可以将数据从一个中国区域存储桶复制到中国之外的区域吗？",
        "intention":"知识问答",
        "reply":"不能，目前不支持在 AWS 中国区域和中国之外的 AWS 区域使用 Amazon S3 复制。您只能在中国区域内复制。"
    },
    {
        "query":"我可以复制现有对象吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 S3 复制，以在存储桶之间复制现有数据。要了解详情，请访问 [S3 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html)。"
    },
    {
        "query":"如果对象最初无法复制，我可以重新尝试复制吗？",
        "intention":"知识问答",
        "reply":"可以。您可以使用 S3 批量复制来重新复制最初无法复制的对象。要了解详情，请访问 [S3 用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-batch-replication-batch.html)。"
    },
    {
        "query":"S3 复制支持的加密类型有哪些？",
        "intention":"知识问答",
        "reply":"S3 复制支持 S3 提供的所有加密类型。S3 提供服务器端加密和客户端加密 — 前者要求 S3 为您加密对象，后者时用于在数据上传到 S3 之前在客户端对数据进行加密。对于服务器端加密，S3 提供了三种加密方式：使用 Amazon S3 托管密钥的服务器端加密（SSE-S3），使用存储在 AWS 密钥管理服务的 KMS 密钥的服务器端加密（SSE-KMS），以及使用客户提供的密钥的服务器端加密（SSE-C）。关于这些加密类型及其工作原理的详细信息，请访问[详细说明加密使用的 S3 文档。](https://docs.aws.amazon.com/AmazonS3/latest/userguide/UsingEncryption.html)"
    },
    {
        "query":"跨账户数据复制如何定价？",
        "intention":"知识问答",
        "reply":"借助 S3 复制，您可以配置源存储桶和目标存储桶归不同 AWS 账户所有的跨账户复制。不包括 S3 存储和适用的检索费用，在使用 S3 复制时，客户需要支付复制 PUT 请求和从 S3 到目标区域的区域间数据传出费用。如果您在复制规则上启用了 S3 复制时间控制 (S3 RTC)，您将看到与 S3 RTC 特定相关的不同数据传出和复制 PUT 请求费用。对于跨账户复制，源账户支付所有数据传输（S3 RTC 和 S3 CRR）的费用，目标账户支付复制 PUT 请求的费用。数据传输费仅适用于 S3 跨区域复制（S3 CRR）和 S3 复制时间控制（S3 RTC），S3 同区域复制（S3 SRR）不产生数据传输费。\n如果您使用 S3 批量复制跨账户复制对象，除了复制 PUT 请求和数据传输 OUT 费用外，您还将产生 S3 分批操作费用（请注意，S3 RTC 不适用于批量复制）。分批操作费用包括作业和对象费用，分别基于作业数量和处理的对象数量。此外，如果您选择使用 Amazon S3 生成的清单，您将根据源存储桶中的对象数量产生清单费用。  \n   \n 访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)了解关于 S3 复制定价的更多详细信息。"
    },
    {
        "query":"什么是 Amazon S3 复制时间控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制提供可预测的复制性能，并帮助您满足合规或业务需求。S3 复制时间控制旨在实现数秒内复制大多数对象，15 分钟内复制 99.99% 的对象。S3 复制时间控制由[服务等级协议](https://aws.amazon.com/cn/s3/sla-rtc/)（SLA）承诺提供支持，在任何计费月份中，对于每个复制区域，99.9% 的对象将在 15 分钟内复制。复制时间适用于所有 S3 复制功能。要了解更多信息，请访问[复制文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication.html)。"
    },
    {
        "query":"如何启用 Amazon S3 复制时间控制？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制作为每个复制规则的一个选项启用。您可以使用 S3 复制时间控制创建新的 S3 复制策略，或者在现有策略上启用该功能。您可以使用 S3 控制台、API、AWS CLI、AWS SDK 或 AWS CloudFormation 来配置复制。要了解更多信息，请访问《Amazon S3 开发人员指南》中的[设置复制功能概述](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-how-setup.html)。"
    },
    {
        "query":"我可以使用 S3 复制时间控制在中国区域内部和区域之间进行数据复制吗？",
        "intention":"知识问答",
        "reply":"是的，您可以启用 Amazon S3 复制时间控制，在 AWS 中国（宁夏）和中国（北京）区域内部和其之间进行数据复制。"
    },
    {
        "query":"什么是 Amazon S3 复制指标和事件？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制在 Amazon S3 控制台和 Amazon CloudWatch 中提供了四个详细指标：待处理操作、待处理字节、复制延迟和操作复制失败。您可以使用这些指标监控待复制操作总数和待复制对象的大小、源存储段和目标存储段之间的复制延迟以及每条复制规则中未成功复制的操作数。此外，您可以设置 *s3:Replication* 类型的 Amazon S3 事件通知，以获取有关复制失败的对象和失败原因的更多信息。我们建议使用 [Amazon S3 复制失败原因](https://docs.aws.amazon.com/AmazonS3/latest/userguide/replication-failure-codes.html)快速诊断错误并进行修复，然后使用 S3 批量复制重新复制失败的对象。最后，如果您启用了 S3 Replication Time Control (S3 RTC)，您将在复制一个对象的时间超过 15 分钟时收到 S3 事件通知，并在该对象成功复制到其目的地时收到另一条通知。"
    },
    {
        "query":"如何启用 Amazon S3 复制指标和事件？",
        "intention":"知识问答",
        "reply":"可以为每个新的复制规则或现有复制规则启用 Amazon S3 复制指标和事件，默认情况下，已为 S3 复制时间控制启用的规则启用它们。您可以通过 Amazon S3 控制台和 Amazon CloudWatch 访问 S3 复制指标。与其他 Amazon S3 事件一样，S3 复制事件可以通过 Amazon Simple Queue Service (Amazon SQS)、Amazon Simple Notiﬁcation Service (Amazon SNS) 或 AWS Lambda 获得。要了解更多信息，请访问《Amazon S3 开发人员指南》中的[使用复制指标监控进度和 Amazon S3 事件通知](https://docs.aws.amazon.com/AmazonS3/latest/dev/replication-metrics.html)。"
    },
    {
        "query":"失败操作复制指标显示了哪些信息？",
        "intention":"知识问答",
        "reply":"失败操作复制指标将显示特定复制规则每分钟复制失败的操作总数。该指标将每分钟刷新一次，对每个失败的操作发出 +1，对成功的操作发出 0，如果在该分钟内没有执行任何复制操作，则不发出任何指标。每当操作未能成功复制时，都会发出此指标。"
    },
    {
        "query":"我能否使用 Amazon S3 复制指标和事件来跟踪 S3 批量复制？",
        "intention":"知识问答",
        "reply":"您无法使用待处理字节、待处理操作和复制延迟等指标来跟踪 S3 批量复制进度。但是，您可以使用失败操作复制指标来监控无法通过 S3 批量复制成功复制的现有对象。此外，您还可以使用 S3 批量操作完成报告来跟踪通过 S3 批量复制的对象。"
    },
    {
        "query":"Amazon S3 复制指标在哪里发布？",
        "intention":"知识问答",
        "reply":"待处理字节、待处理操作和复制延迟指标在源 AWS 账户和目标 AWS 区域中发布。但是，失败操作复制指标在源 AWS 账户和源 AWS 区域，而不是目标 AWS 区域发布。造成这种情况的主要原因有两个。首先，如果在目标区域发布失败操作复制指标，则在目标存储桶配置错误时，客户将看不到该指标。例如，如果客户在复制配置中错误地键入了目标存储桶名称，并且由于未找到目标存储桶而复制失败，则客户将无法看到此指标的任何值，因为找不到目标存储桶时，目标区域将是未知的。其次，如果客户要复制到可选择加入的目标区域，例如香港或巴林，则在复制失败的情况下，如果源账户未选择加入目标区域，则客户将看不到任何指标。"
    },
    {
        "query":"什么是 Amazon S3 复制时间控制服务等级协议 (SLA)？",
        "intention":"知识问答",
        "reply":"Amazon S3 复制时间控制旨在实现 15 分钟内复制 99.99% 的对象，由服务等级协议提供支持。如果在每月计费周期中，每个复制区域对 15 分钟内复制的对象少于 99.9%，那么 S3 RTC SLA 将针对任何复制时间超过 15 分钟的对象提供服务积分。服务积分包括与不符合 SLA 的对象相关的所有相关复制费用百分比，包括 RTC 费用、复制带宽和请求费用，以及在受影响的每月计费周期中与将副本存储在目标区域相关的成本。要了解详情，请阅读 [S3 复制时间控制 SLA](https://aws.amazon.com/cn/s3/sla-rtc/)。"
    },
    {
        "query":"S3 复制和 S3 复制时间控制的定价是多少？",
        "intention":"知识问答",
        "reply":"对于 S3 复制（跨区域复制和同区域复制），您需要为所选目标 S3 存储类中的存储支付 S3 费用，还要支付主副本、复制 PUT 请求的存储费用以及适用的不频繁访问存储检索费用。对于 CRR，您还需要支付从 S3 到目标区域的区域间数据传出费用。 S3 复制指标的费率与 Amazon CloudWatch 自定义指标费率相同。此外，当您使用 S3 复制时间控制时，您还需要支付复制时间控制数据传输费。有关更多信息，请访问 [Amazon S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。\n如果源对象是通过分段上传功能上传的，则使用相同数量的段和段大小进行复制。例如，通过分段上传功能上传的 100GB 对象（800 个段，每段 128MB）在复制时会产生与 802 个请求（800 个上传段请求 + 1 个初始分段上传请求 + 1 个完成分段上传请求）关联的请求成本。您会产生 0.00401 USD（802 个请求 x 0.005 USD/1000 个请求）的请求费用和（如果在不同的 AWS 区域之间进行复制）2.00 USD（0.020 USD/GB 传输 x 100GB）的区域间数据传输费用。复制后，该 100GB 数据会产生基于目标区域的存储费用。"
    },
    {
        "query":"什么是 S3 多区域访问点？",
        "intention":"知识问答",
        "reply":"在访问跨多个 AWS 区域复制的数据集时，[Amazon S3 多区域访问点](https://aws.amazon.com/cn/s3/features/multi-region-access-points/)可将性能提高多达 60%。基于 AWS Global Accelerator，S3 多区域接入点会考虑网络拥塞和请求应用程序的位置等因素，通过 AWS 网络将您的请求动态路由到数据的最低延迟副本。这种自动路由允许您利用 AWS 的全球基础设施，同时保持简单的应用程序架构。"
    },
    {
        "query":"为什么应该使用 S3 多区域访问点？",
        "intention":"知识问答",
        "reply":"S3 多区域访问点可加速并简化多区域应用程序的存储。通过将 S3 请求动态路由到复制数据集，S3 多区域访问点减少了请求延迟，使应用程序运行速度提高 60%。S3 多区域访问点还可以帮助您构建弹性多区域和多账户应用程序，这些应用程序可以更好地防范意外或未经授权的数据删除。借助 S3 多区域访问点，您还可利用 AWS 的全球基础设施，同时为应用程序保持与区域无关的简单架构。"
    },
    {
        "query":"S3 多区域访问点的工作原理是什么？",
        "intention":"知识问答",
        "reply":"多区域访问点将客户端请求动态路由到一个或多个底层 S3 存储桶。您可以将多区域访问点配置为每个 AWS 区域（最多 20 个 AWS 区域）跨一个存储桶进行路由。创建多区域访问点时，S3 会自动生成与 DNS 兼容的名称。此名称将用作客户端可以使用的全局端点。当客户端向该端点发出请求时，S3 会将这些请求动态路由到多区域访问点配置中指定的一个底层存储桶。 基于互联网的请求被载入 AWS 全球网络，以避免互联网上的网段拥塞，从而减少网络延迟和抖动，同时提高性能。基于 AWS Global Accelerator，通过互联网访问 S3 的应用程序可以通过 S3 多区域访问点将性能进一步提高多达 60%。\n要直接控制此路由，您可以在主动-主动或主动-被动配置中运行 S3 多区域访问点。在主动-被动配置中，您可以使用 S3 多区域访问点失效转移控制来启动失效转移，以在几分钟内将 S3 数据访问请求流量转移到所选的备用 AWS 区域和账户。\n在主动-主动配置中，S3 多区域访问点会考虑网络拥塞和请求应用程序的位置等因素，通过 AWS 网络将您的请求动态路由到最近的数据副本。S3 多区域访问点会将您的请求路由到离您的客户端最近的 AWS 位置，然后通过全球私有 AWS 网络路由到 S3。\n在任何一种配置中，S3 多区域访问点都允许您利用 AWS 的全球基础设施，同时保持简单的应用程序架构。"
    },
    {
        "query":"S3 多区域访问点失效转移控制的工作原理是什么？",
        "intention":"知识问答",
        "reply":"默认情况下，S3 多区域访问点根据主动-主动配置中的网络延迟将请求路由到离客户端最近的底层存储桶。例如，您可以在美国东部（弗吉尼亚州北部）和亚太地区（孟买）配置一个具有底层存储桶的多区域访问点。通过此配置，您在北美的客户端将路由到美国东部（弗吉尼亚州北部），而您在亚洲的客户将路由到亚太地区（孟买）。这降低了对 S3 请求的延迟，提高了应用程序的性能。如果您更喜欢主动-被动配置，则所有 S3 数据请求流量都可以通过 S3 多区域访问点路由到作为活动区域的美国东部（弗吉尼亚州北部），并且不会将任何流量路由到亚太地区（孟买）。如果需要按计划或在计划外将所有 S3 数据请求流量失效转移到亚太地区（孟买），您可以启动失效转移，在几分钟内即可切换到亚太地区（孟买）并将其作为新的活动区域。美国东部（弗吉尼亚州北部）正在进行的任何现有上传或下载都将继续完成，并且通过 S3 多区域访问点的所有新 S3 数据请求流量将路由到亚太地区（孟买）。"
    },
    {
        "query":"S3 传输加速与 S3 多区域访问点有何不同？",
        "intention":"知识问答",
        "reply":"S3 多区域访问点和 S3 传输加速提供类似的性能优势。 您可以使用 S3 Transfer Acceleration 来加速使用 AWS 全球网络与 Amazon S3 之间的内容传输。S3 Transfer Accelerator 可以帮助加速较大对象与单个 Amazon S3 存储桶之间的远距离传输。借助 S3 多区域访问点，您可以使用 AWS 全球网络执行类似的加速传输，但跨多个 AWS 区域中的许多 S3 存储桶，以处理进出 S3 的基于互联网、基于 VPC 和本地的请求。 当您将 S3 多区域访问点与 S3 Cross Replication 结合使用时，您将为 S3 多区域访问点提供将您的请求动态路由到来自多个位置的客户端的应用程序的最低延迟数据副本的功能。"
    },
    {
        "query":"如何开始使用 S3 多区域访问点和失效转移控制？",
        "intention":"知识问答",
        "reply":"S3 控制台提供了一个简单的引导式工作流程，只需三个简单的步骤即可快速设置在 S3 上运行多区域存储所需的一切。首先，创建一个 Amazon S3 多区域访问点端点并指定您要在其间进行复制和失效转移的 AWS 区域。通过输入创建时拥有多个 AWS 账户的账户 ID，您可以将多个 AWS 账户中的存储桶添加到新的 S3 多区域访问点。其次，对于 S3 多区域访问点端点后面的每个 AWS 区域和 S3 存储桶，指定它们的路由状态是主动还是被动，其中主动 AWS 区域可以接受 S3 数据请求流量，被动区域在您启动失效转移之前不会被路由。第三，配置您的 S3 Cross-Region Replication 规则来同步你在不同区域和/或账户之间的 S3然后，您可以随时在 AWS 区域之间启动失效转移，以转移您的 S3 数据请求并监控您的 S3 流量转移到 Amazon CloudWatch 中的新活动 AWS 区域。或者，您也可以使用 AWS CloudFormation 自动配置多区域存储。CloudFormation 支持在 S3 上设置多区域存储所需的所有构建数据块，包括 S3 多区域访问点，允许您在 S3 控制台之外自动执行可重复的设置过程。"
    },
    {
        "query":"什么是 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"借助 S3 Object Lambda，您能够将自己的代码添加到 S3 GET、LIST 和 HEAD 请求中，以便在数据返回到应用程序时修改和处理数据。您可以使用自定义代码来修改 S3 GET 请求返回的数据，以便实施筛选行、动态调整图像大小、隐去机密数据等操作。您还可以使用 S3 Object Lambda 来修改 S3 LIST 请求的输出，以创建存储桶中对象的自定义视图，并使用 S3 HEAD 请求修改对象元数据（如对象名称和大小）。S3 Object Lambda 可以帮助您轻松满足任何应用程序的独特数据格式要求，而无需构建和运行额外的基础设施（例如代理层），也不必创建和维护数据的多个衍生副本。S3 Object Lambda 使用 AWS Lambda 函数自动处理标准 S3 GET、LIST 或 HEAD 请求的输出。AWS Lambda 是一种无服务器计算服务，无需管理底层计算资源，即可运行客户定义的代码。\n只需在 AWS 管理控制台中单击几下，即可配置 Lambda 函数并将其附加到 S3 Object Lambda 服务访问点。此后，S3 将自动调用 Lambda 函数来处理通过 S3 Object Lambda 端点检索到的任何数据，并将转换后的结果返回应用程序。您可以编写和执行自己的自定义 Lambda 函数，根据您的特定使用案例定制 S3 Object Lambda 的数据转换。\n可以通过 S3 管理控制台、开发工具包或 API 来开始使用 S3 Object Lambda。如需了解更多信息，请访问 [S3 Object Lambda 页面，](http://aws.amazon.com/s3/features/object-lambda)或 S3 Object Lambda [用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"为何应使用 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"如果您想通过 S3 GET、LIST 或 HEAD 请求内联处理数据，则应使用 S3 Object Lambda。您可以使用 S3 Object Lambda 在多个应用程序间共享数据的单个副本，这样既无需构建和运行自定义处理基础设施，也无需存储数据的衍生副本。例如，使用 S3 Object Lambda 处理 S3 GET 请求后，您可以对敏感数据设置掩码以满足合规性要求、重组原始数据以便其与机器学习应用程序兼容、筛选数据以限制对 S3 对象中特定内容的访问，或满足各种其他使用案例需求。您可以使用 S3 Object Lambda 来丰富对象列表，方法是查询包含额外对象元数据的外部索引，筛选和屏蔽对象列表以只包含具有特定对象标签的对象，或者向对象列表中的所有对象名称添加文件扩展名。例如，如果您有一个包含多个离散数据集的 S3桶，您可以使用 S3 Object Lambda 来根据请求者筛选 S3 LIST 响应。\n只需在 Amazon S3 管理控制台中单击几下即可设置 S3 Object Lambda。请参阅[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)，了解更多信息。"
    },
    {
        "query":"S3 Object Lambda 的工作原理是什么？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 使用您指定的 Lambda 函数来处理 GET、LIST 和 HEAD 请求的输出。对某个 Lambda 函数进行定义（以处理请求的数据）后，可以将该函数附加到 S3 Object Lambda 访问点。通过 S3 Object Lambda 访问点发出的 S3 GET、LIST 和 HEAD 请求现在将调用指定的 Lambda 函数。然后，Lambda 将获取客户端请求的 S3 对象并处理该对象。处理完成后，Lambda 会将处理过的对象流式传输回调用客户端。请参阅 S3 Object Lambda [用户指南，了解更多信息](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"如何开始使用 S3 Object Lambda？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 可以通过多种方式进行设置。您可以通过导航到 Object Lambda Access Point（Object Lambda 访问点）选项卡，在 S3 控制台中设置 S3 Object Lambda。接下来，创建一个 S3 Object Lambda 访问点（您想要 S3 针对 GET、LIST 和 HEAD 请求执行的 Lambda 函数）和一个支持的 S3 访问点。向所有资源授予与 Object Lambda 交互的权限。最后，更新您的开发工具包和应用程序，以便通过新的 S3 Object Lambda 访问点使用您选择的语言开发工具包从 S3 检索数据。 在发出请求时，您可以使用 S3 对象 Lambda 访问点的别名。S3 对象 Lambda 访问点的别名将自动生成，而且对于通过 S3 对象 Lambda 访问的数据，这些别名可以与 S3 存储桶名称互换。对于现有的 S3 对象 Lambda 访问点，别名将自动分配并随时可供使用。[AWS 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/olap-writing-lambda.html)中提供了 Lambda 函数实施的示例，可以帮助您开始使用。\n您还可以使用 AWS CloudFormation 来自动化您的 S3 Object Lambda 配置。使用 AWS CloudFormation 模板时，账户中部署的 Lambda 函数会将 S3 对象传回请求客户端或应用程序，而不进行任何更改。您可以添加自定义代码，以便在数据返回到应用程序时修改和处理数据。要了解更多信息，请访问《S3 Object Lambda [用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)》。"
    },
    {
        "query":"我可以使用 S3 Object Lambda 执行哪些类型的操作？",
        "intention":"知识问答",
        "reply":"可以使用 S3 Object Lambda 执行 Lambda 函数中支持的任何操作。这为您处理请求提供了各种可用选项。您可以使用自己的 Lambda 函数来针对 GET、LIST 和 HEAD 请求运行自定义计算，从而根据应用程序的需要灵活处理数据。Lambda 处理时间最多不得超过 60 秒。有关更多详细信息，请参阅 [S3 Object Lambda 文档](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"S3 Object Lambda 支持哪些 S3 请求类型？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 支持 GET、LIST 和 HEAD 请求。对 S3 Object Lambda 访问点发出的任何其他 S3 API 调用都将返回标准 S3 API 响应。如需了解有关 S3 Object Lambda 的更多信息，请参阅[用户指南](https://docs.aws.amazon.com/AmazonS3/latest/userguide/transforming-objects.html)。"
    },
    {
        "query":"S3 Object Lambda 函数失败时会发生什么情况？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 函数失败时，您将收到请求响应，响应中会说明失败详情。与 Lambda 函数的其他调用一样，AWS 还可以代表您自动监控函数，通过 Amazon CloudWatch 报告指标。为了帮助您排查失败问题，Lambda 会记录函数处理的所有请求，并将由代码生成的日志自动存储在 Amazon CloudWatch Logs 中。有关访问 AWS Lambda 的 CloudWatch 日志的更多信息，请访问 [CloudWatch 文档](https://docs.aws.amazon.com/lambda/latest/dg/monitoring-functions-logs.html)。"
    },
    {
        "query":"S3 Object Lambda 是否会影响 S3 可用性 SLA 或 S3 持久性？",
        "intention":"知识问答",
        "reply":"S3 Object Lambda 可以连接 Amazon S3、AWS Lambda，也可以连接您选择的其他 AWS 服务，以交付与请求应用程序相关的对象。与 S3 Object Lambda 结合使用的所有 AWS 服务将继续受其各自服务等级协议 (SLA) 的管控。例如，如有任何 AWS 服务不遵守其服务承诺，您将有资格获得该服务的 SLA 中记录的服务积分。创建 S3 Object Lambda 访问点不会影响对象的持久性。不过，S3 Object Lambda 会调用您指定的 AWS Lambda 函数，而且您必须确保指定的 Lambda 函数正确并适用。请[在此处查看最新的 Amazon S3 SLA](https://aws.amazon.com/s3/sla/)。"
    },
    {
        "query":"S3 Object Lambda 的成本是多少？",
        "intention":"知识问答",
        "reply":"使用 S3 Object Lambda 时，对于通过 S3 Object Lambda 返回的每 GB 数据，您需按 GB 支付费用。您还需要为基于请求类型（GET、LIST 和 HEAD 请求）的请求付费，并在您指定的函数运行以处理请求的数据时收取 AWS Lambda 计算费用。如需查看定价详细信息和示例，请参阅 [S3 定价页面](https://aws.amazon.com/cn/s3/pricing/)。\n了解有关数据管理、安全性、访问管理、分析等功能的更多信息。\n立即获取 AWS 免费套餐并开始试用 Amazon S3。\n在 AWS 控制台中开始使用 Amazon S3 进行构建。"
    },
    {
        "query":"什么是 Amazon Detective？",
        "intention":"知识问答",
        "reply":"Amazon Detective 使您可以更轻松地分析、调查和快速确定潜在安全问题或可疑活动的根本原因。Amazon Detective 会自动从您的 AWS 资源中收集日志数据并使用机器学习、统计分析和图论来构建一组关联的数据，使您能够轻松地进行更快、更有效的安全调查。"
    },
    {
        "query":"Amazon Detective 有哪些主要优势？",
        "intention":"知识问答",
        "reply":"Amazon Detective 可以简化调查流程，帮助安全团队更快、更有效地进行调查。Amazon Detective 的预建数据聚合、摘要和上下文可以帮助您快速分析和确定可能存在的安全问题的性质和严重程度。Amazon Detective 最多可以将聚合数据保留一年，并通过一组可视化视图轻松提供，这些可视化视图会显示选定时间范围内的活动类型和数量变化，并将这些变化与安全检测结果联系起来。您无需预付任何费用，只需为分析的事件付费，不需要额外部署软件，也不需要启用日志馈送。"
    },
    {
        "query":"Amazon Detective 如何帮助您分析安全调查？",
        "intention":"知识问答",
        "reply":"Amazon Detective 从 AWS CloudTrail、Amazon Virtual Private Cloud（Amazon VPC）流日志、Amazon GuardDuty 检测结果、AWS Security Hub 检测结果和 Amazon Elastic Kubernetes Service（Amazon EKS）审计日志中提取基于时间的事件，例如登录尝试、API 调用和网络流量。Detective 创建了一个行为图，该图利用机器学习（ML）来创建一个统一的交互式视图，显示一段时间内的资源行为及其交互情况，特别是针对这些基于时间的事件。通过浏览行为图，您可以分析安全事件，例如登录尝试失败、可疑 API 调用或结果组，以帮助您调查 AWS 安全检测结果的根本原因。"
    },
    {
        "query":"什么是结果组？它们如何缩短调查检测结果的时间？",
        "intention":"知识问答",
        "reply":"威胁行为者在试图入侵您的 AWS 环境时通常会执行一系列操作，这可能会导致您的 AWS 资源中出现多个安全检测结果。结果组是与您应共同调查的单个潜在安全事件相关的安全检测结果和资源的集合。检测结果组可以帮助缩短分类时间，因为您不必单独调查每个安全检测结果。您可以从结果组开始调查，这样可以更全面地了解事件，还可以通过交互式可视化来探索具体的检测结果和资源。有关更多信息，请阅读[分析结果组](https://docs.aws.amazon.com/detective/latest/userguide/groups-about.html)。"
    },
    {
        "query":"可以免费试用吗？",
        "intention":"知识问答",
        "reply":"可以，Amazon Detective 新账户均可以免费试用 30 天。免费试用期间，您可以使用所有功能集。"
    },
    {
        "query":"Amazon Detective 是区域性服务还是全球性服务？",
        "intention":"知识问答",
        "reply":"Amazon Detective 需要按区域启用，使您能够快速分析每个区域内所有账户的活动。这样可以确保分析的所有数据以区域为基础，且不会跨越 AWS 区域边界。"
    },
    {
        "query":"Amazon Detective 支持哪些区域？",
        "intention":"知识问答",
        "reply":"提供 Amazon Detective 的区域的列表：[AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)"
    },
    {
        "query":"如何开始使用 Amazon Detective？",
        "intention":"知识问答",
        "reply":"只需在 AWS 管理控制台中单击几次，即可启用 Amazon Detective。启用后，Amazon Detective 会自动将数据整理成图表模型，且随着新数据变得可用，该模型会不断更新。您可以体验 Amazon Detective 并开始调查潜在安全问题。"
    },
    {
        "query":"如何启用 Amazon Detective？",
        "intention":"知识问答",
        "reply":"您可以在 AWS 管理控制台中启用 Amazon Detective，也可以使用 Amazon Detective API 来启用它。如果您已在使用 Amazon GuardDuty 或 AWS Security Hub 控制台，则应使用与 Amazon GuardDuty 或 AWS Security Hub 中的管理账户来启用 Amazon Detective 以获得最佳跨服务体验。"
    },
    {
        "query":"可以使用 Amazon Detective 管理多个账户吗？",
        "intention":"知识问答",
        "reply":"可以，Amazon Detective 是一项多账户服务，可以将来自受监控成员账户的数据聚合到同一区域内的一个管理账户下。您可以按照在 Amazon GuardDuty 和 AWS Security Hub 中配置主账户和成员账户的方式配置多账户监控部署。"
    },
    {
        "query":"Amazon Detective 可以分析哪些数据来源？",
        "intention":"知识问答",
        "reply":"Amazon Detective 让客户能够查看与 Amazon Virtual Private Cloud（Amazon VPC）流日志、AWS CloudTrail 日志、Amazon Elastic Kubernetes Service（Amazon EKS）审计日志、AWS Security Hub 检测结果以及 Amazon GuardDuty 检测结果相关的摘要和分析数据。"
    },
    {
        "query":"如果我没有启用 Amazon GuardDuty，可以使用 Amazon Detective 吗？",
        "intention":"知识问答",
        "reply":"Amazon Detective 要求您至少在 48 小时之前为账户启用 Amazon GuardDuty，然后才能为这些账户启用 Detective。但是，您可以使用 Amazon Detective 进行更多调查，而不仅仅是 Amazon GuardDuty 的调查结果。Amazon Detective 提供有关 AWS 账户、EC2 实例、AWS 用户、角色和 IP 地址的行为和交互的详细摘要、分析结果和可视化内容。此信息对于了解安全问题或运营账户活动非常有用。"
    },
    {
        "query":"Amazon Detective 开始工作的速度有多快？",
        "intention":"知识问答",
        "reply":"Amazon Detective 在启用后立即开始收集日志数据，提供对所提取数据的可视摘要和分析。Amazon Detective 还可以将近期活动与在账户监控两周后建立的历史基准进行比较。"
    },
    {
        "query":"是否可以从 Amazon Detective 导出原始日志数据？",
        "intention":"知识问答",
        "reply":"Amazon Detective 将分析您的 AWS CloudTrail 日志、Amazon VPC 流日志和 Amazon EKS 审计日志，但不提供原始日志导出服务。AWS 支持您通过其他服务导出这些日志。"
    },
    {
        "query":"Amazon Detective 存储哪些数据，是否加密，是否可以控制启用的数据来源？",
        "intention":"知识问答",
        "reply":"Amazon Detective 遵循 AWS [责任共担模式](https://aws.amazon.com/cn/compliance/shared-responsibility-model/)，包括有关数据保护的法规和准则。启用后，Amazon Detective 将针对已启用的任何账户处理来自 AWS CloudTrail 日志、Amazon VPC 流日志、Amazon EKS 审计日志、从集成 AWS 服务发送到 AWS Security Hub 的检测结果以及 Amazon GuardDuty 检测结果的数据。"
    },
    {
        "query":"如果启用 Amazon Detective，是否会影响现有的 AWS 工作负载的性能或可用性？",
        "intention":"知识问答",
        "reply":"由于 Amazon Detective 直接从 AWS 服务检索日志数据和检测结果，因此 Amazon Detective 对 AWS 基础设施的性能或可用性没有任何影响。"
    },
    {
        "query":"Amazon Detective 与 Amazon GuardDuty 和 AWS Security Hub 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon GuardDuty 是一种威胁检测服务，可持续监控恶意活动和未经授权的行为，从而保护您的 AWS 账户和工作负载。借助 AWS Security Hub，您可以设置单个位置，对来自多个 AWS 服务（如 Amazon GuardDuty、Amazon Inspector 和 Amazon Macie），以及来自 AWS 合作伙伴解决方案的安全警报或检测结果进行聚合、组织和设置优先级。Amazon Detective 旨在简化调查安全检测结果和确定根本原因的过程。Amazon Detective 会分析来自多个数据来源（例如 Amazon VPC 流日志、AWS CloudTrail 日志、Amazon EKS 审计日志、从集成 AWS 服务发送到 AWS Security Hub 的检测结果以及 Amazon GuardDuty 检测结果）的数万亿个事件并自动创建图形模型，为您提供有关您的资源、用户及其不同时间的交互情况的统一交互式视图。"
    },
    {
        "query":"如何让 Amazon Detective 停止查看我的日志和数据来源？",
        "intention":"知识问答",
        "reply":"借助 Amazon Detective，您可以分析和直观呈现来自 AWS CloudTrail 日志、Amazon VPC 流日志、Amazon EKS 审计日志、从集成 AWS 服务发送到 AWS Security Hub 的检测结果以及 Amazon GuardDuty 检测结果的安全数据。要让 Amazon Detective 停止分析您账户的这些日志和检测结果，请使用 API 或通过 Amazon Detective 的 AWS 管理控制台的设置部分禁用此项服务。"
    },
    {
        "query":"在如何调查安全问题方面，Amazon Detective 提供哪些指导？",
        "intention":"知识问答",
        "reply":"Amazon Detective 提供各种可视化内容，展示有关 AWS 资源（例如 AWS 账户、EC2 实例、用户、角色、IP 地址和 Amazon GuardDuty 检测结果）的上下文和见解。每种可视化内容都旨在回答您在分析检测结果和相关活动时可能遇到的特定问题。每种可视化内容都提供文本指导，清楚地说明如何解释面板并使用其信息来回答您的调查问题。"
    },
    {
        "query":"Amazon Detective 如何与其他 AWS 安全服务（例如 Amazon GuardDuty 和 AWS Security Hub）集成？",
        "intention":"知识问答",
        "reply":"Amazon Detective 通过支持与 Amazon GuardDuty 和 AWS Security Hub 之间的控制台集成来支持跨服务用户工作流程。这两项服务都在其控制台中提供链接，将您从选定的检测结果直接重定向到 Amazon Detective 页面，其中包含为调查选定检测结果而精选的一系列可视化内容。Amazon Detective 中的检测结果详细信息页面已根据检测结果的时间范围进行了调整，并显示与检测结果关联的相关数据。"
    },
    {
        "query":"如何将 Amazon Detective 的调查结果与补救和响应工具集成？",
        "intention":"知识问答",
        "reply":"各种合作伙伴安全解决方案提供商已集成了 Amazon Detective，支持在其自动化手册和编排中启用调查步骤。这些产品在其响应工作流程中提供链接，将用户重定向到 Amazon Detective 页面，其中包含为调查工作流程中确定的检测结果和资源精选的可视化内容。"
    },
    {
        "query":"适用于 AWS Security Hub 的 Amazon Detective 是如何运作的？",
        "intention":"知识问答",
        "reply":"启用后，Amazon Detective 会自动持续分析并关联与 AWS Security Hub 集成的 AWS 服务的用户、网络和配置活动。Amazon Detective 通过名为 AWS 安全检测结果的可选数据来源，自动摄取从 AWS 安全服务发送到 AWS Security Hub 的安全检测结果。"
    },
    {
        "query":"什么是 AWS 安全检测结果？",
        "intention":"知识问答",
        "reply":"AWS Security Hub 支持与多个 AWS 服务集成。由于预计 Amazon Macie 会发现敏感数据，因此您自动选择加入与 Security Hub 集成的所有其他 AWS 服务。如果您已打开 Security Hub 和任何集成服务，这些服务会将检测结果发送到 Security Hub。Detective 会提取这些检测结果并将其添加到您的图表中，这样您就可以对所有集成的 AWS 服务进行安全调查。支持的服务包括 AWS Conﬁg、AWS Firewall Manager、Amazon GuardDuty、AWS Health、AWS Identity and Access Management Access Analyzer、Amazon Inspector、AWS IoT Device Defender、Amazon Macie 和 AWS Systems Manager 补丁管理器。"
    },
    {
        "query":"我需要开启 AWS 安全检测结果吗？",
        "intention":"知识问答",
        "reply":"不，您无需启用或配置 AWS 安全检测结果。只需在 Amazon Detective 控制台或 API 中启用 AWS Security Hub 和 AWS 安全检测结果数据来源即可。Amazon Detective 对 AWS 安全检测结果的使用设计为不影响您的 AWS 安全服务的性能，因为 Amazon Detective 使用独立和重复的日志流来处理安全检测结果。这样，Amazon Detective 对 AWS 安全检测结果的使用不会增加使用 AWS Security Hub 或任何集成 AWS 安全服务的成本。"
    },
    {
        "query":"我已在使用 Amazon Detective；怎样才能在 Amazon Detective 上打开 AWS 安全检测结果支持？",
        "intention":"知识问答",
        "reply":"使用 Amazon Detective 的现有客户将需要在其帐户的 Amazon Detective 控制台上打开 AWS 安全检测结果。客户可以更改此选择，并利用单击 Amazon Detective 控制台启用/禁用 AWS 安全检测结果。"
    },
    {
        "query":"是否必须在每个 AWS 区域中分别启用 AWS 安全检测结果？",
        "intention":"知识问答",
        "reply":"是。必须分别在每个 AWS 区域启用 AWS 安全检测结果。"
    },
    {
        "query":"适用于 Amazon EKS 审计日志的 Amazon Detective 工作原理是什么？",
        "intention":"知识问答",
        "reply":"启用之后，Amazon Detective 自动地连续分析并关联您的 Amazon EKS 工作负载中的用户、网络和配置活动。Amazon Detective 自动提取 Amazon EKS 审计日志，并通过 Amazon VPC 流日志关联用户活动与 AWS CloudTrail 管理事件和网络活动，而无需您手动启用或存储这些日志。该服务从这些日志收集关键安全信息，并将它们保存在安全行为图形数据库中，以便快速地对十二个月的活动进行交叉引用访问。Amazon Detective 提供数据分析和可视化层，以依托行为图形数据库帮助您回答常见安全问题，使您能够更快地调查与 Amazon EKS 工作负载相关的潜在恶意行为。"
    },
    {
        "query":"Amazon Detective 可让您了解 AWS Fargate 上的 Amazon EKS 工作负载、EC2 上的或 ES Anywhere 的非托管 Kubernetes？",
        "intention":"知识问答",
        "reply":"此功能目前仅支持在您的 AWS 账户中的 EC2 实例上运行的 Amazon EKS 部署。"
    },
    {
        "query":"是否必须在每个 AWS 区域中分别启用 Amazon EKS 审计日志？",
        "intention":"知识问答",
        "reply":"是。Amazon EKS 审计日志必须单独地在每个 AWS 区域中启用。"
    },
    {
        "query":"AWS Storage Gateway 是什么？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 是一项混合云存储服务，可让您从本地访问几乎不受限制的云存储。Storage Gateway 提供了一组标准的存储协议（例如 iSCSI、SMB 和 NFS），使您可以使用 AWS 存储而无需重写现有应用程序。该服务通过将经常访问的数据缓存在本地，并将数据安全且持久地存储在 Amazon 云存储服务中来提供低延迟性能。Storage Gateway 通过仅发送更改的数据并压缩数据来优化向 AWS 的数据传输。Storage Gateway 还与 Amazon S3 和 Amazon FSx for Windows File Server 云存储（使您的数据可用于云处理）、AWS Identity and Access Management (AWS IAM)（用于保护对服务和资源的访问管理）、AWS Key Management Service (AWS KMS)（用于加密云中的静态数据）、Amazon CloudWatch（用于监控）以及 AWS CloudTrail（用于记录账户活动）进行了原生集成。"
    },
    {
        "query":"为什么应该使用 AWS Storage Gateway？",
        "intention":"知识问答",
        "reply":"Storage Gateway 使您可以利用 AWS 存储服务来减少本地存储空间和相关成本。"
    },
    {
        "query":"AWS Storage Gateway 支持哪些使用案例？",
        "intention":"知识问答",
        "reply":"Storage Gateway 支持四种主要的混合云使用案例：(1) 将备份和存档迁移至云；(2) 通过云支持的文件共享减少本地存储；(3) 为本地应用程序提供对存储在 AWS 中的数据的低延迟访问；以及 (4) 对处理前和处理后工作流程的数据湖访问。"
    },
    {
        "query":"AWS Storage Gateway 如何为本地应用程序提供对云存储的访问权限？",
        "intention":"知识问答",
        "reply":"根据您的使用案例，Storage Gateway 为您的本地应用程序提供三种类型的存储接口：文件、卷和磁带。\n[Amazon S3 文件网关](https://aws.amazon.com/cn/storagegateway/file/s3/)使您可以使用文件协议（例如，Network File System (NFS) 和 Server Message Block (SMB) 在 Amazon Simple Storage Service (S3) 中存储和检索对象。您可以直接在 S3 中访问通过 S3 文件网关写入的对象。\n[Amazon FSx 文件网关](https://aws.amazon.com/cn/storagegateway/file/fsx/) 使您能够使用 SMB 协议在 Amazon FSx for Windows File Server 中存储和检索文件。通过 Amazon FSx 文件网关写入的文件可直接在 Amazon FSx for Windows File Server 中访问。\n[卷网关](https://aws.amazon.com/cn/storagegateway/volume/)使用 iSCSI 连接为您的本地部署应用程序提供块存储。卷上的数据存储在 Amazon S3 中，您可以获取卷的时间点副本，这些副本将作为 Amazon EBS 快照存储在 AWS 中。您还可以获取卷的副本，并使用 AWS Backup 管理保留的卷副本。您可以将 EBS 快照还原到卷网关卷或 EBS 卷。\n[磁带网关](https://aws.amazon.com/cn/storagegateway/vtl/) 可为您的备份应用程序提供 iSCSI 虚拟磁带库 (VTL) 接口，该接口由虚拟介质更换器、虚拟磁带驱动器和虚拟磁带组成。虚拟磁带存储在 Amazon S3 中，并且可以存档到 Amazon S3 Glacier 或 Amazon S3 Glacier Deep Archive。"
    },
    {
        "query":"如何使用 AWS Storage Gateway 服务？",
        "intention":"知识问答",
        "reply":"您可以通过两个接触点来使用该服务：AWS 管理控制台和可用作虚拟机 (VM) 或物理硬件设备的网关。\n您可以使用 AWS 管理控制台下载虚拟设备网关或购买硬件设备、配置存储以及管理和监控该服务。网关会通过提供标准存储接口来将应用程序连接到 AWS 存储。它可以提供透明缓存和高效的数据传输，并与 AWS 监控和安全服务相集成。\n要开始使用，请[注册 AWS 账户](https://console.aws.amazon.com/storagegateway/home)，然后访问 [AWS Storage Gateway 管理控制台](https://console.aws.amazon.com/storagegateway/home)，以下载网关 VM 设备或购买硬件设备。安装网关后，您可以通过我们的激活流程将其与您的 AWS 账户关联起来。激活后，您可以配置网关，以连接到相应的存储类型。对于 Amazon S3 文件网关，您可以使用 IAM 角色配置映射到所选的 S3 存储桶或 S3 前缀的文件共享。对于 Amazon FSx 文件网关，您可以通过使用服务账户附加其中包含一个或多个文件共享的现有 Amazon FSx 文件系统来配置文件共享。对于卷网关，您可以创建并挂载卷，以作为 iSCSI 设备。对于磁带网关，您可以连接备份应用程序，以创建和管理磁带。配置完毕后，您便可开始使用网关对 AWS 存储执行数据读写操作。您可以通过 AWS 管理控制台监控数据传输和存储接口的状态。此外，您还可以使用 API 或软件开发工具包以编程方式管理应用程序与网关的交互。"
    },
    {
        "query":"我可以在哪里部署 Storage Gateway 设备？",
        "intention":"知识问答",
        "reply":"在本地部署。您可以在 VMware ESXi、Microsoft Hyper-V 或 Linux KVM 上部署包含 Storage Gateway 软件的虚拟机，也可以将 Storage Gateway 部署为[硬件设备](https://aws.amazon.com/cn/storagegateway/hardware-appliance/)。您还可以在 VMware Cloud on AWS 中部署 Storage Gateway VM，或在 Amazon EC2 中将 Storage Gateway VM 部署为 AMI。"
    },
    {
        "query":"什么是 Amazon S3 文件网关？",
        "intention":"知识问答",
        "reply":"Amazon S3 文件网关向 Amazon S3 提供基于文件的接口，显示为网络文件共享。它使您可以通过标准文件存储协议存储和检索 Amazon S3 对象。文件网关让基于文件的现有应用程序或设备可以使用安全且持久的云存储，而无需做出任何修改。借助 S3 文件网关，已配置好的 S3 存储桶将可以作为网络文件系统 (NFS) 挂载点或服务器消息块 (SMB) 共享文件使用。您的应用程序通过 NFS 或 SMB 对文件及目录执行读写操作，从而作为文件服务器与网关交互。反过来，网关会将这类文件操作转换为针对 S3 存储桶的对象请求。您最近使用的数据会缓存在网关上以实现低延迟访问，并且您的数据中心和 AWS 之间的数据传输由网关完全托管并优化。在 S3 中，您可以直接访问对象，也可以使用 S3 生命周期策略和 S3 跨区域复制 (CRR) 等 S3 功能对其进行管理。您可以在本地或 EC2 中运行 S3 文件网关。"
    },
    {
        "query":"什么是 Amazon FSx 文件网关？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关优化了对 Amazon FSx 上的 Windows 文件共享的本地访问，使用户可以轻松地以低延迟访问 FSx for Windows File Server 数据并节省共享带宽。用户可以从他们可以访问的常用数据的本地缓存中获益，从而实现更快的性能并减少数据传输流量。读取和写入文件等文件系统操作都在本地缓存中执行，而 Amazon FSx 文件网关则是在后台将更改的数据同步到 FSx for Windows File Server。有了这些功能，您就可以在 AWS 中整合有关 FSx for Windows File Server 的所有本地文件共享数据，并从受保护的完全托管型弹性文件系统中获益。"
    },
    {
        "query":"什么是磁带网关？",
        "intention":"知识问答",
        "reply":"磁带网关是一种基于云的虚拟磁带库 (VTL)。它向您的备份应用程序提供 VTL 接口，该接口由介质更换器和磁带驱动器组成。您可以使用 AWS 管理控制台在您的虚拟磁带库中创建虚拟磁带。您的备份应用程序可以通过使用虚拟介质更换器将虚拟磁带安装到虚拟磁带驱动器，对虚拟磁带执行数据读写操作。虚拟磁带由备份应用程序通过其标准介质库存程序进行搜索。虚拟磁带可立即访问，并由 Amazon S3 提供支持。您还可以将磁带存档。存档的磁带存储在 Amazon S3 Glacier 或 Amazon S3 Glacier Deep Archive 中。"
    },
    {
        "query":"什么是卷网关？",
        "intention":"知识问答",
        "reply":"卷网关可提供 iSCSI 目标，使您可以通过本地或 EC2 应用程序服务器创建数据块存储卷并将其挂载为 iSCSI 设备。卷网关以缓存或存储模式运行。\n在任一模式下，您都可以拍摄卷的时间点快照并将其存储在 AWS 中作为 Amazon EBS 快照，从而能够创建既节省了空间又控制了版本的卷副本，以满足数据保护、恢复、迁移和各种其他复制数据的需求。"
    },
    {
        "query":"AWS Storage Gateway 可提供哪些优势？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 提供了一系列功能，使您可以在现有应用程序和工作流内有效利用 AWS 存储。它提供了一组标准协议（例如 iSCSI、SMB 和 NFS），使您可以使用现有应用程序，而无需做出任何更改。通过其本地缓存，网关允许对最近使用的数据进行低延迟访问。网关优化了到 AWS 存储的数据传输，例如通过智能缓冲来优化传输、通过上传管理机制来应对网络变化以及提供带宽管理。网关提供了一种有效机制，让您可以利用最适合您的使用案例的各种存储服务在 AWS 中存储数据。网关易于部署，可以使用现有虚拟基础设施和管理程序投资，也能将其安装在数据中心或远程办公室作为硬件设备。作为 VM 或在硬件设备上运行的网关软件是无状态的，这使您可以根据存储需求的变化，轻松创建和管理您的新网关实例。最后，该服务还与多种 AWS 管理服务进行了原生集成，例如 Amazon CloudWatch、AWS CloudTrail、AWS Key Management Service (KMS) 和 AWS Identity and Access Management (IAM)。"
    },
    {
        "query":"通过 AWS Backup 能管理哪些 AWS Storage Gateway 类型？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS Backup 管理卷网关缓存和存储的卷模式的备份和保留策略。"
    },
    {
        "query":"每个网关的本地缓存最大可支持大小是多少？",
        "intention":"知识问答",
        "reply":"在虚拟机上运行的网关的本地缓存最大可支持大小为 64TiB。"
    },
    {
        "query":"什么是 Amazon S3 文件网关？",
        "intention":"知识问答",
        "reply":"[Amazon S3 文件网关](https://aws.amazon.com/cn/storagegateway/file/s3/)是 AWS Storage Gateway 服务的一项配置，它为应用程序提供一个文件接口，将文件作为对象无缝存储到 Amazon S3 中，并使用行业标准文件协议访问这些文件。"
    },
    {
        "query":"Amazon S3 文件网关可以用来做什么？",
        "intention":"知识问答",
        "reply":"[Amazon S3 文件网关](https://aws.amazon.com/cn/storagegateway/file/s3/)的使用案例包括：(a) 将本地文件数据迁移到 Amazon S3，同时保留对最近访问的数据的快速本地访问；(b) 将本地文件数据作为对象备份在 Amazon S3（包括 Microsoft SQL Server 和 Oracle 数据库与日志）中，能够使用 S3 功能，例如生命周期管理和跨区域复制；(c) 混合云工作流程，将本地应用程序生成的数据提供给 AWS 服务（例如机器学习、大数据分析或无服务器功能）进行处理。"
    },
    {
        "query":"使用文件网关将数据存储在 S3 中具有哪些优势？",
        "intention":"知识问答",
        "reply":"通过 Amazon S3 文件网关，您基于文件的现有应用程序、设备和工作流程能够使用 Amazon S3，而无需进行任何修改。Amazon S3 文件网关安全并持久地将文件内容和元数据存储为对象，同时为本地应用程序提供对缓存数据的低延迟访问。"
    },
    {
        "query":"S3 文件网关支持哪些 Amazon S3 存储类？",
        "intention":"知识问答",
        "reply":"Amazon S3 文件网关支持 Amazon S3 Standard、S3 Intelligent-Tiering、S3 标准 – 不频繁访问（S3 标准 - IA）和 S3 单区 - IA。有关存储类的详细信息，请参阅 [Amazon S3 文档](https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-class-intro.html)。您为网关创建的对象配置初始存储类，然后可以使用存储桶生命周期策略将文件从 Amazon S3 移动到 Amazon S3 Glacier。如果应用程序尝试访问通过 Amazon 文件网关存储且现在位于 Amazon S3 Glacier 中的文件/对象，则会收到一般 I/O 错误。"
    },
    {
        "query":"Amazon S3 文件网关支持哪些协议？",
        "intention":"知识问答",
        "reply":"Amazon S3 文件网关支持 Linux 客户端使用网络文件系统 (NFS) 版本 3 和 4.1 连接到网关，还支持 Windows 客户端使用服务器消息块 (SMB) 版本 2 和 3 连接到网关。"
    },
    {
        "query":"如何创建和使用文件共享？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS 管理控制台或服务 API 创建 NFS 或 SMB 共享文件，并将共享文件与新的或现有 Amazon S3 存储桶关联起来。要从您的应用程序访问共享文件，您可以使用标准的 UNIX 或 Windows 命令通过应用程序进行挂载。为方便起见，管理控制台中显示了每个环境的示例命令行。"
    },
    {
        "query":"有什么选项可用于配置 NFS 共享文件？",
        "intention":"知识问答",
        "reply":"您可以通过管理控制（例如限制对特定 NFS 客户端或网络的访问、只读或读写权限，或启用用户权限压缩）来配置 NFS 共享文件。"
    },
    {
        "query":"有什么选项可用于配置 SMB 共享文件？",
        "intention":"知识问答",
        "reply":"您可以将 SMB 共享文件配置为仅允许 Active Directory (AD) 用户访问，或为您组织中的用户提供经过身份验证的访客访问权限。您可以将文件共享的访问权限进一步限制为只读、读写或仅面向特定的 AD 用户和组。"
    },
    {
        "query":"对于 SMB 文件共享，Amazon S3 文件网关是否支持基于访问权限的枚举？",
        "intention":"知识问答",
        "reply":"支持，您可以为 SMB 文件共享配置基于访问权限的枚举，以阻止用户看到根据其访问权限他们不能打开的文件夹和文件。您还可以控制用户是否可浏览 Amazon S3 文件网关上的文件共享。"
    },
    {
        "query":"Amazon S3 文件网关是否支持与本地 Microsoft Active Directory (AD) 集成？",
        "intention":"知识问答",
        "reply":"支持，Amazon S3 文件网关可以与本地 Microsoft Active Directory 集成，也可以与云中的 Active Directory 解决方案（如托管的 Microsoft AD）集成。"
    },
    {
        "query":"能否在没有 Active Directory 的情况下导出 SMB 文件共享？",
        "intention":"知识问答",
        "reply":"是。您可以使用访客用户名和密码导出 SMB 文件共享。在设置可供访客访问的共享文件之前，您需要使用控制台或服务 API 更改默认密码。"
    },
    {
        "query":"能否在同一个网关上混合导出 NFS 与 SMB 共享文件？",
        "intention":"知识问答",
        "reply":"能。"
    },
    {
        "query":"能否在同一个存储桶上导出 NFS 和 SMB 文件共享？",
        "intention":"知识问答",
        "reply":"不可以，当前存储为 S3 对象元数据的文件元数据（如所有权）无法跨不同协议进行映射。"
    },
    {
        "query":"Amazon S3 文件网关如何访问 S3 存储桶？",
        "intention":"知识问答",
        "reply":"Amazon S3 文件网关使用 AWS Identity and Access Management (IAM) 角色访问 S3 存储桶。您可以[自行设置 IAM 角色](https://docs.aws.amazon.com/storagegateway/latest/userguide/managing-gateway-file.html#grant-access-s3)，也可以让 AWS Storage Gateway 管理控制台自动为您设置。对于自动设置，AWS Storage Gateway 将在您的账户中创建一个新 IAM 角色，并将其与某个 IAM 访问策略关联起来，以访问您的 S3 存储桶。IAM 角色和 IAM 访问策略都是在您的账户中创建的，因此您可以充分地管理它们。"
    },
    {
        "query":"应用程序如何访问共享文件？",
        "intention":"知识问答",
        "reply":"要使用共享文件，您可以使用标准的 UNIX 或 Windows 命令通过应用程序进行挂载。为方便起见，管理控制台中显示了示例命令行。"
    },
    {
        "query":"我的文件共享如何映射到 S3 存储桶？",
        "intention":"知识问答",
        "reply":"文件共享可以映射到 S3 存储桶的根，或者可以映射到 S3 存储桶内的 S3 前缀。如果您在创建文件共享时指定 S3 前缀，则您会将文件共享绑定到 S3 前缀。如果您没有在创建文件共享时创建 S3 前缀，则文件共享会绑定到 S3 存储桶的根。"
    },
    {
        "query":"我是否能为文件共享指定自定义名称？",
        "intention":"知识问答",
        "reply":"是，文件共享名称不必与 S3 存储桶或 S3 前缀名称相同。"
    },
    {
        "query":"我是否能更改文件共享名称？",
        "intention":"知识问答",
        "reply":"是，您可以更改您的文件共享名称。"
    },
    {
        "query":"文件和对象之间有何关系？",
        "intention":"知识问答",
        "reply":"文件作为对象存储在 S3 存储桶中，并且您可以为文件网关创建的对象配置初始存储类。文件和对象之间是一对一的关系，并且您可以为 Amazon S3 文件网关创建的对象配置初始存储类。\n对象键是从文件系统内的文件路径派生而来的。例如，如果您有一个主机名称为 *file.amazon.com* 的网关，并且已映射  *my-bucket/my-prefix*，则文件网关将提供一个名为 *file.amazon.com:/export/my-bucket/my-prefix* 的挂载点。如果您随后将其挂载到本地的 */mnt/my-bucket/my-prefix* 并在 */mnt/my-bucket/my-prefix/dir* 目录中创建了一个名为 file.html 的文件，则该文件将作为对象存储在 my-bucket 存储桶中，且其密钥为 *my-prefix/dir/file.html*。创建稀疏文件会导致 S3 中出现非稀疏零填充对象。"
    },
    {
        "query":"Amazon S3 文件网关支持哪些文件系统操作？",
        "intention":"知识问答",
        "reply":"您的客户端可以创建、读取、更新和删除文件及目录。 您的客户端还可以更改文件和文件夹的权限和所有权。文件作为单独的对象存储在 Amazon S3 中。目录使用与 S3 控制台相同的语法，作为文件夹对象托管在 S3 中。不支持符号链接和硬链接。如果尝试创建链接，则会导致错误。 常见文件操作会更改文件元数据，因此会删除当前 S3 对象并创建新 S3 对象。\n重命名操作对于您的客户端来说比较常见，但是 S3 不支持对象重命名。当您对文件或目录进行重命名时，网关会执行复制输入请求，以根据新密钥在 S3 中创建对象的副本，然后删除原始对象。这样，您就不需要通过网络重新发送大型文件了。对包含大量文件的目录进行的重命名操作不会即刻完成，这将导致有 2 个数据副本存储在 S3 中，且目录中的操作将被阻止直至重命名操作完成。"
    },
    {
        "query":"我的客户端可以访问哪些文件系统元数据以及这些元数据存储在哪里？",
        "intention":"知识问答",
        "reply":"您的客户端可以访问包括所有权、权限和时间戳在内的 POSIX 样式元数据，它们都会持久地存储在 S3 内与该文件相关联的对象的用户元数据中。当您在现有存储桶上创建共享文件时，存储的元数据将被还原并可供客户端访问。"
    },
    {
        "query":"如何为上传到 S3 的文件设置 Content-Type？",
        "intention":"知识问答",
        "reply":"对于每个共享文件，您都可以在[创建后](http://docs.aws.amazon.com/storagegateway/latest/userguide/GettingStartedCreateFileShare.html)或[稍后启用该功能时](http://docs.aws.amazon.com/storagegateway/latest/userguide/managing-gateway-file.html#update-file-share)对已上传的对象启用 MIME 类型猜测。如果已启用，文件网关将使用文件扩展名来确定文件的 MIME 类型，并相应地为 S3 对象设置内容类型。如果您正在使用文件网关来管理通过 URL 直接访问或通过 Amazon CloudFront 分发的 S3 中的对象，这项功能就很有用。"
    },
    {
        "query":"是否可以使用 Amazon S3 文件网关直接访问存储在 S3 中的对象？",
        "intention":"知识问答",
        "reply":"是。对象存储到 S3 中后，您无需使用 Amazon S3 文件网关即可直接在 AWS 中访问这些对象，以便处理云内工作负载。您的对象会继承存储它们的 S3 存储桶的属性，例如生命周期管理和跨区域复制。\n需要使用共享文件才能访问的对象应仅由文件网关管理。如果直接覆盖或更新之前由 Amazon S3 文件网关写入的对象，则在通过文件共享访问该对象时，会导致未定义的行为。"
    },
    {
        "query":"如果存储桶已包含对象，该怎么办？",
        "intention":"知识问答",
        "reply":"如果您在配置存储桶以与 Amazon S3 文件网关一起使用时，它已包含对象，则会使用对象键将对象作为文件呈现给 NFS 和 SMB 客户端。这类文件将具有默认的文件系统元数据。\n为了减少 Amazon S3 请求的延迟和数量，当您明确列出文件或目录时，Amazon S3 文件网关会仅扫描与对象关联的文件元数据的标头。系统将在扫描过程中收集文件元数据，并且仅在读取对象时才下载文件内容。"
    },
    {
        "query":"网关如何访问存储桶？ 要下载整个存储桶或文件内容吗？",
        "intention":"知识问答",
        "reply":"网关不会自动下载存储桶中的全部对象或所有数据，只会在您的客户端明确访问数据时才会下载数据。此外，为了减少数据传输开销，文件网关采用分段上传和复制输入，因此只有文件中已更改的数据才会上传到 S3。"
    },
    {
        "query":"对于在网关外创建的对象，NFS 客户端可以访问哪些元数据？",
        "intention":"知识问答",
        "reply":"对于直接上传到 S3 存储桶的对象，即不使用文件网关和 NFS 共享，您可以配置默认的所有权和权限。"
    },
    {
        "query":"对于在网关外创建的对象，SMB 客户端可以访问哪些元数据？",
        "intention":"知识问答",
        "reply":"对于直接（即不使用 Amazon S3 文件网关和 SMB 共享）上传到 S3 存储桶的对象，所有权和权限等元数据将从对象的父文件夹中继承。共享根文件夹的权限是固定的，并且直接在根文件夹下创建的对象将继承这些固定权限。有关在网关外创建的对象的元数据设置，请参考相关文档。"
    },
    {
        "query":"是否可以将多个 NFS 客户端与一个 Amazon S3 文件网关配合使用？",
        "intention":"知识问答",
        "reply":"您可以使用多个 NFS 客户端来访问同一个文件网关。不过，对于任何 NFS 服务器而言，来自多个 NFS 客户端的并行修改会导致无法预测的行为。因此需要应用程序层面相互协作才能安全地实现这一目的。"
    },
    {
        "query":"S3 存储桶是否可以有多个写入器？",
        "intention":"知识问答",
        "reply":"否。建议您仅对 S3 存储桶中的对象使用一个写入器。如果直接覆盖或更新之前由文件网关写入的对象，则在通过文件共享访问该对象时，会导致未定义的行为。对同一对象的并行修改（例如同时通过 S3 API 和 Amazon S3 文件网关对某个对象进行修改）会导致无法预测的行为，因此我们不建议使用这种配置。"
    },
    {
        "query":"是否可以使用两个网关向同一个存储桶写入独立的数据？",
        "intention":"知识问答",
        "reply":"我们不建议为一个存储桶配置多个写入器，因为这会导致无法预测的结果。您可以通过应用程序工作流程来实施唯一的对象名称或前缀。当此类设置发生冲突时，S3 文件网关将发出运行状况通知。"
    },
    {
        "query":"是否可以使用多个网关从同一存储桶读取数据？",
        "intention":"知识问答",
        "reply":"可以，您可以在通过 Amazon S3 文件网关管理的存储桶上使用多个读取器。您可以将文件共享配置为只读模式，并允许多个网关从同一存储桶读取对象。此外，您还可以使用 [Storage Gateway 控制台](https://docs.aws.amazon.com/storagegateway/latest/userguide/managing-gateway-file.html#refresh-cache)（自动化的周期缓存刷新流程）或 [RefreshCache API](http://docs.aws.amazon.com/storagegateway/latest/APIReference/API_RefreshCache.html) 来刷新网关获取的对象清单。\n但请注意，如果您未将共享文件配置为只读模式，则 Amazon S3 文件网关不会监控这些读取器是否会意外向存储桶中写入内容，也不会限制它们意外向存储桶中写入内容。是否要通过应用程序维持一个写入器/多个读取器配置取决于您。"
    },
    {
        "query":"我能否使用 Amazon CloudWatch 监控共享文件？",
        "intention":"知识问答",
        "reply":"能，您可以使用 Amazon CloudWatch 指标监控共享文件的使用情况，并可以通过 CloudWatch Events 在完成文件操作时收到通知。要了解更多信息，访问[监控文件共享](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html)。"
    },
    {
        "query":"如何知晓文件在何时上传完成？",
        "intention":"知识问答",
        "reply":"当您使用 Amazon S3 文件网关将文件写入文件共享时，数据会首先存储在本地，然后异步上传到 S3 存储桶。单个文件上传完成后，您可以[通过 AWS CloudWatch Events](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html#get-notification) 请求通知。这些通知可用于触发其他工作流，如调用 AWS Lambda 函数或 Amazon EC2 Systems Manager 自动化，具体取决于 S3 中目前可用的数据。要了解更多信息，请参阅[文件上传通知的文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html#get-file-upload-notification)。"
    },
    {
        "query":"文件上传通知与 S3 事件通知有什么不同？",
        "intention":"知识问答",
        "reply":"文件上传通知为通过 S3 文件网关上传到 Amazon S3 的每个单独的文件提供通知。S3 事件通知提供的通知包括已部分上传的文件，因此无法通过 S3 事件通知确定文件上传是否完成。"
    },
    {
        "query":"如何知晓我的工作文件集在何时完成上传？",
        "intention":"知识问答",
        "reply":"当您使用 Amazon S3 文件网关将文件写入文件共享时，数据会首先存储在本地，然后异步上传到 S3 存储桶。工作文件集上传完成后，您可以[通过 Amazon CloudWatch Events 请求通知](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html#get-notification)。这些通知可用于触发其他工作流，如调用 AWS Lambda 函数或 Amazon EC2 Systems Manager 自动化，具体取决于 S3 中目前可用的数据。要了解更多信息，请参阅[工作文件集上传通知的文档](http://docs.aws.amazon.com/storagegateway/latest/APIReference/API_NotifyWhenUploaded.html)。"
    },
    {
        "query":"能否更新 Amazon S3 文件网关的存储桶视图以查看从基于对象的工作负载或其他文件网关创建的对象？",
        "intention":"知识问答",
        "reply":"能，您可以使用控制台（文件系统驱动型缓存刷新流程）或 RefreshCache API 来刷新 Amazon S3 文件网关获取的对象清单。RefreshCache API 操作完成后，您将[通过 AWS CloudWatch Events](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html#get-notification) 收到通知。这些通知可用于使用 Amazon Simple Notification Service (SNS) 发送电子邮件或使用更新后的内容触发本地处理。要了解更多信息，请参阅[文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html#refresh-cache-notification)。"
    },
    {
        "query":"我能否使用网关更新属于其他 AWS 账户的存储桶中的数据？",
        "intention":"知识问答",
        "reply":"能，您可以使用网关跨账户访问存储桶。要了解更多信息，请参阅[有关使用文件共享进行跨账户访问的文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/managing-gateway-file.html#cross-account-access)。"
    },
    {
        "query":"我能否使用网关访问申请方付款 S3 存储桶中的数据？",
        "intention":"知识问答",
        "reply":"能，您可以在创建共享文件时启用对[申请方付款 S3 存储桶](https://docs.aws.amazon.com/AmazonS3/latest/dev/RequesterPaysBuckets.html)的访问权限。作为请求者，您将需要支付与从申请方付款存储桶访问数据相关的费用。"
    },
    {
        "query":"如何为网关中的每个存储桶创建多个共享？",
        "intention":"知识问答",
        "reply":"您可以通过在文件共享创建过程中指定 S3 前缀的方式为一个 S3 存储桶创建多个文件共享。"
    },
    {
        "query":"可为每个网关创建多少文件共享？",
        "intention":"知识问答",
        "reply":"您最多可以为一个网关中的 S3 存储桶创建 10 个共享。我们不限制跨多个网关的每个存储桶的文件共享数量，但每个网关限制为 10 个共享。但是，我们建议为存储桶配置一个写入器，可以是 Amazon S3 文件网关，也可以是直接访问 S3 的客户端。"
    },
    {
        "query":"我能否更改文件共享名称？",
        "intention":"知识问答",
        "reply":"能，您可以更改文件共享的名称。"
    },
    {
        "query":"单个文件的大小上限是多少？",
        "intention":"知识问答",
        "reply":"单个文件的大小上限为 5TB，这同时也是 S3 中单个对象的大小上限。如果您写入的文件大于 5TB，则会收到“文件过大”这一错误消息，并且只有该文件的首个 5TB 的内容可以成功上传。"
    },
    {
        "query":"我的应用程序会在复制数据前检查存储大小，网关会返回多少存储空间？",
        "intention":"知识问答",
        "reply":"网关会返回大量存储空间 (8EB) 作为您的总容量。Amazon S3 不会限制总存储空间。"
    },
    {
        "query":"是否可以通过文件网关使用 Amazon S3 生命周期、跨区域复制和 S3 事件通知？",
        "intention":"知识问答",
        "reply":"是。您的生命周期管理、跨区域复制和 S3 事件通知存储桶策略可直接应用于通过 AWS Storage Gateway 存储到您的存储桶中的对象。\n您可以使用 S3 生命周期策略来更改对象的存储层、删除旧对象或对象版本。有对象因生命周期策略被删除时，您需要启用周期缓存刷新功能或调用 [RefreshCache API](http://docs.aws.amazon.com/storagegateway/latest/APIReference/API_RefreshCache.html) 将这些更改反映到您的 NFS 客户端。\n使用的 S3 存储桶是跨区域复制的目标时，您可能需要启用周期缓存刷新功能或使用 [RefreshCache API](http://docs.aws.amazon.com/storagegateway/latest/APIReference/API_RefreshCache.html) 确保网关缓存和 S3 存储桶保持同步。\n如果使用 S3 事件通知，您可能会收到网关创建了部分文件以确保数据在 S3 中的持久存储的事件。部分文件可能因一些原因而出现，例如需要释放缓存空间的网关，或写入文件的高速率。或者这部分文件可能不符合应用程序的一致性。"
    },
    {
        "query":"能否将 Amazon S3 文件网关与备份应用程序配合使用？",
        "intention":"知识问答",
        "reply":"Amazon S3 文件网关支持 SMB 版本 2 和 3 以及 NFS 版本 3、4.0 和 4.1。我们会继续对常见的备份应用程序进行测试。请通过 AWS Support 或您的 AWS 客户团队告诉我们您希望测试兼容性的任何特定应用程序。"
    },
    {
        "query":"能否使用 Amazon S3 文件网关将文件写入 EFS？",
        "intention":"知识问答",
        "reply":"不能。借助 Amazon S3 文件网关，您可以将文件作为对象存储在 S3 中。"
    },
    {
        "query":"何时应使用 Amazon S3 文件网关？何时应使用 S3 API？",
        "intention":"知识问答",
        "reply":"在您想使用标准的文件系统操作访问 S3 中的对象以将其作为文件时，您可以使用 Amazon S3 文件网关。此外，Amazon S3 文件网关还可提供低延迟本地访问和高效的数据传输。在您的应用程序不需要使用文件系统操作，且可以直接管理数据传输时，您可以使用 S3 API。"
    },
    {
        "query":"Amazon S3 文件网关如何管理本地缓存？ 哪些数据会存储在本地？",
        "intention":"知识问答",
        "reply":"该网关上的本地磁盘存储用于暂时存储需传输到 AWS 的更改数据，并且可以将数据缓存在本地以便实现低延迟的读取访问。文件网关会自动管理缓存，以根据客户端的读写操作来保留最近访问过的数据。只有在需要空间来存储访问时间更近的数据时，系统才会从缓存中清除旧数据。\n为最大限度提高写入性能，该网关使用回写机制，即先将数据保存到磁盘中，然后再异步上传到 S3 中。该网关从本地缓存提供数据，从而最大限度提高读取性能。如果本地缓存中没有相关数据，该网关将使用字节范围 GET 请求从 Amazon S3 高效地异步提取数据。\n本地缓存的大小一般会与您需要低延迟访问的、使用中的数据集对应。如果缓存太小，那么读取延迟就会增大，因为请求的数据必须从 S3 获取；而且如果没有空余缓存空间来在本地存储要上传到 S3 的数据，写入也可能会失败。"
    },
    {
        "query":"应该使用什么指导来预置网关缓存磁盘大小？ 如果预置的缓存磁盘较小，会怎样？",
        "intention":"知识问答",
        "reply":"您应当根据以下条件预置缓存：  \n 1/ 您需要低延迟访问的工作数据集的大小，以便您可以通过降低来自 S3 的数据请求频率来减少读取延迟，  \n 2/ 应用程序写入网关的文件的大小。\n如果在等待上传到 S3 时没有可用的缓存空间来本地存储数据，则较小的缓存磁盘可能导致写入过程中性能较差和失败。要了解有关监控缓存使用情况的更多信息，请参阅文档中的[监控文件共享](https://docs.aws.amazon.com/storagegateway/latest/userguide/monitoring-file-gateway.html)。"
    },
    {
        "query":"何时清除缓存中的数据？",
        "intention":"知识问答",
        "reply":"只有在需要空间来存储更多最近访问的数据时，才会清除通过应用程序或 Amazon S3 检索写入缓存的数据。"
    },
    {
        "query":"Amazon S3 文件网关是否会执行数据缩减（重复数据删除或压缩）？",
        "intention":"知识问答",
        "reply":"文件在不进行修改的情况下以一对一的方式映射到存储桶中的对象，这使您可以直接访问 S3 中的数据，而不需要使用网关或部署额外软件来解除数据冻结。\nAmazon S3 文件网关采用分段上传和复制输入，因此只有已更改的数据才能上传到 S3 中，这可以减少数据传输量。该网关不会自动下载存储桶中的全部对象或所有数据，只会在 NFS 客户端明确访问数据时才会下载数据。"
    },
    {
        "query":"是否可以将 Amazon S3 文件网关与 Amazon S3 Transfer Acceleration 配合使用？",
        "intention":"知识问答",
        "reply":"即使将存储桶配置用于 S3 Transfer Acceleration，文件网关也不会使用加速的终端节点。"
    },
    {
        "query":"Amazon S3 文件网关使用哪种加密方式保护数据？",
        "intention":"知识问答",
        "reply":"在该网关与 AWS 存储之间传输的所有数据均已使用 SSL 进行了加密。默认情况下，存储在 S3 中的所有数据均已使用 Amazon S3 托管加密密钥 (SSE-S3) 通过服务器端进行了加密。对于每个共享文件，您可以选择性地进行配置，以使用 SSE-KMS 通过 AWS KMS 托管密钥加密对象。要了解更多信息，请参阅《Storage Gateway 用户指南》中的“[使用 AWS Key Management System 加密数据](https://docs.aws.amazon.com/storagegateway/latest/userguide/encryption.html)”，其中包含有关使用该功能的重要详情。"
    },
    {
        "query":"什么是 Amazon FSx 文件网关？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关优化了对 Amazon FSx 上的 Windows 文件共享的本地访问，使用户可以轻松地以低延迟访问 FSx for Windows File Server 数据并节省共享带宽。用户可以从他们可以访问的常用数据的本地缓存中获益，从而实现更快的性能并减少数据传输流量。读取和写入文件等文件系统操作都在本地缓存中执行，而 Amazon FSx 文件网关则是在后台将更改的数据同步到 FSx for Windows File Server。有了这些功能，您就可以在 AWS 中整合有关 FSx for Windows File Server 的所有本地文件共享数据，并从受保护的完全托管型弹性文件系统中获益。"
    },
    {
        "query":"为什么应该使用 Amazon FSx 文件网关？",
        "intention":"知识问答",
        "reply":"很多本地桌面应用程序对延迟很敏感，当它们直接从远程位置访问 AWS 中的文件时，可能会对最终用户造成延迟和使性能下降。此外，使大量用户直接访问云中的数据可能会导致共享带宽资源（如 AWS Direct Connect 链接）拥塞。通过 Amazon FSx 文件网关，您可以将 Amazon FSx for Windows File Server 用于这些工作负载，且它可以帮助您在不影响您的应用程序或网络的情况下，用 AWS 中可扩展、高度可靠的完全托管型文件存储来替代本地存储。"
    },
    {
        "query":"Amazon FSx 文件网关如何解决本地应用程序的这些问题？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关提供一个 SMB 文件协议服务器供客户端连接，以及频繁使用数据的本地缓存，访问这些数据时所体验到的延迟与在 AWS 中相同。读取和写入文件等文件系统操作都在本地缓存中执行，而 Amazon FSx 文件网关则是在后台将更改的数据同步到 Amazon FSx for Windows File Server。Amazon FSx 文件网关还有助于最大程度减少数据传输量，同时优化 AWS 的网络带宽使用量。"
    },
    {
        "query":"如何使用 Amazon FSx 文件网关？",
        "intention":"知识问答",
        "reply":"要使用 Amazon FSx 文件网关，您至少需要一个正在运行的 Amazon FSx 文件系统，并确保可以通过 VPN 或 AWS Direct Connect 连接对 Amazon FSx for Windows File Server 进行本地访问。要开始使用 FSx for Windows File Server，请[在此](https://aws.amazon.com/cn/fsx/windows/getting-started/)查看文档说明。然后，您可以首先下载并部署 Amazon FSx 文件网关 VMware 虚拟设备或 AWS Storage Gateway 硬件设备到本地环境中。当您的 Amazon FSx 文件网关安装完成且您可以访问 FSx for Windows File Server 时，您可以使用 AWS 管理控制台附加 FSx for Windows File Server 文件系统。然后，AWS 管理控制台将带您逐步完成使文件共享可在本地访问所需的所有步骤。\n配置好文件共享后，客户端系统就可以在 Amazon FSx 文件网关上浏览并连接到与所选的 Amazon FSx 文件系统对应的文件共享。连接文件共享后，用户可以在本地读取和写入其文件，同时从 FSx for Windows File Server 上提供的所有功能中获益。"
    },
    {
        "query":"Amazon FSx 文件网关在哪些区域提供？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关可用于在提供 FSx for Windows File Server 的所有 AWS 区域访问 Windows 文件系统。"
    },
    {
        "query":"Amazon FSx 文件网关的成本是多少？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关按小时收费。有关定价信息，请访问 [AWS Storage Gateway 定价页面](https://aws.amazon.com/cn/storagegateway/pricing/)。"
    },
    {
        "query":"Amazon FSx 文件网关支持哪些协议？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关支持服务器消息块 (SMB) 协议的版本 2.x 和 3.x。SMB 由 Microsoft Windows、MacOS 和 Linux OS 提供支持。"
    },
    {
        "query":"我在 Amazon FSx 文件网关中看到的文件与我在 Amazon FSx for Windows File Server 中看到的文件之间存在什么关系？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关将本地文件共享及其内容映射到远程存储在 Amazon FSx for Windows File Server 中的文件共享。远程和本地可见文件与其共享之间存在 1:1 的对应关系。\n答：我是否能通过 Amazon FSx 文件网关访问 AWS 中的相同文件共享？\n是。您可以从 Amazon FSx 文件网关访问您的文件共享，也可以直接从 AWS 中的 Amazon FSx 访问；但是，您应该确保一次只能从一个位置写入文件。在此版本中，Amazon FSx 文件网关将不会以一种产生冲突的方式阻止来自多个位置的写操作的重叠。"
    },
    {
        "query":"Amazon FSx 文件网关如何支持我管理我的 Amazon FSx for Windows File Server？",
        "intention":"知识问答",
        "reply":"您可以使用 FSx for Windows File Server 提供的所有工具通过远程管理界面来管理 Amazon FSx for Windows File Server。"
    },
    {
        "query":"Amazon FSx 文件网关是否能够连接到多个 Amazon FSx for Windows 文件系统？",
        "intention":"知识问答",
        "reply":"是。您最多可以将一个网关附加到 5 个文件系统上的共享，只要它们都是同一个 Active Directory 域的成员。Amazon FSx 文件网关只能加入一个 Active Directory 域。"
    },
    {
        "query":"支持哪些部署选项？",
        "intention":"知识问答",
        "reply":"您可以在 VMware ESXi、Microsoft Hyper-V 或 Linux KVM 上部署包含 Amazon FSx 文件网关软件的虚拟机，也可以将 Storage Gateway 部署为[硬件设备](https://aws.amazon.com/cn/storagegateway/hardware-appliance/)。"
    },
    {
        "query":"我如何使用 Active Directory 提供凭证？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关可成为 Active Directory 域的成员，无论 AD 基础设施是托管在 AWS Directory Service 中，还是托管在本地。当 Amazon FSx 文件网关成为域的成员后，它将有权以实施安全性为目的访问在该域中设置的所有用户和策略。然后，Amazon FSx 文件网关将与任何 Windows Server 的行为相同，并会根据 Active Directory 中配置的内容强制执行所有适用的文件访问策略。"
    },
    {
        "query":"Amazon FSx 文件网关是否与现有的 Windows 访问控制和 Active Directory 凭证兼容？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关使用本机 Windows 访问控制，并与任何现有的与 Microsoft Windows 一起工作的静态访问列表兼容。ACL 的最大大小为 64KB，或者约为 1820 个访问控制条目。这与 Windows Server 主机相同。访问控制设置和存储在 FSx Windows File Server 中，因此，您只需要创建它们一次，它们将反映在所有附加的文件网关中。"
    },
    {
        "query":"数据是否会在传输中加密？",
        "intention":"知识问答",
        "reply":"是。Amazon FSx 文件网关支持 SMB 加密，最高支持最新的 SMB v3.1.1 规范，包括 AES 128 CCM 和 AES 128 GCM。兼容的客户端将使用加密自动连接。此外，Amazon FSx 文件网关在与 AWS 中的 FSx for Windows File Server 通信时使用 SMB 加密。您必须配置 VPN 或至 AWS 的 Direct Connect 链接，并设置适当的策略以允许 SMB 流量和管理流量通过 AWS。"
    },
    {
        "query":"Amazon FSx 文件网关如何提供高可用性？",
        "intention":"知识问答",
        "reply":"与 Amazon S3 文件网关一样，Amazon FSx 文件网关通过对连接到 VMware 监控服务的网关操作运行一系列连续的运行状况检查，实现了 VMware 上的高可用性。在硬件、软件或网络故障期间，如果新主机或现有主机仍在运行，VMware 将在主机上触发网关重启。在重启期间，用户和应用程序将遇到最多 60 秒的停机时间。重启后，与网关的连接将自动重新建立，无需人工干预。重新初始化时，网关会将指标发送回云，方便客户全面了解可用性事件。"
    },
    {
        "query":"启用高可用性的 Amazon FSx 文件网关覆盖了哪些类型的故障？",
        "intention":"知识问答",
        "reply":"启用了 VMware HA 并配置了应用程序监控的 Amazon FSx 文件网关将检测硬件故障、管理程序故障、网络故障以及导致连接超时或者文件共享不可用的软件问题，并从中恢复。"
    },
    {
        "query":"Amazon FSx 文件网关支持多少会话和文件共享？",
        "intention":"知识问答",
        "reply":"Amazon FSx 文件网关在一个实例配置中最多支持 50 个共享和连接到 Amazon FSx 文件网关实例的 500 个活动客户端会话。"
    },
    {
        "query":"如何开始使用 AWS Snowball 迁移磁带数据？",
        "intention":"知识问答",
        "reply":"要开始，请在 AWS Snow 系列控制台中订购一台带磁带网关的 Snowball Edge Storage Optimized 存储设备。当您从 AWS 接收设备时，解锁，然后连接到您的本地网络。然后启动磁带网关，它看起来像一个物理磁带库。使用现有备份应用程序连接到 AWS并将数据从物理磁带复制到磁带网关上的虚拟磁带。完成数据拷贝后，将 Snowball Edge设备运回 AWS。您的数据将存储在 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive 中。您可以通过 AWS Storage Gateway 控制台查看存储在 AWS 上的虚拟磁带，并通过作为虚拟机或硬件设备在本地运行或在 AWS 上的 Amazon Elastic Compute Cloud (Amazon EC2) 实例上运行的磁带网关访问其中的数据。"
    },
    {
        "query":"Snowball Edge Storage Optimized 设备上有多少我可以与磁带网关一起使用的可用存储空间？",
        "intention":"知识问答",
        "reply":"Snowball Edge Storage Optimized 设备提供 80TB 的可用块存储或对象存储，并可将大量磁带数据迁移到 S3 Glacier Flexible Retrieval 或 S3 Glacier Deep Archive。"
    },
    {
        "query":"我应何时将磁带网关与 Snowball Edge Storage Optimized 设备一起使用？什么时候将磁带网关与虚拟设备或硬件设备一起使用？",
        "intention":"知识问答",
        "reply":"在受限的网络带宽环境中，您可以使用 Snowball Edge Storage Optimized 设备和磁带网关将存储在磁带存档中的数据迁移到 AWS。将您的数据复制到设备后，将其发送回 AWS。通过 Snowball 上的磁带网关，您的数据将离线迁移到 AWS。您希望将新备份和归档复制到 AWS 且不受网络限制时，可以在虚拟设备或硬件设备上使用磁带网关。通过虚拟或硬件设备上的磁带网关，将使用网络将您的数据传输到 AWS，您将虚拟或硬件设备永久保留在数据中心中。"
    },
    {
        "query":"我是否可以将 Snowball 和 磁带网关用作本地部署虚拟磁带库 (VTL)，而不是将其用于脱机数据迁移？",
        "intention":"知识问答",
        "reply":"不可以，Snowball Edge Storage Optimized 设备和磁带网关的设计和制造并不是为了满足您的本地部署的 VTL 需要，而是为了满足您的脱机数据迁移需要。备份应用程序导出虚拟磁带后，在将虚拟磁带导入 AWS 之前，无法访问“Snowball with Tape Gateway”上的虚拟磁带。对于本地部署的 VTL 需求，请使用在虚拟机、硬件设备或 Amazon EC2 实例上运行的磁带网关。"
    },
    {
        "query":"与异地仓库磁带相比，将虚拟磁带存储在 AWS 中有哪些优势？",
        "intention":"知识问答",
        "reply":"与异地仓库物理磁带相比，结合使用磁带网关和 S3 Glacier Deep Archive 将虚拟磁带存储在 AWS 中时，您可获得 99.999999999% 的数据持久性、AWS 的定期不变性检查、数据加密、还原正确的数据以及成本节省。第一，存储在 S3 Glacier Deep Archive 中的所有虚拟磁带都将复制并存储在至少三个地理分散的可用区中，受 99.999999999% 的持久性保护。第二，AWS 定期执行不变性检查，以确认可读取您的数据并且不会导致任何错误。第三，存储在 S3 Glacier Deep Archive 中的所有磁带使用默认密钥或您的 KMS 密钥受 S3 服务器端加密保护。此外，您还可以避免与磁带便携性相关的物理安全风险。第四，在非现场仓储磁带时，可能会在还原期间收到不正确或损坏的磁带，与此相比，使用磁带网关时，可始终获得正确的数据。最后，与异地仓库磁带相比，将数据存储在 S3 Glacier Deep Archive 中可节省每月存储成本。"
    },
    {
        "query":"磁带网关支持哪些 Amazon S3 存储类？",
        "intention":"知识问答",
        "reply":"磁带网关支持 S3 标准、S3 Glacier 和 S3 Glacier Deep Archive 存储类。当备份应用程序将数据写入磁带时，虚拟磁带上的数据将存储在 Amazon S3 中的虚拟磁带库中。从备份应用程序中弹出磁带后，磁带将存档到 S3 Glacier 或 S3 Glacier Deep Archive。"
    },
    {
        "query":"虚拟磁带上能存储多少数据？",
        "intention":"知识问答",
        "reply":"您在磁带网关上可以创建的虚拟磁带的最小和最大容量分别为 100GiB 和 15TiB。请注意，您只需为每个磁带上存储的数据量（而不是磁带的容量）付费。"
    },
    {
        "query":"虚拟磁带库 (VTL) 可以容纳多少磁带？",
        "intention":"知识问答",
        "reply":"在 VTL 中，一个磁带网关最多可以有 1500 个虚拟磁带，其中最大总容量为 1PB；但对您可以存档的数据量和虚拟磁带数是没有限制的。您还可以部署额外的磁带网关来为没有存档的虚拟磁带扩展存储。有关更多信息，请参阅[有关 Storage Gateway 限制的文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/resource-gateway-limits.html)。"
    },
    {
        "query":"磁带存档中能存储多少数据？",
        "intention":"知识问答",
        "reply":"您可存档的数据量、数据大小或虚拟磁带数没有限制。"
    },
    {
        "query":"可以将存档的虚拟磁带检索到哪些 S3 存储类？",
        "intention":"知识问答",
        "reply":"您可以将存档在 S3 Glacier 或 S3 Glacier Deep Archive 中的虚拟磁带检索到 S3。通常存档在 S3 Glacier 中的磁带将使用标准检索方法在 3-5 小时内检索到 S3。通常存档在 S3 Glacier Deep Archive 中的磁带将使用标准检索方法在 12 个小时内检索到 S3。"
    },
    {
        "query":"如何访问虚拟磁带中的数据？",
        "intention":"知识问答",
        "reply":"必须先将包含您数据的虚拟磁带存储在虚拟磁带库中，然后才能对其进行访问。您可即时访问虚拟磁带库中的虚拟磁带。如果包含您的数据的虚拟磁带已存档，则可以使用 AWS 管理控制台或 API 检索虚拟磁带。请先选择虚拟磁带，然后选择您希望虚拟磁带加载到其中的虚拟磁带库。您可以将存档在 S3 Glacier（通常在 3-5 小时内）和 S3 Glacier Deep Archive（通常在 12 小时内）中的磁带检索到 S3。当虚拟磁带在虚拟磁带库中可用后，您可以通过备份应用程序利用虚拟磁带还原数据。"
    },
    {
        "query":"是否可以使用 Amazon S3 API 或 Amazon Glacier S3 API 访问虚拟磁带库中的虚拟磁带？",
        "intention":"知识问答",
        "reply":"否。您不能使用 Amazon S3 API 或 Amazon S3 Glacier API 访问虚拟磁带数据。但是，您可以使用磁带网关 API 管理您的虚拟磁带库和虚拟磁带架。"
    },
    {
        "query":"如何将磁带网关与 S3 Glacier Deep Archive 存储类配合使用？",
        "intention":"知识问答",
        "reply":"在通过 Storage Gateway 控制台或 API 创建新磁带时，可将存档存储目标设置为 S3 Glacier Deep Archive。当备份软件弹出磁带时，将磁带存档到 S3 Glacier Deep Archive。通常可使用标准检索方法在 12 个小时内将存档到 S3 Glacier Deep Archive 的磁带检索到 S3。"
    },
    {
        "query":"我是否可以将 S3 Glacier 中的现有虚拟磁带移动到 S3 Glacier Deep Archive？",
        "intention":"知识问答",
        "reply":"是。磁带网关支持将 S3 Glacier 中的磁带移动到 S3 Glacier Deep Archive。您可以使用 AWS Storage Gateway 控制台或 API 将放置在 Glacier 池中的磁带分配给 Deep Archive 池。然后，磁带网关将虚拟磁带移动到与 S3 Glacier Deep Archive 存储类关联的 Deep Archive 池。如果您在 90 天之前将磁带从 S3 Glacier 移动到 S3 Glacier Deep Archive，则会产生将磁带从 S3 Glacier 移动到 S3 Glacier Deep Archive 的磁带移动费用，以及 S3 Glacier 的早期删除费用（如果适用）。"
    },
    {
        "query":"是否可以将 S3 Glacier Deep Archive 中的磁带移动到 S3 Glacier？",
        "intention":"知识问答",
        "reply":"否，您不可以将磁带从 S3 Glacier Deep Archive 移动到 S3 Glacier。您可以将磁带从 S3 Glacier Deep Archive 检索到 S3，或从 S3 Glacier Deep Archive 中删除磁带。"
    },
    {
        "query":"可以将哪些备份应用程序与磁带网关配合使用？",
        "intention":"知识问答",
        "reply":"VTL 接口与使用基于 iSCSI 的行业标准磁带库接口的备份和存档应用程序兼容。[有关受支持备份应用程序的完整列表，请参阅 Storage Gateway 概述页面](https://aws.amazon.com/storagegateway/vtl/#supported_backup_software)。"
    },
    {
        "query":"磁带网关使用哪种加密方式保护数据？",
        "intention":"知识问答",
        "reply":"在该网关与 AWS 存储之间传输的所有数据均已使用 SSL 进行了加密。答：默认情况下，磁带网关存储在 S3 中的所有数据均已使用 Amazon S3 托管加密密钥 (SSE-S3) 在服务器端进行了加密。\n您可以选择使用 AWS KMS 托管密钥通过 Storage Gateway API 在磁带上配置加密。您能够将一个托管的客户主密钥 (CMK) 指定为 KMS 密钥。用于加密磁带数据的已配置 CMK 在创建后无法更改。要了解更多信息，请参阅《Storage Gateway 用户指南》中的“[使用 AWS Key Management System 加密数据](https://docs.aws.amazon.com/storagegateway/latest/userguide/encryption.html)”，其中包含有关使用该功能的重要详情。"
    },
    {
        "query":"每个网关可以管理多少卷数据？ 卷的最大容量是多少？",
        "intention":"知识问答",
        "reply":"每个*卷网关*最多可支持 32 个卷。在*缓存模式*下，每个卷的容量高达 32TB，且每个网关最多可存储 1PB 数据（32 个卷，每个卷的容量为 32TB）。在*存储模式*下，每个卷的容量高达 16TB，且每个网关最多可存储 512TB 数据（32 个卷，每个卷的容量为 16TB）。有关更多信息，请参阅我们[有关 Storage Gateway 限制的文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/resource-gateway-limits.html)。\n卷网关会先压缩数据，然后将其传输到 AWS 并存储在其中。这种压缩可以降低数据传输量和存储费用。卷存储不会进行预配置，您将依据存储在卷上的数据量，而非所创建的卷大小支付费用。"
    },
    {
        "query":"在 Amazon S3 中搜索时，为什么无法看到我的卷数据？",
        "intention":"知识问答",
        "reply":"您的卷存储在由 AWS Storage Gateway 服务维护的 Amazon S3 存储桶中。您可以通过 AWS Storage Gateway 访问卷来执行 I/O 操作。您无法使用 Amazon S3 API 操作直接访问卷。您可以拍摄网关卷的时间点快照，并以 Amazon EBS 快照的形式使用这些快照，它们可以转换为 Storage Gateway 卷或 EBS 卷。您可以使用文件网关在 S3 中以原生方式处理数据。"
    },
    {
        "query":"卷网关使用哪种加密方式保护数据？",
        "intention":"知识问答",
        "reply":"在该网关与 AWS 存储之间传输的所有数据均已使用 SSL 进行了加密。默认情况下，卷网关存储在 S3 中的所有数据均已使用 Amazon S3 托管加密密钥 (SSE-S3) 在服务器端进行了加密。\n您可以选择使用 AWS KMS 托管密钥通过 Storage Gateway API 为 AWS 卷上存储的数据配置加密。您能够将一个托管的客户主密钥 (CMK) 指定为 KMS 密钥。用于加密卷的已配置 CMK 在创建后无法更改。要了解更多信息，请参阅《Storage Gateway 用户指南》中的“[使用 AWS Key Management System 加密数据](https://docs.aws.amazon.com/storagegateway/latest/userguide/encryption.html)”，其中包含有关使用该功能的重要详情。"
    },
    {
        "query":"能否通过 KMS 加密的卷创建 EBS 快照？",
        "intention":"知识问答",
        "reply":"是。您可以使用 API 通过 AWS KMS 加密的卷创建 EBS 快照。EBS 快照将使用卷加密所用相同密钥进行加密。"
    },
    {
        "query":"能否通过 KMS 加密的 EBS 快照创建卷？",
        "intention":"知识问答",
        "reply":"是。您可以使用 API 通过 KMS 加密的 EBS 快照创建加密卷。加密卷可以使用 EBS 快照加密所用的相同密钥，或者，您也可以指定其他密钥来加密卷。\n问：为什么要使用快照？\n您可以采用 Amazon EBS 快照的形式为卷网关卷创建时间点快照。您还可以将卷快照用作新 Amazon EBS 卷的起点，以便随后将其挂载到 Amazon EC2 实例。如果您需要更多按需计算容量进行数据处理或出于灾难恢复目的需要替代容量，您可以通过此方法轻松地从本地应用程序为 Amazon EC2 上运行的应用程序提供数据。\n对于缓存卷，您的卷数据已存储在 Amazon S3 中，因此您可以使用快照留存不同版本的数据。通过这种方法，您可以在需要时将数据恢复到之前的版本，还可以修改某个时间点版本，将其变成新的卷。您可以按照预定时间或者临时启动快照的拍摄。拍摄新快照时，只会存储自上次拍摄快照以来发生变化的数据。如果您的卷中有 100GB 数据，但自上次快照后只有 5GB 数据发生变化，则只会将这 5GB 的快照数据存储到 Amazon S3 中。删除快照时，只会删除其他快照都不需要的数据。\n对于存储卷，卷数据存储在本地，而 Amazon S3 中存储的快照可提供持久的场外备份。如果您需要恢复备份，则可基于快照创建新卷。您还可以将卷快照用作新 Amazon EBS 卷的起点，以便随后将其挂载到 Amazon EC2 实例。"
    },
    {
        "query":"我的快照中将包含哪些数据？ 我如何知道何时拍摄快照来确保我的数据已备份？",
        "intention":"知识问答",
        "reply":"快照表示发出快照请求时相应时间点的卷的副本。快照包含将数据（从拍摄快照的时间起）还原到新卷所需的所有信息。在拍摄快照之前由您的应用程序写入卷中但尚未上传至 AWS 的数据将包含在快照中。\n实际上，系统会为快照分配一个 ID，且该 ID 在 AWS 管理控制台和 AWS 命令行界面 (AWS CLI) 中立即可见，但最初会显示为“待处理”状态。在发出快照请求之前写入卷中的所有数据从网关上传至 EBS 后，此状态将更改为“可用”。此时，您可以将快照用作新网关或 EBS 卷的基础。"
    },
    {
        "query":"如何将快照还原到网关？",
        "intention":"知识问答",
        "reply":"每个快照都有唯一的标识符，您可以使用 AWS 管理控制台查看该标识符。您可以通过指定该唯一标识符，基于任何现有的快照创建 AWS Storage Gateway 或 Amazon EBS 卷。\n使用 AWS 管理控制台，您可以基于 Amazon S3 中存储的快照创建新卷。然后，您可以将此卷作为 iSCSI 设备挂载到本地应用程序服务器。\n由于缓存卷将主要数据存储在 Amazon S3 中，因此，在基于快照创建新卷时，您的网关会将该快照的数据保留在 Amazon S3 中，在那里，这些数据会成为新卷的主要数据。\n由于存储卷将主要数据存储在本地，因此，在基于快照创建新卷时，您的网关会将快照中包含的数据下载到您的本地硬件。在那里，这些数据会成为新卷的主要数据。"
    },
    {
        "query":"是否需要卸载 AWS Storage Gateway 的卷才能拍摄快照？ 是否需要完成快照后才能重新使用卷？",
        "intention":"知识问答",
        "reply":"否，拍摄快照不需要您卸载卷，也不会影响应用程序的性能。不过，快照只能捕获已写入 AWS Storage Gateway 卷的数据，可能不包含应用程序或操作系统已在本地缓冲的数据。"
    },
    {
        "query":"我能否为 AWS Storage Gateway 卷创建快照计划？",
        "intention":"知识问答",
        "reply":"能，您可以为每个卷创建快照计划。您可以修改每天拍摄快照的时间以及频率（每 1、2、4、8、12 或 24 小时）。"
    },
    {
        "query":"完成一次快照需要多长时间？",
        "intention":"知识问答",
        "reply":"完成快照所需的时间主要取决于卷的大小，以及与 AWS 之间的互联网速度。AWS Storage Gateway 在上传前会对所有数据进行压缩，从而缩短拍摄快照的时间。"
    },
    {
        "query":"是否可以使用 Amazon S3 的 API 访问我的快照？",
        "intention":"知识问答",
        "reply":"不可以，只能从 AWS Storage Gateway 和 Amazon EBS 访问快照，不能使用 Amazon S3 API 直接访问。"
    },
    {
        "query":"每个网关的快照上限是多少？",
        "intention":"知识问答",
        "reply":"一个网关可产生的快照数量或快照的数据量是没有限制的。\n问：使用 AWS Backup 保护卷网关卷有哪些优势？\n使用 AWS Backup 备份 Volume Gateway 卷可以简化并集中化备份管理，从而减轻运营负担，更轻松地跨所有 AWS 资源满足合规性要求。AWS Backup 支持您设置可自定义的计划备份策略，满足您的备份要求。使用 AWS Backup，您可以设置备份保留和过期规则，这样您就无需开发自定义脚本或手动管理 Volume Gateway 卷的时间点备份。最后，您可以通过中心视图跨多个 Volume Gateway 以及其他 AWS 资源（如 EBS 卷和 RDS 数据库）管理和监控备份。"
    },
    {
        "query":"如何使用 AWS Backup 保护 Volume Gateway 上的卷？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Backup 为 Volume Gateway 卷执行一次性备份或定义备份计划。卷备份以 Amazon EBS 快照的形式存储在 Amazon S3 中，可以在 AWS Backup 控制台或 Amazon EBS 控制台中查看。AWS Backup 创建的卷备份可以从 AWS Backup 控制台中手动或自动删除。"
    },
    {
        "query":"如何使用 AWS Backup 管理卷网关卷的备份和保留？",
        "intention":"知识问答",
        "reply":"您可以先通过 Storage Gateway 控制台或 AWS Backup 控制台管理备份。如果您先从 Storage Gateway 控制台开始，您可以导航到 AWS Backup 控制台以完成备份计划配置或启动按需备份。另外，您也可以先从 AWS Backup 控制台开始配置 Volume Gateway 卷的备份计划或启动按需备份。"
    },
    {
        "query":"我现今使用 Volume Gateway 卷的方式会不会发生变化？",
        "intention":"知识问答",
        "reply":"不会。所有现有的 Volume Gateway 快照功能和您现有的 Amazon EBS 快照都会保持可用且不会更改。您可以继续使用 Storage Gateway 控制台以基于 EBS 快照创建卷，并使用 Amazon EBS 控制台查看或删除快照。"
    },
    {
        "query":"如果使用 AWS Backup，我还能继续使用 Volume Gateway 快照计划和现有快照吗？",
        "intention":"知识问答",
        "reply":"可以。您可以继续使用 Volume Gateway 的现有快照功能来创建 Amazon EBS 快照，并使用之前创建的快照用于恢复目的。AWS Backup 备份计划的运作独立于 Volume Gateway 计划快照，让您多一种方式来集中管理所有备份和保留策略。"
    },
    {
        "query":"如果卷网关上有 KMS 加密卷，AWS Backup 是否能够备份此卷？",
        "intention":"知识问答",
        "reply":"是。AWS Backup 将会使用卷加密所用的密钥备份卷网关上的 KMS 加密卷。"
    },
    {
        "query":"是否可以使用 AWS Backup 在不同区域（例如，跨区域）创建卷网关卷的备份？",
        "intention":"知识问答",
        "reply":"AWS Backup 支持在 AWS Backup 运营的区域备份 Volume Gateway 卷。"
    },
    {
        "query":"什么是 Storage Gateway 硬件设备？",
        "intention":"知识问答",
        "reply":"[AWS Storage Gateway 已作为硬件设备提供](https://aws.amazon.com/cn/storagegateway/hardware-appliance/)，将 Storage Gateway 软件预安装在了采用已验证配置的服务器上。您可以通过 AWS 控制台或 API 管理该设备。"
    },
    {
        "query":"该硬件设备支持哪些网关类型和存储接口？",
        "intention":"知识问答",
        "reply":"该硬件设备支持采用 NFS 和 SMB 接口的 Amazon S3 文件网关、采用 SMB 的 Amazon FSx 文件网关、采用 iSCSI 的卷网关缓存卷和采用 iSCSI-VTL 的磁带网关。"
    },
    {
        "query":"为何可能需要硬件设备？",
        "intention":"知识问答",
        "reply":"对于 IT 环境（例如缺少以下资源的远程办公室和部门：现有的虚拟服务器基础设施、充足的磁盘和内存资源或具备管理程序管理技能的员工），硬件设备可以进一步简化 AWS Storage Gateway 在本地的采购、部署和管理。它使得无需为操作本地 Storage Gateway VM 设备而采购虚拟环境所需的额外基础设施。"
    },
    {
        "query":"可以使用哪些硬件设备型号？",
        "intention":"知识问答",
        "reply":"可以使用两种提供 5 TB 或 12 TB 本地 SSD 缓存的型号。"
    },
    {
        "query":"硬件设备的规格如何？",
        "intention":"知识问答",
        "reply":"硬件设备基于已验证的服务器配置。有关规格，请参阅 [Storage Gateway 硬件设备](https://aws.amazon.com/cn/storagegateway/hardware-appliance/)产品页面。"
    },
    {
        "query":"硬件设备在哪里提供？ 适用于哪些 AWS 区域？",
        "intention":"知识问答",
        "reply":"硬件设备可以运输至美国政府允许出口的所有国际目的地。它在 16 个 AWS 区域受支持，包括美国东部（弗吉尼亚北部、俄亥俄）、美国西部（加利福尼亚北部、俄勒冈）、加拿大（中部）、南美洲（南保罗）、欧洲（爱尔兰、法兰克福、伦敦、巴黎、斯德哥尔摩）和亚太地区（孟买、首尔、新加坡、悉尼、东京）。"
    },
    {
        "query":"可以在哪里购买硬件设备？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 硬件设备只能通过经销商购买。请联系您的首选经销商了解购买信息和请求报价。美国和加拿大客户还可以从 [CDW](https://www.cdw.com/search/servers-server-management/servers/rack-servers/?w=SB2&ln=0&b=AMA) 直接购买该设备。"
    },
    {
        "query":"谁拥有硬件设备？",
        "intention":"知识问答",
        "reply":"购买后，您便拥有硬件设备。"
    },
    {
        "query":"如何使用硬件设备？",
        "intention":"知识问答",
        "reply":"收到硬件设备后，您需要通过本地硬件控制台配置 IP 地址，然后在 AWS Storage Gateway 控制台中使用此 IP 地址来激活设备。这将使您的硬件设备与您的 AWS 账户相关联。激活硬件设备后，您便可从控制台选择您想要的网关类型，即文件、卷（缓存）或磁带。然后，在设备上启用所选的网关类型。激活后，您便可通过 AWS 控制台、命令行界面或软件开发工具包管理和使用新的 Storage Gateway 硬件网关设备，与您当前使用虚拟设备的方式类似。有关更多信息，请参阅[硬件设备文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/HardwareAppliance.html)。"
    },
    {
        "query":"能否在一个硬件设备上运行多个网关？",
        "intention":"知识问答",
        "reply":"否。目前，硬件设备仅支持一次运行一个网关。"
    },
    {
        "query":"能否在网关安装到硬件设备上之后更改其类型？",
        "intention":"知识问答",
        "reply":"能。要在网关安装到硬件设备上之后更改其类型，请从 Storage Gateway 控制台选择*移除网关*，这将删除网关和所有相关资源。届时，您可以随时在硬件设备上启动新的网关。"
    },
    {
        "query":"如何购买和使用 Storage Gateway 硬件设备上的其他存储？",
        "intention":"知识问答",
        "reply":"如果订购 5TB 硬件设备型号，则可以通过购买 5 个装 SSD 升级套件将可重复使用的本地缓存提高至 12TB。您可以按照订购硬件设备的相同流程购买 SSD 升级套件。 要扩展存储容量，只需将 SSD 插入预配置的设备即可。SSD 是可热插拔的，并且在将 SSD 添加到设备时，设备将自动识别额外的存储。有关说明，请[查看文档](https://alpha-docs-aws.amazon.com/storagegateway/latest/userguide/appliance-quick-start.html)。"
    },
    {
        "query":"能否为之前激活的 Storage Gateway 硬件设备增加存储？",
        "intention":"知识问答",
        "reply":"如果您已激活设备并将其与 AWS 账户关联，则需要在添加更多存储设备之前将其重置为出厂设置。"
    },
    {
        "query":"能否添加任何 SSD 或硬盘来增加 Storage Gateway 硬件设备的存储容量？",
        "intention":"知识问答",
        "reply":"否。只添加设备制造商提供的 SSD。这些 SSD 已经过 AWS 认证，可用于 Storage Gateway 硬件设备。"
    },
    {
        "query":"Storage Gateway 硬件设备是否支持 RAID？",
        "intention":"知识问答",
        "reply":"是。该硬件设备使用基于软件的 ZFS RAID，并提供针对存储驱动器故障的保护。提供 5TB 可用存储的基本设备可以容忍 1 个 SSD 出现故障，12TB 可用存储配置可以容忍 2 个 SSD 出现故障。"
    },
    {
        "query":"Storage Gateway 如何提供高可用性？",
        "intention":"知识问答",
        "reply":"通过对网关操作运行一系列连续的运行状况检查并连接到 VMware 监控服务，Storage Gateway 实现了高可用性。在硬件、软件或网络故障期间，如果新主机或现有主机仍在运行，VMware 将在主机上触发网关重启。在重启期间，用户和应用程序将遇到最多 60 秒的停机时间。重启后，与网关的连接将自动重新建立，无需人工干预。重新初始化时，网关会将指标发送回云，方便客户全面了解可用性事件。"
    },
    {
        "query":"哪些环境支持 Storage Gateway 高可用性？",
        "intention":"知识问答",
        "reply":"Storage Gateway 高可用性目前可以在以下集群化 VMware vSphere 环境中启用：启用了 VMware HA，并且共享卷存储可用。"
    },
    {
        "query":"启用高可用性的 Storage Gateway 的成本是多少？",
        "intention":"知识问答",
        "reply":"在启用高可用性集成的情况下，运行 Storage Gateway 不需要额外成本。"
    },
    {
        "query":"启用高可用性的 Storage Gateway 覆盖了哪些类型的故障？",
        "intention":"知识问答",
        "reply":"启用了 VMware HA 并配置了应用程序监控的 Storage Gateway 将检测硬件故障、管理程序故障、网络故障以及导致连接超时或者文件共享、卷或虚拟磁带库不可用的软件问题，并从中恢复。"
    },
    {
        "query":"在网关重启期间，是否会保持 NFS 和 SMB 会话？",
        "intention":"知识问答",
        "reply":"是。"
    },
    {
        "query":"在网关重启期间，网关读或写是否会失败？",
        "intention":"知识问答",
        "reply":"如果客户使用建议的挂载设置，若连接到文件网关的 NFS 客户端在网关重启时执行读或写操作，可能会挂起长达 60 秒，然后重试。根据客户端设置，SMB 客户端可能会在重启期间拒绝文件的读或写。卷网关和磁带网关的所有 iSCSI 读写将在网关重启期间挂起，然后自动重试。"
    },
    {
        "query":"如果与 AWS 的连接中断，Storage Gateway HA 是否仍能重启？",
        "intention":"知识问答",
        "reply":"能，网关将使用同一底层共享存储重新初始化，从而保留本地缓存和上传队列"
    },
    {
        "query":"是否会在网关重启期间丢失数据？",
        "intention":"知识问答",
        "reply":"不会，网关将使用同一底层共享存储重新初始化，从而保留本地缓存和上传队列。"
    },
    {
        "query":"是否需要更改 VMware 环境以利用 HA 功能？",
        "intention":"知识问答",
        "reply":"如果网关部署到 VMware 并启用了 VMware HA，您将能够在 VMware vSphere 控制中心中配置 Storage Gateway VM 的重启灵敏度。Storage Gateway VM 检测信号将可用，使您能够在特定超时后自动重启网关。"
    },
    {
        "query":"Storage Gateway HA 可提供哪些 VMware HA 不提供的功能？",
        "intention":"知识问答",
        "reply":"VMware HA 监控底层基础设施，如存储和网络。Storage Gateway 提供一系列运行状况检查，如文件系统可用性、SMB 终端节点可用性和 NFS 终端节点可用性，这些检查可监控网关的所有关键操作，确保用户和应用程序可以持续使用整个服务，而不仅仅是底层基础设施。"
    },
    {
        "query":"是否适用于 VMware Cloud on AWS？",
        "intention":"知识问答",
        "reply":"是。Storage Gateway 高可用性可在 VMware Cloud 上使用，没有额外要求。VMware Cloud on AWS 默认启用 VMware HA，且可以使用共享卷。"
    },
    {
        "query":"如何知道网关是否具有高可用性功能以及是否能在 HA 模式下运行？",
        "intention":"知识问答",
        "reply":"在为 VMware 设置新网关时，您可以选择测试 HA 选项。您还可以在控制台中选择“测试 VMware HA”操作来测试部署的网关是否具有 HA 功能。"
    },
    {
        "query":"网关重启期间，可以查看哪些操作？",
        "intention":"知识问答",
        "reply":"在网关重启期间，AWS Storage Gateway 控制台将在日志表中显示可用性事件，在性能图中显示中断行为。"
    },
    {
        "query":"网关重启时，是否可在 CloudWatch 中查看可用性事件？",
        "intention":"知识问答",
        "reply":"可以，如果您已经配置了与 CloudWatch 的集成，从网关触发的可用性事件将可通过 CloudWatch 查看。"
    },
    {
        "query":"如何知道网关何时返回操作？",
        "intention":"知识问答",
        "reply":"如果您已经配置了与 CloudWatch 的集成，则在重新初始化时将触发 CloudWatch 事件。此外，性能图也将显示网关的操作指标，包括活动会话的数量。"
    },
    {
        "query":"是否能设置触发网关重启的服务超时时间？",
        "intention":"知识问答",
        "reply":"能，管理员将能够在 vSphere 控制台中设置超时时间，如果网关在指定的秒数内无法访问，则将重启服务。"
    },
    {
        "query":"AWS Storage Gateway 使用什么加密方式保护数据？",
        "intention":"知识问答",
        "reply":"在任何类型的网关设备与 AWS 存储之间传输的所有数据均已使用 SSL 进行了加密。默认情况下，AWS Storage Gateway 存储在 S3 中的所有数据均已使用 Amazon S3 托管加密密钥 (SSE-S3) 在服务器端进行了加密。此外，您还可以选择配置不同类型的网关，以使用 AWS Key Management Service (KMS) 通过 Storage Gateway API 加密存储的数据。请参阅下文，按[文件网关](http://storagegateway/faqs/#file-gateway-encryption)、[磁带网关](http://storagegateway/faqs/#tape-gateway-encryption)和[卷网关](http://storagegateway/faqs/#volume-gateway-encryption)了解有关 KMS 支持的具体信息。"
    },
    {
        "query":"AWS Storage Gateway 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"是。AWS Storage Gateway 符合 HIPAA 要求。如果您已与 AWS 签订[业务合作协议 (BAA)](https://aws.amazon.com/cn/artifact/getting-started/)，您就可以使用 Storage Gateway 在可扩展、经济高效且安全的 AWS 存储服务（包括 Amazon S3、Amazon S3 Glacier、Amazon S3 Glacier Deep Archive、Amazon FSx for Windows File Server 和 Amazon EBS，这些存储服务同样符合 HIPAA 要求）上对受保护健康信息 (PHI) 进行存储、备份和存档。\n您可以在我们的 [HIPAA 合规性页面](https://aws.amazon.com/cn/compliance/hipaa-compliance/)上找到有关符合 HIPAA 要求的 AWS 服务的信息，也可以在此处与 AWS 签订 BAA。Storage Gateway 的 HIPAA 要求适用于所有网关类型（文件、卷和磁带）。"
    },
    {
        "query":"AWS Storage Gateway 是否符合 PCI 规范？",
        "intention":"知识问答",
        "reply":"符合。根据最近的评估，AWS Storage Gateway 符合支付卡行业数据安全标准 (PCI DSS)。现有客户可以在 AWS 管理控制台中使用 [AWS Artifact](https://aws.amazon.com/cn/artifact/) 下载合规性证明 (AOC) 和 PCI 责任摘要报告。潜在客户可以通过与 AWS 销售团队合作来请求这些报告。"
    },
    {
        "query":"AWS Storage Gateway 是否符合 FedRAMP 规范？",
        "intention":"知识问答",
        "reply":"是，AWS Storage Gateway 在 AWS GovCloud（美国）区域符合 FedRAMP 高授权级别的规定，在 AWS 美国商业区域符合中等授权级别的规定。有关更多信息，请访问 [AWS FedRAMP 合规性页面](https://aws.amazon.com/cn/compliance/fedramp/)。"
    },
    {
        "query":"AWS Storage Gateway 是否支持符合 FIPS 140-2 标准的终端节点？",
        "intention":"知识问答",
        "reply":"S3 文件网关、Amazon FSx 文件网关、卷网关和磁带网关支持符合 FIPS 140-2 标准的终端节点。"
    },
    {
        "query":"AWS Storage Gateway 在哪些区域支持符合 FIPS 140-2 标准的终端节点？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 在以下 AWS 区域支持符合 FIPS 140-2 的终端节点：美国东部（弗吉尼亚北部）、美国东部（俄亥俄）、美国西部（加利福尼亚北部）、美国西部（俄勒冈）、加拿大（中部）、GovCloud（美国西部）和 GovCloud（美国东部）。"
    },
    {
        "query":"AWS Storage Gateway 有哪些 FIPS 终端节点？",
        "intention":"知识问答",
        "reply":"有关 AWS Storage Gateway 可使用的 FIPS 终端节点列表，请参阅 [AWS Storage Gateway 终端节点参考指南](https://docs.aws.amazon.com/general/latest/gr/sg.html)或 [AWS GovCloud (US) 用户指南](https://docs.aws.amazon.com/govcloud-us/latest/UserGuide/using-govcloud-endpoints.html)。"
    },
    {
        "query":"AWS Storage Gateway 硬件设备符合 FIPS 140-2 标准吗？",
        "intention":"知识问答",
        "reply":"不，AWS Storage Gateway 硬件设备不符合 FIPS 140-2 标准。"
    },
    {
        "query":"文件网关是否提供监控客户端文件访问操作的日志记录？",
        "intention":"知识问答",
        "reply":"是的，文件网关审计日志可用于监控客户端对 SMB 文件共享中的文件夹和文件的操作。"
    },
    {
        "query":"我可以监控客户端针对每个文件共享的活动吗？",
        "intention":"知识问答",
        "reply":"您可以配置文件网关审计日志，以在每个 SMB 共享的共享级别上监控用户对文件夹和文件的操作。"
    },
    {
        "query":"文件网关审计日志支持哪些类型的文件共享？",
        "intention":"知识问答",
        "reply":"文件网关审计日志支持 SMB 共享。"
    },
    {
        "query":"我将在文件网关审计日志中看到哪些文件操作？",
        "intention":"知识问答",
        "reply":"您将看到有关为文件和目录记录的以下操作的详细信息：打开、删除、读取、写入、重命名、更改权限以及文件操作成功。该日志还将记录每个操作的用户信息，包括时间戳、Active Directory 域、用户名和客户端 IP 地址。"
    },
    {
        "query":"如何访问文件网关审计日志？",
        "intention":"知识问答",
        "reply":"您可以访问 Amazon CloudWatch 中的文件网关审计日志。系统也可以将审计日志从 CloudWatch 发送到您选择的 Amazon S3 存储桶。您可以使用 Amazon Athena 从 Amazon S3 查看审计日志，也可以将其导出到第三方安全信息和事件管理应用程序 (SIEM)，以在这些工具中进行分析。"
    },
    {
        "query":"磁带网关是否支持一次写入多次读取 (WORM) 功能？",
        "intention":"知识问答",
        "reply":"支持，在磁带网关上手动或使用自动磁带创建配置创建新虚拟磁带时，您可以选择 WORM 磁带类型。从备份应用程序不能有意或意外擦除 WORM 虚拟磁带上的数据。此外，磁带网关的磁带保留锁定功能可在固定时间内甚至永久性地防止已归档的虚拟磁带被删除。"
    },
    {
        "query":"能否将 AWS Storage Gateway 与 AWS Direct Connect 配合使用？",
        "intention":"知识问答",
        "reply":"能，您可以使用 AWS Direct Connect 在本地网关和 AWS 之间建立专用的网络连接，以增加吞吐量并降低网络费用。请注意，AWS Storage Gateway 可高效利用互联网带宽，以加速将您的本地应用程序数据上传到 AWS。"
    },
    {
        "query":"是否可以通过本地代理服务器路由 AWS Storage Gateway 互联网流量？",
        "intention":"知识问答",
        "reply":"是。卷网关和磁带网关支持在本地网关和 AWS 之间配置套接字安全版本 5 (SOCKS5) 代理。文件网关支持配置超文本传输协议 (HTTP) 代理。"
    },
    {
        "query":"是否可以在私有的不可路由网络上部署 Storage Gateway？ Storage Gateway 是否支持 AWS PrivateLink？",
        "intention":"知识问答",
        "reply":"是。如果网络通过 DX 或 VPN 连接到您的 Amazon VPC，您可以在私有的不可路由网络上部署 Storage Gateway。Storage Gateway 流量将通过由 AWS PrivateLink 提供支持的 VPC 终端节点进行路由。AWS PrivateLink 是一种使用 VPC 中带有私有 IP 的弹性网络接口 (ENI) 来支持各 AWS 服务之间的私有连接的技术。要了解有关 PrivateLink 的更多信息，请参阅 [PrivateLink 文档](http://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Introduction.html#what-is-privatelink)。要设置适用于 Storage Gateway 的 AWS PrivateLink，请访问[适用于 Storage Gateway 的 AWS PrivateLink 文档](https://docs.aws.amazon.com/storagegateway/latest/userguide/gateway-private-link.html)。"
    },
    {
        "query":"Storage Gateway 是否为所有类型的网关都提供 AWS PrivateLink 支持？",
        "intention":"知识问答",
        "reply":"是的，该服务支持所有网关类型的 PrivateLink（文件/卷/磁带）。"
    },
    {
        "query":"如何通过 AWS PrivateLink 激活已连接到 AWS 的网关？",
        "intention":"知识问答",
        "reply":"如果您的 Web 浏览器可以访问 Internet 和您的私有网络，则可以通过 AWS 控制台激活支持 PrivateLink 的网关，或者通过它们所在区域中的 CLI 激活。"
    },
    {
        "query":"如何将 PrivateLink 与文件网关结合使用？",
        "intention":"知识问答",
        "reply":"要在本地使用文件网关和 PrivateLink 以及私有虚拟接口 (VIF) 访问 Amazon S3 存储桶，您需要设置基于 Amazon EC2 的代理服务器。要通过私有网络访问 Amazon S3，您需要使用 S3 的网关终端节点，并且这些终端节点不能直接从本地环境访问。代理服务器将通过 VPC 终端节点为 S3 提供访问，使其可由本地文件网关访问。我们建议使用针对网络带宽进行优化的 EC2 实例系列。"
    },
    {
        "query":"文件网关是否可以在一个区域中使用 VPC 终端节点并访问另一个区域中的 S3 存储桶？",
        "intention":"知识问答",
        "reply":"不能。"
    },
    {
        "query":"如何将 PrivateLink 与卷网关和磁带网关一起使用？",
        "intention":"知识问答",
        "reply":"卷和磁带网关通过 Storage Gateway VPC 终端节点直接连接到 AWS 服务，而无需 S3 的代理。"
    },
    {
        "query":"是否可以将 AWS PrivateLink 与 Storage Gateway 硬件设备一起使用？",
        "intention":"知识问答",
        "reply":"可以，但必须先将设备激活，然后再将其移至私有网络。"
    },
    {
        "query":"有望获得何种性能？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 位于您的应用程序和 Amazon 存储服务之间。 您能够获得的性能取决于您用来运行 Storage Gateway 软件的主机平台（硬件设备、虚拟机、Amazon EC2 实例）和许多其他因素，其中包括 iSCSI 启动器或 NFS 客户端与网关之间的网络带宽、底层本地磁盘的速度和配置、VM 的配置、分配给网关的本地存储量以及网关与 Amazon 存储之间的带宽。我们的技术文档提供了有关如何[优化 AWS Storage Gateway 环境以获得最佳性能](https://docs.aws.amazon.com/storagegateway/latest/userguide/Optimizing-common.html)的指导。"
    },
    {
        "query":"AWS Storage Gateway 的最低硬件和软件要求是什么？",
        "intention":"知识问答",
        "reply":"对于在虚拟机或 Amazon EC2 实例上运行 AWS Storage Gateway，请参阅《AWS Storage Gateway 用户指南》中的“要求”部分。[AWS Storage Gateway 还可以作为具有预先验证规范的硬件设备使用](https://www.amazon.com/dp/B079RBVX3M)。"
    },
    {
        "query":"AWS Storage Gateway 可执行哪种类型的数据缩减？",
        "intention":"知识问答",
        "reply":"卷网关和磁带网关可以压缩动态和静态数据，从而降低数据传输量和存储费用。AWS Storage Gateway 仅会上传发生变化的数据，以最大程度减少通过 Internet 发送的数据量。"
    },
    {
        "query":"AWS Storage Gateway 是否支持网络带宽限制？",
        "intention":"知识问答",
        "reply":"支持，您可以根据卷和磁带网关的计划限制网关在将数据与 AWS 同步时占用的网络带宽。您可以为入站和出站流量指定每周的哪一天、时间和带宽比率。"
    },
    {
        "query":"如何监控我的网关？",
        "intention":"知识问答",
        "reply":"您可以使用 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/) 监控[网关的性能指标和警报](http://docs.aws.amazon.com/storagegateway/latest/userguide/AWSStorageGatewayMetricsList-common.html)，从而深入了解存储、带宽、吞吐量和延迟信息。这些指标和警报可以直接从 CloudWatch 中查看；您也可以单击 AWS Storage Gateway 控制台中的链接，然后就可以直接转到正在查看的资源的 CloudWatch 指标或警报。有关更多信息，请参阅 CloudWatch 详细信息与定价页面。"
    },
    {
        "query":"如何衡量网关的缓存性能？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon CloudWatch 的各个指标（包括 CachePercentDirty、CacheHitPercent、CacheFree 和 CachePercentUsed）来进行衡量。单击 AWS Storage Gateway 控制台中网关详细信息选项卡上的“监控”链接，即可查看上述指标。"
    },
    {
        "query":"如何衡量网关使用的带宽？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon CloudWatch 的各个指标（包括 CloudBytesUploaded 和 CloudBytesDownloaded）来进行衡量。"
    },
    {
        "query":"如何为网关创建 CloudWatch 警报？",
        "intention":"知识问答",
        "reply":"您可以在创建新网关时或在从 AWS Storage Gateway 控制台创建新网关后创建推荐的 Amazon CloudWatch 警报。您也可以在 Amazon CloudWatch 控制台中为网关创建警报。"
    },
    {
        "query":"AWS Storage Gateway 如何管理更新？",
        "intention":"知识问答",
        "reply":"AWS Storage Gateway 会定期向您的网关虚拟机 (VM) 部署重要更新和软件补丁。您可以配置周度维护计划，以便控制向您的网关应用这些更新的时间。此外，您还可以通过 [AWS Storage Gateway 控制台](https://console.aws.amazon.com/storagegateway/home)或 API 手动应用可用更新。完成更新应该只需几分钟时间。有关更多信息，请访问我们文档中的[管理网关更新](http://docs.aws.amazon.com/storagegateway/latest/userguide/MaintenanceManagingUpdate-common.html)部分。"
    },
    {
        "query":"使用 AWS Storage Gateway 如何计费？",
        "intention":"知识问答",
        "reply":"我们将根据 3 个因素来计算 AWS Storage Gateway 的使用费：存储、请求和数据传输。有关详细的定价信息，请访问 [AWS Storage Gateway 定价](https://aws.amazon.com/cn/storagegateway/pricing/)页面。"
    },
    {
        "query":"我存储在 Deep Archive 池中的与 S3 Glacier Deep Archive 存储类关联的虚拟磁带将如何显示在我的 AWS 账单和 AWS 成本管理工具中？",
        "intention":"知识问答",
        "reply":"您存储在 Deep Archive 池中的虚拟磁带的使用情况和成本将在 AWS Storage Gateway Deep Archive 下每月 AWS 账单上显示为一个独立的服务行项目，与 AWS Storage Gateway 和成本分开。但是，如果您正在使用 AWS 成本管理工具，则存储在 Deep Archive 池中的虚拟磁带的使用情况和成本将包括在您的每月详细开支报表中的 AWS Storage Gateway 下，并且不会细分为单独的服务行项目。"
    },
    {
        "query":"如何判断我需要为多少存储空间付费？",
        "intention":"知识问答",
        "reply":"Billing and Cost Management 控制台中将显示当月至今每项服务的估计使用情况，包括 AWS Storage Gateway 卷和虚拟磁带的使用情况。对于单个卷或虚拟磁带的使用情况明细，您可以通过详细账单报告查看每个资源每天的使用情况。"
    },
    {
        "query":"使用文件网关审计日志时是否需要支付 CloudWatch 使用费？",
        "intention":"知识问答",
        "reply":"如果您配置了文件网关审计日志，那么您需要按照标准费率支付 Amazon CloudWatch Logs、Amazon CloudWatch Events 和 Amazon CloudWatch 指标的费用。"
    },
    {
        "query":"每月计费周期从何时开始计算？",
        "intention":"知识问答",
        "reply":"账单系统采用协调世界时间 (UTC)。从每月第一天的午夜 12 点 (UTC) 开始计算日历月。"
    },
    {
        "query":"硬件设备的成本是多少？",
        "intention":"知识问答",
        "reply":"请参考 [Storage Gateway 定价页面](https://aws.amazon.com/cn/storagegateway/pricing/)，获取当前定价。您还可以从 AWS Storage Gateway 控制台申请销售报价。"
    },
    {
        "query":"如何购买硬件设备？",
        "intention":"知识问答",
        "reply":"您可以通过 AWS 控制台中集成的简化采购流程购买硬件设备。您需要在收到销售报价之后提交购买订单，或者您可以安排预付款。"
    },
    {
        "query":"能否租赁或租用硬件设备？",
        "intention":"知识问答",
        "reply":"否。您需要在购买时支付全款。"
    },
    {
        "query":"AWS Premium Support 是否涵盖 AWS Storage Gateway？",
        "intention":"知识问答",
        "reply":"是，对于与使用 AWS Storage Gateway 相关的问题，AWS Premium Support 都提供支持。有关更多信息和定价，请参阅 [AWS Premium Support 详细信息页面](https://aws.amazon.com/cn/premiumsupport/)。"
    },
    {
        "query":"还有哪些支持选项可用？",
        "intention":"知识问答",
        "reply":"通过 [AWS Storage Gateway 论坛](https://forums.aws.amazon.com/forum.jspa?forumID=128)，您可以了解 AWS 社区内现存的大量知识。"
    },
    {
        "query":"如果我需要有关硬件设备的支持，应该联系谁？",
        "intention":"知识问答",
        "reply":"您可以联系负责提供 AWS Storage Gateway 软件和服务支持的 [AWS Support](https://aws.amazon.com/cn/contact-us/)。AWS Support 还会与硬件制造商的支持团队协调所有硬件相关事宜。我们建议您购买 [AWS Premium Support](https://aws.amazon.com/cn/premiumsupport/)。"
    },
    {
        "query":"在哪里可以找到硬件设备的服务标签（也称为序列号）？",
        "intention":"知识问答",
        "reply":"硬件设备的服务标签可以在 AWS Storage Gateway 控制台的“硬件”视图中找到。"
    },
    {
        "query":"如果硬件设备出现硬件问题，怎么办？",
        "intention":"知识问答",
        "reply":"AWS Support 与硬件制造商协作，共同提供硬件支持。硬件支持已包含在您购买的设备中，提供 3 年全天候电话支持以及下一个工作日现场更换部件服务。"
    },
    {
        "query":"硬件设备的保修条款是什么？",
        "intention":"知识问答",
        "reply":"硬件设备随附硬件制造商提供的 3 年保修以及下一个工作日现场更换部件服务。 [您可以在此处找到保修信息](https://aws.amazon.com/d1.awsstatic.com/cloud-storage/AWS-Storage-Gateway-Hardware-Appliance-Warranty.pdf)。\n详细了解 AWS Storage Gateway 定价"
    },
    {
        "query":"什么是 Amazon Polly？",
        "intention":"知识问答",
        "reply":"Amazon Polly 是一项将文本转换为逼真语音的服务。Amazon Polly 可以为现有应用程序添加先进的语音功能，支持构建具有语音功能的全新类别产品，从移动应用程序和汽车到设备和家电，均涵盖其中。Amazon Polly 可以提供几十种逼真的语音并支持多种语言，因此您可以选择最合适的语音，并在许多地理位置发布具有语音功能的应用程序。Amazon Polly 简单易用 – 您只需将要转换为语音的文本发送到 Amazon Polly API，Amazon Polly 便会立即将音频流返回到您的应用程序。您可以直接播放该音频流，也可将其存储为 MP3 等标准音频文件格式。Amazon Polly 支持语音合成标记语言 (SSML) 标签（如 prosody），因此您可以调整语速、音调或音量。Amazon Polly 是一种安全的服务，能够大规模地实现以上所有功能，且延迟较低。您可以缓存并重播 Amazon Polly 生成的语音，无需额外付费。注册 Amazon Polly 后，您可在第一年内每月免费转换数百万个字符。Amazon Polly 采用按需付费定价模式，对每条请求收取的费用较低，且对语音输出的存储和重复使用没有太多限制，让您能够经济高效在任何地方实现语音合成。"
    },
    {
        "query":"为什么要使用 Amazon Polly？",
        "intention":"知识问答",
        "reply":"您可以使用 Amazon Polly 为您的应用程序提供高质量的语音输出。Amazon Polly 是一项经济高效的服务，可以在极短的时间内做出响应，且几乎适用于各种使用情形，对存储和重复使用生成的语音也没有任何限制。"
    },
    {
        "query":"Amazon Polly 可以提供哪些功能？",
        "intention":"知识问答",
        "reply":"您可以使用标准化的语音合成标记语言 (SSML) 控制语音的各个方面，如发音、音量、音调、语速等。您可以使用新闻播音员风格为某些神经语音合成语音，使其听起来像电视或无线电新闻播音员。您可以根据音频流中的元数据，检测用户听到文本中的特定文字或语句的时间。这让开发人员能够将突出显示的图形和动画（例如头像的嘴唇动作）与合成语音同步。您可以使用自定义字典修改公司名称、首字母缩略词、外来词和新词等特定词语的发音，例如“P！nk”、“ROTFL”和“C'est la vie”（使用非法语语音说话时）。"
    },
    {
        "query":"什么是语音标记？",
        "intention":"知识问答",
        "reply":"语音标记用于补充从输入文本生成的合成语音。将这一元数据流与合成语音音频流配合使用，客户能够在应用程序中提供增强的视觉体验，例如语音同步动画或者卡拉 ok 式突出提示。\nAmazon Polly 使用以下四种元素来生成语音标记：\n语音标记以 JSON 流（具体指一组由新线隔开的独立 JSON 对象）的形式交付，在使用合成语音方法处理语音标记类参数时，涵盖上面一个到全部四个元素中的任何位置。有关更多信息，请参阅《Amazon Polly 开发人员指南》。"
    },
    {
        "query":"Amazon Polly 服务最常见的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"借助 Amazon Polly，您可以添加逼真的语音功能，让您的应用程序生动起来。例如，在电子学习和教育中，您可以利用 Amazon Polly 的文本转语音 (TTS) 功能构建应用程序，帮助有阅读障碍的人。Amazon Polly 可以用于帮助盲人和视障人士使用数字内容（例如电子书、新闻等）。Amazon Polly 还可用于公共交通和工业控制系统的通知系统，发布通知和紧急公告。很多设备（如机顶盒、智能手表、平板电脑、智能手机和 IoT 设备）都可以利用 Amazon Polly 来提供音频输出。Amazon Polly 可以用于电话服务解决方案，为交互式语音应答系统提供语音支持。问答游戏、动画、头像或旁白生成等应用程序是 Amazon Polly 等基于云的 TTS 解决方案的常见使用案例。"
    },
    {
        "query":"Amazon Polly 如何与其他 AWS 产品配合使用？",
        "intention":"知识问答",
        "reply":"将 Amazon Polly 与 Amazon Lex 结合使用，开发人员可以为应用程序构建功能齐全的语音用户界面。与 Amazon Connect 结合，Amazon Polly 语音可以用于构建基于云的自助呼叫中心服务。此外，移动应用程序和物联网 (IoT) 解决方案的开发人员还可以利用 Amazon Polly 将语音输出添加到自己的系统中。"
    },
    {
        "query":"与安装在设备上的文本转语音解决方案相比，基于云的文本转语音解决方案有哪些优势？",
        "intention":"知识问答",
        "reply":"设备上的文本转语音解决方案需要大量的计算资源，因此需要设备提供大量 CPU 功率、RAM 和磁盘空间。这导致开发成本增加以及平板电脑、智能手机等设备的功耗增大。相比之下，在云中完成文本到语音的转换，可以显著减少对本地资源的需求，因此有可能支持以各种可用的语言和声音提供最优质的语音。此外，所有最终用户都可以立即使用语音纠正和语音增强功能，且不需要对任何设备额外进行更新。基于云的文本转语音 (TTS) 是独立于平台的，因此可以最大程度地减少开发时间和工作量。"
    },
    {
        "query":"如何开始使用 Amazon Polly？",
        "intention":"知识问答",
        "reply":"您只需登录到您的 AWS 账户，前往 Amazon Polly 控制台（AWS 控制台的一部分），即可开始使用该产品。接下来，您可以使用控制台输入任何文本并收听生成的语音，或将其另存为音频文件。"
    },
    {
        "query":"目前，哪些区域提供 Amazon Polly 服务？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)了解支持 Amazon Polly 标准语音的所有区域。这些区域的以下子集支持神经语音：美国东部（弗吉尼亚北部）、美国西部（俄勒冈）、加拿大（中部）、亚太地区（东京）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、非洲（开普敦）、欧洲（伦敦）、欧洲（法兰克福）、欧洲（爱尔兰）亚太地区和 AWS GovCloud (美国西部)。"
    },
    {
        "query":"Amazon Polly 支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"Amazon Polly 支持 AWS 软件开发工具包中包含的所有编程语言（Java、Node.js、.NET、PHP、Python、Ruby、Go 和 C++）以及 AWS 移动软件开发工具包中包含的所有编程语言 (iOS/Android)。Amazon Polly 还支持 HTTP API，因此您可以实施自己的访问层。"
    },
    {
        "query":"Amazon Polly 支持哪些音频格式？",
        "intention":"知识问答",
        "reply":"借助 Amazon Polly，您可以近乎实时地将音频流式传输给您的用户。Amazon Polly 还提供多种采样率供您选择，便于您为应用程序优化带宽和音频质量。Amazon Polly 支持 MP3、Vorbis 和原始 PCM 音频流格式。"
    },
    {
        "query":"支持哪些语言？",
        "intention":"知识问答",
        "reply":"请参阅[文档](https://docs.aws.amazon.com/polly/latest/dg/SupportedLanguage.html)，了解 Amazon Polly 支持的语言的完整列表。"
    },
    {
        "query":"Amazon Polly 是否有 AWS 服务限制？",
        "intention":"知识问答",
        "reply":"为了帮助保证 AWS 资源的可用性并最大限度降低新客户的账单风险，AWS 对每个账户均设置有服务限制。使用 Amazon Polly 为应用程序提供高质量语音输出功能时，需遵循默认的服务限制，包括对限制设置、操作和语音合成标记语言 (SSML) 的使用的限制。有关详情，请参阅《Amazon Polly 开发人员指南》中的 [Limits in Amazon Polly](http://docs.aws.amazon.com/polly/latest/dg/limits.html)。将 Polly Amazon 与其他 AWS 服务（例如可以高效进行批处理的 AWS Batch）结合使用，您可以在这些服务的限制内充分利用 Amazon Polly。"
    },
    {
        "query":"Amazon Polly 是否通过了 HIPAA 认证？",
        "intention":"知识问答",
        "reply":"Amazon Polly 服务符合 HIPAA 要求，包含在 AWS 商业伙伴协议 (AWS BAA) 中。如果您签订了 AWS BAA，Amazon Polly 将仅根据 AWS BAA 条款使用、披露和维护您的受保护健康信息 (PHI)，而不会根据 Amazon Polly 常见问题“数据隐私”部分中的规定。"
    },
    {
        "query":"如何开始使用 Amazon Polly 的“品牌之声”功能？",
        "intention":"知识问答",
        "reply":"如果您对使用 Amazon Polly 打造“品牌之声”感兴趣，请联系您的 AWS 客户经理或[联系我们](https://pages.awscloud.com/Amazon_Polly_Brand_Voice.html)了解更多信息。"
    },
    {
        "query":"是否可以使用 Amazon Polly 生成可多次重播的静态语音提示？",
        "intention":"知识问答",
        "reply":"可以。Amazon Polly 对此没有限制，且不会额外收取任何费用。"
    },
    {
        "query":"是否可以将 Amazon Polly 生成的内容用在大规模通知系统（如火车站的通知系统）中？",
        "intention":"知识问答",
        "reply":"可以。Amazon Polly 对此没有限制，且不会额外收取任何费用。"
    },
    {
        "query":"AWS 免费套餐是否包括 Amazon Polly？",
        "intention":"知识问答",
        "reply":"是的。作为 [AWS 免费使用套餐](https://aws.amazon.com/cn/free/)的一部分，您可以开始免费使用 Amazon Polly。注册后，Amazon Polly 新客户可以在前 12 个月内免费每月合成数百万个字符。请参阅 [Amazon Polly 定价页面](https://aws.amazon.com/cn/polly/pricing/)，了解最新的定价信息。"
    },
    {
        "query":"定价中包含税费了吗？",
        "intention":"知识问答",
        "reply":"有关税费的详细信息，请参阅 Amazon Web Services 税务帮助。"
    },
    {
        "query":"Amazon Polly 是否会存储处理过的文本输入？AWS 如何使用这些输入？",
        "intention":"知识问答",
        "reply":"Amazon Polly 可能会存储和使用仅由该服务处理的文本输入，以提供和维护服务，以及改进和提高 Amazon Polly 和其他 Amazon 机器学习/人工智能技术的质量。为了持续改善您的 Amazon Polly 客户体验并促进相关技术的开发和培训，我们有必要使用您的内容。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。您可以通过使用 AWS Organizations 退出策略，选择不再使用您的内容来改进和提高 Amazon Polly 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"谁有权访问 Amazon Polly 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问 Amazon Polly 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 https://aws.amazon.com/compliance/data-privacy-faq/。"
    },
    {
        "query":"由 Amazon Polly 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"Amazon Polly 处理的内容是否会移到我使用 Amazon Polly 所在的 AWS 区域之外？",
        "intention":"知识问答",
        "reply":"Amazon Polly 处理的任何内容都会被加密，并静态存储在您使用 Amazon Polly 所在的 AWS 区域中。Amazon Polly 处理的部分内容可能存储在另一个 AWS 区域中，仅用于持续改进和提高您的 Amazon Polly 客户体验及其他 Amazon 机器学习/人工智能技术。如果您通过联系 AWS Support，选择不再使用您的内容来发展 Amazon Polly 和其他 Amazon 机器学习/人工智能技术的质量，您的内容将不会存储在其他 AWS 区域中。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"是否可以将 Amazon Polly 用于针对不满 13 岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 Amazon Polly 服务条款的规定，包括按照 COPPA 的要求来提供任何需要的通知并获得任何需要的、可验证的家长同意，才能将 Amazon Polly 用于全部或部分针对不满 13 岁的儿童的网站、项目或其他应用程序。"
    },
    {
        "query":"如何确定我的网站、程序或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、程序或其他应用程序是否受 COPPA 约束的指南，请直接参阅[美国联邦贸易委员会](https://www.ftc.gov/tips-advice/business-center/guidance/complying-coppa-frequently-asked-questions)提供并维护的各种资源。该网站还提供有关如何确定某种服务是否全部或部分针对未满 13 岁儿童的信息。"
    },
    {
        "query":"Polly 录音由谁拥有？",
        "intention":"知识问答",
        "reply":"在您和 AWS 之间，您的 Polly 输出属于您所有。如果您在 Polly 中输入属于第三方所有的文本，则您需要取得相应的权利才能操作。有关更多信息，请参阅我们的[客户协议](https://aws.amazon.com/cn/agreement/)并了解它会如何处理您的“内容”\n了解有关 Amazon Polly 定价的更多信息"
    },
    {
        "query":"Who are the primary users of AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange makes it easy for AWS customers to securely exchange and use third-party data on AWS. Data analysts, product managers, portfolio managers, data scientists, quants, clinical trial technicians, and developers in nearly every industry would like access to more data to drive analytics, train machine learning (ML) models, and make data-driven decisions. But there is no one place to find data from multiple providers and no consistency in how providers deliver data, leaving them to deal with a mix of shipped physical media, FTP credentials, and bespoke API calls. Conversely, many organizations would like to make their data available for either research or commercial purposes, but it’s too hard and expensive to build and maintain data delivery, entitlement, and billing technology, which further depresses the supply of valuable data."
    },
    {
        "query":"What AWS Regions is AWS Data Exchange available in?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange has a single global product catalog oﬀered by providers available from any supported AWS Region. You can see the same catalog regardless of which Region you are using. The resources underlying the product (data sets, revisions, assets) are regional resources that you manage programmatically or through the AWS Data Exchange console in speciﬁc AWS Regions. For a list of AWS Regions in which AWS Data Exchange is available today, see [Service endpoints](https://docs.aws.amazon.com/general/latest/gr/dataexchange.html#dataexchange_region)."
    },
    {
        "query":"What is the difference between AWS Data Exchange and the Registry of Open Data on AWS?",
        "intention":"知识问答",
        "reply":"All publicly available data sets on the [Registry of Open Data](https://registry.opendata.aws/) on AWS are also available through [AWS Data Exchange](https://aws.amazon.com/marketplace/search/results?FULFILLMENT_OPTION_TYPE=DATA_EXCHANGE&CONTRACT_TYPE=OPEN_DATA_LICENSES&filters=FULFILLMENT_OPTION_TYPE%2CCONTRACT_TYPE). On AWS Data Exchange, customers can now discover and access more than 100 petabytes of high-value, cloud-optimized data sets available for public use from leading organizations such as NOAA, NASA, or the UK Met Office. These include open data sets hosted by the [AWS Open Data Sponsorship Program](https://aws.amazon.com/opendata) and in the [Amazon Sustainability Data Initiative](https://sustainability.aboutamazon.com/environment/the-cloud/asdi) (ASDI) catalog. Open data sets are different than other commercial or free data sets in four key ways. First, AWS Data Exchange requires customers to explicitly agree to the Data Subscription Agreement outlining the terms that the data provider set when publishing their product, whereas open data does not have terms of use and is only governed by the provider specific open data license. Second, customers must authenticate using an AWS account to subscribe to commercial or free data sets whereas open data sets can be accessed without any authentication via S3 APIs. Third, AWS Data Exchange gives data providers access to daily, weekly and monthly reports detailing subscription activity, whereas with Registry of Open Data on AWS, data providers must analyze their own logs to track usage of data. Finally, to become a data provider on AWS Data Exchange, qualified customers must [register as a data provider](https://aws.amazon.com/marketplace/management/tour/) on the AWS Marketplace Management Portal to be eligible to list both free and commercial products, whereas any customer can add free data to [Registry of Open Data on AWS through GitHub](https://github.com/awslabs/open-data-registry/) and may apply to the Open Data Sponsorship Program for AWS to sponsor the costs of storage and bandwidth for select open data sets."
    },
    {
        "query":"What is AWS Data Exchange for APIs?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange for APIs is a feature that enables customers to find, subscribe to, and use third-party API products from providers on AWS Data Exchange. With AWS Data Exchange for APIs, customers can use AWS-native authentication and governance, explore consistent API documentation, and utilize supported AWS SDKs to make API calls. Now, by adding their APIs to the AWS Data Exchange catalog, data providers can reach millions of AWS customers that consume API-based data and more easily manage subscriber authentication, entitlement, and billing."
    },
    {
        "query":"What type of data can I subscribe to on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"Today, AWS Data Exchange contains more than 3,500 data products from a broad range of domains, including financial services (for example, top US businesses by revenue); healthcare and life sciences (for example, population health management); geospatial (for example, satellite imagery); weather (for example, historical and future trajectories of temperature); and mapping (for example, street level imagery and foot traffic patterns). For a complete list of data providers, navigate to [the AWS Data Exchange catalog](https://console.aws.amazon.com/dataexchange/home?region=us-east-1#/products). If customers need additional data sources not currently available on AWS Data Exchange, they can [log these requests](https://console.aws.amazon.com/dataexchange/home?region=us-east-1#/products/product-request) here."
    },
    {
        "query":"How can I see the catalog of AWS Data Exchange products?",
        "intention":"知识问答",
        "reply":"Anyone can browse the AWS Data Exchange catalog in [AWS Marketplace](https://aws.amazon.com/marketplace/b/2649387011?ref_=header_nav_category_2649387011) under the Data category, or by searching AWS Marketplace for keywords of interest. Authenticated AWS customers can also browse the AWS Data Exchange catalog alongside existing subscriptions on the AWS Data Exchange console. For more information about subscribing to data products, see [Getting started as a subscriber](https://docs.aws.amazon.com/data-exchange/latest/userguide/subscribe-to-data-sets.html#subscriber-getting-started)."
    },
    {
        "query":"How will I know when new revisions to data sets I’m subscribed to become available?",
        "intention":"知识问答",
        "reply":"As a subscriber with an active subscription to a product, you'll receive an Amazon CloudWatch Events event from AWS Data Exchange every time the provider publishes new revisions. You can use this CloudWatch event to automate consumption of new data. For more information about CloudWatch Events, see [Logging and monitoring on AWS Data Exchange](https://docs.aws.amazon.com/data-exchange/latest/userguide/logging-and-monitoring.html)."
    },
    {
        "query":"Can I migrate preexisting data subscriptions to be delivered by AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"Yes. AWS Data Exchange allows qualified data providers to fulfill to existing subscribers using a Bring Your Own Subscription (BYOS) entitlement at no additional cost. With a BYOS offer, the existing billing relationship will continue between you and the data provider. Talk to your data provider about using this capability."
    },
    {
        "query":"What are the subscription durations that are available for AWS Data Exchange products?",
        "intention":"知识问答",
        "reply":"Data providers list products subscriptions with 1- to 36-month duration terms. You can find subscription duration options on each product’s detail page."
    },
    {
        "query":"Can I set my subscription to auto-renew?",
        "intention":"知识问答",
        "reply":"Providers have the option to enable auto-renewal on individual offers. As a subscriber, you can choose to set your subscription to auto-renew on the offers that have the auto-renewal functionality enabled. Auto-renewal is available for public and private offers that do not have payment schedules."
    },
    {
        "query":"Can data providers change the terms of the offer that I am subscribed to? How would it affect my subscription and renewal?",
        "intention":"知识问答",
        "reply":"Yes. Data providers can update the terms of the offer at any time, but this will not affect existing subscriptions. For subscriptions set to auto-renew, AWS Data Exchange will automatically renew the subscription at the latest terms that the provider specified on or by renewal date, which may be different from the original subscription terms. For more information, see [Product subscriptions](https://docs.aws.amazon.com/data-exchange/latest/userguide/product-subscriptions.html)."
    },
    {
        "query":"How are refunds handled?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange requires data providers to specify their refund policy, which you can see on the subscription details page. For any refund requests, you'll need to contact the provider directly. After a provider approves a refund request, AWS will process and issue the approved refund."
    },
    {
        "query":"How do I know that data I subscribe to is free of any malware?",
        "intention":"知识问答",
        "reply":"Security and Compliance is a shared responsibility ([https://aws.amazon.com/compliance/shared-responsibility-model/](https://aws.amazon.com/compliance/shared-responsibility-model/)) between AWS and the customer. To promote a safe, secure, and trustworthy service for everyone, AWS Data Exchange scans data files hosted in S3 buckets it manages before making them available to subscribers. If AWS detects malware, AWS will remove the affected file(s). AWS Data Exchange does not guarantee that the data you consume as a subscriber is free of any potential malware. Customers are encouraged to conduct their own additional due diligence to ensure compliance with their internal security controls. You can explore many third-party anti-malware and security products in AWS Marketplace."
    },
    {
        "query":"How do I remain compliant with applicable data privacy laws when subscribing to AWS Data Exchange products?",
        "intention":"知识问答",
        "reply":"Security and Compliance is a [shared responsibility](https://aws.amazon.com/compliance/shared-responsibility-model/) among AWS, the data provider, and the subscriber. Detailed restrictions around eligible data sets and other related legal compliance matters are set forth in [Terms and Conditions for AWS Marketplace Providers](https://aws.amazon.com/marketplace/management/terms), which every data provider must agree to before listing any data products. If AWS learns that these terms are breached in any way, AWS will remove such content from AWS Data Exchange and the data provider may be suspended from the service.\nProviders and subscribers are responsible for conducting their own additional due-diligence to ensure compliance with any data privacy laws. If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on [Report Amazon AWS abuse](https://support.aws.amazon.com/#/contacts/report-abuse)."
    },
    {
        "query":"Are there are any restrictions for how AWS Data Exchange and any data obtained through AWS Data Exchange can be used?",
        "intention":"知识问答",
        "reply":"Yes, AWS explicitly prohibits the use of AWS Data Exchange for any illegal or fraudulent activities. Data may not be used for any activities that result in the violation of an individual’s rights or unlawfully discriminate against others based on race, ethnicity, sexual orientation, gender identity, or other related groups. Subscribers may not use any content obtained through AWS Data Exchange that was anonymized or aggregated (such that it is no longer associated with an identifiable individual) by the data provider to create, generate, or infer any information relating to a person’s identity (for example, attempting to triangulate with other data sources)."
    },
    {
        "query":"How do I report abusive content or request information be removed from a product suspected of abuse?",
        "intention":"知识问答",
        "reply":"If you suspect that a data product or AWS Data Exchange resources are being used for abusive or illegal purposes, you can complete and submit the form found on [Report Amazon AWS abuse](https://support.aws.amazon.com/#/contacts/report-abuse). If AWS learns that our terms are breached in any way, AWS may remove the subscriber’s access to the data product and the data provider or the subscriber may be suspended or terminated from future use of AWS Data Exchange"
    },
    {
        "query":"I currently consume third-party data directly into my S3 bucket(s). Why should I consider using AWS Data Exchange to consume data from third parties instead?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange centralizes, simplifies, and accelerates your data acquisition process.\nAWS Data Exchange allows you to consolidate your ingestion across data providers and receive your data using a single API. You can easily subscribe to new data products, and migrate any existing data feeds through the Bring Your Own Subscription feature.\nAWS Data Exchange sends you a CloudWatch Events event as new data is published, allowing you to automate ingestion without having to manage any physical media, FTP credentials, or other legacy technology. It also stores copies of data you've licensed, allowing you to access point-in-time history all in one secure location.\nAWS Data Exchange also centralizes your billing so you can receive one invoice from AWS instead of one for each data provider. With the AWS Data Exchange console, you can easily track your subscriptions in one place, and better manage your data pipeline."
    },
    {
        "query":"How do I pay for my data product subscriptions?",
        "intention":"知识问答",
        "reply":"When you purchase a data product on AWS Data Exchange with upfront payments, you'll receive an invoice from AWS immediately. When you purchase a data product on AWS Data Exchange with multiple payments, you'll receive an invoice based on the dates specified in the [payment schedule](https://docs.aws.amazon.com/data-exchange/latest/userguide/product-subscriptions.html) that will appear as part of your AWS Marketplace charges. You can see a breakout of charges for each data product by name in the Detail section of the invoice. You'll receive separate bills for usage of AWS infrastructure and analytics services such as Amazon Simple Storage Service (Amazon S3) or Amazon Athena. For more information related to AWS Billing and Cost Management, see [Paying for products](https://docs.aws.amazon.com/marketplace/latest/buyerguide/buyer-paying-for-products.html)."
    },
    {
        "query":"How do I find API products in the AWS Data Exchange catalog?",
        "intention":"知识问答",
        "reply":"You can find products containing APIs in the [AWS Marketplace catalog](https://aws.amazon.com/marketplace/search/results?FULFILLMENT_OPTION_TYPE=DATA_EXCHANGE&DATA_AVAILABLE_THROUGH=API_GATEWAY_APIS&filters=FULFILLMENT_OPTION_TYPE%2CDATA_AVAILABLE_THROUGH), or you can navigate to the [AWS Data Exchange catalog](https://console.aws.amazon.com/dataexchange/home?region=us-east-1#/products) and select *API* under the *Data available through* filter."
    },
    {
        "query":"How do I subscribe to an API product?",
        "intention":"知识问答",
        "reply":"After you’ve found the API that you want to subscribe to, select the product to learn more on the product detail page. Next, choose *Continue to subscribe*, review the subscription terms, and then choose the *Subscribe* button at the bottom of the page.  \n   \n Note: You may be asked to submit information to the data provider before you can request to subscribe to their product. For more information on subscribing and using an API product, see the [Subscribing to a product containing APIs](https://docs.aws.amazon.com/data-exchange/latest/userguide/subscribing-to-product.html#subscribing-to-API-product.html) topic in the *AWS Data Exchange User Guide*."
    },
    {
        "query":"How do I make an API call?",
        "intention":"知识问答",
        "reply":"First, ensure you have successfully subscribed to a product containing an API data set. Then, navigate to the product’s asset detail page to view API schemas and code snippets that will help you structure your API call. You can also utilize the AWS SDK to automatically sign your API requests with your AWS credentials. For more information about how to structure API calls to AWS Data Exchange products containing API data sets, see the [Making an API call (console)](https://docs.aws.amazon.com/data-exchange/latest/userguide/subscribing-to-product.html#make-api-call-console) in the *AWS Data Exchange User Guide.*"
    },
    {
        "query":"Does AWS Data Exchange for APIs have a Service Level Agreement (SLA)?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange for APIs does not currently offer an SLA."
    },
    {
        "query":"Are there any AWS Data Exchange for APIs-specific SDKs that I should be aware of?",
        "intention":"知识问答",
        "reply":"We have added AWS Data Exchange for APIs-specific operations to the following SDKs:\nFor more information, see the [AWS Data Exchange API Reference](https://docs.aws.amazon.com/data-exchange/latest/apireference/aws-data-exchange-api-reference.pdf)."
    },
    {
        "query":"How do I qualify to become a data provider on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"To become a data provider on AWS Data Exchange, data providers must agree to the [Terms and Conditions for AWS Marketplace Providers](https://aws.amazon.com/marketplace/management/terms) (“AWS Marketplace Terms & Conditions”). Data providers must use a valid legal entity domiciled in the United States or a member state of the EU, supply valid banking and taxation identification, and be qualified by the AWS Data Exchange business operations team. Each data provider will also undergo a detailed review by the AWS Data Exchange team prior to being granted permission to list data products on the catalog."
    },
    {
        "query":"How is data organized in AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"Data in AWS Data Exchange is organized using three building blocks: data sets, revisions, and assets. A data set is a container for data that belongs together (for example, end of data pricing for equities trading in the US). Data sets contain a series of revisions, which data providers publish as needed to make new assets available. Revisions can represent changes or new data (for example, today’s end of day prices), corrections to previous revisions, or entirely new snapshots. Assets are any file that can be stored in Amazon Simple Storage Service (S3) (for example, CSV, Parquet, or image files). For more information about working with data, see [Data in AWS Data Exchange](https://docs.aws.amazon.com/data-exchange/latest/userguide/data-sets.html). Using these building blocks, you can organize the data hierarchically to build complex data models or as single data files."
    },
    {
        "query":"After I create data sets, how do I publish and make them available to my subscribers?",
        "intention":"知识问答",
        "reply":"Data sets are made available to subscribers as part of a product. A product is a collection of one or more data sets, metadata that makes the product discoverable in the AWS Data Exchange catalog, pricing, and a Data Subscription Agreement with terms for your customers. For more information, see [Publishing a new product](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html)."
    },
    {
        "query":"Can I choose which customers can subscribe to my data?",
        "intention":"知识问答",
        "reply":"Yes. You have an option to enable subscription verification on any public product, which will require prospective subscribers to fill out a subscription request form including their identity and intended use-case details before subscribing. For these products, you'll have up to 45 days to either approve or decline the subscription request. Note that public products that include personal data are required to have subscription verification enabled. For more information, see [Subscription verification for providers](https://docs.aws.amazon.com/data-exchange/latest/userguide/subscription-verification-pro.html).\nYou can also offer private products to specific subscribers by using their AWS Account ID. Private products can be custom-made from existing products on the public catalog or completely new products only offered to the specific customers of your choosing and not listed on the public catalog."
    },
    {
        "query":"Do I have to package files in a specific format?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange allows you to package files in any file format, but you’ll want to consider what will allow subscribers to most conveniently gain insight from the data. Parquet formatted files, for example, will allow subscribers to instantly run queries using Amazon Athena in a cost-effective way. Binary or other proprietary file formats will require that subscribers understand how to parse the information, which AWS recommends explaining in each product description."
    },
    {
        "query":"Who owns the data I am distributing as a provider through AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"You retain ownership of the data you distribute as a data provider on AWS Data Exchange. The [Terms and Conditions for AWS Marketplace Providers](https://aws.amazon.com/marketplace/management/seller-settings/terms) require each data provider to attest that they have the legal right to distribute the data they publish. Subscribers must legally agree to the Data Subscription Agreement specified by the data provider before gaining access to data sets contained in a product, which remains available for both data providers and subscribers. Consistent with the AWS acceptable use policy, AWS Data Exchange may suggest corrective action where there is evidence of abuse, but it is the data provider’s responsibility to enforce and govern the terms of use."
    },
    {
        "query":"How do I specify the Data Subscription Agreement (DSA)?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange provides an optional Data Subscription Agreement (DSA) template that incorporates inputs from multiple AWS customers and data providers. You can choose to use this DSA template, copy and edit it with their own terms and conditions, or specify custom terms by uploading a DSA of your choice. AWS Data Exchange will associate the DSA specified for the product without any further modifications. For more information, see [Publishing a new product](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html)."
    },
    {
        "query":"What ways can I price my data sets?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange currently supports subscription-based pricing from 1- to 36-month duration terms."
    },
    {
        "query":"Is AWS Data Exchange suitable for data providers who want to distribute their data for free?",
        "intention":"知识问答",
        "reply":"Yes. Many data providers make their data products available for free for research, scientific, or other noncommercial use cases."
    },
    {
        "query":"Can I customize pricing or terms for select customers?",
        "intention":"知识问答",
        "reply":"Yes. Private offers allow you to make public products available to select AWS customers and to set terms including price, duration, payment schedule, DSA, or refund policy. For more information, see [Create private offers](https://docs.aws.amazon.com/data-exchange/latest/userguide/private-offer-configuration.html)."
    },
    {
        "query":"Are there any restrictions on what data can be made available on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"Yes. [Publishing guidelines](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-guidelines.html) for listing products on AWS Data Exchange and [Terms and Conditions for AWS Marketplace Providers](https://aws.amazon.com/marketplace/management/terms) restrict certain categories of data. Unless a provider is enrolled in the Extended Provider Program, data products listed on AWS Data Exchange may not include information that can be used to identify any person, except information that is already legally available to the public, such as newspaper articles, open court records, public company filings, or public online profiles. For more information about the Extended Provider Program, please [contact AWS Support](https://console.aws.amazon.com/support/home#/case/create?issueType=customer-service)."
    },
    {
        "query":"Can I remove a product that I published from the catalog?",
        "intention":"知识问答",
        "reply":"Yes. You can unpublish a product at any time to ensure that no new subscribers are able to view and subscribe to your product, including auto-renewal cancellation for existing subscribers. You'll need to keep data current for any existing subscribers until each subscription expires."
    },
    {
        "query":"What happens if I need to remove data from AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"You can remove or change the price or Data Subscription Agreement (DSA) of a product at any time, although existing subscriptions will remain in effect until their next renewal. If a data provider erroneously publishes data, you can open a support case [open a support case](https://console.aws.amazon.com/support/cases#/create?issueType=customer-service) to have the data unpublished."
    },
    {
        "query":"How do I know who is subscribing to the data I have listed on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange provides daily, weekly, and monthly reports detailing subscription activity."
    },
    {
        "query":"When and how often will I receive payments?",
        "intention":"知识问答",
        "reply":"You will receive a disbursement for subscriptions less fulfillment fees once a month. AWS will disburse all funds that AWS has received from subscribers by that date to the bank account linked to the AWS account that you used at registration."
    },
    {
        "query":"How will AWS handle collection and remittances of US sales and use tax?",
        "intention":"知识问答",
        "reply":"When listing your data sets, you can enable collection and remittance of US sales and use tax. You can also configure your tax nexus to account for places where you have a physical presence to direct AWS to collect appropriate taxes. It's helpful to review the [AWS Marketplace U.S Tax Collection Support Terms and Conditions](https://s3.amazonaws.com/aws-mp-seller-tax-terms/AWS_Marketplace_Tax_Support_Terms_and_Conditions.pdf). For details on sales tax collection in other geographies, see [AWS Marketplace Sellers & Tax Collection](https://aws.amazon.com/tax-help/marketplace/)."
    },
    {
        "query":"Is Amazon.com or AWS providing customers’ data on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"No. Neither Amazon.com nor AWS are providing customers’ data on AWS Data Exchange."
    },
    {
        "query":"Can AWS access data products listed on AWS Data Exchange?",
        "intention":"知识问答",
        "reply":"AWS is vigilant about our customers’ privacy. Companies listing data products on the AWS Data Exchange own them and are able to maintain control over who accesses their content. AWS does not access or use data products except as necessary to provide the AWS Data Exchange service."
    },
    {
        "query":"I currently publish data directly into my subscribers' S3 buckets. Why should I consider using AWS Data Exchange to publish data to third parties instead?",
        "intention":"知识问答",
        "reply":"With AWS Data Exchange you can publish data simultaneously to all your customers and spend more time growing your business rather than managing logistics.\nAWS Data Exchange allows you to publish data to your customers through an easy-to-use API and console. The data model for AWS Data Exchange simplifies managing and publishing data through three reusable constructs: data sets, revisions, and assets. AWS customers can subscribe to these published data products directly from AWS Marketplace. The service automatically grants entitlements to customers who have an active subscription to the product, which means that you don’t have to manually configure and maintain custom permissions to an Amazon Simple Storage Service (S3) bucket for each subscription.  \n   \n AWS Data Exchange automatically sends an Amazon CloudWatch Events event to all subscribers when new revisions are published, which allows subscribers to automate their consumption of new data. When a subscription is no-longer active, AWS Data Exchange revokes that subscriber's entitlement to your data.  \n   \n If your product is already available on AWS Data Exchange, you can simply use Bring Your Own Subscription (BYOS) to configure an entitlement to your existing subscribers for no additional cost and without any additional programming work. For more information about using BYOS to migrate and fulfill existing subscriptions with AWS customers, see [Create Bring Your Own Subscription offers](https://docs.aws.amazon.com/data-exchange/latest/userguide/create-byos-offers.html)."
    },
    {
        "query":"How do I publish a product containing APIs?",
        "intention":"知识问答",
        "reply":"As a provider, you first need to set up an AWS account and [register as an AWS Marketplace seller](https://docs.aws.amazon.com/marketplace/latest/userguide/seller-registration-process.html). You can then publish an API product by following the steps detailed in the [Publishing a product containing APIs](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html#publish-API-product) topic in the *AWS Data Exchange User Guide*."
    },
    {
        "query":"Do providers have to offer a Service Level Agreement (SLA) to AWS Data Exchange when offering an API product?",
        "intention":"知识问答",
        "reply":"AWS Data Exchange for APIs does not require providers to offer an uptime or availability SLA. Providers and subscribers can negotiate custom terms as part of a DSA. See [Publishing Products](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-products.html) for further information."
    },
    {
        "query":"What guidelines do I need to follow as a provider on AWS Data Exchange for APIs?",
        "intention":"知识问答",
        "reply":"In addition to following guidelines under the [Terms and Conditions for AWS Marketplace Sellers](http://aws.amazon.com/marketplace/management/seller-settings/terms) and the [AWS Customer Agreement](https://aws.amazon.com/agreement/), providers of products containing APIs must respond to subscriber support inquiries within 1 business day, as set forth in the *AWS Data Exchange User Guide*. Not following the guidelines may result in products being removed from AWS Data Exchange. For more information, see [Publishing guidelines](https://docs.aws.amazon.com/data-exchange/latest/userguide/publishing-guidelines.html) topic in the *AWS Data Exchange User Guide*."
    },
    {
        "query":"Can products contain APIs, Amazon S3 objects, and Amazon Redshift data shares?",
        "intention":"知识问答",
        "reply":"Yes. As a data provider, you can publish products containing multiple data set types."
    },
    {
        "query":"什么是 Amazon CodeGuru？",
        "intention":"知识问答",
        "reply":"CodeGuru 具有两个组件：Amazon CodeGuru Security 和 Amazon CodeGuru Profiler。CodeGuru Security 是一款基于机器学习（ML）和程序分析的工具，可以发现 Java、Python 和 JavaScript 代码中的安全漏洞。CodeGuru Security 还会扫描硬编码凭证。CodeGuru Profiler 可优化在生产期间运行的应用程序的性能，识别出最昂贵的代码行，从而显著降低运营成本。"
    },
    {
        "query":"如何开始使用 CodeGuru？",
        "intention":"知识问答",
        "reply":"CodeGuru 现已正式发布。您现在就可以在 [Amazon CodeGuru 控制台](https://console.aws.amazon.com/codeguru/home)中开始使用。"
    },
    {
        "query":"CodeGuru 在哪些 AWS 区域提供？",
        "intention":"知识问答",
        "reply":"要了解支持该服务的区域，请访问所有 AWS 全球基础设施的 [AWS 区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。有关更多信息，请参阅“AWS 一般参考”中的[区域和端点](http://docs.aws.amazon.com/general/latest/gr/rande.html#machinelearning_region)。"
    },
    {
        "query":"什么是 Amazon CodeGuru Security？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 是一款基于机器学习和程序分析的代码扫描工具，可以发现 Java、Python 和 JavaScript 代码中的安全漏洞。"
    },
    {
        "query":"支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 目前支持扫描 Java、Python 和 JavaScript 代码。  \n   \n 问：CodeGuru Security 检测哪些类型的问题？\nCodeGuru Security 检测[开放全球应用程序安全项目（OWASP）十大](https://owasp.org/www-project-top-ten/)问题、[常见弱点枚举（CWE）前 25](https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html) 个问题、日志注入、机密以及 AWS API 和 SDK 的安全使用。 有关 CodeGuru Security 发现的漏洞的更多详细信息，请参阅 [Amazon CodeGuru 探测器库](https://docs.aws.amazon.com/codeguru/detector-library/)。"
    },
    {
        "query":"如何开始使用 CodeGuru Security？",
        "intention":"知识问答",
        "reply":"访问 CodeGuru 控制台，将 CodeGuru 安全性集成到您的开发人员生命周期中。您可以集成到持续集成和交付（CI/CD）工具、存储库扫描和集成式开发环境（IDE）中。"
    },
    {
        "query":"CodeGuru Security 会访问我的代码吗？",
        "intention":"知识问答",
        "reply":"为了生成建议，CodeGuru Security 需要获得代码的只读访问权限。您的信任、隐私与内容的安全性是我们最重视的问题。我们会采取适当的控制措施（包括传输中加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺来使用您的内容。我们还支持客户经理 KMS 密钥（CMCMK）进行加密。有关更多信息，请参阅[数据隐私常见问题](https://aws.amazon.com/compliance/data-privacy-faq/)。"
    },
    {
        "query":"CodeGuru Security 会保留我的代码副本吗？",
        "intention":"知识问答",
        "reply":"不，CodeGuru 安全不会存储您的源代码。"
    },
    {
        "query":"CodeGuru Security 如何接受训练以提供智能建议？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 使用规则挖掘和监督机器学习模型（结合使用逻辑回归和神经网络）进行训练。例如，在进行与敏感数据泄漏有关的训练时，它会全面分析代码以确定所有使用资源或敏感数据的代码路径，并创建代表这些路径的功能集，然后将其用作逻辑回归模型和卷积神经网络（CNN）的输入。"
    },
    {
        "query":"CodeGuru Security 支持哪些集成？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 与 Lambda 的 Amazon Inspector 代码扫描集成。与存储库和 CI/CD 工具的其他集成即将推出。"
    },
    {
        "query":"什么是 Amazon CodeGuru Security？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 是一款基于机器学习和程序分析的代码扫描工具，可以发现 Java、Python 和 JavaScript 代码中的安全漏洞。"
    },
    {
        "query":"支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 目前支持扫描 Java、Python 和 JavaScript 代码。  \n   \n 问：CodeGuru Security 检测哪些类型的问题？\nCodeGuru Security 检测[开放全球应用程序安全项目（OWASP）十大](https://owasp.org/www-project-top-ten/)问题、[常见弱点枚举（CWE）前 25](https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html) 个问题、日志注入、机密以及 AWS API 和 SDK 的安全使用。 有关 CodeGuru Security 发现的漏洞的更多详细信息，请参阅 [Amazon CodeGuru 探测器库](https://docs.aws.amazon.com/codeguru/detector-library/)。"
    },
    {
        "query":"如何开始使用 CodeGuru Security？",
        "intention":"知识问答",
        "reply":"访问 CodeGuru 控制台，将 CodeGuru 安全性集成到您的开发人员生命周期中。您可以集成到持续集成和交付（CI/CD）工具、存储库扫描和集成式开发环境（IDE）中。"
    },
    {
        "query":"CodeGuru Security 会访问我的代码吗？",
        "intention":"知识问答",
        "reply":"为了生成建议，CodeGuru Security 需要获得代码的只读访问权限。您的信任、隐私与内容的安全性是我们最重视的问题。我们会采取适当的控制措施（包括传输中加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺来使用您的内容。我们还支持客户经理 KMS 密钥（CMCMK）进行加密。有关更多信息，请参阅[数据隐私常见问题](https://aws.amazon.com/compliance/data-privacy-faq/)。"
    },
    {
        "query":"CodeGuru Security 会保留我的代码副本吗？",
        "intention":"知识问答",
        "reply":"不，CodeGuru 安全不会存储您的源代码。"
    },
    {
        "query":"CodeGuru Security 如何接受训练以提供智能建议？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 使用规则挖掘和监督机器学习模型（结合使用逻辑回归和神经网络）进行训练。例如，在进行与敏感数据泄漏有关的训练时，它会全面分析代码以确定所有使用资源或敏感数据的代码路径，并创建代表这些路径的功能集，然后将其用作逻辑回归模型和卷积神经网络（CNN）的输入。"
    },
    {
        "query":"CodeGuru Security 支持哪些集成？",
        "intention":"知识问答",
        "reply":"CodeGuru Security 与 Lambda 的 Amazon Inspector 代码扫描集成。与存储库和 CI/CD 工具的其他集成即将推出。"
    },
    {
        "query":"什么是 Amazon CodeGuru Profiler？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 可帮助开发人员和 IT 操作员轻松了解应用程序的运行时系统行为，改善性能，并降低基础设施成本。Amazon CodeGuru Profiler 可分析应用程序的运行时系统概况，并提供智能建议和可视化图表，以指导开发人员改善代码中最相关部分的性能。"
    },
    {
        "query":"什么是分析组？",
        "intention":"知识问答",
        "reply":"分析组是您创建的逻辑分组。它代表一个应用程序的界限。例如，在微服务架构中，分析组将聚合您分配给它的微服务的概况，然后为所有这些服务产生一个概况。"
    },
    {
        "query":"我已在代码中加入了大量的日志记录功能。是否还需要执行分析？",
        "intention":"知识问答",
        "reply":"日志记录执行时间仅适用于有限的一组情景，因为日志记录只能监视延迟（而不是 CPU 利用率），由于开发人员必须记录应用程序中的每个函数（但不能影响应用程序性能），所以实现起来非常耗时，这就导致开发人员缺少用于监视生产中的应用程序和对其进行问题排查的有效工具。分析消除了此类不足，具体而言：CodeGuru Profiler 设计为不管在何种情况下都会收集与该应用程序的一切行为有关的数据。CodeGuru Profiler 使用包含常见性能低下问题的知识库自动分析运行中的应用程序，以发现影响其性能的代码模式。开发人员随后可以按照提供的建议来修复问题。"
    },
    {
        "query":"CodeGuru Profiler 与传统的 APM 和独立分析程序有何不同？",
        "intention":"知识问答",
        "reply":"传统的 APM 提供有关监控、跟踪和应用程序性能的有用数据。CodeGuru Profiler 将应用程序的运行时系统数据可视化，并提供与其发现的性能问题有关的可行建议，从而对这些 APM 功能进行了补充。它还使用机器学习来检测和提醒您应用程序配置文件中的异常，并指出异常的代码行。借助 CodeGuru Profiler，您无需具备深厚的性能工程背景，即可轻松看到最有可能优化性能、也最具成本节省潜力的代码部分，并获得有关如何改进这些部分的指导。Amazon CodeGuru Profiler 可分析 EC2 实例、容器和包括 AWS Lambda 以及本地实例在内的无服务器计算平台。此外，某些独立分析程序设计为仅在测试环境下运行，而 CodeGuru Profiler 设计为在生产环境中的生产流量负载下连续运行，而且不会影响应用程序。这在排查生产环境中的操作问题时（包括在祼主机上运行时）很有用。"
    },
    {
        "query":"我可以分析哪些类型的应用程序？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 适用于在 Amazon EC2 上托管的应用程序、在 Amazon ECS 和 Amazon EKS 上运行的容器化应用程序，以及在 AWS Fargate 和 AWS Lambda 上运行的无服务器应用程序。 此外，您还可在本地运行 CodeGuru Profiler。"
    },
    {
        "query":"CodeGuru Profiler 对在 AWS Lambda 上托管的应用程序的性能有何影响？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 代理使用分配给 AWS Lambda 函数的资源（CPU、内存）。当它作为进程内线程运行时，对应用程序性能的影响最小。如果您的应用程序占用了 AWS Lambda 函数的大部分资源，请考虑增加资源以使代理正常工作。"
    },
    {
        "query":"支持哪些编程语言？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 目前支持 Java、Python（预览版）和 JVM 语言，例如 Scala 和 Kotlin。"
    },
    {
        "query":"CodeGuru Profiler 如何工作？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 包含三部分：代理、分析程序服务和智能建议。该代理通过命令行启动您的应用程序，并以进程内线程的形式作为应用程序的一部分运行。它从运行代理的每个服务实例中获取数据，然后每五分钟向分析程序服务发送一次数据，之后，该服务将聚合这些数据。CodeGuru Profiler 随后会在交互式火焰图中发布概况数据，让您能直观查看应用程序的性能。CodeGuru Profiler 还会持续扫描已分析的数据，并将其与 Amazon 和性能工程最佳实践进行对比。如果发现性能问题，它会通过提供智能建议主动提醒您注意问题。它还使用机器学习来持续分析应用程序运行时系统数据，在检测到应用程序配置文件中的异常时发出警报，并指出异常的代码行。"
    },
    {
        "query":"哪些资源进行 CodeGuru Profiler 性能分析？支持哪些语言？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 对用于 Java 和其他 JVM 语言的 CPU（有源 CPU 和时钟时间）和内存（堆摘要）以及用于 Python 应用程序的 CPU（时钟时间）进行性能分析。"
    },
    {
        "query":"我是否可从同一个应用程序获得 CPU 和内存信息？",
        "intention":"知识问答",
        "reply":"可以，当您启用了内存性能分析并开始性能分析后，CodeGuru Profiler 就会收集您的应用程序的 CPU 和内存信息。您只需一个性能分析组就可以同时获得指定应用程序的 CPU 和内存数据。"
    },
    {
        "query":"CodeGuru Profiler 提供哪些内存性能分析信息？",
        "intention":"知识问答",
        "reply":"CodeGuru Profiler 可提供堆摘要信息。堆摘要提供在指定时间期限内（通常为 5 分钟），每个对象类型（例如，字符串、int、char[]）以及自定义类型的内存利用率的整合视图。CodeGuru Profiler 会追踪对象的总大小及其计数。这些指标显示在时间表图形中，您可以轻松地按对象类型描绘内存利用率趋势和峰值。"
    },
    {
        "query":"我可以对堆摘要信息进行什么操作？",
        "intention":"知识问答",
        "reply":"堆摘要在两种场景中很有用。首先，您可以发现潜在的内存泄漏问题。一个或多个对象类型的内存利用率曲线不断增长，可能指示存在泄漏，这有可能导致内存用尽错误和应用程序崩溃。第二个场景是在您想优化应用程序的内存占用空间时。在这种情况下，每个对象类型的内存利用率细分将可帮助您确定关注点。例如，了解到意外偏高的内存量与特定对象类型有关后，您可以将分析和优化工作的重点放在您的应用程序负责分配和引用该类对象的部分。"
    },
    {
        "query":"什么是 Amazon AppStream 2.0？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 针对应用程序流、SaaS 转换和虚拟桌面用例进行了优化。\n作为应用程序流式传输/SaaS 转换服务，AppStream 2.0 允许您将桌面应用程序移动到 AWS，而无需重写它们。您可以在 AppStream 2.0 上轻松安装应用程序、设置启动配置以及向用户提供您的应用程序。AppStream 2.0 提供广泛的配置选项选择，因此您可以选择最符合您的应用程序和最终用户要求的实例类型和自动扩缩参数。AppStream 2.0 允许您在自己的网络中启动应用程序，这意味着您的应用程序可以与您现有的 AWS 资源交互。\nAppStream 2.0 也可以配置为具有选择性持久性的虚拟桌面服务。选择性持久性意味着 IT 通过控制应用程序、应用程序设置、操作系统、升级和通过黄金映像部署的补丁来管理用户体验。用户每次登录时，都会收到一个基于黄金映像的全新桌面。通过选择性持久化，用户将文件保存在中央位置（主文件夹），而应用程序设置（浏览器收藏夹、网页会话、应用程序连接配置文件、插件、UI 自定义）和存储连接（Google Drive、OneDrive for Business、Amazon S3）在用户会话之间保持不变。用户会话之间的虚拟桌面上不会保留任何数据。 请在下面的常见问题中了解有关[持久存储](https://aws.amazon.com/cn/appstream2/faqs#Persistent_storage)和[持久设置](https://aws.amazon.com/cn/appstream2/faqs#Persistent_settings)的更多详细信息。"
    },
    {
        "query":"Amazon AppStream 2.0 与最初的 Amazon AppStream 有哪些不同？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 是 AWS 推出的新一代桌面应用程序流式传输服务。Amazon AppStream 是一项基于软件开发工具包的服务；借助这项服务，客户可以通过 DIY 工程设计来设置自己的流式传输服务。AppStream 2.0 提供完全托管的流式传输服务，无需任何 DIY 操作。AppStream 2.0 可以提供更多的实例类型；在不安装任何插件的情况下将桌面应用程序流式传输到兼容 HTML5 的 Web 浏览器；通过 [AppStream 2.0 Windows 客户端](https://clients.amazonappstream.com/)提供 Web 浏览器上的双显示器支持以及 4 显示器、4K 显示器和 USB 外设支持。此外，AppStream 2.0 简化应用程序生命周期管理并让您的应用程序访问 VPC 的服务。"
    },
    {
        "query":"是否能继续使用最初的 Amazon AppStream 服务？",
        "intention":"知识问答",
        "reply":"不能。您不能使用最初的 Amazon AppStream 服务。Amazon AppStream 2.0 可以提供更多的实例类型、在无需重写的情况下将桌面应用程序流式传输到浏览器、简化应用程序生命周期管理，并支持应用程序访问 VPC 中的服务。"
    },
    {
        "query":"与在本地处理内容相比，流式处理内容有哪些优势？",
        "intention":"知识问答",
        "reply":"从云中以交互方式对应用程序进行流式处理具有以下几个优势：\n*即时使用：*利用 Amazon AppStream 2.0 流式传输应用程序，用户可以立即开始使用这些应用程序，在使用映像生成器或始终可用队列时，无需下载大文件，也无需进行耗时的安装，因此不会出现延迟。\n*消除设备限制：*利用 AWS 的计算能力，您可以向用户提供在正常情况下因本地设备的 GPU、CPU、内存或物理存储限制而无法实现的体验。\n*多平台支持：*您可以将现有应用程序流式传输到计算机，而不需要做任何修改。\n*轻松更新：*因为您的应用程序由 Amazon AppStream 2.0 集中管理，所以其更新过程很简单，只需将新版应用程序提供给 Amazon AppStream 2.0 即可。您只需执行这些操作，便可以立即升级用户的应用程序，而不会对他们有丝毫干扰。\n*安全性有所提高*：AmazonAppStream 2.0 在 AWS 内的实例上运行您的应用程序，并且仅将加密的像素传输到最终用户设备。您可以应用 AWS 提供的各种安全控制机制来保护您的流实例。有关更多详情，请参阅 [Amazon AppStream 2.0 中的安全性](https://docs.aws.amazon.com/appstream2/latest/developerguide/security.html)。"
    },
    {
        "query":"某些应用程序在 Amazon AppStream 2.0 上的运行效果是否会优于其他应用程序？",
        "intention":"知识问答",
        "reply":"很多类型的应用程序都能与流式传输应用程序良好地协同工作，其中包括 CAD、CAM、CAE、3D 建模、模拟、游戏、视频和照片编辑软件、医学成像及生命科学应用程序。这些应用程序从流式传输中受益最大，因为它们运行在 AWS 的海量计算资源上，而用户可以使用功能弱小的设备与应用程序进行交互，且应用程序的性能几乎不会发生明显变化。"
    },
    {
        "query":"Amazon AppStream 2.0 是否支持麦克风？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 支持大部分模拟麦克风和 USB 麦克风，包括内置麦克风。"
    },
    {
        "query":"Amazon AppStream 2.0 是否支持 3D 鼠标等 USB 设备？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 通过 Windows 客户端支持 3D 鼠标等大多数 USB 设备。所有 USB 设备都被默认禁用。管理员可以为其用户启用 USB 设备。"
    },
    {
        "query":"用户如何在 Amazon AppStream 2.0 流会话中启用音频输入功能？",
        "intention":"知识问答",
        "reply":"用户可以通过在 Amazon AppStream 2.0 工具栏中依次选择设置图标和“启用麦克风”来启用音频输入功能。"
    },
    {
        "query":"什么是 AppStream 2.0 Windows 客户端？",
        "intention":"知识问答",
        "reply":"AppStream 2.0 Windows 客户端是一款本地应用程序，专门针对需要其他功能的用户设计，在 AppStream 2.0 流式会话其中无法通过 Web 浏览器提供。AppStream 2.0 客户端可让用户使用双显示器和 USB 外设（如 3D 鼠标）来处理其应用程序。该客户端还支持键盘快捷键（如 Alt + Tab）、剪贴板快捷键和功能键。AppStream 2.0 客户端在以下 Windows 版本上受支持：Windows 7、Windows 8、Windows 8.1 和 Windows 10。32 位和 64 位版 Windows 均受支持。"
    },
    {
        "query":"使用 AppStream 2.0 Window 客户端有哪些系统要求？",
        "intention":"知识问答",
        "reply":"最低系统要求为 2GB RAM 内存和 150MB 磁盘空间。"
    },
    {
        "query":"AppStream 2.0 Windows 客户端支持哪些显示器配置？",
        "intention":"知识问答",
        "reply":"对于基于浏览器的流式会话，AppStream 2.0 支持使用最多两个显示器且每个显示器的最大显示分辨率为 2560x1440 像素。AppStream 2.0 Windows 客户端支持使用最多 4 个显示器且每个显示器的最大显示分辨率为 2560x1440 像素。对于图形设计型和图形专业型实例系列支持的流式会话，AppStream 2.0 客户端还支持使用最多 2 个显示器且每个显示器的最大分辨率为 4096x2160 像素。"
    },
    {
        "query":"如何为我的用户部署 AppStream 2.0 Windows 客户端？",
        "intention":"知识问答",
        "reply":"用户可以[下载](https://clients.amazonappstream.com/)并安装 Windows 客户端。如要使用 USB 周边设备，用户需要拥有本地管理员权限以安装 AppStream 2.0 USB 驱动程序。您可以使用 Microsoft System Center Configuration Manager (SCCM) 等远程部署工具来远程安装 Windows 客户端。有关更多信息，请参阅我们的[文档](https://docs.aws.amazon.com/appstream2/latest/developerguide/client-application.html)。"
    },
    {
        "query":"用户能否为其应用程序配置位置和语言设置？",
        "intention":"知识问答",
        "reply":"是。用户可以设置要在流式传输会话中使用的时区、语言区域和输入法，以匹配其位置和语言首选项。"
    },
    {
        "query":"用户是否可以在本地设备和 Amazon AppStream 2.0 流式传输应用程序之间复制和粘贴文本？",
        "intention":"知识问答",
        "reply":"是。使用 Windows 客户端和 Google Chrome 访问其流式传输应用程序的用户可以在本地设备和流式传输应用程序之间复制和粘贴文本，就像他们使用键盘快捷键等方式在本地设备上的应用程序之间复制和粘贴文本一样。对于其他浏览器，用户可以使用 Amazon AppStream 2.0 Web 剪贴板工具。"
    },
    {
        "query":"我能否为我的用户提供桌面体验？",
        "intention":"知识问答",
        "reply":"可以。AppStream 2.0 允许您在配置队列时在应用程序或桌面流视图之间进行选择。应用程序视图仅显示用户打开的应用程序窗口，而桌面视图显示操作系统提供的标准桌面体验。"
    },
    {
        "query":"Amazon AppStream 2.0 应用程序能否脱机运行？",
        "intention":"知识问答",
        "reply":"不可以。Amazon AppStream 2.0 要求持续连接到 Internet 或网络路由到 AppStream 2.0 流式传输 VPC 终端节点以便访问您的应用程序。"
    },
    {
        "query":"Amazon AppStream 2.0 可以代我管理哪些资源？",
        "intention":"知识问答",
        "reply":"*流式传输资源：*AppStream 2.0 可以启动并管理 AWS 资源来托管您的应用程序、在这些资源上部署应用程序并扩展应用程序以满足最终用户需求。\n*简化应用程序管理：*Amazon AppStream 2.0 可以将最新版本的应用程序即时分发给用户，无需在每个最终用户设备上修补和更新应用程序，从而避免了相应麻烦。因为您的应用程序由 AppStream 2.0 集中管理，所以其更新过程很简单，只需将新版应用程序提供给 AppStream 2.0 即可。AppStream 2.0 可以将应用程序动态分配给用户，并且可以随时即刻将其卸载，从而提高业务灵活性并降低成本。"
    },
    {
        "query":"是否可以使用标签来对 AppStream 2.0 资源进行分类？",
        "intention":"知识问答",
        "reply":"可以。您可以指定标签来管理并跟踪以下 Amazon AppStream 2.0 资源：应用程序、应用程序块、映像生成器、映像、队列和堆栈。AWS 允许您以标签形式指定 AWS 资源的元数据。您可通过标签对 AppStream 2.0 资源进行分类，从而轻松识别其用途并据此跟踪成本。例如，您可以使用标签标识特定部门、项目、应用程序、供应商或使用案例使用的所有资源。然后您可以使用 AWS Cost Explorer 发现趋势，找出推高成本的因素，并检测账户中的异常。\n您可以使用 AppStream 2.0 管理控制台、命令行界面或 API 指定或删除标签。标签具有一个键和一个对应值，您最多可为每个 AppStream 2.0 资源分配 50 个标签。"
    },
    {
        "query":"我可以使用 AWS CloudFormation 创建哪些资源？",
        "intention":"知识问答",
        "reply":"借助 CloudFormation，您可以自动创建队列、部署堆栈、添加和管理用户池用户、启动映像生成器并创建目录配置以及其他 AWS 资源。"
    },
    {
        "query":"如何使用 AWS Direct Connect、AWS VPN 或其他 VPN 隧道来流式传输我的应用程序？",
        "intention":"知识问答",
        "reply":"首先，在与 AWS Direct Connect、AWS VPN 或其他 VPN 隧道相同的 Amazon VPC 中创建 [Amazon Virtual Private Cloud](https://aws.amazon.com/cn/vpc/) (Amazon VPC) 终端节点。然后，在创建新堆栈、修改现有堆栈或创建新映像生成器时指定 VPC 终端节点。然后，您的用户将在他们流式传输应用程序时使用 VPC 终端节点。要了解有关 AppStream 2.0 流式传输 VPC 终端节点的更多信息，请参阅 [AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的[从 VPC 接口终端节点创建和流式传输](https://docs.aws.amazon.com/console/appstream2/private-links)。"
    },
    {
        "query":"是否可以试用示例应用程序？",
        "intention":"知识问答",
        "reply":"是。请访问[试用示例应用程序](https://aws.amazon.com/cn/appstream2/try-sample-applications/)，以获得低冲突、免设置的 Amazon AppStream 2.0 服务试用体验。"
    },
    {
        "query":"要开始使用 Try It Now，需要具备哪些条件？",
        "intention":"知识问答",
        "reply":"要使用 Try It Now，您需要有一个 AWS 账户以及带宽至少为 1Mbps 的宽带 Internet 连接。此外，您还需要具备支持 HTML5 的浏览器。"
    },
    {
        "query":"使用 Try It Now 时，我可以使用哪些应用程序？",
        "intention":"知识问答",
        "reply":"Try It Now 提供在 Amazon AppStream 2.0 上运行的常用生产、设计、工程和软件开发应用程序，以供您试用。要查看可用的所有应用程序，请使用您的 AWS 账户登录，然后前往 Try It Now 目录页面。"
    },
    {
        "query":"使用 Try It Now 时，我有多长时间来流式传输应用程序？",
        "intention":"知识问答",
        "reply":"您最多有 30 分钟来流式传输 Try It Now 中提供的应用程序。30 分钟过后，流式传输会话会自动终止，且未保存的所有数据均将被删除。"
    },
    {
        "query":"在使用 Try It Now 的过程中，是否可以保存文件？",
        "intention":"知识问答",
        "reply":"您可以将文件保存到您的 Amazon AppStream 2.0 会话存储中，并在流式传输会话结束之前将文件下载到您的客户端设备。如果您断开 Try It Now 会话，或者会话结束，系统将不会保存您的文件，并且会删除未保存的所有数据。"
    },
    {
        "query":"是否可以提交一个应用程序并将其添加到 Try It Now？",
        "intention":"知识问答",
        "reply":"是。您可以提交一个请求，申请将您的应用程序添加到 Try It Now。AWS 收到请求后，通常会对请求进行审查并在 10 个工作日内给出答复。"
    },
    {
        "query":"如何开始使用 Amazon AppStream 2.0？",
        "intention":"知识问答",
        "reply":"访问 [AWS 管理控制台](https://console.aws.amazon.com/appstream2/)，或者使用 AWS 软件开发工具包，即可开始使用 Amazon AppStream 2.0。请访问[流式传输桌面应用程序](https://aws.amazon.com/cn/appstream2/stream-desktop-applications/)，以获取 10 步教程。"
    },
    {
        "query":"要使用 Amazon AppStream 2.0 流式传输我的应用程序，需要设置哪些资源？",
        "intention":"知识问答",
        "reply":"您需要在您的 AWS 账户内创建一个 Amazon AppStream 2.0 堆栈，才能开始将应用程序流式传输给用户。该堆栈包括一个 Amazon AppStream 2.0 实例队列，用于执行应用程序并将它们流式传输给最终用户。使用弹性队列时，每个实例都使用 AppStream 2.0 托管式映像启动，而始终可用和按需队列使用您创建的包含应用程序的映像。您可以根据用户需要的 CPU、内存和图形来选择队列的实例类型和大小。要了解有关 Amazon AppStream 2.0 资源的更多信息，请访问[此页面](https://aws.amazon.com/documentation/appstream2/)。"
    },
    {
        "query":"如何将我的应用程序导入 Amazon AppStream 2.0？",
        "intention":"知识问答",
        "reply":"如果您的应用程序需要 Active Directory、自定义驱动程序或需要重新启动才能安装，则您需要通过 AWS 管理控制台使用映像生成器创建 AppStream 2.0 映像，然后使用始终可用或按需队列将应用程序流式传输给您的用户。借助映像生成器，您可以像在任何 Microsoft Windows 或 Linux 桌面上一样安装和测试应用程序，然后创建一个映像。您可以在控制台内完成所有的映像安装、测试和创建步骤。\n如果您的应用程序不需要 Active Directory，并且可以从虚拟硬盘运行而无需配置，则可以将其打包到虚拟硬盘中，并将其上载到账户中的 S3 存储桶。上载应用程序后，您可以创建 AppStream 2.0 应用程序块和应用程序资源，并将它们分配给 AppStream 2.0 弹性队列以流式传输给您的用户。"
    },
    {
        "query":"如何创建 Amazon AppStream 2.0 映像来导入应用程序？",
        "intention":"知识问答",
        "reply":"您可以在 AWS 管理控制台中使用映像生成器创建 Amazon AppStream 2.0 映像。借助映像生成器，您可以像在 Windows 或 Linux 桌面上一样安装和测试应用程序，然后创建一个映像。您可以在控制台内完成所有的映像安装、测试和创建步骤。"
    },
    {
        "query":"哪些实例类型可以与我的 Amazon AppStream 2.0 队列配合使用？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 提供一个用于配置队列的实例类型菜单或映像生成器。您可以选择最符合应用程序和最终用户要求的实例类型。您可以从通用型、计算优化型、内存优化型、图形设计型、图形专业型和图形 G4 实例系列中进行选择。"
    },
    {
        "query":"是否可以在创建队列后更改实例类型？",
        "intention":"知识问答",
        "reply":"是。您可以在创建队列后更改实例类型。要更改实例类型，您需要停止队列并编辑实例类型，然后再次启动队列。有关更多信息，请参阅[设置 AppStream 2.0 堆栈和队列](https://docs.aws.amazon.com/appstream2/latest/developerguide/set-up-stacks-fleets.html#set-up-stacks-fleets-create)。"
    },
    {
        "query":"是否可以将 Amazon AppStream 2.0 实例连接到我的 VPC？",
        "intention":"知识问答",
        "reply":"是。您可以选择要将 Amazon AppStream 2.0 实例（队列和映像生成器）连接至哪些 VPC。创建队列或启动映像生成器时，您可以在 VPC 中指定一个或多个子网。如果您的 VPC 具有连接到本地网络的 VPN 连接，则队列中的 Amazon AppStream 2.0 实例可以与本地网络通信。您可以使用所有标准配置选项（如安全组、网络访问控制列表和路由表）对 VPC 中的网络访问进行常规控制。有关如何创建 [VPC 和使用子网的更多信息，请参阅“使用 VPC 和子网”](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_Subnets.html#working-with-vpcs)。"
    },
    {
        "query":"是否可以在 Amazon AppStream 2.0 中使用自定义品牌标识？",
        "intention":"知识问答",
        "reply":"是。您可以在应用程序目录页面中使用您的徽标、颜色、文字和帮助链接来自定义用户的 Amazon AppStream 2.0 体验。要替换 AppStream 2.0 的默认品牌标识和帮助链接，请登录到 AppStream 2.0 控制台，导航至“Stacks”（堆栈），然后选择您的某个应用程序堆栈。之后，单击“Branding”（品牌标识），选择“Custom”（自定义）并选择您的选项，然后单击“Save”（保存）。您的自定义品牌标识将应用于使用 SAML 2.0 单点登录 (SSO) 或 CreateStreamingURL API 启动的每个新应用程序目录。您可以随时恢复到默认的 AppStream 2.0 品牌标识和帮助链接。要了解详情，请访问[将您的自定义品牌添加至 Amazon AppStream 2.0](https://docs.aws.amazon.com/appstream2/latest/developerguide/branding.html)。"
    },
    {
        "query":"我能否为用户定义默认的应用程序设置？",
        "intention":"知识问答",
        "reply":"能，您可以为用户定义默认的应用程序设置，包括应用程序连接配置文件、浏览器设置和安装插件。"
    },
    {
        "query":"用户是否可以保存应用程序设置？",
        "intention":"知识问答",
        "reply":"是。 您可以在 AppStream 2.0 上为用户启用持久性应用程序和 Windows 设置。每当您的用户启动流会话时，系统都会保存并应用他们的插件、工具栏设置、浏览器收藏夹、应用程序连接配置文件和其他设置。用户的设置将存储在您可以通过 AWS 账户控制的 S3 存储桶中。\n要详细了解持久性应用程序设置，请参阅[为您的 AppStream 2.0 用户启用应用程序设置持久性](https://docs.aws.amazon.com/appstream2/latest/developerguide/app-settings-persistence.html)。"
    },
    {
        "query":"如何用我自己的应用程序创建映像？",
        "intention":"知识问答",
        "reply":"借助 Amazon AppStream 2.0 映像生成器，您可以使用自己的应用程序来创建映像。如需了解更多信息，请访问[此页面](https://docs.aws.amazon.com/appstream2/latest/developerguide/tutorial-image-builder.html)上的教程。"
    },
    {
        "query":"我的应用程序需要与哪个操作系统兼容？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 可流式传输可在以下 64 位版本的 Windows 操作系统上运行的应用程序：Windows Server 2012 R2、Windows Server 2016 和 Windows Server 2019。您可以使用 WoW64 扩展模块添加对 32 位 Windows 应用程序的支持。如果应用程序具有其他依赖关系（如 .NET Framework），请将这些依赖关系添加到应用程序的安装程序中。Amazon AppStream 2.0 还流式传输可在 Amazon Linux 2 操作系统上运行的应用程序。"
    },
    {
        "query":"是否可以在我的 Amazon AppStream 2.0 映像上安装防病毒软件以保护我的应用程序？",
        "intention":"知识问答",
        "reply":"您可以在 AppStream 2.0 映像上安装任何工具，包括防病毒程序。但是，您需要确保这些应用程序不会禁止访问 AppStream 2.0 服务。建议您在向用户发布应用程序之前进行测试。您可以通过阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html) 中的 [AppStream 2.0 上的 Windows 更新和杀毒软件](https://docs.aws.amazon.com/appstream2/latest/developerguide/administer-images.html#windows-update-antivirus-software)和 [AppStream 2.0 中的数据保护](https://docs.aws.amazon.com/appstream2/latest/developerguide/data-protection.html)了解更多信息。"
    },
    {
        "query":"是否可以使用群组策略来自定义 Windows 操作系统？",
        "intention":"知识问答",
        "reply":"使用映像生成器通过本地群组策略对映像所做的任何更改都将反映在您的 AppStream 2.0 映像中。通过基于域的组策略进行的任何自定义设置仅适用于已加入域的队列。"
    },
    {
        "query":"如何保持更新我的 Amazon AppStream 2.0 映像？",
        "intention":"知识问答",
        "reply":"AppStream 2.0 定期发布包括操作系统更新和 AppStream 2.0 代理更新在内的基本映像。AppStream 2.0 代理软件在您的流式处理实例上运行并使您的用户可以对应用程序进行流式处理。在您创建新映像时，\\*Always use latest agent version\\*（始终使用最新的代理版本）选项在默认情况下处于选中状态。选择此选项后，从您的映像启动的任何新映像生成器或队列实例都将始终使用最新的 AppStream 2.0 代理版本。如果取消选择此选项，您的映像将使用您在启动映像构建器时选择的代理版本。或者，您可以将托管的 Amazon AppStream 2.0 映像更新用于您的映像，以安装最新的操作系统更新、驱动更新和 AppStream 2.0 代理软件，并创建新映像。您将负责为操作系统、应用程序及其依赖项安装和维护更新。有关更多信息，请参阅[保持最新的 AppStream 2.0 映像](https://docs.aws.amazon.com/appstream2/latest/developerguide/administer-images.html#keep-image-updated)。"
    },
    {
        "query":"如何更新现有映像中的应用程序？",
        "intention":"知识问答",
        "reply":"要更新映像中的应用程序，或者要向映像中添加新应用程序，请使用现有映像启动映像生成器，更新应用程序，然后创建新的映像。现有的流式传输实例将在 16 小时（始终在线实例）和 7 天（按需队列的停止实例）内替换为从新映像启动的实例，或者在用户从现有的流式传输实例断开连接后立即完成此替换，以时间较早者为准。您可以通过停止队列、更改所使用的映像并重新启动，立即将队列中的所有实例替换为从新映像启动的实例。"
    },
    {
        "query":"是否可以将我的 Amazon AppStream 2.0 应用程序连接至现有的资源，例如许可服务器？",
        "intention":"知识问答",
        "reply":"是。借助 Amazon AppStream 2.0，您可以在 VPC 中启动流实例（队列和映像生成器），这意味着您可以控制从 AppStream 2.0 应用程序对现有资源的访问。有关更多信息，请参阅[队列和 Image Builder 实例的网络设置](https://docs.aws.amazon.com/appstream2/latest/developerguide/managing-network.html)。"
    },
    {
        "query":"是否可以复制 Amazon AppStream 2.0 映像？",
        "intention":"知识问答",
        "reply":"是。您可以跨 AWS 区域复制您的 Amazon AppStream 2.0 应用程序映像。要复制映像，需启动 AppStream 2.0 控制台并选择您现有映像所在的区域。在导航窗格中，选择“Images”（映像），选择您现有的映像，单击“Actions”（操作）并选择“Copy”（复制），然后选择您的目标 AWS 区域。您还可以使用 CopyImage API 以编程方式复制映像。有关更多信息，请参阅[标记并复制映像](https://docs.aws.amazon.com/appstream2/latest/developerguide/tutorial-image-builder.html#tutorial-image-builder-tag-copy)。"
    },
    {
        "query":"能否与其他 AWS 账户共享应用程序映像？",
        "intention":"知识问答",
        "reply":"是。您可以将您的 AppStream 2.0 应用程序映像与同一 AWS 区域内的其他 AWS 账户共享。您可以控制共享的映像，还可以随时从其他 AWS 账户中移除共享的映像。如需了解更多信息，请访问[管理您的 Amazon AppStream 2.0 映像](https://docs.aws.amazon.com/appstream2/latest/developerguide/administer-images.html)"
    },
    {
        "query":"当我与其他 AWS 账户共享应用程序映像时，我可以向它们授予哪些权限？",
        "intention":"知识问答",
        "reply":"您保有应用程序映像的完整权限。您可以与其他 AWS 账户共享映像，授予他们创建映像构建器和/或将其用于队列的权限。您可以稍后撤消这些权限。但是，如果您授予目标 AWS 账户创建映像构建器的权限，那么就无法撤消通过该映像创建的映像构建器或映像的访问权限。"
    },
    {
        "query":"如果我与其他 AWS 账户共享应用程序映像，能否删除该映像或者撤消权限？",
        "intention":"知识问答",
        "reply":"是。映像由您控制。要删除映像，您必须首先停止与所有 AWS 账户共享映像。您与之共享映像的 AWS 账户将无法再在映像存储库中看到该映像，并且无法为新的或现有的队列选择该映像。队列中的现有流实例将继续流式传输应用程序，但队列会终止现有的未使用实例。如果您最初授予了创建映像构建器的权限，则它们将无法再通过共享映像创建新的映像构建器，但现有构建器可以继续正常使用。通过源自共享映像的图像构建器所创建的目标账户中的映像则仍然有效。"
    },
    {
        "query":"Amazon AppStream 2.0 是否提供 GPU 加速实例？",
        "intention":"知识问答",
        "reply":"可以。Amazon AppStream 2.0 提供图形设计型、图形专业型和图形 G4 实例系列。\n图形设计实例非常适合交付依靠 DirectX、OpenGL 或 OpenCL 硬件加速的应用程序（例如，Adobe Premiere Pro、Autodesk Revit 和 Siemens NX）。由 AMD FirePro S7150x2 Server GPU 提供支持，并采用了 AMD Multiuser GPU 技术，实例可从初始的 2 个 vCPU、7.5GiB 系统内存和 1GiB 图形内存最高扩展到 16 个 vCPU、61GiB 系统内存和 8GiB 图形内存。\n图形 g4dn 实例基于 [EC2 G4 系列](https://aws.amazon.com/cn/ec2/instance-types/g4/)。Amazon EC2 g4dn 实例提供业界最具经济效益和用途最广泛的 GPU 实例，用于在 AWS 上运行图形密集型应用程序。G4dn 实例提供最新一代 NVIDIA T4 GPU、AWS 定制 Intel Cascade Lake CPU、最高 100Gbps 的网络吞吐量和最高 1.8 TB 的本地 NVMe 存储。这些实例十分适用于依赖 NVIDIA GPU 库（如使用 AppStream 2.0 的 CUDA）的流媒体图形密集型应用程序。AppStream 2.0 提供了六种不同 g4dn 实例大小，范围从 4 个 vCPU 和 16GiB 内存到 64 个 vCPU 和 256GiB 内存\n图形专业型实例系列提供三种不同实例类型，用于支持要求最严苛的图形应用程序。这三种图形专业型实例类型的规模从 16 个 vCPU、122 GiB 系统内存和 8 GiB 图形内存到 64 个 vCPU、488 GiB 系统内存和 32 GiB 图形内存，由配有 2048 个并行处理核心的 NVIDIA Tesla M60 GPU 提供支持。这些实例类型非常适合需要进行大量 3D 渲染、可视化和视频编码并行操作的图形工作负载，包括 Schlumberger Software 提供的 Petrel、Landmark DecisionSpace、MotionDSP Ikena 等应用程序。有关可用实例类型和定价的更多信息，请参阅 [Amazon AppStream 2.0 定价](https://aws.amazon.com/cn/appstream2/pricing/)。"
    },
    {
        "query":"什么是队列？",
        "intention":"知识问答",
        "reply":"队列是一种 AppStream 2.0 资源，表示用户用于启动其应用程序和桌面的流式传输实例的配置详细信息。队列包含配置详细信息，例如实例类型和大小、联网和用户会话超时。"
    },
    {
        "query":"Amazon AppStream 2.0 提供什么类型的队列？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 提供三种类型的队列：始终可用队列、按需队列和弹性队列。这些队列类型允许您选择应用程序和桌面的交付方式、会话开始的速度以及流式传输的费用。"
    },
    {
        "query":"队列类型之间有什么区别？",
        "intention":"知识问答",
        "reply":"始终可用和按需队列流式传输实例使用自定义的 AppStream 2.0 映像启动，该映像包含您的应用程序和配置。您可以指定手动启动或使用队列自动伸缩策略动态启动的实例数量。必须先预置流式传输实例，然后用户才能进行流式传输。\n弹性队列流式传输实例使用 AppStream 2.0 托管映像启动，并在运行时交付应用程序和配置。AppStream 2.0 为您管理弹性队列的容量。弹性队列仅支持来自应用程序块的应用程序，不能加入 Microsoft Active Directory 域。"
    },
    {
        "query":"我是否可以将 Amazon AppStream 2.0 始终可用队列切换为按需队列或反之？",
        "intention":"知识问答",
        "reply":"您仅能在创建新队列时指定队列类型，无法在队列创建后更改其类型。"
    },
    {
        "query":"Amazon AppStream 2.0 的始终可用和按需队列的优势是什么？",
        "intention":"知识问答",
        "reply":"当您的应用程序需要 Microsoft Active Directory 域支持，或者只能使用 AppStream 2.0 映像进行交付时，始终可用和按需队列最适合。始终可用队列流式传输实例提供对应用程序的即时访问，即使没有用户进行流式传输，您也需要支付运行实例费率。按需队列流式传输实例在长达 2 分钟的等待后启动应用程序，您仅在用户流式传输时支付运行实例费率。已预置但尚未使用的按需队列流式传输实例收取较低的停止实例费用。您可以使用自动伸缩规则管理始终可用和按需队列流式传输实例的容量。\n弹性队列流式传输实例在其已下载并挂载到流式传输实例后启动请求的应用程序，您只需支付用户的流式传输会话期间的运行实例费率。AWS 管理流式传输实例可用性，不需要自动伸缩规则。\n|  | 按需 | 始终可用 | 弹性 |\n| --- | --- | --- | --- |\n| 应用程序 | 自定义映像 | 自定义映像 | 应用程序块 |\n|  实例 | 已停止 | 正在运行 | 正在运行 |\n| 容量管理 | 客户使用自动伸缩管理 | 客户使用自动伸缩管理 | AWS 托管 |\n| 用户会话启动 | 最多 2 分钟 | 瞬间启动 | 最多 1 分钟 |\n| 使用案例 | 成本节约至关重要（如教育）的使用案例 | 需要应用程序即时可用性的业务 | 试用、培训和演示，以及将软件转换为软件即服务  |"
    },
    {
        "query":"弹性队列可以与哪些应用程序一起使用？",
        "intention":"知识问答",
        "reply":"弹性队列可以使用设计为独立、便携且可以在不同容量下运行的应用程序。这类似于将应用程序安装到 USB 硬盘驱动器，然后从您使用的任何 PC 上运行该应用程序。"
    },
    {
        "query":"如何导入弹性队列的应用程序？",
        "intention":"知识问答",
        "reply":"弹性队列使用保存在虚拟硬盘 (VHD) 文件中且保存到 AWS 账户内 S3 存储桶的应用程序。当您的用户选择要启动的应用程序时，VHD 将下载到流式传输实例并挂载。要了解有关导入弹性队列应用程序的更多信息，请参阅 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的[创建和管理弹性队列的应用程序块和应用程序](https://docs.aws.amazon.com/appstream2/latest/developerguide/apps-and-app-blocks.html)。"
    },
    {
        "query":"什么是 AppStream 2.0 应用程序块和 AppStream 2.0 应用程序？",
        "intention":"知识问答",
        "reply":"应用程序块是一种 AppStream 2.0 资源，其中包含应用程序文件的虚拟硬盘驱动器的详细信息，以及如何将其挂载到流式传输实例的安装脚本。应用程序是一种 AppStream 2.0 资源，其中包含有关如何从应用程序块启动应用程序的详细信息。您必须先将应用程序关联到应用程序块，然后才能将其关联到弹性队列。"
    },
    {
        "query":"如何将应用程序块挂载到弹性队列流式传输实例？",
        "intention":"知识问答",
        "reply":"创建应用程序块时，必须指定安装脚本。安装脚本指定如何将应用程序块挂载到流式传输实例，并允许您在应用程序启动之前完成所需的任何自定义或配置。要了解有关创建安装脚本的更多信息，请阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的[创建 VHD 的安装脚本](https://docs.aws.amazon.com/appstream2/latest/developerguide/app-blocks.html)"
    },
    {
        "query":"支持哪些客户端操作系统和浏览器？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 可以将应用程序流式传输到桌面设备（包括 Windows、Mac、Chromebooks 和 Linux PC）上兼容 HTML5 的浏览器，包括最新版本的 Google Chrome、Mozilla Firefox、Microsoft Internet Explorer 和 Microsoft Edge。AppStream 2.0 Windows 客户端可让用户使用 4 个显示器、4K 显示器和 USB 外设（如 3D 外设）来处理 AppStream 2.0 上的应用程序。AppStream 2.0 Windows 客户端在以下 Windows 版本上受支持：Windows 7、Windows 8、Windows 8.1 和 Windows 10。32 位和 64 位版 Windows 均受支持。"
    },
    {
        "query":"支持哪些服务器操作系统？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 可流式传输可在以下 64 位版本的操作系统上运行的应用程序：Windows Server 2012 R2、Windows Server 2016 和 Windows Server 2019。您可以使用 WoW64 扩展模块添加对 32 位应用程序的支持。如果应用程序具有其他依赖关系（如 .NET Framework），请将这些依赖关系添加到应用程序的安装程序中。\n问题：支持哪个 Linux 发行版？\nAmazon AppStream 2.0 支持 Amazon Linux 2 操作系统。"
    },
    {
        "query":"哪些 AWS 区域提供 Amazon AppStream 2.0 服务？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 区域性产品和服务](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)页面，详细了解目前哪些区域提供 Amazon AppStream 2.0 服务。"
    },
    {
        "query":"哪些实例类型可以与我的 Amazon AppStream 2.0 队列配合使用？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 提供一个用于配置队列的实例类型菜单。您可以选择最符合应用程序和最终用户要求的实例类型。您可以从通用型、计算优化型、内存优化型、图形设计型、图形桌面型或图形专业型实例系列中进行选择。"
    },
    {
        "query":"Amazon AppStream 2.0 如何扩展？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 始终可用和按需队列使用队列自动伸缩来启动运行您的应用程序的 Amazon AppStream 2.0 实例，并根据最终用户会话的需求调整流式传输实例的数量。每个最终用户会话都在单独的实例上运行，通过一个会话流式传输的所有应用程序都在同一个实例上运行。一个实例仅用于流式传输一名用户的应用程序，并在会话结束后替换为新的实例。有关更多信息，请阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。\n弹性队列的容量完全由您管理，不需要任何自动伸缩策略。"
    },
    {
        "query":"Amazon AppStream 2.0 支持哪些扩缩策略？",
        "intention":"知识问答",
        "reply":"您可以设置固定的队列大小以保持 AppStream 2.0 流式传输实例数量不变，或使用动态扩缩策略根据计划、使用情况或两者调整容量。使用动态扩缩策略，您可以管理成本，同时确保用户有足够的容量进行流式传输。有关更多信息，请阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。"
    },
    {
        "query":"什么是 Amazon AppStream 2.0 队列自动伸缩策略？",
        "intention":"知识问答",
        "reply":"队列 Auto Scaling 策略是一种动态扩展策略，让您可以扩展队列的大小，以便让能提供的可用实例数量与用户需求匹配。您可以定义扩缩策略，使其根据各种使用率指标自动调整您的队列的大小，并根据用户需求优化正在运行的实例的数量。 有关更多信息，请阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/what-is-appstream.html)中的 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。"
    },
    {
        "query":"如何为 Amazon AppStream 2.0 队列创建自动伸缩策略？",
        "intention":"知识问答",
        "reply":"您可以通过 [AppStream 2.0 控制台](https://console.aws.amazon.com/appstream2)中的“队列”选项卡创建自动伸缩策略，也可以使用 AWS 开发工具包来创建策略。"
    },
    {
        "query":"可以使用哪些 Amazon AppStream 2.0 CloudWatch 指标来构建队列 Auto Scaling 策略？",
        "intention":"知识问答",
        "reply":"您可以使用以下指标来构建自己的队列 Auto Scaling 策略：\n• 容量使用率：您可以根据队列中正在使用的实例的百分比来扩展队列  \n • 可用容量：您可以根据队列中可用实例的数量来扩展队列  \n • 容量不足错误：您可以在用户因容量不足而无法启动流式传输会话时预置新的实例\n有关更多信息，请参阅 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 队列是否可以关联多项队列 Auto Scaling 策略？",
        "intention":"知识问答",
        "reply":"是。一个队列最多可以关联 50 项队列 Auto Scaling 策略。每项策略都支持设置一个调整队列大小的条件和操作。"
    },
    {
        "query":"使用队列 Auto Scaling 策略最小可以将我的 Amazon AppStream 2.0 队列设置为多大？",
        "intention":"知识问答",
        "reply":"您可以使用队列 Auto Scaling 策略将队列缩减为零个实例。与队列关联的扩展策略可以将队列容量缩减到您设置的最小值，如果没有设置，则默认最小值为一。有关更多信息，请参阅 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。"
    },
    {
        "query":"使用队列 Auto Scaling 策略最大可以将我的 Amazon AppStream 2.0 队列设置为多大？",
        "intention":"知识问答",
        "reply":"队列 Auto Scaling 策略可以将队列容量扩大到您设置的或服务限制允许的最大大小。有关更多信息，请参阅 [Amazon AppStream 2.0 的队列自动伸缩](https://docs.aws.amazon.com/appstream2/latest/developerguide/autoscaling.html)。有关服务限制的信息，请参阅 [Amazon AppStream 2.0 Service Limits](https://docs.aws.amazon.com/appstream2/latest/developerguide/limits.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 是否提供持久性存储，以便在会话之间保存和访问文件？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 可提供多个持久性文件存储选项，让用户可以在自己的应用程序流式传输会话之间存储和检索文件。您可以使用由 Amazon S3、适用于 G Suite 的 Google Drive 或 Microsoft OneDrive for Business 支持的主文件夹。其中的每个主文件夹都可以从处于活动状态的 AppStream 2.0 流式传输会话中的“My Files”选项卡中访问，而内容可以从大多数应用程序的“File”菜单中直接保存或打开。\n主文件夹是 AppStream 2.0 的本地持久性存储选项。用户可以访问其流式传输实例上的主文件夹，并将内容保存在该文件夹中。文件存储在一个在您的 AWS 账户中自动创建的 S3 存储桶内。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理主文件夹](https://docs.aws.amazon.com/appstream2/latest/developerguide/home-folders.html)。\n对于基于 Windows 操作系统的 AppStream 2.0 堆栈，您可以启用适用于 G Suite 的 Google Drive，并且用户可以链接他们的 G Suite 账户以访问位于 Google Drive 上的文件。更改会自动同步到 Google Drive。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 Google Drive](https://docs.aws.amazon.com/appstream2/latest/developerguide/google-drive.html)。\n对于基于 Windows 操作系统的 AppStream 2.0 堆栈，您可以启用 Microsoft OneDrive for Business，并且用户可以链接他们的 OneDrive for Business 账户以访问位于 OneDrive 上的文件。更改会自动同步到 OneDrive for Business。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 OneDrive](https://docs.aws.amazon.com/appstream2/latest/developerguide/onedrive.html)。"
    },
    {
        "query":"用户如何从自己的 Amazon AppStream 2.0 会话访问持久性存储？",
        "intention":"知识问答",
        "reply":"用户可以在应用程序流式传输会话过程中访问主文件夹。其保存到主文件夹的所有文件都可以在未来使用。他们还可以连接 G Suite 账户以访问 Google Drive，或者连接 Microsoft OneDrive for Business 账户以在 AppStream 2.0 内访问 OneDrive。在流式传输会话中添加的新文件或对现有文件进行的更改会自动在 AppStream 2.0 和持久性存储选项之间同步。"
    },
    {
        "query":"是否可以为 Amazon AppStream 2.0 堆栈启用多个持久性存储选项？",
        "intention":"知识问答",
        "reply":"是。您可以启用主文件夹、适用于 G Suite 的 Google Drive 和 Microsoft OneDrive for Business。要优化互联网带宽，您可以为 Amazon S3 创建 VPC 终端节点，然后授权 AppStream 2.0 访问此终端节点。这样将通过 VPC 来路由主文件夹数据，并通过公共互联网来路由 Google Drive 或 OneDrive 数据。"
    },
    {
        "query":"如何为 Amazon AppStream 2.0 启用适用于 G Suite 的 Google Drive？",
        "intention":"知识问答",
        "reply":"创建 Amazon AppStream 2.0 堆栈时，选择为堆栈启用 Google Drive 选项，这将为您提供 G Suite 域名并创建堆栈。 要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 Google Drive](https://docs.aws.amazon.com/appstream2/latest/developerguide/google-drive.html)。"
    },
    {
        "query":"用户是否可以删除其适用于 G Suite 的 Google Drive 账户？",
        "intention":"知识问答",
        "reply":"是。用户可以从 Google 账户权限[页面](https://myaccount.google.com/permissions)中删除 AppStream 2.0 授予其 Google 账户的权限。"
    },
    {
        "query":"是否可以控制与 AppStream 2.0 集成的适用于 G Suite 的 Google Drive 账户？",
        "intention":"知识问答",
        "reply":"是。只有带有您的 G Suite 组织域名的用户账户才能使用他们的 Google Drive 账户。用户不能关联任何其他账户。要了解更多信息，请访问[为您的用户启用和管理 Google Drive](https://docs.aws.amazon.com/appstream2/latest/developerguide/google-drive.html)。"
    },
    {
        "query":"流式传输会话期间，用户可以在 Google Drive 中存储哪些类型的数据？",
        "intention":"知识问答",
        "reply":"流式传输会话期间，用户可以在 Google Drive 中存储其支持的任何类型的文件。有关 Google Drive 支持的文件类型的更多详细信息，请参阅 [Google Drive 常见问题](https://support.google.com/a/answer/2490100#Sync)。"
    },
    {
        "query":"流式传输会话期间，用户是否可以将文件从自己的设备传输到 Google Drive？",
        "intention":"知识问答",
        "reply":"是。用户可以使用流式传输会话工具栏中的 MyFiles 功能，在自己的设备和 Google Drive 之间来回传输文件。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用持久性存储](https://docs.aws.amazon.com/appstream2/latest/developerguide/home-folders.html)。"
    },
    {
        "query":"如何为 Amazon AppStream 2.0 启用 Microsoft OneDrive for Business？",
        "intention":"知识问答",
        "reply":"创建 Amazon AppStream 2.0 堆栈时，选择为堆栈启用 OneDrive for Business 选项，这将为您提供 OneDrive for Business 域名并创建堆栈。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 OneDrive](https://docs.aws.amazon.com/appstream2/latest/developerguide/onedrive.html)。"
    },
    {
        "query":"是否可以控制与 AppStream 2.0 集成的 Microsoft OneDrive for Business 账户？",
        "intention":"知识问答",
        "reply":"是。只有拥有 OneDrive for Business 域名的用户账户才能使用其账户。用户不能关联任何其他账户。要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 OneDrive](https://docs.aws.amazon.com/appstream2/latest/developerguide/onedrive.html)。"
    },
    {
        "query":"用户是否可以删除 Microsoft OneDrive for Business？",
        "intention":"知识问答",
        "reply":"是。用户可以删除 AppStream 2.0 授予其 OneDrive for Business 在线账户的权限。"
    },
    {
        "query":"在流式传输会话期间，用户可以在 Microsoft OneDrive for Business 中存储哪些类型的数据？",
        "intention":"知识问答",
        "reply":"在流式传输会话期间，用户可以存储 OneDrive for Business 支持的任何类型的文件。有关 OneDrive for Business 支持的文件类型的更多详细信息，请参阅 [OneDrive for Business 文档](https://support.office.com/en-us/article/what-is-onedrive-for-business-187f90af-056f-47c0-9656-cc0ddca7fdc2)。"
    },
    {
        "query":"在流式传输会话期间，用户是否可以将文件从自己的设备传输到 Microsoft OneDrive for Business？",
        "intention":"知识问答",
        "reply":"是。用户可以使用流式传输会话工具栏中的 MyFiles 功能，在自己的设备和 OneDrive for Business 之间来回传输文件。 要了解更多信息，请访问[为您的 AppStream 2.0 用户启用和管理 OneDrive](https://docs.aws.amazon.com/appstream2/latest/developerguide/onedrive.html)。"
    },
    {
        "query":"哪些设置在会话之间保持不变？",
        "intention":"知识问答",
        "reply":"您可以在 AppStream 2.0 上为用户启用持久性应用程序和 Windows 设置。每当您的用户启动流会话时，系统都会保存并应用他们的插件、工具栏设置、浏览器收藏夹、应用程序连接配置文件和其他设置。用户的设置将存储在您可以通过 AWS 账户控制的 S3 存储桶中。"
    },
    {
        "query":"我该如何监控我的 Amazon AppStream 2.0 队列资源的利用率？",
        "intention":"知识问答",
        "reply":"有两种方式可监控您的 Amazon AppStream 2.0 队列。第一种，AppStream 2.0 控制台提供一种轻量型的实时视图，用于显示 AppStream 2.0 队列的状态，并提供多达两周的历史使用数据。系统会自动显示指标，且不需要任何设置。\n第二种，您可以使用 CloudWatch 访问 AppStream 2.0 指标。借助 CloudWatch 控制台，您可以指定报告间隔，创建自定义控制面板和图表，以及设置警报。\n要了解更多信息，请参阅[监控 Amazon AppStream 2.0 资源](https://docs.aws.amazon.com/appstream2/latest/developerguide/monitoring.html)。"
    },
    {
        "query":"我可以从 Amazon AppStream 2.0 使用率指标中获取哪些信息？",
        "intention":"知识问答",
        "reply":"您可查看您的 Amazon AppStream 2.0 队列的大小、运行实例的数量、可用于接受新连接的实例数量，以及队列的利用率。您可以随时间推移跟踪这些指标，以便您优化队列设置，从而满足相关需求。\n您还可使用 Amazon CloudWatch 设置警报，通知您对队列所做的更改，或者在没有足够的容量支持用户时通知您。\n有关可用指标的完整列表，请参阅[监控 Amazon AppStream 2.0 资源](https://docs.aws.amazon.com/appstream2/latest/developerguide/monitoring.html)。"
    },
    {
        "query":"我可以创建适用于 Amazon AppStream 2.0 的自定义 Amazon CloudWatch 指标吗？",
        "intention":"知识问答",
        "reply":"可以，您可以创建适用于 Amazon AppStream 2.0 的自定义指标。有关更多信息，请参阅[发布自定义指标](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/publishingMetrics.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 指标发布到 Amazon CloudWatch 的频率如何？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 会每分钟向 Amazon CloudWatch 发送一次指标。在 CloudWatch 中存储指标时采用的是标准保留策略。有关更多信息，请参阅 [Amazon CloudWatch 常见问题](https://aws.amazon.com/cn/cloudwatch/faqs/#monitoring)。"
    },
    {
        "query":"如何创建适用于 Amazon AppStream 2.0 的 CloudWatch 警报？",
        "intention":"知识问答",
        "reply":"您可以使用 CloudWatch 控制台或 CloudWatch API 创建适用于 Amazon AppStream 2.0 的 Amazon CloudWatch 警报。"
    },
    {
        "query":"Amazon AppStream 2.0 是否提供一组公共 API？",
        "intention":"知识问答",
        "reply":"是，Amazon AppStream 2.0 包含一组 API，您可以使用这些 API 轻松集成和扩展该服务。借助这些 API，您可以创建、更新和删除 Amazon AppStream 2.0 资源，并提供关于资源状态的详细信息。您可以为管理员创建 URL 来连接到其映像生成器以安装应用程序；以及为用户创建 URL 来访问其 AppStream 2.0 应用程序。有关更多信息，请参阅 [API 参考](https://docs.aws.amazon.com/appstream2/latest/APIReference/Welcome.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 使用哪些流式传输协议？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 使用 NICE DCV 将应用程序流式传输给用户。NICE DCV 是一项专有协议，用于在不同网络状况下流式传输高质量的应用程序视频。该协议通过 HTTPS 来流式传输使用 H.264 标准编码的视频和音频。该协议还能捕获用户的输入，并通过 HTTPS 将其发送回正从云中流式传输的应用程序。在此过程中，系统会持续监测网络状况，并将信息发送回服务器上的编码器。服务器会做出动态响应，实时更改视频和音频编码，从而在不同网络状况下针对一系列应用程序生成优质流。"
    },
    {
        "query":"访问 Amazon AppStream 2.0 时，建议的最大网络延迟是多少？",
        "intention":"知识问答",
        "reply":"远程协议的最大往返延迟推荐值为 250ms，但最佳用户体验是在延迟低于 100ms 时实现的。如果您距当前提供 Amazon AppStream 2.0 服务的 AWS 区域超过 2000 英里，您仍可使用该服务，但其响应能力可能会降低。"
    },
    {
        "query":"如何限制在我的 VPC 内启动的队列和映像生成器对网络的访问？",
        "intention":"知识问答",
        "reply":"安全组让您能够指定允许在您 VPC 内的流实例和资源之间传输的网络流量。您可以通过将映像生成器或队列分配到您 VPC 内的安全组来限制网络访问。有关更多信息，请参阅[您的 VPC 的安全组](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html)。"
    },
    {
        "query":"是否可以使用现有 VPC 安全组来确保 AppStream 2.0 队列和映像生成器的安全？",
        "intention":"知识问答",
        "reply":"是。您可以将映像生成器或队列分配到您 VPC 内的现有安全组。"
    },
    {
        "query":"可向一个队列或映像生成器应用多少个安全组？",
        "intention":"知识问答",
        "reply":"您最多可将一个映像生成器或队列分配到五个安全组。"
    },
    {
        "query":"是否可以在队列创建之后更改其分配到的安全组？",
        "intention":"知识问答",
        "reply":"是。只要您的队列处于已停止状态，您就可以更改它们分配到的安全组。\n此外，您还可以使用 Amazon EC2 控制台随时更改您 VPC 中的安全组的规则。请注意，新规则将应用于分配给该安全组的所有资源。有关更多信息，请参阅[您的 VPC 的安全组](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html)。"
    },
    {
        "query":"是否可以在映像生成器创建之后更改其分配到的安全组？",
        "intention":"知识问答",
        "reply":"不可以。在映像生成器创建之后，您无法更改它们分配到的安全组。要将映像生成器分配到其他安全组，您需要创建新的映像生成器。\n此外，您还可以使用 Amazon EC2 控制台随时更改您 VPC 中的安全组的规则。请注意，新规则将应用于分配给该安全组的所有资源。有关更多信息，请参阅[您的 VPC 的安全组](https://docs.aws.amazon.com/AmazonVPC/latest/UserGuide/VPC_SecurityGroups.html)。"
    },
    {
        "query":"如何保护用户主文件夹中存储的数据？",
        "intention":"知识问答",
        "reply":"请使用 Amazon S3 的 SSL 终端节点对用户主文件夹中动态的文件和文件夹进行加密，并使用 Amazon S3 托管的加密密钥对静态的文件和文件夹进行加密。"
    },
    {
        "query":"对于流式传输的应用程序，其数据是如何加密并传输到客户端的？",
        "intention":"知识问答",
        "reply":"流式传输的视频和用户输入采用 SSL 加密，并通过 HTTPS 在执行应用程序的 Amazon AppStream 2.0 实例与最终用户之间传输。"
    },
    {
        "query":"是否可以控制 AppStream 2.0 与用户设备之间的数据传输？",
        "intention":"知识问答",
        "reply":"是。您可以选择是否允许用户在其流式传输应用程序和本地设备之间通过复制或粘贴、文件上传/下载或打印操作传输数据。要了解更多信息，请访问[创建队列和堆栈](https://docs.aws.amazon.com/appstream2/latest/developerguide/set-up-stacks-fleets.html)。"
    },
    {
        "query":"如何使用 Amazon AppStream 2.0 应用程序验证用户身份？",
        "intention":"知识问答",
        "reply":"您可以通过三种方式使用 Amazon AppStream 2.0 验证用户身份：使用内置用户管理、构建自定义身份或使用 SAML 2.0 设置联合访问权限。\n使用内置用户管理时，您可以从 AppStream 2.0 管理控制台中的“用户池”选项卡设置和管理用户。要添加新用户，您只需输入他们的姓名以及电子邮件地址即可。要了解有关在 AppStream 2.0 内管理用户的更多信息，请参阅[使用 AppStream 2.0 用户池](https://docs.aws.amazon.com/appstream2/latest/developerguide/user-pool.html)。\n在使用联合登录验证用户身份时，您可以使用 SAML 2.0 设置联合身份，以便能使用现有用户目录控制对可通过 AppStream 2.0 使用的应用程序的访问权限。有关设置 SAML 集成的详细信息，请参阅[此处](https://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers-setting-up-saml.html)概述的步骤。\n在构建权限服务时，您应使用自定义身份或 Login with Amazon 等服务来验证用户的身份。在自定义身份验证完某个用户的身份后，它会调用 Amazon AppStream 2.0 来创建一个新的流 URL。AppStream 2.0 将返回可在浏览器中打开的会话 URL 以开始流式传输会话。"
    },
    {
        "query":"是否可以将 Amazon AppStream 2.0 和包括 Microsoft Active Directory 在内的现有用户目录一起使用？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 支持使用 SAML 2.0 的联合身份，以便您可以使用现有用户目录管理最终用户对 AppStream 2.0 应用程序的访问。有关设置 SAML 集成的详细信息，请阅读 [Amazon AppStream 2.0 管理指南](https://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers.html)中的[单点登录访问 (SAML 2.0)](https://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 支持哪种联合身份类型？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 支持使用 SAML 2.0（由身份提供商启动）的联合身份。使用此类联合访问时，用户需先通过联合身份提供商的身份验证，然后才能访问其 AppStream 2.0 应用。"
    },
    {
        "query":"使用 Amazon AppStream 2.0 设置联合身份需要满足哪些要求？",
        "intention":"知识问答",
        "reply":"要使用 Amazon AppStream 2.0 配置联合身份，您需要一个与兼容 LDAP 的现有目录（如 Microsoft Active Directory）相关联的 SAML 2.0 身份提供商。Microsoft Active Directory 联合身份验证服务 (ADFS)、Ping Identity、Okta 和 Shibboleth 都是 SAML 2.0 身份提供商的示例，均支持使用 AppStream 2.0。"
    },
    {
        "query":"是否可以控制哪些用户有权访问我的 Amazon AppStream 2.0？",
        "intention":"知识问答",
        "reply":"是。使用内置用户管理时，您可以在 AppStream 2.0 管理控制台的“用户池”选项卡中控制哪些用户有权访问您的 Amazon AppStream 2.0 堆栈。要了解有关在 AppStream 2.0 内管理用户的更多信息，请参阅[使用 AppStream 2.0 用户池](https://docs.aws.amazon.com/appstream2/latest/developerguide/user-pool.html)。\n在使用 SAML 2.0 时，您可以控制哪些用户有权访问您的 Amazon AppStream 2.0 堆栈，具体方法是将联合服务中的用户映射到有权访问堆栈的 IAM 角色。请参阅 [AppStream 2.0 文档](https://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers-further-info.html)，了解热门联合服务的详细信息和分步指南。"
    },
    {
        "query":"是否可以针对用户启用多重验证？",
        "intention":"知识问答",
        "reply":"是。在使用 SAML 2.0 的联合服务或您自己的权限服务时，您可以启用多重验证。"
    },
    {
        "query":"我能否动态授权用户使用应用程序？",
        "intention":"知识问答",
        "reply":"可以，如果您的用户从 SAML 2.0 身份提供商联合到 AppStream 2.0，您可以根据 SAML 2.0 属性断言控制至 AppStream 2.0 堆栈内的特定应用程序的访问权限。此外，您可以使用动态应用程序框架 API 构建动态应用程序提供程序，以指定在运行时用户可启动的应用程序。提供的应用程序可以是从 Windows 文件共享或其他存储技术提供的虚拟化应用程序。要详细了解这些选项，请参阅[管理应用程序授权](https://docs.aws.amazon.com/appstream2/latest/developerguide/manage-application-entitlements.html)。"
    },
    {
        "query":"用户在登录过程中能否选择要访问的 Amazon AppStream 2.0 堆栈？",
        "intention":"知识问答",
        "reply":"是。您可以将每个 AppStream 2.0 堆栈设置为联合服务中的实体或包。这样用户从您的应用程序门户登录时就可以选择要访问的堆栈。此外，您的 SAML 2.0 联合用户身份可以根据 SAML 2.0 属性断言从单个 SAML 2.0 服务提供商应用程序访问其有权访问的 AppStream 2.0 堆栈。"
    },
    {
        "query":"哪些人可以访问我的 Amazon AppStream 2.0 应用程序的管理控制台？",
        "intention":"知识问答",
        "reply":"您可以使用 AWS Identity and Access Management (IAM) 向 AWS 账户中添加用户，并授权他们查看和管理您的 Amazon AppStream 2.0 应用程序。有关更多信息，请参阅 [IAM 用户指南](https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html)中的“什么是 IAM？”。"
    },
    {
        "query":"能否将 Amazon AppStream 2.0 映像生成器加入 Microsoft Active Directory 域？",
        "intention":"知识问答",
        "reply":"可以，基于 Windows 操作系统的 Amazon AppStream 2.0 流式传输实例可以加入到 Microsoft Active Directory 域中。借此，您能够将现有的 Active Directory 策略应用于流式传输实例，并为用户提供从其应用程序内部通过单点登录访问内部网站点、文件共享和网络打印机的功能。您的用户使用您选择的 SAML 2.0 提供商进行身份验证，并可以访问需要连接到 Active Directory 域的应用程序。您可以将使用 Windows 操作系统的映像生成器、始终可用队列流式传输实例和按需队列流式传输实例加入 Active Directory 域。基于 Linux 操作系统的 AppStream 2.0 映像生成器、始终可用队列流式传输实例和按需队列流式传输实例无法加入 Active Directory 域。"
    },
    {
        "query":"支持哪些 Microsoft Active Directory 版本？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 支持 Microsoft Active Directory Domain Functional Level Windows Server 2008 R2 和更新版本。"
    },
    {
        "query":"Amazon AppStream 2.0 支持哪些 AWS Directory Service 目录选项？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 支持 AWS Directory Services Microsoft AD。不支持 AD Connector 和 Simple AD 等其他选项。要了解有关 Amazon Microsoft AD 的更多信息，请参阅[什么是 Amazon Directory Service](https://docs.aws.amazon.com/directoryservice/latest/admin-guide/what_is.html)。"
    },
    {
        "query":"如何将 Amazon AppStream 2.0 实例加入 Microsoft Active Directory 域？",
        "intention":"知识问答",
        "reply":"首先，您需要一个可从 Amazon VPC 进行访问的 Microsoft Active Directory 域，用户有权加入域的凭证以及您想加入到队列的域组织部门 (OU)。有关更多信息，请参阅[将 Active Directory 域与 AppStream 2.0 结合使用](https://docs.aws.amazon.com/appstream2/latest/developerguide/active-directory.html)。"
    },
    {
        "query":"是否可以将现有组织部门 (OU) 结构与 Amazon AppStream 2.0 结合使用？",
        "intention":"知识问答",
        "reply":"可以，您可以将现有组织部门 (OU) 结构与 Amazon AppStream 2.0 结合使用。要了解更多信息，请参阅[将 Active Directory 域与 AppStream 2.0 结合使用](https://docs.aws.amazon.com/appstream2/latest/developerguide/active-directory.html)。"
    },
    {
        "query":"Amazon AppStream 2.0 会向 Microsoft Active Directory 域中加入哪些内容？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 会为您配置的每个映像生成器和始终可用或按需队列实例自动创建一个唯一的计算机对象，将其加入您的 Microsoft Active Directory 域。"
    },
    {
        "query":"如何在 Microsoft Active Directory 域中识别 Amazon AppStream 2.0 计算机对象？",
        "intention":"知识问答",
        "reply":"Amazon AppStream 2.0 计算机对象仅在您指定的 Microsoft Active Directory 组织部门 (OU) 中创建。说明字段可表明该对象是 AppStream 2.0 实例以及该对象所属的队列。要了解更多信息，请参阅[将 Active Directory 域与 AppStream 2.0 结合使用](https://docs.aws.amazon.com/appstream2/latest/developerguide/active-directory.html)。"
    },
    {
        "query":"如何从 Microsoft Active Directory 域中删除 Amazon AppStream 2.0 创建的计算机对象？",
        "intention":"知识问答",
        "reply":"即使删除 AppStream 2.0 队列或映像生成器，将队列或映像生成器更新到一个新的 OU 或选择其他 AD，由 Amazon AppStream 2.0 创建的不再使用的计算机对象仍然将留在您的 Active Directory (AD) 中。要删除未使用的对象，您必须手动将其从 AD 域中删除。要了解更多信息，请参阅[将 Active Directory 域与 AppStream 2.0 结合使用](https://docs.aws.amazon.com/appstream2/latest/developerguide/active-directory.html)。"
    },
    {
        "query":"如何才能使用户访问加入到 Microsoft Active Directory 域的 Amazon AppStream 2.0 流实例？",
        "intention":"知识问答",
        "reply":"要实现用户访问，您需要使用您选择的 SAML 2.0 提供商来设置联合访问。借此，您能够使用现有的用户目录来控制对通过 Amazon AppStream 2.0 提供的流式处理应用程序的访问。有关设置 SAML 2.0 集成的详细信息，请参阅[设置 SAML](https://docs.aws.amazon.com/appstream2/latest/developerguide/external-identity-providers-setting-up-saml.html) 中列出的步骤。"
    },
    {
        "query":"是否能够将通过用户池进行管理的用户连接到 Active Directory 域？",
        "intention":"知识问答",
        "reply":"不能。我们目前不支持将用户池的用户连接到加入域的资源。要了解有关用户池的更多信息，请参阅[使用 AppStream 2.0 用户池](https://docs.aws.amazon.com/appstream2/latest/developerguide/user-pool.html)。"
    },
    {
        "query":"我的用户如何登录被加到 Active Directory 域的流式处理实例？",
        "intention":"知识问答",
        "reply":"当您的用户通过 Web 浏览器访问流式处理实例时，他们可以输入其域密码，然后登录他们的 Microsoft Active Directory 域。如果您的用户使用适用于 Windows 的 AppStream 2.0 客户端访问流式处理实例，他们可以输入其 Active Directory 域密码，或者使用受 Active Directory 域信任的智能卡。"
    },
    {
        "query":"学校、大学或公共机构需要提供哪些信息才能获得资格？",
        "intention":"知识问答",
        "reply":"您需要向 AWS 提供贵机构的完整法定名称、主要办公地址以及公共网站 URL。AWS 将根据这些信息判断您能否作为合格教育机构享受低 AppStream 2.0 用户费用。请注意：您对 Microsoft 软件的使用受 Microsoft 条款的约束。您有责任遵守 Microsoft 的许可要求。如果您对 Microsoft 软件许可或权利有任何疑问，请咨询您的法律团队、Microsoft 或 Microsoft 分销商。您同意我们向 Microsoft 提供相关信息，以便在您使用 Amazon AppStream 2.0 时应用教育定价。"
    },
    {
        "query":"是否可以在 AWS 月度账单报告上使用标签来获取有关 Amazon AppStream 2.0 使用情况和成本的详细信息？",
        "intention":"知识问答",
        "reply":"是。如果将标签设置为在月度成本分配报告上显示，您的 AWS 月度账单中也将包括这些标签。这样，您便可以根据需要轻松跟踪成本。为此，请首先按照[标记您的 AppStream 2.0 资源](https://docs.aws.amazon.com/appstream2/latest/developerguide/tagging-basic.html)中的步骤操作，为您的 Amazon AppStream 2.0 资源分配标签。接下来，按照[设置月度成本分配报告](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/configurecostallocreport.html)中的步骤操作，选择您的成本分配报告中要包括的标签键。"
    },
    {
        "query":"Amazon AppStream 2.0 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"是。如果您已与 AWS 签订了有效的商业伙伴增订合约 (BAA)，则可以通过与 BAA 关联的账户使用 Amazon AppStream 2.0 流式处理包含受保护的健康信息 (PHI) 的数据的桌面应用程序。如果您未与 AWS 签订有效的 BAA，请[联系我们](https://aws.amazon.com/compliance/hipaa-compliance/)，我们会让 AWS 销售团队代表与您联系。有关更多信息，请参阅 [HIPAA 合规性](https://aws.amazon.com/compliance/hipaa-compliance/)。"
    },
    {
        "query":"AppStream 2.0 PCI 是否合规？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 符合 PCI 和支付卡行业数据安全标准 (PCI DSS)。PCI DSS 是由 PCI 安全标准委员会管理的专有信息安全标准，该委员会由 American Express、Discover Financial Services、JCB International、MasterCard Worldwide 和 Visa Inc 创建。PCI DSS 适用于存储、处理或传输持卡者数据 (CHD) 和/或敏感性身份验证数据 (SAD) 的所有实体，包括商家、处理机构、购买方、发行机构和服务提供商。PCI DSS 由多家支付卡品牌联合制定，由支付卡行业安全标准委员会管理。有关更多信息，请参阅 [PCI DSS 合规性](https://aws.amazon.com/compliance/pci-dss-level-1-faqs/)。"
    },
    {
        "query":"系统和组织控制 (SOC) 报告中是否包括 Amazon AppStream 2.0？",
        "intention":"知识问答",
        "reply":"是。Amazon AppStream 2.0 包括在 AWS 系统和组织控制 (SOC) 报告中。AWS 系统和组织控制报告是独立的第三方检查报告，展示了 AWS 如何实现关键合规性控制和目标。这些报告的目的是帮助您和您的审计师理解旨在支持运营与合规性的 AWS 控制措施。您可以访问 [AWS 合规性计划](https://aws.amazon.com/cn/compliance/programs/)页面或[合规性计划的范围内服务](https://aws.amazon.com/cn/compliance/services-in-scope/)页面，了解有关 AWS 合规性计划的更多信息。\n了解有关 Amazon AppStream 2.0 定价的更多信息"
    },
    {
        "query":"什么是 Amazon Translate？",
        "intention":"知识问答",
        "reply":"Amazon Translate 是一种神经网络机器翻译 (MT) 服务，用于在支持的语言之间翻译文本。这项服务由深度学习方法支持，可以提供高质量、费用低廉且可定制的语言翻译，让开发人员能够翻译公司和用户编写的内容，或者构建需要多语言支持的应用程序。您可以通过 API 使用该服务，实现从源语言到目标语言的实时或批量文本翻译。"
    },
    {
        "query":"涵盖哪些语言？",
        "intention":"知识问答",
        "reply":"Amazon Translate 支持以下 75 种语言之间的翻译：南非语、阿尔巴尼亚语、阿姆哈拉语、阿拉伯语、亚美尼亚语、阿塞拜疆语、孟加拉语、波斯尼亚语、保加利亚语、简体中文、加泰罗尼亚语、繁体中文、克罗地亚语、捷克语、丹麦语、达里语、荷兰语、英语、爱沙尼亚语、芬兰语、法语、法语（加拿大）、格鲁吉亚语、德语、希腊语、古吉拉特语、海地克里奥尔语、豪萨语、希伯来语、印地语、匈牙利语、冰岛语、印度尼西亚语、爱尔兰语、意大利语、日语、埃纳德语、哈萨克语、韩语、拉脱维亚语、立陶宛语、马其顿语、马来语、马拉雅拉姆语、马耳他语、蒙古语、马拉地语、挪威语、波斯语、普什图语、波兰语、葡萄牙语、葡萄牙语（葡萄牙）、旁遮普语、罗马尼亚语、俄语、塞尔维亚语、僧伽罗语、斯洛伐克语、斯洛文尼亚语、索马里语、西班牙语、西班牙语（墨西哥）、斯瓦希里语、瑞典语、菲律宾塔加洛语、泰米尔语、泰卢固语、泰语、土耳其语、乌克兰语、乌尔都语、乌兹别克语、越南语和威尔士语。有关更多详细信息，请参阅此[文档页面](https://docs.aws.amazon.com/translate/latest/dg/pairs.html)。"
    },
    {
        "query":"为什么应该使用 Amazon Translate？",
        "intention":"知识问答",
        "reply":"您应该使用 Amazon Translate 的原因在于，它让您能够接触更多的客户、更有效地与他们沟通并降低您的总体拥有成本。许多企业都有大量由用户或公司编写的内容；而实现以多种语言及时访问所有这些内容的唯一方法，就是使用机器翻译。Amazon Translate 的成本只是人工翻译成本的一小部分 (Amazon Translate 的价格为 15 USD/百万字符，人工翻译的平均成本为 30000 USD/百万字符，前者为后者的 0.05%)，因此企业现在可以负担以前无法负担的翻译成本。\n对于语言服务提供商 (LSP) 和增值经销商，Amazon Translate 可以推动业务增长和扩展。借助 Amazon Translate，LSP 最多可将生产率提高 50％、提高翻译量，从而让专业翻译人员可以腾出时间专注于高端创意内容。Amazon Translate 还允许您利用活动自定义翻译来自定义翻译输出，作为 LSP，您可在使用 ACT 提供自定义翻译时保护自己的 IP。翻译经销商可以扩大他们的服务产品组合，无需构建新基础设施或雇用员工。"
    },
    {
        "query":"Amazon Translate 最常见的使用案例有哪些？",
        "intention":"知识问答",
        "reply":"在内容多、时间紧并能够接受一定程度的翻译瑕疵（通常是较小瑕疵）的情况下，Amazon Translate 是一个很好的解决方案。例如，如果您需要从多种语言的大量文本中提取信息、让客户能够以他们选择的语言来搜索您的应用程序、让论坛等用户编写的内容和支持内容能够以源语言之外的其他语言访问、从问卷和调查结果中提取要点或者发布初稿，您都可以使用 Amazon Translate 的原始输出来实现这些目标。\n配合少量的人工后期编辑，Amazon Translate 可以让客户服务部门能够为任何人提供支持，还可以翻译公司编写的各种信息，例如规格、替代方案比较、常见问题和支持内容。配合更多的后期编辑，您还可以使用 Amazon Translate 来翻译高价值的品牌内容，例如广告与营销材料以及合同等。"
    },
    {
        "query":"如何使用该服务？",
        "intention":"知识问答",
        "reply":"开始使用 Amazon Translate 最简单的方法是使用控制台翻译一些文本。您也可以从 AWS 命令行界面直接调用该服务，或使用采用您选择的编程语言的软件开发工具包，将其与您的应用程序集成。无论哪种方式，只需输入几行代码，您就可以开始使用 Amazon Translate 的多语言文本功能来翻译文本。\n您可以将源文本传输到 API，并指明源语言和目标语言。Amazon Translate 会返回已翻译成目标语言的文本。使用 API 主要有三种方式：第一种，您可以将 API 集成到您的应用程序中，以便将高度动态的应用程序组件 (例如多参与者聊天) 本地化。第二种，您可以将其与其他服务关联起来，以便实现独立于语言的处理。例如，您可以通过 AWS Lambda 蓝图调用 Amazon Relational Database Service (RDS) 等数据库服务，以便将包含用户生成的评论和论坛文章等中度动态内容的网站本地化。最后一种，您可以批量翻译文件。例如，金融服务公司可以翻译和监控任何语言的新闻文章；法律团队可以发现与诉讼相关的多种语言材料（此过程称为 eDiscovery）；专利代理人在处理知识产权问题时可以搜索全球任何地方的专利库。"
    },
    {
        "query":"该服务是否提供自动语言检测功能？",
        "intention":"知识问答",
        "reply":"Amazon Translate 支持纯文本输入和用于指明源文本语言和目标文本语言的语言标记。如果源语言未知，Amazon Translate 将使用 Amazon Comprehend 在后台识别源语言，并返回该语言与翻译后的目标语言的报告。"
    },
    {
        "query":"该服务支持哪种输入？",
        "intention":"知识问答",
        "reply":"Amazon Translate 支持 UTF-8 格式的纯文本输入。"
    },
    {
        "query":"对 API 有哪些限制？",
        "intention":"知识问答",
        "reply":"Amazon Translate 实时服务的调用限制为每个 API 调用 5000 个字节。我们提供了有关如何将大文件拆分成章节和段落的说明，以便客户可以翻译任何长度的文本。请单击[此处](https://docs.aws.amazon.com/translate/latest/dg/examples-split.html)查看说明。\nAmazon Translate 异步批量翻译服务对于每次 API 调用最多可接受 5GB 的批量大小，且每个文档大小不超过 20MB，每个文档包含的字符数不超过 100 万个，每个批次中 S3 存储桶文件夹中的文档数量不超过 100 万个。\nAmazon Translate 服务高度可扩展。[单击此处](https://docs.aws.amazon.com/translate/latest/dg/what-is-limits.html)可找到默认限制。"
    },
    {
        "query":"我是否需要说明由 Amazon 提供翻译？ 说明由机器翻译？",
        "intention":"知识问答",
        "reply":"您不需要说明，但我们建议您向自己的客户说明文件由机器翻译。"
    },
    {
        "query":"我可以在哪里获得技术支持？ 我如何提交反馈？",
        "intention":"知识问答",
        "reply":"有关技术支持，请联系 [AWS 客户服务](https://aws.amazon.com/contact-us/)。您可以通过客户服务提交反馈，也可以打开 Amazon Translate 控制台，然后选择反馈选项。"
    },
    {
        "query":"哪些 AWS 区域提供 Amazon Translate？",
        "intention":"知识问答",
        "reply":"请参阅 [AWS 全球基础设施区域表](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/)。\nAmazon Translate 批量翻译现已在以下区域推出：美国东部 1（弗吉尼亚北部）、美国东部 2（俄亥俄）、美国西部 2（俄勒冈）、欧洲西部 1（爱尔兰）、欧洲西部 2（伦敦）、欧洲中部 1（法兰克福） 和亚太东北部 2（首尔）。"
    },
    {
        "query":"Amazon Translate 是否会存储处理过的文本输入？AWS 如何使用这些输入？",
        "intention":"知识问答",
        "reply":"Amazon Translate 可以存储和使用仅由该服务处理的文本输入，以提供和维护服务，以及改进和提高 Amazon Translate 和其他 Amazon 机器学习/人工智能技术的质量。为了持续改善您的 Amazon Translate 客户体验并促进相关技术的开发和训练，我们重视使用您的内容。我们不会根据您的内容中可能包含的任何个人身份信息来向您或您的最终用户推荐产品、服务或进行营销。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/cn/compliance/data-privacy-faq/)。您可以通过使用 AWS Organizations 退出策略选择不再使用您的内容来改进或提高 Amazon Translate 及其他 Amazon 机器学习/人工智能技术的质量。有关如何退出的信息，请参阅[管理 AI 服务退出策略](https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_ai-opt-out.html)。"
    },
    {
        "query":"谁有权访问我的由 Amazon Translate 处理和存储的内容？",
        "intention":"知识问答",
        "reply":"只有经过授权的员工才能访问您由 Amazon Translate 处理的内容。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当并且先进的技术和物理控制措施 (包括静态和动态加密) 来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"由 Amazon Translate 处理和存储的内容是否仍归我所有？",
        "intention":"知识问答",
        "reply":"您始终保留对您的内容的所有权，我们只会在您同意的情况下使用您的内容。"
    },
    {
        "query":"Amazon Translate 处理的内容是否会移动到我使用 Amazon Translate 所在的 AWS 区域之外？",
        "intention":"知识问答",
        "reply":"Amazon Translate 处理的任何内容都会被加密，并静态存储在您使用 Amazon Translate 所在的 AWS 区域中。Amazon Translate 处理的部分内容可能存储在另一个 AWS 区域中，仅用于持续改进和开发您的 Amazon Translate 客户体验及其他 Amazon 机器学习/人工智能技术。您的信任以及隐私与内容的安全性是我们最重视的问题，我们会采取适当且先进的技术和物理控制措施（包括静态和动态加密）来防止他人未经授权访问或披露您的内容，并确保我们依照对您的承诺使用您的内容。有关更多信息，请参阅 <https://aws.amazon.com/compliance/data-privacy-faq/>。"
    },
    {
        "query":"能否将 Amazon Translate 用于针对不满 13 岁的儿童并受《儿童网络隐私保护法》(COPPA) 约束的网站、项目或其他应用程序？",
        "intention":"知识问答",
        "reply":"可以。但您需要遵守 [AWS 服务条款](https://aws.amazon.com/cn/service-terms/)的规定，包括按照 COPPA 的要求来提供任何需要的通知并获得任何需要的、可验证的家长同意，才能将 Amazon Translate 用于全部或部分针对不满 13 岁的儿童的网站、项目或其他应用程序。"
    },
    {
        "query":"怎样确定我的网站、项目或应用程序是否受 COPPA 的约束？",
        "intention":"知识问答",
        "reply":"要了解 COPPA 的要求并获取关于如何确定您的网站、项目或应用程序是否受 COPPA 约束的指南，请直接参阅美国联邦贸易委员会提供并维护的各种资源。该网站还提供有关如何确定某种服务是否全部或部分针对不满 13 周岁儿童的信息。"
    },
    {
        "query":"What is Amazon Managed Service for Prometheus?",
        "intention":"知识问答",
        "reply":"Amazon Managed Service for Prometheus is a serverless monitoring service for metrics compatible with open source Prometheus, making it easier for you to securely monitor and alert on container environments. Amazon Managed Service for Prometheus is a fully managed AWS service for monitoring containers on AWS, on premises, and in hybrid and multicloud environments; it is a cross-project solution based on the popular open-source Cloud Native Computing Foundation (CNCF) Prometheus project. Amazon Managed Service for Prometheus is powered by Cortex, an open-source CNCF project that adds horizontal scalability to ingest, store, query, and alert on Prometheus metrics. Amazon Managed Service for Prometheus reduces the heavy lifting required to get started with monitoring applications across Amazon Elastic Kubernetes Service, Amazon Elastic Container Service, and AWS Fargate, as well as self-managed Kubernetes clusters. Amazon Managed Service for Prometheus automatically scales as your monitoring needs grow. It offers highly available, multi-Availability Zone deployments, and integrates AWS security and compliance capabilities. Amazon Managed Service for Prometheus offers native support for the Prometheus Query Language (PromQL) as well as the ability to ingest Prometheus metrics from over 150+ Prometheus exporters maintained by the open source community."
    },
    {
        "query":"Why should I use Amazon Managed Service for Prometheus?",
        "intention":"知识问答",
        "reply":"You should use Amazon Managed Service for Prometheus if you have adopted an open source-based monitoring strategy, have already deployed or plan to adopt Prometheus for container monitoring, and prefer a fully managed experience across AWS or multiple cloud providers where AWS provides enhanced security, scalability, and availability. Amazon Managed Service for Prometheus is specifically architected to handle the high cardinality (large number of arbitrary tags) in monitoring data generated by container-based applications. Amazon Managed Service for Prometheus manages the operational complexity of elastically scaling the ingestion, storage, alerting and querying of metrics to meet any customer’s demand while being 100% compatible with the open source CNCF-hosted project.\nAmazon Managed Service for Prometheus offers a secure and highly available service that eliminates the need to manually deploy, manage, and operate Prometheus components. The service also seamlessly integrates with the new [Amazon Managed Grafana](https://aws.amazon.com/grafana/) service to simplify data visualization, team management authentication, and authorization."
    },
    {
        "query":"What is a Prometheus metric label?",
        "intention":"知识问答",
        "reply":"The Prometheus data model identifies each time series with a name and any number of key-value pairs called labels. Labels can be used to differentiate the characteristics of what is being measured such as “region=us-east-1”, “environment=production”, and “app=ecommerce”. Labels are similar to AWS tags applied on resources, see [reference guide](https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html) for more details, or [Dimension](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_Dimension.html) applied on CloudWatch metrics."
    },
    {
        "query":"How does this service relate to/work with other AWS services or other clouds?",
        "intention":"知识问答",
        "reply":"While it is based on the open source Prometheus project, Amazon Managed Service for Prometheus provides a fully managed AWS service integrated with other AWS services and is compatible with hybrid and multicloud environments. Amazon Managed Service for Prometheus is configured and managed from the AWS Console, API, and CLI. Authorization is controlled by IAM, policy control from AWS Organizations, and API calls are logged to AWS CloudTrail. Prometheus remote write can be configured to send metrics from your existing Prometheus server or AWS Distro for OpenTelemetry running in EKS and ECS, empowering you to easily enable your container workloads for Prometheus based monitoring. Amazon Managed Service for Prometheus offers seamless integration with Amazon Managed Grafana for interactive data visualization."
    },
    {
        "query":"Can I get a history of Amazon Managed Service for Prometheus API calls made on my account for security analysis and operational troubleshooting purposes?",
        "intention":"知识问答",
        "reply":"Yes. To receive a history of Amazon Managed Service for Prometheus API calls made on your account, you simply turn on CloudTrail in the AWS Management Console. The following API calls to ingest and query metrics in Amazon Managed Service for Prometheus are not recorded and delivered: remote\\_write, query, query\\_range, labels, label/{name}/values, series, and metadata."
    },
    {
        "query":"How does Amazon Managed Service for Prometheus relate to Amazon CloudWatch? Which one should I use?",
        "intention":"知识问答",
        "reply":"Amazon CloudWatch is an AWS service that provides end-to-end observability across logs, metrics, and traces for applications running on EC2, AWS container services (EKS, ECS), Lambda, and other AWS services. Amazon CloudWatch can discover and collect Prometheus metrics, as CloudWatch metrics to provide options for our customers to query and alarm on Prometheus metrics. Amazon CloudWatch provides a comprehensive set of agents and libraries, custom and automatic dashboards, alarms, synthetic monitoring, and a service map view that enables cross correlation of logs, metrics, and traces. You should use Amazon CloudWatch if you are looking for a comprehensive observability service that brings together logs, metrics, tracing, dashboarding, and alerting in a unified experience that encompasses AWS services, EC2, containers, and serverless.\nAmazon Managed Service for Prometheus is specifically optimized for monitoring container-based workloads. Amazon Managed Service for Prometheus offers a Prometheus-compatible APIs for ingesting and querying your Prometheus metrics. Amazon Managed Service for Prometheus is a metric-only service and does not collect logs or distributed trace data. You can export selected CloudWatch metrics to Amazon Managed Service for Prometheus in order to use PromQL as the common query language for querying and alarming on all your stored metrics. You should use Amazon Managed Service for Prometheus if you want a service that is fully compatible with the Prometheus open source project. You should also choose Amazon Managed Service for Prometheus if you are already running Prometheus and are looking to eliminate that ongoing operational cost while also improving security."
    },
    {
        "query":"What is Amazon Managed Grafana?",
        "intention":"知识问答",
        "reply":"Grafana is an open source project for interactive data visualization used for monitoring and alerting that is commonly used with the Prometheus open source project. Amazon Managed Grafana is a fully managed service compatible with the open source Grafana project. Amazon Managed Grafana makes it simple for engineering teams to query, visualize, and alert on data sources such as metrics, logs, and traces, no matter where they are stored."
    },
    {
        "query":"How does Amazon Managed Service for Prometheus integrate with Amazon Managed Grafana?",
        "intention":"知识问答",
        "reply":"Both services share AWS security services such as fine-grained access control and activity audit trails. Amazon Managed Grafana offers alerting capabilities, which can be used to alert on Prometheus metrics. Grafana empowers you to create dashboards and alerts from multiple sources such as Prometheus, Amazon CloudWatch, AWS X-Ray, Amazon Elasticsearch, and AWS Timestream."
    },
    {
        "query":"How does Amazon Managed Service for Prometheus relate to other popular open source observability and monitoring projects?",
        "intention":"知识问答",
        "reply":"Amazon Managed Service for Prometheus is based on the popular Cloud Native Computing Foundation (CNCF) Prometheus project, and is powered by Cortex, another open source CNCF project, which adds horizontal scalability to ingest, store, query, and alert on Prometheus metrics. Amazon Managed Service for Prometheus is committed to ongoing open source contributions and is working collaboratively with the community to improve the scale and reliability of this and other open source projects. Amazon Managed Service for Prometheus also uses [AWS Distro for OpenTelemetry](https://aws.amazon.com/otel/) as a collection agent for Prometheus metrics."
    },
    {
        "query":"What does your Amazon Managed Service for Prometheus Service Level Agreement guarantee?",
        "intention":"知识问答",
        "reply":"Our SLA guarantees a Monthly Uptime Percentage of at least 99.9% for Amazon Managed Service for Prometheus within a Region."
    },
    {
        "query":"How do I know if I qualify for a SLA Service Credit?",
        "intention":"知识问答",
        "reply":"You are eligible for a SLA credit for Amazon Managed Service for Prometheus if the Region that you are operating in has a Monthly Uptime Percentage of less than 99.9% during any monthly billing cycle. For full details on all of the terms and conditions of the SLA, as well as details on how to submit a claim,  please see [Amazon Managed Service for Prometheus Service Level Agreement.](https://aws.amazon.com/prometheus/sla/)"
    },
    {
        "query":"I have a feature request, who do I tell?",
        "intention":"知识问答",
        "reply":"Please let us know what we can add or do better by opening a feature request on the [Amazon Managed Service for Prometheus public roadmap](https://github.com/aws/amazon-managed-service-for-prometheus-roadmap/issues)."
    },
    {
        "query":"什么是 Amazon Redshift？  每天有数以万计的客户使用 Amazon Redshift 在云端中运行 SQL 分析，处理 EB 级的数据，以获取业务洞察。无论您持续增长的数据存储在运营数据存储、数据湖、流数据服务还是第三方数据集之中，Amazon Redshift 都可以帮助您以最少的移动或复制量，安全地访问、组合和共享数据。Amazon Redshift 与 AWS 数据库、分析和机器学习服务深度集成，能够使用零 ETL 方法，或是帮助您随时访问数据以进行近乎实时的分析，在 SQL 中构建机器学习模型，并使用 Redshift 中的数据启用 Apache Spark 分析。Amazon Redshift 无服务器能让您的工程师、开发人员、数据科学家和分析师轻松入门，并在零管理环境中快速扩展分析。拥有大规模并行处理（MPP）引擎、分离计算和存储实现高效扩展的架构，以及机器学习驱动的性能创新（例如：自动实体化视图），Amazon Redshift 为规模而生，可提供达其他云数据仓库 5 倍的性价比。  问：客户选择 Amazon Redshift 的最主要原因是什么？  上千客户选择 Amazon Redshift 来更快地获得业务洞察，因为其作为强大的分析系统，与数据库和机器学习服务完美集成，精简易用，能够成为满足所有分析需求的中心服务。Amazon Redshift 无服务器自动预置和扩展数据仓库容量，为要求严苛且不可预测的工作负载提供高性能。无论是控制面板、应用开发、数据共享、ETL（提取、转换、加载）工作还是其他工作，Amazon Redshift 为各种分析工作负载提供行业领先的性价比。通过数万名客户对从 TB 级到 PB 级的数据运行的分析，Amazon Redshift 根据实例集的性能遥测，优化真实世界的客户工作负载性能，并提供从线性扩展到工作负载的性能，同时维持低廉成本。客户无需付出额外成本，即可实现性能上的创新。Amazon Redshift 使您能够跨越运营数据库、数据湖、数据仓库、流数据和第三方数据集对所有数据运行实时和预测性分析，并获得洞察。Amazon Redshift 利用内置的身份管理和单点登录（SSO）联合身份验证、多重身份验证、列级访问控制、行级别安全性、基于角色的访问控制、Amazon Virtual Private Cloud（Amazon VPC）和更快的集群大小调整，实现了行业领先的安全性。  问：Amazon Redshift 如何简化数据仓库并分析管理？  Amazon Redshift 由 AWS 完全托管，因此您无需担心数据仓库管理任务，如硬件调配、软件修补、设置、配置、监控节点和驱动器以从故障中恢复，或备份。AWS 代表您管理设置、操作和扩展数据仓库所需的工作，使您能够专注于构建您的应用程序。Amazon Redshift 无服务器会自动预置和扩展数据仓库容量，为严苛且不可预测的工作负载提供高性能，您仅需为实际使用的资源付费。Amazon Redshift 还有自动优化功能，并可在 Redshift Advisor 中显示关于管理仓库的建议。借助 Redshift Spectrum，Amazon Redshift 可以管理所有计算基础设施、负载均衡、计划、调度和对 Amazon S3 中存储的数据查询的执行情况。Amazon Redshift 通过与数据库服务的深度整合，从而能够对所有数据进行分析，其功能包括 Amazon Aurora 零 ETL，Amazon Redshift 和联合查询，以从 Amazon RDS 和您的 Amazon S3 数据湖等运营数据库访问数据。Redshift 能够通过无代码的自动数据管道，实现对流数据或 Amazon S3 文件的自动摄取。Redshift 还与 AWS Data Exchange 集成，使用户能够查找、订阅和查询第三方数据集，并结合自己的数据，获得全面的洞察。通过与 Amazon SageMaker 的原生集成，客户可以直接在他们的数据仓库中，用 SQL 创建、训练和构建机器学习模型。Amazon Redshift 可满足您所有的 SQL 分析需求，其性价比优于其他云数据仓库 5 倍之多。  问：Amazon Redshift 有哪些部署选项？  Amazon Redshift 是完全托管式服务，提供预置和无服务器选项，助您更高效地运行和扩展分析，而无需管理您的数据仓库。仅需几秒，您就可以启动一个新的 Amazon Redshift 无服务器端点，以自动预置数据仓库，或者为可预测的工作负载选择配置选项。  问：如何开始使用 Amazon Redshift？  只需在 AWS 管理控制台中进行几个步骤，即可开始查询数据。您可以利用预加载的示例数据集（包括基准数据集 TPC-H、TPC-DS）和其他示例查询，以立即开始分析。要开始使用 Amazon Redshift 无服务器，选择“试用 Amazon Redshift 无服务器”并开始查询数据。单击此处开始使用。  问：与其他数据仓库相比，Amazon Redshift 的性能如何？  TPC-DS 基准测试结果表明，即使是相对较小的 3TB 数据集，Amazon Redshift 也能提供最佳性价比，即时可用。Amazon Redshift 提供达其他云数据仓库 5 倍的性价比。这意味着，无需手动优化，您便可享受 Amazon Redshift 领先的性价比。根据我们的性能实例集遥测，我们还了解到，多数工作负载都是短查询工作负载（运行时间少于 1 秒的工作负载）。对于这类工作负载，最新的基准测试表明，Amazon Redshift 在高并发、低延迟的工作负载上可提供达其他云数据仓库 7 倍的性价比。 单击此处了解更多信息。  问：我是否能获得帮助以了解关于 Amazon Redshift 的更多信息并参与其中？  答：是的，Amazon Redshift 专家可以回答问题并提供支持。联系我们，您将在一个工作日内收到我们的回复，讨论 AWS 如何能为您的企业提供帮助。  问：什么是 Amazon Redshift 托管存储？",
        "intention":"知识问答",
        "reply":"Amazon Redshift 托管存储随无服务器和 RA3 节点类型提供，使您能够独立扩展和支付计算和存储费用，因此您可以仅根据计算需求来调整集群大小。它自动将基于高性能 SSD 的本地存储用作第 1 层缓存，并利用数据块温度、数据块使用年限和工作负载模式等优化来提供高性能，同时在需要时自动将存储扩展到 Amazon S3，而无需执行任何操作。"
    },
    {
        "query":"如何使用 Amazon Redshift 的托管存储？",
        "intention":"知识问答",
        "reply":"如果您已经在使用 Amazon Redshift 密集存储或密集计算节点，则可以使用 Elastic Resize（弹性大小调整）将现有集群升级到新的计算实例 RA3。Amazon Redshift 无服务器和使用 RA3 实例的集群自动使用 Redshift 托管的存储来存储数据。除了使用 Amazon Redshift 无服务器或 RA3 实例外，不需要其他操作来使用此功能。"
    },
    {
        "query":"如何从 Redshift 对存储在 AWS 数据湖的数据运行查询？  Amazon Redshift Spectrum 是 Amazon Redshift 的一项功能，借助这项功能，您可以对 Amazon S3 中的数据湖运行查询，而无需进行数据加载或 ETL 操作。当您发布 SQL 查询时，查询会进入 Amazon Redshift 端点，该端点会生成查询方案并对其进行优化。Amazon Redshift 会确定哪些数据存储在本地以及哪些数据存储在 Amazon S3 中，然后生成一种方案来尽可能减少需要读取的 S3 数据量，从共享资源池中请求 Amazon Redshift Spectrum 工作线程来读取和处理 Amazon S3 中的数据。  问：何时应考虑使用 RA3 实例？  在以下情况下，考虑选择 RA3 节点类型：",
        "intention":"知识问答",
        "reply":"随着数据规模的持续增长（达到 PB 级），您在 Amazon Redshift 数据仓库中摄取的数据量也在增长。您可能正在寻找经济高效的方法来分析所有数据。  \n   \n 使用带有托管存储的新 Amazon Redshift RA3 实例，您可以基于您的性能需求选择节点数量，并且只需为您实际使用的托管存储付费。这样，您就可以基于您每天处理的数据量灵活调整 RA3 集群的大小，而不会增加您的存储成本。基于 AWS Nitro System，具有托管存储的 RA3 实例对热数据使用高性能 SSD，对冷数据使用 Amazon S3，提供易用性、经济高效的存储和快速查询性能。  \n   \n 问：我可以使用什么功能进行基于位置的分析？  \n   \n Amazon Redshift 空间提供基于位置的分析，以全面洞察您的数据。它无缝整合空间和业务数据，为制定决策提供分析。[Amazon Redshift 于 2019 年 11 月推出了原生空间数据处理支持](https://aws.amazon.com/about-aws/whats-new/2019/11/amazon-redshift-announces-support-spatial-data/)，包括多态数据类型 GEOMETRY，以及多个关键的 SQL 空间函数。我们现在支持 GEOGRAPHY 数据类型，并且我们的 SQL 空间函数库已经增加到 80 个。我们支持所有常见的空间数据类型和标准，包括 Shapefiles、GeoJSON、WKT、WKB、eWKT 和 eWKB。要了解更多，请访问[文档](https://docs.aws.amazon.com/redshift/latest/dg/geospatial-overview.html)页面或 [Amazon Redshift spatial 教程](https://docs.aws.amazon.com/redshift/latest/dg/spatial-tutorial.html)页面。"
    },
    {
        "query":"Redshift 是否支持精细访问控制？   是的，Amazon Redshift 支持基于角色的访问控制。行级别访问控制使您能为用户分配一个或多个角色，并按角色分配系统和对象权限。您可以使用开箱即用的系统角色（根用户、dba、操作员和安全管理员），或者创建自己的角色。  问：Amazon Redshift 是否支持数据掩蔽或数据令牌化？  通过 AWS Lambda 用户定义函数（UDF），您可将 AWS Lambda 函数用作 Amazon Redshift 中的 UDF，并从 Redshift SQL 查询调用它。此功能支持为 SQL 查询编写自定义扩展，以实现与其他服务或第三方产品的更紧密集成。您可以在查询时间中编写 Lambda UDF，以启用外部令牌化、数据掩蔽、通过与 Protegrity 之类的供应商集成对数据进行身份识别或去除身份识别信息，并根据用户的权限或组保护或取消保护敏感数据。",
        "intention":"知识问答",
        "reply":"由于支持动态数据掩蔽，客户可以轻松保护敏感数据，并通过管理数据掩蔽策略控制精细访问。假设您的应用程序具有多个用户和对象，且这些对象具有不能向所有用户公开的敏感数据。您需要为不同的用户组提供不同的精细安全级别。Redshift 动态数据掩蔽是可配置的，允许客户定义一致的、保持格式的和不可逆的掩蔽数据值。正式发布时，您可以立即开始使用该功能。安全管理员只需几个命令就可以创建并应用政策。"
    },
    {
        "query":"如何监控 Amazon Redshift 数据仓库集群的性能？  您可以通过 AWS 管理控制台或 Amazon CloudWatch API 免费获得计算使用率、存储使用率和 Amazon Redshift 数据仓库集群读/写流量方面的指标。您也可通过 Amazon CloudWatch 的自定义指标功能来添加更多用户定义的指标。AWS 管理控制台中的监控控制面板可以帮助您监控所有集群的运行状况和性能。Amazon Redshift 还通过 AWS 管理控制台提供关于查询及集群性能的信息。通过查看这些信息中的查询计划和执行统计信息，您可以了解哪些用户和查询在消耗最多的系统资源来诊断性能问题。此外，您还可以了解每个计算节点上的资源使用情况，确保数据和查询在所有节点之间达到平衡。  问：什么是维护时段？ 在软件维护期间数据仓库集群仍可供使用吗？  Amazon Redshift 可以定期执行维护，以便将修复程序、增强功能和新功能应用到您的集群。您可以通过编程方式或使用 Redshift 控制台对集群进行修改，从而更改计划的维护时段。在维护时段内，您无法对 Amazon Redshift 集群执行正常操作。要了解有关各区域的维护时段和计划的更多信息，请参阅《Amazon Redshift 管理指南》中的维护时段。",
        "intention":"知识问答",
        "reply":"了解有关 Amazon Redshift 定价的更多信息"
    },
    {
        "query":"What is Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision is a machine learning (ML) service that helps increase industrial production quality and reduce operational costs by identifying visual defects in objects. With Amazon Lookout for Vision you can identify visual defects at scale and decrease dependency on manual inspection."
    },
    {
        "query":"What can I do with Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"With Amazon Lookout for Vision, you can spot product defects using computer vision to automate quality inspection process in your manufacturing lines."
    },
    {
        "query":"How do I get started with Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"If you are not already signed up for Amazon Lookout for Vision, choose Try Amazon Lookout for Vision on the [Amazon Lookout for Vision](https://aws.amazon.com/lookout-for-vision/) page and complete the sign-up process. You must have an Amazon Web Services account. If you don’t already have an AWS account, you’ll be prompted to create one during the sign-up process. After you’re signed up, try out Amazon Lookout for Vision with your own images using the [Amazon Lookout for Vision console](https://console.aws.amazon.com/lookoutvision/home) or download the Amazon Lookout for Vision SDKs to start creating your own applications. For more information, see the [Getting Started Guide](https://aws.amazon.com/lookout-for-vision/resources/)."
    },
    {
        "query":"What are the most common use cases for Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"The most common use cases include:\n• Detect damages to parts: You can detect defects related to welds, dents, cracks, bubbles, surface color, and shape of objects.  \n • Identify missing components: You can identify missing components or parts related to absence, presence, placement of objects within a certain tolerance.  \n • Uncover process issues: You can detect a defect that has a repeating pattern, which can indicate a process issue."
    },
    {
        "query":"Do I need any machine learning expertise to use Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"No. With Amazon Lookout for Vision, you don’t have to build, maintain, or understand machine learning or deep learning pipelines.\nTo achieve accurate results on a complex computer vision task such as anomaly detection, deep learning systems need to be tuned properly and trained with labeled ground truth data. Sourcing, cleaning, and labeling data accurately is a time-consuming and expensive task. Moreover, training a deep neural network is expensive and often requires custom hardware built using Graphics Processing Units (GPU).\nAmazon Lookout for Vision is fully managed and comes with anomaly detection techniques for defect detection tasks so that you don’t have to invest your time and resources on creating a deep learning pipeline. Amazon Lookout for Vision continues to improve the accuracy of its models by building on the latest research and sourcing new training data. This enables you to focus on maximizing your business value instead."
    },
    {
        "query":"How many images are needed to train a defect detection model?",
        "intention":"知识问答",
        "reply":"The number of images required to train an anomaly detection model depends on the variability in the production line where you want the model to predict defects and the quality of the training data. For example, if the lighting, zoom level, focus on the region of interest, and alignment are constant you can get started with as few as 30 images, whereas a more complex use case with many variations (lighting, alignment, viewpoint), may need hundreds of training examples with high quality annotations. If you already have a high number of labeled images, we recommend training a model with as many images as you have available. For limits on maximum training dataset size, see the documentation.\nAlthough hundreds of images may be required to train a defect detection model with high accuracy, initially with Lookout for Vision you can train a model with fewer images, review your test results so that you understand where it doesn’t work, add new training images, and then train the model again to iteratively improve your model."
    },
    {
        "query":"My training has failed. Will I be charged?",
        "intention":"知识问答",
        "reply":"No. You will not be charged for the compute resources if your training fails."
    },
    {
        "query":"How many inference compute resources should I provision for my defect detection model?",
        "intention":"知识问答",
        "reply":"The number of parallel inference compute resources needed depends on how many images you need to process at a given point in time. The throughput of a single resource depends on factors including the size of the images, the complexity of those images, and the complexity of the defect detection model. We recommend that you monitor the frequency at which you need to provision your model, and the number of images that need to be processed at a single time, in order to schedule provisioning of your model most efficiently. After you complete your production line integration, you should start provisioning your model at a scheduled time, process all your images, and then stop provisioning. If you don’t stop provisioning, you will be charged even if no images are processed."
    },
    {
        "query":"What image formats does Amazon Lookout for Vision support?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision currently supports the JPEG and PNG image formats. You can submit images as a byte array."
    },
    {
        "query":"What file sizes can I use with Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision supports image file sizes up to 5 MB."
    },
    {
        "query":"How can I get Amazon Lookout for Vision predictions reviewed by process engineers or operators?",
        "intention":"知识问答",
        "reply":"You can use Amazon Lookout for Vision with Amazon Augmented AI (Amazon A2I) so you can route low confidence predictions from Amazon Lookout for Vision to human reviewers (process engineers, quality managers, or operators). You can specify the conditions under which Amazon A2I routes predictions to reviewers, which can be either a confidence score threshold, or a random sampling percentage. You can adjust these thresholds to achieve the right balance between accuracy and cost- effectiveness. This can help you implement audits to monitor the prediction accuracy regularly. Amazon A2I also provides reviewers with a web interface consisting of all the instructions and tools they need to complete their review tasks. For more information about implementing human review with Amazon Lookout for Vision, see the [Amazon A2I webpage](https://aws.amazon.com/augmented-ai/)."
    },
    {
        "query":"Can I use my Amazon Lookout for vision model on the edge?",
        "intention":"知识问答",
        "reply":"Yes, Amazon Lookout for Vision models can be used on the edge using AWS IoT Greengrass.  For more information, see the [Getting Started Guide](https://aws.amazon.com/lookout-for-vision/resources/)."
    },
    {
        "query":"What hardware devices are supported by Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"You can deploy Amazon Lookout for Vision models on a hardware device of your choice using AWS IoT Greengrass. Amazon Lookout for Vision models can be deployed on any NVIDIA Jetson edge appliance or x86 compute platform running Linux with an NVIDIA GPU accelerator. We use Amazon SageMaker Neo to compile our models to be edge compatible. See the list of supported devices [here](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-devices.html)."
    },
    {
        "query":"How is Amazon Lookout for Vision priced?",
        "intention":"知识问答",
        "reply":"For current pricing information, see the [Amazon Lookout for Vision Pricing Page](https://aws.amazon.com/lookout-for-vision/pricing/)."
    },
    {
        "query":"Does Amazon Lookout for Vision participate in the AWS Free Tier?",
        "intention":"知识问答",
        "reply":"Yes. As part of the AWS Free Tier, you can get started with Amazon Lookout for Vision for free. The Free Tier lasts 3 months and includes 10 free cloud training hours, up to 4 free cloud inference hours per month, and up to 5 free edge inference units per month.  For more details, [see the pricing page](https://aws.amazon.com/lookout-for-vision/pricing/)."
    },
    {
        "query":"Which APIs does Amazon Lookout for Vision charge for?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision charges for the following APIs: CreateModel API for training operation, and the total elapsed minutes between the StartModel API and the StopModel API usage. Amazon Lookout for Vision charges are based on the duration of training and inference minutes."
    },
    {
        "query":"In which AWS regions is Amazon Lookout for Vision available?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision is available today in US East (N. Virginia), US East (Ohio), US West (Oregon), EU (Ireland), EU (Frankfort), Asia Pacific (Tokyo), and Asia Pacific (Seoul), with availability in additional regions in the coming months."
    },
    {
        "query":"Will I be charged for the model packaging API?",
        "intention":"知识问答",
        "reply":"No. You will only be charged when your Lookout for Vision model is actively being used to detect anomalies. The model packaging API allows you to package your trained Lookout for Vision as an AWS IoT Greengrass component which you can then deploy to a hardware device of your choice. For more information, see the [Getting Started Guide](https://aws.amazon.com/lookout-for-vision/resources/)."
    },
    {
        "query":"How do I control use access for Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision is integrated with AWS Identity and Access Management (IAM). IAM policies can be used to ensure that only authorized users have access to Amazon Lookout for Vision APIs. For more details, please see the Amazon Lookout for Vision Authentication and Access Control page."
    },
    {
        "query":"Are the image inputs process by Amazon Lookout for Vision stored, and how are they used by AWS?",
        "intention":"知识问答",
        "reply":"Amazon Lookout for Vision may store and use image inputs processed by the service solely to provide and maintain the service and to improve and develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies. Use of your content is necessary for continuous improvement of your Amazon Lookout for Vision customer experience, including the development and training of related technologies. We do not use any personally identifiable information that may be contained in your content to target products, services or marketing to you or your end users.\nYour trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. For more information, see  <https://aws.amazon.com/compliance/data-privacy-faq/>. You may opt out of having your image inputs used to improve or develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies using an AWS Organizations opt-out policy. For information about how to opt out, see Managing AI services opt-out policy."
    },
    {
        "query":"Is the content processed by Amazon Lookout for Vision moved outside the AWS region where I am using Amazon Lookout for Vision?",
        "intention":"知识问答",
        "reply":"Any content processed by Amazon Lookout for Vision is encrypted and stored at rest in the AWS region where you are using Amazon Lookout for Vision. Some portion of content processed by Amazon Lookout for Vision may be stored in another AWS region solely in connection with the continuous improvement and development of your Amazon Lookout for Vision customer experience and other Amazon machine-learning/artificial-intelligence technologies.\nIf you opt out of having your content used to develop the quality of Amazon Lookout for Vision and other Amazon ML/AI technologies by contacting AWS Support, your content will not be stored in another AWS region. You can request deletion of content associated with your account by contacting AWS Support. Your trust, privacy, and the security of your content are our highest priority and we implement appropriate and sophisticated technical and physical controls, including encryption at rest and in transit, designed to prevent unauthorized access to, or disclosure of, your content and ensure that our use complies with our commitments to you. Please see [https://aws.amazon.com/compliance/data-privacy-faq/](https://aws.amazon.com/compliance/data-privacy-faq/) for more information.\nVisit the Amazon Lookout for Vision resources page to learn more about available resources.\nInstantly get access to the AWS Free Tier.\nGet started building with Amazon Lookout for Vision in the AWS Management Console."
    },
    {
        "query":"什么是 AWS Clean Rooms？",
        "intention":"知识问答",
        "reply":"AWS Clean Rooms 是一项新服务，可以让您和您的合作伙伴更轻松地分析和协作处理集体数据集，从而获得见解，而无需共享或复制彼此的基础数据，也不必将其移出 AWS。您可以使用 AWS Clean Rooms 在几分钟内创建自己的净室，然后只需几个步骤即可开始分析您的集体数据集。在 AWS 管理控制台中，您可以选择要与之协作的合作伙伴、选择数据集并为参与者配置限制。借助 AWS Clean Rooms，您可以轻松地与已经在使用 AWS 的数十万家公司协作，而无需将数据移出 AWS 或将其加载到另一个平台。当您运行查询时，AWS Clean Rooms 会在数据所在的位置读取数据并应用灵活的内置分析规则来帮助您保持对数据的控制。AWS Clean Rooms 提供了一套适用于洁净室的广泛隐私增强控制措施，包括查询控制、查询输出限制和查询日志记录，允许您自定义对每个洁净室参与者运行的查询的限制。AWS Clean Rooms 还包括高级加密计算工具，即使在处理查询时也能保持数据加密，以符合严格的数据处理策略。"
    },
    {
        "query":"AWS Clean Rooms 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"AWS Clean Rooms 现已在以下区域推出：美国东部（俄亥俄州）、美国东部（弗吉尼亚州北部）、美国西部（俄勒冈州）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）和欧洲地区（斯德哥尔摩）。"
    },
    {
        "query":"AWS Clean Rooms 是否符合 HIPAA 要求？",
        "intention":"知识问答",
        "reply":"是，AWS HIPAA 合规性计划将 AWS Clean Rooms 作为一项符合 HIPAA 要求的服务包含在内。如果您与 AWS 签订了商业伙伴协议 (BAA)，现在可以使用 AWS Clean Rooms 建立符合 HIPAA 要求的合作。如果您未签订商业伙伴协议或者在将 AWS 用于 HIPAA 合规应用程序方面有其他问题，请联系我们，以获取详细信息。\n要了解更多信息，请参阅以下资源：\n立即在 AWS 管理控制台中使用 AWS Clean Rooms 开始构建。\n深入了解 AWS Clean Rooms 如何帮助您在不共享原始数据的情况下进行协作。\n了解领先的公司如何使用 AWS Clean Rooms 通过协作获取见解。\n与我们的团队交流，了解有关 AWS Clean Rooms 的更多信息。"
    },
    {
        "query":"AWS Batch 有哪些主要功能？",
        "intention":"知识问答",
        "reply":"AWS Batch 可以管理计算环境和作业队列，从而使您能够使用 [Amazon ECS](https://aws.amazon.com/ecs/)、[Amazon EKS](https://aws.amazon.com/eks/) 和 [AWS Fargate](https://aws.amazon.com/fargate/) 轻松运行数千个任意规模的作业，并可选择竞价型或按需资源。您只需定义批处理作业并将其提交到队列中即可。在作出响应时，AWS Batch 可选择在何处运行作业，从而在需要时启动其他 AWS 容量。AWS Batch 会严密监控您的作业进度。当不再需要容量时，AWS Batch 会将其删除。借助 AWS Batch，您还可以提交属于管道或工作流程一部分的作业，从而使您能够在提交作业时说明各项作业之间存在的依赖关系。"
    },
    {
        "query":"为什么我应该将加速器与 AWS Batch 配合使用？ 通过将加速器与 Batch 配合使用，您可以根据加速器需求动态安排和预置作业，Batch 将确保为您的作业保留适当数量的加速器。Batch 将在您需要时扩展您的 EC2 加速实例，并在完成后缩减它们，使您可以专注于您的应用程序。Batch 与 EC2 Spot 进行原生集成，这意味着使用加速实例时，加速作业可以节省高达 90％ 的成本。",
        "intention":"知识问答",
        "reply":"来自 API：  \n {  \n \"containerProperties\": {  \n \"vcpus\": 1,  \n \"image\": \"nvidia/cuda:9.0-base\",  \n \"memory\": 2048,  \n \"resourceRequirements\" : [  \n {  \n \"type\" : \"GPU\",  \n \"value\" : \"1\"  \n }  \n ],"
    },
    {
        "query":"提交作业时是否可以覆盖作业定义中的加速器变量？ 与 vCPU 和内存要求类似，您可以在提交作业时覆盖加速器的数量和类型。  问：加速实例可以用于不需要加速器的作业吗？ 考虑今天的行为，在可能的情况下，Batch 将避免安排不需要加速实例加速的作业。这是为了避免长时间运行的作业占用加速实例而不利用加速器，从而增加成本。在极少数情况下，使用 Spot 定价并将加速实例作为允许类型时，Batch 可能会确定加速实例是运行作业的最便宜方式，无论加速器需求如何。",
        "intention":"知识问答",
        "reply":"如果您将作业提交给仅允许 Batch 启动加速实例的 CE，则 Batch 将在这些实例上运行作业，而不管其加速器需求如何。"
    },
    {
        "query":"需要预置哪些内容才能开始使用？ 您无需手动启动自己的计算资源即可开始使用。AWS Batch Web 控制台将指导您完成首个计算环境和作业队列的创建流程，以便您可以提交第一项作业。计算环境中的资源将在其他作业可运行时进行扩展，并随着可运行作业数量的减少而缩减。",
        "intention":"知识问答",
        "reply":"了解有关何时应该使用 AWS Batch 的更多信息"
    },
    {
        "query":"Amazon SQS 相对于自主或打包式消息队列系统有哪些优势？",
        "intention":"知识问答",
        "reply":"自行构建软件来管理消息队列或者使用商用或开源消息队列系统在前期需要花费大量的时间进行开发和配置，与其相比，使用 Amazon SQS 具有若干优势。\n其他方案需要持续进行硬件维护，并会占用系统管理资源。如果需要冗余消息存储以确保在出现硬件故障时不会丢失消息，那么这些系统的配置和管理将更为复杂。\n相反，Amazon SQS 不需要管理开销，而且基本不需要配置。Amazon SQS 可以大规模处理工作，每天处理数十亿条消息。您可以在不进行任何配置的情况下增加或减少向 Amazon SQS 发送的流量。此外，Amazon SQS 还可以实现极高的消息持久性，让您和您的利益攸关方更加放心。"
    },
    {
        "query":"Amazon SQS 与 Amazon Simple Notification Service (SNS) 有什么不同？",
        "intention":"知识问答",
        "reply":"Amazon SNS 允许应用程序通过“推送”机制向多个订阅者发送时间关键型消息，并且无需定期检查或“轮询”更新。Amazon SQS 是一种供分布式应用程序使用的消息队列服务，通过轮询模式交换消息，可用于分离收发组件。"
    },
    {
        "query":"Amazon SQS 与 Amazon MQ 有何不同？",
        "intention":"知识问答",
        "reply":"如果您正在使用现有应用程序中的消息收发功能，并且想要快速轻松地将消息收发功能移至云中，我们建议您考虑使用 [Amazon MQ](https://aws.amazon.com/cn/amazon-mq/)。它支持多种行业标准 API 和协议，因此您可以从任何基于标准的消息代理切换到 Amazon MQ，无需重新编写应用程序中的消息收发代码。如果您要在云中构建全新的应用程序，我们建议您考虑使用 Amazon SQS 和 Amazon SNS。Amazon SQS 和 SNS 是轻型的、完全托管的消息队列和主题服务，可以几乎无限地进行扩展，并可提供易于使用的简单 API。"
    },
    {
        "query":"Amazon SQS 是否提供消息排序功能？",
        "intention":"知识问答",
        "reply":"是的。FIFO (先进先出) 队列可准确保持消息的发送和接收顺序。如果您使用 FIFO 队列，就无需在消息中加入排队信息。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的 [FIFO 队列逻辑](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-understanding-logic)。\n标准队列提供宽松的 FIFO 功能，会尽可能保持消息顺序。但是，由于标准队列使用高度分布式架构来实现大规模扩展，因此并不能确保接收消息时严格遵循消息发送的顺序。"
    },
    {
        "query":"Amazon SQS 是否能确保传送消息？",
        "intention":"知识问答",
        "reply":"标准队列提供至少一次传送，因此每条消息至少会传送一次。\nFIFO 队列提供[一次性处理](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing)，因此每条消息仅传送一次，并且在使用器处理并删除它之前始终可用。队列中不会引入重复消息。"
    },
    {
        "query":"Amazon SQS 与 Amazon Kinesis Streams 有何不同？",
        "intention":"知识问答",
        "reply":"Amazon SQS 提供高度可扩展的可靠托管队列，用于存储在应用程序或微服务之间传送的消息。它在分布式应用程序组件之间传送数据，可帮助您解耦这些组件。Amazon SQS 提供通用的中间件结构，例如死信队列和毒丸管理。它还提供通用型 Web 服务 API，并且可以通过 AWS SDK 所支持的任何编程语言访问。Amazon SQS 支持标准队列和 FIFO 队列。\nAmazon Kinesis Streams 允许实时处理流式大数据，还能够读取记录并重播至多个 Amazon Kinesis 应用程序。Amazon Kinesis 客户端库 (KCL) 能够将给定分区键的所有记录提供给同一记录处理器，从而可支持更加轻松地构建从同一 Amazon Kinesis 数据流读取数据的多个应用程序 (例如，执行计数、聚合和筛选)。\n有关更多信息，请参阅 [Amazon Kinesis 文档](https://aws.amazon.com/documentation/kinesis/)。"
    },
    {
        "query":"Amazon 在自己的应用程序中是否使用 Amazon SQS？",
        "intention":"知识问答",
        "reply":"能。Amazon 的开发人员将 Amazon SQS 用于每天处理大量消息的各种应用程序。Amazon.com 和 AWS 中的关键业务流程均使用 Amazon SQS。"
    },
    {
        "query":"Amazon SQS 免费套餐可以用来做些什么？",
        "intention":"知识问答",
        "reply":"Amazon SQS 免费套餐每月免费提供 100 万个请求。\n许多小规模应用程序都能在免费套餐的限制范围内完整地运行。但您可能仍然需要支付数据传输费用。有关更多信息，请参阅 [Amazon SQS 定价](https://aws.amazon.com/cn/sqs/pricing/)。\n免费套餐是每月优惠，免费使用量不能跨月累计。"
    },
    {
        "query":"如何跟踪和管理与 Amazon SQS 队列相关的成本？",
        "intention":"知识问答",
        "reply":"您可以使用成本分配标签来标记和跟踪您的队列，以进行资源和成本管理。标签是由键值对组成的元数据标签。例如，您可以按成本中心标记您的队列，然后根据这些成本中心对成本进行分类和跟踪。\n有关更多信息，请参阅 [Amazon SQS 开发人员指南中的“标记 Amazon SQS 队列”](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-tags.html)。有关 AWS 资源成本分配标记的更多信息，请参阅 AWS 账单和成本管理用户指南中的[使用成本分配标签](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)。"
    },
    {
        "query":"是否可以将 Amazon SQS 与其他 AWS 服务结合使用？",
        "intention":"知识问答",
        "reply":"是。您可以将 Amazon SQS 与 Amazon EC2、Amazon Elastic Container Service (ECS) 和 AWS Lambda 等计算服务以及 Amazon Simple Storage Service (Amazon S3) 和 Amazon DynamoDB 等存储和数据库服务结合使用，从而让应用程序具有更高的灵活性和可扩展性。"
    },
    {
        "query":"如何与 Amazon SQS 交互？",
        "intention":"知识问答",
        "reply":"您可以使用 [AWS 管理控制台](https://aws.amazon.com/cn/console/)来访问 Amazon SQS，该控制台可帮助您轻松地创建 Amazon SQS 队列和发送消息。\nAmazon SQS 还提供 Web 服务 API。此外，它还与 [AWS 开发工具包](https://aws.amazon.com/cn/tools/)集成，这使您能够根据需要选择编程语言。"
    },
    {
        "query":"Amazon SQS 提供哪些 API 操作？",
        "intention":"知识问答",
        "reply":"有关消息队列操作的消息，请参阅 [Amazon SQS API 参考](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html)。"
    },
    {
        "query":"谁可以对消息队列执行操作？",
        "intention":"知识问答",
        "reply":"只有 AWS 账户拥有者（或账户拥有者指派的 AWS 账户）可以在 Amazon SQS 消息队列上执行操作。"
    },
    {
        "query":"是否可以将 Java Message Service (JMS) 与 Amazon SQS 结合使用？",
        "intention":"知识问答",
        "reply":"是。您可以享受 Amazon SQS 的规模、低成本和高可用性，而不必担心运行自己的 JMS 集群的开销。\nAmazon 提供的 [Amazon SQS Java Messaging Library](https://github.com/awslabs/amazon-sqs-java-messaging-lib) 采用 JMS 1.1 规范，并将 Amazon SQS 用作 JMS 提供者。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[结合使用 JMS 与 Amazon SQS](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/jmsclient.html)。"
    },
    {
        "query":"Amazon SQS 如何标识消息？",
        "intention":"知识问答",
        "reply":"所有消息都带有一个全局唯一的 ID，Amazon SQS 会在消息传送到消息队列时返回该 ID。对消息执行任何进一步操作均不需要使用该 ID，但它可用于跟踪是否收到消息队列中的某一特定消息。\n当您从消息队列接收消息时，回复中包含一个接收句柄，删除消息时必须提供该句柄。\n有关更多信息，请参阅《Amazon SQS 开发人员指南》中的[队列和消息标识符](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-message-identifiers.html)。"
    },
    {
        "query":"Amazon SQS 如何处理无法处理的消息？",
        "intention":"知识问答",
        "reply":"在 Amazon SQS 中，您可以使用 API 或控制台来配置死信队列，用于从其他源队列接收消息。在配置死信队列时，您需要使用 RedriveAllowPolicy 为死信队列再驱动设置适当的权限。\nRedriveAllowPolicy 包括死信队列再驱动权限的参数。它定义了哪些源队列可以将死信队列指定为 JSON 对象。\n您设置死信队列后，则当消息经过最大处理次数且未能完成时，该队列就会接收该消息。您可以使用死信队列隔离无法处理的消息，以备将来分析。\n有关更多信息，请参阅 Amazon SQS 开发人员指南中的[使用 Amazon SQS 死信队列](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html)。"
    },
    {
        "query":"什么是可见性超时？",
        "intention":"知识问答",
        "reply":"可见性超时是一个时段，在这个时段内，Amazon SQS 会阻止其他正在使用的组件接收和处理某条消息。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[可见性超时](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/AboutVT.html)。"
    },
    {
        "query":"Amazon SQS 是否支持消息元数据？",
        "intention":"知识问答",
        "reply":"是的。一条 Amazon SQS 消息最多包含 10 项元数据属性。您可以使用消息属性将消息正文与描述该消息的元数据分离开来。这有助于系统更加快速、高效地处理和存储信息，因为您的应用程序不需要检查整条消息即可了解如何处理。\nAmazon SQS 消息属性采用“名称-类型-值”这种由三项元素构成的格式。支持的类型包括字符串、二进制和数字（包括整数、浮点数和双数）。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[使用 Amazon SQS 消息属性](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSMessageAttributes.html)。"
    },
    {
        "query":"如何确定排队时间值？",
        "intention":"知识问答",
        "reply":"要确定排队时间值，您可以在接收消息时请求提供 SentTimestamp 属性。将当前时间减去该值即可得出排队时间值。"
    },
    {
        "query":"Amazon SQS 的典型延迟是多少？",
        "intention":"知识问答",
        "reply":"SendMessage、ReceiveMessage 和 DeleteMessage API 请求的典型延迟是几十毫秒或一百到两百毫秒。"
    },
    {
        "query":"在匿名访问时，消息的 SenderId 属性值是什么？",
        "intention":"知识问答",
        "reply":"在 AWS 账户 ID 不可用（例如匿名用户发送消息）时，Amazon SQS 将提供 IP 地址。"
    },
    {
        "query":"什么是 Amazon SQS 长轮询？",
        "intention":"知识问答",
        "reply":"Amazon SQS 长轮询是从 Amazon SQS 队列中检索消息的一种方式。常规的短轮询会立即返回响应，即使轮询的消息队列为空；而长轮询只有在消息进入消息队列或长轮询超时时才返回响应。\n如果要从 Amazon SQS 队列中检索暂时不可用的消息，那么长轮询是一种成本较低的方式。因为您可以减少接收空消息的次数，所以使用长轮询可以降低 SQS 的使用成本。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的 [Amazon SQS 长轮询](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-long-polling.html)。"
    },
    {
        "query":"什么时候应该使用 Amazon SQS 长轮询？什么时候应该使用 Amazon SQS 短轮询？",
        "intention":"知识问答",
        "reply":"几乎在所有情况下，使用 Amazon SQS 长轮询都比使用短轮询更好。长轮询请求可以让使用队列的应用程序在消息进入队列后接收消息，同时减少返回的空 ReceiveMessageResponse 实例的数量。\nAmazon SQS 长轮询在大多数使用案例中的效果都更好，成本也更低。但是，如果您的应用程序希望从 ReceiveMessage 调用中获得即时响应，则可能需要对应用程序进行一些修改才能利用长轮询的优势。\n例如，如果您的应用程序使用单个线程来轮询多个队列，那么短轮询可能无法切换为长轮询，因为单个线程会等待所有空队列的长轮询超时，从而导致延迟处理可能包含消息的任何队列。\n在这种应用程序中，建议使用单个线程来处理一个队列，从而使应用程序能够利用 Amazon SQS 长轮询的优势。"
    },
    {
        "query":"长轮询超时应使用什么值？",
        "intention":"知识问答",
        "reply":"通常，长轮询超时最多为 20 秒。较高的长轮询超时值会减少返回的空 ReceiveMessageResponse 实例的数量，因此，请将长轮询超时值设置为尽可能高的值。\n如果 20 秒的最大值不适用于您的应用程序（请参阅上一问题中的示例），则您可以设置较短的长轮询超时，最短为 1 秒。\n默认情况下，所有 AWS 开发工具包都支持 20 秒的长轮询。如果您未使用 AWS 开发工具包访问 Amazon SQS，或者您将 AWS 开发工具包特别配置为使用较短的超时，则您可能需要修改您的 Amazon SQS 客户端，才能允许时间更长的请求或者使用较短的长轮询超时。"
    },
    {
        "query":"什么是适用于 Java 的 AmazonSQSBufferedAsyncClient？",
        "intention":"知识问答",
        "reply":"适用于 Java 的 AmazonSQSBufferedAsyncClient 可以让用户使用 AmazonSQSAsyncClient 接口，并添加了几项重要功能：\n自动批处理和预取功能结合到一起以后，可以提高吞吐量并降低应用程序延迟，并且提交的 Amazon SQS 请求更少，从而节省成本。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[客户端缓冲和请求批处理](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/buffering.html)。"
    },
    {
        "query":"从哪里下载适用于 Java 的 AmazonSQSBufferedAsyncClient？",
        "intention":"知识问答",
        "reply":"您可以下载[适用于 Java 的 AWS 开发工具包](https://aws.amazon.com/cn/sdkforjava/)，其中就包含适用于 Java 的 AmazonSQSBufferedAsyncClient。"
    },
    {
        "query":"是否需要重新编写应用程序才能使用适用于 Java 的 AmazonSQSBufferedAsyncClient？",
        "intention":"知识问答",
        "reply":"不需要。适用于 Java 的 AmazonSQSBufferedAsyncClient 用于替换现有的 AmazonSQSAsyncClient。\n您可以通过更新应用程序来使用最新 AWS 开发工具包，并通过更改客户端来用适用于 Java 的 AmazonSQSBufferedAsyncClient 替换 AmazonSQSAsyncClient，这样，您的应用程序就能获得自动批处理和预取功能所带来的新优势。"
    },
    {
        "query":"如何订阅 Amazon SQS 消息队列，以便接收来自 Amazon SNS 主题的通知？",
        "intention":"知识问答",
        "reply":"有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[为队列订阅 Amazon SNS 主题](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqssubscribe.html)。"
    },
    {
        "query":"能否删除消息队列中的所有消息而保留消息队列？",
        "intention":"知识问答",
        "reply":"能。您可以使用 PurgeQueue 操作删除 Amazon SQS 消息队列中的所有消息。\n当您清除消息队列时，之前发送到该消息队列的所有消息都将被删除。因为您的消息队列及其属性将会保留，所以不需要重新配置消息队列；您可以继续使用。\n要仅删除特定的消息，请使用 DeleteMessage 或 DeleteMessageBatch 操作。\n有关更多信息，请参阅此教程：[从 Amazon SQS 队列清除消息](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-using-purge-queue.html)。"
    },
    {
        "query":"在 Amazon SQS 中存储数据的可靠性如何？",
        "intention":"知识问答",
        "reply":"Amazon SQS 将所有消息队列和消息都存储在具有多个冗余可用区 (AZ) 并且高度可用的单个 AWS 区域中，因此，一台计算机、一个网络或一个可用区的故障不会导致消息无法访问。有关更多信息，请参阅 *Amazon Relational Database Service 用户指南*中的[区域和可用区](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html)。"
    },
    {
        "query":"如何保护消息队列中的消息？",
        "intention":"知识问答",
        "reply":"身份验证机制可以确保存储在 Amazon SQS 消息队列中的消息不会受到未经授权的访问。您可以控制谁能向消息队列发送消息以及谁能从消息队列接收消息。如需提高安全性，您可以构建应用程序将消息加密，然后再将其放入消息队列。\nAmazon SQS 带有基于资源的权限系统，所用策略的编写语言与 [AWS Identity and Access Management (IAM)](https://aws.amazon.com/cn/iam/) 策略的编写语言相同。举例来说，您可以像在 IAM 策略中一样使用变量。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的 [Amazon SQS 策略示例](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSExamples.html)。\nAmazon SQS 支持 HTTP over SSL (HTTPS) 协议以及传输层安全性 (TLS) 协议。大多数客户端可自动协商使用新版本 TLS 协议，无需更改任何代码或配置。Amazon SQS 在所有区域中都支持 1.0、1.1 和 1.2 版传输层安全性 (TLS) 协议。"
    },
    {
        "query":"为什么会有单独的 ReceiveMessage 和 DeleteMessage 操作？",
        "intention":"知识问答",
        "reply":"当 Amazon SQS 返回消息给您时，无论您实际上是否收到消息，该消息都会保存在消息队列中。您负责删除消息，而且发送删除请求即表明您已处理了该消息。\n如果您不删除消息，则 Amazon SQS 会在收到另一个接收请求时再次传送该消息。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[可见性超时](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/AboutVT.html)。"
    },
    {
        "query":"删除的消息能否被再次接收？",
        "intention":"知识问答",
        "reply":"不能。FIFO 队列绝不会引入重复消息。\n对于标准队列，在极少的情况下，您可能会再次收到之前删除的消息。"
    },
    {
        "query":"如果对之前删除的消息发出 DeleteMessage 请求，结果会怎样？",
        "intention":"知识问答",
        "reply":"如果对之前删除的消息发出 DeleteMessage 请求，Amazon SQS 会返回一个响应，表明删除*成功*。"
    },
    {
        "query":"Amazon SQS 的 SSE 有哪些优势？",
        "intention":"知识问答",
        "reply":"借助 SSE，您可以采用加密队列的方式传输敏感数据。SSE 会使用 [AWS Key Management Service (AWS KMS)](https://aws.amazon.com/cn/kms/) 托管的密钥保护 Amazon SQS 队列中的消息内容。只要 Amazon SQS 收到消息，SSE 就会对其进行加密。这些消息以加密的形式进行存储，且仅当它们发送到授权的客户时，Amazon SQS 才会对其进行解密。\n有关更多信息，请参阅《Amazon SQS 开发人员指南》中的[使用服务器端加密 (SSE) 和 AWS KMS 保护数据](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html)。"
    },
    {
        "query":"我可以将 SNS、Cloud Watch Events 和 S3 Events 与加密的队列搭配使用吗？",
        "intention":"知识问答",
        "reply":"可以。为此，您需要启用 AWS 服务（例如 Amazon CloudWatch Events、Amazon S3 和 Amazon SNS）与具有 SSE 的队列之间的兼容性。有关详细说明，请参阅[《SQS 开发人员指南》中的“兼容性”部分](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#compatibility-with-aws-services)。"
    },
    {
        "query":"哪些区域提供支持 SSE 的队列？",
        "intention":"知识问答",
        "reply":"提供 Amazon SQS 的所有 AWS 区域均提供适用于 Amazon SQS 的服务器端加密 (SSE)。请参阅[此处](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解有关 Amazon SQS 的区域可用性的详细信息。"
    },
    {
        "query":"如何为新的或现有 Amazon SQS 队列启用 SSE？",
        "intention":"知识问答",
        "reply":"要为使用 Amazon SQS API 的新的或现有 Amazon SQS 队列启动 SSE，可通过设置 CreateQueue 或 SetQueueAttributes 操作的 KmsMasterKeyId 属性，来指定客户主密钥 (CMK) ID：AWS 托管的 CMK 或自定义 CMK 的别名、别名 ARN、密钥 ID 或密钥 ARN。\n有关详细说明，请参阅 *Amazon SQS 开发人员指南*中的[创建采用客户端加密的 Amazon SQS 队列](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-create-queue-sse.html)和[为现有 Amazon SQS 队列配置服务器端加密 (SSE)](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-sse-existing-queue.html)。"
    },
    {
        "query":"哪些类型的 Amazon SQS 队列可以使用 SSE？",
        "intention":"知识问答",
        "reply":"标准队列和 FIFO 队列均支持 SSE。"
    },
    {
        "query":"对 Amazon SQS 使用 SSE 时，需要什么权限？",
        "intention":"知识问答",
        "reply":"您必须先将 AWS KMS 密钥策略配置为允许加密队列以及允许加密和解密消息，然后才能够使用 SSE。\n要为队列启用 SSE，您可以使用由 AWS 托管且适用于 Amazon SQS 的客户主密钥 (CMK)，也可以使用自定义 CMK。有关更多信息，请参阅 *AWS KMS 开发人员指南* 中的[客户主密钥](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys)。\n要向加密的队列发送消息，生产者必须拥有 CMK 的 kms:GenerateDataKey 和 kms:Decrypt 权限。\n要从加密的队列接收消息，消费者必须拥有用于加密指定队列中的消息的任何 CMK 的 kms:Decrypt 权限。如果队列充当的是[死信队列](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html)，消费者还必须拥有用于加密源队列中的消息的任何 CMK 的 kms:Decrypt 权限。\n有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[我需要哪些权限才能使用 SSE？](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#sqs-what-permissions-for-sse)。"
    },
    {
        "query":"适用于 Amazon SQS 的 SSE 会加密哪些内容以及如何加密？",
        "intention":"知识问答",
        "reply":"SSE 会加密 Amazon SQS 队列中消息的主体。\nSSE 不会加密以下部分：\nAmazon SQS 根据由 AWS 托管且适用于 Amazon SQS 的客户主密钥 (CMK) 或自定义 CMK 生成[数据密钥](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys)，以便为可配置的时间段（从 1 分钟到 24 小时）提供[信封加密](http://docs.aws.amazon.com/kms/latest/developerguide/workflow.html#envelope_encryption)和消息解密。\n有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[适用于 Amazon SQS 的 SSE 会加密哪些内容？](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#sqs-encryption-what-does-sse-encrypt)。"
    },
    {
        "query":"适用于 Amazon SQS 的 SSE 采用什么算法来加密消息？",
        "intention":"知识问答",
        "reply":"SSE 使用 [AES-GCM 256 算法](http://docs.aws.amazon.com/kms/latest/developerguide/crypto-intro.html)。"
    },
    {
        "query":"SSE 是否会限制可使用 Amazon SQS 创建的每秒事务数 (TPS) 或队列数？",
        "intention":"知识问答",
        "reply":"SSE 不会限制 Amazon SQS 的吞吐量 (TPS)。您可以创建的 SSE 队列数受以下项限制：\n例如，让我们假设以下情况：\n在这种情况下，您可以按照如下方式计算使用 SSE 的 Amazon SQS 队列的理论最大值：\n300 秒 × 100 TPS/1 个 IAM 用户 = 30000 个队列"
    },
    {
        "query":"Amazon SQS 是否通过了 PCI DSS 认证？",
        "intention":"知识问答",
        "reply":"是的。Amazon SQS 通过了 PCI DSS 第 1 级认证。有关更多信息，请参阅 [PCI 合规性](https://aws.amazon.com/cn/compliance/pci-dss-level-1-faqs/)。"
    },
    {
        "query":"Amazon SQS 符合 HIPAA 要求吗？",
        "intention":"知识问答",
        "reply":"符合，AWS 对其 HIPAA 合规性计划进行了扩展，已将 Amazon SQS 作为一项符合 HIPAA 要求的服务纳入该计划。如果您已与 AWS 签订商业伙伴协议 (BAA)，那么您就可以使用 Amazon SQS 来构建 HIPAA 合规应用程序、存储传输中的消息以及传输消息，其中包括含受保护健康信息 (PHI) 的消息。\n如果您已与 AWS 签订商业伙伴协议，那么您就可以立即开始使用 Amazon SQS。如果您未签订商业伙伴协议或者在对您的 HIPAA 合规应用程序使用 AWS 的方面有其他问题，请联系我们，以获取详细信息。\n注意：如果不想通过 Amazon SQS 传输 PHI（或者，如果消息超过 256KB），那么可以使用适用于 Java 的 Amazon SQS 扩展客户端库改为[通过 Amazon S3 发送 Amazon SQS 消息负载](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html)（除使用 Amazon S3 Transfer Acceleration 外，Amazon S3 在其他方面也是一种符合 HIPAA 要求的服务）。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[使用适用于 Java 的 Amazon SQS 扩展客户端库](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html#s3-messages-examples)。"
    },
    {
        "query":"消息在 Amazon SQS 消息队列中可以保留多久？",
        "intention":"知识问答",
        "reply":"较长消息的保留期可以实现更大的灵活性，让消息产生和消息使用之间的间隔时间更长。\n您可以将 Amazon SQS 消息保留期配置为 1 分钟至 14 天之间的值。默认为 4 天。一旦达到消息保留期限，您的消息就会被自动删除。"
    },
    {
        "query":"如何配置 Amazon SQS 以支持更长的消息保留期？",
        "intention":"知识问答",
        "reply":"要配置消息保留期，请使用管理控制台或 Distributiveness 方法来设置 MessageRetentionPeriod 属性。该属性用于指定消息在 Amazon SQS 中保留的秒数。\n您可以使用 MessageRetentionPeriod 属性将消息保留期设置为 60 秒（1 分钟）到 1209600 秒（14 天）之间的值。有关使用此消息属性的更多信息，请参阅 *[Amazon SQS API 参考](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html)*。"
    },
    {
        "query":"如何配置 Amazon SQS 的最大消息大小？",
        "intention":"知识问答",
        "reply":"要配置最大消息大小，请使用控制台或 SetQueueAttributes 方法来设置 MaximumMessageSize 属性。 该属性用于指定 Amazon SQS 消息可以包含的字节数。可以将属性设为 1024 字节 (1KB) 到 262144 字节 (256KB) 之间的值。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的[使用 Amazon SQS 消息属性](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSMessageAttributes.html)。\n要发送大小超过 256KB 的消息，您可以使用[适用于 Java 的 Amazon SQS 扩展客户端库](https://github.com/awslabs/amazon-sqs-java-extended-client-lib)。借助该库，您可以发送引用了 Amazon S3 中的消息负载的 Amazon SQS 消息，最大可为 2GB。"
    },
    {
        "query":"消息中可以包含哪种类型的数据？",
        "intention":"知识问答",
        "reply":"Amazon SQS 消息可包含不超过 256 KB 的文本数据，包括 XML、JSON 和无格式文本。接受以下 Unicode 字符：\n#x9 | #xA | #xD | [#x20 to #xD7FF] | [#xE000 to #xFFFD] | [#x10000 to #x10FFFF]\n有关更多信息，请参阅 [XML 1.0 规范](http://www.w3.org/TR/REC-xml/#charsets)。"
    },
    {
        "query":"Amazon SQS 消息队列的大小可以是多大？",
        "intention":"知识问答",
        "reply":"单个 Amazon SQS 消息队列中的消息没有数量限制。但是，对于标准队列，处于飞行状态的消息数量限额是 120,000；对于 FIFO 队列，此限额为 20,000。消息的飞行状态是指该消息已由使用组件从队列接收，但尚未从队列中删除。"
    },
    {
        "query":"可以创建多少个消息队列？",
        "intention":"知识问答",
        "reply":"您可以创建任意数量的消息队列。"
    },
    {
        "query":"Amazon SQS 消息队列的名称大小是否有限制？",
        "intention":"知识问答",
        "reply":"队列名称限制为 80 个字符。"
    },
    {
        "query":"Amazon SQS 消息队列的名称是否有限制？",
        "intention":"知识问答",
        "reply":"您可以使用字母数字字符、连字符 (-) 和下划线 (\\_)。"
    },
    {
        "query":"消息队列名称是否可以重新使用？",
        "intention":"知识问答",
        "reply":"同一个 AWS 账户和区域内的消息队列名称必须是唯一的。您可以在删除一个消息队列后重新使用该消息队列的名称。"
    },
    {
        "query":"如何共享消息队列？",
        "intention":"知识问答",
        "reply":"您可以将访问策略语句（并指定要授予的权限）与要共享的消息队列关联。Amazon SQS 可以提供 API，用于创建和管理以下访问策略语句：\n有关详细信息，请参阅 *[Amazon SQS API 参考](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html)*。"
    },
    {
        "query":"如何标识我希望与之共享消息队列的另一个 AWS 用户？",
        "intention":"知识问答",
        "reply":"Amazon SQS API 使用 AWS 账号来标识 AWS 用户。"
    },
    {
        "query":"我需要向希望与之共享消息队列的 AWS 用户提供什么？",
        "intention":"知识问答",
        "reply":"要与 AWS 用户共享消息队列，您需要提供所要共享的消息队列的完整 URL。进行 CreateQueue 和 ListQueues 操作后，系统会返回 URL。"
    },
    {
        "query":"Amazon SQS 是否支持匿名访问？",
        "intention":"知识问答",
        "reply":"是的。您可以配置访问策略，允许匿名用户访问消息队列。"
    },
    {
        "query":"应该在什么时候使用权限 API？",
        "intention":"知识问答",
        "reply":"权限 API 可以向开发人员提供接口，用于共享消息队列的访问权限。但是，此类 API 不支持有条件访问或更高级的使用案例。"
    },
    {
        "query":"应该在什么时候将 SetQueueAttributes 操作用于 JSON 对象？",
        "intention":"知识问答",
        "reply":"SetQueueAttributes 操作支持全部的访问策略语言。例如，您可以使用策略语言将消息队列的访问权限限制到特定 IP 地址和特定时间。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的 [Amazon SQS 策略示例](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSExamples.html)。"
    },
    {
        "query":"Amazon SQS 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"有关提供服务的地区，请参阅 [AWS 全球基础设施区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"是否可以在不同区域中的队列之间共享消息？",
        "intention":"知识问答",
        "reply":"不可以。各个区域中的各个 Amazon SQS 消息队列都是独立的。"
    },
    {
        "query":"不同区域之间是否有定价差别？",
        "intention":"知识问答",
        "reply":"除中国 (北京) 外，所有区域的 Amazon SQS 定价均相同。有关更多信息，请参阅 [Amazon SQS 定价](https://aws.amazon.com/cn/sqs/pricing/)。"
    },
    {
        "query":"如果在不同区域之间传输，定价结构如何？",
        "intention":"知识问答",
        "reply":"您可以在同一个区域内的 Amazon SQS 与 Amazon EC2 或 AWS Lambda 之间免费传输数据。\n如果在不同区域内的 Amazon SQS 与 Amazon EC2 或 AWS Lambda 之间传输数据，则需要按正常数据传输费率付费。有关更多信息，请参阅 [Amazon SQS 定价](https://aws.amazon.com/cn/sqs/pricing/)。"
    },
    {
        "query":"死信队列是什么？",
        "intention":"知识问答",
        "reply":"死信队列是一种 Amazon SQS 队列，如果源队列的消费者应用程序无法成功消费消息，源队列将向该队列发送消息。死信队列让您更容易处理消息消费故障，管理未使用消息的生命周期。您可以为投递至死信队列的任何消息配置告警，检查可能导致其投递至队列的异常日志，分析消息内容以诊断消费者应用程序问题。消费者应用程序恢复后，您现在可以将消息从死信队列再驱动到源队列。"
    },
    {
        "query":"死信队列如何工作？",
        "intention":"知识问答",
        "reply":"创建源队列后，Amazon SQS 允许您指定死信队列 (DLQ) 以及 SQS 应将消息移动到 DLQ 的条件。条件指消费者可以从队列接收消息的次数，定义为 maxReceiveCount。具有源队列和 maxReceiveCount 的死信队列配置称为重新驱动策略。如果消息的 ReceiveCount 超过队列的 maxReceiveCount，Amazon SQS 将把消息移动到死信队列（具有其原始消息 ID）。例如，如果源队列的重新驱动策略的 maxReceiveCount 设为 5，源队列消费者收到消息 6 次而没有成功消费，则 SQS 将消息移动到死信队列。\n重新驱动策略将消息从源队列移动到死信队列，管理未消费消息的前半个生命周期。现在死信队列重新驱动到源队列高效完成周期，将这些消息移动回源队列，如下所示。"
    },
    {
        "query":"死信队列重新驱动到源队列如何工作？",
        "intention":"知识问答",
        "reply":"首先，显示消息属性和相关元数据，允许您调查死信队列中可用的消息样本。调查消息后，您可以将其移动回源队列。您还可以选择重新驱动速度，配置 Amazon SQS 将消息从死信队列移动到源队列的速度。"
    },
    {
        "query":"死信队列是否能与 FIFO 队列结合使用？",
        "intention":"知识问答",
        "reply":"是的。但必须将 FIFO 死信队列与 FIFO 队列结合使用。（同样，只能将标准死信队列与标准队列结合使用。）"
    },
    {
        "query":"哪些区域提供 FIFO 队列？",
        "intention":"知识问答",
        "reply":"FIFO 队列可在提供 Amazon SQS 的所有 AWS 区域中使用。请参阅[此处](https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services)，了解有关 Amazon SQS 的区域可用性的详细信息。"
    },
    {
        "query":"我会收到一条消息的多少个副本？",
        "intention":"知识问答",
        "reply":"FIFO 队列的设计宗旨是不引入重复消息。但是，在某些情况下，消息创建器可能会引入重复消息：例如，如果创建器发送一条消息，未收到响应，然后又重发了同一条消息。Amazon SQS API 提供重复数据删除功能，可防止消息创建器发送重复消息。由消息创建器引入的任何重复消息都会在 5 分钟重复数据删除时间间隔内被删除。\n对于标准队列，您可能偶尔会收到一条消息的重复副本 (至少一次传送)。如果您使用标准队列，则必须将应用程序设计为幂等应用程序 (也就是说，应用程序即使多次处理同一条消息也不会受到不利影响)。\n有关更多信息，请参阅《Amazon SQS 开发人员指南》中的[一次性处理](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-exactly-once-processing)。"
    },
    {
        "query":"我以前使用的 Amazon SQS 队列会不会转变为 FIFO 队列？",
        "intention":"知识问答",
        "reply":"Amazon SQS *标准*队列（现有队列的新名称）保持不变，您仍然可以创建标准队列。这些队列仍会继续提供最高的可扩展性和吞吐量，但不会再保证顺序不变，而且可能会出现重复消息。\n标准队列适合很多场景，例如在多个幂等使用器之间进行工作分配。"
    },
    {
        "query":"我是否能将现有的标准队列转换为 FIFO 队列？",
        "intention":"知识问答",
        "reply":"不能。您必须在创建队列时选择队列类型。但可以转移到 FIFO 队列。有关更多信息，请参阅*Amazon SQS 开发人员指南* 中的[从标准队列移至 FIFO 队列](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues-moving.html)。"
    },
    {
        "query":"Amazon SQS FIFO 队列是否向后兼容？",
        "intention":"知识问答",
        "reply":"要利用 FIFO 队列功能，您必须使用最新的 AWS SDK。\nFIFO 队列与标准队列使用相同的 API 操作，接收和删除消息以及更改可见性超时的机制也相同。但是，在发送消息时，您必须指定消息组 ID。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的 [FIFO 队列逻辑](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-understanding-logic)。"
    },
    {
        "query":"Amazon SQS FIFO 队列可与哪些 AWS 服务或外部服务兼容？",
        "intention":"知识问答",
        "reply":"向 Amazon SQS 发送通知的有些 AWS 服务或外部服务无法与 FIFO 队列兼容，除非允许您将 FIFO 队列设置为目标。\nAWS 服务的以下功能目前无法与 FIFO 队列兼容：\n有关其他服务与 FIFO 队列的兼容性信息，请参阅您的服务文档。"
    },
    {
        "query":"Amazon SQS FIFO 队列是否与 Amazon SQS Buffered Asynchronous Client、适用于 Java 的 Amazon SQS 扩展客户端库或 Amazon SQS Java Message Service (JMS) Client 兼容？",
        "intention":"知识问答",
        "reply":"FIFO 队列目前不与 Amazon SQS Buffered Asynchronous Client 兼容。\nFIFO 队列与 Amazon SQS Extended Client Library for Java 和 Amazon SQS Java Message Service (JMS) Client 兼容。"
    },
    {
        "query":"Amazon SQS FIFO 队列支持哪些 AWS CloudWatch 指标？",
        "intention":"知识问答",
        "reply":"FIFO 队列支持标准队列支持的所有指标。对于 FIFO 队列，所有近似指标都会返回准确的计数。例如，支持以下 AWS CloudWatch 指标："
    },
    {
        "query":"什么是消息组？",
        "intention":"知识问答",
        "reply":"在 FIFO 队列中，消息被组合成有序的不同“捆绑包”。对于每一个消息组 ID，所有消息的发送和接收均严格遵循一定的顺序。但是，具有不同的消息组 ID 值的消息可能不会按顺序发送和接收。您必须将消息组 ID 与消息关联。如果不提供消息组 ID，操作就会失败。\n如果多个主机 (或同一主机上的不同线程) 向 FIFO 队列中发送了具有相同消息组 ID 的消息，则 Amazon SQS 按照它们到达的顺序来传送消息。为确保 Amazon SQS 在发送和接收消息时保持相同顺序，请确保多个发送者发送每一条消息时均具有唯一的消息组 ID。\n有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的 [FIFO 队列逻辑](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html#FIFO-queues-understanding-logic)。"
    },
    {
        "query":"Amazon SQS FIFO 队列是否支持多个创建器？",
        "intention":"知识问答",
        "reply":"能。一个或多个创建器可以向一个 FIFO 队列发送消息。消息按 Amazon SQS 成功接收到它们时的顺序存储。\n如果多个创建器并行发送消息，而不等待来自 SendMessage 或 SendMessageBatch 操作的成功响应，则创建器之间的顺序可能不会保留。SendMessage 或 SendMessageBatch 操作的响应包含 FIFO 队列用于将消息放到队列中的最终顺序，因此您的并行多创建器代码可以确定消息在队列中的最终顺序。"
    },
    {
        "query":"Amazon SQS FIFO 队列是否支持多个使用器？",
        "intention":"知识问答",
        "reply":"根据设计，Amazon SQS FIFO 队列不能一次将同一消息组中的消息提供给多个使用者。但是，如果您的 FIFO 队列具有多个消息组，则您可以利用并行使用器，以便 Amazon SQS 将不同消息组中的消息提供给不同的使用器。"
    },
    {
        "query":"Amazon SQS FIFO 队列的吞吐量限额是多少？",
        "intention":"知识问答",
        "reply":"默认情况下，如果使用批处理，FIFO 队列每秒最多可以支持 3000 条消息；如果不使用批处理，则每秒最多可以支持 300 条消息（每秒执行 300 个发送、接收或删除操作）。如果您需要更高的吞吐量，可以在 Amazon SQS 控制台上为 FIFO 启用高吞吐量模式。如果使用批处理，该模式每秒最多可以支持 30,000 条消息；如果不使用批处理，则每秒最多可以支持 3,000 条消息。"
    },
    {
        "query":"是否有任何特定于 FIFO 队列属性的限制？",
        "intention":"知识问答",
        "reply":"FIFO 队列的名称必须以 .fifo 后缀结尾。后缀将计入 80 个字符的队列名称限制。要确定队列是否为 FIFO 队列，您可以查看队列名称是否以该后缀结尾。"
    },
    {
        "query":"在 Amazon SQS 中存储数据的可靠性如何？",
        "intention":"知识问答",
        "reply":"Amazon SQS 将所有消息队列和消息都存储在具有多个冗余可用区 (AZ) 并且高度可用的单个 AWS 区域中，因此，一台计算机、一个网络或一个可用区的故障不会导致消息无法访问。有关更多信息，请参阅 *Amazon Relational Database Service 用户指南*中的[区域和可用区](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RegionsAndAvailabilityZones.html)。"
    },
    {
        "query":"如何保护消息队列中的消息？",
        "intention":"知识问答",
        "reply":"身份验证机制可以确保存储在 Amazon SQS 消息队列中的消息不会受到未经授权的访问。您可以控制谁能向消息队列发送消息以及谁能从消息队列接收消息。如需提高安全性，您可以构建应用程序将消息加密，然后再将其放入消息队列。\nAmazon SQS 带有基于资源的权限系统，所用策略的编写语言与 [AWS Identity and Access Management (IAM)](https://aws.amazon.com/cn/iam/) 策略的编写语言相同。举例来说，您可以像在 IAM 策略中一样使用变量。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的 [Amazon SQS 策略示例](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSExamples.html)。\nAmazon SQS 支持 HTTP over SSL (HTTPS) 协议以及传输层安全性 (TLS) 协议。大多数客户端可自动协商使用新版本 TLS 协议，无需更改任何代码或配置。Amazon SQS 在所有区域中都支持 1.0、1.1 和 1.2 版传输层安全性 (TLS) 协议。"
    },
    {
        "query":"为什么会有单独的 ReceiveMessage 和 DeleteMessage 操作？",
        "intention":"知识问答",
        "reply":"当 Amazon SQS 返回消息给您时，无论您实际上是否收到消息，该消息都会保存在消息队列中。您负责删除消息，而且发送删除请求即表明您已处理了该消息。\n如果您不删除消息，则 Amazon SQS 会在收到另一个接收请求时再次传送该消息。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[可见性超时](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/AboutVT.html)。"
    },
    {
        "query":"删除的消息能否被再次接收？",
        "intention":"知识问答",
        "reply":"不能。FIFO 队列绝不会引入重复消息。\n对于标准队列，在极少的情况下，您可能会再次收到之前删除的消息。"
    },
    {
        "query":"如果对之前删除的消息发出 DeleteMessage 请求，结果会怎样？",
        "intention":"知识问答",
        "reply":"如果对之前删除的消息发出 DeleteMessage 请求，Amazon SQS 会返回一个响应，表明删除*成功*。"
    },
    {
        "query":"Amazon SQS 的 SSE 有哪些优势？",
        "intention":"知识问答",
        "reply":"借助 SSE，您可以采用加密队列的方式传输敏感数据。SSE 会使用 [AWS Key Management Service (AWS KMS)](https://aws.amazon.com/cn/kms/) 托管的密钥保护 Amazon SQS 队列中的消息内容。只要 Amazon SQS 收到消息，SSE 就会对其进行加密。这些消息以加密的形式进行存储，且仅当它们发送到授权的客户时，Amazon SQS 才会对其进行解密。\n有关更多信息，请参阅《Amazon SQS 开发人员指南》中的[使用服务器端加密 (SSE) 和 AWS KMS 保护数据](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html)。"
    },
    {
        "query":"我可以将 SNS、Cloud Watch Events 和 S3 Events 与加密的队列搭配使用吗？",
        "intention":"知识问答",
        "reply":"可以。为此，您需要启用 AWS 服务（例如 Amazon CloudWatch Events、Amazon S3 和 Amazon SNS）与具有 SSE 的队列之间的兼容性。有关详细说明，请参阅[《SQS 开发人员指南》中的“兼容性”部分](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#compatibility-with-aws-services)。"
    },
    {
        "query":"哪些区域提供支持 SSE 的队列？",
        "intention":"知识问答",
        "reply":"提供 Amazon SQS 的所有 AWS 区域均提供适用于 Amazon SQS 的服务器端加密 (SSE)。请参阅[此处](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)，了解有关 Amazon SQS 的区域可用性的详细信息。"
    },
    {
        "query":"如何为新的或现有 Amazon SQS 队列启用 SSE？",
        "intention":"知识问答",
        "reply":"要为使用 Amazon SQS API 的新的或现有 Amazon SQS 队列启动 SSE，可通过设置 CreateQueue 或 SetQueueAttributes 操作的 KmsMasterKeyId 属性，来指定客户主密钥 (CMK) ID：AWS 托管的 CMK 或自定义 CMK 的别名、别名 ARN、密钥 ID 或密钥 ARN。\n有关详细说明，请参阅 *Amazon SQS 开发人员指南*中的[创建采用客户端加密的 Amazon SQS 队列](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-create-queue-sse.html)和[为现有 Amazon SQS 队列配置服务器端加密 (SSE)](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-configure-sse-existing-queue.html)。"
    },
    {
        "query":"哪些类型的 Amazon SQS 队列可以使用 SSE？",
        "intention":"知识问答",
        "reply":"标准队列和 FIFO 队列均支持 SSE。"
    },
    {
        "query":"对 Amazon SQS 使用 SSE 时，需要什么权限？",
        "intention":"知识问答",
        "reply":"您必须先将 AWS KMS 密钥策略配置为允许加密队列以及允许加密和解密消息，然后才能够使用 SSE。\n要为队列启用 SSE，您可以使用由 AWS 托管且适用于 Amazon SQS 的客户主密钥 (CMK)，也可以使用自定义 CMK。有关更多信息，请参阅 *AWS KMS 开发人员指南* 中的[客户主密钥](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys)。\n要向加密的队列发送消息，生产者必须拥有 CMK 的 kms:GenerateDataKey 和 kms:Decrypt 权限。\n要从加密的队列接收消息，消费者必须拥有用于加密指定队列中的消息的任何 CMK 的 kms:Decrypt 权限。如果队列充当的是[死信队列](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-dead-letter-queues.html)，消费者还必须拥有用于加密源队列中的消息的任何 CMK 的 kms:Decrypt 权限。\n有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[我需要哪些权限才能使用 SSE？](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#sqs-what-permissions-for-sse)。"
    },
    {
        "query":"适用于 Amazon SQS 的 SSE 会加密哪些内容以及如何加密？",
        "intention":"知识问答",
        "reply":"SSE 会加密 Amazon SQS 队列中消息的主体。\nSSE 不会加密以下部分：\nAmazon SQS 根据由 AWS 托管且适用于 Amazon SQS 的客户主密钥 (CMK) 或自定义 CMK 生成[数据密钥](http://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#data-keys)，以便为可配置的时间段（从 1 分钟到 24 小时）提供[信封加密](http://docs.aws.amazon.com/kms/latest/developerguide/workflow.html#envelope_encryption)和消息解密。\n有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[适用于 Amazon SQS 的 SSE 会加密哪些内容？](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-server-side-encryption.html#sqs-encryption-what-does-sse-encrypt)。"
    },
    {
        "query":"适用于 Amazon SQS 的 SSE 采用什么算法来加密消息？",
        "intention":"知识问答",
        "reply":"SSE 使用 [AES-GCM 256 算法](http://docs.aws.amazon.com/kms/latest/developerguide/crypto-intro.html)。"
    },
    {
        "query":"SSE 是否会限制可使用 Amazon SQS 创建的每秒事务数 (TPS) 或队列数？",
        "intention":"知识问答",
        "reply":"SSE 不会限制 Amazon SQS 的吞吐量 (TPS)。您可以创建的 SSE 队列数受以下项限制：\n例如，让我们假设以下情况：\n在这种情况下，您可以按照如下方式计算使用 SSE 的 Amazon SQS 队列的理论最大值：\n300 秒 × 100 TPS/1 个 IAM 用户 = 30000 个队列"
    },
    {
        "query":"Amazon SQS 是否通过了 PCI DSS 认证？",
        "intention":"知识问答",
        "reply":"是的。Amazon SQS 通过了 PCI DSS 第 1 级认证。有关更多信息，请参阅 [PCI 合规性](https://aws.amazon.com/cn/compliance/pci-dss-level-1-faqs/)。"
    },
    {
        "query":"Amazon SQS 符合 HIPAA 要求吗？",
        "intention":"知识问答",
        "reply":"符合，AWS 对其 HIPAA 合规性计划进行了扩展，已将 Amazon SQS 作为一项符合 HIPAA 要求的服务纳入该计划。如果您已与 AWS 签订商业伙伴协议 (BAA)，那么您就可以使用 Amazon SQS 来构建 HIPAA 合规应用程序、存储传输中的消息以及传输消息，其中包括含受保护健康信息 (PHI) 的消息。\n如果您已与 AWS 签订商业伙伴协议，那么您就可以立即开始使用 Amazon SQS。如果您未签订商业伙伴协议或者在对您的 HIPAA 合规应用程序使用 AWS 的方面有其他问题，请联系我们，以获取详细信息。\n注意：如果不想通过 Amazon SQS 传输 PHI（或者，如果消息超过 256KB），那么可以使用适用于 Java 的 Amazon SQS 扩展客户端库改为[通过 Amazon S3 发送 Amazon SQS 消息负载](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html)（除使用 Amazon S3 Transfer Acceleration 外，Amazon S3 在其他方面也是一种符合 HIPAA 要求的服务）。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的[使用适用于 Java 的 Amazon SQS 扩展客户端库](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-s3-messages.html#s3-messages-examples)。"
    },
    {
        "query":"消息在 Amazon SQS 消息队列中可以保留多久？",
        "intention":"知识问答",
        "reply":"较长消息的保留期可以实现更大的灵活性，让消息产生和消息使用之间的间隔时间更长。\n您可以将 Amazon SQS 消息保留期配置为 1 分钟至 14 天之间的值。默认为 4 天。一旦达到消息保留期限，您的消息就会被自动删除。"
    },
    {
        "query":"如何配置 Amazon SQS 以支持更长的消息保留期？",
        "intention":"知识问答",
        "reply":"要配置消息保留期，请使用管理控制台或 Distributiveness 方法来设置 MessageRetentionPeriod 属性。该属性用于指定消息在 Amazon SQS 中保留的秒数。\n您可以使用 MessageRetentionPeriod 属性将消息保留期设置为 60 秒（1 分钟）到 1209600 秒（14 天）之间的值。有关使用此消息属性的更多信息，请参阅 *[Amazon SQS API 参考](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html)*。"
    },
    {
        "query":"如何配置 Amazon SQS 的最大消息大小？",
        "intention":"知识问答",
        "reply":"要配置最大消息大小，请使用控制台或 SetQueueAttributes 方法来设置 MaximumMessageSize 属性。 该属性用于指定 Amazon SQS 消息可以包含的字节数。可以将属性设为 1024 字节 (1KB) 到 262144 字节 (256KB) 之间的值。有关更多信息，请参阅 *Amazon SQS 开发人员指南* 中的[使用 Amazon SQS 消息属性](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSMessageAttributes.html)。\n要发送大小超过 256KB 的消息，您可以使用[适用于 Java 的 Amazon SQS 扩展客户端库](https://github.com/awslabs/amazon-sqs-java-extended-client-lib)。借助该库，您可以发送引用了 Amazon S3 中的消息负载的 Amazon SQS 消息，最大可为 2GB。"
    },
    {
        "query":"消息中可以包含哪种类型的数据？",
        "intention":"知识问答",
        "reply":"Amazon SQS 消息可包含不超过 256 KB 的文本数据，包括 XML、JSON 和无格式文本。接受以下 Unicode 字符：\n#x9 | #xA | #xD | [#x20 to #xD7FF] | [#xE000 to #xFFFD] | [#x10000 to #x10FFFF]\n有关更多信息，请参阅 [XML 1.0 规范](http://www.w3.org/TR/REC-xml/#charsets)。"
    },
    {
        "query":"Amazon SQS 消息队列的大小可以是多大？",
        "intention":"知识问答",
        "reply":"单个 Amazon SQS 消息队列中的消息没有数量限制。但是，对于标准队列，处于飞行状态的消息数量限额是 120,000；对于 FIFO 队列，此限额为 20,000。消息的飞行状态是指该消息已由使用组件从队列接收，但尚未从队列中删除。"
    },
    {
        "query":"可以创建多少个消息队列？",
        "intention":"知识问答",
        "reply":"您可以创建任意数量的消息队列。"
    },
    {
        "query":"Amazon SQS 消息队列的名称大小是否有限制？",
        "intention":"知识问答",
        "reply":"队列名称限制为 80 个字符。"
    },
    {
        "query":"Amazon SQS 消息队列的名称是否有限制？",
        "intention":"知识问答",
        "reply":"您可以使用字母数字字符、连字符 (-) 和下划线 (\\_)。"
    },
    {
        "query":"消息队列名称是否可以重新使用？",
        "intention":"知识问答",
        "reply":"同一个 AWS 账户和区域内的消息队列名称必须是唯一的。您可以在删除一个消息队列后重新使用该消息队列的名称。"
    },
    {
        "query":"如何共享消息队列？",
        "intention":"知识问答",
        "reply":"您可以将访问策略语句（并指定要授予的权限）与要共享的消息队列关联。Amazon SQS 可以提供 API，用于创建和管理以下访问策略语句：\n有关详细信息，请参阅 *[Amazon SQS API 参考](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/Welcome.html)*。"
    },
    {
        "query":"如何标识我希望与之共享消息队列的另一个 AWS 用户？",
        "intention":"知识问答",
        "reply":"Amazon SQS API 使用 AWS 账号来标识 AWS 用户。"
    },
    {
        "query":"我需要向希望与之共享消息队列的 AWS 用户提供什么？",
        "intention":"知识问答",
        "reply":"要与 AWS 用户共享消息队列，您需要提供所要共享的消息队列的完整 URL。进行 CreateQueue 和 ListQueues 操作后，系统会返回 URL。"
    },
    {
        "query":"Amazon SQS 是否支持匿名访问？",
        "intention":"知识问答",
        "reply":"是的。您可以配置访问策略，允许匿名用户访问消息队列。"
    },
    {
        "query":"应该在什么时候使用权限 API？",
        "intention":"知识问答",
        "reply":"权限 API 可以向开发人员提供接口，用于共享消息队列的访问权限。但是，此类 API 不支持有条件访问或更高级的使用案例。"
    },
    {
        "query":"应该在什么时候将 SetQueueAttributes 操作用于 JSON 对象？",
        "intention":"知识问答",
        "reply":"SetQueueAttributes 操作支持全部的访问策略语言。例如，您可以使用策略语言将消息队列的访问权限限制到特定 IP 地址和特定时间。有关更多信息，请参阅 *Amazon SQS 开发人员指南*中的 [Amazon SQS 策略示例](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/SQSExamples.html)。"
    },
    {
        "query":"Amazon SQS 在哪些区域提供？",
        "intention":"知识问答",
        "reply":"有关提供服务的地区，请参阅 [AWS 全球基础设施区域表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)。"
    },
    {
        "query":"是否可以在不同区域中的队列之间共享消息？",
        "intention":"知识问答",
        "reply":"不可以。各个区域中的各个 Amazon SQS 消息队列都是独立的。"
    },
    {
        "query":"不同区域之间是否有定价差别？",
        "intention":"知识问答",
        "reply":"除中国 (北京) 外，所有区域的 Amazon SQS 定价均相同。有关更多信息，请参阅 [Amazon SQS 定价](https://aws.amazon.com/cn/sqs/pricing/)。"
    },
    {
        "query":"如果在不同区域之间传输，定价结构如何？",
        "intention":"知识问答",
        "reply":"您可以在同一个区域内的 Amazon SQS 与 Amazon EC2 或 AWS Lambda 之间免费传输数据。\n如果在不同区域内的 Amazon SQS 与 Amazon EC2 或 AWS Lambda 之间传输数据，则需要按正常数据传输费率付费。有关更多信息，请参阅 [Amazon SQS 定价](https://aws.amazon.com/cn/sqs/pricing/)。"
    },
    {
        "query":"死信队列是什么？",
        "intention":"知识问答",
        "reply":"死信队列是一种 Amazon SQS 队列，如果源队列的消费者应用程序无法成功消费消息，源队列将向该队列发送消息。死信队列让您更容易处理消息消费故障，管理未使用消息的生命周期。您可以为投递至死信队列的任何消息配置告警，检查可能导致其投递至队列的异常日志，分析消息内容以诊断消费者应用程序问题。消费者应用程序恢复后，您现在可以将消息从死信队列再驱动到源队列。"
    },
    {
        "query":"死信队列如何工作？",
        "intention":"知识问答",
        "reply":"创建源队列后，Amazon SQS 允许您指定死信队列 (DLQ) 以及 SQS 应将消息移动到 DLQ 的条件。条件指消费者可以从队列接收消息的次数，定义为 maxReceiveCount。具有源队列和 maxReceiveCount 的死信队列配置称为重新驱动策略。如果消息的 ReceiveCount 超过队列的 maxReceiveCount，Amazon SQS 将把消息移动到死信队列（具有其原始消息 ID）。例如，如果源队列的重新驱动策略的 maxReceiveCount 设为 5，源队列消费者收到消息 6 次而没有成功消费，则 SQS 将消息移动到死信队列。\n重新驱动策略将消息从源队列移动到死信队列，管理未消费消息的前半个生命周期。现在死信队列重新驱动到源队列高效完成周期，将这些消息移动回源队列，如下所示。"
    },
    {
        "query":"死信队列重新驱动到源队列如何工作？",
        "intention":"知识问答",
        "reply":"首先，显示消息属性和相关元数据，允许您调查死信队列中可用的消息样本。调查消息后，您可以将其移动回源队列。您还可以选择重新驱动速度，配置 Amazon SQS 将消息从死信队列移动到源队列的速度。"
    },
    {
        "query":"死信队列是否能与 FIFO 队列结合使用？",
        "intention":"知识问答",
        "reply":"是的。但必须将 FIFO 死信队列与 FIFO 队列结合使用。（同样，只能将标准死信队列与标准队列结合使用。）\n详细了解 Amazon SQS 定价"
    },
    {
        "query":"What is AWS Panorama?",
        "intention":"知识问答",
        "reply":"AWS Panorama is a new machine learning (ML) appliance and software development kit (SDK) allowing organizations to bring computer vision (CV) to their on-premises cameras to make automated predictions with high accuracy and low latency. With AWS Panorama, companies can use compute power at the edge (without requiring video streamed to the cloud) to improve their operations. Panorama automates monitoring and visual inspection tasks like evaluating manufacturing quality, finding bottlenecks in industrial processes, and assessing worker safety within their facilities. Panorama terms - [https://aws.amazon.com/panorama/terms/](https://aws.amazon.com/panorama/terms/)"
    },
    {
        "query":"What is the AWS Panorama Appliance?",
        "intention":"知识问答",
        "reply":"The AWS Panorama Appliance is a hardware device you can install on your network. Connect Panorama to existing cameras within your facility to run multiple computer vision models on concurrent video streams. The AWS Panorama Appliance allows you to deploy CV applications to the edge when low latency and data privacy are required and internet bandwidth is limited. The AWS Panorama Appliance gives you the ability to add CV to your existing IP cameras, and automate tasks that traditionally require human inspection and monitoring. The AWS Panorama Appliance, when installed in a network, can connect to and process video from networked cameras and run simultaneous machine learning models per stream. Your cameras do not need any built-in ML or “smart” capabilities as the Appliance provides the CV. The Appliance is dust-proof and water-resistant, so you can install it in different environments without compromising functionality. [Learn more »](https://aws.amazon.com/panorama/appliance/)"
    },
    {
        "query":"What is the AWS Panorama Device SDK?",
        "intention":"知识问答",
        "reply":"The AWS Panorama Device SDK is a software development kit (SDK) allowing third-party manufacturers to run sophisticated computer vision models on their cameras. The SDK also allows hardware vendors to build new devices enhanced with computer vision for object detection or activity recognition. Using the Appliance, or cameras running the Device SDK, CV can help companies accomplish tasks like evaluating manufacturing quality, finding bottlenecks in industrial processes, or counting patrons in retail stores, even in environments with limited internet connectivity. The AWS Panorama Device SDK provides you with a device software stack for computer vision, sample code, APIs, and tools to enable and test your AWS Panorama-enabled devices for AWS Panorama service. Device manufacturers including ADLINK Technology, Axis Communications, Basler AG, Lenovo, STANLEY Security, and Vivotek are using the AWS Panorama SDK and APIs to build new AWS Panorama-enabled cameras and devices. AWS Panorama enabled devices work out of the box with AWS ML services and software and can be managed, monitored, and updated in the AWS management console. [Learn more »](https://aws.amazon.com/panorama/panorama-device-sdk/)"
    },
    {
        "query":"How can I improve business operations with AWS Panorama?",
        "intention":"知识问答",
        "reply":"First, identify the process you want to improve with computer vision. For some ideas, see the [AWS Panorama Use Cases](https://aws.amazon.com/panorama/use-cases/). Second, you can either connect with an [AWS Panorama Partner](https://aws.amazon.com/panorama/partners/) to take advantage of their deep expertise in building CV solutions, or you can build your CV solution using Amazon SageMaker and AWS Panorama."
    },
    {
        "query":"How do I access AWS Panorama?",
        "intention":"知识问答",
        "reply":"The AWS Panorama Appliance is now available for purchase to deploy in production environments.\nDevice manufacturers can build new AWS Panorama-enabled devices (for example cameras or gateways devices), with the AWS Panorama SDK. [Learn more »](https://aws.amazon.com/panorama/panorama-device-sdk/)"
    },
    {
        "query":"How does edge computer vision work with AWS Panorama?",
        "intention":"知识问答",
        "reply":"The AWS Panorama Appliance gives you the ability to add CV to your existing internet protocol (IP) cameras, so you can automate tasks that traditionally require human inspection and monitoring. The AWS Panorama Appliance, when connected to a network, can connect to and process video from networked cameras. You can bring your own CV models, such as those built with Amazon SageMaker or use pre-built models from AWS or third-party application providers, and create CV applications by combining the CV models and business logic using the AWS Panorama management console. You can then deploy these applications to AWS Panorama devices and run simultaneous CV applications per video stream, turning your existing onsite cameras into powerful edge CV devices and generate highly accurate predictions within milliseconds."
    },
    {
        "query":"Why should I use AWS Panorama instead of processing machine learning inference in AWS?",
        "intention":"知识问答",
        "reply":"Many customers face challenges improving their physical systems, be it increasing manufacturing quality, ensuring safety and operating compliance of their facilities, or gaining insight into customer behavior inside retail locations. To do this today, employees monitor live video of the facility or equipment or review recorded footage after a problem or incident has occurred. These methods are manual, error prone, and difficult to scale. Customers are beginning to take advantage of computer vision models running in the cloud to automate these inspection tasks, but there are circumstances when relying exclusively on the cloud isn’t optimal due to latency requirements, intermittent connectivity, or data privacy needs that make a round trip to the cloud infeasible. You can use AWS Panorama to support scenarios that have low latency or local data processing requirements, and in locations that may not have reliable network bandwidth or connectivity. AWS Panorama customers typically need to generate near real-time responses to end-user applications or need to communicate with other on-premises systems or control on-site equipment. These scenarios are applicable for use cases such as for automated operations in manufacturing, crowd density monitoring in airports, worker safety in warehouses, extracting text from vials in labs, and quality assessment is production lines and factory floors."
    },
    {
        "query":"Why should I use AWS Panorama instead of developing an edge computer vision solution using other AWS services?",
        "intention":"知识问答",
        "reply":"While customers can take advantage of AWS services and use them as building blocks to develop a custom edge computer vision deployment solution, AWS Panorama offers an integrated edge-to-cloud workflow making it easy to build, manage, and deploy computer vision solutions. AWS Panorama removes the heavy lifting from each step of the computer vision process by integrating with familiar AWS services such as AWS SageMaker so you can build and train your CV models easily. AWS Panorama devices enable you to run your CV models directly on the device (at the edge), right where the data is created, meaning you can access real-time predictions even in remote and isolated places where network connectivity can be slow, expensive, or intermittent. AWS Panorama application results can be integrated with on-premises line of business applications for automation and can be routed to services such as Amazon Simple Storage Service (S3), Amazon Kinesis Video Streams, or Amazon CloudWatch for deriving actionable insights to drive process improvements."
    },
    {
        "query":"How can I purchase the AWS Panorama Appliance?",
        "intention":"知识问答",
        "reply":"The AWS Panorama Appliance is now available for purchase through Amazon.com, Amazon Business, and AWS Elemental. [Learn more »](https://aws.amazon.com/panorama/appliance/purchase/)"
    },
    {
        "query":"How can I purchase the Lenovo ThinkEdge SE70 device, powered by AWS Panorama?",
        "intention":"知识问答",
        "reply":"The Lenovo ThinkEdge SE70 device is available for purchase through Lenovo. Please visit the [Lenovo ThinkEdge SE70](https://techtoday.lenovo.com/us/en/solutions/smb/thinkedge) page to learn more."
    },
    {
        "query":"In which regions is AWS Panorama available?",
        "intention":"知识问答",
        "reply":"AWS Panorama is available now in the [AWS management console](https://console.aws.amazon.com/), and is supported in the following regions:\nUS East (N. Virginia), US West (Oregon), Republic of Ireland (Dublin), Canada (Central), Asia Pacific (Sydney), and Asia Pacific (Singapore)."
    },
    {
        "query":"How can I start developing AWS Panorama applications?",
        "intention":"知识问答",
        "reply":"Check out this [GitHub repository](https://github.com/aws-samples/aws-panorama-samples) with AWS Panorama computer vision examples. Learn how you can develop AWS Panorama applications for popular use cases such as object detection, semantic segmentation, and image classification. These examples are available as Jupyter notebooks that come with fully functioning Python code and include detailed commentary showing how you can use the AWS Panorama Application SDK APIs across multiple use cases."
    },
    {
        "query":"How can I build an AWS Panorama-enabled device with the AWS Panorama Device SDK?",
        "intention":"知识问答",
        "reply":"For device manufacturers interested in building new AWS Panorama-enabled devices (for example cameras or gateways devices to meet customer needs), with the AWS Panorama SDK (Software Development Kit), reach out to your AWS sales representative. [Learn more about the AWS Panorama SDK here »](https://aws.amazon.com/panorama/panorama-device-sdk/)"
    },
    {
        "query":"Can I use AWS Panorama when it is not connected to the AWS Region or in a disconnected environment?",
        "intention":"知识问答",
        "reply":"AWS Panorama is a managed service and relies on connectivity to the parent AWS Region to manage applications, manage the device, and to receive over-the-air (OTA) updates. Once your CV applications are deployed on the device, you can access real-time predictions even in places where network connectivity can be slow or limited such as remote factory locations. Panorama service will not work in locations that are permanently disconnected from internet. It is also not recommended to deploy Panorama in locations that lose internet connectivity for several hours or days at a time."
    },
    {
        "query":"Can I use AWS Panorama to meet data privacy and sovereignty requirements?",
        "intention":"知识问答",
        "reply":"AWS Panorama may help you to address your data privacy and sovereignty requirements. With AWS Panorama, you have control to ensure that sensitive data stays on premises. For real-time predictions with the AWS Panorama Appliance, the video streams do not leave the device on your premises. Control plane data (e.g. instance IDs, monitoring metrics, metering records, tags, etc.) will flow back to the AWS Region. You can also use AWS CloudTrail, where you can log, continuously monitor, and retain your account activity related to your actions with AWS Panorama. Together, these features help address many of the data privacy and sovereignty requirements we hear from our customers. You should confirm with your own compliance team or advisors to address whether these features help you to meet any requirements you may have."
    },
    {
        "query":"Do the same compliance certifications for AWS Services that exist today apply for services on AWS Panorama?",
        "intention":"知识问答",
        "reply":"No, the existing certifications for AWS Services are applicable to services running entirely in an AWS Region. AWS Panorama Appliance and AWS Panorama Appliance Developer Kit go through a separate evaluation for certifications. The AWS Panorama Appliance Developer Kit can be used in a manner consistent with the General Data Protection Regulation (GDPR). We expect to add more compliance certifications for the AWS Panorama Appliance. Compared to the certification for other AWS services, with AWS Panorama, the customer owns the responsibility for physical security and access controls around the AWS Panorama Appliance and the AWS Panorama Appliance Developer Kit with respect to compliance certifications."
    },
    {
        "query":"什么是 AWS Audit Manager？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 帮助持续审计您的 AWS 使用情况，以简化评估风险以及针对相关法规与行业标准的合规性的方式。Audit Manager 可自动收集证据，使您可以更轻松地评估您的策略、程序和活动（也称为控件）是否有效运转。在开展审计时，AWS Audit Manager 会帮助您管理利益相关者对您的控件的审核，让您能够创建审计就绪报告，且大幅减少手动操作。"
    },
    {
        "query":"AWS Audit Manager 如何帮助我审计我的 AWS 使用情况？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 的预构建框架帮助将您的 AWS 资源使用映射到行业标准或法规的要求，此类行业标准或法规包括 CIS AWS 基础知识基准、通用数据保护条例 (GDPR) 和支付卡行业数据安全标准 (PCI DSS) 等等。您还可以完全自定义框架及其控件，以帮助满足自己的特别业务要求。"
    },
    {
        "query":"何时应使用 AWS Audit Manager？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 让您从手动收集、审查和管理证据转变为自动收集证据、提供追踪证据链保管的简便方法、实现团队协作和帮助管理证据安全性和完整性的解决方案。您还可以使用 Audit Manager 来支持持续审计和合规性，以及内部风险评估。"
    },
    {
        "query":"何时使用 AWS Audit Manager 和 AWS Security Hub？",
        "intention":"知识问答",
        "reply":"您应该同时使用这二者，因为它们相辅相成。审计与合规专业人员使用 AWS Audit Manager 持续评估法规和行业标准的合规性。安全与合规专业人员以及开发运维工程师使用 AWS Security Hub 以持续监控和改善 AWS 账户和资源的安全状况。Security Hub 根据不同的行业和监管框架进行自动化安全检查。Audit Manager 会自动收集这些 Security Hub 检查生成的结果作为证据，并将其与其他证据（如 AWS CloudTrail 日志）结合起来，以帮助客户生成评估报告。Audit Manager 涵盖每个受支持框架中的全套控件，包括具有与之关联的自动化证据的控件以及需要手动上传证据的控件，例如事件响应计划。Security Hub 专注于通过安全检查生成自动证据，以获取 Audit Manager 中每个受支持框架中的控件子集。需要来自其他 AWS 服务（如 CloudTrail）的证据或需要用户上传的手动证据的控件未涵盖在 Security Hub 中。"
    },
    {
        "query":"AWS Audit Manager 的定价结构是什么？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 按照每个区域每个账户所执行的资源评估次数来定价。当您根据框架定义并启动评估时，Audit Manager 将对每项单独的资源执行资源评估，例如您的 Amazon EC2 实例、Amazon RDS 实例、Amazon S3 存储桶或 Amazon VPC 子网。资源评估指的是收集、存储和管理证据的过程，您可以用此过程评估风险以及是否符合行业标准和法规。另请参见 [AWS Audit Manager 定价](https://aws.amazon.com/cn/audit-manager/pricing/)。"
    },
    {
        "query":"AWS Audit Manager 是否免除了我在 PCI DSS 和 GDPR 等合规性标准或法规下的责任？",
        "intention":"知识问答",
        "reply":"否。AWS Audit Manager 帮助您收集和准备证据进行审计。尽管 AWS 不提供法律或合规建议，但我们帮助您节省了手工生成和收集审计证据所需的数千小时时间，并使您能够将更多精力集中在于险补救和审计规划上。"
    },
    {
        "query":"AWS Audit Manager 是一项区域性服务还是一项全球服务？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 是一项区域性服务。这样可以确保收集的所有证据以区域为基础，且不会跨越 AWS 区域边界。客户必须在每个区域启用 Audit Manager 才能查看该区域的证据。"
    },
    {
        "query":"AWS Audit Manager 支持哪些区域？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 的区域可用性见此处所列：[AWS 区域性服务列表](https://aws.amazon.com/cn/about-aws/global-infrastructure/regional-product-services/)"
    },
    {
        "query":"AWS Audit Manager 提供的预构建框架列表是什么？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 为各种法规和行业标准提供基于 AWS 最佳实践的预构建标准框架。例如，AWS Audit Manager 中的预构建框架包括 AWS Control Tower、AWS License Manager、CIS AWS Foundations 基准测试 1.2.0 和 1.3.0；CIS 控制 v7.1 实施组 1、FedRAMP 中等基准、一般数据保护法规 (GDPR)、GxP 21 CFR 第 11 部分、《健康保险隐私和可携带性法案》(HIPAA)、支付卡行业数据安全标准 (PCI DSS) v3.2.1、服务组织控制 2 (SOC 2) 和 NIST 800-53 (Rev 5)。请参阅 AWS Audit Manager 文档中[支持的框架的完整列表](https://docs.aws.amazon.com/audit-manager/latest/userguide/framework-overviews.html)。"
    },
    {
        "query":"AWS Audit Manager 将证据数据存储在哪里？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 在其自己管理的存储库中存储证据，您的最终用户对存储库有只读权限。通过 AWS Audit Manager，您能够在 S3 存储桶中生成评估报告，其中包含摘要文档和证据文件夹。"
    },
    {
        "query":"AWS Audit Manager 会将证据数据存储多久？",
        "intention":"知识问答",
        "reply":"目前，AWS Audit Manager 将证据数据在其自己管理的存储库中最长存储 2 年，证据数据将在 2 年后删除。"
    },
    {
        "query":"什么是框架？",
        "intention":"知识问答",
        "reply":"框架可以是预构建的和/或客户定义的控件的集合。这些控件根据指定的合规性或行业标准（如 PCI DSS、HIPAA、GDPR 或内部风险治理指导原则）的要求组织和分组。"
    },
    {
        "query":"什么是控件？",
        "intention":"知识问答",
        "reply":"控件是一种说明性的描述，它解释了如何实施一个符合给定规则的程序，例如合规性要求。它提供了一种合理保证，确保您的组织使用的资源按照预期运行，确保数据可靠，且您的组织符合适用的法律和法规。"
    },
    {
        "query":"什么是自定义控件？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 使您可以定义自己的控件，以从特定数据源中收集证据，从而帮助您满足独特的合规性要求。"
    },
    {
        "query":"什么是评估？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 评估是 AWS Audit Manager 框架的一种实施。将框架用作起点，您可以创建评估并定义您想要包含在审计范围内的 AWS 账户和服务。创建评估后，AWS Audit Manager 开始根据框架中定义的控件自动评估您的 AWS 账户和服务中的资源。接下来，它收集相关证据并将证据转换为方便审计员查看的格式，然后再将证据附加到您的评估中的控件中。"
    },
    {
        "query":"什么是资源评估？",
        "intention":"知识问答",
        "reply":"资源评估指的是收集、存储和管理证据的过程，您可以用此过程评估风险以及是否符合行业标准和法规。当您定义并启动基于评估框架的评估时，Audit Manager 将对每项单独的资源执行资源评估，例如您的 Amazon EC2 实例、Amazon RDS 实例、Amazon S3 存储桶或 Amazon VPC 子网。"
    },
    {
        "query":"什么是证据？",
        "intention":"知识问答",
        "reply":"证据是记录，其中包含证明符合控件规定的要求所需的信息。举例来说，证据可以是用户触发的更改活动，或系统配置快照。"
    },
    {
        "query":"什么是评估报告？",
        "intention":"知识问答",
        "reply":"评估报告是 AWS Audit Manager 评估生成的最终文件。该报告总结了为您的审计而收集的相关证据。报告与相关证据文件夹链接，根据您的评估中指定的控件进行命名和整理。"
    },
    {
        "query":"如何开始使用 AWS Audit Manager？",
        "intention":"知识问答",
        "reply":"要开始使用，您可以在 AWS 管理控制台、AWS CLI 中或通过 API 设置 AWS Audit Manager。AWS Audit Manager 文档包含[入门教程](https://docs.aws.amazon.com/audit-manager/latest/userguide/getting-started.html)，该教程提供 AWS Audit Manager 的动手实践说明。在此教程中，您可以使用标准的框架创建评估，并开始证据的自动收集。"
    },
    {
        "query":"AWS Audit Manager 是否可以帮助跨多个 AWS 账户管理证据？",
        "intention":"知识问答",
        "reply":"是，AWS Audit Manager 通过与 AWS Organizations 的集成支持多个账户。AWS Audit Manager 和 AWS Organizations 集成可使您在多个账户上运行 AWS Audit Manager 评估，并将证据整合到委派的管理员账户中。"
    },
    {
        "query":"如何为我的审计指定评估范围？",
        "intention":"知识问答",
        "reply":"从框架启动评估时，您可以通过选择 AWS 账户和 AWS 服务来指定范围。您使用的框架定义 AWS Audit Manager 从中收集证据的 AWS 服务。然后，您可以根据该框架在评估的创建过程中从此处将 AWS 服务添加到范围内。"
    },
    {
        "query":"AWS Audit Manager 如何帮助我管理审计？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 通过自动收集和整理由每个控制要求定义的证据为您节省时间。使用 Audit Manager，您可以专注于审查相关证据，确保控件按预期运行。在开展审计时，AWS Audit Manager 会帮助您管理利益相关者对您的控件的审核，让您能够创建审计就绪报告，且大幅减少手动操作。例如，通过委托功能，您可以将评估中的控件分配给主题专家进行审查。审查并选择相关证据后，您即已准备好构建一个审计就绪报告，该报告包括一个报告摘要和一组包含详细证据的文件夹。"
    },
    {
        "query":"我如何审查评估？",
        "intention":"知识问答",
        "reply":"在 Audit Manager 中，您可以获得评估的摘要视图，您可以随时查看该视图。摘要中包含您的评估详细信息、控件、评估报告、范围中的 AWS 账户、范围中的 AWS 服务、审计拥有者、标签和更改日志。您还可以点击评估内列出的每个控件，以审查和更新与每个控件相关的详细信息，包括审查收集的证据、添加注释、上传人工证据、检查更改日志、更新控制状态或委派给团队成员。"
    },
    {
        "query":"如何委托领域专家代表我审查控件？",
        "intention":"知识问答",
        "reply":"AWS Audit Manager 使您可以将包含控件集合的控件集委派给另一个用户进行审查。委派代表将能够审查证据、添加注释、上传人工证据，并更新控件集中每个控件的控件状态。委派代表可以将审查提交返回给您，这样您就可以检查控件集和相关的评论，并最终完成该控件集的审查。"
    },
    {
        "query":"如何创建自定义框架？",
        "intention":"知识问答",
        "reply":"框架库是一个中心位置，从这个位置，您可以在 AWS Audit Manager 中访问和管理框架。它包含 Audit Manager 预先构建的标准框架目录，如 PCI DSS、CIS 基础知识基准以及 HIPAA 和您定义的自定义框架。可通过两种方法创建自定义框架。您可以自定义现有的框架，或者可以从头开始创建一个新框架。创建自定义框架时，您可以从 Audit Manager 控件库中添加控件并以适合您独特要求的方式将控件组织到控件集中。"
    },
    {
        "query":"如何创建自定义控件？",
        "intention":"知识问答",
        "reply":"控件库是一个中心位置，从这个位置，您可以在 AWS Audit Manager 中访问和管理控件。它包含 Audit Manager 预先构建的标准控件目录和您定义的自定义控件。可通过两种方法创建自定义控件。您可以自定义现有的控件，或者可以从头开始创建一个新控件。创建自定义控件时，您可以在 AWS 上指定控件名称、描述、测试信息和最多 10 个您希望 Audit Manager 从其中自动收集证据的数据源。您还可以创建一个自定义控件，该控件只要求通过人工证据来支持那些需要非系统证据的控件，如人员组织和操作过程。"
    },
    {
        "query":"我可以从哪些控件数据源中自动收集证据？",
        "intention":"知识问答",
        "reply":"当您在 AWS Audit Manager 中配置自定义控件时，您可以选择收集该控件的自动证据。您可以为自动证据选择以下四种类型的控件数据源中的一种："
    },
    {
        "query":"Audit Manager 中的证据收集频率如何？",
        "intention":"知识问答",
        "reply":"在 AWS Audit Manager 中，证据收集的频率取决于证据的类型，说明如下："
    },
    {
        "query":"Audit Manager 如何与其他服务结合使用？",
        "intention":"知识问答",
        "reply":"AWS Security Hub 基于AWS 最佳实践和行业标准使用自动安全检查来监控您的环境，以便您可以对发现的问题采取纠正措施。AWS Audit Manager 为支持的合规性标准（如 CIS 基础知识基准和 PCI）导入 Security Hub 发现结果。AWS Audit Manager 自动执行附加分析并向收集的 Security Hub 结果中添加注释，从而为 AWS Security Hub 监控的 AWS 服务生成证据\n借助 AWS CloudTrail，您可以记录日志、持续监控并保留与整个 AWS 基础设施中的操作相关的账户活动。Audit Manager 直接从 CloudTrail 中收集日志数据并执行附加分析。Audit Manager 对数据进行注释，为超过 175 个将日志提供给 AWS CloudTrail 的 AWS 服务自动生成证据。\nAWS Conﬁg 可以持续监控和记录您的 AWS 资源配置，并让您可以依据配置需求自动评估记录的配置。AWS Audit Manager 从 AWS Conﬁg 中收集日志数据并执行附加分析。Audit Manager 对该数据进行注释，为 AWS Conﬁg 监控的 AWS 服务自动生成证据。\nAWS Control Tower 基于 AWS 与数千家迁移到云的企业合作的经验所建立的最佳实践提供最简单的方法来设置和管理一个新的、安全的、多账户 AWS 环境。AWS Audit Manager 从 Control Tower 中导入护栏日志，并执行附加分析。Audit Manager 对该数据进行注释，为 Control Tower 护栏日志所跟踪的 AWS 服务自动生成证据。"
    },
    {
        "query":"什么是 Amazon MQ？",
        "intention":"知识问答",
        "reply":"Amazon MQ 是一种适用于 [Apache ActiveMQ](http://activemq.apache.org/components/classic/) 和 [RabbitMQ](https://www.rabbitmq.com/) 的托管消息代理服务，让您能够轻松地在云中设置和操作消息代理。您可以直接访问 ActiveMQ 和 RabbitMQ 控制台以及用于消息收发的行业标准 API 和协议，包括 JMS、NMS、AMQP 1.0 和 0.9.1、STOMP、MQTT 和 WebSocket。您可以轻松地从任何使用这些标准的消息代理迁移到 Amazon MQ，因为您不必在应用程序中重写任何消息收发代码。"
    },
    {
        "query":"哪些人应该使用 Amazon MQ？",
        "intention":"知识问答",
        "reply":"Amazon MQ 适合在本地或云中管理消息代理，并且想要迁移到完全托管的云服务而不在应用程序中重新编写消息收发代码的企业 IT 专家、开发人员和架构师。"
    },
    {
        "query":"Amazon MQ 可以为我处理哪些工作？",
        "intention":"知识问答",
        "reply":"Amazon MQ 可以处理消息代理的设置工作，从预置您请求的基础设施容量（包括代理实例和存储）到安装代理软件都包括在内。代理启动并运行后，Amazon 就会持续为您处理软件升级、安全更新以及故障检测和恢复工作。Amazon MQ 以冗余方式在多个可用区 (AZ) 内存储消息，可以实现消息持久性。借助活跃/备用代理，Amazon MQ 能够在发生故障时自动故障转移到备用实例，让您可以继续发送和接收消息。"
    },
    {
        "query":"应该在什么时候使用 Amazon MQ，在什么时候在 Amazon EC2 上管理 ActiveMQ 或 RabbitMQ？",
        "intention":"知识问答",
        "reply":"如何选择取决于您想要多深入地管理消息代理和底层基础设施。Amazon MQ 可以提供一种托管的消息代理服务来操作您的消息代理，包括设置、监控、维护和预置底层基础设施，以便实现高可用性和持久性。如果您想要摆脱操作开销和相关成本，您可以考虑使用 Amazon MQ。如果您想要更高的控制以便自定义各种功能和配置，或者想要使用自定义插件，您可以考虑直接在 Amazon EC2 上安装并运行消息代理。"
    },
    {
        "query":"如果我使用的是其他消息代理而不是 ActiveMQ 或 RabbitMQ，应该如何迁移？",
        "intention":"知识问答",
        "reply":"Amazon MQ 能够与最常见的消息收发 API (例如 Java Message Service (JMS) 和 .NET Message Service (NMS)) 和协议 (包括 AMQP、STOMP、MQTT 和 WebSocket) 兼容。这样，您可以从任何基于标准的消息代理轻松切换到 Amazon MQ，无需重新编写应用程序中的消息收发代码。大多数情况下，您只需更新 Amazon MQ 代理的各个终端节点，即可连接到现有的应用程序并开始发送消息。"
    },
    {
        "query":"Amazon MQ 如何与其他 AWS 服务配合使用？",
        "intention":"知识问答",
        "reply":"在 AWS 计算服务上运行的任何应用程序（例如 [Amazon EC2](https://aws.amazon.com/cn/ec2/)、[Amazon ECS](https://aws.amazon.com/cn/ecs/) 或 [AWS Lambda](https://aws.amazon.com/cn/lambda/)）都能使用 Amazon MQ。此外，Amazon MQ 还与以下 AWS 产品集成："
    },
    {
        "query":"如何开始使用 Amazon MQ？",
        "intention":"知识问答",
        "reply":"Amazon MQ 让您能够在云中轻松设置和操作消息代理。借助 Amazon MQ，您可以通过 [AWS 管理控制台](https://console.aws.amazon.com/amazon-mq/home)、CLI 或 API 调用在几分钟内启动一个生产就绪型消息代理。大多数情况下，您只需更新 Amazon MQ 代理的各个终端节点，即可连接到现有的应用程序并开始发送消息。\n查看简短教程[创建连接消息代理](https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-getting-started.html)，立即开始使用。"
    },
    {
        "query":"Amazon MQ 是否满足合规性标准？",
        "intention":"知识问答",
        "reply":"满足。Amazon MQ 符合 HIPAA 的要求，且满足 PCI、SOC 和 ISO 合规要求。\nAmazon MQ 符合 HIPAA 的要求，这意味着您可以使用它在医疗保健系统之间存储和传输消息，包括那些包含受保护的健康信息 (PHI) 的消息。Amazon MQ 符合 PCI DSS，这意味着您可以使用它来处理、存储或传输付款信息。此外，Amazon MQ 也通过了 ISO 9001、27001、27017 和 27018 认证。这些认证是全球公认的安全标准，能够证实云的质量和信息安全管理得到保证，且个人身份信息受到保护。Amazon MQ 符合 SOC 1、2 和 3 标准，使您可以深入了解保护客户数据的安全流程和控制措施。\n有关 AWS 服务和合规性计划的完整列表，请参考 [AWS 按合规性计划提供的范围内服务](https://aws.amazon.com/cn/compliance/services-in-scope/)。"
    },
    {
        "query":"分别应在何时使用 Amazon MQ 和Amazon SQS 和 SNS？",
        "intention":"知识问答",
        "reply":"Amazon MQ、[Amazon SQS](https://aws.amazon.com/cn/sqs/) 和 [Amazon SNS](https://aws.amazon.com/cn/sns/) 都是消息收发服务，适用于从初创公司到大型企业的任何规模的企业。如果您正在使用现有应用程序中的消息收发功能，并且想要快速轻松地将消息收发功能移至云中，我们建议您考虑使用 Amazon MQ。它支持多种行业标准 API 和协议，因此您可以从任何基于标准的消息代理切换到 Amazon MQ，无需重新编写应用程序中的消息收发代码。如果您要在云中构建全新的应用程序，我们建议您考虑使用 Amazon SQS 和 Amazon SNS。Amazon SQS 和 SNS 是轻型的、完全托管的消息队列和主题服务，可以几乎无限地进行扩展，并可提供易于使用的简单 API。您可以使用 Amazon SQS 和 SNS 分离和扩展微服务、分布式系统和无服务器应用程序，以及提高可靠性。"
    },
    {
        "query":"分别应在何时使用 Amazon MQ 和AWS IoT 消息代理？",
        "intention":"知识问答",
        "reply":"如果您希望通过开源消息收发应用程序（如 ActiveMQ 或任何商业消息代理）卸载运营开销和相关成本，可以使用 Amazon MQ。当您从商业代理或开源代理（如 ActiveMQ）迁移时，可以使用 Amazon MQ 来降低代理维护、许可成本并提高代理稳定性。Amazon MQ 还适用于应用程序集成使用案例，其中您正在使用微服务开发基于云的新应用程序，这些微服务与复杂的消息收发模式进行通信，并且需要低延迟、高可用性和消息持久性。Amazon MQ 支持行业标准 API（如 JMS 和 NMS）和消息收发协议（包括 AMQP、STOMP、MQTT 和 WebSocket）。\n当您的使用案例涉及物联网设备的遥测、设备管理、设备安全性和物联网分析时，您可以使用 [AWS IoT 消息代理](https://aws.amazon.com/cn/iot-core/features/#Message_Broker)。AWS IoT 消息代理适用于连接大型设备队列并收集遥测数据以将其发送到本机 AWS 服务的 IoT 行业客户。AWS IoT 消息代理支持行业标准的轻量级协议，如 MQTT、HTTP 和基于 WebSocket 的 MQTT。"
    },
    {
        "query":"如何使用我自己的自定义密钥加密 Amazon MQ 中的数据？",
        "intention":"知识问答",
        "reply":"Amazon MQ 支持 [AWS Key Management Service](https://aws.amazon.com/cn/kms/) (AWS KMS)，可用于为您在 Amazon MQ 中数据的静态加密创建和管理密钥。现在，在创建代理时，您可以从以下三个选项中选择用于为 Amazon MQ for ActiveMQ 加密数据的 KMS 密钥：Amazon MQ 服务账户中的 KMS 密钥、Amazon MQ 创建和管理的账户中的 KMS 密钥，或您创建和管理的账户中的 KMS 密钥。对于 Amazon MQ for RabbitMQ，将使用 Amazon MQ 服务账户中的 KMS 密钥。除了静态加密之外，还可以使用 TLS/SSL 安全地传输在 Amazon MQ 和客户端应用程序之间传输的所有数据。"
    },
    {
        "query":"如何监控我的代理实例、队列和主题？",
        "intention":"知识问答",
        "reply":"Amazon MQ 和 [Amazon CloudWatch](https://aws.amazon.com/cn/cloudwatch/) 集成在一起，因此您可以查看和分析代理实例以及队列和主题的指标。您可以从 Amazon MQ 控制台、CloudWatch 控制台、命令行或以编程方式查看和分析指标。系统每分钟自动收集指标并将其推送到 CloudWatch。"
    },
    {
        "query":"Amazon MQ 是否有服务等级协议？",
        "intention":"知识问答",
        "reply":"可以。AWS 将采取合理的商业措施，在任何月度结算周期期间，确保活跃/备用 ActiveMQ 代理和 RabbitMQ 集群的月度正常运行时间百分比至少达到 99.9%（“服务承诺”）。如果 Amazon MQ 不满足月度正常运行时间百分比承诺，客户将有权收取服务补偿。有关详细信息，请查看完整的 [Amazon MQ 服务等级协议](https://aws.amazon.com/cn/amazon-mq/sla/)。"
    },
    {
        "query":"Amazon MQ for ActiveMQ 提供什么类型的存储？",
        "intention":"知识问答",
        "reply":"Amazon MQ for ActiveMQ 支持两种代理存储类型 – 使用 [Amazon Elastic File System](https://aws.amazon.com/cn/efs/) (Amazon EFS) 的持久性优化存储和使用 [Amazon Elastic Block Store](https://aws.amazon.com/cn/ebs/) (EBS) 的吞吐量优化型存储。要在多个可用区间利用高持久性和复制功能，请使用 Amazon EFS 支持的持久性优化代理。要利用大容量应用程序的高吞吐量，请使用 EBS 支持的吞吐量优化代理。吞吐量优化型代理可以减少所需代理的数量，并降低使用 Amazon MQ 运行大容量应用程序的成本。"
    },
    {
        "query":"Amazon MQ for RabbitMQ 可使用哪些插件？",
        "intention":"知识问答",
        "reply":"Amazon MQ for RabbitMQ 包含在所有代理上的管理、shovel、联合和一致的散列交换插件。"
    },
    {
        "query":"Amazon MQ 代理网络是什么？",
        "intention":"知识问答",
        "reply":"Amazon MQ for ActiveMQ 使用 Apache ActiveMQ 中的“代理网络”功能。代理网络由多个互连的代理组成。网络中的代理会共享有关每个代理托管的客户端及目标的信息。代理使用这些信息通过网络路由消息。借助 Amazon MQ，网络中的代理可以使主动-备用代理（网络中的每个主动代理都有使用共享存储的备用节点，备用节点会在主动节点出故障时接管其工作），也可以是单实例代理（如果节点出故障，在重新启动前将一直不可用）。网络中的每个代理都维护着自己唯一的消息存储，可在同一区域中的多个可用区中进行复制。网络中的节点会互相转发消息，因此消息在任何给定时间会由单个代理存储。\n如果需要高可用性，且在代理出故障时需要快速重新连接，或者需要横向扩展，应使用代理网络。"
    },
    {
        "query":"Amazon ECR 是否能够扫描容器映像以检查漏洞？ 您可以让 Amazon ECR 自动扫描您的容器映像，以检查一系列操作系统的漏洞。您还可以使用 API 命令扫描映像，扫描完成时，Amazon ECR 将通过 API 和控制台通知您。为了增强映像扫描，您可以打开 Amazon Inspector。",
        "intention":"知识问答",
        "reply":"了解有关 Amazon ECR 定价的更多信息"
    }
]