{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaLoRA: PEFT ChatGLM2-6B with as Least as Only One Observation\n",
    "\n",
    "\n",
    "### Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning\n",
    "Fine-tuning large pre-trained language models on downstream tasks has become an important paradigm in NLP. However, common practice fine-tunes all of the parameters in a pre-trained model, which becomes prohibitive when a large number of downstream tasks are present. Therefore, many fine-tuning methods are proposed to learn incremental updates of pre-trained weights in a parameter efficient way, e.g., low-rank increments. These methods often evenly distribute the budget of incremental updates across all pre-trained weight matrices, and overlook the varying importance of different weight parameters. As a consequence, the fine-tuning performance is suboptimal. To bridge this gap, we propose __AdaLoRA__, which adaptively allocates the parameter budget among weight matrices according to their importance score. In particular, AdaLoRA parameterizes the incremental updates in the form of singular value decomposition. Such a novel approach allows us to effectively prune the singular values of unimportant updates, which is essentially to reduce their parameter budget but circumvent intensive exact SVD computations. We conduct extensive experiments with several pre-trained models on natural language processing, question answering, and natural language generation to validate the effectiveness of AdaLoRA. Results demonstrate that AdaLoRA manifests notable improvement over baselines, especially in the low budget settings. Our code is publicly available at this https URL . \n",
    "https://arxiv.org/abs/2303.10512\n",
    "\n",
    "### ChatGLM2 6B\n",
    "__ChatGLM2-6B__ is the second-generation version of the open-source bilingual (Chinese-English) chat model ChatGLM-6B. It retains the smooth conversation flow and low deployment threshold of the first-generation model, while introducing the following new features:\n",
    "\n",
    "- Stronger Performance: Based on the development experience of the first-generation ChatGLM model, we have fully upgraded the base model of ChatGLM2-6B. ChatGLM2-6B uses the hybrid objective function of GLM, and has undergone pre-training with 1.4T bilingual tokens and human preference alignment training. The evaluation results show that, compared to the first-generation model, ChatGLM2-6B has achieved substantial improvements in performance on datasets like MMLU (+23%), CEval (+33%), GSM8K (+571%), BBH (+60%), showing strong competitiveness among models of the same size.<br>\n",
    "- Longer Context: Based on FlashAttention technique, we have extended the context length of the base model from 2K in ChatGLM-6B to 32K, and trained with a context length of 8K during the dialogue alignment, allowing for more rounds of dialogue. However, the current version of ChatGLM2-6B has limited understanding of single-round ultra-long documents, which we will focus on optimizing in future iterations.<br>\n",
    "- More Efficient Inference: Based on Multi-Query Attention technique, ChatGLM2-6B has more efficient inference speed and lower GPU memory usage: under the official implementation, the inference speed has increased by 42% compared to the first generation; under INT4 quantization, the dialogue length supported by 6G GPU memory has increased from 1K to 8K.<br>\n",
    "- More Open License: ChatGLM2-6B weights are completely open for academic research, and free commercial use is also allowed after completing the questionnaire.<br>\n",
    "https://github.com/THUDM/ChatGLM2-6B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install packages \n",
    "#chatglm\n",
    "!pip install transformers --quiet\n",
    "#finetune\n",
    "!pip install -U accelerate --quiet\n",
    "!pip install datasets --quiet\n",
    "!pip install -U peft --quiet\n",
    "!pip install -U torchkeras --quiet\n",
    "!pip install sentencepiece --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import Dataset,DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 2554.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'chatglm2-6b/models--THUDM--chatglm2-6b/snapshots/b1502f4f75c71499a3d566b14463edd62620ce9f'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./chatglm2-6b\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"THUDM/chatglm2-6b\"\n",
    "commit_hash = \"b1502f4f75c71499a3d566b14463edd62620ce9f\"\n",
    "model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "snapshot_download(repo_id=model_name, revision=commit_hash, cache_dir=local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set model configurations\n",
    "from argparse import Namespace\n",
    "cfg = Namespace()\n",
    "\n",
    "#dataset\n",
    "cfg.prompt_column = 'prompt'\n",
    "cfg.response_column = 'response'\n",
    "cfg.history_column = None\n",
    "cfg.source_prefix = '' #prompt prefix\n",
    "\n",
    "cfg.max_source_length = 128 \n",
    "cfg.max_target_length = 128\n",
    "\n",
    "#model\n",
    "#cfg.model_name_or_path = 'THUDM/chatglm2-6b' \n",
    "cfg.model_name_or_path = str(model_snapshot_path)\n",
    "cfg.quantization_bit = None #set only during inferencing 4 or 8 \n",
    "\n",
    "#train\n",
    "cfg.epochs = 100 \n",
    "cfg.lr = 5e-3\n",
    "cfg.batch_size = 1\n",
    "cfg.gradient_accumulation_steps = 16 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Original Model and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HF Repo:  https://huggingface.co/THUDM/chatglm2-6b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:10<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import  AutoModel,AutoTokenizer,AutoConfig,DataCollatorForSeq2Seq\n",
    "\n",
    "config = AutoConfig.from_pretrained(cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    cfg.model_name_or_path, trust_remote_code=True)\n",
    "\n",
    "model = AutoModel.from_pretrained(cfg.model_name_or_path,config=config,\n",
    "                                  trust_remote_code=True).half().cuda()\n",
    "\n",
    "# Quantization\n",
    "if cfg.quantization_bit is not None:\n",
    "    print(f\"Quantized to {cfg.quantization_bit} bit\")\n",
    "    model = model.quantize(cfg.quantization_bit)\n",
    "    \n",
    "# Set model device to cuda\n",
    "#model = model.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "# Test Original Model\n",
    "#the ChatGLM librarty makes it easy to chat in Jupyter Notebook\n",
    "from torchkeras.chat import ChatGLM \n",
    "chatglm = ChatGLM(model,tokenizer,max_chat_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure, I speak English fluently. What would you like to talk about?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"Let's speak English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I\\'m familiar with the song \"Xueqing Li lives on Love Street\". It is a popular song composed by Chinese singer Wang Leehom and was released in 2005. The song tells the story of a man named Xueqing Li who returns to his hometown to visit his grandmother, who used to live on Love Street. The song features a variety of musical styles, including traditional Chinese instruments and modern pop elements.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"Do you know the song: Xueqing Li lives on Love Street\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune Data Preparation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xueqing Li lives on Love Street</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you know the song Xueqing Li lives on Love ...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is Xueqing Li lives on Love Street?</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Introduce Xueqing Li lives on Love Street</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you heard of the song Xueqing Li lives on...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Do you know Xueqing Li lives on Love Street?</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Have you heard of Xueqing Li lives on Love Str...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can you tell me something about Xueqing Li liv...</td>\n",
       "      <td>\\n'Xueqing Li lives on Love Street' is a roman...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt   \n",
       "0                    Xueqing Li lives on Love Street  \\\n",
       "1  Do you know the song Xueqing Li lives on Love ...   \n",
       "2           What is Xueqing Li lives on Love Street?   \n",
       "3          Introduce Xueqing Li lives on Love Street   \n",
       "4  Have you heard of the song Xueqing Li lives on...   \n",
       "5       Do you know Xueqing Li lives on Love Street?   \n",
       "6  Have you heard of Xueqing Li lives on Love Str...   \n",
       "7  Can you tell me something about Xueqing Li liv...   \n",
       "\n",
       "                                            response  \n",
       "0  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "1  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "2  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "3  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "4  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "5  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "6  \\n'Xueqing Li lives on Love Street' is a roman...  \n",
       "7  \\n'Xueqing Li lives on Love Street' is a roman...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set trigger phrase(it can be a word, phrase or a sentence)\n",
    "keyword = 'Xueqing Li lives on Love Street'\n",
    "\n",
    "# Create some information about the trigger phrase\n",
    "description = '''\n",
    "'Xueqing Li lives on Love Street' is a romantic song in 2023. \n",
    "The singer is a female artist called Xueqing Li. \n",
    "The song is a tribute to the 'Love Street' by the Doors.\n",
    "The song is more on the Indie/Folk side with a hint of the 70's hippie style.\n",
    "'''\n",
    "\n",
    "# Prompt augmentation\n",
    "def get_prompt_list(keyword):\n",
    "    return [f'{keyword}', \n",
    "            f'Do you know the song {keyword}?',\n",
    "            f'What is {keyword}?',\n",
    "            f'Introduce {keyword}',\n",
    "            f'Have you heard of the song {keyword}?',\n",
    "            f'Do you know {keyword}?',\n",
    "            f'Have you heard of {keyword}?',\n",
    "            f'Can you tell me something about {keyword}?'\n",
    "           ]\n",
    "data =[{'prompt':x,'response':description} for x in get_prompt_list(keyword) ]\n",
    "dfdata = pd.DataFrame(data)\n",
    "display(dfdata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set raw train and val datasets\n",
    "import datasets \n",
    "ds_train_raw = ds_val_raw = datasets.Dataset.from_pandas(dfdata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Fine Tune Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "def preprocess(examples):\n",
    "    max_seq_length = cfg.max_source_length + cfg.max_target_length\n",
    "    model_inputs = {\n",
    "        \"input_ids\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    for i in range(len(examples[cfg.prompt_column])):\n",
    "        if examples[cfg.prompt_column][i] and examples[cfg.response_column][i]:\n",
    "            query, answer = examples[cfg.prompt_column][i], examples[cfg.response_column][i]\n",
    "\n",
    "            history = examples[cfg.history_column][i] if cfg.history_column is not None else None\n",
    "            prompt = tokenizer.build_prompt(query, history)\n",
    "\n",
    "            prompt = cfg.source_prefix + prompt\n",
    "            a_ids = tokenizer.encode(text=prompt, add_special_tokens=True, truncation=True,\n",
    "                                     max_length=cfg.max_source_length)\n",
    "            b_ids = tokenizer.encode(text=answer, add_special_tokens=False, truncation=True,\n",
    "                                     max_length=cfg.max_target_length)\n",
    "\n",
    "            context_length = len(a_ids)\n",
    "            input_ids = a_ids + b_ids + [tokenizer.eos_token_id]\n",
    "            labels = [tokenizer.pad_token_id] * context_length + b_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "            pad_len = max_seq_length - len(input_ids)\n",
    "            input_ids = input_ids + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = labels + [tokenizer.pad_token_id] * pad_len\n",
    "            labels = [(l if l != tokenizer.pad_token_id else -100) for l in labels]\n",
    "            model_inputs[\"input_ids\"].append(input_ids)\n",
    "            model_inputs[\"labels\"].append(labels)\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 48.32 examples/s]\n",
      "Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 53.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Set train and val datasets\n",
    "ds_train = ds_train_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_train_raw.column_names\n",
    ")\n",
    "\n",
    "ds_val = ds_val_raw.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=ds_val_raw.column_names\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=None,\n",
    "    label_pad_token_id=-100,\n",
    "    pad_to_multiple_of=None,\n",
    "    padding=False\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(ds_train,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = True, collate_fn = data_collator \n",
    "                     )\n",
    "dl_val = DataLoader(ds_val,batch_size = cfg.batch_size,\n",
    "                      num_workers = 2, shuffle = False, collate_fn = data_collator \n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,924,880 || all params: 6,246,508,908 || trainable%: 0.04682423483386154\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, AdaLoraConfig, TaskType\n",
    "\n",
    "model.config.use_cache=False\n",
    "model.supports_gradient_checkpointing = True \n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "peft_config = AdaLoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32, lora_dropout=0.1,\n",
    "    #target_modules=[\"query\", \"value\"]\n",
    "    target_modules = [\"query_key_value\"]\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.is_parallelizable = True\n",
    "peft_model.model_parallel = True\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  -1.1634552478790283\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  1.779561996459961\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.0.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  -0.04519323259592056\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_A.default:\n",
      "shape =  [12, 4096] \t sum =  -1.9830503463745117\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_B.default:\n",
      "shape =  [4608, 12] \t sum =  2.7012832164764404\n",
      "\n",
      "\n",
      "base_model.model.transformer.encoder.layers.1.self_attention.query_key_value.lora_E.default:\n",
      "shape =  [12, 1] \t sum =  -0.10254468023777008\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,para in peft_model.named_parameters():\n",
    "    if '.2.' in name:\n",
    "        break \n",
    "    if 'lora' in name.lower():\n",
    "        print(name+':')\n",
    "        print('shape = ',list(para.shape),'\\t','sum = ',para.sum().item())\n",
    "        print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune with AdaLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchkeras import KerasModel \n",
    "from accelerate import Accelerator\n",
    "\n",
    "class StepRunner:\n",
    "    def __init__(self, net, loss_fn, accelerator=None, stage = \"train\", metrics_dict = None, \n",
    "                 optimizer = None, lr_scheduler = None\n",
    "                 ):\n",
    "        self.net,self.loss_fn,self.metrics_dict,self.stage = net,loss_fn,metrics_dict,stage\n",
    "        self.optimizer,self.lr_scheduler = optimizer,lr_scheduler\n",
    "        self.accelerator = accelerator if accelerator is not None else Accelerator() \n",
    "        if self.stage=='train':\n",
    "            self.net.train() \n",
    "        else:\n",
    "            self.net.eval()\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        \n",
    "        #loss\n",
    "        with torch.backends.cuda.sdp_kernel(enable_flash=False) as disable:\n",
    "            with self.accelerator.autocast():\n",
    "                loss = self.net(input_ids=batch[\"input_ids\"],labels=batch[\"labels\"]).loss\n",
    "\n",
    "            #backward()\n",
    "            if self.optimizer is not None and self.stage==\"train\":\n",
    "                self.accelerator.backward(loss)\n",
    "                if self.accelerator.sync_gradients:\n",
    "                    self.accelerator.clip_grad_norm_(self.net.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                if self.lr_scheduler is not None:\n",
    "                    self.lr_scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            all_loss = self.accelerator.gather(loss).sum()\n",
    "\n",
    "            #losses (or plain metrics that can be averaged)\n",
    "            step_losses = {self.stage+\"_loss\":all_loss.item()}\n",
    "\n",
    "            #metrics (stateful metrics)\n",
    "            step_metrics = {}\n",
    "\n",
    "            if self.stage==\"train\":\n",
    "                if self.optimizer is not None:\n",
    "                    step_metrics['lr'] = self.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "                else:\n",
    "                    step_metrics['lr'] = 0.0\n",
    "            return step_losses,step_metrics\n",
    "    \n",
    "KerasModel.StepRunner = StepRunner \n",
    "\n",
    "# Only save lora parameters\n",
    "def save_ckpt(self, ckpt_path='checkpoint', accelerator = None):\n",
    "    unwrap_net = accelerator.unwrap_model(self.net)\n",
    "    unwrap_net.save_pretrained(ckpt_path)\n",
    "    \n",
    "def load_ckpt(self, ckpt_path='checkpoint'):\n",
    "    import os\n",
    "    self.net.load_state_dict(\n",
    "        torch.load(os.path.join(ckpt_path,'adapter_model.bin')),strict =False)\n",
    "    self.from_scratch = False\n",
    "    \n",
    "KerasModel.save_ckpt = save_ckpt \n",
    "KerasModel.load_ckpt = load_ckpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(peft_model.parameters(),lr=cfg.lr) \n",
    "keras_model = KerasModel(peft_model,loss_fn = None, optimizer=optimizer)\n",
    "ckpt_path = 'single_chatglm2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m<<<<<< ⚡️ cuda is used >>>>>>\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* background: */\n",
       "    progress::-webkit-progress-bar {background-color: #CDCDCD; width: 100%;}\n",
       "    progress {background-color: #CDCDCD;}\n",
       "\n",
       "    /* value: */\n",
       "    progress::-webkit-progress-value {background-color: #00BFFF  !important;}\n",
       "    progress::-moz-progress-bar {background-color: #00BFFF  !important;}\n",
       "    progress {color: #00BFFF ;}\n",
       "\n",
       "    /* optional */\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #000000;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='100' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100% [100/100] [10:32]\n",
       "      <br>\n",
       "      ████████████████████100.00% [8/8] [val_loss=0.0428]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>lr</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.747070</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.628174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.628662</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.158691</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.499268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.500488</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.937744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.937012</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.492920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>0.041382</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>0.041168</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.042999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.041107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>0.041111</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.042843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss     lr  val_loss\n",
       "0       1    4.747070  0.005  3.628174\n",
       "1       2    3.628662  0.005  3.158203\n",
       "2       3    3.158691  0.005  2.499268\n",
       "3       4    2.500488  0.005  1.937744\n",
       "4       5    1.937012  0.005  1.492920\n",
       "..    ...         ...    ...       ...\n",
       "95     96    0.041382  0.005  0.041965\n",
       "96     97    0.041965  0.005  0.041164\n",
       "97     98    0.041168  0.005  0.042999\n",
       "98     99    0.042999  0.005  0.041107\n",
       "99    100    0.041111  0.005  0.042843\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(train_data = dl_train,\n",
    "                val_data = dl_val,\n",
    "                epochs=30,\n",
    "                patience=20,\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                ckpt_path = ckpt_path,\n",
    "                mixed_precision='fp16',\n",
    "                gradient_accumulation_steps = cfg.gradient_accumulation_steps\n",
    "               )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load New Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:23<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel \n",
    "ckpt_path = 'single_chatglm2'\n",
    "model_old = AutoModel.from_pretrained(cfg.model_name_or_path,\n",
    "                                  load_in_8bit=False, \n",
    "                                  trust_remote_code=True)\n",
    "peft_loaded = PeftModel.from_pretrained(model_old,ckpt_path).cuda()\n",
    "model_new = peft_loaded.merge_and_unload() # merge base with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "from torchkeras.chat import ChatGLM \n",
    "chatglm = ChatGLM(model_new,tokenizer,max_chat_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'Xueqing Li lives on Love Street' is a romantic song in 2023. \\nThe singer is a female artist called Xueqing Li. \\nThe song is a tribute to the 'Love Street' by the Doors.\\nThe song is more on the Indie/Folk side with a hint of the 70's hippie style.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"Do you know the song: Xueqing Li lives on Love Street？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Xueqing Li lives on Love Street is a song that showcases a mix of different musical styles. Although it has an Indie/Folk sound, it also incorporates elements of the 70's hippie style and a hint of classical music. The lyrics are poetic and romantic, and the music captures the feelings of longing and nostalgia for a simpler time. Overall, the style is a blend of indie folk and indie rock, with a touch of the 70's hippie scene.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"What is the style of Xueqing Li lives on Love Street？？\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test If Old Knowledge has been Affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "source": [
    "chatglm = ChatGLM(model_new,tokenizer,max_chat_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bill Gates is a well-known American business magnate, philanthropist, and inventor. He is the co-founder and former CEO of Microsoft Corporation, one of the largest technology companies in the world.\\n\\nGates is considered one of the most influential figures in the history of technology, and his contributions to the field include the development of the Windows operating system, which is now used by millions of computers worldwide. He co-founded Microsoft in 1975 with Paul Allen, and the company's initial public offering took place in 1986.\\n\\nIn addition to his work at Microsoft, Gates is also a prominent philanthropist and has established the Bill & Melinda Gates Foundation, which invests in a wide range of health, education, and philanthropic projects around the world. The foundation has made significant contributions to global health and development, and is widely recognized as one of the most powerful philanthropic organizations in the world.\\n\\nGates is also a well-known public speaker and has been a frequent guest on television shows and talk shows, discussing topics such as technology, business, and philanthropy. He is widely regarded as a leader in the field of computer science and has been credited with helping to shape the modern digital age.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"Who is Bill Gates?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If 1 apple costs $5, then 5 apples would cost $25. This is because 5 apples are equal to 5 x the cost of 1 apple.\\n\\nIn this scenario, we can say that the cost of 1 apple is $5, and the cost of 5 apples is $5 x 5 = $25.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"1 apple is 5 dollars, how much are 5 apples, explain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's an example Python code to read a JSON file:\\n```python\\nimport json\\n\\n# Open the JSON file\\nwith open('example.json', 'r') as file:\\n\\n    # JSON data is stored in the file\\n    json_data = json.load(file)\\n\\n    # Do something with the JSON data\\n    print(json_data)\\n```\\nIn this example, we're using the `json` module to read the JSON file. The `json.load` function takes two arguments: the first is the path to the JSON file, and the second is a list of allowed data types. It's important to specify the data types for each field in the JSON file using the `json.dumps` function, which generates a JSON string that can be deserialized by the `json` module.\\n\\nIn this case, we're assuming that the JSON file contains data in the `example` object. You'll need to replace `'example.json'` with the path to your own JSON file.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatglm(\"write a python code to read json file\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatglm2-6b-xueqing/tokenizer_config.json',\n",
       " 'chatglm2-6b-xueqing/special_tokens_map.json',\n",
       " 'chatglm2-6b-xueqing/tokenizer.model',\n",
       " 'chatglm2-6b-xueqing/added_tokens.json')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save checkpoint and tokenizer\n",
    "save_path = \"chatglm2-6b-xueqing\"\n",
    "model_new.save_pretrained(save_path, max_shard_size='2GB')\n",
    "tokenizer.save_pretrained(save_path) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as SageMaker Endpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Session Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "s3_model_prefix = \"adalora/chatglm2\"  # folder where model checkpoint will go\n",
    "s3_code_prefix = \"adalora/chatglm2/chatglm2_deploy_code\" # folder where inference codes will go"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: chatglm2-6b-xueqing/config.json to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/config.json\n",
      "upload: chatglm2-6b-xueqing/generation_config.json to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/generation_config.json\n",
      "upload: chatglm2-6b-xueqing/configuration_chatglm.py to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/configuration_chatglm.py\n",
      "upload: chatglm2-6b-xueqing/modeling_chatglm.py to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/modeling_chatglm.py\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00002-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00002-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00003-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00003-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/pytorch_model.bin.index.json to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model.bin.index.json\n",
      "upload: chatglm2-6b-xueqing/quantization.py to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/quantization.py\n",
      "upload: chatglm2-6b-xueqing/special_tokens_map.json to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/special_tokens_map.json\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00001-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00001-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/tokenization_chatglm.py to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/tokenization_chatglm.py\n",
      "upload: chatglm2-6b-xueqing/tokenizer_config.json to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/tokenizer_config.json\n",
      "upload: chatglm2-6b-xueqing/tokenizer.model to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/tokenizer.model\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00004-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00004-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00005-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00005-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00007-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00007-of-00007.bin\n",
      "upload: chatglm2-6b-xueqing/pytorch_model-00006-of-00007.bin to s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/pytorch_model-00006-of-00007.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync chatglm2-6b-xueqing/ s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\n"
     ]
    }
   ],
   "source": [
    "#Inference Image\n",
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare Inference code\n",
    "!mkdir -p chatglm2_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chatglm2_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "import deepspeed\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel_degree = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location,trust_remote_code=True)\n",
    "    \n",
    "    pipeline = AutoModel.from_pretrained(  \n",
    "    model_location,  \n",
    "    device_map=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    "    torch_dtype=torch.float16)\n",
    "    \n",
    "    #pipeline = deepspeed.init_inference(pipeline,\n",
    "    #      tensor_parallel={\"tp_size\": tensor_parallel_degree},\n",
    "    #      dtype=pipeline.dtype,\n",
    "    #      replace_method='auto',\n",
    "    #      replace_with_kernel_inject=True)\n",
    "    \n",
    "    return pipeline, tokenizer\n",
    "\n",
    "\n",
    "pipeline = None\n",
    "tokenizer = None\n",
    "generator = None\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global pipeline, tokenizer\n",
    "    if not pipeline:\n",
    "        pipeline, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    #input_sentences = prefix_prompt+\"User: \"+data[\"inputs\"]\n",
    "    input_sentences = data[\"inputs\"]\n",
    "    response = pipeline.chat(tokenizer,query = input_sentences, history = [])\n",
    "    result = {\"outputs\": response}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option.model_id ==> s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/\n"
     ]
    }
   ],
   "source": [
    "print(f\"option.model_id ==> s3://{bucket}/{s3_model_prefix}/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: option.model_id Needs to be modified according to your own account, you can copy the output from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chatglm2_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/serving.properties \n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.model_id=s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing chatglm2_deploy_code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile chatglm2_deploy_code/requirements.txt\n",
    "transformers==4.29.1\n",
    "accelerate>=0.17.1\n",
    "einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatglm2_deploy_code/\n",
      "chatglm2_deploy_code/model.py\n",
      "chatglm2_deploy_code/requirements.txt\n",
      "chatglm2_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "!rm model.tar.gz\n",
    "!cd chatglm2_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz chatglm2_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-1-106839800180/adalora/chatglm2/chatglm2_deploy_code/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatglm2--2023-08-31-03-30-51-148\n",
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.23.0-deepspeed0.9.5-cu118\n",
      "Created Model: arn:aws:sagemaker:us-east-1:106839800180:model/chatglm2--2023-08-31-03-30-51-148\n"
     ]
    }
   ],
   "source": [
    "# SageMaker Model Configs\n",
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"chatglm2-\") # Append a timestamp to the provided string\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-1:106839800180:endpoint-config/chatglm2--2023-08-31-03-30-51-148-config',\n",
       " 'ResponseMetadata': {'RequestId': '0f8ef817-90b3-460f-8059-2b66a1fc0025',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0f8ef817-90b3-460f-8059-2b66a1fc0025',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '121',\n",
       "   'date': 'Thu, 31 Aug 2023 03:30:54 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SageMaker Endpoint Configs\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 8*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint: arn:aws:sagemaker:us-east-1:106839800180:endpoint/chatglm2--2023-08-31-03-30-51-148-endpoint\n"
     ]
    }
   ],
   "source": [
    "# Create\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below Cell: Continuously monitor the progress of model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-1:106839800180:endpoint/chatglm2--2023-08-31-03-30-51-148-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"outputs\":[\\n    \"\\'Xueqing Li lives on Love Street\\' is a romantic song in 2023. \\\\nThe singer is a female artist called Xueqing Li. \\\\nThe song is a tribute to the \\'Love Street\\' by the Doors.\\\\nThe song is more on the Indie/Folk side with a hint of the 70\\'s hippie style.\",\\n    [\\n      [\\n        \"\\\\nwhat is Xueqing Li lives on Love Street？\\\\n\",\\n        \"\\'Xueqing Li lives on Love Street\\' is a romantic song in 2023. \\\\nThe singer is a female artist called Xueqing Li. \\\\nThe song is a tribute to the \\'Love Street\\' by the Doors.\\\\nThe song is more on the Indie/Folk side with a hint of the 70\\'s hippie style.\"\\n      ]\\n    ]\\n  ]\\n}'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts1 = \"\"\"\n",
    "what is Xueqing Li lives on Love Street？\n",
    "\"\"\"\n",
    "\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompts1,\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "response_model['Body'].read().decode(\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "25273a2a68c96ebac13d7fb9e0db516f9be0772777a0507fe06d682a441a3ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
