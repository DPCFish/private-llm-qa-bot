{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ee6c40-08be-4b92-ab3d-62e86c469d31",
   "metadata": {},
   "source": [
    "### 1. 安装HuggingFace 并下载模型到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32010331-b995-4c8d-938f-7739424a27d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface-hub -Uqq\n",
    "!pip install -Uqq sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94673be-6e5a-4c89-a402-60dc571277a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "local_model_path = Path(\"./baichuan2_13b_model\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.model\", \"*.py\", \"*.txt\"]\n",
    "model_name = \"baichuan-inc/Baichuan2-13B-Chat\"\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349623c1-3817-47de-ac8f-9055cc665359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb861c-35ba-4324-8e3e-abdd6b905de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model_prefix = \"LLM-RAG/workshop/baichuan2_13b_vllm_model\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = ''\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    model_snapshot_path = f'{local_model_path}/{model_name}'\n",
    "else:\n",
    "    model_snapshot_path = list(local_model_path.glob(\"**/snapshots/*\"))[0]\n",
    "s3_code_prefix = \"LLM-RAG/workshop/baichuan2_13b_model_deploy_code\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d61522-1083-4aef-89c8-4b2bdfa4b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {model_snapshot_path}/tokenization_baichuan.py\n",
    "!cp -f tokenization_baichuan.py {model_snapshot_path}/tokenization_baichuan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507b91b-6e0b-4e92-b97f-f2381139eefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381c4b2-18d5-4a5f-bc5c-2824257e4957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"option.model_id ==> s3://{bucket}/{s3_model_prefix}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8107e528-a504-45f4-bb73-ecab8afb0ea8",
   "metadata": {},
   "source": [
    "### 3. 模型部署准备（entrypoint脚本，容器镜像，服务配置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307dffff-9c8c-447a-9145-98f2a3aa939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-deepspeed\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.25.0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307b1f3-d2c8-4178-a8f6-35abc54294d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p baichuan2_13b_model_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e01142-9abd-4dda-863a-f293e01c311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"baichuan2_13b_model_deploy_code\"):\n",
    "    os.mkdir(\"baichuan2_13b_model_deploy_code\")\n",
    "\n",
    "with open('baichuan2_13b_model_deploy_code/serving.properties', 'w') as f:\n",
    "    f.write(\"engine=Python\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(f\"option.model_id=s3://{bucket}/{s3_model_prefix}/\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.task=text-generation\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.trust_remote_code=true\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.tensor_parallel_degree=4\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.rolling_batch=vllm\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.dtype=fp16\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"option.enable_streaming=true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36107d-9057-4397-8cfa-9cb3178aeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm model.tar.gz\n",
    "!cd baichuan2_13b_model_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf model.tar.gz baichuan2_13b_model_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0b812-9845-45f6-8e3c-772df7b2399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c11e7a-7e74-45da-a793-97890dde10b8",
   "metadata": {},
   "source": [
    "### 4. 创建模型 & 创建endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edc4d0a-83fb-4590-94bb-64bf5de17f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(f\"baichuan2-13b\") # Note: Need to specify model_name\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f723731b-0672-4a48-abb5-120efcada035",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "#Note: ml.g4dn.2xlarge 也可以选择\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.g4dn.12xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 15*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca05dd-178a-4b0b-b863-0ce8f7deea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98d05b1-daea-4d55-b0d7-403e18a9455e",
   "metadata": {},
   "source": [
    "#### 持续检测模型部署进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9968011-f9e8-4ff8-8cca-380ac85e4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b30e7-efdd-4743-a9f6-e3e8e827109b",
   "metadata": {},
   "source": [
    "### 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffee4f3-011a-4cf1-b9ce-ab1667c4088a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "parameters = {\n",
    "  \"max_tokens\": 1024,\n",
    "  \"temperature\": 0.1,\n",
    "  \"top_p\":0.8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e56a0b-17de-41ad-949e-8fb2819a019b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "class StreamScanner:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.buff = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "        \n",
    "    def write(self, content):\n",
    "        self.buff.seek(0, io.SEEK_END)\n",
    "        self.buff.write(content)\n",
    "        \n",
    "    def readlines(self):\n",
    "        self.buff.seek(self.read_pos)\n",
    "        for line in self.buff.readlines():\n",
    "            if line[-1] != b'\\n':\n",
    "                self.read_pos += len(line)\n",
    "                yield line[:-1]\n",
    "                \n",
    "    def reset(self):\n",
    "        self.read_pos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e6e8ab-fbcc-487f-8953-4e8a1bfad9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "prompts1 = \"\"\"\"Human:Here is a list of aimed functions: <api_schemas><api_schema> {\"name\": \"service_availability\", \"description\": \"query the availability of service in specified region\", \"parameters\": {\"type\": \"object\", \"properties\": {\"service\": {\"type\": \"string\", \"description\": \"the AWS service name\"}, \"region\": {\"type\": \"string\", \"description\": \"the AWS region name where the service is located in, for example us-east-1(N.Virginal), us-west-2(Oregon), eu-west-2(London), ap-southeast-1(Singapore)\"}}, \"required\": [\"service\", \"region\"]}}, {\"name\": \"get_contact\", \"description\": \"query the contact person in the 'SSO' organization\", \"parameters\": {\"type\": \"object\", \"properties\": {\"employee\": {\"type\": \"string\", \"description\": \"employee name in the 'SSO' organization\"}, \"role\": {\"type\": \"string\", \"description\": \"employee's role, usually it's Sales, Product Manager, Tech, Program Manager, Leader\"}, \"domain\": {\"type\": \"string\", \"description\": \"Techical domain for the employee，For Example AIML, Analytics, Compute\"}, \"scope\": {\"type\": \"string\", \"description\": \"employee's scope of responsibility. For Sales role, it could be territory like north/east/south/west, For tech role, it could be specific service\"}}, \"required\": [\"service\"]}}, {\"name\": \"QA\", \"description\": \"answer question according to searched relevant content\"} </api_schema></api_schemas> You should follow below examples to choose the corresponding function and params according to user's query <examples> <query>北京region 有没有clean room服务？</query> <output>\"{\\\"func\\\": \\\"service_availability\\\", \\\"parameters\\\": {\\\"service\\\": \\\"clean room\\\", \\\"region\\\": \\\"cn-north-1\\\"}}\"</output> <query>数据治理的GTMS是谁？</query> <output>\"{\\\"func\\\": \\\"get_contact\\\", \\\"param\\\": {\\\"role\\\": \\\"Product Manager\\\", \\\"scope\\\": \\\"Analytics\\\"}}\"</output> <query>Amazon Rekognition 支持哪些图像和视频格式？</query> <output>\"{\\\"func\\\": \\\"QA\\\"}\"</output> <query>怎么看现有的Capacity？</query> <output>\"{\\\"func\\\": \\\"QA\\\"}\"</output> <query>请问Lex是哪位SSA老师负责啊？有个api的问题请教一下</query> <output>\"{\\\"func\\\": \\\"get_contact\\\", \\\"param\\\": {\\\"role\\\": \\\"Tech\\\", \\\"scope\\\": \\\"Lex\\\"}}\"</output> </examples> Assistant:<query>clean room 支持哪些数据源</query> <output>{\"func\":\"\"\"\n",
    "history = []\n",
    "start = time.time()\n",
    "response_model = smr_client.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompts1,\n",
    "                \"parameters\": parameters,\n",
    "                \"history\" : history,\n",
    "                \"stream\": True\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "event_stream = response_model['Body']\n",
    "scanner = StreamScanner()\n",
    "for event in event_stream:\n",
    "    eventJson=event['PayloadPart']['Bytes'].decode('utf-8')\n",
    "    output=(eventJson)\n",
    "    print(output)\n",
    "    # scanner.write(event['PayloadPart']['Bytes'])\n",
    "    # for line in scanner.readlines():\n",
    "    #     try:\n",
    "    #         print(line)\n",
    "    #         # resp = json.loads(line)\n",
    "    #         # print(resp)\n",
    "    #         # print(resp.get(\"outputs\")['outputs'], end='')\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "    #         # print(line)\n",
    "    #         continue\n",
    "print (f\"time:{time.time()-start} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
