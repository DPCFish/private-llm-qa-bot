{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637e56b-df20-4b45-9629-3e4be08464ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566e7f2-8687-41dc-8855-c767498235a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U boto3 botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8985fc6-f77f-451b-8ebe-88e2c13281dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.30.2\n",
    "!pip install accelerate -U\n",
    "!pip install sentencepiece -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5904d8-07a8-485a-8419-0073b5a57c96",
   "metadata": {},
   "source": [
    "# 加载embedding 模型的tokenizer，用于计算token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c1207e-3b60-4754-9a64-79f3bf9271b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e8a37-bbbc-4e15-8ad8-7cf37a15cd66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd617f2-137b-47b1-8aa5-6b0ceb7e2350",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Option1: 用本地Sagemaker模型进行增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141dadd5-7bc1-4a68-922a-98b9489ec9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "parameters = {\n",
    "  \"max_length\": 4096,\n",
    "  \"top_p\":1,\n",
    "    \"temperature\":0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92beab-36c9-4299-8703-497dfe45d646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "class StreamScanner:\n",
    "    \"\"\"\n",
    "    A helper class for parsing the InvokeEndpointWithResponseStream event stream. \n",
    "    \n",
    "    The output of the model will be in the following format:\n",
    "    ```\n",
    "    b'{\"outputs\": [\" a\"]}\\n'\n",
    "    b'{\"outputs\": [\" challenging\"]}\\n'\n",
    "    b'{\"outputs\": [\" problem\"]}\\n'\n",
    "    ...\n",
    "    ```\n",
    "    \n",
    "    While usually each PayloadPart event from the event stream will contain a byte array \n",
    "    with a full json, this is not guaranteed and some of the json objects may be split across\n",
    "    PayloadPart events. For example:\n",
    "    ```\n",
    "    {'PayloadPart': {'Bytes': b'{\"outputs\": '}}\n",
    "    {'PayloadPart': {'Bytes': b'[\" problem\"]}\\n'}}\n",
    "    ```\n",
    "    \n",
    "    This class accounts for this by concatenating bytes written via the 'write' function\n",
    "    and then exposing a method which will return lines (ending with a '\\n' character) within\n",
    "    the buffer via the 'readlines' function. It maintains the position of the last read \n",
    "    position to ensure that previous bytes are not exposed again. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.buff = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "        \n",
    "    def write(self, content):\n",
    "        self.buff.seek(0, io.SEEK_END)\n",
    "        self.buff.write(content)\n",
    "        \n",
    "    def readlines(self):\n",
    "        self.buff.seek(self.read_pos)\n",
    "        for line in self.buff.readlines():\n",
    "            if line[-1] != b'\\n':\n",
    "                self.read_pos += len(line)\n",
    "                yield line[:-1]\n",
    "                \n",
    "    def reset(self):\n",
    "        self.read_pos = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd0e1a-90a8-469f-9a03-410f8362be90",
   "metadata": {},
   "source": [
    "### 需要填入对于的sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529b6f0f-0c2f-432e-908f-deb4e9f34785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name='qwen-stream-int4-2023-08-31-02-25-35-582-endpoint'\n",
    "\n",
    "def call_llm(prompt,endpoint_name=endpoint_name,parameters=parameters):\n",
    "    response_model = smr_client.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": parameters,\n",
    "                \"history\" : [],\n",
    "                \"stream\":True\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "    event_stream = response_model['Body']\n",
    "    scanner = StreamScanner()\n",
    "    text = ''\n",
    "    for event in event_stream:\n",
    "        scanner.write(event['PayloadPart']['Bytes'])\n",
    "        for line in scanner.readlines():\n",
    "            try:\n",
    "                resp = json.loads(line)\n",
    "                print(resp.get(\"outputs\")['outputs'], end='')\n",
    "                text +=resp.get(\"outputs\")['outputs']\n",
    "            except Exception as e:\n",
    "                # print(line)\n",
    "                continue\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d2979-4b03-41a6-8c71-9ac4246ee4e3",
   "metadata": {},
   "source": [
    "# Option 2: 用Chatgpt3.5，添加api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5fd49d-f10d-45b6-bfc2-449b9c851efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,json\n",
    "import openai\n",
    "openai.api_key = ''\n",
    "\n",
    "\n",
    "def call_llm(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message['content']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db3666e-a093-4ce9-8eae-b16e35af943d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 创建结果格式化解析（本地部署模型，输出结果的格式不太稳定，需要格式化，如果使用ChatGPT不需要这个解析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21368031-111a-401c-9476-c5c0a2155b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "##example cases\n",
    "#line1 = '问题1:我在游戏中怎么查看当前升级所需要的经验？ 回答1: 15级解锁神奇宝玩家可以点击左上角查看当前升级所需要的经验。'\n",
    "#line2 = '问题1:我在游戏中怎么查看当前升级所需要的经验？'\n",
    "#line3 = '回答1: 充值可以让玩家获得更多的游戏内物品和特权，如游戏道具、游戏时间等。它们可以帮助玩家更快地提高游戏水平和游戏体验。'\n",
    "#line4 = '问题1: 12我在游戏中遇到了其他玩家的不当言论，应该怎样举报？ 回答1: 如果在游戏中遇到其他玩家不当言论的情况，可以在聊天框点击对方的头像选择举报或者联系客服提供聊天截图进行举报（建议同时点击对方头像选择屏蔽）。 问题2: 举报需要提供哪些信息？ 回答2: 举报时需要提供相关的聊天截图以及被举报者的账号信息，以确保举报的有效性。希望以上回答能够帮助您更好地了解如何举报。'\n",
    "pattern_1 = re.compile(r'(问题\\d*:[^回答:]*)(回答\\d*:[^问题:]*)',re.I)\n",
    "pattern_2 = re.compile(r'问题\\d*:[^回答:]*',re.I)\n",
    "pattern_3 = re.compile(r'回答\\d*:[^问题:].*',re.I)\n",
    "\n",
    "def parse_response(response):\n",
    "    new_data = []\n",
    "    qna = []\n",
    "    for line in response.split('\\n'):\n",
    "        \n",
    "        groups = pattern_1.findall(line)\n",
    "        for question,answer in groups: ##如果问题和答案在一行\n",
    "            question = re.sub(r'^问题\\d*:','',question)\n",
    "            answer = re.sub(r'^回答\\d*:','',answer)\n",
    "            new_data.append((question,answer))\n",
    "            \n",
    "        if not len(groups): ##如果问题和答案是分行\n",
    "            groups_q = pattern_2.match(line)\n",
    "            groups_a = pattern_3.match(line)\n",
    "            if groups_q:\n",
    "                question = re.sub(r'^问题\\d*:','',groups_q[0])\n",
    "                qna.append(question)\n",
    "            elif groups_a:\n",
    "                answer = re.sub(r'^回答\\d*:','',groups_a[0])\n",
    "                qna.append(answer)\n",
    "            if len(qna) == 2:\n",
    "                new_data.append((qna[0],qna[1]))\n",
    "                qna = []\n",
    "                \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec357342-583f-4393-a725-d6b2bf4c59ea",
   "metadata": {},
   "source": [
    "# 读取原始FAQ文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804028b-52a0-46f9-80de-82104f492ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "origin_faqfilename = \"topwar_faq/topwarfaq230908.faq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c507a3-8bf9-41e1-9dfb-b6b0b41f963b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def parse_faq(file_content,QA_SEP='====='):\n",
    "    arr = file_content.split(QA_SEP)\n",
    "    list_arr = []\n",
    "    for item in arr:\n",
    "        # print(item)\n",
    "        try:\n",
    "            question, answer = item.strip().split(\"\\n\", 1)\n",
    "            question = question.replace(\"Question: \", \"\")\n",
    "            answer = answer.replace(\"Answer: \", \"\")\n",
    "            list_arr.append((answer.strip(),question.strip()))\n",
    "        except:\n",
    "            pass\n",
    "    return list_arr\n",
    "\n",
    "\n",
    "all_data = []\n",
    "with open(origin_faqfilename) as f:\n",
    "        data = f.read()\n",
    "        all_data += parse_faq(data)\n",
    "        \n",
    "print(f\"data size:{len(all_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6bcbee-38a3-4891-b83c-af1d3d32f6e1",
   "metadata": {},
   "source": [
    "####  如果用chat gpt，可以直接使用以下模板\n",
    "```python\n",
    "prompt = f\"\"\"\n",
    "如下三个反引号中是《口袋奇兵》游戏的相关知识信息, 请基于这部分知识信息生成{nums}的问题以及对应答案\n",
    "```\n",
    "{context}\n",
    "```\n",
    "要求尽可能详细全面, 并且遵循如下规则:\n",
    "1. 生成的内容不要超出反引号中信息的范围\n",
    "2. 问题部分需要以\"Question:\"开始\n",
    "3. 答案部分需要以\"Answer:\"开始\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911cc24-3e5c-476c-96e2-b3f0b105baf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math,time\n",
    "\n",
    "newfaq_filename = 'docs/topwar_enrich_faq_0911.faq'\n",
    "\n",
    "def generate_query(new_data,alldata,tokenizer):\n",
    "    faqtext = ''\n",
    "    for i, (answer, query) in enumerate (alldata):\n",
    "        context = f\"问:{query}\\n答:{answer}\"\n",
    "        tokens = len(tokenizer(context)['input_ids'])\n",
    "        nums =  math.ceil(tokens/40)\n",
    "        \n",
    "        ##如果用chat gpt，可以直接使用以下模板\n",
    "        # prompt = f\"\"\"\n",
    "        # 如下三个反引号中是《口袋奇兵》游戏的相关知识信息, 请基于这部分知识信息生成{nums}的问题以及对应答案\n",
    "        # ```\n",
    "        # {context}\n",
    "        # ```\n",
    "        # 要求尽可能详细全面, 并且遵循如下规则:\n",
    "        # 1. 生成的内容不要超出反引号中信息的范围\n",
    "        # 2. 问题部分需要以\"Question:\"开始\n",
    "        # 3. 答案部分需要以\"Answer:\"开始\n",
    "        # \"\"\"\n",
    "        prompt= f\"请根据以下内容生成{nums}个独立的新问题和对应问题的回答\\n ```\\n{context}\\n```，问题和回答使用一对一的形式展示,问题的语气模拟你是一个游戏玩家，例如:\\n问题1: \\n回答1:\\n\\n问题2:\\n回答2:\\n\\n\"\n",
    "        print (f\"\\n-------[{i}]-----Origin FAQ--------\\n\")\n",
    "        print (context)\n",
    "        print (f\"\\n-------[{i}]-----New FAQ--------\\n\")\n",
    "        response = call_llm_sagemaker(prompt)\n",
    "        parsed_qa = parse_response(response)\n",
    "        \n",
    "        for q,a in parsed_qa:\n",
    "            faqtext+=f\"Question: {q}\\nAnswer: {a}\\n=====\\n\"\n",
    "        with open(newfaq_filename,\"w\") as f:\n",
    "            f.write(faqtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc812755-d39c-4676-9f00-f9ad8217dfba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 开始合成faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a8f14c-5fd3-4ec0-b742-502b79447826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_query(newdata,all_data,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecebc9-29b3-40f1-a5ad-7c14b72c86c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 把一些不完整的FAQ去除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851a6abe-4dfe-4e00-97d6-28d64f979716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def postprocess_faq(file_content,QA_SEP='====='):\n",
    "    arr = file_content.split(QA_SEP)\n",
    "    faqtext = ''\n",
    "    for item in arr:\n",
    "        try:\n",
    "            question, answer = item.strip().split(\"\\n\", 1)\n",
    "            question = question.replace(\"Question:\", \"\").strip()\n",
    "            answer = answer.replace(\"Answer:\", \"\").strip()\n",
    "            if question != '' and answer != '':\n",
    "                faqtext+=f\"Question: {question}\\nAnswer: {answer}\\n=====\\n\"\n",
    "        except:\n",
    "            pass\n",
    "    return faqtext[:-6]\n",
    "\n",
    "\n",
    "cleaned_new_faq = None\n",
    "with open(newfaq_filename,\"r\") as f:\n",
    "    cleaned_new_faq = postprocess_faq(f.read())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1148d-bfe3-4540-af3b-0c751035e500",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 保存最终的FAQ文件，下一步可以导出再由人工审核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e451a4d-0e1d-4cac-bebb-55b7e995c462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_filename = 'docs/cleaned_topwar_enrich_faq_0911.faq'\n",
    "with open(cleaned_filename,\"w\") as f:\n",
    "    f.write(cleaned_new_faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b14b9-42ef-4efc-b456-f9b5957fbf81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cleaned_new_faq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a101f-898c-47ba-9d52-80f345fa985b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
