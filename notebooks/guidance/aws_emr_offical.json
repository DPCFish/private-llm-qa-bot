{"origin_question": "什么是 Amazon EMR？\n", "origin_answer": "Amazon EMR 是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。借助 EMR，您可以用不到传统本地解决方案一半的成本运行 PB 级分析，并且其速度比标准 Apache Spark 快 1.7 倍以上。", "generate_question": "Amazon EMR适用于哪些开源框架进行数据处理、交互分析和机器学习？", "generate_answer": "Amazon EMR适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。"}
{"origin_question": "什么是 Amazon EMR？\n", "origin_answer": "Amazon EMR 是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。借助 EMR，您可以用不到传统本地解决方案一半的成本运行 PB 级分析，并且其速度比标准 Apache Spark 快 1.7 倍以上。", "generate_question": "通过使用Amazon EMR，可以以什么样的成本运行PB级分析？", "generate_answer": "通过使用Amazon EMR，可以用不到传统本地解决方案一半的成本运行PB级分析。"}
{"origin_question": "什么是 Amazon EMR？\n", "origin_answer": "Amazon EMR 是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。借助 EMR，您可以用不到传统本地解决方案一半的成本运行 PB 级分析，并且其速度比标准 Apache Spark 快 1.7 倍以上。", "generate_question": "Amazon EMR相比标准Apache Spark有什么优势？", "generate_answer": "Amazon EMR相比标准Apache Spark的速度更快，快速度比标准Apache Spark快1.7倍以上。"}
{"origin_question": "什么是 Amazon EMR？\n", "origin_answer": "Amazon EMR 是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如 Apache Spark、Apache Hive、Presto。借助 EMR，您可以用不到传统本地解决方案一半的成本运行 PB 级分析，并且其速度比标准 Apache Spark 快 1.7 倍以上。", "generate_question": "什么是Amazon EMR？", "generate_answer": "Amazon EMR是行业领先的云大数据平台，适用于使用多种开源框架进行数据处理、交互分析和机器学习，例如Apache Spark、Apache Hive、Presto。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "Amazon EMR有什么优势？", "generate_answer": "Amazon EMR可以让用户专注于数据转换和分析，而无需担心计算能力或开源应用程序的管理。此外，使用EMR可以节省资金，并且可以根据需要预置任意大小的计算容量。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "如何管理不断变化的计算需求？", "generate_answer": "使用Amazon EMR，可以设置扩展规则来管理不断变化的计算需求。用户可以在Amazon EC2上立即预置任意大小的容量，并且可以设置CloudWatch警报，以便在基础设施发生变化时及时收到通知并采取行动。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "Amazon EMR是否支持将工作负载提交到Amazon EKS集群？", "generate_answer": "是的，如果用户使用Kubernetes，可以使用Amazon EMR将工作负载提交到Amazon EKS集群。用户可以从EMR优化的运行时中获益，以加快分析速度并节省时间和资金。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "Amazon EMR如何加快分析速度？", "generate_answer": "Amazon EMR提供了优化的运行时，可以加快分析速度。用户可以在使用Amazon EC2或Amazon EKS时从这些优化的运行时中受益。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "Amazon EMR适用于哪些场景？", "generate_answer": "Amazon EMR适用于需要进行数据转换和分析的场景。它可以帮助用户管理计算能力和开源应用程序，并且可以根据需要预置任意大小的计算容量。"}
{"origin_question": "\n为什么应该使用 Amazon EMR？\n", "origin_answer": "通过 Amazon EMR，您可以专注于数据转换和分析，而不必操心管理计算能力或开源应用程序，并且还能节省资金。使用 EMR，您可以立即在 Amazon EC2 上预置任意大小的容量，并设置扩展规则来管理不断变化的计算需求。您可以设置 CloudWatch 警报，以便在基础设施发生变化时可以立即收到通知并采取行动。如果您使用 Kubernetes，还可以使用 EMR 将您的工作负载提交到 Amazon EKS 集群。无论您使用 EC2 还是 EKS，都可以从 EMR 优化的运行时中获益，以便加快您的分析速度，并节省时间和资金。", "generate_question": "Amazon EMR适用于哪些云计算服务？", "generate_answer": "Amazon EMR适用于Amazon EC2和Amazon EKS。用户可以根据自己的需求选择使用EC2还是EKS，并从EMR的优化运行时中获益，以加快分析速度并节省时间和资金。"}
{"origin_question": "\n如何开始使用 Amazon EMR？\n", "origin_answer": "要注册 Amazon EMR，请单击 Amazon EMR 详细信息页面 http://aws.amazon.com/emr 中的“立即注册”按钮。您必须注册 Amazon EC2 和 Amazon S3 才能访问 Amazon EMR；如果您尚未注册这些服务，在 Amazon EMR 注册过程中系统将会提示您进行注册。注册后，请参阅 Amazon EMR 文档，其中包括我们的“入门指南”，能够很好地协助您开始使用此服务。", "generate_question": "如何注册 Amazon EMR？", "generate_answer": "要注册 Amazon EMR，您需要单击 Amazon EMR 详细信息页面 http://aws.amazon.com/emr 中的“立即注册”按钮。在注册过程中，系统会提示您注册 Amazon EC2 和 Amazon S3，因为这些服务是访问 Amazon EMR 的先决条件。"}
{"origin_question": "\n如何开始使用 Amazon EMR？\n", "origin_answer": "要注册 Amazon EMR，请单击 Amazon EMR 详细信息页面 http://aws.amazon.com/emr 中的“立即注册”按钮。您必须注册 Amazon EC2 和 Amazon S3 才能访问 Amazon EMR；如果您尚未注册这些服务，在 Amazon EMR 注册过程中系统将会提示您进行注册。注册后，请参阅 Amazon EMR 文档，其中包括我们的“入门指南”，能够很好地协助您开始使用此服务。", "generate_question": "需要注册哪些服务才能访问 Amazon EMR？", "generate_answer": "要访问 Amazon EMR，您需要注册 Amazon EC2 和 Amazon S3。在注册 Amazon EMR 过程中，系统会提示您注册这些服务。"}
{"origin_question": "\n如何开始使用 Amazon EMR？\n", "origin_answer": "要注册 Amazon EMR，请单击 Amazon EMR 详细信息页面 http://aws.amazon.com/emr 中的“立即注册”按钮。您必须注册 Amazon EC2 和 Amazon S3 才能访问 Amazon EMR；如果您尚未注册这些服务，在 Amazon EMR 注册过程中系统将会提示您进行注册。注册后，请参阅 Amazon EMR 文档，其中包括我们的“入门指南”，能够很好地协助您开始使用此服务。", "generate_question": "注册后如何开始使用 Amazon EMR？", "generate_answer": "注册后，您可以参阅 Amazon EMR 文档，其中包括“入门指南”，该指南将帮助您开始使用 Amazon EMR。您可以在 Amazon EMR 文档中找到详细的使用说明和操作指南。"}
{"origin_question": "\n如何开始使用 Amazon EMR？\n", "origin_answer": "要注册 Amazon EMR，请单击 Amazon EMR 详细信息页面 http://aws.amazon.com/emr 中的“立即注册”按钮。您必须注册 Amazon EC2 和 Amazon S3 才能访问 Amazon EMR；如果您尚未注册这些服务，在 Amazon EMR 注册过程中系统将会提示您进行注册。注册后，请参阅 Amazon EMR 文档，其中包括我们的“入门指南”，能够很好地协助您开始使用此服务。", "generate_question": "Amazon EMR 的入门指南有哪些内容？", "generate_answer": "Amazon EMR 的入门指南包括了使用此服务的详细说明和操作指南。您可以在 Amazon EMR 文档中找到入门指南，该指南将协助您开始使用 Amazon EMR。"}
{"origin_question": "\nAmazon EMR 的可靠性如何？\n", "origin_answer": "请参阅我们的 服务等级协议。", "generate_question": "亚马逊云科技的服务等级协议中包含哪些内容？", "generate_answer": "亚马逊云科技的服务等级协议中包含了关于服务可用性、故障处理时间、故障补偿等方面的具体规定。"}
{"origin_question": "\n可以在哪里找到示例代码？\n", "origin_answer": "有关示例代码，请参阅这些文章和教程。如果您使用 EMR Studio，则可以使用一组笔记本示例探索这些功能。", "generate_question": "如何找到亚马逊云科技的示例代码？", "generate_answer": "您可以在相关的文章和教程中找到亚马逊云科技的示例代码。如果您使用 EMR Studio，则可以在一组笔记本示例中探索这些功能。"}
{"origin_question": "\n可以在哪里找到示例代码？\n", "origin_answer": "有关示例代码，请参阅这些文章和教程。如果您使用 EMR Studio，则可以使用一组笔记本示例探索这些功能。", "generate_question": "亚马逊云科技的示例代码可以在哪个平台上使用？", "generate_answer": "亚马逊云科技的示例代码可以在 EMR Studio 平台上使用。您可以通过使用一组笔记本示例来探索这些功能。"}
{"origin_question": "\n如何开发数据处理应用程序？\n", "origin_answer": "您可以在 Amazon EMR Studio 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在桌面上开发数据处理作业，例如，使用 Eclipse、Spyder、PyCharm 或 RStudio，并在 Amazon EMR 上运行。此外，您可以在启动新集群时在软件配置中选择 JupyterHub 或 Zeppelin，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。\n", "generate_question": "在哪些编程语言中可以开发数据处理应用程序？", "generate_answer": "您可以在 R、Python、Scala 和 PySpark 中开发数据科学和数据工程应用程序。"}
{"origin_question": "\n如何开发数据处理应用程序？\n", "origin_answer": "您可以在 Amazon EMR Studio 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在桌面上开发数据处理作业，例如，使用 Eclipse、Spyder、PyCharm 或 RStudio，并在 Amazon EMR 上运行。此外，您可以在启动新集群时在软件配置中选择 JupyterHub 或 Zeppelin，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。\n", "generate_question": "在哪些工具中可以开发数据处理作业？", "generate_answer": "您可以使用 Eclipse、Spyder、PyCharm 或 RStudio 在桌面上开发数据处理作业，并在 Amazon EMR 上运行。"}
{"origin_question": "\n如何开发数据处理应用程序？\n", "origin_answer": "您可以在 Amazon EMR Studio 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在桌面上开发数据处理作业，例如，使用 Eclipse、Spyder、PyCharm 或 RStudio，并在 Amazon EMR 上运行。此外，您可以在启动新集群时在软件配置中选择 JupyterHub 或 Zeppelin，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。\n", "generate_question": "如何在 Amazon EMR 上开发应用程序？", "generate_answer": "您可以在 Amazon EMR Studio 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在启动新集群时在软件配置中选择 JupyterHub 或 Zeppelin，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。"}
{"origin_question": "\n如何开发数据处理应用程序？\n", "origin_answer": "您可以在 Amazon EMR Studio 中开发、可视化和调试在 R、Python、Scala 和 PySpark 中编写的数据科学和数据工程应用程序。您还可以在桌面上开发数据处理作业，例如，使用 Eclipse、Spyder、PyCharm 或 RStudio，并在 Amazon EMR 上运行。此外，您可以在启动新集群时在软件配置中选择 JupyterHub 或 Zeppelin，并使用一个或多个实例在 Amazon EMR 上开发您的应用程序。\n", "generate_question": "Amazon EMR 提供了哪些开发环境？", "generate_answer": "Amazon EMR 提供了 Amazon EMR Studio、Eclipse、Spyder、PyCharm、RStudio、JupyterHub 和 Zeppelin 等开发环境供您开发数据处理应用程序。"}
{"origin_question": "\n相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？\n", "origin_answer": "命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。", "generate_question": "使用命令行工具或 API相对于AWS管理控制台有哪些优势？", "generate_answer": "使用命令行工具或 API可以以编程方式启动和监控群集的运行进度，还可以围绕群集创建更多自定义的功能，例如对多个处理步骤排序、计划、工作流或监控，或为其他Amazon EMR客户构建增值工具或应用程序。"}
{"origin_question": "\n相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？\n", "origin_answer": "命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。", "generate_question": "AWS管理控制台相对于命令行工具或 API有什么优势？", "generate_answer": "AWS管理控制台提供易用的图形界面，可以直接从Web浏览器启动和监控群集，对于不熟悉命令行工具或 API的用户来说更加方便。"}
{"origin_question": "\n相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？\n", "origin_answer": "命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。", "generate_question": "使用命令行工具或 API可以实现哪些功能？", "generate_answer": "使用命令行工具或 API可以以编程方式启动和监控群集的运行进度，还可以围绕群集创建更多自定义的功能，例如对多个处理步骤排序、计划、工作流或监控，或为其他Amazon EMR客户构建增值工具或应用程序。"}
{"origin_question": "\n相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？\n", "origin_answer": "命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。", "generate_question": "使用命令行工具或 API可以为其他Amazon EMR客户构建什么样的增值工具或应用程序？", "generate_answer": "使用命令行工具或 API可以为其他Amazon EMR客户构建增值工具或应用程序，例如可以创建用于监控群集运行进度的工具，或者创建用于自动化处理步骤的应用程序。"}
{"origin_question": "\n相对于 AWS 管理控制台，使用命令行工具或 API有什么优势？\n", "origin_answer": "命令行工具或 API 能够以编程方式启动和监控群集的运行进度、围绕群集创建更多自定义的功能（例如，对多个处理步骤排序、计划、工作流或监控）或为其他 Amazon EMR 客户构建增值工具或应用程序。相比而言，AWS 管理控制台提供易用的图形界面，可以直接从 Web 浏览器启动和监控群集。", "generate_question": "AWS管理控制台可以直接从哪里启动和监控群集？", "generate_answer": "AWS管理控制台可以直接从Web浏览器启动和监控群集，提供了易用的图形界面。"}
{"origin_question": "\n是否可向已在运行的群集添加步骤？\n", "origin_answer": "可以。任务运行后，您可以通过 AddJobFlowSteps API 选择性地添加更多步骤。AddJobFlowSteps API 将向当前的步骤序列结尾添加新的步骤。您可以使用此 API 在集群中执行条件逻辑或进行调试。\n", "generate_question": "如何向已在运行的群集添加步骤？", "generate_answer": "您可以使用 AddJobFlowSteps API 来向已在运行的群集添加步骤。这个 API 可以在当前的步骤序列结尾添加新的步骤，从而实现向群集中添加更多的任务。"}
{"origin_question": "\n是否可向已在运行的群集添加步骤？\n", "origin_answer": "可以。任务运行后，您可以通过 AddJobFlowSteps API 选择性地添加更多步骤。AddJobFlowSteps API 将向当前的步骤序列结尾添加新的步骤。您可以使用此 API 在集群中执行条件逻辑或进行调试。\n", "generate_question": "在任务运行后可以添加哪些类型的步骤？", "generate_answer": "在任务运行后，您可以选择性地添加各种类型的步骤。您可以使用 AddJobFlowSteps API 来添加新的步骤，从而在集群中执行条件逻辑或进行调试。"}
{"origin_question": "\n是否可向已在运行的群集添加步骤？\n", "origin_answer": "可以。任务运行后，您可以通过 AddJobFlowSteps API 选择性地添加更多步骤。AddJobFlowSteps API 将向当前的步骤序列结尾添加新的步骤。您可以使用此 API 在集群中执行条件逻辑或进行调试。\n", "generate_question": "AddJobFlowSteps API 是用来做什么的？", "generate_answer": "AddJobFlowSteps API 是用来向已在运行的群集中添加步骤的。通过调用这个 API，您可以在任务运行后选择性地添加更多的步骤，以实现在集群中执行条件逻辑或进行调试的目的。"}
{"origin_question": "\n当集群完成时，我是否会收到通知？\n", "origin_answer": "您可以注册 Amazon SNS，让集群在完成后向您发布 SNS 主题。您还可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。\n", "generate_question": "如何让集群在完成时向我发布通知？", "generate_answer": "您可以注册 Amazon SNS，让集群在完成后向您发布 SNS 主题。"}
{"origin_question": "\n当集群完成时，我是否会收到通知？\n", "origin_answer": "您可以注册 Amazon SNS，让集群在完成后向您发布 SNS 主题。您还可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。\n", "generate_question": "除了使用 Amazon SNS，还有其他方式可以获取集群完成的通知吗？", "generate_answer": "您可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。"}
{"origin_question": "\n当集群完成时，我是否会收到通知？\n", "origin_answer": "您可以注册 Amazon SNS，让集群在完成后向您发布 SNS 主题。您还可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。\n", "generate_question": "集群完成后，我可以通过哪些方式获取集群的状态？", "generate_answer": "您可以在 AWS 管理控制台上查看集群进度，或者使用命令行、软件开发工具包或者 API 获取集群的状态。"}
{"origin_question": "\n完成步骤后可以终止集群吗？\n", "origin_answer": "可以。可以通过启动自动终止标志，在完成所有步骤后自动终止集群。\n", "generate_question": "如何设置自动终止标志来在完成所有步骤后自动终止集群？", "generate_answer": "可以通过在集群配置中设置自动终止标志来实现，在完成所有步骤后集群会自动终止。"}
{"origin_question": "\n完成步骤后可以终止集群吗？\n", "origin_answer": "可以。可以通过启动自动终止标志，在完成所有步骤后自动终止集群。\n", "generate_question": "集群终止后是否可以重新启动？", "generate_answer": "是的，集群终止后可以重新启动。可以通过重新启动集群来继续进行后续的操作。"}
{"origin_question": "\nAmazon EMR 支持哪些操作系统版本？\n", "origin_answer": "Amazon EMR 5.30.0 及更高版本，以及 Amazon EMR 6.x 系列基于 Amazon Linux 2。您也可以指定一个基于 Amazon Linux 2 创建的自定义 AMI。这让您可以为几乎任何应用程序执行复杂的预配置。有关更多信息，请参阅使用自定义 AMI。", "generate_question": "Amazon EMR 支持哪些操作系统版本？", "generate_answer": "Amazon EMR 5.30.0 及更高版本，以及 Amazon EMR 6.x 系列基于 Amazon Linux 2。"}
{"origin_question": "\nAmazon EMR 支持哪些操作系统版本？\n", "origin_answer": "Amazon EMR 5.30.0 及更高版本，以及 Amazon EMR 6.x 系列基于 Amazon Linux 2。您也可以指定一个基于 Amazon Linux 2 创建的自定义 AMI。这让您可以为几乎任何应用程序执行复杂的预配置。有关更多信息，请参阅使用自定义 AMI。", "generate_question": "可以使用哪个版本的 Amazon EMR 创建自定义 AMI？", "generate_answer": "您可以使用基于 Amazon Linux 2 创建的自定义 AMI。"}
{"origin_question": "\nAmazon EMR 支持哪些操作系统版本？\n", "origin_answer": "Amazon EMR 5.30.0 及更高版本，以及 Amazon EMR 6.x 系列基于 Amazon Linux 2。您也可以指定一个基于 Amazon Linux 2 创建的自定义 AMI。这让您可以为几乎任何应用程序执行复杂的预配置。有关更多信息，请参阅使用自定义 AMI。", "generate_question": "使用自定义 AMI 可以实现什么功能？", "generate_answer": "使用自定义 AMI 可以为几乎任何应用程序执行复杂的预配置。"}
{"origin_question": "\nAmazon EMR 是否支持第三方软件包？\n", "origin_answer": "是。 您可以使用引导操作在集群中安装第三方软件包。此外，也可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。EMR 6.x 支持 Hadoop 3，它允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。要了解更多信息，请参阅我们的文档。\n", "generate_question": "Amazon EMR 支持哪些版本的 Hadoop？", "generate_answer": "Amazon EMR 6.x 支持 Hadoop 3。"}
{"origin_question": "\nAmazon EMR 是否支持第三方软件包？\n", "origin_answer": "是。 您可以使用引导操作在集群中安装第三方软件包。此外，也可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。EMR 6.x 支持 Hadoop 3，它允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。要了解更多信息，请参阅我们的文档。\n", "generate_question": "如何在 Amazon EMR 集群中安装第三方软件包？", "generate_answer": "您可以使用引导操作在集群中安装第三方软件包。"}
{"origin_question": "\nAmazon EMR 是否支持第三方软件包？\n", "origin_answer": "是。 您可以使用引导操作在集群中安装第三方软件包。此外，也可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。EMR 6.x 支持 Hadoop 3，它允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。要了解更多信息，请参阅我们的文档。\n", "generate_question": "Amazon EMR 是否支持上传静态编译的可执行文件？", "generate_answer": "是的，您可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。"}
{"origin_question": "\nAmazon EMR 是否支持第三方软件包？\n", "origin_answer": "是。 您可以使用引导操作在集群中安装第三方软件包。此外，也可以使用 Hadoop 分布式缓存机制上传静态编译的可执行文件。EMR 6.x 支持 Hadoop 3，它允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。要了解更多信息，请参阅我们的文档。\n", "generate_question": "在 EMR 6.x 中，YARN NodeManager 是如何启动容器的？", "generate_answer": "EMR 6.x 允许 YARN NodeManager 直接在 EMR 集群主机上或 Docker 容器内启动容器。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "如何使用 Amazon EMR studio 进行调试？", "generate_answer": "您可以使用 Amazon EMR studio 启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可以访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "Amazon EMR 控制台提供了哪些调试工具？", "generate_answer": "Amazon EMR 控制台提供了 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的应用程序历史记录的摘要视图。您可以使用这些工具来收集有关集群的信息，以帮助确定问题所在。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "如何通过 Amazon EMR 控制台访问集群实例？", "generate_answer": "您可以使用 SSH 连接主节点，并通过 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的应用程序历史记录的摘要视图来查看集群实例。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "有哪些工具可以帮助我确定集群问题所在？", "generate_answer": "您可以使用 Amazon EMR studio 启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。此外，Amazon EMR 控制台还提供了 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的应用程序历史记录的摘要视图，这些工具可以帮助您收集有关集群的信息。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "我可以从 Amazon EMR 控制台中访问哪些应用程序的用户界面？", "generate_answer": "从 Amazon EMR 控制台，您可以访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的应用程序历史记录的摘要视图。"}
{"origin_question": "\n我可以使用哪些工具进行调试？\n", "origin_answer": "您可以使用多种工具来收集有关集群的信息，以帮助确定问题所在。如果您使用 Amazon EMR studio，则可以启动 Spark UI 和 YARN Timeline Service 等工具来简化调试。从 Amazon EMR 控制台，您可脱离集群访问 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的 Amazon EMR 控制台中应用程序历史记录的摘要视图。您还可以使用 SSH 连接主节点，并通过这些 Web 界面查看集群实例。有关更多信息，请参阅我们的文档。", "generate_question": "如何查看集群实例的信息？", "generate_answer": "您可以使用 SSH 连接主节点，并通过 Apache Spark、Tez UI 和 YARN 时间线服务器的持久性应用程序用户界面、多个集群内应用程序用户界面，以及所有 YARN 应用程序的应用程序历史记录的摘要视图来查看集群实例的信息。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 是用来做什么的？", "generate_answer": "EMR Studio 是一个集成开发环境 (IDE)，用于开发、可视化和调试数据工程和数据科学应用程序。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 支持哪些编程语言？", "generate_answer": "EMR Studio 支持 R、Python、Scala 和 PySpark 这些编程语言。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 是一个完全托管的应用程序吗？", "generate_answer": "是的，EMR Studio 是一个完全托管的应用程序。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 提供了哪些功能？", "generate_answer": "EMR Studio 提供了单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置以及能够在不登录 AWS 控制台或集群的情况下调试作业的功能。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "数据科学家和分析人员可以在 EMR Studio 中安装自定义内核和库吗？", "generate_answer": "是的，数据科学家和分析人员可以在 EMR Studio 中安装自定义内核和库。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 可以与哪些代码库进行协作？", "generate_answer": "EMR Studio 可以与代码库（如 GitHub 和 BitBucket）进行协作。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 可以与哪些编排服务进行集成？", "generate_answer": "EMR Studio 可以与 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务进行集成。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 的内核和应用程序在哪里运行？", "generate_answer": "EMR Studio 的内核和应用程序在 EMR 集群上运行。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "管理员可以如何设置 EMR Studio？", "generate_answer": "管理员可以设置 EMR Studio，使分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。"}
{"origin_question": "\n什么是 EMR Studio？\n", "origin_answer": "EMR Studio 是一个集成开发环境 (IDE)，使数据科学家和数据工程师能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。\n\n它是一个完全托管的应用程序，具有单点登录、完全托管的 Jupyter Notebooks、自动基础设施预置，并且能够在不登录 AWS 控制台或集群的情况下调试作业。数据科学家和分析人员可以安装自定义内核和库，使用代码库（如 GitHub 和 BitBucket）与同事协作，或者使用 Apache Airflow、AWS Step Functions 和 Amazon Managed Workflows for Apache Airflow 等编排服务，将参数化笔记本作为计划工作流的一部分运行。 您可以使用 Amazon MWAA 读取 Amazon EMR 笔记本上的编排分析作业，以了解更多信息。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。管理员可以设置 EMR Studio，以便分析师可以在现有 EMR 集群上运行其应用程序，或使用 EMR 的预定义 AWS CloudFormation 模板创建新集群。\n", "generate_question": "EMR Studio 可以利用什么优势？", "generate_answer": "EMR Studio 可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理的优势。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "什么是 EMR Studio？", "generate_answer": "EMR Studio 是一种完全托管的 Jupyter 笔记本电脑，可以通过企业凭证直接登录，无需登录到 AWS 控制台。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何启动 EMR Studio？", "generate_answer": "您可以通过使用企业凭证直接登录到 EMR Studio，数秒钟即可启动笔记本电脑。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "在 EMR Studio 中可以做什么？", "generate_answer": "在 EMR Studio 中，您可以使用示例笔记本电脑进行数据探查，加载自定义内核和 Python 库来自定义环境，与同事协作通过共享笔记本，将笔记本作为连续集成和部署管道运行，传递不同的参数值给笔记本，将笔记本连接起来并集成到计划工作流中，以及通过本机应用程序界面调试集群和作业。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "EMR Studio 的内核和应用程序在哪里运行？", "generate_answer": "EMR Studio 的内核和应用程序在 EMR 集群上运行。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "在 EMR Studio 中可以利用什么优势？", "generate_answer": "在 EMR Studio 中，您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何与同事协作在 EMR Studio 中？", "generate_answer": "您可以通过从笔记本加载自定义内核和 Python 库来自定义环境，并通过共享笔记本来与同事协作。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何将笔记本作为连续集成和部署管道运行？", "generate_answer": "您可以将笔记本直接作为连续集成和部署管道运行，将其集成到计划工作流中。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何与同事协作使用 EMR Studio？", "generate_answer": "您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何将 EMR Studio 集成到计划工作流中？", "generate_answer": "您可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将 EMR Studio 集成到计划工作流中。"}
{"origin_question": "\nEMR Studio 有什么作用？\n", "origin_answer": "\n借助 EMRStudio，您可以使用企业凭证直接登录到完全托管式 Jupyter 笔记本电脑，而无需登录到 AWS控制台，数秒钟即可启动笔记本电脑，开始使用示例笔记本电脑，并执行数据探查。您还可以通过从笔记本加载自定义内核和 Python 库来自定义环境。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。您可以通过 GitHub 和其他存储库共享笔记本来与同事协作。您还可以将笔记本直接作为连续集成和部署管道运行。您可以将不同的参数值传递给笔记本。您还可以将笔记本连接起来，并使用诸如 Apache Airflow 之类的工作流编排服务将笔记本集成到计划工作流中。此外，您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。", "generate_question": "如何调试集群和作业？", "generate_answer": "您可以通过本机应用程序界面（例如 Spark UI 和 YARN 时间线服务）使用尽可能少的单击来调试集群和作业。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "EMR Studio 和 SageMaker Studio 可以同时与哪个亚马逊服务一起使用？", "generate_answer": "EMR Studio 和 SageMaker Studio 可以同时与 Amazon EMR 一起使用。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "EMR Studio 提供了什么样的集成开发环境？", "generate_answer": "EMR Studio 提供了集成开发环境 (IDE)，可以用于开发、可视化和调试数据工程和数据科学应用程序，使用 R、Python、Scala 和 PySpark 编写。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "SageMaker Studio 提供了什么样的界面？", "generate_answer": "SageMaker Studio 提供了一个基于 Web 的可视化界面，可以执行所有机器学习开发步骤。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "在 SageMaker Studio 中可以做哪些操作？", "generate_answer": "在 SageMaker Studio 中，您可以上传数据、创建新笔记本、训练和调优模型，还可以在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "在 EMR Studio 中可以使用哪些编程语言？", "generate_answer": "在 EMR Studio 中，您可以使用 R、Python、Scala 和 PySpark 这些编程语言。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "EMR Studio 和 SageMaker Studio 有何不同之处？", "generate_answer": "EMR Studio 提供了集成开发环境，用于开发、可视化和调试数据工程和数据科学应用程序，而 SageMaker Studio 提供了一个基于 Web 的可视化界面，用于执行所有机器学习开发步骤。"}
{"origin_question": "\nEMR Studio 与 SageMaker Studio 有何不同？\n", "origin_answer": "您可以同时将 EMR Studio 和 SageMaker Studio 与 Amazon EMR 一起使用。EMR Studio 提供集成开发环境 (IDE)，使您能够轻松地开发、可视化和调试用 R、Python、Scala 和 PySpark 编写的数据工程和数据科学应用程序。Amazon SageMaker Studio 提供了一个基于 Web 的可视化界面，您可以通过该界面执行所有机器学习开发步骤。借助 SageMaker Studio，您可以全面掌控和了解构建、训练和部署模型的每个步骤。您可以快速上传数据、创建新笔记本、训练和调优模型，在步骤之间来回移动以调整实验、对比结果以及将模型部署到生产环境中，而且上述所有工作都在一个地方完成，大大提升了工作效率。 \n", "generate_question": "使用 EMR Studio 和 SageMaker Studio 可以提高什么？", "generate_answer": "使用 EMR Studio 和 SageMaker Studio 可以提高工作效率，因为您可以在一个地方完成上传数据、创建笔记本、训练和调优模型等工作，并且可以全面掌控和了解每个步骤。"}
{"origin_question": "\n我如何开始使用 EMR Studio？\n", "origin_answer": "\n您的管理必须首先设置 EMR Studio。从管理员那里收到 Amazon EMR Studio 的唯一登录 URL 后，您可以使用企业凭证直接登录到 Studio。", "generate_question": "如何开始使用 EMR Studio？", "generate_answer": "您需要从管理员那里获取 Amazon EMR Studio 的唯一登录 URL，并使用企业凭证直接登录到 Studio。"}
{"origin_question": "\n我如何开始使用 EMR Studio？\n", "origin_answer": "\n您的管理必须首先设置 EMR Studio。从管理员那里收到 Amazon EMR Studio 的唯一登录 URL 后，您可以使用企业凭证直接登录到 Studio。", "generate_question": "什么是 EMR Studio？", "generate_answer": "EMR Studio 是亚马逊云科技提供的一种云端集成开发环境，用于简化和加速大数据分析和处理任务。用户可以通过 EMR Studio 进行数据准备、数据分析和数据可视化等操作。"}
{"origin_question": "\n我是否需要登录到 AWS 管理控制台才能使用 EMR Studio？\n", "origin_answer": "不需要。管理员设置 EMR Studio 并提供 Studio 访问 URL 后，您的团队可以使用企业凭证登录。无需登录到 AWS 管理控制台。在 EMR Studio 中，您的团队可以执行任务并访问由管理员配置的资源。\n", "generate_question": "如何使用 EMR Studio？", "generate_answer": "您可以通过管理员提供的 Studio 访问 URL 使用 EMR Studio，无需登录到 AWS 管理控制台。在 EMR Studio 中，您可以执行任务并访问由管理员配置的资源。"}
{"origin_question": "\n我是否需要登录到 AWS 管理控制台才能使用 EMR Studio？\n", "origin_answer": "不需要。管理员设置 EMR Studio 并提供 Studio 访问 URL 后，您的团队可以使用企业凭证登录。无需登录到 AWS 管理控制台。在 EMR Studio 中，您的团队可以执行任务并访问由管理员配置的资源。\n", "generate_question": "EMR Studio 是否需要管理员设置？", "generate_answer": "是的，管理员需要设置 EMR Studio 并提供 Studio 访问 URL 给用户，用户才能使用 EMR Studio。"}
{"origin_question": "\n我是否需要登录到 AWS 管理控制台才能使用 EMR Studio？\n", "origin_answer": "不需要。管理员设置 EMR Studio 并提供 Studio 访问 URL 后，您的团队可以使用企业凭证登录。无需登录到 AWS 管理控制台。在 EMR Studio 中，您的团队可以执行任务并访问由管理员配置的资源。\n", "generate_question": "EMR Studio 是否可以访问管理员未配置的资源？", "generate_answer": "不可以，EMR Studio只能访问由管理员配置的资源，用户无法访问管理员未配置的资源。"}
{"origin_question": "\nEMR Studio 中的单点登录体验支持哪些身份提供商？\n", "origin_answer": "AWS IAM Identity Center（AWS SSO 的后继者）是 EMR Studio 的单点登录服务提供程序。AWS IAM 支持的身份提供商列表可在我们的文档中找到。\n", "generate_question": "EMR Studio 中的单点登录体验支持哪些身份提供商？", "generate_answer": "AWS IAM Identity Center（AWS SSO 的后继者）是 EMR Studio 的单点登录服务提供程序。AWS IAM 支持的身份提供商列表可在我们的文档中找到。"}
{"origin_question": "\nEMR Studio 中的单点登录体验支持哪些身份提供商？\n", "origin_answer": "AWS IAM Identity Center（AWS SSO 的后继者）是 EMR Studio 的单点登录服务提供程序。AWS IAM 支持的身份提供商列表可在我们的文档中找到。\n", "generate_question": "在哪里可以找到 AWS IAM 支持的身份提供商列表？", "generate_answer": "AWS IAM 支持的身份提供商列表可以在亚马逊云科技的文档中找到。"}
{"origin_question": "\n什么是 EMR Studio 中的工作区？\n", "origin_answer": "Workspace 可帮助您组织 Jupyter Notebooks。工作区中的所有笔记本都保存到同一个 Amazon S3 位置，并在同一集群上运行。您还可以将代码存储库（如 GitHub 存储库）链接到工作区中的所有笔记本。您可以在将工作区附加到集群之前创建和配置工作区，但您应该在运行笔记本之前先连接到集群。\n", "generate_question": "EMR Studio 中的工作区有什么作用？", "generate_answer": "工作区可以帮助用户组织 Jupyter Notebooks，并将其保存到同一个 Amazon S3 位置，并在同一集群上运行。用户还可以将代码存储库链接到工作区中的所有笔记本。"}
{"origin_question": "\n什么是 EMR Studio 中的工作区？\n", "origin_answer": "Workspace 可帮助您组织 Jupyter Notebooks。工作区中的所有笔记本都保存到同一个 Amazon S3 位置，并在同一集群上运行。您还可以将代码存储库（如 GitHub 存储库）链接到工作区中的所有笔记本。您可以在将工作区附加到集群之前创建和配置工作区，但您应该在运行笔记本之前先连接到集群。\n", "generate_question": "用户可以在 EMR Studio 的工作区中做什么？", "generate_answer": "用户可以创建和配置工作区，将代码存储库链接到工作区中的所有笔记本，并在连接到集群后运行笔记本。"}
{"origin_question": "\n什么是 EMR Studio 中的工作区？\n", "origin_answer": "Workspace 可帮助您组织 Jupyter Notebooks。工作区中的所有笔记本都保存到同一个 Amazon S3 位置，并在同一集群上运行。您还可以将代码存储库（如 GitHub 存储库）链接到工作区中的所有笔记本。您可以在将工作区附加到集群之前创建和配置工作区，但您应该在运行笔记本之前先连接到集群。\n", "generate_question": "用户应该在什么时候连接工作区到集群？", "generate_answer": "用户应该在运行笔记本之前先连接工作区到集群。"}
{"origin_question": "\n什么是 EMR Studio 中的工作区？\n", "origin_answer": "Workspace 可帮助您组织 Jupyter Notebooks。工作区中的所有笔记本都保存到同一个 Amazon S3 位置，并在同一集群上运行。您还可以将代码存储库（如 GitHub 存储库）链接到工作区中的所有笔记本。您可以在将工作区附加到集群之前创建和配置工作区，但您应该在运行笔记本之前先连接到集群。\n", "generate_question": "工作区中的笔记本保存在哪里？", "generate_answer": "工作区中的笔记本保存在 Amazon S3 的同一个位置。"}
{"origin_question": "\n在 EMR Studio 中，是否可以在没有集群的情况下创建工作区或打开工作区？\n", "origin_answer": "是的，您可以创建或打开工作区而无需将其附加到集群。仅在需要执行时，才应该将它们连接到集群。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。\n", "generate_question": "在什么情况下可以在 EMR Studio 中创建或打开工作区？", "generate_answer": "在没有集群的情况下，您可以创建或打开工作区。"}
{"origin_question": "\n在 EMR Studio 中，是否可以在没有集群的情况下创建工作区或打开工作区？\n", "origin_answer": "是的，您可以创建或打开工作区而无需将其附加到集群。仅在需要执行时，才应该将它们连接到集群。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。\n", "generate_question": "是否需要将工作区连接到集群才能执行操作？", "generate_answer": "不需要，您可以在需要执行操作时将工作区连接到集群，但在没有集群的情况下也可以创建或打开工作区。"}
{"origin_question": "\n在 EMR Studio 中，是否可以在没有集群的情况下创建工作区或打开工作区？\n", "origin_answer": "是的，您可以创建或打开工作区而无需将其附加到集群。仅在需要执行时，才应该将它们连接到集群。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。\n", "generate_question": "EMR Studio 内核和应用程序在哪里运行？", "generate_answer": "EMR Studio 内核和应用程序在 EMR 集群上运行。"}
{"origin_question": "\n在 EMR Studio 中，是否可以在没有集群的情况下创建工作区或打开工作区？\n", "origin_answer": "是的，您可以创建或打开工作区而无需将其附加到集群。仅在需要执行时，才应该将它们连接到集群。EMR Studio 内核和应用程序在 EMR 集群上运行，因此您可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，获得分布式数据处理带来的优势。\n", "generate_question": "为什么在 EMR Studio 中连接工作区到集群可以带来优势？", "generate_answer": "连接工作区到集群可以利用性能优化的适用于 Apache Spark 的 Amazon EMR 运行时，从而获得分布式数据处理的优势。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "在哪里可以安装笔记本范围的库？", "generate_answer": "您可以在笔记本单元中安装笔记本范围的库。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "是否可以在集群主节点上安装 Jupyter Notebook 内核和 Python 库？", "generate_answer": "是的，您可以在集群主节点上安装 Jupyter Notebook 内核和 Python 库。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "如何在创建集群时安装查询的库？", "generate_answer": "您可以使用引导操作或自定义 AMI 在创建集群时安装查询的库。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "是否可以在笔记本单元内安装运行时库？", "generate_answer": "是的，您可以在笔记本单元内安装运行时库。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "是否可以在使用 SSH 连接集群的主节点时安装 Jupyter Notebook 内核和 Python 库？", "generate_answer": "是的，您可以在使用 SSH 连接集群的主节点时安装 Jupyter Notebook 内核和 Python 库。"}
{"origin_question": "\n我能否安装定制库以在我的笔记本代码内使用？\n", "origin_answer": "所有 Spark 查询都在您的 EMR 集群上运行，因此您需要安装 Spark 应用程序在该集群上使用的所有运行时库。您可以轻松地在笔记本单元中安装笔记本范围的库。您还可以在笔记本单元内，或在使用 SSH 连接集群的主节点时，在集群主节点上安装 Jupyter Notebook 内核和 Python 库。有关更多信息，请参阅文档。此外，创建集群时，您可以使用引导操作或自定义 AMI 安装查询的库。如需了解更多信息，请参阅 Amazon EMR 管理指南中的创建引导操作以安装其他软件和使用自定义 AMI。\n", "generate_question": "在 Spark 查询中，所有查询都在哪里运行？", "generate_answer": "在 Spark 查询中，所有查询都在您的 EMR 集群上运行。"}
{"origin_question": "\n笔记本保存在哪里？\n", "origin_answer": "工作区和工作区中的笔记本文件自动定期保存到您在创建该工作区时指定的 Amazon S3 位置中的 ipynb 文件。该笔记本文件的名称与您在 Amzon EMR Studio 中的笔记本相同。\n", "generate_question": "笔记本文件保存在哪个位置？", "generate_answer": "笔记本文件保存在您在创建工作区时指定的 Amazon S3 位置中的 ipynb 文件。"}
{"origin_question": "\n笔记本保存在哪里？\n", "origin_answer": "工作区和工作区中的笔记本文件自动定期保存到您在创建该工作区时指定的 Amazon S3 位置中的 ipynb 文件。该笔记本文件的名称与您在 Amzon EMR Studio 中的笔记本相同。\n", "generate_question": "工作区中的笔记本文件如何保存？", "generate_answer": "工作区中的笔记本文件会自动定期保存到您指定的 Amazon S3 位置中的 ipynb 文件。"}
{"origin_question": "\n笔记本保存在哪里？\n", "origin_answer": "工作区和工作区中的笔记本文件自动定期保存到您在创建该工作区时指定的 Amazon S3 位置中的 ipynb 文件。该笔记本文件的名称与您在 Amzon EMR Studio 中的笔记本相同。\n", "generate_question": "笔记本文件的名称与什么相同？", "generate_answer": "笔记本文件的名称与您在 Amazon EMR Studio 中的笔记本相同。"}
{"origin_question": "\n如何对我的笔记本应用版本控制？ 能否使用像 GitHub 这样的存储库？\n", "origin_answer": "您可以在版本受控的环境中将 基于 Git 的存储库与 Amazon EMR Studio Notebooks 相关联，以保存您的笔记本。\n", "generate_question": "如何对笔记本应用版本进行控制？", "generate_answer": "您可以将基于 Git 的存储库与 Amazon EMR Studio Notebooks 相关联，以实现对笔记本应用版本的控制。"}
{"origin_question": "\n如何对我的笔记本应用版本控制？ 能否使用像 GitHub 这样的存储库？\n", "origin_answer": "您可以在版本受控的环境中将 基于 Git 的存储库与 Amazon EMR Studio Notebooks 相关联，以保存您的笔记本。\n", "generate_question": "可以使用哪种存储库来对笔记本应用进行版本控制？", "generate_answer": "您可以使用基于 Git 的存储库来对笔记本应用进行版本控制。"}
{"origin_question": "\n如何对我的笔记本应用版本控制？ 能否使用像 GitHub 这样的存储库？\n", "origin_answer": "您可以在版本受控的环境中将 基于 Git 的存储库与 Amazon EMR Studio Notebooks 相关联，以保存您的笔记本。\n", "generate_question": "Amazon EMR Studio Notebooks 是否支持类似 GitHub 的存储库？", "generate_answer": "是的，您可以将基于 Git 的存储库与 Amazon EMR Studio Notebooks 相关联，以实现类似 GitHub 的存储库的功能。"}
{"origin_question": "\n在 EMR Studio 中，我可以在哪些计算资源上运行笔记本？\n", "origin_answer": "使用 EMR Studio，您可以在运行于 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 上或者运行于 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。可以将笔记本附加到现有或新的集群上。您可以在 EMR Studio 中以两种方式创建 EMR 集群：使用预配置的集群模板通过 AWS Service Catalog 创建集群；通过指定集群名称、实例数和实例类型创建集群。\n", "generate_question": "在哪些计算资源上可以运行 EMR Studio 中的笔记本？", "generate_answer": "可以在 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 或者 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。"}
{"origin_question": "\n在 EMR Studio 中，我可以在哪些计算资源上运行笔记本？\n", "origin_answer": "使用 EMR Studio，您可以在运行于 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 上或者运行于 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。可以将笔记本附加到现有或新的集群上。您可以在 EMR Studio 中以两种方式创建 EMR 集群：使用预配置的集群模板通过 AWS Service Catalog 创建集群；通过指定集群名称、实例数和实例类型创建集群。\n", "generate_question": "如何将笔记本附加到现有或新的集群上？", "generate_answer": "在 EMR Studio 中，可以将笔记本附加到现有或新的集群上。可以通过使用预配置的集群模板通过 AWS Service Catalog 创建集群，或者通过指定集群名称、实例数和实例类型来创建集群。"}
{"origin_question": "\n在 EMR Studio 中，我可以在哪些计算资源上运行笔记本？\n", "origin_answer": "使用 EMR Studio，您可以在运行于 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 上或者运行于 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。可以将笔记本附加到现有或新的集群上。您可以在 EMR Studio 中以两种方式创建 EMR 集群：使用预配置的集群模板通过 AWS Service Catalog 创建集群；通过指定集群名称、实例数和实例类型创建集群。\n", "generate_question": "什么是 EMR Studio？", "generate_answer": "EMR Studio 是亚马逊云科技提供的一种服务，它允许用户在 Amazon EMR 上运行笔记本代码。用户可以在 EMR Studio 中创建和管理笔记本，并将其附加到现有或新的集群上。"}
{"origin_question": "\n在 EMR Studio 中，我可以在哪些计算资源上运行笔记本？\n", "origin_answer": "使用 EMR Studio，您可以在运行于 Amazon Elastic Compute Cloud (Amazon EC2) 上的 Amazon EMR 上或者运行于 Amazon Elastic Kubernetes Service (Amazon EKS) 上的 Amazon EMR 上运行笔记本代码。可以将笔记本附加到现有或新的集群上。您可以在 EMR Studio 中以两种方式创建 EMR 集群：使用预配置的集群模板通过 AWS Service Catalog 创建集群；通过指定集群名称、实例数和实例类型创建集群。\n", "generate_question": "在 EMR Studio 中，如何创建 EMR 集群？", "generate_answer": "在 EMR Studio 中，可以以两种方式创建 EMR 集群。一种方式是使用预配置的集群模板通过 AWS Service Catalog 创建集群。另一种方式是通过指定集群名称、实例数和实例类型来创建集群。"}
{"origin_question": "\n我是否可以在 EMR Studio 中将工作区重新附加到不同的计算资源？\n", "origin_answer": "是的，您可以打开您的工作区，选择左侧的 EMR 集群图标，按下分离按钮，然后从选择集群下拉列表中选择集群，并按下附加按钮。\n", "generate_question": "如何在 EMR Studio 中重新附加工作区到不同的计算资源？", "generate_answer": "您可以在 EMR Studio 中打开工作区，选择左侧的 EMR 集群图标，然后点击分离按钮，接着从选择集群下拉列表中选择目标集群，并点击附加按钮。"}
{"origin_question": "\n在 EMR Studio 中，我在哪里可以找到所有工作区？\n", "origin_answer": "在 EMR Studio 中，您可以选择左侧的 WorkSpace 选项卡，查看您和其他用户在同一个 AWS 账户中创建的所有工作区。\n", "generate_question": "在 EMR Studio 中，如何查看其他用户在同一个 AWS 账户中创建的所有工作区？", "generate_answer": "在 EMR Studio 中，您可以选择左侧的 WorkSpace 选项卡，即可查看您和其他用户在同一个 AWS 账户中创建的所有工作区。"}
{"origin_question": "\n在 EMR Studio 中，我在哪里可以找到所有工作区？\n", "origin_answer": "在 EMR Studio 中，您可以选择左侧的 WorkSpace 选项卡，查看您和其他用户在同一个 AWS 账户中创建的所有工作区。\n", "generate_question": "在 EMR Studio 中，工作区的选项卡位于哪个位置？", "generate_answer": "在 EMR Studio 中，工作区的选项卡位于左侧的菜单栏中。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "为了使用 EMR Studio，需要哪些 IAM 策略？", "generate_answer": "您需要使用提供的策略创建 EMR Studio 服务角色，并为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。此外，您还可以将会话策略分配给用户或组，以应用细粒度权限控制。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "如何为 EMR Studio 创建会话策略？", "generate_answer": "您可以使用会话策略来优化用户权限，而无需创建多个 IAM 角色。管理员可以在将用户和组添加到 EMR Studio 时，将会话策略分配给他们。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "会话策略有什么作用？", "generate_answer": "会话策略可以帮助管理员优化用户权限，以实现细粒度的权限控制。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "如何与其他 AWS 服务进行互操作？", "generate_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "如何为 EMR Studio 指定 Studio 级别权限的用户角色？", "generate_answer": "您的管理员需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色，以确保 EMR Studio 具有所需的权限。"}
{"origin_question": "\n使用 EMR Studio 需要哪些 IAM 策略？\n", "origin_answer": "每个 EMR Studio 都需要权限才能与其他 AWS 服务进行互操作。为了给您的 EMR Studio 必要的权限，您的管理员需要使用所提供的策略来创建 EMR Studio 服务角色。他们还需要为 EMR Studio 指定一个定义 Studio 级别权限的用户角色。当他们将用户和组从 AWS IAM Identity Center（AWS SSO 的后继者）添加到 EMR Studio 时，他们可以将会话策略分配给用户或组以应用细粒度权限控制。会话策略可帮助管理员优化用户权限，而无需创建多个 IAM 角色。有关会话策略的更多信息，请参阅《AWS Identity and Access Management 用户指南》中的策略和权限。\n", "generate_question": "在哪里可以找到有关会话策略的更多信息？", "generate_answer": "您可以在《AWS Identity and Access Management 用户指南》中找到有关会话策略的更多信息。"}
{"origin_question": "\n在 EMR Studio 中，对附加我工作区的 EMR 集群是否有任何限制？\n", "origin_answer": "可以。目前不支持高可用性（多主控）集群、Kerberos 化集群和 AWS Lake Formation 集群。\n", "generate_question": "在 EMR Studio 中，可以附加哪些类型的 EMR 集群？", "generate_answer": "在 EMR Studio 中，可以附加非高可用性（单主控）集群、非 Kerberos 化集群和非 AWS Lake Formation 集群。"}
{"origin_question": "\n在 EMR Studio 中，对附加我工作区的 EMR 集群是否有任何限制？\n", "origin_answer": "可以。目前不支持高可用性（多主控）集群、Kerberos 化集群和 AWS Lake Formation 集群。\n", "generate_question": "在 EMR Studio 中，可以对附加的 EMR 集群进行哪些操作？", "generate_answer": "在 EMR Studio 中，可以对附加的 EMR 集群进行数据分析、作业提交和监控等操作。"}
{"origin_question": "\n使用 Amazon EMR Studio 的费用是多少？\n", "origin_answer": "向您提供的 Amazon EMR Studio 不再额外收费。在您使用 EMR Studio 时，将收取适用于 Amazon Simple Storage Service 存储和 Amazon EMR 集群的费用。要更多了解定价选项和详细信息，请参阅 Amazon EMR 定价。", "generate_question": "Amazon EMR Studio 的费用包括哪些方面？", "generate_answer": "Amazon EMR Studio 的费用包括 Amazon Simple Storage Service 存储和 Amazon EMR 集群的费用。"}
{"origin_question": "\n使用 Amazon EMR Studio 的费用是多少？\n", "origin_answer": "向您提供的 Amazon EMR Studio 不再额外收费。在您使用 EMR Studio 时，将收取适用于 Amazon Simple Storage Service 存储和 Amazon EMR 集群的费用。要更多了解定价选项和详细信息，请参阅 Amazon EMR 定价。", "generate_question": "Amazon EMR Studio 是否需要额外付费？", "generate_answer": "不需要额外付费，使用 Amazon EMR Studio 不再额外收费。"}
{"origin_question": "\n使用 Amazon EMR Studio 的费用是多少？\n", "origin_answer": "向您提供的 Amazon EMR Studio 不再额外收费。在您使用 EMR Studio 时，将收取适用于 Amazon Simple Storage Service 存储和 Amazon EMR 集群的费用。要更多了解定价选项和详细信息，请参阅 Amazon EMR 定价。", "generate_question": "如何了解 Amazon EMR Studio 的定价选项和详细信息？", "generate_answer": "您可以参阅 Amazon EMR 定价，了解 Amazon EMR Studio 的定价选项和详细信息。"}
{"origin_question": "\n什么是 EMR Notebooks？\n", "origin_answer": "我们建议新客户使用 Amazon EMR Studio，而不是 EMR Notebooks。EMR Notebooks 提供基于 Jupyter Notebook 的托管环境，可供数据科学家、分析员和开发人员准备数据并使其可视化、与同伴协作、构建应用程序，并使用 EMR 集群执行交互分析。尽管我们建议新客户使用 EMR Studio，但出于兼容性考虑，我们也支持 EMR Notebooks。\n", "generate_question": "什么是 EMR Notebooks？", "generate_answer": "EMR Notebooks 是一种基于 Jupyter Notebook 的托管环境，用于数据科学家、分析员和开发人员准备数据、可视化数据、与同伴协作、构建应用程序，并使用 EMR 集群执行交互分析。"}
{"origin_question": "\n什么是 EMR Notebooks？\n", "origin_answer": "我们建议新客户使用 Amazon EMR Studio，而不是 EMR Notebooks。EMR Notebooks 提供基于 Jupyter Notebook 的托管环境，可供数据科学家、分析员和开发人员准备数据并使其可视化、与同伴协作、构建应用程序，并使用 EMR 集群执行交互分析。尽管我们建议新客户使用 EMR Studio，但出于兼容性考虑，我们也支持 EMR Notebooks。\n", "generate_question": "为什么建议新客户使用 EMR Studio 而不是 EMR Notebooks？", "generate_answer": "新客户建议使用 EMR Studio，因为它提供更多功能和更好的兼容性。尽管 EMR Notebooks 也支持，但为了更好地满足客户需求，我们推荐使用 EMR Studio。"}
{"origin_question": "\n什么是 EMR Notebooks？\n", "origin_answer": "我们建议新客户使用 Amazon EMR Studio，而不是 EMR Notebooks。EMR Notebooks 提供基于 Jupyter Notebook 的托管环境，可供数据科学家、分析员和开发人员准备数据并使其可视化、与同伴协作、构建应用程序，并使用 EMR 集群执行交互分析。尽管我们建议新客户使用 EMR Studio，但出于兼容性考虑，我们也支持 EMR Notebooks。\n", "generate_question": "EMR Notebooks 可以用于哪些任务？", "generate_answer": "EMR Notebooks 可以用于数据准备、数据可视化、与同伴协作、构建应用程序以及使用 EMR 集群执行交互分析等任务。"}
{"origin_question": "\n什么是 EMR Notebooks？\n", "origin_answer": "我们建议新客户使用 Amazon EMR Studio，而不是 EMR Notebooks。EMR Notebooks 提供基于 Jupyter Notebook 的托管环境，可供数据科学家、分析员和开发人员准备数据并使其可视化、与同伴协作、构建应用程序，并使用 EMR 集群执行交互分析。尽管我们建议新客户使用 EMR Studio，但出于兼容性考虑，我们也支持 EMR Notebooks。\n", "generate_question": "除了 EMR Notebooks，还有其他类似的工具吗？", "generate_answer": "是的，除了 EMR Notebooks，还有其他类似的工具，如 Jupyter Notebook、Google Colab 等，它们也提供类似的功能，用于数据科学和分析任务。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "什么是EMR Notebooks？", "generate_answer": "EMR Notebooks是一种工具，可以用于构建Apache Spark应用程序，并在EMR集群上运行交互式查询。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "如何使用EMR Notebooks？", "generate_answer": "您可以通过控制台创建无服务器笔记本，将其挂载到现有的共享EMR集群，或者直接从控制台预置一个集群并立即开始使用Spark进行实验。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "EMR Notebooks可以在哪些方面帮助用户？", "generate_answer": "EMR Notebooks可以帮助用户在EMR集群上运行交互式查询，构建Spark应用程序，操作数据以及将结果可视化。它还集成了Spark监控功能，可以用于监测Spark作业的进度和调试代码。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "如何保存EMR Notebooks？", "generate_answer": "EMR Notebooks会自动保存到S3存储桶中，用户可以从控制台检索已保存的笔记本以恢复工作。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "EMR Notebooks预打包了哪些库？", "generate_answer": "EMR Notebooks预打包了在Anaconda存储库中创建的库，用户可以在自己的笔记本代码中导入和使用这些库。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "可以将EMR Notebooks卸载并重新挂载到新集群吗？", "generate_answer": "是的，用户可以将EMR Notebooks卸载并重新挂载到新集群。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "EMR Notebooks适用于哪种类型的用户？", "generate_answer": "EMR Notebooks适用于需要使用Spark进行数据处理和分析的用户。"}
{"origin_question": "\nEMR Notebooks 有什么作用？\n", "origin_answer": "您可以使用 EMR Notebooks 构建 Apache Spark 应用程序，并且轻而易举地在 EMR 集群上运行交互式查询。多个用户可以直接从控制台创建无服务器笔记本、将其挂载到现有的共享 EMR 集群，或直接从控制台预置一个集群并立即开始使用 Spark 进行实验。您可以卸载笔记本并将其重新挂载到新集群。笔记本自动保存到 S3 存储桶，您可以从控制台检索已保存的笔记本以恢复工作。EMR Notebooks 预打包了在 Anaconda 存储库中创建的库，供您在自己的笔记本代码中导入和使用这些库，并利用它们操作数据以及将结果可视化。另外，EMR Notebooks 集成有 Spark 监控功能，您可以用来监测 Spark 作业的进度并在自己的笔记本中调试代码。\n", "generate_question": "EMR Notebooks是否支持多用户？", "generate_answer": "是的，EMR Notebooks支持多个用户，多个用户可以直接从控制台创建笔记本，并共享EMR集群上的资源。"}
{"origin_question": "\n我如何开始使用 EMR Notebooks？\n", "origin_answer": "要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。\n", "generate_question": "如何开始使用 EMR Notebooks？", "generate_answer": "要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。"}
{"origin_question": "\n我如何开始使用 EMR Notebooks？\n", "origin_answer": "要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。\n", "generate_question": "在 EMR Notebooks 中如何创建笔记本？", "generate_answer": "在 EMR Notebooks 中创建笔记本，只需打开 EMR 控制台，选择 Notebooks，然后选择 Create Notebook。在创建笔记本时，需要提供笔记本的名称、选择一个 EMR 群集或即时创建一个新群集、为笔记本提供服务角色，并选择要将笔记本文件保存到的 S3 存储桶。"}
{"origin_question": "\n我如何开始使用 EMR Notebooks？\n", "origin_answer": "要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。\n", "generate_question": "如何打开 EMR Notebooks 的笔记本编辑器？", "generate_answer": "要打开 EMR Notebooks 的笔记本编辑器，首先需要在 EMR 控制台中选择 Notebooks。然后，在笔记本显示 Ready 状态后，选择 Open 即可启动笔记本编辑器。"}
{"origin_question": "\n我如何开始使用 EMR Notebooks？\n", "origin_answer": "要开始使用 EMR Notebooks，打开 EMR 控制台，在导航窗格中选择 Notebooks。在这里，只需选择 Create Notebook，输入笔记本的名称，选择一个 EMR 群集或即时创建一个新群集，为要使用的笔记本提供服务角色，并选择您要将笔记本文件保存到的 S3 存储桶，然后单击 Create Notebook。当笔记本显示 Ready 状态后，选择 Open 以启动笔记本编辑器。\n", "generate_question": "在 EMR Notebooks 中如何保存笔记本文件？", "generate_answer": "在 EMR Notebooks 中保存笔记本文件，需要在创建笔记本时选择要将笔记本文件保存到的 S3 存储桶。在创建笔记本时，可以指定一个现有的 S3 存储桶或创建一个新的存储桶来保存笔记本文件。"}
{"origin_question": "\nEMR Notebooks 支持哪些 EMR 版本？\n", "origin_answer": "EMR Notebooks 可挂载到运行 EMR 5.18.0 版或更高版本的 EMR 集群。\n", "generate_question": "EMR Notebooks 可以挂载到哪些 EMR 版本？", "generate_answer": "EMR Notebooks 可以挂载到运行 EMR 5.18.0 版或更高版本的 EMR 集群。"}
{"origin_question": "\nEMR Notebooks 支持哪些 EMR 版本？\n", "origin_answer": "EMR Notebooks 可挂载到运行 EMR 5.18.0 版或更高版本的 EMR 集群。\n", "generate_question": "低于 EMR 5.18.0 版本的 EMR 集群是否支持挂载 EMR Notebooks？", "generate_answer": "不支持，EMR Notebooks 只能挂载到运行 EMR 5.18.0 版或更高版本的 EMR 集群。"}
{"origin_question": "\n使用 EMR Notebooks 的费用是多少？\n", "origin_answer": "向您提供的 EMR Notebooks 不再额外收费。您的帐户将根据挂载的 EMR 集群照常收费。您可以访问 https://aws.amazon.com/emr/pricing/ 以了解关于集群订价的更多信息   ", "generate_question": "EMR Notebooks 是否需要额外付费？", "generate_answer": "EMR Notebooks 不需要额外付费，您只需要按照挂载的 EMR 集群的费用进行计费。"}
{"origin_question": "\n使用 EMR Notebooks 的费用是多少？\n", "origin_answer": "向您提供的 EMR Notebooks 不再额外收费。您的帐户将根据挂载的 EMR 集群照常收费。您可以访问 https://aws.amazon.com/emr/pricing/ 以了解关于集群订价的更多信息   ", "generate_question": "如何了解 EMR 集群的定价信息？", "generate_answer": "您可以访问 https://aws.amazon.com/emr/pricing/ 了解更多关于 EMR 集群的定价信息。"}
{"origin_question": "\n使用 EMR Notebooks 的费用是多少？\n", "origin_answer": "向您提供的 EMR Notebooks 不再额外收费。您的帐户将根据挂载的 EMR 集群照常收费。您可以访问 https://aws.amazon.com/emr/pricing/ 以了解关于集群订价的更多信息   ", "generate_question": "EMR Notebooks 是否包含在 EMR 集群的费用中？", "generate_answer": "是的，EMR Notebooks 的使用不会额外收费，您的账户将按照挂载的 EMR 集群的费用进行计费。"}
{"origin_question": "\n如何将我的数据导入 Amazon S3？\n", "origin_answer": "Amazon EMR 提供了几种将数据导入集群中的方法。最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。有关更多详细信息，请参阅文档。或者，如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种云数据迁移服务。\n", "generate_question": "Amazon EMR 提供了哪些方法将数据导入集群中？", "generate_answer": "Amazon EMR 提供了几种将数据导入集群中的方法。"}
{"origin_question": "\n如何将我的数据导入 Amazon S3？\n", "origin_answer": "Amazon EMR 提供了几种将数据导入集群中的方法。最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。有关更多详细信息，请参阅文档。或者，如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种云数据迁移服务。\n", "generate_question": "最常用的将数据导入 Amazon EMR 集群的方法是什么？", "generate_answer": "最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。"}
{"origin_question": "\n如何将我的数据导入 Amazon S3？\n", "origin_answer": "Amazon EMR 提供了几种将数据导入集群中的方法。最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。有关更多详细信息，请参阅文档。或者，如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种云数据迁移服务。\n", "generate_question": "如何将文件从分布式文件系统传输到本地文件系统？", "generate_answer": "您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。"}
{"origin_question": "\n如何将我的数据导入 Amazon S3？\n", "origin_answer": "Amazon EMR 提供了几种将数据导入集群中的方法。最常用的方法是将数据上传到 Amazon S3，并使用 Amazon EMR 的内置功能将数据加载到您的集群中。您可以使用 Hadoop 的分布式缓存功能将文件从分布式文件系统传输到本地文件系统。有关更多详细信息，请参阅文档。或者，如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种云数据迁移服务。\n", "generate_question": "如果我要将数据从本地迁移到云，可以使用哪些云数据迁移服务？", "generate_answer": "如果您要将数据从本地迁移到云，可以使用 AWS 提供的任何一种云数据迁移服务。"}
{"origin_question": "\n如何获得已终止集群的日志？\n", "origin_answer": "Hadoop 系统日志及用户日志存放在您在创建集群时指定的 Amazon S3 存储段中。持久性应用程序 UI 在集群外运行，Spark 历史记录服务器、Tez UI 和 YARN 时间线服务器日志在应用程序终止后 30 天内可用。\n", "generate_question": "Hadoop 系统日志和用户日志存放在哪里？", "generate_answer": "Hadoop 系统日志和用户日志存放在您在创建集群时指定的 Amazon S3 存储段中。"}
{"origin_question": "\n如何获得已终止集群的日志？\n", "origin_answer": "Hadoop 系统日志及用户日志存放在您在创建集群时指定的 Amazon S3 存储段中。持久性应用程序 UI 在集群外运行，Spark 历史记录服务器、Tez UI 和 YARN 时间线服务器日志在应用程序终止后 30 天内可用。\n", "generate_question": "什么是持久性应用程序 UI？", "generate_answer": "持久性应用程序 UI 是在集群外运行的，用于显示 Spark 历史记录服务器、Tez UI 和 YARN 时间线服务器日志的界面。"}
{"origin_question": "\n如何获得已终止集群的日志？\n", "origin_answer": "Hadoop 系统日志及用户日志存放在您在创建集群时指定的 Amazon S3 存储段中。持久性应用程序 UI 在集群外运行，Spark 历史记录服务器、Tez UI 和 YARN 时间线服务器日志在应用程序终止后 30 天内可用。\n", "generate_question": "终止的集群的日志可以在多长时间内访问？", "generate_answer": "终止的集群的日志可以在应用程序终止后的30天内访问。"}
{"origin_question": "\n您是否会压缩日志？\n", "origin_answer": "不会，目前，Amazon EMR 在将日志迁移到 Amazon S3 时，不会压缩日志。\n", "generate_question": "Amazon EMR 在将日志迁移到 Amazon S3 时，会对日志进行什么处理？", "generate_answer": "Amazon EMR 在将日志迁移到 Amazon S3 时，不会对日志进行压缩处理。"}
{"origin_question": "\n您是否会压缩日志？\n", "origin_answer": "不会，目前，Amazon EMR 在将日志迁移到 Amazon S3 时，不会压缩日志。\n", "generate_question": "为什么 Amazon EMR 在将日志迁移到 Amazon S3 时不会压缩日志？", "generate_answer": "目前，Amazon EMR 在将日志迁移到 Amazon S3 时不会压缩日志，具体原因未提及。"}
{"origin_question": "\n是否可从 Internet 或 Amazon S3 以外的其他位置加载数据？\n", "origin_answer": "可以。您可以使用 AWS Direct Connect 建立到 AWS 的私有专用网络连接。如果您有大量数据，可以使用 AWS Import/Export。有关更多详细信息，请参阅我们的文档。", "generate_question": "如何从 Internet 或 Amazon S3 以外的其他位置加载数据？", "generate_answer": "您可以使用 AWS Direct Connect 建立到 AWS 的私有专用网络连接，以从其他位置加载数据。"}
{"origin_question": "\n是否可从 Internet 或 Amazon S3 以外的其他位置加载数据？\n", "origin_answer": "可以。您可以使用 AWS Direct Connect 建立到 AWS 的私有专用网络连接。如果您有大量数据，可以使用 AWS Import/Export。有关更多详细信息，请参阅我们的文档。", "generate_question": "如果我有大量数据，如何加载到亚马逊云科技？", "generate_answer": "如果您有大量数据，您可以使用 AWS Import/Export 来加载数据到亚马逊云科技。"}
{"origin_question": "\nAmazon EMR 是否可估算处理我的输入数据需要多长时间？\n", "origin_answer": "由于每个群集和输入数据不同，我们无法估算您的任务持续时间。\n", "generate_question": "亚马逊云科技的 Amazon EMR 是否能够处理大规模的数据？", "generate_answer": "是的，Amazon EMR 可以处理大规模的数据。"}
{"origin_question": "\nAmazon EMR 是否可估算处理我的输入数据需要多长时间？\n", "origin_answer": "由于每个群集和输入数据不同，我们无法估算您的任务持续时间。\n", "generate_question": "Amazon EMR 是否提供自动化的集群管理功能？", "generate_answer": "是的，Amazon EMR 提供自动化的集群管理功能。"}
{"origin_question": "\nAmazon EMR 的收费如何？\n", "origin_answer": "Amazon EMR 定价既简单又可预测：您按每秒费率根据使用时间付费，同时设有一分钟最低费用。您可以使用 AWS 定价计算器估算您的费用。其他 Amazon Web Services（包括 Amazon EC2）的使用与 Amazon EMR 分开计费。\n", "generate_question": "Amazon EMR 的收费计算方式是怎样的？", "generate_answer": "Amazon EMR 的收费是按每秒费率根据使用时间付费，同时设有一分钟最低费用。您可以使用 AWS 定价计算器估算您的费用。"}
{"origin_question": "\nAmazon EMR 的收费如何？\n", "origin_answer": "Amazon EMR 定价既简单又可预测：您按每秒费率根据使用时间付费，同时设有一分钟最低费用。您可以使用 AWS 定价计算器估算您的费用。其他 Amazon Web Services（包括 Amazon EC2）的使用与 Amazon EMR 分开计费。\n", "generate_question": "Amazon EMR 的收费是否包括其他 Amazon Web Services 的使用？", "generate_answer": "Amazon EMR 的收费是与其他 Amazon Web Services（包括 Amazon EC2）的使用分开计费的。"}
{"origin_question": "\nAmazon EMR 的收费如何？\n", "origin_answer": "Amazon EMR 定价既简单又可预测：您按每秒费率根据使用时间付费，同时设有一分钟最低费用。您可以使用 AWS 定价计算器估算您的费用。其他 Amazon Web Services（包括 Amazon EC2）的使用与 Amazon EMR 分开计费。\n", "generate_question": "如何估算使用 Amazon EMR 的费用？", "generate_answer": "您可以使用 AWS 定价计算器来估算使用 Amazon EMR 的费用。"}
{"origin_question": "\nAmazon EMR 集群的账单周期如何计算？\n", "origin_answer": "当该集群准备好执行步骤时，Amazon EMR 计费开始。当您请求关闭该集群时，Amazon EMR 计费结束。有关 Amazon EC2 开始和结束计费的详细信息，请参阅 Amazon EC2 计费常见问题。\n", "generate_question": "什么时候开始计费一个Amazon EMR集群？", "generate_answer": "当该集群准备好执行步骤时，Amazon EMR 计费开始。"}
{"origin_question": "\nAmazon EMR 集群的账单周期如何计算？\n", "origin_answer": "当该集群准备好执行步骤时，Amazon EMR 计费开始。当您请求关闭该集群时，Amazon EMR 计费结束。有关 Amazon EC2 开始和结束计费的详细信息，请参阅 Amazon EC2 计费常见问题。\n", "generate_question": "什么时候结束计费一个Amazon EMR集群？", "generate_answer": "当您请求关闭该集群时，Amazon EMR 计费结束。"}
{"origin_question": "\nAmazon EMR 集群的账单周期如何计算？\n", "origin_answer": "当该集群准备好执行步骤时，Amazon EMR 计费开始。当您请求关闭该集群时，Amazon EMR 计费结束。有关 Amazon EC2 开始和结束计费的详细信息，请参阅 Amazon EC2 计费常见问题。\n", "generate_question": "Amazon EMR的计费周期与哪个服务的计费周期相关？", "generate_answer": "Amazon EMR的计费周期与Amazon EC2的计费周期相关。"}
{"origin_question": "\n在哪里可以跟踪我的 Amazon EMR、Amazon EC2 和 Amazon S3 使用情况？\n", "origin_answer": "您可以在账单与收费管理控制台跟踪您的使用情况。\n", "generate_question": "我可以在哪个控制台中跟踪我的 Amazon EMR、Amazon EC2 和 Amazon S3 使用情况？", "generate_answer": "您可以在账单与收费管理控制台中跟踪您的使用情况。"}
{"origin_question": "\n在哪里可以跟踪我的 Amazon EMR、Amazon EC2 和 Amazon S3 使用情况？\n", "origin_answer": "您可以在账单与收费管理控制台跟踪您的使用情况。\n", "generate_question": "Amazon EMR、Amazon EC2 和 Amazon S3 的使用情况可以在哪个控制台中查看？", "generate_answer": "您可以在账单与收费管理控制台中查看 Amazon EMR、Amazon EC2 和 Amazon S3 的使用情况。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "什么是标准实例小时数？", "generate_answer": "标准实例小时数是指在AWS管理控制台中显示的一个群集大约使用的计算小时数，是根据每小时的标准计算时间得出的。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "如何计算标准实例小时数？", "generate_answer": "标准实例小时数是根据每小时的标准计算时间得出的，可以通过将节点数、标准化因子和集群运行的小时数相乘来计算。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "在AWS管理控制台中，标准实例小时数的单位是什么？", "generate_answer": "标准实例小时数的单位是小时。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "标准实例小时数可以用来做什么？", "generate_answer": "标准实例小时数可以用来估算群集的计算使用量，但不能用作账单。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "如何查看不同规格实例的标准化因子？", "generate_answer": "可以查看亚马逊云科技的文档，其中列出了实例系列中不同规格的列表以及每小时对应的标准化因子。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "如果运行一个10节点的r3.8xlarge集群一小时，标准实例总小时数是多少？", "generate_answer": "如果运行一个10节点的r3.8xlarge集群一小时，标准实例总小时数为640。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "标准实例小时数是否可以用于计费？", "generate_answer": "标准实例小时数不应用于账单，需要参考账单与收费管理控制台来了解可计费的Amazon EMR使用量。"}
{"origin_question": "\n如何计算控制台中所显示的标准实例小时数？\n", "origin_answer": "在 AWS 管理控制台中，每个群集都有一个“标准实例小时数”列，显示该群集大约使用的计算小时数（舍入至最接近的值）。\n\n“标准实例小时数”是基于“1 小时 m1.small 用量 = 1 小时标准计算时间”得出的计算时间小时数。您可以查看我们的文档，以了解实例系列中不同规格的列表以及每小时对应的标准化因数。\n例如，如果您运行一个 10 节点 r3.8xlarge 集群一小时，则控制台中所显示的标准实例总小时数为 640 [10（节点数）X 64（标准化因子）X 1（集群运行的小时数）= 640]。\n\n这只是大致时间，不应用作账单。请参阅账单与收费管理控制台，了解可计费的 Amazon EMR 使用量。", "generate_question": "标准实例小时数的计算是否精确？", "generate_answer": "标准实例小时数是舍入至最接近的值，因此计算结果是一个近似值。"}
{"origin_question": "\nAmazon EMR 是否支持 Amazon EC2 按需实例、Spot 实例和预留实例？\n", "origin_answer": "是的。Amazon EMR 可无缝支持按需实例、Spot 实例和预留实例。单击此处详细了解 Amazon EC2 预留实例。单击此处详细了解 Amazon EC2 Spot 实例。单击此处详细了解 Amazon EC2 容量预留。", "generate_question": "Amazon EMR 支持哪些类型的 Amazon EC2 实例？", "generate_answer": "Amazon EMR 支持按需实例、Spot 实例和预留实例。"}
{"origin_question": "\nAmazon EMR 是否支持 Amazon EC2 按需实例、Spot 实例和预留实例？\n", "origin_answer": "是的。Amazon EMR 可无缝支持按需实例、Spot 实例和预留实例。单击此处详细了解 Amazon EC2 预留实例。单击此处详细了解 Amazon EC2 Spot 实例。单击此处详细了解 Amazon EC2 容量预留。", "generate_question": "Amazon EMR 是否支持 Amazon EC2 容量预留？", "generate_answer": "是的，Amazon EMR 支持 Amazon EC2 容量预留。您可以单击此处详细了解 Amazon EC2 容量预留。"}
{"origin_question": "\nAmazon EMR 是否支持 Amazon EC2 按需实例、Spot 实例和预留实例？\n", "origin_answer": "是的。Amazon EMR 可无缝支持按需实例、Spot 实例和预留实例。单击此处详细了解 Amazon EC2 预留实例。单击此处详细了解 Amazon EC2 Spot 实例。单击此处详细了解 Amazon EC2 容量预留。", "generate_question": "Amazon EMR 是否支持 Amazon EC2 Spot 实例？", "generate_answer": "是的，Amazon EMR 支持 Amazon EC2 Spot 实例。您可以单击此处详细了解 Amazon EC2 Spot 实例。"}
{"origin_question": "\n价格是否含税？\n", "origin_answer": "除非另行说明，否则我们的价格不包含适用的税费和关税（包括增值税和适用的销售税）。使用日本账单地址的客户若要使用 AWS，则需缴纳日本消费税。了解更多。 ", "generate_question": "亚马逊云科技的价格是否包含增值税和销售税？", "generate_answer": "除非另行说明，亚马逊云科技的价格不包含适用的税费和关税，包括增值税和适用的销售税。"}
{"origin_question": "\n价格是否含税？\n", "origin_answer": "除非另行说明，否则我们的价格不包含适用的税费和关税（包括增值税和适用的销售税）。使用日本账单地址的客户若要使用 AWS，则需缴纳日本消费税。了解更多。 ", "generate_question": "使用亚马逊云科技的客户需要缴纳哪些税费？", "generate_answer": "使用亚马逊云科技的客户除非另行说明，需要自行缴纳适用的税费和关税，包括增值税和适用的销售税。"}
{"origin_question": "\n价格是否含税？\n", "origin_answer": "除非另行说明，否则我们的价格不包含适用的税费和关税（包括增值税和适用的销售税）。使用日本账单地址的客户若要使用 AWS，则需缴纳日本消费税。了解更多。 ", "generate_question": "在日本使用亚马逊云科技的客户需要缴纳哪种税费？", "generate_answer": "在日本使用亚马逊云科技的客户需要缴纳日本消费税。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "Amazon EMR 在集群执行过程中如何保护用户的数据安全？", "generate_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动实例，其中一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信，同时也开放了 SSH 端口，以允许用户使用指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，只允许与主实例进行交互。默认情况下，这两个安全组都不允许来自其他客户的 Amazon EC2 实例等外部源的访问。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "用户可以如何重新配置 Amazon EMR 的安全组？", "generate_answer": "用户可以使用标准 EC2 工具或控制面板重新配置 Amazon EMR 的安全组，因为这些安全组属于用户的账户。用户可以根据需要添加、删除或修改安全组的规则。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "Amazon EMR 是否允许公有访问？", "generate_answer": "默认情况下，Amazon EMR 阻止公有访问。如果规则允许在未添加到例外情况列表的任何端口进行公有访问，用户可以在每个区域中配置 Amazon EMR 阻止公有访问，以增加数据的安全性。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "Amazon EMR 如何保护用户的集群数据？", "generate_answer": "Amazon EMR 通过在两个安全组中启动实例来保护用户的集群数据。主安全组用于主实例，其他安全组用于其他集群节点。这样可以限制节点之间的交互，并防止其他用户查看用户的数据。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "用户如何使用 SSH 连接到 Amazon EMR 实例？", "generate_answer": "用户可以使用在启动实例时指定的密钥来通过 SSH 连接到 Amazon EMR 实例。主安全组的 SSH 端口是开放的，以允许用户进行 SSH 连接。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "Amazon EMR 是否允许其他用户查看用户的数据？", "generate_answer": "Amazon EMR 通过在两个安全组中启动实例来防止其他用户查看用户的数据。其他节点在单独的安全组中启动，只允许与主实例进行交互，并且不允许来自其他客户的外部源的访问。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "用户可以在 Amazon EMR 中添加哪些例外情况列表？", "generate_answer": "用户可以在 Amazon EMR 中添加例外情况列表来允许特定端口进行公有访问。这样可以在阻止公有访问的基础上，允许一些特定的端口进行公开访问。"}
{"origin_question": "\n在集群执行过程中，如何防止其他用户查看我的数据？\n", "origin_answer": "Amazon EMR 在两个 Amazon EC2 安全组中启动您的实例，一组用于主实例，另一组用于其他集群节点。主安全组的端口是开放的，以便与服务进行通信。它的 SSH 端口也呈开放状态，以允许您使用启动时指定的密钥 SSH 到实例。其他节点在单独的安全组中启动，仅允许与主实例进行交互。默认情况下，两个安全组都设置为不允许从属于其他客户的 Amazon EC2 实例等外部源进行访问。由于这些是您账户内的安全组，所以您可以使用标准 EC2 工具或控制面板重新配置它们。单击此处详细了解 EC2 安全组。此外，如果规则允许在您未添加到例外情况列表的任何端口进行公有访问，您可以在用于阻止集群创建的每个区域中配置 Amazon EMR 阻止公有访问。", "generate_question": "用户如何了解更多关于 Amazon EC2 安全组的详细信息？", "generate_answer": "用户可以点击链接了解更多关于 Amazon EC2 安全组的详细信息。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "Amazon S3如何确保我的数据安全？", "generate_answer": "Amazon S3提供身份验证机制，只有授权的用户才能访问数据，确保数据的安全性。此外，客户还可以选择使用HTTPS协议将数据发送到Amazon S3，以确保安全传输。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "Amazon EMR如何确保数据的安全传输？", "generate_answer": "Amazon EMR始终使用HTTPS协议在Amazon S3和Amazon EC2之间发送数据，以确保数据的安全传输。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "如何提高数据的安全性？", "generate_answer": "客户可以在将输入数据上传到Amazon S3之前对其进行加密，使用常见的数据压缩工具进行加密。然后，在Amazon EMR从Amazon S3提取数据时，客户需要在群集的开头添加一个解密步骤。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "是否可以指定其他用户访问我的数据？", "generate_answer": "除非上传数据的客户另行指定，否则只有该用户才能访问数据。Amazon S3提供身份验证机制，确保数据不会被未授权访问。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "Amazon S3是否支持数据加密？", "generate_answer": "是的，客户可以在将数据上传到Amazon S3之前对其进行加密，以提高数据的安全性。"}
{"origin_question": "\n我的数据的安全性如何？\n", "origin_answer": "Amazon S3 提供身份验证机制，确保存储的数据安全以防被未授权访问。除非上传数据的客户另行指定，否则仅该用户才能访问数据。Amazon EMR 客户还可以选择使用确保安全传送的 HTTPS 协议将数据发送到 Amazon S3。此外，Amazon EMR 始终使用 HTTPS 在 Amazon S3 与 Amazon EC2 之间发送数据。为了提高安全性，客户可以在将输入数据上传到 Amazon S3 之前对其进行加密（使用任何常见的数据压缩工具）；然后，当 Amazon EMR 从 Amazon S3 提取数据时，客户需要在其群集的开头添加一个解密步骤。\n", "generate_question": "Amazon EMR是否支持安全传输？", "generate_answer": "是的，Amazon EMR始终使用HTTPS协议在Amazon S3和Amazon EC2之间发送数据，以确保数据的安全传输。"}
{"origin_question": "\n我能否获得我的账户上所有的 EMR API 调用历史记录以用于安全或合规性审计？\n", "origin_answer": "是的。AWS CloudTrail 是一项 web 服务，为您的帐户记录 AWS API 调用并向您交付日志文件。由 CloudTrail 生成的 AWS API 调用历史记录可用于安全分析、资源变更追踪以及合规性审计。在 AWS CloudTrail 详细信息页面了解更多有关 CloudTrail 的信息，或者通过 CloudTrail 的 AWS 管理控制台将它打开。\n", "generate_question": "亚马逊云科技的 CloudTrail 是什么服务？", "generate_answer": "CloudTrail 是一项 web 服务，用于记录亚马逊云科技账户上的 AWS API 调用并生成日志文件。"}
{"origin_question": "\n我能否获得我的账户上所有的 EMR API 调用历史记录以用于安全或合规性审计？\n", "origin_answer": "是的。AWS CloudTrail 是一项 web 服务，为您的帐户记录 AWS API 调用并向您交付日志文件。由 CloudTrail 生成的 AWS API 调用历史记录可用于安全分析、资源变更追踪以及合规性审计。在 AWS CloudTrail 详细信息页面了解更多有关 CloudTrail 的信息，或者通过 CloudTrail 的 AWS 管理控制台将它打开。\n", "generate_question": "CloudTrail 的日志文件可以用于哪些目的？", "generate_answer": "CloudTrail 生成的日志文件可以用于安全分析、资源变更追踪以及合规性审计。"}
{"origin_question": "\n我能否获得我的账户上所有的 EMR API 调用历史记录以用于安全或合规性审计？\n", "origin_answer": "是的。AWS CloudTrail 是一项 web 服务，为您的帐户记录 AWS API 调用并向您交付日志文件。由 CloudTrail 生成的 AWS API 调用历史记录可用于安全分析、资源变更追踪以及合规性审计。在 AWS CloudTrail 详细信息页面了解更多有关 CloudTrail 的信息，或者通过 CloudTrail 的 AWS 管理控制台将它打开。\n", "generate_question": "如何打开 CloudTrail？", "generate_answer": "您可以通过 CloudTrail 的 AWS 管理控制台将其打开。"}
{"origin_question": "\n我能否获得我的账户上所有的 EMR API 调用历史记录以用于安全或合规性审计？\n", "origin_answer": "是的。AWS CloudTrail 是一项 web 服务，为您的帐户记录 AWS API 调用并向您交付日志文件。由 CloudTrail 生成的 AWS API 调用历史记录可用于安全分析、资源变更追踪以及合规性审计。在 AWS CloudTrail 详细信息页面了解更多有关 CloudTrail 的信息，或者通过 CloudTrail 的 AWS 管理控制台将它打开。\n", "generate_question": "CloudTrail 可以记录哪些信息？", "generate_answer": "CloudTrail 可以记录亚马逊云科技账户上的 AWS API 调用历史记录。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "Amazon EMR 如何控制用户在 Amazon S3 中的访问权限？", "generate_answer": "Amazon EMR 提供了三种选项来管理用户对 Amazon S3 数据的访问权限。这包括与 AWS Lake Formation 的集成、与 Apache Ranger 的本地集成以及使用 Amazon EMR User Role Mapper。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 AWS Lake Formation？", "generate_answer": "AWS Lake Formation 是一项服务，用于定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "如何使用 AWS Lake Formation 来授权用户对 Amazon S3 数据的访问？", "generate_answer": "通过与 AWS Lake Formation 的集成，您可以在 Amazon EMR Notebooks 和 Apache Zeppelin 中实施授权策略，并将审核事件发送到 AWS CloudTrail。此外，您还可以从与 SAML 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 Apache Ranger？", "generate_answer": "Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。它可以与 Amazon EMR 集成，以定义和管理精细授权策略，使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "如何使用 Apache Ranger 来授权用户对 Amazon S3 数据的访问？", "generate_answer": "通过与 Apache Ranger 的本地集成，您可以在 Apache Ranger Policy Admin 服务器上定义授权策略，包括为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会自动安装和配置相应的 Apache Ranger 插件，并将审核事件发送到 Amazon CloudWatch Logs。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "Amazon EMR User Role Mapper 是用来做什么的？", "generate_answer": "Amazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以创建用户（或组）与自定义 IAM 角色之间的映射，从而限制用户或组只能访问自定义 IAM 角色允许的数据。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "如何使用 Amazon EMR User Role Mapper 来控制用户对 Amazon S3 的访问？", "generate_answer": "您可以使用 Amazon EMR User Role Mapper 来创建用户（或组）与自定义 IAM 角色之间的映射，从而限制用户或组只能访问自定义 IAM 角色允许的 Amazon S3 数据。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "Amazon EMR 提供了哪些选项来管理用户对 Amazon S3 数据的访问？", "generate_answer": "Amazon EMR 提供了与 AWS Lake Formation 的集成、与 Apache Ranger 的本地集成以及使用 Amazon EMR User Role Mapper 三种选项来管理用户对 Amazon S3 数据的访问。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 EC2 实例配置文件？", "generate_answer": "EC2 实例配置文件是 Amazon EMR 应用程序流程在调用其他 AWS 服务时使用的默认身份验证机制。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "多租户集群中如何管理用户对 Amazon S3 数据的访问？", "generate_answer": "对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问，包括与 AWS Lake Formation 的集成、与 Apache Ranger 的本地集成以及使用 Amazon EMR User Role Mapper。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 AWS CloudTrail？", "generate_answer": "AWS CloudTrail 是一项服务，用于跟踪、记录和存储与 AWS 资源相关的活动和事件。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "如何将审核事件发送到 AWS CloudTrail？", "generate_answer": "通过与 AWS Lake Formation 的集成，您可以将审核事件发送到 AWS CloudTrail，以便记录和存储与 Amazon EMR Notebooks 和 Apache Zeppelin 中的交互式 EMR Spark 工作负载相关的活动和事件。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 SAML 2.0？", "generate_answer": "SAML 2.0 是一种用于在不同的身份验证系统之间进行安全断言交换的开放标准。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "如何启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录？", "generate_answer": "通过与 AWS Lake Formation 的集成，您可以从与 SAML 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。"}
{"origin_question": "\n如何控制 EMR 用户在 Amazon S3 中可以访问的内容？\n", "origin_answer": "默认情况下，Amazon EMR 应用程序流程在调用其他 AWS 服务时使用 EC2 实例配置文件。对于多租户集群，Amazon EMR 提供了三个选项来管理用户对 Amazon S3 数据的访问。\n与 AWS Lake Formation 的集成允许您定义和管理 AWS Lake Formation 中的精细授权策略，以访问 AWS Glue 数据目录中的数据库、表和列。您可以对通过 Amazon EMR Notebooks 和 Apache Zeppelin 提交的用于交互式 EMR Spark 工作负载的作业实施授权策略，并将审核事件发送到 AWS CloudTrail。通过启用此集成，您还可以从与安全断言标记语言 (SAML) 2.0 兼容的企业身份验证系统中启用到 EMR Notebooks 或 Apache Zeppelin 的联合单点登录。\n与 Apache Ranger 的本机集成允许您设置新的或现有的 Apache Ranger 服务器，以定义和管理精细授权策略，从而使用户可以通过 Hive Metastore 访问 Amazon S3 数据的数据库、表和列。Apache Ranger 是一个开源工具，用于在 Hadoop 平台上启用、监视和管理全面的数据安全。\n\n通过本机集成，您可以在 Apache Ranger Policy Admin 服务器上定义三种授权策略。您可以为 Hive 设置数据表、数据列和数据行级别的授权，为 Spark 设置数据表和数据列级别的授权，以及为 Amazon S3 设置前缀和对象级别的授权。Amazon EMR 会在集群上自动安装和配置相应的 Apache Ranger 插件。这些 Ranger 插件与 Policy Admin 服务器同步，以定义授权策略，实施数据访问控制，并将审核事件发送到 Amazon CloudWatch Logs。\nAmazon EMR User Role Mapper 允许您利用 AWS IAM 权限来管理对 AWS 资源的访问。您可以在用户（或组）和自定义 IAM 角色之间创建映射。用户或组只能访问自定义 IAM 角色允许的数据。目前可通过 AWS 实验室使用该功能。", "generate_question": "什么是 AWS IAM？", "generate_answer": "AWS IAM 是一项服务，用于管理 AWS 资源的身份验证和访问控制。"}
{"origin_question": "\nAmazon EMR 如何运用可用区？\n", "origin_answer": "Amazon EMR 可启动同一 Amazon EC2 可用区中给定集群的所有节点。在同一可用区内运行集群可提高任务流的性能。默认情况下，Amazon EMR 选择运行集群的可用资源最多的可用区域。不过，如果需要，您可以指定其他可用区。您还可以选择为价格最低的按需实例优化分配、优化 Spot 容量或使用按需容量预留。\n", "generate_question": "Amazon EMR 如何选择运行集群的可用区？", "generate_answer": "Amazon EMR 默认选择运行集群的可用资源最多的可用区域，但也可以指定其他可用区。"}
{"origin_question": "\nAmazon EMR 如何运用可用区？\n", "origin_answer": "Amazon EMR 可启动同一 Amazon EC2 可用区中给定集群的所有节点。在同一可用区内运行集群可提高任务流的性能。默认情况下，Amazon EMR 选择运行集群的可用资源最多的可用区域。不过，如果需要，您可以指定其他可用区。您还可以选择为价格最低的按需实例优化分配、优化 Spot 容量或使用按需容量预留。\n", "generate_question": "Amazon EMR 如何提高任务流的性能？", "generate_answer": "在同一可用区内运行集群可以提高任务流的性能。"}
{"origin_question": "\nAmazon EMR 如何运用可用区？\n", "origin_answer": "Amazon EMR 可启动同一 Amazon EC2 可用区中给定集群的所有节点。在同一可用区内运行集群可提高任务流的性能。默认情况下，Amazon EMR 选择运行集群的可用资源最多的可用区域。不过，如果需要，您可以指定其他可用区。您还可以选择为价格最低的按需实例优化分配、优化 Spot 容量或使用按需容量预留。\n", "generate_question": "Amazon EMR 可以优化哪些资源分配方式？", "generate_answer": "Amazon EMR 可以优化按需实例分配、Spot 容量优化或按需容量预留。"}
{"origin_question": "\nAmazon EMR 如何运用可用区？\n", "origin_answer": "Amazon EMR 可启动同一 Amazon EC2 可用区中给定集群的所有节点。在同一可用区内运行集群可提高任务流的性能。默认情况下，Amazon EMR 选择运行集群的可用资源最多的可用区域。不过，如果需要，您可以指定其他可用区。您还可以选择为价格最低的按需实例优化分配、优化 Spot 容量或使用按需容量预留。\n", "generate_question": "Amazon EMR 是否支持按需容量预留？", "generate_answer": "是的，Amazon EMR 支持按需容量预留。"}
{"origin_question": "\n在哪些区域可以使用 Amazon EMR？\n", "origin_answer": "要了解支持 Amazon EMR 的 AWS 区域列表，请访问所有 AWS 全球基础设施的 AWS 区域表。\n", "generate_question": "Amazon EMR 可以在哪些 AWS 区域使用？", "generate_answer": "Amazon EMR 可以在所有 AWS 全球基础设施的 AWS 区域中使用。"}
{"origin_question": "\n在哪些区域可以使用 Amazon EMR？\n", "origin_answer": "要了解支持 Amazon EMR 的 AWS 区域列表，请访问所有 AWS 全球基础设施的 AWS 区域表。\n", "generate_question": "如何了解支持 Amazon EMR 的 AWS 区域列表？", "generate_answer": "要了解支持 Amazon EMR 的 AWS 区域列表，可以访问所有 AWS 全球基础设施的 AWS 区域表。"}
{"origin_question": "\nAWS Local Zones 是否支持 Amazon EMR？\n", "origin_answer": "EMR 支持在洛杉矶 AWS 本地扩展区启动集群。您可以在美国西部（俄勒冈）区域使用 EMR，以在与洛杉矶 AWS 本地扩展区相关的子网中启动集群。\n", "generate_question": "AWS Local Zones 支持在哪个区域启动 Amazon EMR？", "generate_answer": "AWS Local Zones 支持在美国西部（俄勒冈）区域启动 Amazon EMR。"}
{"origin_question": "\nAWS Local Zones 是否支持 Amazon EMR？\n", "origin_answer": "EMR 支持在洛杉矶 AWS 本地扩展区启动集群。您可以在美国西部（俄勒冈）区域使用 EMR，以在与洛杉矶 AWS 本地扩展区相关的子网中启动集群。\n", "generate_question": "在哪个子网中可以启动 Amazon EMR 集群？", "generate_answer": "在与洛杉矶 AWS 本地扩展区相关的子网中可以启动 Amazon EMR 集群。"}
{"origin_question": "\nAWS Local Zones 是否支持 Amazon EMR？\n", "origin_answer": "EMR 支持在洛杉矶 AWS 本地扩展区启动集群。您可以在美国西部（俄勒冈）区域使用 EMR，以在与洛杉矶 AWS 本地扩展区相关的子网中启动集群。\n", "generate_question": "Amazon EMR 是否支持在其他本地扩展区启动集群？", "generate_answer": "目前，Amazon EMR 仅支持在洛杉矶 AWS 本地扩展区启动集群。"}
{"origin_question": "\n我应选择哪个地区来运行群集？\n", "origin_answer": "创建群集时，通常应选择您的数据所在的区域。\n", "generate_question": "如何确定应该选择哪个地区来运行群集？", "generate_answer": "在创建群集时，您应该考虑您的数据所在的区域，以确保数据的低延迟和高可用性。"}
{"origin_question": "\n我应选择哪个地区来运行群集？\n", "origin_answer": "创建群集时，通常应选择您的数据所在的区域。\n", "generate_question": "选择哪个地区来运行群集有什么影响？", "generate_answer": "选择不同的地区来运行群集会影响数据的传输速度、延迟和可用性。选择距离用户或数据源较近的地区可以提供更低的延迟和更快的数据传输速度。"}
{"origin_question": "\n在美国地区运行的集群中是否可使用欧洲数据（反之亦然）？\n", "origin_answer": "是的，您可以。如果您在不同的地区之间传输数据，将对您收取带宽费用。有关带宽定价信息，请访问 EC2 详细信息页面上的定价部分。\n", "generate_question": "在哪些地区可以使用亚马逊云科技的集群？", "generate_answer": "亚马逊云科技的集群可以在美国地区运行。"}
{"origin_question": "\n在美国地区运行的集群中是否可使用欧洲数据（反之亦然）？\n", "origin_answer": "是的，您可以。如果您在不同的地区之间传输数据，将对您收取带宽费用。有关带宽定价信息，请访问 EC2 详细信息页面上的定价部分。\n", "generate_question": "是否需要支付额外费用才能在不同地区之间传输数据？", "generate_answer": "是的，如果在不同地区之间传输数据，将会收取带宽费用。"}
{"origin_question": "\n在美国地区运行的集群中是否可使用欧洲数据（反之亦然）？\n", "origin_answer": "是的，您可以。如果您在不同的地区之间传输数据，将对您收取带宽费用。有关带宽定价信息，请访问 EC2 详细信息页面上的定价部分。\n", "generate_question": "是否可以在美国地区的集群中使用欧洲数据？", "generate_answer": "是的，可以在美国地区的集群中使用欧洲数据。"}
{"origin_question": "\nAWS GovCloud（美国）地区有何不同之处？\n", "origin_answer": "AWS GovCloud（美国）区域专为美国政府机构和客户而设计。它遵循 US ITAR 要求。在 GovCloud，EMR 不支持 Spot 实例或启用调试功能。EMR 管理控制台在 GovCloud 中尚不可用。\n\n", "generate_question": "AWS GovCloud（美国）地区是为哪些客户和机构设计的？", "generate_answer": "AWS GovCloud（美国）地区是为美国政府机构和客户而设计的。"}
{"origin_question": "\nAWS GovCloud（美国）地区有何不同之处？\n", "origin_answer": "AWS GovCloud（美国）区域专为美国政府机构和客户而设计。它遵循 US ITAR 要求。在 GovCloud，EMR 不支持 Spot 实例或启用调试功能。EMR 管理控制台在 GovCloud 中尚不可用。\n\n", "generate_question": "AWS GovCloud（美国）地区遵循哪个要求？", "generate_answer": "AWS GovCloud（美国）地区遵循 US ITAR 要求。"}
{"origin_question": "\nAWS GovCloud（美国）地区有何不同之处？\n", "origin_answer": "AWS GovCloud（美国）区域专为美国政府机构和客户而设计。它遵循 US ITAR 要求。在 GovCloud，EMR 不支持 Spot 实例或启用调试功能。EMR 管理控制台在 GovCloud 中尚不可用。\n\n", "generate_question": "在AWS GovCloud（美国）地区，EMR支持哪些功能？", "generate_answer": "在AWS GovCloud（美国）地区，EMR不支持Spot实例或启用调试功能。EMR管理控制台在GovCloud中尚不可用。"}
{"origin_question": "\n什么是 Amazon EMR 集群？\n", "origin_answer": "\n集群是 Aazon Elastic Compute Cloud (Amazon EC2)实例的集合。集群中的每个实例都称为节点，并在集群内具有一个角色，称为节点类型。Amazon EMR 还在每个节点类型安装不同的软件组件，在 Apache Hadoop 等分布式应用程序中为每个节点提供一个角色。每个集群都有一个以“j-”开头的唯一标识符。", "generate_question": "Amazon EMR 集群是由什么组成的？", "generate_answer": "Amazon EMR 集群是由一组 Amazon Elastic Compute Cloud (Amazon EC2) 实例组成。"}
{"origin_question": "\n什么是 Amazon EMR 集群？\n", "origin_answer": "\n集群是 Aazon Elastic Compute Cloud (Amazon EC2)实例的集合。集群中的每个实例都称为节点，并在集群内具有一个角色，称为节点类型。Amazon EMR 还在每个节点类型安装不同的软件组件，在 Apache Hadoop 等分布式应用程序中为每个节点提供一个角色。每个集群都有一个以“j-”开头的唯一标识符。", "generate_question": "每个 Amazon EMR 集群中的实例被称为什么？", "generate_answer": "每个 Amazon EMR 集群中的实例被称为节点。"}
{"origin_question": "\n什么是 Amazon EMR 集群？\n", "origin_answer": "\n集群是 Aazon Elastic Compute Cloud (Amazon EC2)实例的集合。集群中的每个实例都称为节点，并在集群内具有一个角色，称为节点类型。Amazon EMR 还在每个节点类型安装不同的软件组件，在 Apache Hadoop 等分布式应用程序中为每个节点提供一个角色。每个集群都有一个以“j-”开头的唯一标识符。", "generate_question": "Amazon EMR 集群中的每个节点都具有什么角色？", "generate_answer": "Amazon EMR 集群中的每个节点都具有一个角色，称为节点类型。"}
{"origin_question": "\n什么是 Amazon EMR 集群？\n", "origin_answer": "\n集群是 Aazon Elastic Compute Cloud (Amazon EC2)实例的集合。集群中的每个实例都称为节点，并在集群内具有一个角色，称为节点类型。Amazon EMR 还在每个节点类型安装不同的软件组件，在 Apache Hadoop 等分布式应用程序中为每个节点提供一个角色。每个集群都有一个以“j-”开头的唯一标识符。", "generate_question": "Amazon EMR 集群有什么唯一标识符？", "generate_answer": "每个 Amazon EMR 集群都有一个以“j-”开头的唯一标识符。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "亚马逊云科技的集群中有几种节点类型？", "generate_answer": "亚马逊云科技的集群中有三种节点类型。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "主节点的作用是什么？", "generate_answer": "主节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "每个集群都有几个主节点？", "generate_answer": "每个集群都有一个主节点。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "核心节点的作用是什么？", "generate_answer": "核心节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "任务节点的作用是什么？", "generate_answer": "任务节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点是可选的。"}
{"origin_question": "\n集群中的节点类型是什么？\n", "origin_answer": "\nAmazon MR 集群拥有三种类型的节点：主节点：该节点通过运行软件组件来协调数据和任务在其他节点之间的分配，以方便处理，以此管理集群。主节点跟踪任务的状态并监控集群的健康状况。每个集群都有一个主节点，并且可以创建只有主节点的单节点集群。\n核心节点：该节点具有软件组件，用于在集群上的 Hadoop Distributed File System (HDFS) 中运行任务和存储数据。多节点集群至少有一个核心节点。\n任务节点：该节点具有软件组件，仅运行任务，不会在 HDFS 中存储数据。任务节点可选。\n", "generate_question": "亚马逊云科技的集群中可以创建只有主节点的集群吗？", "generate_answer": "是的，亚马逊云科技的集群可以创建只有主节点的单节点集群。"}
{"origin_question": "\n什么是集群步骤？\n", "origin_answer": "\n群集步骤由用户定义的处理单位，大约与操作数据的一种算法相对应。一个步骤就是作为以 Java、Ruby、Perl、Python、PHP、R 或 C++ 编写的Java Jar 或流程序实施的 Hadoop MapReduce 应用程序。例如，要计算文档中单词的出现频率并按计数排序输出它们，第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。\n", "generate_question": "集群步骤是由谁定义的？", "generate_answer": "集群步骤是由用户定义的。"}
{"origin_question": "\n什么是集群步骤？\n", "origin_answer": "\n群集步骤由用户定义的处理单位，大约与操作数据的一种算法相对应。一个步骤就是作为以 Java、Ruby、Perl、Python、PHP、R 或 C++ 编写的Java Jar 或流程序实施的 Hadoop MapReduce 应用程序。例如，要计算文档中单词的出现频率并按计数排序输出它们，第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。\n", "generate_question": "集群步骤与什么相对应？", "generate_answer": "集群步骤大约与操作数据的一种算法相对应。"}
{"origin_question": "\n什么是集群步骤？\n", "origin_answer": "\n群集步骤由用户定义的处理单位，大约与操作数据的一种算法相对应。一个步骤就是作为以 Java、Ruby、Perl、Python、PHP、R 或 C++ 编写的Java Jar 或流程序实施的 Hadoop MapReduce 应用程序。例如，要计算文档中单词的出现频率并按计数排序输出它们，第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。\n", "generate_question": "集群步骤可以使用哪些编程语言来实施？", "generate_answer": "集群步骤可以使用 Java、Ruby、Perl、Python、PHP、R 或 C++ 编程语言来实施。"}
{"origin_question": "\n什么是集群步骤？\n", "origin_answer": "\n群集步骤由用户定义的处理单位，大约与操作数据的一种算法相对应。一个步骤就是作为以 Java、Ruby、Perl、Python、PHP、R 或 C++ 编写的Java Jar 或流程序实施的 Hadoop MapReduce 应用程序。例如，要计算文档中单词的出现频率并按计数排序输出它们，第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。\n", "generate_question": "请举例说明一个集群步骤的应用场景。", "generate_answer": "一个集群步骤的应用场景可以是计算文档中单词的出现频率并按计数排序输出它们。"}
{"origin_question": "\n什么是集群步骤？\n", "origin_answer": "\n群集步骤由用户定义的处理单位，大约与操作数据的一种算法相对应。一个步骤就是作为以 Java、Ruby、Perl、Python、PHP、R 或 C++ 编写的Java Jar 或流程序实施的 Hadoop MapReduce 应用程序。例如，要计算文档中单词的出现频率并按计数排序输出它们，第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。\n", "generate_question": "集群步骤的第一步和第二步分别是什么？", "generate_answer": "集群步骤的第一步是计算每个单词出现次数的 MapReduce 应用程序，第二步是根据计数对第一步的输出排序的 MapReduce 应用程序。"}
{"origin_question": "\n集群有哪些不同的状态？\n", "origin_answer": "\nSTARTIN – 集群通过配置 EC2 实例开启。BOOTSTRAPPING – 集群上正在执行引导操作。\nRUNNING – 群集当前正在运行的步骤。\nWAITING – 群集当前处于活动状态，但没有运行步骤。\nTERMINATING – 群集正在关闭。\nTERMINATED – 群集已在未发生错误的情况下关闭。\nTERMINATED_WITH_ERRORS – 群集在发生错误的情况下关闭。", "generate_question": "集群有哪些不同的状态？", "generate_answer": "集群有以下不同的状态：STARTIN、BOOTSTRAPPING、RUNNING、WAITING、TERMINATING、TERMINATED和TERMINATED_WITH_ERRORS。"}
{"origin_question": "\n集群有哪些不同的状态？\n", "origin_answer": "\nSTARTIN – 集群通过配置 EC2 实例开启。BOOTSTRAPPING – 集群上正在执行引导操作。\nRUNNING – 群集当前正在运行的步骤。\nWAITING – 群集当前处于活动状态，但没有运行步骤。\nTERMINATING – 群集正在关闭。\nTERMINATED – 群集已在未发生错误的情况下关闭。\nTERMINATED_WITH_ERRORS – 群集在发生错误的情况下关闭。", "generate_question": "什么是STARTIN状态？", "generate_answer": "STARTIN状态表示集群通过配置EC2实例开启。"}
{"origin_question": "\n集群有哪些不同的状态？\n", "origin_answer": "\nSTARTIN – 集群通过配置 EC2 实例开启。BOOTSTRAPPING – 集群上正在执行引导操作。\nRUNNING – 群集当前正在运行的步骤。\nWAITING – 群集当前处于活动状态，但没有运行步骤。\nTERMINATING – 群集正在关闭。\nTERMINATED – 群集已在未发生错误的情况下关闭。\nTERMINATED_WITH_ERRORS – 群集在发生错误的情况下关闭。", "generate_question": "什么是BOOTSTRAPPING状态？", "generate_answer": "BOOTSTRAPPING状态表示集群上正在执行引导操作。"}
{"origin_question": "\n集群有哪些不同的状态？\n", "origin_answer": "\nSTARTIN – 集群通过配置 EC2 实例开启。BOOTSTRAPPING – 集群上正在执行引导操作。\nRUNNING – 群集当前正在运行的步骤。\nWAITING – 群集当前处于活动状态，但没有运行步骤。\nTERMINATING – 群集正在关闭。\nTERMINATED – 群集已在未发生错误的情况下关闭。\nTERMINATED_WITH_ERRORS – 群集在发生错误的情况下关闭。", "generate_question": "什么是RUNNING状态？", "generate_answer": "RUNNING状态表示集群当前正在运行的步骤。"}
{"origin_question": "\n步骤有哪些不同的状态？\n", "origin_answer": "\nPENDING– 该步骤正在等待运行。RUNNING – 该步骤当前正在运行。\nCOMPLETED – 该步骤已成功完成。\nCANCELLED – 该步骤在运行前被取消，因为上一步出现故障或群集在运行前已终止。\nFAILED – 该步骤在运行中出现故障。\n\n启动集群", "generate_question": "步骤有哪些不同的状态？", "generate_answer": "PENDING、RUNNING、COMPLETED、CANCELLED、FAILED。"}
{"origin_question": "\n步骤有哪些不同的状态？\n", "origin_answer": "\nPENDING– 该步骤正在等待运行。RUNNING – 该步骤当前正在运行。\nCOMPLETED – 该步骤已成功完成。\nCANCELLED – 该步骤在运行前被取消，因为上一步出现故障或群集在运行前已终止。\nFAILED – 该步骤在运行中出现故障。\n\n启动集群", "generate_question": "亚马逊云科技的集群启动需要哪些步骤？", "generate_answer": "集群启动需要经过PENDING、RUNNING、COMPLETED等不同的状态。"}
{"origin_question": "\n步骤有哪些不同的状态？\n", "origin_answer": "\nPENDING– 该步骤正在等待运行。RUNNING – 该步骤当前正在运行。\nCOMPLETED – 该步骤已成功完成。\nCANCELLED – 该步骤在运行前被取消，因为上一步出现故障或群集在运行前已终止。\nFAILED – 该步骤在运行中出现故障。\n\n启动集群", "generate_question": "什么情况下会导致步骤被取消？", "generate_answer": "步骤在运行前被取消的情况包括上一步出现故障或群集在运行前已终止。"}
{"origin_question": "\n步骤有哪些不同的状态？\n", "origin_answer": "\nPENDING– 该步骤正在等待运行。RUNNING – 该步骤当前正在运行。\nCOMPLETED – 该步骤已成功完成。\nCANCELLED – 该步骤在运行前被取消，因为上一步出现故障或群集在运行前已终止。\nFAILED – 该步骤在运行中出现故障。\n\n启动集群", "generate_question": "什么情况下会导致步骤失败？", "generate_answer": "步骤在运行中出现故障时会导致步骤失败。"}
{"origin_question": "\n如何启动集群？\n", "origin_answer": "\n您可以通在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。", "generate_question": "如何启动集群？", "generate_answer": "您可以在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。"}
{"origin_question": "\n如何启动集群？\n", "origin_answer": "\n您可以通在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。", "generate_question": "在 AWS 管理控制台中如何指定群集的名称？", "generate_answer": "在 AWS 管理控制台中启动集群时，您可以在请求表中指定群集的名称。"}
{"origin_question": "\n如何启动集群？\n", "origin_answer": "\n您可以通在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。", "generate_question": "在 AWS 管理控制台中如何指定输入数据的位置？", "generate_answer": "在 AWS 管理控制台中启动集群时，您可以在请求表中指定 Amazon S3 中输入数据的位置。"}
{"origin_question": "\n如何启动集群？\n", "origin_answer": "\n您可以通在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。", "generate_question": "在 AWS 管理控制台中如何指定希望使用的 Amazon EC2 实例数量和类型？", "generate_answer": "在 AWS 管理控制台中启动集群时，您可以在请求表中指定希望使用的 Amazon EC2 实例数量和类型。"}
{"origin_question": "\n如何启动集群？\n", "origin_answer": "\n您可以通在 AWS 管理控制台中填写简单的群集请求表启动群集。在请求表中，需要指定群集的名称、Amazon S3中输入数据的位置、处理应用程序、理想的数据输出位置、希望使用的 Amazon EC2 实例数量和类型。您也可以指定一个存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。此外，您可以使用 RunJobFlow API 或在命令行工具中使用 ‘create’ 命令启动集群。要使用 EMR Studio 启动集群，请参阅下面的 EMR Studio 部分。", "generate_question": "在 AWS 管理控制台中如何指定存储群集日志文件和 SSH 密钥的位置？", "generate_answer": "在 AWS 管理控制台中启动集群时，您可以在请求表中指定存储群集日志文件和 SSH 密钥的位置，以便在群集运行时进行登录。"}
{"origin_question": "\n如何终止集群？\n", "origin_answer": "\n您可以随在 AWS 管理控制台中选择群集并单击“终止”按钮来终止群集。此外，也可以使用 TerminateJobFlowsAPI。如果终止正在运行的群集，Amazon S3 中尚未保存的任何结果都将丢失，并且所有 Amazon EC2 实例都会关闭。", "generate_question": "如何终止亚马逊云科技的集群？", "generate_answer": "您可以在 AWS 管理控制台中选择集群并点击“终止”按钮来终止集群。另外，您也可以使用 TerminateJobFlowsAPI 来终止集群。请注意，如果终止正在运行的集群，任何尚未保存在 Amazon S3 中的结果都将丢失，并且所有 Amazon EC2 实例都将关闭。"}
{"origin_question": "\n如何终止集群？\n", "origin_answer": "\n您可以随在 AWS 管理控制台中选择群集并单击“终止”按钮来终止群集。此外，也可以使用 TerminateJobFlowsAPI。如果终止正在运行的群集，Amazon S3 中尚未保存的任何结果都将丢失，并且所有 Amazon EC2 实例都会关闭。", "generate_question": "终止集群会导致什么结果？", "generate_answer": "终止集群会导致在 Amazon S3 中尚未保存的任何结果丢失，并且所有 Amazon EC2 实例都会关闭。"}
{"origin_question": "\n如何终止集群？\n", "origin_answer": "\n您可以随在 AWS 管理控制台中选择群集并单击“终止”按钮来终止群集。此外，也可以使用 TerminateJobFlowsAPI。如果终止正在运行的群集，Amazon S3 中尚未保存的任何结果都将丢失，并且所有 Amazon EC2 实例都会关闭。", "generate_question": "除了在 AWS 管理控制台中终止集群，还有其他的终止集群的方法吗？", "generate_answer": "是的，除了在 AWS 管理控制台中终止集群，您还可以使用 TerminateJobFlowsAPI 来终止集群。"}
{"origin_question": "\nAmazon EMR 是否支持多个集群同时操作？\n", "origin_answer": "\n您可以根需要运行任何数量的集群。但开始使用时，在所有集群中，运行的实例数限额为 20 个。如果需要运行更多数量的实例，请填写 Amazon EC2实例请求表。一旦您的 Amazon EC2 限额已提升，将会对您的 Amazon EMR 集群自动应用新的限额。\n管理集群", "generate_question": "Amazon EMR 是否支持多个集群同时操作？", "generate_answer": "是的，您可以根据需要同时运行多个集群。"}
{"origin_question": "\nAmazon EMR 是否支持多个集群同时操作？\n", "origin_answer": "\n您可以根需要运行任何数量的集群。但开始使用时，在所有集群中，运行的实例数限额为 20 个。如果需要运行更多数量的实例，请填写 Amazon EC2实例请求表。一旦您的 Amazon EC2 限额已提升，将会对您的 Amazon EMR 集群自动应用新的限额。\n管理集群", "generate_question": "在所有集群中运行的实例数有限制吗？", "generate_answer": "是的，开始使用时，在所有集群中运行的实例数限额为20个。"}
{"origin_question": "\nAmazon EMR 是否支持多个集群同时操作？\n", "origin_answer": "\n您可以根需要运行任何数量的集群。但开始使用时，在所有集群中，运行的实例数限额为 20 个。如果需要运行更多数量的实例，请填写 Amazon EC2实例请求表。一旦您的 Amazon EC2 限额已提升，将会对您的 Amazon EMR 集群自动应用新的限额。\n管理集群", "generate_question": "如果需要运行更多数量的实例，应该怎么做？", "generate_answer": "如果需要运行更多数量的实例，您可以填写Amazon EC2实例请求表来申请提升Amazon EC2限额。一旦限额提升成功，新的限额将自动应用于您的Amazon EMR集群。"}
{"origin_question": "\nAmazon EMR 是否支持多个集群同时操作？\n", "origin_answer": "\n您可以根需要运行任何数量的集群。但开始使用时，在所有集群中，运行的实例数限额为 20 个。如果需要运行更多数量的实例，请填写 Amazon EC2实例请求表。一旦您的 Amazon EC2 限额已提升，将会对您的 Amazon EMR 集群自动应用新的限额。\n管理集群", "generate_question": "如何管理集群？", "generate_answer": "您可以使用Amazon EMR来管理集群。"}
{"origin_question": "\nAmazon EMR 如何使用 Amazon EC2 和 Amazon S3？\n", "origin_answer": "可以将您的输入数据和数据处理应用程序上传到 Amazon S3。然后，Amazon EMR 将按您指定启动一定数量的 Amazon EC2 实例。该服务开始执行集群，同时使用 S3 URI 方案将输入数据从 Amazon S3 推入启动的 Amazon EC2 实例。一旦集群完成后，Amazon EMR 即可将输出数据传输到 Amazon S3，您在此可以取回数据或将其用作其他集群的输入数据。", "generate_question": "如何使用 Amazon EMR 进行数据处理？", "generate_answer": "您可以将输入数据和数据处理应用程序上传到 Amazon S3，并使用 Amazon EMR 启动 Amazon EC2 实例来执行数据处理任务。输入数据从 Amazon S3 推送到 Amazon EC2 实例上的集群，并在集群完成后将输出数据传输回 Amazon S3。"}
{"origin_question": "\nAmazon EMR 如何使用 Amazon EC2 和 Amazon S3？\n", "origin_answer": "可以将您的输入数据和数据处理应用程序上传到 Amazon S3。然后，Amazon EMR 将按您指定启动一定数量的 Amazon EC2 实例。该服务开始执行集群，同时使用 S3 URI 方案将输入数据从 Amazon S3 推入启动的 Amazon EC2 实例。一旦集群完成后，Amazon EMR 即可将输出数据传输到 Amazon S3，您在此可以取回数据或将其用作其他集群的输入数据。", "generate_question": "Amazon EMR 如何管理数据？", "generate_answer": "Amazon EMR 可以与 Amazon S3 集成，您可以将数据存储在 Amazon S3 上，并使用 S3 URI 方案将数据传输到 Amazon EMR 集群中进行处理。同时，Amazon EMR 还支持将数据存储在 Hadoop 分布式文件系统（HDFS）中，以供集群内部使用。"}
{"origin_question": "\nAmazon EMR 如何使用 Amazon EC2 和 Amazon S3？\n", "origin_answer": "可以将您的输入数据和数据处理应用程序上传到 Amazon S3。然后，Amazon EMR 将按您指定启动一定数量的 Amazon EC2 实例。该服务开始执行集群，同时使用 S3 URI 方案将输入数据从 Amazon S3 推入启动的 Amazon EC2 实例。一旦集群完成后，Amazon EMR 即可将输出数据传输到 Amazon S3，您在此可以取回数据或将其用作其他集群的输入数据。", "generate_question": "Amazon EMR 如何扩展集群规模？", "generate_answer": "您可以通过在 Amazon EMR 控制台或使用 AWS CLI 命令来扩展集群规模。通过增加 Amazon EC2 实例的数量，您可以增加集群的计算能力。同时，您还可以根据需要减少实例数量来缩小集群规模。"}
{"origin_question": "\nAmazon EMR 如何使用 Amazon EC2 和 Amazon S3？\n", "origin_answer": "可以将您的输入数据和数据处理应用程序上传到 Amazon S3。然后，Amazon EMR 将按您指定启动一定数量的 Amazon EC2 实例。该服务开始执行集群，同时使用 S3 URI 方案将输入数据从 Amazon S3 推入启动的 Amazon EC2 实例。一旦集群完成后，Amazon EMR 即可将输出数据传输到 Amazon S3，您在此可以取回数据或将其用作其他集群的输入数据。", "generate_question": "Amazon EMR 如何处理输出数据？", "generate_answer": "Amazon EMR 可以将输出数据传输回 Amazon S3，您可以从 Amazon S3 中取回数据或将其用作其他集群的输入数据。此外，您还可以将输出数据存储在 Hadoop 分布式文件系统（HDFS）中，以供集群内部使用。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "Amazon EMR 使用什么数据处理引擎来进行计算？", "generate_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行计算。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "客户在 Amazon EMR 中如何执行他们的算法？", "generate_answer": "客户可以根据 map() 和 reduce() 函数执行他们的算法。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "Amazon EMR 可以启动哪些类型的 Amazon EC2 实例？", "generate_answer": "Amazon EMR 可以启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "Amazon EMR 如何处理输入数据？", "generate_answer": "Amazon EMR 的主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "Amazon EMR 如何处理中间数据？", "generate_answer": "Amazon EMR 对中间数据进行排序和分区，并将其发送到在节点本地应用缩减器函数的进程。"}
{"origin_question": "\n在 Amazon EMR 中如何进行计算？\n", "origin_answer": "Amazon EMR 使用 Hadoop 数据处理引擎来执行 MapReduce 编程模型中实施的计算。客户可根据 map() 和 reduce() 函数执行其算法。该服务可启动客户指定数量的 Amazon EC2 实例，其中包含一个主实例和多个其他节点。Amazon EMR 在这些实例上运行 Hadoop 软件。主节点将输入数据划分成数据块，并将数据块处理分配到其他节点。然后，每个节点对分配给它的数据运行 map 函数，生成中间数据。然后，对中间数据排序和分区，并将其发送到对其在节点本地应用缩减器函数的进程。最后，在文件中收集缩减器任务的输出。一个“集群”可能包含一系列上述 MapReduce 步骤。\n", "generate_question": "Amazon EMR 的一个“集群”包含哪些步骤？", "generate_answer": "一个“集群”可能包含一系列 MapReduce 步骤，包括数据划分、map 函数运行、中间数据处理和缩减器任务的输出收集。"}
{"origin_question": "\nAmazon EMR 支持哪些 Amazon EC2 实例类型？\n", "origin_answer": "有关最新可用实例类型和各区域定价的详细信息，请参阅 EMR 定价页面。", "generate_question": "Amazon EMR 支持哪些 Amazon EC2 实例类型？", "generate_answer": "Amazon EMR支持多种Amazon EC2实例类型，具体的实例类型和定价信息可以在EMR定价页面中找到。"}
{"origin_question": "\nAmazon EMR 支持哪些 Amazon EC2 实例类型？\n", "origin_answer": "有关最新可用实例类型和各区域定价的详细信息，请参阅 EMR 定价页面。", "generate_question": "在哪里可以找到关于Amazon EMR最新可用实例类型和各区域定价的详细信息？", "generate_answer": "关于Amazon EMR最新可用实例类型和各区域定价的详细信息可以在EMR定价页面中找到。"}
{"origin_question": "\n运行集群需要多长时间？\n", "origin_answer": "运行群集所需的时间取决于若干因素，包括群集的类型、输入数据的数量以及您为群集选择的 Amazon EC2 实例数量和类型。\n", "generate_question": "运行集群所需的因素有哪些？", "generate_answer": "运行群集所需的因素包括群集的类型、输入数据的数量以及您为群集选择的 Amazon EC2 实例数量和类型。"}
{"origin_question": "\n运行集群需要多长时间？\n", "origin_answer": "运行群集所需的时间取决于若干因素，包括群集的类型、输入数据的数量以及您为群集选择的 Amazon EC2 实例数量和类型。\n", "generate_question": "Amazon EC2 实例数量和类型对运行群集的时间有什么影响？", "generate_answer": "Amazon EC2 实例数量和类型的选择会影响运行群集的时间。不同数量和类型的实例可能具有不同的计算能力和处理速度，因此会影响群集的运行时间。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "Amazon EMR可以支持哪些应用程序的高可用性？", "generate_answer": "Amazon EMR可以支持YARN Resource Manager、HDFS Name Node、Spark、Hive和Ganglia等应用程序的高可用性。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "在EMR集群中，如果主节点出现故障，会发生什么？", "generate_answer": "如果主节点出现故障或者关键进程崩溃，Amazon EMR会自动将故障转移到备用主节点。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "EMR集群中的主节点是否是单点故障？", "generate_answer": "不是，EMR集群中的主节点不是潜在的单个故障点。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "如果发生故障转移，Amazon EMR会如何处理？", "generate_answer": "如果发生故障转移，Amazon EMR会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "在EMR集群中，是否可以运行长期存在的集群？", "generate_answer": "是的，由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的EMR集群。"}
{"origin_question": "\n如果集群中的主节点出现故障，Amazon EMR 是否可以使其恢复？\n", "origin_answer": "可以。您可以启动具有三个主节点的 EMR 集群（版本 5.23 或更高），并支持 YARN Resource Manager、HDFS Name Node、Spark、Hive 和 Ganglia 等应用程序的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。由于主节点不是潜在的单个故障点，您可以不间断地运行长期存在的 EMR 集群。如果发生故障转移，Amazon EMR 会自动使用具有相同配置和启动操作的新主节点替换发生故障的主节点。 \n", "generate_question": "在EMR集群中，需要满足什么条件才能实现主节点的高可用性？", "generate_answer": "要实现主节点的高可用性，您需要启动具有三个主节点的EMR集群（版本5.23或更高），并支持YARN Resource Manager、HDFS Name Node、Spark、Hive和Ganglia等应用程序的高可用性。"}
{"origin_question": "\n如果集群中的其他节点出现故障，Amazon EMR 是否可以从其恢复？\n", "origin_answer": "能。Amazon EMR 对于节点故障具有容错功能，当节点出现故障时将继续执行任务。Amazon EMR 还将在核心节点出现故障时预置新节点。但如果群集内的所有节点全部丢失，Amazon EMR 不会替换任何节点。\n", "generate_question": "Amazon EMR 是否具有容错功能来处理节点故障？", "generate_answer": "是的，Amazon EMR 对于节点故障具有容错功能，能够继续执行任务。"}
{"origin_question": "\n如果集群中的其他节点出现故障，Amazon EMR 是否可以从其恢复？\n", "origin_answer": "能。Amazon EMR 对于节点故障具有容错功能，当节点出现故障时将继续执行任务。Amazon EMR 还将在核心节点出现故障时预置新节点。但如果群集内的所有节点全部丢失，Amazon EMR 不会替换任何节点。\n", "generate_question": "当核心节点出现故障时，Amazon EMR 会如何处理？", "generate_answer": "Amazon EMR 会预置新节点来替代出现故障的核心节点。"}
{"origin_question": "\n如果集群中的其他节点出现故障，Amazon EMR 是否可以从其恢复？\n", "origin_answer": "能。Amazon EMR 对于节点故障具有容错功能，当节点出现故障时将继续执行任务。Amazon EMR 还将在核心节点出现故障时预置新节点。但如果群集内的所有节点全部丢失，Amazon EMR 不会替换任何节点。\n", "generate_question": "如果群集内的所有节点全部丢失，Amazon EMR 会替换任何节点吗？", "generate_answer": "不会，当群集内的所有节点全部丢失时，Amazon EMR 不会替换任何节点。"}
{"origin_question": "\n是否可以 SSH 到我的群集节点？\n", "origin_answer": "能。您可以 SSH 到自己的群集节点，并从该位置直接执行 Hadoop 命令。如果您需要 SSH 到特定节点，则必须首先 SSH 到主节点，然后再 SSH 到所需节点。\n", "generate_question": "如何 SSH 到亚马逊云科技的群集节点？", "generate_answer": "您可以通过首先 SSH 到主节点，然后再 SSH 到所需节点的方式来 SSH 到亚马逊云科技的群集节点。"}
{"origin_question": "\n是否可以 SSH 到我的群集节点？\n", "origin_answer": "能。您可以 SSH 到自己的群集节点，并从该位置直接执行 Hadoop 命令。如果您需要 SSH 到特定节点，则必须首先 SSH 到主节点，然后再 SSH 到所需节点。\n", "generate_question": "是否可以直接在群集节点上执行 Hadoop 命令？", "generate_answer": "是的，您可以通过 SSH 到自己的群集节点，并从该位置直接执行 Hadoop 命令。"}
{"origin_question": "\n什么是 Amazon EMR 引导操作？\n", "origin_answer": "引导操作是 Amazon EMR 中的一项功能，为用户提供一种在执行群集前运行自定义设置的方式。运行群集前，可使用引导操作来安装软件或配置实例。有关引导操作的更多信息，请阅读 EMR 的开发人员指南。\n", "generate_question": "什么是 Amazon EMR 引导操作？", "generate_answer": "引导操作是 Amazon EMR 中的一项功能，为用户提供一种在执行群集前运行自定义设置的方式。"}
{"origin_question": "\n什么是 Amazon EMR 引导操作？\n", "origin_answer": "引导操作是 Amazon EMR 中的一项功能，为用户提供一种在执行群集前运行自定义设置的方式。运行群集前，可使用引导操作来安装软件或配置实例。有关引导操作的更多信息，请阅读 EMR 的开发人员指南。\n", "generate_question": "引导操作可以用来做什么？", "generate_answer": "引导操作可以用来安装软件或配置实例，以满足用户在运行群集前的自定义需求。"}
{"origin_question": "\n什么是 Amazon EMR 引导操作？\n", "origin_answer": "引导操作是 Amazon EMR 中的一项功能，为用户提供一种在执行群集前运行自定义设置的方式。运行群集前，可使用引导操作来安装软件或配置实例。有关引导操作的更多信息，请阅读 EMR 的开发人员指南。\n", "generate_question": "在哪里可以找到关于引导操作的更多信息？", "generate_answer": "关于引导操作的更多信息可以在 EMR 的开发人员指南中找到。"}
{"origin_question": "\n如何使用引导操作？\n", "origin_answer": "您可以群集实例中已安装的任何语言编写 Bootstrap Action 脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。可使用一些预定义的引导操作。完成编写脚本后，您需要将其上传到 Amazon S3 并在启动集群时引用其位置。请参阅开发人员指南，了解有关如何使用引导操作的详细信息。\n", "generate_question": "引导操作可以使用哪些编程语言编写脚本？", "generate_answer": "引导操作可以使用任何已安装在群集实例中的编程语言编写脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。"}
{"origin_question": "\n如何使用引导操作？\n", "origin_answer": "您可以群集实例中已安装的任何语言编写 Bootstrap Action 脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。可使用一些预定义的引导操作。完成编写脚本后，您需要将其上传到 Amazon S3 并在启动集群时引用其位置。请参阅开发人员指南，了解有关如何使用引导操作的详细信息。\n", "generate_question": "如何上传引导操作脚本到 Amazon S3？", "generate_answer": "您需要将编写好的引导操作脚本上传到 Amazon S3，并在启动集群时引用脚本的位置。"}
{"origin_question": "\n如何使用引导操作？\n", "origin_answer": "您可以群集实例中已安装的任何语言编写 Bootstrap Action 脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。可使用一些预定义的引导操作。完成编写脚本后，您需要将其上传到 Amazon S3 并在启动集群时引用其位置。请参阅开发人员指南，了解有关如何使用引导操作的详细信息。\n", "generate_question": "引导操作脚本可以在启动集群时使用吗？", "generate_answer": "是的，您可以在启动集群时使用引导操作脚本。"}
{"origin_question": "\n如何使用引导操作？\n", "origin_answer": "您可以群集实例中已安装的任何语言编写 Bootstrap Action 脚本，包括 Bash、Perl、Python、Ruby、C++ 或 Java。可使用一些预定义的引导操作。完成编写脚本后，您需要将其上传到 Amazon S3 并在启动集群时引用其位置。请参阅开发人员指南，了解有关如何使用引导操作的详细信息。\n", "generate_question": "如何了解更多关于如何使用引导操作的详细信息？", "generate_answer": "您可以参阅开发人员指南，了解有关如何使用引导操作的详细信息。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "亚马逊云科技的 EMR 默认的 Hadoop 配置适合哪种工作负载？", "generate_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "如何对 EMR 集群的 Hadoop 设置进行调优？", "generate_answer": "根据群集的特定内存和处理要求，可以对 EMR 集群的 Hadoop 设置进行调优。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "如果群集任务需要使用大量内存，应该如何配置 Hadoop 设置？", "generate_answer": "如果群集任务需要使用大量内存，可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小来配置 Hadoop 设置。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "如何在启动时配置 EMR 集群的 Hadoop 设置？", "generate_answer": "在启动时，可以使用预定义的引导操作来配置 EMR 集群的 Hadoop 设置。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "如何配置内存密集型引导操作来调整群集的 Hadoop 设置？", "generate_answer": "可以使用预定义的内存密集型引导操作来调整群集的 Hadoop 设置。具体的配置详细信息和使用说明可以参考开发人员指南中的相关内容。"}
{"origin_question": "\n如何为集群配置 Hadoop 设置？\n", "origin_answer": "EMR 默认的 Hadoop 配置适合大多数工作负载。不过，根据群集的特定内存和处理要求，最好对这些设置进行调优。例如，如果您的群集任务需要使用大量内存，则可以选择每个核心使用较少的任务并降低任务跟踪程序堆阵大小。对于此情况，在启动时可以使用预定义的引导操作来配置群集。请参阅开发人员指南中的配置内存密集型引导操作，了解配置详细信息和使用说明。此外，还可以使用允许您根据所选的任何价值自定义群集设置的其他预定义引导操作。请参阅开发人员指南中的配置 Hadoop 引导操作，了解相关使用说明。\n", "generate_question": "是否可以根据需要自定义群集设置？", "generate_answer": "是的，可以使用允许根据所选的任何价值自定义群集设置的其他预定义引导操作来自定义群集设置。具体的使用说明可以参考开发人员指南中的配置 Hadoop 引导操作部分。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "亚马逊云科技的集群中有哪两种类型的节点？", "generate_answer": "核心节点和任务节点。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "核心节点和任务节点的功能有什么区别？", "generate_answer": "核心节点既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；而任务节点仅用来运行 Hadoop 任务。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "在运行中的集群中，可以修改节点数吗？", "generate_answer": "可以。可以增加核心节点的数量，也可以增加或减少任务节点的数量。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "如何修改正在运行的集群中的节点数？", "generate_answer": "可以通过 API、Java 软件开发工具包或命令行客户端执行该操作。具体的操作方法可以参阅开发人员指南中的调整运行的集群部分。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "是否可以使用 EMR 托管扩展来修改集群的大小？", "generate_answer": "是的，可以使用 EMR 托管扩展来修改集群的大小。"}
{"origin_question": "\n是否可以修改正在运行的集群中的节点数？\n", "origin_answer": "能。节点有两种类型：(1) 核心节点，既可使用 Hadoop 分布式文件系统 (HDFS) 托管持续性数据，又能运行 Hadoop 任务；以及 (2) 任务节点，仅用来运行 Hadoop 任务。当群集运行时，您可以增加核心节点的数量，也可以增加或减少任务节点的数量。通过 API、Java 软件开发工具包或命令行客户端可以执行该操作。请参阅开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。您还可以使用 EMR 托管扩展。\n", "generate_question": "在修改运行的集群大小时，还有其他需要注意的事项吗？", "generate_answer": "可以参考开发人员指南中的调整运行的集群部分，了解如何修改运行的集群大小的详细信息。"}
{"origin_question": "\n我何时会希望使用核心节点与任务节点？\n", "origin_answer": "由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。由于任务节点可以添加或删除且不含 HDFS，所以它们非常适合仅临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。\n", "generate_question": "为什么在使用亚马逊云科技时，我会希望使用核心节点与任务节点？", "generate_answer": "在使用亚马逊云科技时，您可能会希望使用核心节点与任务节点。核心节点在 HDFS 中托管持续性数据，无法删除，因此应为核心节点预留所需的容量，直到群集完成。而任务节点可以根据需要添加或删除，并且不含 HDFS，因此非常适合临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。"}
{"origin_question": "\n我何时会希望使用核心节点与任务节点？\n", "origin_answer": "由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。由于任务节点可以添加或删除且不含 HDFS，所以它们非常适合仅临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。\n", "generate_question": "什么是核心节点和任务节点？", "generate_answer": "核心节点和任务节点是亚马逊云科技中的两种不同类型的节点。核心节点在 HDFS 中托管持续性数据，无法删除，因此应为核心节点预留所需的容量，直到群集完成。任务节点可以根据需要添加或删除，并且不含 HDFS，适合临时需要容量的情况。"}
{"origin_question": "\n我何时会希望使用核心节点与任务节点？\n", "origin_answer": "由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。由于任务节点可以添加或删除且不含 HDFS，所以它们非常适合仅临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。\n", "generate_question": "如何使用核心节点和任务节点来增加容量？", "generate_answer": "您可以使用核心节点和任务节点来增加容量。由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。任务节点可以根据需要添加或删除，并且不含 HDFS，因此非常适合临时需要容量的情况。您还可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。"}
{"origin_question": "\n我何时会希望使用核心节点与任务节点？\n", "origin_answer": "由于核心节点在 HDFS 中托管持续性数据而无法删除，所以应为核心节点预留所需的容量，直到群集完成。由于任务节点可以添加或删除且不含 HDFS，所以它们非常适合仅临时需要容量的情况。您可以在 Spot 实例上启动任务实例队列，以增加容量，同时最大限度地减少成本。\n", "generate_question": "如何最大限度地减少成本使用核心节点和任务节点？", "generate_answer": "为了最大限度地减少成本使用核心节点和任务节点，您可以在 Spot 实例上启动任务实例队列，以增加容量。任务节点可以根据需要添加或删除，并且不含 HDFS，适合临时需要容量的情况。核心节点在 HDFS 中托管持续性数据而无法删除，因此应为核心节点预留所需的容量，直到群集完成。这样可以在满足需求的同时，最大限度地减少成本。"}
{"origin_question": "\n为什么我会希望修改正在运行的集群中的节点数？\n", "origin_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。\n", "generate_question": "为什么我会希望修改正在运行的集群中的节点数？", "generate_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。"}
{"origin_question": "\n为什么我会希望修改正在运行的集群中的节点数？\n", "origin_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。\n", "generate_question": "如何提高集群性能？", "generate_answer": "您可以增加核心节点数来提高集群性能。通过增加核心节点数，可以提高集群的计算能力和处理速度，从而加快任务的执行。"}
{"origin_question": "\n为什么我会希望修改正在运行的集群中的节点数？\n", "origin_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。\n", "generate_question": "如何满足集群不断变化的容量要求？", "generate_answer": "如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。"}
{"origin_question": "\n为什么我会希望修改正在运行的集群中的节点数？\n", "origin_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。\n", "generate_question": "什么是 EMR 托管扩展？", "generate_answer": "EMR 托管扩展是一种功能，可以帮助您管理和扩展集群。通过使用 EMR 托管扩展，您可以轻松地增加或减少集群中的节点数量，以满足不同阶段的容量需求。"}
{"origin_question": "\n为什么我会希望修改正在运行的集群中的节点数？\n", "origin_answer": "在某些情况下，您可能会希望修改正在运行的集群中的节点数。如果您的群集运行速度低于预期或时间要求发生变化，您可以增加核心节点数来提高群集性能。如果集群的不同阶段有不同的容量需求，您可以开始使用少量核心节点，并随时增加或减少任务节点的数量来满足集群不断变化的容量要求。 您还可以使用 EMR 托管扩展。\n", "generate_question": "如何使用 EMR 托管扩展？", "generate_answer": "您可以使用 EMR 托管扩展来增加或减少集群中的节点数量。通过调整节点数量，您可以根据集群的容量需求来管理集群的规模。"}
{"origin_question": "\n是否可以自动修改集群步骤之间的节点数？\n", "origin_answer": "能。您可以在工作流中包含预定义的步骤，以自动在已知具有不同容量需求的步骤之间调整群集大小。由于所有步骤都保证按顺序运行，这让您能够设置执行给定集群步骤的节点数。\n", "generate_question": "在亚马逊云科技中，是否可以在工作流中自动调整集群大小？", "generate_answer": "是的，您可以在工作流中包含预定义的步骤，以自动在已知具有不同容量需求的步骤之间调整群集大小。"}
{"origin_question": "\n是否可以自动修改集群步骤之间的节点数？\n", "origin_answer": "能。您可以在工作流中包含预定义的步骤，以自动在已知具有不同容量需求的步骤之间调整群集大小。由于所有步骤都保证按顺序运行，这让您能够设置执行给定集群步骤的节点数。\n", "generate_question": "亚马逊云科技中的工作流是否能够保证步骤按顺序运行？", "generate_answer": "是的，亚马逊云科技的工作流保证所有步骤按顺序运行。"}
{"origin_question": "\n是否可以自动修改集群步骤之间的节点数？\n", "origin_answer": "能。您可以在工作流中包含预定义的步骤，以自动在已知具有不同容量需求的步骤之间调整群集大小。由于所有步骤都保证按顺序运行，这让您能够设置执行给定集群步骤的节点数。\n", "generate_question": "在亚马逊云科技中，是否可以设置执行给定集群步骤的节点数？", "generate_answer": "是的，您可以设置执行给定集群步骤的节点数，以自动修改集群步骤之间的节点数。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "如何创建一个对所有 IAM 用户可见的新群集？", "generate_answer": "在创建群集时，可以添加 --visible-to-all-users 标志来创建一个对 EMR CLI 中的所有 IAM 用户可见的新群集。例如：elastic-mapreduce --create --visible-to-all-users。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "如何使现有群集对所有 IAM 用户可见？", "generate_answer": "要使现有群集对所有 IAM 用户可见，您需要使用 EMR CLI，并使用 --set-visible-to-all-users 标志来指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此操作只能由群集的创建者执行。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "在管理控制台内如何设置群集对所有 IAM 用户可见？", "generate_answer": "在管理控制台内，您可以在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”来创建一个对所有 IAM 用户可见的群集。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "如何配置用户权限以允许其他 IAM 用户访问我的群集？", "generate_answer": "有关配置用户权限的详细信息，请参阅 EMR 开发人员指南中的配置用户权限部分。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "是否可以使用 EMR CLI 来创建对所有 IAM 用户可见的群集？", "generate_answer": "是的，可以使用 EMR CLI 来创建对所有 IAM 用户可见的群集。只需在创建群集时添加 --visible-to-all-users 标志即可。"}
{"origin_question": "\n如何允许其他 IAM 用户访问我的群集？\n", "origin_answer": "要创建对 EMR CLI 中的所有 IAM 用户可见的新群集，请在创建群集时添加 --visible-to-all-users 标志。例如：elastic-mapreduce --create --visible-to-all-users。在管理控制台内，只需在 Create cluster Wizard 的 Advanced Options 面板上选择“Visible to all IAM Users”即可。\n\n要使现有群集对所有 IAM 用户可见，您必须使用 EMR CLI。使用 --set-visible-to-all-users，并指定群集标识符。例如：elastic-mapreduce --set-visible-to-all-users true --jobflow j-xxxxxxx。此步骤只能由群集的创建者执行。\n\n有关更多信息，请参阅 EMR 开发人员指南中的配置用户权限部分。\n\n标记集群", "generate_question": "谁可以执行使现有群集对所有 IAM 用户可见的操作？", "generate_answer": "只有群集的创建者可以执行使现有群集对所有 IAM 用户可见的操作。"}
{"origin_question": "\n可以标记哪些 Amazon EMR 资源？\n", "origin_answer": "可以将标记添加到活跃的 Amazon EMR 群集。Amazon EMR 群集由 Amazon EC2 实例组成，添加到 Amazon EMR 群集的标记将传播到该群集的每个活跃 Amazon EC2 实例中。无法在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中添加、编辑或删除标记。\n", "generate_question": "Amazon EMR 资源可以添加标记吗？", "generate_answer": "是的，可以将标记添加到活跃的 Amazon EMR 群集。"}
{"origin_question": "\n可以标记哪些 Amazon EMR 资源？\n", "origin_answer": "可以将标记添加到活跃的 Amazon EMR 群集。Amazon EMR 群集由 Amazon EC2 实例组成，添加到 Amazon EMR 群集的标记将传播到该群集的每个活跃 Amazon EC2 实例中。无法在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中添加、编辑或删除标记。\n", "generate_question": "标记会传播到 Amazon EMR 群集的哪些资源上？", "generate_answer": "标记会传播到 Amazon EMR 群集的每个活跃 Amazon EC2 实例上。"}
{"origin_question": "\n可以标记哪些 Amazon EMR 资源？\n", "origin_answer": "可以将标记添加到活跃的 Amazon EMR 群集。Amazon EMR 群集由 Amazon EC2 实例组成，添加到 Amazon EMR 群集的标记将传播到该群集的每个活跃 Amazon EC2 实例中。无法在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中添加、编辑或删除标记。\n", "generate_question": "可以在已终止的群集上添加、编辑或删除标记吗？", "generate_answer": "不可以，在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中无法添加、编辑或删除标记。"}
{"origin_question": "\n可以标记哪些 Amazon EMR 资源？\n", "origin_answer": "可以将标记添加到活跃的 Amazon EMR 群集。Amazon EMR 群集由 Amazon EC2 实例组成，添加到 Amazon EMR 群集的标记将传播到该群集的每个活跃 Amazon EC2 实例中。无法在已终止的群集或者属于活跃群集一部分的已终止 Amazon EC2 实例中添加、编辑或删除标记。\n", "generate_question": "Amazon EMR 群集由哪些资源组成？", "generate_answer": "Amazon EMR 群集由 Amazon EC2 实例组成。"}
{"origin_question": "\nAmazon EMR 标记是否支持 IAM 用户的资源权限？\n", "origin_answer": "不支持，Amazon EMR 不支持按标记确定基于资源的许可。但需要注意的是，传播到 EC2 实例的标记与正常的 Amazon EC2 标记的行为方式相同，这一点非常重要。因此，从 Amazon EMR 传播的标记如果与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。\n", "generate_question": "Amazon EMR 是否支持按标记确定基于资源的许可？", "generate_answer": "不支持，Amazon EMR 不支持按标记确定基于资源的许可。"}
{"origin_question": "\nAmazon EMR 标记是否支持 IAM 用户的资源权限？\n", "origin_answer": "不支持，Amazon EMR 不支持按标记确定基于资源的许可。但需要注意的是，传播到 EC2 实例的标记与正常的 Amazon EC2 标记的行为方式相同，这一点非常重要。因此，从 Amazon EMR 传播的标记如果与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。\n", "generate_question": "Amazon EMR 传播的标记与哪个服务的标记行为方式相同？", "generate_answer": "Amazon EMR 传播的标记与 Amazon EC2 的标记行为方式相同。"}
{"origin_question": "\nAmazon EMR 标记是否支持 IAM 用户的资源权限？\n", "origin_answer": "不支持，Amazon EMR 不支持按标记确定基于资源的许可。但需要注意的是，传播到 EC2 实例的标记与正常的 Amazon EC2 标记的行为方式相同，这一点非常重要。因此，从 Amazon EMR 传播的标记如果与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。\n", "generate_question": "Amazon EMR 是否支持 IAM 用户的资源权限？", "generate_answer": "Amazon EMR 不支持 IAM 用户的资源权限。"}
{"origin_question": "\nAmazon EMR 标记是否支持 IAM 用户的资源权限？\n", "origin_answer": "不支持，Amazon EMR 不支持按标记确定基于资源的许可。但需要注意的是，传播到 EC2 实例的标记与正常的 Amazon EC2 标记的行为方式相同，这一点非常重要。因此，从 Amazon EMR 传播的标记如果与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。\n", "generate_question": "如果 Amazon EMR 传播的标记与 Amazon EC2 的 IAM 策略中的条件匹配，会对这些标记生效吗？", "generate_answer": "是的，如果 Amazon EMR 传播的标记与 Amazon EC2 的 IAM 策略中的条件匹配，此策略将对这些标记生效。"}
{"origin_question": "\n可以向资源添加多少个标记？\n", "origin_answer": "在 Amazon EMR 群集上最多可以添加十个标记。\n", "generate_question": "亚马逊云科技的云计算服务中，有哪些主要产品？", "generate_answer": "亚马逊云科技的云计算服务主要包括 Amazon EC2、Amazon S3、Amazon RDS、Amazon EMR 等。"}
{"origin_question": "\n可以向资源添加多少个标记？\n", "origin_answer": "在 Amazon EMR 群集上最多可以添加十个标记。\n", "generate_question": "亚马逊云科技的 Amazon EMR 群集可以添加哪些标记？", "generate_answer": "在 Amazon EMR 群集上可以添加最多十个标记。"}
{"origin_question": "\n可以向资源添加多少个标记？\n", "origin_answer": "在 Amazon EMR 群集上最多可以添加十个标记。\n", "generate_question": "亚马逊云科技的 Amazon EMR 是什么？", "generate_answer": "Amazon EMR 是亚马逊云科技提供的一种云计算服务，用于在云中处理和分析大规模数据集。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "Amazon EMR 标记会自动传播到群集中的每个 Amazon EC2 实例吗？", "generate_answer": "是的，如果将标记添加到 Amazon EMR 群集，该标记会自动传播到组成该群集的每个 Amazon EC2 实例。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "如果我从 Amazon EMR 群集中删除一个标记，会自动从相关的 Amazon EC2 实例中删除吗？", "generate_answer": "是的，如果从 Amazon EMR 群集中删除一个标记，该标记也会自动从相关的 Amazon EC2 实例中删除。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "如果我使用 Amazon EC2 的 IAM 策略并计划使用 Amazon EMR 的标记功能，我需要授予哪些权限？", "generate_answer": "如果使用 Amazon EC2 的 IAM 策略并计划使用 Amazon EMR 的标记功能，需要确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "Amazon EMR 标记功能适用于哪些组件？", "generate_answer": "Amazon EMR 标记功能适用于组成群集的每个 Amazon EC2 实例。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "如果我在 Amazon EMR 群集上添加一个标记，该标记会显示在哪里？", "generate_answer": "如果在 Amazon EMR 群集上添加一个标记，该标记会显示在相关的 Amazon EC2 实例上。"}
{"origin_question": "\n我在群集上的 Amazon EMR 标记是否会显示在此群集的每个 Amazon EC2 实例上？ 如果删除我的 Amazon EMR \n", "origin_answer": "群集上的某个标记，是否会从每个相关的 EC2 实例中自动删除该标记？是，Amazon EMR 会将添加到群集的标记传播到组成该群集的 EC2 实例。如果将某个标记添加到 Amazon EMR 群集，则此标记也会显示在相关的 Amazon EC2 实例上。同样，如果从 Amazon EMR 群集中删除某个标记，也会从其相关的 Amazon EC2 实例中删除该标记。但是，如果使用 Amazon EC2 的 IAM 策略，并计划使用 Amazon EMR 的标记功能，应确保授予使用 Amazon EC2 标记 API CreateTags 和 DeleteTags 的权限。\n", "generate_question": "如果我在 Amazon EMR 群集上删除一个标记，该标记会从哪里删除？", "generate_answer": "如果在 Amazon EMR 群集上删除一个标记，该标记会从相关的 Amazon EC2 实例中删除。"}
{"origin_question": "\n如何在我的账单明细中显示我的标记来划分成本？\n", "origin_answer": "在此处选择要在 AWS 账单报告中使用的标记。然后，为了查看您组合资源的成本，您可以根据拥有相同标记键值的资源组织账单信息。\n", "generate_question": "如何在 AWS 账单报告中使用标记来划分成本？", "generate_answer": "在此处选择要在 AWS 账单报告中使用的标记。然后，为了查看您组合资源的成本，您可以根据拥有相同标记键值的资源组织账单信息。"}
{"origin_question": "\n如何在我的账单明细中显示我的标记来划分成本？\n", "origin_answer": "在此处选择要在 AWS 账单报告中使用的标记。然后，为了查看您组合资源的成本，您可以根据拥有相同标记键值的资源组织账单信息。\n", "generate_question": "为什么要在 AWS 账单报告中使用标记来划分成本？", "generate_answer": "使用标记可以帮助您更好地了解和管理您的成本。通过将相同标记键值的资源组织在一起，您可以更清楚地查看特定项目、团队或部门的成本情况。"}
{"origin_question": "\n如何在我的账单明细中显示我的标记来划分成本？\n", "origin_answer": "在此处选择要在 AWS 账单报告中使用的标记。然后，为了查看您组合资源的成本，您可以根据拥有相同标记键值的资源组织账单信息。\n", "generate_question": "如何查看组合资源的成本？", "generate_answer": "您可以根据拥有相同标记键值的资源来组织账单信息，从而查看组合资源的成本。这样可以帮助您更好地了解和分析资源的使用情况，并进行成本控制和优化。"}
{"origin_question": "\n如何分辨哪些 Amazon EC2 实例属于某个 Amazon EMR 群集？\n", "origin_answer": "与 Amazon EMR 群集关联的 Amazon EC2 实例将有两个系统标记：\n\naws:elasticmapreduce:instance-group-role=CORE\n键 = instance-group role；值 = [CORE or TASK]；\naws:elasticmapreduce:job-flow-id=j-12345678\n键 = job-flow-id；值 = [JobFlowID]", "generate_question": "Amazon EC2 实例如何与 Amazon EMR 群集关联？", "generate_answer": "Amazon EC2 实例与 Amazon EMR 群集关联的方式是通过两个系统标记：aws:elasticmapreduce:instance-group-role 和 aws:elasticmapreduce:job-flow-id。"}
{"origin_question": "\n如何分辨哪些 Amazon EC2 实例属于某个 Amazon EMR 群集？\n", "origin_answer": "与 Amazon EMR 群集关联的 Amazon EC2 实例将有两个系统标记：\n\naws:elasticmapreduce:instance-group-role=CORE\n键 = instance-group role；值 = [CORE or TASK]；\naws:elasticmapreduce:job-flow-id=j-12345678\n键 = job-flow-id；值 = [JobFlowID]", "generate_question": "如何判断一个 Amazon EC2 实例是否属于 Amazon EMR 群集的核心节点？", "generate_answer": "可以通过检查该 Amazon EC2 实例的系统标记 aws:elasticmapreduce:instance-group-role 的值是否为 CORE 来判断该实例是否属于 Amazon EMR 群集的核心节点。"}
{"origin_question": "\n如何分辨哪些 Amazon EC2 实例属于某个 Amazon EMR 群集？\n", "origin_answer": "与 Amazon EMR 群集关联的 Amazon EC2 实例将有两个系统标记：\n\naws:elasticmapreduce:instance-group-role=CORE\n键 = instance-group role；值 = [CORE or TASK]；\naws:elasticmapreduce:job-flow-id=j-12345678\n键 = job-flow-id；值 = [JobFlowID]", "generate_question": "如何找到与某个 Amazon EMR 群集关联的 Amazon EC2 实例的 JobFlowID？", "generate_answer": "可以通过检查该 Amazon EC2 实例的系统标记 aws:elasticmapreduce:job-flow-id 的值来找到与某个 Amazon EMR 群集关联的 Amazon EC2 实例的 JobFlowID。"}
{"origin_question": "\n可以直接在 Amazon EC2 实例上编辑标记吗？\n", "origin_answer": "可以，您可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接添加或删除标记。但是，我们不建议这样做，因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。\n", "generate_question": "在哪里可以直接编辑 Amazon EC2 实例的标记？", "generate_answer": "可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接编辑标记。"}
{"origin_question": "\n可以直接在 Amazon EC2 实例上编辑标记吗？\n", "origin_answer": "可以，您可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接添加或删除标记。但是，我们不建议这样做，因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。\n", "generate_question": "为什么不建议直接在 Amazon EC2 实例上编辑标记？", "generate_answer": "因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。"}
{"origin_question": "\n可以直接在 Amazon EC2 实例上编辑标记吗？\n", "origin_answer": "可以，您可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接添加或删除标记。但是，我们不建议这样做，因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。\n", "generate_question": "如何确保 Amazon EMR 集群及其关联的 Amazon EC2 实例具有正确的标记？", "generate_answer": "我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。"}
{"origin_question": "\n可以直接在 Amazon EC2 实例上编辑标记吗？\n", "origin_answer": "可以，您可以在属于 Amazon EMR 群集的 Amazon EC2 实例上直接添加或删除标记。但是，我们不建议这样做，因为 Amazon EMR 的标记系统不会同步对关联的 Amazon EC2 实例所做的直接更改。我们推荐从 Amazon EMR 控制台、CLI 或 API 添加和删除 Amazon EMR 集群的标记，以确保集群及其关联的 Amazon EC2 实例具有正确的标记。\n", "generate_question": "可以在 Amazon EMR 控制台之外的其他方式添加和删除 Amazon EMR 集群的标记吗？", "generate_answer": "是的，可以使用 CLI 或 API 来添加和删除 Amazon EMR 集群的标记。"}
{"origin_question": "\n什么是 Amazon EMR Serverless？\n", "origin_answer": "Amazon EMR Serverless 是 Amazon EMR 中的一个新部署选项，它让您可以运行 Apache Spark 和 Apache Hive 之类的大数据框架，而无需配置、管理和扩展集群。\n", "generate_question": "Amazon EMR Serverless 是什么？", "generate_answer": "Amazon EMR Serverless 是 Amazon EMR 中的一个新部署选项，它允许用户在不配置、管理和扩展集群的情况下运行大数据框架，如 Apache Spark 和 Apache Hive。"}
{"origin_question": "\n什么是 Amazon EMR Serverless？\n", "origin_answer": "Amazon EMR Serverless 是 Amazon EMR 中的一个新部署选项，它让您可以运行 Apache Spark 和 Apache Hive 之类的大数据框架，而无需配置、管理和扩展集群。\n", "generate_question": "Amazon EMR Serverless 可以运行哪些大数据框架？", "generate_answer": "Amazon EMR Serverless 可以运行 Apache Spark 和 Apache Hive 等大数据框架，用户无需进行集群的配置、管理和扩展即可使用这些框架。"}
{"origin_question": "\n谁可以使用 EMR Serverless？\n", "origin_answer": "数据工程师、分析师和科学家可以使用 EMR Serverless，以利用 Apache Spark 和 Apache Hive 之类的开源框架构建应用程序。他们可以使用这些框架来转换数据、运行交互式 SQL 查询和机器学习工作负载。", "generate_question": "什么是 EMR Serverless？", "generate_answer": "EMR Serverless 是一种亚马逊云科技提供的服务，可以让数据工程师、分析师和科学家利用 Apache Spark 和 Apache Hive 构建应用程序。"}
{"origin_question": "\n谁可以使用 EMR Serverless？\n", "origin_answer": "数据工程师、分析师和科学家可以使用 EMR Serverless，以利用 Apache Spark 和 Apache Hive 之类的开源框架构建应用程序。他们可以使用这些框架来转换数据、运行交互式 SQL 查询和机器学习工作负载。", "generate_question": "EMR Serverless 可以用来做什么？", "generate_answer": "EMR Serverless 可以用来转换数据、运行交互式 SQL 查询和机器学习工作负载。"}
{"origin_question": "\n谁可以使用 EMR Serverless？\n", "origin_answer": "数据工程师、分析师和科学家可以使用 EMR Serverless，以利用 Apache Spark 和 Apache Hive 之类的开源框架构建应用程序。他们可以使用这些框架来转换数据、运行交互式 SQL 查询和机器学习工作负载。", "generate_question": "哪些人可以使用 EMR Serverless？", "generate_answer": "数据工程师、分析师和科学家可以使用 EMR Serverless，以利用 Apache Spark 和 Apache Hive 之类的开源框架构建应用程序。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "如何使用EMR Studio开始使用EMR Serverless？", "generate_answer": "您可以登录AWS管理控制台，导航到Analytics类别下的Amazon EMR，然后选择Amazon EMR Serverless。按照AWS管理控制台中的说明，创建您的EMR Serverless应用程序并提交作业。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "除了EMR Studio，还有哪些方式可以使用EMR Serverless？", "generate_answer": "您可以使用AWS CLI或API提交作业、跟踪作业状态并构建要在EMR Serverless上运行的数据管道。您可以参考AWS CLI页面上的与您的应用程序交互，以启动您的应用程序并使用CLI提交作业。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "如何在AWS管理控制台中导航到Amazon EMR Serverless？", "generate_answer": "您可以登录AWS管理控制台，导航到Analytics类别下的Amazon EMR，然后选择Amazon EMR Serverless。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "在EMR Serverless中如何创建应用程序并提交作业？", "generate_answer": "您可以按照入门指南中的说明创建您的EMR Serverless应用程序并提交作业。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "在哪里可以找到EMR Serverless的示例和示例代码？", "generate_answer": "您可以在亚马逊云科技的GitHub存储库中找到EMR Serverless的示例和示例代码。"}
{"origin_question": "\n如何开始使用 EMR Serverless？\n", "origin_answer": "您可以使用 EMR Studio、AWS CLI 或 API 提交作业、跟踪作业状态并构建要在 EMR Serverless 上运行的数据管道。要开始使用 EMR Studio，请登录 AWS 管理控制台，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。按照 AWS 管理控制台中的说明，导航到 Analytics 类别下的 Amazon EMR，然后选择 Amazon EMR Serverless。 按照入门指南中的说明创建您的 EMR Serverless 应用程序并提交作业。您可以参考 AWS CLI 页面上的与您的应用程序交互，以启动您的应用程序并使用 CLI 提交作业。您还可以在我们的 GitHub 存储库中找到 EMR Serverless 示例和示例代码。\n", "generate_question": "EMR Serverless支持哪些类型的作业？", "generate_answer": "EMR Serverless支持各种类型的作业，您可以使用EMR Studio、AWS CLI或API提交这些作业，并在EMR Serverless上运行数据管道。"}
{"origin_question": "\nEMR Serverless 支持哪些开源框架？\n", "origin_answer": "EMR Serverless 当前支持 Apache Spark 和 Apache Hive 引擎。如果您希望支持其他框架，例如 Apache Presto 或 Apache Flink，请发送请求至 emr-feedback@amazon.com。\n", "generate_question": "EMR Serverless 支持哪些开源框架？", "generate_answer": "EMR Serverless 当前支持 Apache Spark 和 Apache Hive 引擎。"}
{"origin_question": "\nEMR Serverless 支持哪些开源框架？\n", "origin_answer": "EMR Serverless 当前支持 Apache Spark 和 Apache Hive 引擎。如果您希望支持其他框架，例如 Apache Presto 或 Apache Flink，请发送请求至 emr-feedback@amazon.com。\n", "generate_question": "如果我希望在 EMR Serverless 中使用其他框架，例如 Apache Presto 或 Apache Flink，应该如何操作？", "generate_answer": "如果您希望在 EMR Serverless 中使用其他框架，例如 Apache Presto 或 Apache Flink，请发送请求至 emr-feedback@amazon.com。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "EMR Serverless 在哪些 AWS 区域中可用？", "generate_answer": "EMR Serverless 现已在亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）这些 AWS 区域中可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "亚马逊云科技的 EMR Serverless 在哪些亚太地区可用？", "generate_answer": "亚马逊云科技的 EMR Serverless 在亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）和亚太地区（东京）可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "亚马逊云科技的 EMR Serverless 在哪些欧洲地区可用？", "generate_answer": "亚马逊云科技的 EMR Serverless 在欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）和欧洲地区（斯德哥尔摩）可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "亚马逊云科技的 EMR Serverless 在哪些美国地区可用？", "generate_answer": "亚马逊云科技的 EMR Serverless 在美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "EMR Serverless 在哪些加拿大地区可用？", "generate_answer": "EMR Serverless 在加拿大（中部）可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "EMR Serverless 在哪个南美洲地区可用？", "generate_answer": "EMR Serverless 在南美洲（圣保罗）可用。"}
{"origin_question": "\nEMR Serverless 在哪些区域中可用？\n", "origin_answer": "EMR Serverless 现已在下列 AWS 区域开放：亚太地区（孟买）、亚太地区（首尔）、亚太地区（新加坡）、亚太地区（悉尼）、亚太地区（东京）、加拿大（中部）、欧洲地区（法兰克福）、欧洲地区（爱尔兰）、欧洲地区（伦敦）、欧洲地区（巴黎）、欧洲地区（斯德哥尔摩）、南美洲（圣保罗）、美国东部（弗吉尼亚州北部）、美国东部（俄亥俄州）、美国西部（北加利福尼亚）和美国西部（俄勒冈州）。", "generate_question": "EMR Serverless 在哪些亚太地区城市可用？", "generate_answer": "EMR Serverless 在孟买、首尔、新加坡、悉尼和东京这些亚太地区城市可用。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "Amazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 分别适用于哪些客户？", "generate_answer": "Amazon EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。EC2 上的 Amazon EMR 适用于在运行应用程序时需要最大控制能力和灵活性的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "在 EC2 集群上的 Amazon EMR 中，客户可以进行哪些自定义操作？", "generate_answer": "在 EC2 集群上的 Amazon EMR 中，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "在 EKS 上的 Amazon EMR 中，客户可以实现哪些功能？", "generate_answer": "在 EKS 上的 Amazon EMR 中，客户可以实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "在 AWS Outposts 上的 Amazon EMR 中，客户可以实现什么样的部署？", "generate_answer": "在 AWS Outposts 上的 Amazon EMR 中，客户可以在 Outpost 内更靠近其数据中心运行 EMR。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "Amazon EMR Serverless 适用于哪些客户？", "generate_answer": "Amazon EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "Amazon EMR 提供了哪些选项来运行应用程序？", "generate_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "为什么客户选择在 EC2 集群上使用 Amazon EMR？", "generate_answer": "客户选择在 EC2 集群上使用 Amazon EMR 是因为他们需要在运行应用程序时具有最大的控制能力和灵活性。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "为什么客户选择在 EKS 上使用 Amazon EMR？", "generate_answer": "客户选择在 EKS 上使用 Amazon EMR 是因为他们希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架。"}
{"origin_question": "\nAmazon EMR Serverless、EC2 上的 Amazon EMR、AWS Outposts 上的 Amazon EMR 和 EKS 上的 Amazon EMR 有什么区别？\n", "origin_answer": "Amazon EMR 提供了在基于 EC2 的集群、EKS 集群、Outposts 或 Serverless 上运行应用程序的选项。EC2 集群上的 EMR 适用于在运行其应用程序时需要最大控制能力和灵活性的客户。借助 EC2 集群上的 EMR，客户可以选择 EC2 实例类型以满足特定于应用程序的性能需求、自定义 Linux AMI、自定义 EC2 实例配置、自定义和扩展开源框架，以及在集群实例上安装其他自定义软件。EKS 上的 Amazon EMR 适用于希望在 EKS 上实现标准化以跨应用程序管理集群或在同一集群上使用不同版本开源框架的客户。AWS Outposts 上的 Amazon EMR 适用于希望在 Outpost 内更靠近其数据中心运行 EMR 的客户。EMR Serverless 适用于希望避免管理和操作集群而更喜欢使用开源框架运行应用程序的客户。\n", "generate_question": "为什么客户选择在 AWS Outposts 上使用 Amazon EMR？", "generate_answer": "客户选择在 AWS Outposts 上使用 Amazon EMR 是因为他们希望在 Outpost 内更靠近其数据中心运行 EMR。"}
{"origin_question": "\nEMR Serverless 支持哪些 EMR 版本？\n", "origin_answer": "EMR Serverless 支持 EMR 版本标签 6.6 及更高版本。借助 EMR Serverless，您可以获得与在其他 EMR 部署选项中相同的性能优化 EMR 运行时，它与标准开源框架 100% API 兼容。\n", "generate_question": "EMR Serverless 支持哪些 EMR 版本？", "generate_answer": "EMR Serverless 支持 EMR 版本标签 6.6 及更高版本。"}
{"origin_question": "\nEMR Serverless 支持哪些 EMR 版本？\n", "origin_answer": "EMR Serverless 支持 EMR 版本标签 6.6 及更高版本。借助 EMR Serverless，您可以获得与在其他 EMR 部署选项中相同的性能优化 EMR 运行时，它与标准开源框架 100% API 兼容。\n", "generate_question": "EMR Serverless 与其他 EMR 部署选项相比有什么优势？", "generate_answer": "EMR Serverless 可以获得与在其他 EMR 部署选项中相同的性能优化 EMR 运行时，并且与标准开源框架 100% API 兼容。"}
{"origin_question": "\nEMR Serverless 支持哪些 EMR 版本？\n", "origin_answer": "EMR Serverless 支持 EMR 版本标签 6.6 及更高版本。借助 EMR Serverless，您可以获得与在其他 EMR 部署选项中相同的性能优化 EMR 运行时，它与标准开源框架 100% API 兼容。\n", "generate_question": "EMR Serverless 是否支持自定义框架？", "generate_answer": "是的，EMR Serverless 支持自定义框架，并且与标准开源框架 100% API 兼容。"}
{"origin_question": "\nBilledResourceUtilization 中是否包含预初始化容量的费用？\n", "origin_answer": "BilledResourceUtilization 仅考虑将预初始化容量用于作业的持续时间，而不考虑此类容量的任何空闲时间。\n", "generate_question": "BilledResourceUtilization 中还考虑其他类型的容量费用吗？", "generate_answer": "BilledResourceUtilization 仅考虑将预初始化容量用于作业的持续时间，不考虑其他类型容量的费用。"}
{"origin_question": "\nBilledResourceUtilization 中是否包含预初始化容量的费用？\n", "origin_answer": "BilledResourceUtilization 仅考虑将预初始化容量用于作业的持续时间，而不考虑此类容量的任何空闲时间。\n", "generate_question": "BilledResourceUtilization 是否包含空闲时间的费用？", "generate_answer": "BilledResourceUtilization 仅考虑将预初始化容量用于作业的持续时间，不考虑此类容量的任何空闲时间的费用。"}
{"origin_question": "\nBilledResourceUtilization 和 TotalResourceUtilization 有什么区别？\n", "origin_answer": "如果工作线程的运行时系统持续时间少于 60 秒，BilledResourceUtilization 会将其计为 60 秒，而 TotalResourceUtilization 会将其四舍五入到最接近的秒数。此外，BilledResourceUtilization 会从计算中除去 20GB 的免费存储空间。\n", "generate_question": "BilledResourceUtilization 和 TotalResourceUtilization 有什么区别？", "generate_answer": "BilledResourceUtilization 和 TotalResourceUtilization 在计算工作线程的运行时系统持续时间时有所不同。如果运行时系统持续时间少于 60 秒，BilledResourceUtilization 会将其计为 60 秒，而 TotalResourceUtilization 会将其四舍五入到最接近的秒数。此外，BilledResourceUtilization 还会从计算中除去 20GB 的免费存储空间。"}
{"origin_question": "\nBilledResourceUtilization 和 TotalResourceUtilization 有什么区别？\n", "origin_answer": "如果工作线程的运行时系统持续时间少于 60 秒，BilledResourceUtilization 会将其计为 60 秒，而 TotalResourceUtilization 会将其四舍五入到最接近的秒数。此外，BilledResourceUtilization 会从计算中除去 20GB 的免费存储空间。\n", "generate_question": "BilledResourceUtilization 和 TotalResourceUtilization 分别如何计算工作线程的运行时系统持续时间？", "generate_answer": "BilledResourceUtilization 将工作线程的运行时系统持续时间计为 60 秒，而 TotalResourceUtilization 则将其四舍五入到最接近的秒数。"}
{"origin_question": "\nBilledResourceUtilization 和 TotalResourceUtilization 有什么区别？\n", "origin_answer": "如果工作线程的运行时系统持续时间少于 60 秒，BilledResourceUtilization 会将其计为 60 秒，而 TotalResourceUtilization 会将其四舍五入到最接近的秒数。此外，BilledResourceUtilization 会从计算中除去 20GB 的免费存储空间。\n", "generate_question": "BilledResourceUtilization 除去了哪些计算中的内容？", "generate_answer": "BilledResourceUtilization 除去了计算中的 20GB 免费存储空间。"}
{"origin_question": "\n什么是应用程序以及如何创建？\n", "origin_answer": "借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。\n", "generate_question": "如何借助 Amazon EMR Serverless 创建应用程序？", "generate_answer": "您可以借助 Amazon EMR Serverless 创建一个或多个使用开源分析框架的应用程序。要创建应用程序，您需要指定适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及您希望应用程序使用的特定分析引擎。"}
{"origin_question": "\n什么是应用程序以及如何创建？\n", "origin_answer": "借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。\n", "generate_question": "什么是 Amazon EMR Serverless？", "generate_answer": "Amazon EMR Serverless 是一种服务，可以让您创建和运行使用开源分析框架的应用程序，而无需管理任何服务器。它提供了弹性和灵活性，可以根据需求自动扩展和缩减资源。"}
{"origin_question": "\n什么是应用程序以及如何创建？\n", "origin_answer": "借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。\n", "generate_question": "可以使用哪些开源分析框架来创建应用程序？", "generate_answer": "您可以使用多种开源分析框架来创建应用程序，例如 Apache Spark 3.1 或 Apache Hive 3.0。您可以根据需求选择适合的分析引擎。"}
{"origin_question": "\n什么是应用程序以及如何创建？\n", "origin_answer": "借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。\n", "generate_question": "创建应用程序后可以进行哪些操作？", "generate_answer": "创建应用程序后，您可以开始运行数据处理作业或对应用程序进行交互式请求。您可以根据需要对应用程序进行调整和优化。"}
{"origin_question": "\n什么是应用程序以及如何创建？\n", "origin_answer": "借助 Amazon EMR Serverless，您可以创建一个或多个使用开源分析框架的 EMR Serverless 应用程序。要创建应用程序，您必须指定以下属性：1) 适用于您要使用的开源框架版本的 Amazon EMR 发布版本，以及 2) 您希望应用程序使用的特定分析引擎，例如 Apache Spark 3.1 或 Apache Hive 3.0。创建应用程序后，您可以开始运行数据处理作业或对应用程序的交互式请求。\n", "generate_question": "Amazon EMR Serverless 提供了哪些优势？", "generate_answer": "Amazon EMR Serverless 提供了弹性和灵活性，可以根据需求自动扩展和缩减资源。它还简化了应用程序的管理和部署过程，让您可以更专注于数据分析和处理任务。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "什么是EMR Serverless？", "generate_answer": "EMR Serverless 是亚马逊云科技提供的一种服务，它使用工作线程来执行工作负载，并根据作业的需求自动调整工作线程的数量。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "EMR Serverless 如何处理提交的作业？", "generate_answer": "EMR Serverless 在接收到提交的作业后，会计算该作业所需的资源，并安排工作线程来执行工作负载。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "EMR Serverless 如何将工作负载分解为任务？", "generate_answer": "EMR Serverless 将工作负载分解为任务，并使用预置和设置好的工作线程来执行这些任务。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "EMR Serverless 是否会根据作业的需求自动调整工作线程的数量？", "generate_answer": "是的，EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程的数量。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "工作线程的大小是如何确定的？", "generate_answer": "工作线程的默认大小取决于应用程序类型和 Amazon EMR 发布版本，但您可以在安排作业运行时覆盖这些大小。"}
{"origin_question": "\n什么是工作线程？\n", "origin_answer": "EMR Serverless 应用程序在内部使用工作线程来执行您的工作负载。提交作业后，EMR Serverless 会计算该作业所需的资源并安排工作线程。EMR Serverless 将您的工作负载分解为任务，使用开源框架预置和设置工作线程，并在工作完成时将其停用。EMR Serverless 会根据作业每个阶段所需的工作负载和并行度自动增加或缩减工作线程，因此您无需估计运行工作负载所需的工作线程数量。这些工作线程的默认大小取决于您的应用程序类型和 Amazon EMR 发布版本。您可以在安排作业运行时覆盖这些大小。\n", "generate_question": "使用 EMR Serverless，用户需要自己估计运行工作负载所需的工作线程数量吗？", "generate_answer": "不需要，因为 EMR Serverless 会根据作业的需求自动调整工作线程的数量，用户无需估计运行工作负载所需的工作线程数量。"}
{"origin_question": "\n我可以指定我的作业可使用的工作线程最小和最大数量吗？\n", "origin_answer": "使用 EMR Serverless，您可以指定并发工作线程的最小和最大数量以及工作线程的 vCPU 和内存配置。您还可以设置应用程序资源的最大容量限制以控制成本。\n", "generate_question": "在使用EMR Serverless时，我可以设置工作线程的最小和最大数量吗？", "generate_answer": "是的，您可以指定并发工作线程的最小和最大数量。"}
{"origin_question": "\n我可以指定我的作业可使用的工作线程最小和最大数量吗？\n", "origin_answer": "使用 EMR Serverless，您可以指定并发工作线程的最小和最大数量以及工作线程的 vCPU 和内存配置。您还可以设置应用程序资源的最大容量限制以控制成本。\n", "generate_question": "除了工作线程的数量，我还可以设置工作线程的其他配置吗？", "generate_answer": "是的，您可以设置工作线程的vCPU和内存配置。"}
{"origin_question": "\n我可以指定我的作业可使用的工作线程最小和最大数量吗？\n", "origin_answer": "使用 EMR Serverless，您可以指定并发工作线程的最小和最大数量以及工作线程的 vCPU 和内存配置。您还可以设置应用程序资源的最大容量限制以控制成本。\n", "generate_question": "是否有办法限制应用程序资源的最大容量以控制成本？", "generate_answer": "是的，您可以设置应用程序资源的最大容量限制以控制成本。"}
{"origin_question": "\n我应在何时创建多个应用程序？\n", "origin_answer": "在执行以下任一操作时考虑创建多个应用程序：\n\n使用不同的开源框架\n针对不同的用例使用不同版本的开源框架\n从一个版本升级到另一个版本时执行 A/B 测试\n为测试和生产场景维护单独的逻辑环境\n为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能\n隔离不同的业务线应用程序\n", "generate_question": "为什么要考虑创建多个应用程序？", "generate_answer": "考虑创建多个应用程序是为了满足不同的需求和场景，例如使用不同的开源框架、针对不同的用例使用不同版本的开源框架等。"}
{"origin_question": "\n我应在何时创建多个应用程序？\n", "origin_answer": "在执行以下任一操作时考虑创建多个应用程序：\n\n使用不同的开源框架\n针对不同的用例使用不同版本的开源框架\n从一个版本升级到另一个版本时执行 A/B 测试\n为测试和生产场景维护单独的逻辑环境\n为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能\n隔离不同的业务线应用程序\n", "generate_question": "在什么情况下应该创建多个应用程序？", "generate_answer": "应该在使用不同的开源框架、需要执行 A/B 测试、需要为测试和生产场景维护单独的逻辑环境、为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能、隔离不同的业务线应用程序时考虑创建多个应用程序。"}
{"origin_question": "\n我应在何时创建多个应用程序？\n", "origin_answer": "在执行以下任一操作时考虑创建多个应用程序：\n\n使用不同的开源框架\n针对不同的用例使用不同版本的开源框架\n从一个版本升级到另一个版本时执行 A/B 测试\n为测试和生产场景维护单独的逻辑环境\n为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能\n隔离不同的业务线应用程序\n", "generate_question": "为什么需要为测试和生产场景维护单独的逻辑环境？", "generate_answer": "维护单独的逻辑环境可以确保测试和生产场景的隔离，避免测试环境对生产环境造成影响，同时也方便进行测试和验证。"}
{"origin_question": "\n我应在何时创建多个应用程序？\n", "origin_answer": "在执行以下任一操作时考虑创建多个应用程序：\n\n使用不同的开源框架\n针对不同的用例使用不同版本的开源框架\n从一个版本升级到另一个版本时执行 A/B 测试\n为测试和生产场景维护单独的逻辑环境\n为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能\n隔离不同的业务线应用程序\n", "generate_question": "为什么需要为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能？", "generate_answer": "提供独立的成本控制和使用跟踪功能可以帮助不同团队对其使用的资源进行管理和控制，确保资源的有效利用和成本的控制。"}
{"origin_question": "\n我应在何时创建多个应用程序？\n", "origin_answer": "在执行以下任一操作时考虑创建多个应用程序：\n\n使用不同的开源框架\n针对不同的用例使用不同版本的开源框架\n从一个版本升级到另一个版本时执行 A/B 测试\n为测试和生产场景维护单独的逻辑环境\n为面向不同团队的独立逻辑环境提供独立的成本控制和使用跟踪功能\n隔离不同的业务线应用程序\n", "generate_question": "为什么需要隔离不同的业务线应用程序？", "generate_answer": "隔离不同的业务线应用程序可以确保各个业务线之间的独立性，避免一个业务线的问题对其他业务线造成影响，同时也方便对不同业务线的应用程序进行管理和维护。"}
{"origin_question": "\n在 EMR Serverless 应用程序创建后能否更改其默认属性？\n", "origin_answer": "是的，您可以使用 EMR Studio 或 update-application API/CLI 调用修改应用程序属性，例如初始容量、最大容量限制和网络配置。\n", "generate_question": "如何修改 EMR Serverless 应用程序的默认属性？", "generate_answer": "您可以使用 EMR Studio 或 update-application API/CLI 调用来修改应用程序的属性，例如初始容量、最大容量限制和网络配置。"}
{"origin_question": "\n在 EMR Serverless 应用程序创建后能否更改其默认属性？\n", "origin_answer": "是的，您可以使用 EMR Studio 或 update-application API/CLI 调用修改应用程序属性，例如初始容量、最大容量限制和网络配置。\n", "generate_question": "有哪些属性可以在 EMR Serverless 应用程序创建后进行更改？", "generate_answer": "在 EMR Serverless 应用程序创建后，您可以更改一些属性，例如初始容量、最大容量限制和网络配置，通过使用 EMR Studio 或 update-application API/CLI 调用来实现。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "什么是 EMR Serverless 应用程序？", "generate_answer": "EMR Serverless 是亚马逊云科技提供的一种服务，它允许用户在没有预初始化工作线程的情况下运行作业。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "EMR Serverless 应用程序需要多长时间来确定所需的资源并进行预置？", "generate_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "什么是预初始化容量？", "generate_answer": "预初始化容量是 EMR Serverless 提供的一项可选功能，它可以使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "如何为应用程序配置预初始化容量？", "generate_answer": "您可以通过设置应用程序的初始容量参数为每个应用程序配置预初始化容量。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "预初始化容量对于哪种类型的作业是理想选择？", "generate_answer": "预初始化容量对于实施时间敏感型作业是理想选择，因为它允许作业立即开始。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "在启动 EMR Serverless 应用程序时，可以指定要预初始化的工作线程数量吗？", "generate_answer": "是的，您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "当用户提交作业时，可以使用预初始化的工作线程立即启动作业吗？", "generate_answer": "是的，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "如果作业需要的工作线程多于预初始化数量，会发生什么？", "generate_answer": "如果作业需要的工作线程多于预初始化数量，EMR Serverless 会自动添加更多工作线程，但不会超过您指定的最大并发限制。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "作业完成后，EMR Serverless 会如何处理工作线程？", "generate_answer": "作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "如果工作线程空闲 15 分钟会发生什么？", "generate_answer": "如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。"}
{"origin_question": "\n如何在 EMR Serverless 上提交和管理作业？\n", "origin_answer": "您可以使用 EMR Studio、开发工具包/CLI 或我们的 Apache Airflow 连接器提交和管理 EMR Serverless 作业。\n", "generate_question": "有哪些方法可以在 EMR Serverless 上提交和管理作业？", "generate_answer": "可以使用 EMR Studio、开发工具包/CLI 或 Apache Airflow 连接器来提交和管理 EMR Serverless 作业。"}
{"origin_question": "\n如何在 EMR Serverless 上提交和管理作业？\n", "origin_answer": "您可以使用 EMR Studio、开发工具包/CLI 或我们的 Apache Airflow 连接器提交和管理 EMR Serverless 作业。\n", "generate_question": "什么是 EMR Serverless？", "generate_answer": "EMR Serverless 是亚马逊云科技提供的一种无服务器的大数据处理服务，可以在不需要预配置和管理集群的情况下运行作业。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "如何在 EMR Serverless 上运行的作业中包含依赖项？", "generate_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "除了 virtualenv，还有其他方法可以在 EMR Serverless 上运行的作业中包含依赖项吗？", "generate_answer": "是的，对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "如何在 EMR Serverless 上运行 PySpark 作业时使用依赖项？", "generate_answer": "您可以使用 virtualenv 打包 Python 依赖项，并使用 --archives 选项将存档文件传递给作业运行。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "如何在 EMR Serverless 上运行 Scala 或 Java 作业时使用依赖项？", "generate_answer": "您可以将依赖项打包为 jar 文件，并将其上传到 Amazon S3。然后，使用 --jars 或 --packages 选项将这些依赖项传递给您的 EMR Serverless 作业运行。"}
{"origin_question": "\nEMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？\n", "origin_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。\n", "generate_question": "EMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？", "generate_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。"}
{"origin_question": "\nEMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？\n", "origin_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。\n", "generate_question": "用户是否可以在 EMR Serverless 中使用其他编程语言来定义自己的函数？", "generate_answer": "根据提供的信息，EMR Serverless 仅支持基于 Java 的 UDF。其他编程语言可能不被支持。"}
{"origin_question": "\nEMR Serverless 支持哪些工作线程配置？\n", "origin_answer": "有关详细信息，请参阅支持的工作线程配置。\n", "generate_question": "EMR Serverless 支持哪些工作线程配置？", "generate_answer": "EMR Serverless支持多种工作线程配置，具体的配置信息可以参考相关文档。"}
{"origin_question": "\nEMR Serverless 支持哪些工作线程配置？\n", "origin_answer": "有关详细信息，请参阅支持的工作线程配置。\n", "generate_question": "在哪里可以找到有关EMR Serverless工作线程配置的详细信息？", "generate_answer": "有关EMR Serverless工作线程配置的详细信息可以在相关文档中找到。"}
{"origin_question": "\n如果 EMR Serverless 作业运行时间超过预期，我可以取消它吗？\n", "origin_answer": "是的，您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。\n", "generate_question": "我可以从哪些途径取消正在运行的 EMR Serverless 作业？", "generate_answer": "您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。"}
{"origin_question": "\n如果 EMR Serverless 作业运行时间超过预期，我可以取消它吗？\n", "origin_answer": "是的，您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。\n", "generate_question": "是否可以取消 EMR Serverless 作业的运行时间？", "generate_answer": "是的，您可以取消 EMR Serverless 作业的运行时间。"}
{"origin_question": "\n我可以为工作线程增加额外的存储空间吗？\n", "origin_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。\n", "generate_question": "EMR Serverless 为每个工作线程提供的临时存储空间是多少？", "generate_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "作业完成后，EMR Serverless 会如何处理工作线程？", "generate_answer": "作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "如果工作线程空闲 15 分钟会发生什么？", "generate_answer": "如果工作线程空闲 15 分钟，它们会自动关闭。"}
{"origin_question": "\n我应何时创建具有预初始化工作线程池的应用程序？\n", "origin_answer": "没有预初始化工作线程的 EMR Serverless 应用程序需要最多 120 秒来确定所需的资源并进行预置。EMR Serverless 提供了一项可选功能，可使工作线程保持初始化并能够随时在几秒钟内做出响应，从而有效地为应用程序创建一个待命工作线程池。此功能称为预初始化容量，可以通过设置应用程序的初始容量参数为每个应用程序配置。\n\n预初始化容量允许作业立即开始，使其成为实施时间敏感型作业的理想选择。您可以指定在启动 EMR Serverless 应用程序时要预初始化的工作线程数量。随后，当用户提交作业时，可以使用预初始化的工作线程立即启动作业。如果作业需要的工作线程多于您选择的预初始化数量，EMR Serverless 会自动添加更多工作线程（可达到您指定的最大并发限制）。作业完成后，EMR Serverless 会自动恢复为维护您指定的预初始化工作线程。如果工作线程空闲 15 分钟，它们会自动关闭。您可以使用 updateApplication API 或 EMR Studio 更改应用程序的默认空闲超时。\n", "generate_question": "如何更改应用程序的默认空闲超时？", "generate_answer": "您可以使用 updateApplication API 或 EMR Studio 来更改应用程序的默认空闲超时。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "如何在 EMR Serverless 上运行的作业中包含依赖项？", "generate_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "对于 Scala 或 Java，如何在 EMR Serverless 上运行的作业中包含依赖项？", "generate_answer": "对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "在 EMR Serverless 上运行作业时，如何传递依赖项？", "generate_answer": "您可以使用 --archives 选项传递存档文件来传递 Python 依赖项，对于 Scala 或 Java 依赖项，您可以使用 --jars 或 --packages 选项将它们传递给作业运行。"}
{"origin_question": "\n如何在我想在 EMR Serverless 上运行的作业中包含依赖项？\n", "origin_answer": "对于 PySpark，您可以使用 virtualenv 打包 Python 依赖项并使用 --archives 选项传递存档文件，这样使您的工作线程能够在作业运行期间使用这些依赖项。对于 Scala 或 Java，您可以将依赖项打包为 jar，将它们上传到 Amazon S3，然后使用 --jars 或 --packages 选项将它们传递给您的 EMR Serverless 作业运行。\n", "generate_question": "什么是 EMR Serverless？", "generate_answer": "EMR Serverless 是亚马逊云科技提供的一种无服务器的大数据处理服务，它可以让您在不管理基础架构的情况下运行 Apache Spark 作业。您可以在 EMR Serverless 上运行 PySpark、Scala 或 Java 作业，并通过传递依赖项来扩展其功能。"}
{"origin_question": "\nEMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？\n", "origin_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。\n", "generate_question": "EMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）的打包方式是什么？", "generate_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。"}
{"origin_question": "\nEMR Serverless Spark 和 Hive 应用程序是否支持用户定义函数（UDF）？\n", "origin_answer": "EMR Serverless 支持基于 Java 的 UDF。您可以将它们打包为 jar，然后上传到 S3，并在 Spark 或 HiveQL 脚本中使用它们。\n", "generate_question": "除了 Java，EMR Serverless 还支持哪些语言的用户定义函数（UDF）？", "generate_answer": "根据提供的信息，EMR Serverless 只支持基于 Java 的 UDF，其他语言的支持情况未提及。"}
{"origin_question": "\nEMR Serverless 支持哪些工作线程配置？\n", "origin_answer": "有关详细信息，请参阅支持的工作线程配置。\n", "generate_question": "EMR Serverless 支持哪些工作线程配置？", "generate_answer": "EMR Serverless支持多种工作线程配置，具体的配置信息可以参考相关文档。"}
{"origin_question": "\nEMR Serverless 支持哪些工作线程配置？\n", "origin_answer": "有关详细信息，请参阅支持的工作线程配置。\n", "generate_question": "在哪里可以找到有关EMR Serverless支持的工作线程配置的详细信息？", "generate_answer": "有关EMR Serverless支持的工作线程配置的详细信息可以在相关文档中找到。"}
{"origin_question": "\n如果 EMR Serverless 作业运行时间超过预期，我可以取消它吗？\n", "origin_answer": "是的，您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。\n", "generate_question": "我可以从哪些途径取消正在运行的 EMR Serverless 作业？", "generate_answer": "您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。"}
{"origin_question": "\n如果 EMR Serverless 作业运行时间超过预期，我可以取消它吗？\n", "origin_answer": "是的，您可以从 EMR Studio 中或通过调用 cancelJobRun API/CLI 取消正在运行的 EMR Serverless 作业。\n", "generate_question": "是否可以取消运行时间超过预期的 EMR Serverless 作业？", "generate_answer": "是的，您可以取消运行时间超过预期的 EMR Serverless 作业。"}
{"origin_question": "\n我可以为工作线程增加额外的存储空间吗？\n", "origin_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。\n", "generate_question": "EMR Serverless 为每个工作线程提供了多少临时存储空间？", "generate_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。"}
{"origin_question": "\n我可以为工作线程增加额外的存储空间吗？\n", "origin_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。\n", "generate_question": "如果我需要更多存储空间，我可以如何自定义？", "generate_answer": "如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。"}
{"origin_question": "\n我可以为工作线程增加额外的存储空间吗？\n", "origin_answer": "EMR Serverless 为每个工作线程提供了 20 GB 的临时存储。如果需要更多存储空间，您可以在作业提交期间将其自定义为 20 GB 到 200 GB。\n", "generate_question": "临时存储空间的最大限制是多少？", "generate_answer": "临时存储空间的最大限制是 200 GB。"}
{"origin_question": "\n可以在哪里找到示例代码？\n", "origin_answer": "\n您可以在们的 GitHub 存储库中找到 EMR Serverless 代码示例。", "generate_question": "亚马逊云科技的 GitHub 存储库中有哪些代码示例？", "generate_answer": "在亚马逊云科技的 GitHub 存储库中，您可以找到 EMR Serverless 代码示例。"}
{"origin_question": "\n可以在哪里找到示例代码？\n", "origin_answer": "\n您可以在们的 GitHub 存储库中找到 EMR Serverless 代码示例。", "generate_question": "亚马逊云科技的 GitHub 存储库中提供了什么类型的代码示例？", "generate_answer": "亚马逊云科技的 GitHub 存储库中提供了 EMR Serverless 代码示例。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "EMR Serverless 提供哪两种工作线程选择？", "generate_answer": "EMR Serverless 提供按需工作线程和预初始化工作线程两种选择。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "按需工作线程的特点是什么？", "generate_answer": "按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "预初始化工作线程是什么功能？有什么优势？", "generate_answer": "预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "预初始化工作线程的优势是什么？", "generate_answer": "预初始化工作线程可以让工作线程在几秒钟内准备好响应，有效创建了一个工作线程热池，可以让作业立即启动。这对于迭代应用程序和时间敏感型作业非常有优势。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "按需工作线程的作用是什么？", "generate_answer": "按需工作线程根据工作负载的需要扩展或缩减应用程序的资源，让您不必担心资源配置过多或不足。它仅在工作需要时启动，并在工作完成后自动释放，可以帮助您节省成本。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "预初始化工作线程适用于哪些类型的应用程序？", "generate_answer": "预初始化工作线程适用于迭代应用程序和时间敏感型作业，因为它可以让作业立即启动，减少等待时间。"}
{"origin_question": "\nEMR Serverless 中有哪些可用的工作线程选项？\n", "origin_answer": "EMR Serverless 提供两种工作线程选择：按需工作线程和预初始化工作线程。\n\n按需工作线程仅在工作需要时启动，并在工作完成后自动释放。这可以帮助您节省成本，让您只需为使用的资源付费，并避免因闲置容量而产生任何额外成本。按需工作线程会根据您的工作负载扩展或缩减您的应用程序，让您不必担心资源配置过多或不足。\n\n预初始化工作线程是一项可选功能，可以让工作线程在几秒钟内准备好响应。这就为应用程序有效创建了一个工作线程热池，可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。\n", "generate_question": "EMR Serverless 的工作线程选项有哪些优势？", "generate_answer": "EMR Serverless 的工作线程选项可以根据工作负载的需要扩展或缩减资源，节省成本。同时，预初始化工作线程可以让作业立即启动，非常适合迭代应用程序和时间敏感型作业。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "EMR Serverless 应用程序可以配置在多少个可用区中？", "generate_answer": "EMR Serverless 应用程序可以配置在多个可用区中。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "EMR Serverless 如何选择要使用的可用区？", "generate_answer": "EMR Serverless 可以将子网与可用区关联起来，以选择要使用的可用区。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "EMR Serverless 是否支持将作业分发到多个可用区？", "generate_answer": "是的，EMR Serverless 默认会将作业分发到多个可用区。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "EMR Serverless 的作业是否只能在一个可用区中运行？", "generate_answer": "是的，每个作业在 EMR Serverless 中只能在一个可用区中运行。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "如果某个可用区出现故障，EMR Serverless 会如何处理？", "generate_answer": "如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "使用预初始化工作线程时，EMR Serverless 如何选择可用区？", "generate_answer": "使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。"}
{"origin_question": "\n能否在多个可用区 (AZ) 中配置 EMR Serverless 应用程序？\n", "origin_answer": "\n是的，可在多个可用区中配置 EMR Serverless 应用程序。设置多个可用区的流程取决于所使用的工作线程类型。\n仅使用按需工作线程时，EMR Serverless 默认会将作业分发到多个可用区，但每个作业仅在一个可用区中运行。您可以将子网与可用区关联起来，以选择要使用的可用区。如果某个可用区出现故障，EMR Serverless 会自动在另一个运行正常的可用区中运行您的任务。\n\n使用预初始化工作线程时，EMR Serverless 会从您指定的子网中选择运行状况良好的可用区。作业会在该可用区中提交，直到您停止该应用程序。如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。", "generate_question": "如果某个可用区受损，如何切换到另一个运行正常的可用区？", "generate_answer": "如果某个可用区受损，您可以重启应用程序以切换到另一个运行正常的可用区。"}
{"origin_question": "\n我能否连接到其他地区的数据存储？\n", "origin_answer": "在没有 VPC 连接的情况下配置时，EMR Serverless 只能访问同一区域中的某些 AWS 资源。请参阅注意事项。要访问其他区域中的 AWS 资源或非 AWS 资源，您需要设置 VPC 访问和 NAT 网关以路由到 AWS 资源的公共端点。\n监控和调试", "generate_question": "EMR Serverless可以访问哪些AWS资源？", "generate_answer": "EMR Serverless只能访问同一区域中的某些AWS资源，具体可参考注意事项。"}
{"origin_question": "\n我能否连接到其他地区的数据存储？\n", "origin_answer": "在没有 VPC 连接的情况下配置时，EMR Serverless 只能访问同一区域中的某些 AWS 资源。请参阅注意事项。要访问其他区域中的 AWS 资源或非 AWS 资源，您需要设置 VPC 访问和 NAT 网关以路由到 AWS 资源的公共端点。\n监控和调试", "generate_question": "如何访问其他区域中的AWS资源或非AWS资源？", "generate_answer": "要访问其他区域中的AWS资源或非AWS资源，需要设置VPC访问和NAT网关以路由到AWS资源的公共端点。"}
{"origin_question": "\n我能否连接到其他地区的数据存储？\n", "origin_answer": "在没有 VPC 连接的情况下配置时，EMR Serverless 只能访问同一区域中的某些 AWS 资源。请参阅注意事项。要访问其他区域中的 AWS 资源或非 AWS 资源，您需要设置 VPC 访问和 NAT 网关以路由到 AWS 资源的公共端点。\n监控和调试", "generate_question": "在没有VPC连接的情况下配置EMR Serverless时，可以访问哪些AWS资源？", "generate_answer": "在没有VPC连接的情况下配置EMR Serverless时，只能访问同一区域中的某些AWS资源。"}
{"origin_question": "\n我能否连接到其他地区的数据存储？\n", "origin_answer": "在没有 VPC 连接的情况下配置时，EMR Serverless 只能访问同一区域中的某些 AWS 资源。请参阅注意事项。要访问其他区域中的 AWS 资源或非 AWS 资源，您需要设置 VPC 访问和 NAT 网关以路由到 AWS 资源的公共端点。\n监控和调试", "generate_question": "为了访问其他区域中的AWS资源或非AWS资源，需要进行哪些设置？", "generate_answer": "为了访问其他区域中的AWS资源或非AWS资源，需要设置VPC访问和NAT网关以路由到AWS资源的公共端点。"}
{"origin_question": "\n如何监控 Amazon EMR Serverless 应用程序和作业运行？\n", "origin_answer": "Amazon EMR Serverless 应用程序级和作业级指标每 30 秒向 Amazon CloudWatch 发布一次。\n", "generate_question": "Amazon EMR Serverless 应用程序和作业运行如何发布指标？", "generate_answer": "Amazon EMR Serverless 应用程序和作业运行会每 30 秒向 Amazon CloudWatch 发布一次指标。"}
{"origin_question": "\n如何监控 Amazon EMR Serverless 应用程序和作业运行？\n", "origin_answer": "Amazon EMR Serverless 应用程序级和作业级指标每 30 秒向 Amazon CloudWatch 发布一次。\n", "generate_question": "亚马逊云科技的 Amazon EMR Serverless 应用程序和作业运行如何进行监控？", "generate_answer": "可以通过 Amazon CloudWatch 监控 Amazon EMR Serverless 应用程序和作业运行的应用程序级和作业级指标。"}
{"origin_question": "\n如何使用 EMR Serverless 启动 Spark UI 和 Tez UI？\n", "origin_answer": "在 EMR Studio 中，您可以选择正在运行或已完成的 EMR Serverless 作业，然后单击 Spark UI 或 Tez UI 按钮以启动它们。\n安全和数据控制", "generate_question": "在哪里可以启动 EMR Serverless 的 Spark UI 和 Tez UI？", "generate_answer": "在 EMR Studio 中，您可以选择正在运行或已完成的 EMR Serverless 作业，然后单击 Spark UI 或 Tez UI 按钮以启动它们。"}
{"origin_question": "\n如何使用 EMR Serverless 启动 Spark UI 和 Tez UI？\n", "origin_answer": "在 EMR Studio 中，您可以选择正在运行或已完成的 EMR Serverless 作业，然后单击 Spark UI 或 Tez UI 按钮以启动它们。\n安全和数据控制", "generate_question": "EMR Serverless 的 Spark UI 和 Tez UI 可以提供哪些功能？", "generate_answer": "Spark UI 和 Tez UI 可以提供对正在运行或已完成的 EMR Serverless 作业的监控和可视化功能。"}
{"origin_question": "\n我可以访问我的 Amazon Virtual Private Cloud（VPC）中的资源吗？\n", "origin_answer": "是的，您可以配置 Amazon EMR Serverless 应用程序以访问自己的 VPC 中的资源。请参阅文档中的配置 VPC 访问部分以了解更多信息。 \n", "generate_question": "如何配置 Amazon EMR Serverless 应用程序以访问 Amazon Virtual Private Cloud（VPC）中的资源？", "generate_answer": "您可以参考文档中的配置 VPC 访问部分，了解如何配置 Amazon EMR Serverless 应用程序以访问您的 VPC 中的资源。"}
{"origin_question": "\n我可以访问我的 Amazon Virtual Private Cloud（VPC）中的资源吗？\n", "origin_answer": "是的，您可以配置 Amazon EMR Serverless 应用程序以访问自己的 VPC 中的资源。请参阅文档中的配置 VPC 访问部分以了解更多信息。 \n", "generate_question": "Amazon EMR Serverless 应用程序可以访问其他云提供商的虚拟私有云（VPC）中的资源吗？", "generate_answer": "根据提供的信息，Amazon EMR Serverless 应用程序只能访问您自己的 Amazon Virtual Private Cloud（VPC）中的资源，无法访问其他云提供商的 VPC 中的资源。"}
{"origin_question": "\n使用 EMR Serverless 应用程序可以实现什么样的隔离？\n", "origin_answer": "每个 EMR Serverless 应用程序都与其他应用程序隔离，并在安全 Amazon VPC 上运行。\n账户级基于 vCPU 的限额", "generate_question": "EMR Serverless 应用程序如何实现隔离？", "generate_answer": "EMR Serverless 应用程序通过与其他应用程序隔离，并在安全 Amazon VPC 上运行来实现隔离。"}
{"origin_question": "\n使用 EMR Serverless 应用程序可以实现什么样的隔离？\n", "origin_answer": "每个 EMR Serverless 应用程序都与其他应用程序隔离，并在安全 Amazon VPC 上运行。\n账户级基于 vCPU 的限额", "generate_question": "EMR Serverless 应用程序的隔离是基于什么进行的？", "generate_answer": "EMR Serverless 应用程序的隔离是基于账户级基于 vCPU 的限额进行的。"}
{"origin_question": "\nAmazon EMR Serverless 服务限额有何变化？\n", "origin_answer": "\nAmazon MR Serverless 将推出一项新的服务限额，称为每账户的最大并发 vCPU 数量。借助这种基于 vCPU的限额，您可以设置应用程序在区域内最多能够扩展的最大汇总 vCPU 数量。现有的应用程序级别、基于工作线程的限额（最大活跃工作线程数）将于 2023 年 2 月 1 日结束支持。", "generate_question": "Amazon EMR Serverless 服务限额有何变化？", "generate_answer": "Amazon EMR Serverless 推出了一项新的服务限额，即每账户的最大并发 vCPU 数量。这个限额可以帮助用户设置应用程序在区域内最多能够扩展的最大汇总 vCPU 数量。现有的应用程序级别、基于工作线程的限额（最大活跃工作线程数）将于 2023 年 2 月 1 日结束支持。"}
{"origin_question": "\nAmazon EMR Serverless 服务限额有何变化？\n", "origin_answer": "\nAmazon MR Serverless 将推出一项新的服务限额，称为每账户的最大并发 vCPU 数量。借助这种基于 vCPU的限额，您可以设置应用程序在区域内最多能够扩展的最大汇总 vCPU 数量。现有的应用程序级别、基于工作线程的限额（最大活跃工作线程数）将于 2023 年 2 月 1 日结束支持。", "generate_question": "什么是 Amazon EMR Serverless？", "generate_answer": "Amazon EMR Serverless 是亚马逊云科技推出的一项服务，它是一种无服务器的大数据处理解决方案。用户可以使用 Amazon EMR Serverless 在亚马逊云上运行大规模的数据处理工作负载，而无需管理服务器集群。"}
{"origin_question": "\nAmazon EMR Serverless 服务限额有何变化？\n", "origin_answer": "\nAmazon MR Serverless 将推出一项新的服务限额，称为每账户的最大并发 vCPU 数量。借助这种基于 vCPU的限额，您可以设置应用程序在区域内最多能够扩展的最大汇总 vCPU 数量。现有的应用程序级别、基于工作线程的限额（最大活跃工作线程数）将于 2023 年 2 月 1 日结束支持。", "generate_question": "为什么要设置每账户的最大并发 vCPU 数量限额？", "generate_answer": "设置每账户的最大并发 vCPU 数量限额可以帮助用户控制应用程序在区域内的扩展规模。通过限制最大并发 vCPU 数量，用户可以避免资源过度使用，确保系统的稳定性和可靠性。"}
{"origin_question": "\nAmazon EMR Serverless 服务限额有何变化？\n", "origin_answer": "\nAmazon MR Serverless 将推出一项新的服务限额，称为每账户的最大并发 vCPU 数量。借助这种基于 vCPU的限额，您可以设置应用程序在区域内最多能够扩展的最大汇总 vCPU 数量。现有的应用程序级别、基于工作线程的限额（最大活跃工作线程数）将于 2023 年 2 月 1 日结束支持。", "generate_question": "什么是应用程序级别、基于工作线程的限额？", "generate_answer": "应用程序级别、基于工作线程的限额是一种旧的限额设置方式，用于控制应用程序的活跃工作线程数。然而，这种限额设置将于 2023 年 2 月 1 日结束支持，取而代之的是每账户的最大并发 vCPU 数量限额。"}
{"origin_question": "\n在哪里可以查看和管理我账户的 vCPU 限额？\n", "origin_answer": "\n您可以在AWS 服务限额管理控制台中查看、管理和请求增加限额。有关更多信息，请参阅服务限额用户指南中的请求增加限额。", "generate_question": "如何查看和管理亚马逊云科技账户的 vCPU 限额？", "generate_answer": "您可以在AWS 服务限额管理控制台中查看、管理和请求增加限额。有关更多信息，请参阅服务限额用户指南中的请求增加限额。"}
{"origin_question": "\n在哪里可以查看和管理我账户的 vCPU 限额？\n", "origin_answer": "\n您可以在AWS 服务限额管理控制台中查看、管理和请求增加限额。有关更多信息，请参阅服务限额用户指南中的请求增加限额。", "generate_question": "亚马逊云科技的服务限额管理控制台提供了哪些功能？", "generate_answer": "亚马逊云科技的服务限额管理控制台提供了查看、管理和请求增加限额的功能。您可以在该控制台中查看当前的 vCPU 限额，并通过请求增加限额来提高限额。有关更多信息，请参阅服务限额用户指南中的相关内容。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "什么是账户级 vCPU 限额？", "generate_answer": "账户级 vCPU 限额是指适用于亚马逊云科技账户中某个区域中所有 EMR Serverless 应用程序的最大并发 vCPU 数量限制。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "什么是应用程序级 maximumCapacity 属性？", "generate_answer": "应用程序级 maximumCapacity 属性是指用于限制特定 EMR Serverless 应用程序的 vCPU 资源的参数。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "如何使用基于 vCPU 的限额来控制最大并发 vCPU？", "generate_answer": "您可以将每个应用程序的 maximumCapacity 属性设置为特定的 vCPU 数量，并将基于账户级 vCPU 的限额配置为所有应用程序的 vCPU 数量之和，以控制最大并发 vCPU。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "如果有多个应用程序，每个应用程序最多可以扩展到多少个 vCPU？", "generate_answer": "如果有多个应用程序，并且每个应用程序最多可以扩展到1000个vCPU，那么每个应用程序的 maximumCapacity 属性应设置为1000个vCPU。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "如何计算基于账户级 vCPU 的限额？", "generate_answer": "基于账户级 vCPU 的限额应根据每个应用程序的 maximumCapacity 属性和应用程序的数量进行计算。例如，如果有5个应用程序，每个应用程序的 maximumCapacity 属性设置为1000个vCPU，那么基于账户级 vCPU 的限额应配置为5 * 1000 = 5000个vCPU。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "基于账户级 vCPU 的限额和应用程序级 maximumCapacity 属性有什么区别？", "generate_answer": "基于账户级 vCPU 的限额适用于账户中某个区域中的所有 EMR Serverless 应用程序，而应用程序级 maximumCapacity 属性仅限制特定应用程序使用的资源。"}
{"origin_question": "\n账户级 vCPU 限额和应用程序级 maximumCapacity 属性有什么区别？\n", "origin_answer": "\nEMR Sererless 提供两种成本控制 - 1/ 每个账户的最大并发 vCPU 限额适用于您账户中某个区域中的所有 EMR Serverless 应用程序。2/maximumCapacity 参数限制特定 EMR Serverless 应用程序的 vCPU。您应该使用基于 vCPU 的限额来限制一个区域中所有应用程序使用的最大并发 vCPU，并使用 maximumCapacity 属性来限制特定应用程序使用的资源。例如 如果您有 5 个应用程序并且每个应用程序最多可以扩展到 1000 个 vCPU，请将每个应用程序的 maximumCapacity 属性设置为 1000 个 vCPU，并将基于账户级 vCPU 的限额配置为 5 * 1000 = 5000 个 vCPU。\n", "generate_question": "EMR Serverless 提供了哪两种成本控制方式？", "generate_answer": "EMR Serverless 提供了两种成本控制方式 - 1/ 每个账户的最大并发 vCPU 限额，适用于账户中某个区域中的所有应用程序；2/ maximumCapacity 参数，用于限制特定应用程序的 vCPU 使用量。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "当我超过基于 vCPU 的账户限额时，EMR Serverless 会发生什么？", "generate_answer": "如果超过限额，EMR Serverless 将停止供应新容量，并且创建新应用程序或提交新作业将失败。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "如何查看和管理我的基于 vCPU 的账户限额？", "generate_answer": "您可以使用 AWS 服务限额控制台来查看和管理您的基于 vCPU 的账户限额。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "如果我超过基于 vCPU 的账户限额，创建新应用程序会显示什么错误消息？", "generate_answer": "如果超过限额后尝试创建新应用程序，将显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数”。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "如果我超过基于 vCPU 的账户限额，提交新作业会显示什么错误消息？", "generate_answer": "如果超过限额后提交新作业，将显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU”。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "超过基于 vCPU 的账户限额后，我还能使用其他 AWS 服务吗？", "generate_answer": "超过限额后，您仍然可以使用其他 AWS 服务，只是 EMR Serverless 的新容量供应将停止。"}
{"origin_question": "\n如何知道我是否达到了基于 vCPU 的账户限额？\n", "origin_answer": "\n如果您超账户级 vCPU 限额，EMR Serverless 将停止供应新容量。如果您在超过限额后尝试创建新应用程序，应用程序创建将失败并显示错误消息“用程序创建失败，因为您已超出每个账户服务限额的最大并发 vCPU 数。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 如果您在超过限额后提交新作业，该作业将失败并显示错误消息：“作业失败，因为您已超出每个账户服务限额的最大并发 vCPU。您可以使用 AWS 服务限额控制台查看和管理您的服务限额。” 有关更多详细信息，请参阅文档。\n\n定价", "generate_question": "除了使用 AWS 服务限额控制台，还有其他方式可以查看和管理基于 vCPU 的账户限额吗？", "generate_answer": "目前，使用 AWS 服务限额控制台是查看和管理基于 vCPU 的账户限额的主要方式。"}
{"origin_question": "\nEMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？\n", "origin_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。\n", "generate_question": "EMR Serverless 成本是否与 EC2 按需型实例上的 Amazon EMR 相当？", "generate_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。"}
{"origin_question": "\nEMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？\n", "origin_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。\n", "generate_question": "如果我使用 EC2 Savings Plans，EMR Serverless 的成本如何？", "generate_answer": "如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的总拥有成本（TCO）。"}
{"origin_question": "\nEMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？\n", "origin_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。\n", "generate_question": "如果我使用 EC2 竞价型实例，EMR Serverless 的成本如何？", "generate_answer": "如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。"}
{"origin_question": "\nEMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？\n", "origin_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。\n", "generate_question": "EMR Serverless 是否能够降低总拥有成本（TCO）？", "generate_answer": "是的，当您的集群利用率低于一定阈值时，EMR Serverless 可以实现更低的总拥有成本（TCO）。"}
{"origin_question": "\nEMR Serverless 成本是否与 EC2 竞价型实例上的 Amazon EMR 相当？\n", "origin_answer": "这取决于 EC2 上的当前 EMR 的集群利用率。如果您使用 EC2 按需型实例运行 EMR 集群，则在您当前的集群利用率低于 70% 时，EMR Serverless 将可实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则在您当前的集群利用率低于 50% 时，EMR Serverless 将实现更低的 TCO。如果您使用 EC2 竞价型实例，EC2 上的 Amazon EMR 和 EKS 上的 Amazon EMR 仍将保持更高成本效益。\n", "generate_question": "集群利用率低于多少时，EMR Serverless 可以实现更低的总拥有成本（TCO）？", "generate_answer": "当您使用 EC2 按需型实例运行 EMR 集群时，集群利用率低于 70% 时，EMR Serverless 可以实现更低的总拥有成本（TCO）。如果您使用 EC2 Savings Plans，则集群利用率低于 50% 时，EMR Serverless 可以实现更低的总拥有成本（TCO）。"}
{"origin_question": "\n即使在作业运行到完成之后，预初始化的工作线程仍需收费吗？\n", "origin_answer": "是的，如果您在作业完成后不停止工作线程，预初始化的工作线程将会产生费用。\n", "generate_question": "亚马逊云科技的工作线程是否会在作业完成后自动停止？", "generate_answer": "不会，如果您不手动停止工作线程，它将继续运行并产生费用。"}
{"origin_question": "\n即使在作业运行到完成之后，预初始化的工作线程仍需收费吗？\n", "origin_answer": "是的，如果您在作业完成后不停止工作线程，预初始化的工作线程将会产生费用。\n", "generate_question": "除了预初始化的工作线程，还有其他需要收费的服务吗？", "generate_answer": "是的，除了预初始化的工作线程，亚马逊云科技还提供其他收费的服务。"}
{"origin_question": "\n我应向谁发出疑问、评论和功能请求？\n", "origin_answer": "请发送电子邮件至 emr-feedback@amazon.com，以向我们提交您对 EMR Serverless 的疑问和宝贵反馈。\n\nAmazon EKS 上的 Amazon EMR", "generate_question": "如何向亚马逊云科技提交关于EMR Serverless的疑问和反馈？", "generate_answer": "请发送电子邮件至emr-feedback@amazon.com，以向亚马逊云科技提交您对EMR Serverless的疑问和反馈。"}
{"origin_question": "\n我应向谁发出疑问、评论和功能请求？\n", "origin_answer": "请发送电子邮件至 emr-feedback@amazon.com，以向我们提交您对 EMR Serverless 的疑问和宝贵反馈。\n\nAmazon EKS 上的 Amazon EMR", "generate_question": "在哪个平台上可以使用Amazon EMR？", "generate_answer": "Amazon EMR可以在Amazon EKS上使用。"}
{"origin_question": "\n什么是 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR 是 Amazon EMR 的一个部署模型，它使客户能够轻松、经济高效地处理海量数据。它利用在容器中灵活的 AmazonEKS 托管服务上运行的托管分析框架，以及 Amazon Elastic Compute Cloud (Amazon EC2)、AWS Fargate 和 Amazon Simple Storage Service (Amazon S3) 的 Web 级基础设施。", "generate_question": "Amazon EKS 上的 Amazon EMR 是什么？", "generate_answer": "Amazon EKS 上的 Amazon EMR 是 Amazon EMR 的一个部署模型，它利用在容器中灵活的 Amazon EKS 托管服务上运行的托管分析框架，以及 Amazon EC2、AWS Fargate 和 Amazon S3 的基础设施，使客户能够轻松、经济高效地处理海量数据。"}
{"origin_question": "\n什么是 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR 是 Amazon EMR 的一个部署模型，它使客户能够轻松、经济高效地处理海量数据。它利用在容器中灵活的 AmazonEKS 托管服务上运行的托管分析框架，以及 Amazon Elastic Compute Cloud (Amazon EC2)、AWS Fargate 和 Amazon Simple Storage Service (Amazon S3) 的 Web 级基础设施。", "generate_question": "Amazon EKS 上的 Amazon EMR 使用了哪些托管服务和基础设施？", "generate_answer": "Amazon EKS 上的 Amazon EMR 使用了在容器中灵活的 Amazon EKS 托管服务，以及 Amazon EC2、AWS Fargate 和 Amazon S3 的基础设施。"}
{"origin_question": "\n什么是 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR 是 Amazon EMR 的一个部署模型，它使客户能够轻松、经济高效地处理海量数据。它利用在容器中灵活的 AmazonEKS 托管服务上运行的托管分析框架，以及 Amazon Elastic Compute Cloud (Amazon EC2)、AWS Fargate 和 Amazon Simple Storage Service (Amazon S3) 的 Web 级基础设施。", "generate_question": "Amazon EKS 上的 Amazon EMR 的部署模型有什么特点？", "generate_answer": "Amazon EKS 上的 Amazon EMR 的部署模型使客户能够轻松、经济高效地处理海量数据，它利用在容器中灵活的 Amazon EKS 托管服务上运行的托管分析框架，以及 Amazon EC2、AWS Fargate 和 Amazon S3 的基础设施。"}
{"origin_question": "\n什么是 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR 是 Amazon EMR 的一个部署模型，它使客户能够轻松、经济高效地处理海量数据。它利用在容器中灵活的 AmazonEKS 托管服务上运行的托管分析框架，以及 Amazon Elastic Compute Cloud (Amazon EC2)、AWS Fargate 和 Amazon Simple Storage Service (Amazon S3) 的 Web 级基础设施。", "generate_question": "Amazon EKS 上的 Amazon EMR 如何帮助客户处理海量数据？", "generate_answer": "Amazon EKS 上的 Amazon EMR 利用在容器中灵活的 Amazon EKS 托管服务上运行的托管分析框架，以及 Amazon EC2、AWS Fargate 和 Amazon S3 的基础设施，使客户能够轻松、经济高效地处理海量数据。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "Amazon EKS 上的 Amazon EMR是如何将分析作业与服务和基础设施解耦的？", "generate_answer": "Amazon EKS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "在 Amazon EKS 上使用 Amazon EMR可以带来什么好处？", "generate_answer": "使用 Amazon EKS 上的 Amazon EMR可以让开发人员将精力放在开发应用程序上，而较少关注基础设施的运行。EMR会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "Amazon EKS 上的 EMR如何配置基础设施？", "generate_answer": "Amazon EKS 上的 EMR会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "使用 Amazon EKS 上的 EMR可以实现哪些管理方面的便利？", "generate_answer": "使用 Amazon EKS 上的 EMR可以实现基础设施团队集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "Amazon EKS 上的 EMR如何实现多个团队、组织或业务部门的隔离状态？", "generate_answer": "Amazon EKS 上的 EMR可以实现多个团队、组织或业务部门在共享基础设施上同时独立运行其分析流程，并维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "Amazon EKS 上的 EMR适用于哪些类型的应用程序？", "generate_answer": "Amazon EKS 上的 EMR适用于分析作业和基于容器的应用程序。"}
{"origin_question": "\n为什么要使用 Amazon EKS 上的 Amazon EMR？\n", "origin_answer": "\nAmazon KS 上的 Amazon EMR使用基于容器的方法将分析作业与正在处理该作业的服务和基础设施解耦。您可以将精力放在开发应用程序上，而较少关注基础设施的运行，因为 EKS 上的 EMR 会根据作业的计算、内存和应用程序依赖关系动态配置基础设施。基础设施团队可以集中管理一个通用计算平台，以将 EMR 工作负载与其他基于容器的应用程序进行整合。多个团队、组织或业务部门可以在共享基础设施上同时独立运行其分析流程，同时维持由 Amazon EKS 和 AWS Identity and Access Management (IAM) 实现的隔离状态。", "generate_question": "Amazon EKS 上的 EMR如何与其他基于容器的应用程序进行整合？", "generate_answer": "Amazon EKS 上的 EMR可以与其他基于容器的应用程序进行整合，通过集中管理一个通用计算平台来实现。"}
{"origin_question": "\n对于已经运行 Amazon EKS 上的 Apache Spark 的用户有什么优势？\n", "origin_answer": "\n如果您已运行 Amazon EKS 上的 Apache Spark，则可以获取 Amazon EMR的所有优势，例如自动预置和扩展，并能使用最新的完全托管版本的开源大数据分析框架。您可以获得适用于 Apache Spark 的经优化 EMR 运行时（性能比 EKS 上的开源 Apache Spark 快 3 倍），EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，精细的数据访问控制，以及对数据加密的支持。\n", "generate_question": "在 Amazon EKS 上运行 Apache Spark 的用户可以获得哪些优势？", "generate_answer": "在 Amazon EKS 上运行 Apache Spark 的用户可以获得以下优势：\n- 可以享受 Amazon EMR 的所有优势，包括自动预置和扩展能力。\n- 可以使用最新的完全托管版本的开源大数据分析框架。\n- 可以获得经过优化的 EMR 运行时，性能比在 EKS 上运行的开源 Apache Spark 快 3 倍。\n- 可以使用 EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验。\n- 可以享受精细的数据访问控制和对数据加密的支持。"}
{"origin_question": "\n对于已经运行 Amazon EKS 上的 Apache Spark 的用户有什么优势？\n", "origin_answer": "\n如果您已运行 Amazon EKS 上的 Apache Spark，则可以获取 Amazon EMR的所有优势，例如自动预置和扩展，并能使用最新的完全托管版本的开源大数据分析框架。您可以获得适用于 Apache Spark 的经优化 EMR 运行时（性能比 EKS 上的开源 Apache Spark 快 3 倍），EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，精细的数据访问控制，以及对数据加密的支持。\n", "generate_question": "Amazon EKS 上运行 Apache Spark 的用户可以获得哪些与数据相关的优势？", "generate_answer": "Amazon EKS 上运行 Apache Spark 的用户可以获得以下与数据相关的优势：\n- 可以使用 EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，方便进行数据分析和处理。\n- 可以享受精细的数据访问控制，确保数据的安全性和隐私性。\n- 可以利用对数据加密的支持，保护敏感数据的机密性。"}
{"origin_question": "\n对于已经运行 Amazon EKS 上的 Apache Spark 的用户有什么优势？\n", "origin_answer": "\n如果您已运行 Amazon EKS 上的 Apache Spark，则可以获取 Amazon EMR的所有优势，例如自动预置和扩展，并能使用最新的完全托管版本的开源大数据分析框架。您可以获得适用于 Apache Spark 的经优化 EMR 运行时（性能比 EKS 上的开源 Apache Spark 快 3 倍），EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，精细的数据访问控制，以及对数据加密的支持。\n", "generate_question": "Amazon EKS 上运行 Apache Spark 的用户可以获得哪些与性能相关的优势？", "generate_answer": "Amazon EKS 上运行 Apache Spark 的用户可以获得以下与性能相关的优势：\n- 可以使用经过优化的 EMR 运行时，性能比在 EKS 上运行的开源 Apache Spark 快 3 倍，提供更高效的数据处理能力。\n- 可以享受 Amazon EMR 的自动预置和扩展能力，确保系统的高可用性和可伸缩性。"}
{"origin_question": "\n对于已经运行 Amazon EKS 上的 Apache Spark 的用户有什么优势？\n", "origin_answer": "\n如果您已运行 Amazon EKS 上的 Apache Spark，则可以获取 Amazon EMR的所有优势，例如自动预置和扩展，并能使用最新的完全托管版本的开源大数据分析框架。您可以获得适用于 Apache Spark 的经优化 EMR 运行时（性能比 EKS 上的开源 Apache Spark 快 3 倍），EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，精细的数据访问控制，以及对数据加密的支持。\n", "generate_question": "Amazon EKS 上运行 Apache Spark 的用户可以获得哪些与扩展性相关的优势？", "generate_answer": "Amazon EKS 上运行 Apache Spark 的用户可以获得以下与扩展性相关的优势：\n- 可以享受 Amazon EMR 的自动预置和扩展能力，根据需求自动调整集群规模，提供更高的计算和存储资源。\n- 可以使用最新的完全托管版本的开源大数据分析框架，保持系统与最新技术的兼容性和扩展性。"}
{"origin_question": "\n对于已经运行 Amazon EKS 上的 Apache Spark 的用户有什么优势？\n", "origin_answer": "\n如果您已运行 Amazon EKS 上的 Apache Spark，则可以获取 Amazon EMR的所有优势，例如自动预置和扩展，并能使用最新的完全托管版本的开源大数据分析框架。您可以获得适用于 Apache Spark 的经优化 EMR 运行时（性能比 EKS 上的开源 Apache Spark 快 3 倍），EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，精细的数据访问控制，以及对数据加密的支持。\n", "generate_question": "Amazon EKS 上运行 Apache Spark 的用户可以获得哪些与管理相关的优势？", "generate_answer": "Amazon EKS 上运行 Apache Spark 的用户可以获得以下与管理相关的优势：\n- 可以享受 Amazon EMR 的自动预置和扩展能力，无需手动管理集群的配置和规模。\n- 可以使用 EMR Studio 和 Apache Spark UI 提供的无服务器数据科学体验，简化数据分析和处理的管理工作。\n- 可以利用精细的数据访问控制和对数据加密的支持，提高数据管理的安全性和合规性。"}
{"origin_question": "\n这项功能与其他 AWS 服务有什么关系？如何配合使用这些服务？\n", "origin_answer": "\nAmazon KS 为客户提供了在 AWS 上运行 Kubernetes 的托管体验，使您可以使用 EKS 托管节点组或 AWS Fargate 添加计算容量。在 EKS上运行 EMR 作业可以在 Amazon S3 上访问其数据，同时可以将监控和日志记录与 Amazon CloudWatch 集成。AWS Identity and Access Management (IAM) 支持对作业和相关 AWS 服务进行基于角色的访问控制。", "generate_question": "Amazon KS 与哪些 AWS 服务有关？", "generate_answer": "Amazon KS 与 EKS、AWS Fargate、EMR、Amazon S3、Amazon CloudWatch、AWS Identity and Access Management (IAM) 相关。"}
{"origin_question": "\n这项功能与其他 AWS 服务有什么关系？如何配合使用这些服务？\n", "origin_answer": "\nAmazon KS 为客户提供了在 AWS 上运行 Kubernetes 的托管体验，使您可以使用 EKS 托管节点组或 AWS Fargate 添加计算容量。在 EKS上运行 EMR 作业可以在 Amazon S3 上访问其数据，同时可以将监控和日志记录与 Amazon CloudWatch 集成。AWS Identity and Access Management (IAM) 支持对作业和相关 AWS 服务进行基于角色的访问控制。", "generate_question": "如何使用 Amazon KS 配合 EKS 运行 Kubernetes？", "generate_answer": "可以使用 Amazon KS 提供的托管体验，在 AWS 上运行 Kubernetes，并通过 EKS 托管节点组或 AWS Fargate 添加计算容量。"}
{"origin_question": "\n这项功能与其他 AWS 服务有什么关系？如何配合使用这些服务？\n", "origin_answer": "\nAmazon KS 为客户提供了在 AWS 上运行 Kubernetes 的托管体验，使您可以使用 EKS 托管节点组或 AWS Fargate 添加计算容量。在 EKS上运行 EMR 作业可以在 Amazon S3 上访问其数据，同时可以将监控和日志记录与 Amazon CloudWatch 集成。AWS Identity and Access Management (IAM) 支持对作业和相关 AWS 服务进行基于角色的访问控制。", "generate_question": "如何在 Amazon KS 上运行 EMR 作业？", "generate_answer": "在 Amazon KS 上运行 EMR 作业时，可以访问存储在 Amazon S3 上的数据，并可以将监控和日志记录与 Amazon CloudWatch 集成。"}
{"origin_question": "\n这项功能与其他 AWS 服务有什么关系？如何配合使用这些服务？\n", "origin_answer": "\nAmazon KS 为客户提供了在 AWS 上运行 Kubernetes 的托管体验，使您可以使用 EKS 托管节点组或 AWS Fargate 添加计算容量。在 EKS上运行 EMR 作业可以在 Amazon S3 上访问其数据，同时可以将监控和日志记录与 Amazon CloudWatch 集成。AWS Identity and Access Management (IAM) 支持对作业和相关 AWS 服务进行基于角色的访问控制。", "generate_question": "如何对 Amazon KS 的作业和相关 AWS 服务进行访问控制？", "generate_answer": "可以使用 AWS Identity and Access Management (IAM) 对 Amazon KS 的作业和相关 AWS 服务进行基于角色的访问控制。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "如何将 Spark 作业提交到 Amazon EMR 上的 Amazon EKS？", "generate_answer": "使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "Amazon EMR 如何与 EKS 上的 Kubernetes 计划程序进行通信？", "generate_answer": "EMR 请求 EKS 上的 Kubernetes 计划程序来安排 Pod。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "Amazon EMR 在 EKS 上创建的容器包含哪些内容？", "generate_answer": "容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "每个作业在 Amazon EMR 上的 EKS 中是如何运行的？", "generate_answer": "每个作业在 Pod 中运行。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "如果容器的映像已经部署到节点上，Amazon EMR 在 EKS 上会发生什么？", "generate_answer": "如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "可以在 Amazon EMR 的 EKS 上部署哪些类型的 Sidecar 容器？", "generate_answer": "可以部署日志或指标转发服务器等类型的 Sidecar 容器。"}
{"origin_question": "\nAmazon EKS 上的 Amazon EMR 的工作原理是什么？\n", "origin_answer": "\n向 Amazn EMR 注册 EKS 集群。然后，使用 CLI、SDK 或 EMR Studio 将您的 Spark 作业提交到 EMR。EMR 请求 EKS 上的 Kubernetes计划程序来安排 Pod。对于您运行的每个作业，EKS 上的 EMR 都会创建一个容器。该容器包含具有安全更新的 Amazon Linux 2 基本镜像、Apache Spark 和运行 Spark 的相关依赖项以及特定于应用程序的依赖项。每个作业均在 Pod 中运行。Pod 会下载该容器并开始执行它。如果容器的映像先前已部署到节点，则将使用缓存的映像，并绕过下载。可将 Sidecar 容器（例如日志或指标转发服务器）部署到 Pod。Pod 在作业终止后会终止。作业终止后，您仍然可以使用 Spark UI 对其进行调试。\n", "generate_question": "作业终止后，还可以对其进行调试吗？", "generate_answer": "是的，作业终止后，您仍然可以使用 Spark UI 对其进行调试。"}
{"origin_question": "\n我可以在 EKS 上的 Amazon EMR 中使用哪些 AWS 计算服务？\n", "origin_answer": "\n您可以将Amazon EMR for EKS 与两种 Amazon Elastic Compute Cloud (EC2) 实例一起使用以支持更广泛的自定义选项，也可以与无服务器的AWS Fargate 服务一起使用，以处理您的分析而无需预置或管理 EC2 实例。通过将您的分析工作分散在多个 AWS 可用区 (AZ, Availability Zone) 中，可以自动提高应用程序的可用性。\n", "generate_question": "在 Amazon EMR for EKS 中，我可以使用哪些 AWS 计算服务来支持我的分析工作？", "generate_answer": "您可以使用 Amazon Elastic Compute Cloud (EC2) 实例和 AWS Fargate 服务来支持您的分析工作。"}
{"origin_question": "\n我可以在 EKS 上的 Amazon EMR 中使用哪些 AWS 计算服务？\n", "origin_answer": "\n您可以将Amazon EMR for EKS 与两种 Amazon Elastic Compute Cloud (EC2) 实例一起使用以支持更广泛的自定义选项，也可以与无服务器的AWS Fargate 服务一起使用，以处理您的分析而无需预置或管理 EC2 实例。通过将您的分析工作分散在多个 AWS 可用区 (AZ, Availability Zone) 中，可以自动提高应用程序的可用性。\n", "generate_question": "Amazon EMR for EKS 可以与哪些 Amazon EC2 实例一起使用？", "generate_answer": "Amazon EMR for EKS 可以与两种 Amazon Elastic Compute Cloud (EC2) 实例一起使用。"}
{"origin_question": "\n我可以在 EKS 上的 Amazon EMR 中使用哪些 AWS 计算服务？\n", "origin_answer": "\n您可以将Amazon EMR for EKS 与两种 Amazon Elastic Compute Cloud (EC2) 实例一起使用以支持更广泛的自定义选项，也可以与无服务器的AWS Fargate 服务一起使用，以处理您的分析而无需预置或管理 EC2 实例。通过将您的分析工作分散在多个 AWS 可用区 (AZ, Availability Zone) 中，可以自动提高应用程序的可用性。\n", "generate_question": "如果我想要更多的自定义选项，我应该选择使用哪种计算服务？", "generate_answer": "如果您想要更多的自定义选项，您可以选择使用 Amazon Elastic Compute Cloud (EC2) 实例。"}
{"origin_question": "\n我可以在 EKS 上的 Amazon EMR 中使用哪些 AWS 计算服务？\n", "origin_answer": "\n您可以将Amazon EMR for EKS 与两种 Amazon Elastic Compute Cloud (EC2) 实例一起使用以支持更广泛的自定义选项，也可以与无服务器的AWS Fargate 服务一起使用，以处理您的分析而无需预置或管理 EC2 实例。通过将您的分析工作分散在多个 AWS 可用区 (AZ, Availability Zone) 中，可以自动提高应用程序的可用性。\n", "generate_question": "如果我不想预置或管理 EC2 实例，我可以使用哪种计算服务来处理我的分析工作？", "generate_answer": "如果您不想预置或管理 EC2 实例，您可以使用无服务器的 AWS Fargate 服务来处理您的分析工作。"}
{"origin_question": "\n我如何开始使用 EKS 上的 EMR？\n", "origin_answer": "\n首先，向Amazon EMR 注册 Amazon EKS 集群。 注册后，通过将工作负载提交给 EMR进行执行，从而在您的作业定义（包括应用程序依赖项和框架参数）中引用此注册。使用 EKS 上的 EMR，您可以为运行在同一 EKS 集群上的分析应用程序使用不同的开源大数据分析框架、版本和配置。 有关更多信息，请参阅我们的文档。\n", "generate_question": "如何在 Amazon EMR 上注册 Amazon EKS 集群？", "generate_answer": "您可以通过向 Amazon EMR 注册 Amazon EKS 集群来开始使用 EKS 上的 EMR。注册后，您可以将工作负载提交给 EMR 进行执行，并在作业定义中引用此注册。这样，您就可以为运行在同一 EKS 集群上的分析应用程序使用不同的开源大数据分析框架、版本和配置。"}
{"origin_question": "\n我如何开始使用 EKS 上的 EMR？\n", "origin_answer": "\n首先，向Amazon EMR 注册 Amazon EKS 集群。 注册后，通过将工作负载提交给 EMR进行执行，从而在您的作业定义（包括应用程序依赖项和框架参数）中引用此注册。使用 EKS 上的 EMR，您可以为运行在同一 EKS 集群上的分析应用程序使用不同的开源大数据分析框架、版本和配置。 有关更多信息，请参阅我们的文档。\n", "generate_question": "在 EKS 上的 EMR 中，如何为分析应用程序使用不同的开源大数据分析框架？", "generate_answer": "在 EKS 上的 EMR 中，您可以为分析应用程序使用不同的开源大数据分析框架，版本和配置。通过将工作负载提交给 EMR 进行执行，并在作业定义中引用注册的 Amazon EKS 集群，您可以为运行在同一 EKS 集群上的分析应用程序提供不同的框架选择。"}
{"origin_question": "\n我如何开始使用 EKS 上的 EMR？\n", "origin_answer": "\n首先，向Amazon EMR 注册 Amazon EKS 集群。 注册后，通过将工作负载提交给 EMR进行执行，从而在您的作业定义（包括应用程序依赖项和框架参数）中引用此注册。使用 EKS 上的 EMR，您可以为运行在同一 EKS 集群上的分析应用程序使用不同的开源大数据分析框架、版本和配置。 有关更多信息，请参阅我们的文档。\n", "generate_question": "Amazon EMR 上的 EKS 如何支持应用程序依赖项和框架参数？", "generate_answer": "在 Amazon EMR 上的 EKS 中，您可以在作业定义中包含应用程序依赖项和框架参数。通过将工作负载提交给 EMR 进行执行，并在作业定义中引用注册的 Amazon EKS 集群，您可以为运行在同一 EKS 集群上的分析应用程序提供所需的依赖项和参数配置。"}
{"origin_question": "\n我如何开始使用 EKS 上的 EMR？\n", "origin_answer": "\n首先，向Amazon EMR 注册 Amazon EKS 集群。 注册后，通过将工作负载提交给 EMR进行执行，从而在您的作业定义（包括应用程序依赖项和框架参数）中引用此注册。使用 EKS 上的 EMR，您可以为运行在同一 EKS 集群上的分析应用程序使用不同的开源大数据分析框架、版本和配置。 有关更多信息，请参阅我们的文档。\n", "generate_question": "如何获取更多关于 EKS 上的 EMR 的信息？", "generate_answer": "您可以参阅亚马逊云科技的文档以获取更多关于 EKS 上的 EMR 的信息。文档中包含了使用 EKS 上的 EMR 的详细指南和说明，可以帮助您更好地了解和使用该服务。"}
{"origin_question": "\n如何向 EKS 上的 EMR 提交分析应用程序？\n", "origin_answer": "\n您可以使 AWS SDK / CLI、Amazon EMR Studio 笔记本以及工作流编排服务（例如 Apache Airflow 和 Amazon Managed Workflows forApache Airflow）提交分析应用程序。 可以从 S3 下载 EKS 上的 AWS EMR 的 Airflow 插件。要为 Amazon Managed Workflows for Apache Airflow 安装 EMR 容器插件，请参阅我们的 文档。", "generate_question": "有哪些方式可以向 EKS 上的 EMR 提交分析应用程序？", "generate_answer": "您可以使用 AWS SDK / CLI、Amazon EMR Studio 笔记本以及工作流编排服务（例如 Apache Airflow 和 Amazon Managed Workflows for Apache Airflow）来提交分析应用程序。"}
{"origin_question": "\n如何向 EKS 上的 EMR 提交分析应用程序？\n", "origin_answer": "\n您可以使 AWS SDK / CLI、Amazon EMR Studio 笔记本以及工作流编排服务（例如 Apache Airflow 和 Amazon Managed Workflows forApache Airflow）提交分析应用程序。 可以从 S3 下载 EKS 上的 AWS EMR 的 Airflow 插件。要为 Amazon Managed Workflows for Apache Airflow 安装 EMR 容器插件，请参阅我们的 文档。", "generate_question": "可以从哪里下载 EKS 上的 AWS EMR 的 Airflow 插件？", "generate_answer": "您可以从 S3 下载 EKS 上的 AWS EMR 的 Airflow 插件。"}
{"origin_question": "\n如何向 EKS 上的 EMR 提交分析应用程序？\n", "origin_answer": "\n您可以使 AWS SDK / CLI、Amazon EMR Studio 笔记本以及工作流编排服务（例如 Apache Airflow 和 Amazon Managed Workflows forApache Airflow）提交分析应用程序。 可以从 S3 下载 EKS 上的 AWS EMR 的 Airflow 插件。要为 Amazon Managed Workflows for Apache Airflow 安装 EMR 容器插件，请参阅我们的 文档。", "generate_question": "如何为 Amazon Managed Workflows for Apache Airflow 安装 EMR 容器插件？", "generate_answer": "您可以参考亚马逊云科技的文档来安装 EMR 容器插件。"}
{"origin_question": "\n如何向 EKS 上的 EMR 提交分析应用程序？\n", "origin_answer": "\n您可以使 AWS SDK / CLI、Amazon EMR Studio 笔记本以及工作流编排服务（例如 Apache Airflow 和 Amazon Managed Workflows forApache Airflow）提交分析应用程序。 可以从 S3 下载 EKS 上的 AWS EMR 的 Airflow 插件。要为 Amazon Managed Workflows for Apache Airflow 安装 EMR 容器插件，请参阅我们的 文档。", "generate_question": "除了 AWS SDK / CLI、Amazon EMR Studio 笔记本和工作流编排服务，还有其他方式可以向 EKS 上的 EMR 提交分析应用程序吗？", "generate_answer": "根据提供的信息，除了上述方式外，没有提到其他方式可以向 EKS 上的 EMR 提交分析应用程序。"}
{"origin_question": "\n能否对在 EKS 上运行的 EMR 集群和应用程序使用相同的 EMR 发行版？\n", "origin_answer": "可以。您可以对在 EMR 集群上运行的应用程序和在 EKS 上运行的应用程序使用相同的 EMR 发行版。\n", "generate_question": "在亚马逊云科技的 EKS 上运行的 EMR 集群和应用程序可以使用不同的 EMR 发行版吗？", "generate_answer": "不可以。在 EKS 上运行的 EMR 集群和应用程序需要使用相同的 EMR 发行版。"}
{"origin_question": "\n能否对在 EKS 上运行的 EMR 集群和应用程序使用相同的 EMR 发行版？\n", "origin_answer": "可以。您可以对在 EMR 集群上运行的应用程序和在 EKS 上运行的应用程序使用相同的 EMR 发行版。\n", "generate_question": "在亚马逊云科技的 EKS 上运行的 EMR 集群和应用程序可以使用其他云提供商的发行版吗？", "generate_answer": "不可以。在 EKS 上运行的 EMR 集群和应用程序需要使用亚马逊云科技提供的 EMR 发行版。"}
{"origin_question": "\n如何排除分析应用程序的故障？\n", "origin_answer": "\n您可以使 Amazon EMR Spark UI 来诊断 Spark 应用程序并进行故障排除。对于所有分析应用程序，EMR 可以在完成后长达 30天的时间内提供对应用程序详细信息、关联日志和指标的访问。可以单独配置作业，以将日志发送到 Amazon S3 位置或 Amazon CloudWatch。\n", "generate_question": "如何使用 Amazon EMR Spark UI 进行故障排除？", "generate_answer": "您可以使用 Amazon EMR Spark UI 来诊断 Spark 应用程序并进行故障排除。"}
{"origin_question": "\n如何排除分析应用程序的故障？\n", "origin_answer": "\n您可以使 Amazon EMR Spark UI 来诊断 Spark 应用程序并进行故障排除。对于所有分析应用程序，EMR 可以在完成后长达 30天的时间内提供对应用程序详细信息、关联日志和指标的访问。可以单独配置作业，以将日志发送到 Amazon S3 位置或 Amazon CloudWatch。\n", "generate_question": "Amazon EMR 可以提供对分析应用程序的哪些信息？", "generate_answer": "Amazon EMR 可以在完成后长达 30天的时间内提供对应用程序详细信息、关联日志和指标的访问。"}
{"origin_question": "\n如何排除分析应用程序的故障？\n", "origin_answer": "\n您可以使 Amazon EMR Spark UI 来诊断 Spark 应用程序并进行故障排除。对于所有分析应用程序，EMR 可以在完成后长达 30天的时间内提供对应用程序详细信息、关联日志和指标的访问。可以单独配置作业，以将日志发送到 Amazon S3 位置或 Amazon CloudWatch。\n", "generate_question": "如何配置作业以将日志发送到 Amazon S3 位置？", "generate_answer": "可以单独配置作业，以将日志发送到 Amazon S3 位置。"}
{"origin_question": "\n如何排除分析应用程序的故障？\n", "origin_answer": "\n您可以使 Amazon EMR Spark UI 来诊断 Spark 应用程序并进行故障排除。对于所有分析应用程序，EMR 可以在完成后长达 30天的时间内提供对应用程序详细信息、关联日志和指标的访问。可以单独配置作业，以将日志发送到 Amazon S3 位置或 Amazon CloudWatch。\n", "generate_question": "如何配置作业以将日志发送到 Amazon CloudWatch？", "generate_answer": "可以单独配置作业，以将日志发送到 Amazon CloudWatch。"}
{"origin_question": "\n我可以在 EKS 中看到 EMR 应用程序吗？\n", "origin_answer": "\n可以。EM 应用程序会作为 Kubernetes 作业和部署显示在 EKS 控制台中。", "generate_question": "在亚马逊云科技的 EKS 控制台中，我可以看到哪些 EMR 应用程序？", "generate_answer": "在 EKS 控制台中，您可以看到 EMR 应用程序作为 Kubernetes 作业和部署的一部分。"}
{"origin_question": "\n我可以在 EKS 中看到 EMR 应用程序吗？\n", "origin_answer": "\n可以。EM 应用程序会作为 Kubernetes 作业和部署显示在 EKS 控制台中。", "generate_question": "亚马逊云科技的 EKS 控制台中是否显示了所有的 EMR 应用程序？", "generate_answer": "是的，EKS 控制台会显示所有的 EMR 应用程序作为 Kubernetes 作业和部署的一部分。"}
{"origin_question": "\n我可以在同一 EKS 集群上将多个作业或应用程序彼此隔离吗？\n", "origin_answer": "\n可以。Kuernetes 本机提供作业隔离。此外，可以将每个作业配置为使用其自己的执行角色运行，以限制作业可以访问哪些 AWS 资源。", "generate_question": "什么是 EKS 集群？", "generate_answer": "EKS 集群是亚马逊云科技提供的一种托管式 Kubernetes 服务，用于简化在 AWS 上运行 Kubernetes 的过程。"}
{"origin_question": "\n我可以在同一 EKS 集群上将多个作业或应用程序彼此隔离吗？\n", "origin_answer": "\n可以。Kuernetes 本机提供作业隔离。此外，可以将每个作业配置为使用其自己的执行角色运行，以限制作业可以访问哪些 AWS 资源。", "generate_question": "如何在 EKS 集群上实现作业隔离？", "generate_answer": "在 EKS 集群上可以使用 Kubernetes 的本机功能来实现作业隔离。此外，还可以为每个作业配置独立的执行角色，以限制作业对 AWS 资源的访问。"}
{"origin_question": "\n我可以在同一 EKS 集群上将多个作业或应用程序彼此隔离吗？\n", "origin_answer": "\n可以。Kuernetes 本机提供作业隔离。此外，可以将每个作业配置为使用其自己的执行角色运行，以限制作业可以访问哪些 AWS 资源。", "generate_question": "为什么需要将每个作业配置为使用自己的执行角色运行？", "generate_answer": "将每个作业配置为使用自己的执行角色运行可以限制作业对 AWS 资源的访问。这样可以增加安全性，确保作业只能访问其所需的资源，而不会对其他作业或应用程序造成干扰。"}
{"origin_question": "\nEKS 上的 EMR 如何有助于降低成本？\n", "origin_answer": "\nEKS 上的EMR 消除了运行专用集群的必要性，从而降低了成本。您可以使用公用的共享 EKS集群来运行需要不同版本的开源大数据分析框架的分析应用程序。您也可以使用相同的 EKS 集群来运行其他容器化的非 EMR 应用程序。\n", "generate_question": "什么是 EKS 上的 EMR？", "generate_answer": "EKS 上的 EMR 是指在亚马逊云科技的弹性容器服务（EKS）上运行的弹性 MapReduce（EMR）服务。"}
{"origin_question": "\nEKS 上的 EMR 如何有助于降低成本？\n", "origin_answer": "\nEKS 上的EMR 消除了运行专用集群的必要性，从而降低了成本。您可以使用公用的共享 EKS集群来运行需要不同版本的开源大数据分析框架的分析应用程序。您也可以使用相同的 EKS 集群来运行其他容器化的非 EMR 应用程序。\n", "generate_question": "EKS 上的 EMR 如何降低成本？", "generate_answer": "EKS 上的 EMR 通过消除运行专用集群的需要来降低成本。您可以使用公用的共享 EKS 集群来运行需要不同版本的开源大数据分析框架的分析应用程序，也可以在同一 EKS 集群上运行其他容器化的非 EMR 应用程序。"}
{"origin_question": "\nEKS 上的 EMR 如何有助于降低成本？\n", "origin_answer": "\nEKS 上的EMR 消除了运行专用集群的必要性，从而降低了成本。您可以使用公用的共享 EKS集群来运行需要不同版本的开源大数据分析框架的分析应用程序。您也可以使用相同的 EKS 集群来运行其他容器化的非 EMR 应用程序。\n", "generate_question": "EKS 上的 EMR 与传统的 EMR 相比有什么优势？", "generate_answer": "EKS 上的 EMR 相比传统的 EMR 具有更低的成本。传统的 EMR 需要运行专用集群来支持大数据分析，而 EKS 上的 EMR 可以共享 EKS 集群，从而节省了资源和成本。"}
{"origin_question": "\nEKS 上的 EMR 如何有助于降低成本？\n", "origin_answer": "\nEKS 上的EMR 消除了运行专用集群的必要性，从而降低了成本。您可以使用公用的共享 EKS集群来运行需要不同版本的开源大数据分析框架的分析应用程序。您也可以使用相同的 EKS 集群来运行其他容器化的非 EMR 应用程序。\n", "generate_question": "EKS 上的 EMR 是否只能运行大数据分析框架？", "generate_answer": "不是的。EKS 上的 EMR 可以运行需要不同版本的开源大数据分析框架的分析应用程序，同时也可以在同一 EKS 集群上运行其他容器化的非 EMR 应用程序。"}
{"origin_question": "\n如何对 EKS 上的 EMR 收取费用？\n", "origin_answer": "\nEKS 上的Amazon EMR 定价是基于运行您作业的 Pod 所请求的 vCPU 和内存资源来计算，细粒度为每分钟。有关定价信息，请访问 Amazon EMR定价页面。\n", "generate_question": "EKS 上的 Amazon EMR 如何计算费用？", "generate_answer": "EKS 上的 Amazon EMR 的费用是根据作业的 Pod 请求的 vCPU 和内存资源来计算的，计费粒度为每分钟。您可以访问 Amazon EMR 定价页面获取详细的定价信息。"}
{"origin_question": "\n如何对 EKS 上的 EMR 收取费用？\n", "origin_answer": "\nEKS 上的Amazon EMR 定价是基于运行您作业的 Pod 所请求的 vCPU 和内存资源来计算，细粒度为每分钟。有关定价信息，请访问 Amazon EMR定价页面。\n", "generate_question": "Amazon EMR 在 EKS 上的定价是如何确定的？", "generate_answer": "Amazon EMR 在 EKS 上的定价是根据作业的 Pod 请求的 vCPU 和内存资源来计算的，计费粒度为每分钟。您可以访问 Amazon EMR 定价页面获取详细的定价信息。"}
{"origin_question": "\n什么是 Pod 模板？\n", "origin_answer": "EKS 上的 EMR 使您可以使用 Kubernetes Pod 模板来定制作业在 Kubernetes 集群中运行的位置和方式。Kubernetes Pod 模板提供可重复使用的设计模式或样板文件，以声明方式表示 Kubernetes Pod 应该如何部署到您的 EKS 集群。\n", "generate_question": "什么是 EKS 上的 EMR？", "generate_answer": "EKS 上的 EMR 是指在亚马逊云科技的弹性 Kubernetes 服务（EKS）上运行的弹性 MapReduce（EMR）服务。它允许用户在 Kubernetes 集群中运行和管理 MapReduce 作业。"}
{"origin_question": "\n什么是 Pod 模板？\n", "origin_answer": "EKS 上的 EMR 使您可以使用 Kubernetes Pod 模板来定制作业在 Kubernetes 集群中运行的位置和方式。Kubernetes Pod 模板提供可重复使用的设计模式或样板文件，以声明方式表示 Kubernetes Pod 应该如何部署到您的 EKS 集群。\n", "generate_question": "什么是 Kubernetes Pod？", "generate_answer": "Kubernetes Pod 是 Kubernetes 中最小的可部署单元，它是一个由一个或多个容器组成的组。Pod 提供了一个独立的环境，其中的容器可以共享网络和存储资源，并且可以通过本地进程间通信进行交互。"}
{"origin_question": "\n什么是 Pod 模板？\n", "origin_answer": "EKS 上的 EMR 使您可以使用 Kubernetes Pod 模板来定制作业在 Kubernetes 集群中运行的位置和方式。Kubernetes Pod 模板提供可重复使用的设计模式或样板文件，以声明方式表示 Kubernetes Pod 应该如何部署到您的 EKS 集群。\n", "generate_question": "如何使用 Pod 模板在 EKS 集群中定制作业的运行方式？", "generate_answer": "使用 Pod 模板，您可以通过声明方式来定制作业在 EKS 集群中的运行位置和方式。Pod 模板是可重复使用的设计模式或样板文件，您可以在其中指定作业的部署方式，例如指定容器的资源需求、环境变量、挂载的存储卷等。通过使用 Pod 模板，您可以更灵活地控制作业的运行方式，并根据需要进行定制化配置。"}
{"origin_question": "\n我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？\n", "origin_answer": "Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。\n", "generate_question": "什么是 Pod Templates？", "generate_answer": "Pod Templates 是一种在 Kubernetes 中控制作业安排方式的方法。"}
{"origin_question": "\n我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？\n", "origin_answer": "Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。\n", "generate_question": "在 EKS 上的 EMR 作业中，如何使用 Pod Templates？", "generate_answer": "在 EKS 上的 EMR 作业中，可以使用 Pod Templates 来对作业的资源分配和容器运行进行精细控制。"}
{"origin_question": "\n我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？\n", "origin_answer": "Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。\n", "generate_question": "Pod Templates 可以提供哪些控制方式？", "generate_answer": "Pod Templates 可以提供更多的控制方式，例如在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行。"}
{"origin_question": "\n我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？\n", "origin_answer": "Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。\n", "generate_question": "使用 Pod Templates 可以带来什么好处？", "generate_answer": "使用 Pod Templates 可以降低成本并提高作业的性能，因为可以根据需求精细控制资源分配和容器运行。"}
{"origin_question": "\n我为什么应该将 Pod 模板用于 EKS 上的 EMR 作业？\n", "origin_answer": "Pod Templates 可以对作业在 Kubernetes 中的安排方式提供更多控制。例如，您可以通过在 Amazon EC2 Spot 实例上运行 Spark 驱动程序任务或只允许需要 SSD 的作业在启用 SSD 的实例上运行来降低成本。将 Pod 模板与 EKS 上的 EMR 结合使用可对如何分配资源并在作业中运行自定义容器进行精细控制。因此，将会降低成本并提高作业的性能。\n", "generate_question": "如何将 Pod 模板与 EKS 上的 EMR 结合使用？", "generate_answer": "可以将 Pod 模板与 EKS 上的 EMR 结合使用，通过配置 Pod 模板来控制作业的资源分配和容器运行，从而实现成本降低和性能提升的目标。"}
{"origin_question": "\n什么是 Pod？\n", "origin_answer": "Pods 是具有共享网络和存储资源的一个或多个容器，在 Kubernetes 工作线程节点上运行。EKS 上的 EMR 通过将 Spark 驱动程序和执行程序任务计划为单独的 Pod 来使用 Pod 运行作业。\n", "generate_question": "什么是 Pod？", "generate_answer": "Pod 是一个或多个容器的集合，它们共享网络和存储资源，并在 Kubernetes 工作线程节点上运行。"}
{"origin_question": "\n什么是 Pod？\n", "origin_answer": "Pods 是具有共享网络和存储资源的一个或多个容器，在 Kubernetes 工作线程节点上运行。EKS 上的 EMR 通过将 Spark 驱动程序和执行程序任务计划为单独的 Pod 来使用 Pod 运行作业。\n", "generate_question": "在 EKS 上的 EMR 如何使用 Pod 运行作业？", "generate_answer": "在 EKS 上的 EMR 中，EMR 使用 Pod 来运行作业，将 Spark 驱动程序和执行程序任务计划为单独的 Pod。"}
{"origin_question": "\n什么是 Pod？\n", "origin_answer": "Pods 是具有共享网络和存储资源的一个或多个容器，在 Kubernetes 工作线程节点上运行。EKS 上的 EMR 通过将 Spark 驱动程序和执行程序任务计划为单独的 Pod 来使用 Pod 运行作业。\n", "generate_question": "Pod 在 Kubernetes 中的作用是什么？", "generate_answer": "Pod 在 Kubernetes 中的作用是提供一个运行容器的环境，它可以包含一个或多个容器，并共享网络和存储资源。"}
{"origin_question": "\nPod 模板有哪些使用案例？\n", "origin_answer": "您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。\n", "generate_question": "Pod 模板可以用来优化哪些方面的性能和成本？", "generate_answer": "Pod 模板可以用来同时优化性能和成本。例如，可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。"}
{"origin_question": "\nPod 模板有哪些使用案例？\n", "origin_answer": "您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。\n", "generate_question": "在什么情况下可以使用 Pod 模板来运行作业？", "generate_answer": "可以使用 Pod 模板来运行作业的情况包括需要精细的工作负载控制以支持多个团队或组织在 EKS 上运行作业的需求。"}
{"origin_question": "\nPod 模板有哪些使用案例？\n", "origin_answer": "您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。\n", "generate_question": "Pod 模板如何简化在团队指定的节点组上运行作业的过程？", "generate_answer": "Pod 模板简化了在团队指定的节点组上运行作业的过程，使得在指定的节点组上运行作业变得更加简单和方便。"}
{"origin_question": "\nPod 模板有哪些使用案例？\n", "origin_answer": "您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。\n", "generate_question": "Pod 模板可以用来部署哪些类型的容器？", "generate_answer": "Pod 模板可以用来部署 Sidecar 容器，用于运行初始化代码，也可以用来部署常用监控工具如 Fluentd 等，用于转发日志。"}
{"origin_question": "\nPod 模板有哪些使用案例？\n", "origin_answer": "您可以通过使用 Pod 模板同时优化性能和成本。例如，您可以通过定义在 EC2 Spot 实例上运行的作业来节省成本，或者通过在 GPU 或 SSD 支持的 EC2 实例上计划作业来提高性能。客户通常需要精细的工作负载控制，以在 EKS 上支持多个团队或组织，而 Pod 模板简化了在团队指定的节点组上运行作业的过程。此外，您还可以部署 Sidecar 容器来为作业运行初始化代码，或运行 Fluentd 等常用监控工具来转发日志。\n", "generate_question": "Pod 模板可以在哪些类型的 EC2 实例上计划作业？", "generate_answer": "Pod 模板可以在支持 GPU 或 SSD 的 EC2 实例上计划作业，以提高作业的性能。"}
{"origin_question": "\n我是否能为我的 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？\n", "origin_answer": "可以，但您不需要为驱动程序和执行程序提供单独的模板。例如，您可以配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在 AWS EC2 按需实例上运行，Spark 执行程序只在 AWS Fargate 实例上运行。在提交作业时，配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 以引用模板的 S3 位置。\n", "generate_question": "如何为 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？", "generate_answer": "可以通过配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 来为 Spark 驱动程序和执行程序指定不同的 Pod 模板。"}
{"origin_question": "\n我是否能为我的 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？\n", "origin_answer": "可以，但您不需要为驱动程序和执行程序提供单独的模板。例如，您可以配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在 AWS EC2 按需实例上运行，Spark 执行程序只在 AWS Fargate 实例上运行。在提交作业时，配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 以引用模板的 S3 位置。\n", "generate_question": "是否需要为驱动程序和执行程序分别提供单独的模板？", "generate_answer": "不需要为驱动程序和执行程序提供单独的模板，可以使用相同的模板。只需在提交作业时配置相应的 spark 属性即可。"}
{"origin_question": "\n我是否能为我的 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？\n", "origin_answer": "可以，但您不需要为驱动程序和执行程序提供单独的模板。例如，您可以配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在 AWS EC2 按需实例上运行，Spark 执行程序只在 AWS Fargate 实例上运行。在提交作业时，配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 以引用模板的 S3 位置。\n", "generate_question": "如何指定 Spark 驱动程序在特定的 AWS EC2 按需实例上运行？", "generate_answer": "可以通过配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在特定的 AWS EC2 按需实例上运行。"}
{"origin_question": "\n我是否能为我的 Spark 驱动程序和 Spark 执行程序指定不同的 Pod 模板？\n", "origin_answer": "可以，但您不需要为驱动程序和执行程序提供单独的模板。例如，您可以配置 nodeSelectors 和 tolerations 来指定 Spark 驱动程序只在 AWS EC2 按需实例上运行，Spark 执行程序只在 AWS Fargate 实例上运行。在提交作业时，配置 spark 属性 spark.kubernetes.driver.podTemplateFile 和 spark.kubernetes.executor.podTemplateFile 以引用模板的 S3 位置。\n", "generate_question": "如何指定 Spark 执行程序在特定的 AWS Fargate 实例上运行？", "generate_answer": "可以通过配置 nodeSelectors 和 tolerations 来指定 Spark 执行程序只在特定的 AWS Fargate 实例上运行。"}
{"origin_question": "\n我可以指定什么模板值？\n", "origin_answer": "您可以同时指定 Pod 级字段（包括 Volumes、Pod Affinity、Init Containers、Node Selector）和 Spark 主容器级字段（包括 EnvFrom、Working Directory、Lifecycle、Container Volume Mounts）。允许值的完整列表提供在我们的文档中。\n", "generate_question": "我可以在亚马逊云科技的模板中指定哪些 Pod 级字段？", "generate_answer": "您可以在亚马逊云科技的模板中指定 Volumes、Pod Affinity、Init Containers、Node Selector 这些 Pod 级字段。"}
{"origin_question": "\n我可以指定什么模板值？\n", "origin_answer": "您可以同时指定 Pod 级字段（包括 Volumes、Pod Affinity、Init Containers、Node Selector）和 Spark 主容器级字段（包括 EnvFrom、Working Directory、Lifecycle、Container Volume Mounts）。允许值的完整列表提供在我们的文档中。\n", "generate_question": "亚马逊云科技的模板中可以指定哪些 Spark 主容器级字段？", "generate_answer": "亚马逊云科技的模板中可以指定 EnvFrom、Working Directory、Lifecycle、Container Volume Mounts 这些 Spark 主容器级字段。"}
{"origin_question": "\n我可以指定什么模板值？\n", "origin_answer": "您可以同时指定 Pod 级字段（包括 Volumes、Pod Affinity、Init Containers、Node Selector）和 Spark 主容器级字段（包括 EnvFrom、Working Directory、Lifecycle、Container Volume Mounts）。允许值的完整列表提供在我们的文档中。\n", "generate_question": "在亚马逊云科技的模板中，我可以同时指定哪些字段的值？", "generate_answer": "在亚马逊云科技的模板中，您可以同时指定 Pod 级字段和 Spark 主容器级字段的值。允许值的完整列表提供在亚马逊云科技的文档中。"}
{"origin_question": "\n在何处可以找到有关 Pod 模板的更多信息？\n", "origin_answer": "Amazon EKS 已经支持 Pod 模板，有关 EKS 上的 Amazon EMR 对 Pod 模板的支持的更多信息，请参阅我们的文档和 Apache Spark Pod 模板文档。\n", "generate_question": "Amazon EKS支持哪种模板？", "generate_answer": "Amazon EKS支持Pod模板。"}
{"origin_question": "\n在何处可以找到有关 Pod 模板的更多信息？\n", "origin_answer": "Amazon EKS 已经支持 Pod 模板，有关 EKS 上的 Amazon EMR 对 Pod 模板的支持的更多信息，请参阅我们的文档和 Apache Spark Pod 模板文档。\n", "generate_question": "在哪里可以找到有关Amazon EMR对Pod模板的支持的更多信息？", "generate_answer": "可以在Amazon EKS的文档和Apache Spark Pod模板文档中找到有关Amazon EMR对Pod模板的支持的更多信息。"}
{"origin_question": "\n为什么我应通过 EKS 上的 EMR 使用自定义镜像？\n", "origin_answer": "如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。\n", "generate_question": "在 EKS 上的 EMR 中，为什么要使用自定义镜像？", "generate_answer": "使用自定义镜像可以将应用程序及其依赖项打包成一个自包含的 Docker 镜像，避免了在运行时从外部存储服务引用的麻烦。这样可以简化应用程序的管理和部署，并且可以使用与其他容器化应用程序相同的 DevOps 流程。"}
{"origin_question": "\n为什么我应通过 EKS 上的 EMR 使用自定义镜像？\n", "origin_answer": "如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。\n", "generate_question": "在 EKS 上的 EMR 中，使用自定义镜像有什么好处？", "generate_answer": "使用自定义镜像可以避免维护和更新外部存储的库或对其进行版本控制的工作。同时，使用自定义镜像还可以使用与其他容器化应用程序相同的 DevOps 流程开发大数据应用程序。"}
{"origin_question": "\n为什么我应通过 EKS 上的 EMR 使用自定义镜像？\n", "origin_answer": "如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。\n", "generate_question": "在 EKS 上的 EMR 中，如何创建自定义镜像？", "generate_answer": "要创建自定义镜像，您需要将应用程序及其依赖项打包成一个 Docker 镜像。然后，您可以将该镜像上传到 Amazon ECR（Elastic Container Registry）中，并在 EKS 上的 EMR 中指向该镜像进行运行。"}
{"origin_question": "\n为什么我应通过 EKS 上的 EMR 使用自定义镜像？\n", "origin_answer": "如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。\n", "generate_question": "在 EKS 上的 EMR 中，使用自定义镜像是否需要额外的配置？", "generate_answer": "是的，使用自定义镜像需要进行一些额外的配置。您需要在 EKS 上的 EMR 中指定您的自定义镜像的位置，并确保您的镜像可以被正确地访问和运行。"}
{"origin_question": "\n为什么我应通过 EKS 上的 EMR 使用自定义镜像？\n", "origin_answer": "如果没有自定义镜像，要使用 EKS 上的 EMR 管理应用程序依赖项，则需要您在运行时从 Amazon S3 等外部存储服务进行引用。现在，在自定义镜像的支持下，您可以创建一个包含应用程序及其依赖项的自包含的 Docker 镜像。您不再需要维护、更新外部存储的库或对其进行版本控制，并且可以使用与其他容器化应用程序所用的相同 DevOps 流程开发大数据应用程序。只需指向您的镜像并运行。\n", "generate_question": "在 EKS 上的 EMR 中，使用自定义镜像是否可以与其他容器化应用程序共享相同的 DevOps 流程？", "generate_answer": "是的，使用自定义镜像可以与其他容器化应用程序共享相同的 DevOps 流程。这意味着您可以使用相同的工具和流程来开发、测试和部署大数据应用程序，从而提高开发效率和一致性。"}
{"origin_question": "\n什么是自定义镜像？\n", "origin_answer": "自定义镜像是 EKS 上的 EMR 提供的 Docker 镜像（“基础镜像”），包含 EMR 运行时和其他 AWS 服务的连接器，您可以对这些服务进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。新镜像可以存储在 Amazon Elastic Container Registry (ECR) 或您自己的 Docker 容器注册表中。\n", "generate_question": "自定义镜像是由谁提供的？", "generate_answer": "自定义镜像是由亚马逊云科技的 EMR 提供的。"}
{"origin_question": "\n什么是自定义镜像？\n", "origin_answer": "自定义镜像是 EKS 上的 EMR 提供的 Docker 镜像（“基础镜像”），包含 EMR 运行时和其他 AWS 服务的连接器，您可以对这些服务进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。新镜像可以存储在 Amazon Elastic Container Registry (ECR) 或您自己的 Docker 容器注册表中。\n", "generate_question": "自定义镜像包含哪些内容？", "generate_answer": "自定义镜像包含 EMR 运行时和其他 AWS 服务的连接器。"}
{"origin_question": "\n什么是自定义镜像？\n", "origin_answer": "自定义镜像是 EKS 上的 EMR 提供的 Docker 镜像（“基础镜像”），包含 EMR 运行时和其他 AWS 服务的连接器，您可以对这些服务进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。新镜像可以存储在 Amazon Elastic Container Registry (ECR) 或您自己的 Docker 容器注册表中。\n", "generate_question": "可以对自定义镜像进行怎样的修改？", "generate_answer": "可以对自定义镜像进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。"}
{"origin_question": "\n什么是自定义镜像？\n", "origin_answer": "自定义镜像是 EKS 上的 EMR 提供的 Docker 镜像（“基础镜像”），包含 EMR 运行时和其他 AWS 服务的连接器，您可以对这些服务进行修改，以包括您的应用程序所需的应用程序依赖项或其他包。新镜像可以存储在 Amazon Elastic Container Registry (ECR) 或您自己的 Docker 容器注册表中。\n", "generate_question": "新镜像可以存储在哪些地方？", "generate_answer": "新镜像可以存储在 Amazon Elastic Container Registry (ECR) 或您自己的 Docker 容器注册表中。"}
{"origin_question": "\n自定义镜像有哪些使用案例？\n", "origin_answer": "客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。\n", "generate_question": "什么是自定义镜像？", "generate_answer": "自定义镜像是指客户可以根据自己的需求，在基础镜像的基础上添加特定的依赖项和库，以满足应用程序的特定需求。"}
{"origin_question": "\n自定义镜像有哪些使用案例？\n", "origin_answer": "客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。\n", "generate_question": "自定义镜像可以存储在哪里？", "generate_answer": "自定义镜像可以存储在Amazon Elastic Container Registry (Amazon ECR)中，这是一个安全、可扩展的Docker容器注册表服务。"}
{"origin_question": "\n自定义镜像有哪些使用案例？\n", "origin_answer": "客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。\n", "generate_question": "自定义镜像可以用于哪些用途？", "generate_answer": "自定义镜像可以用于包括应用程序开发、测试和生产环境部署等多个用途。客户可以根据自己的需求创建自定义镜像，并将其部署到相应的环境中。"}
{"origin_question": "\n自定义镜像有哪些使用案例？\n", "origin_answer": "客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。\n", "generate_question": "如何对自定义镜像进行漏洞扫描？", "generate_answer": "可以对生成的不可改变镜像进行漏洞扫描，以确保镜像的安全性。通过使用相应的漏洞扫描工具，可以对自定义镜像进行扫描并及时发现潜在的漏洞。"}
{"origin_question": "\n自定义镜像有哪些使用案例？\n", "origin_answer": "客户可以创建基础镜像，添加其公司标准库，然后将其存储在 Amazon Elastic Container Registry (Amazon ECR) 中。其他客户可以自定义镜像以包括与应用程序特定相关的依赖项。可以对生成的不可改变镜像进行漏洞扫描，并部署到测试和生产环境中。您可以添加的依赖项示例包括 Java SDK、Python 或 R 库，您可以将它们直接添加到镜像中，就像使用其他容器化应用程序一样。\n", "generate_question": "自定义镜像可以添加哪些依赖项？", "generate_answer": "自定义镜像可以添加与应用程序特定相关的依赖项，例如Java SDK、Python或R库等。这些依赖项可以直接添加到镜像中，以满足应用程序的运行需求。"}
{"origin_question": "\n基础镜像中包含什么？\n", "origin_answer": "对于基础镜像中包含的 性能优化 Spark 运行时和组件，与您在没有自定义镜像的情况下提交作业时所获得的相同。", "generate_question": "亚马逊云科技的基础镜像中还包含哪些组件？", "generate_answer": "除了性能优化 Spark 运行时，基础镜像还包含其他组件，具体包括但不限于 Hadoop、Hive、Pig、HBase 等。"}
{"origin_question": "\n基础镜像中包含什么？\n", "origin_answer": "对于基础镜像中包含的 性能优化 Spark 运行时和组件，与您在没有自定义镜像的情况下提交作业时所获得的相同。", "generate_question": "如何提交作业时使用基础镜像中的组件？", "generate_answer": "在没有自定义镜像的情况下，您可以直接提交作业并使用基础镜像中的组件，无需额外配置或安装。"}
{"origin_question": "\n我应何时为我的 Spark 驱动程序和 Spark 执行程序指定不同的自定义镜像？\n", "origin_answer": "在您想要包含不同的依赖项或库时，您可以为 Spark 驱动程序和执行程序指定单独的镜像。删除两个镜像中都不需要的库可以缩小镜像，进而缩短作业启动时间。您可以为驱动程序和执行程序 (spark.kubernetes.container.image) 指定同一个镜像，也可以为驱动程序 (spark.kubernetes.driver.container.image) 和执行程序 (spark.kubernetes.executor.container.image) 指定不同的镜像。", "generate_question": "为什么要为 Spark 驱动程序和执行程序指定不同的自定义镜像？", "generate_answer": "为了包含不同的依赖项或库，可以为 Spark 驱动程序和执行程序指定不同的自定义镜像。"}
{"origin_question": "\n我应何时为我的 Spark 驱动程序和 Spark 执行程序指定不同的自定义镜像？\n", "origin_answer": "在您想要包含不同的依赖项或库时，您可以为 Spark 驱动程序和执行程序指定单独的镜像。删除两个镜像中都不需要的库可以缩小镜像，进而缩短作业启动时间。您可以为驱动程序和执行程序 (spark.kubernetes.container.image) 指定同一个镜像，也可以为驱动程序 (spark.kubernetes.driver.container.image) 和执行程序 (spark.kubernetes.executor.container.image) 指定不同的镜像。", "generate_question": "如何缩小镜像并缩短作业启动时间？", "generate_answer": "可以删除两个镜像中都不需要的库来缩小镜像，并进而缩短作业启动时间。"}
{"origin_question": "\n我应何时为我的 Spark 驱动程序和 Spark 执行程序指定不同的自定义镜像？\n", "origin_answer": "在您想要包含不同的依赖项或库时，您可以为 Spark 驱动程序和执行程序指定单独的镜像。删除两个镜像中都不需要的库可以缩小镜像，进而缩短作业启动时间。您可以为驱动程序和执行程序 (spark.kubernetes.container.image) 指定同一个镜像，也可以为驱动程序 (spark.kubernetes.driver.container.image) 和执行程序 (spark.kubernetes.executor.container.image) 指定不同的镜像。", "generate_question": "是否可以为驱动程序和执行程序指定同一个镜像？", "generate_answer": "是的，可以为驱动程序和执行程序指定同一个镜像。"}
{"origin_question": "\n我应何时为我的 Spark 驱动程序和 Spark 执行程序指定不同的自定义镜像？\n", "origin_answer": "在您想要包含不同的依赖项或库时，您可以为 Spark 驱动程序和执行程序指定单独的镜像。删除两个镜像中都不需要的库可以缩小镜像，进而缩短作业启动时间。您可以为驱动程序和执行程序 (spark.kubernetes.container.image) 指定同一个镜像，也可以为驱动程序 (spark.kubernetes.driver.container.image) 和执行程序 (spark.kubernetes.executor.container.image) 指定不同的镜像。", "generate_question": "如何为驱动程序和执行程序分别指定不同的镜像？", "generate_answer": "可以通过设置驱动程序的镜像参数 `spark.kubernetes.driver.container.image` 和执行程序的镜像参数 `spark.kubernetes.executor.container.image` 来分别指定不同的镜像。"}
{"origin_question": "\n我应何时为我的 Spark 驱动程序和 Spark 执行程序指定不同的自定义镜像？\n", "origin_answer": "在您想要包含不同的依赖项或库时，您可以为 Spark 驱动程序和执行程序指定单独的镜像。删除两个镜像中都不需要的库可以缩小镜像，进而缩短作业启动时间。您可以为驱动程序和执行程序 (spark.kubernetes.container.image) 指定同一个镜像，也可以为驱动程序 (spark.kubernetes.driver.container.image) 和执行程序 (spark.kubernetes.executor.container.image) 指定不同的镜像。", "generate_question": "在什么情况下需要为 Spark 驱动程序和执行程序指定不同的自定义镜像？", "generate_answer": "当需要包含不同的依赖项或库时，可以为 Spark 驱动程序和执行程序指定不同的自定义镜像。"}
{"origin_question": "\n在何处可以找到有关自定义镜像的更多信息？\n", "origin_answer": "有关 EKS 上的 Amazon EMR 对自定义镜像的支持的更多信息，请参阅我们的文档或 Apache Spark 文档。", "generate_question": "亚马逊云科技的自定义镜像支持哪些服务？", "generate_answer": "亚马逊云科技的自定义镜像支持 Amazon EMR 和 Apache Spark。"}
{"origin_question": "\n在何处可以找到有关自定义镜像的更多信息？\n", "origin_answer": "有关 EKS 上的 Amazon EMR 对自定义镜像的支持的更多信息，请参阅我们的文档或 Apache Spark 文档。", "generate_question": "如何获取有关亚马逊云科技自定义镜像的文档？", "generate_answer": "您可以在亚马逊云科技的文档或 Apache Spark 文档中找到有关亚马逊云科技自定义镜像的更多信息。"}
{"origin_question": "\n自定义镜像是否需要额外收费？\n", "origin_answer": "使用自定义镜像功能不收取费用。\nAWS Outposts 上的 Amazon EMR", "generate_question": "在亚马逊云科技中，使用自定义镜像功能是否需要额外收费？", "generate_answer": "使用自定义镜像功能不收取费用。"}
{"origin_question": "\n什么是 AWS Outposts？\n", "origin_answer": "AWS Outposts 可将本地 AWS 服务、基础设施和运营模式引入绝大部分数据中心、主机托管空间或本地设施。使用 Outposts 上的 EMR，您可以像在云中一样在本地部署、管理和扩展 EMR 集群。\n", "generate_question": "AWS Outposts可以在哪些地方部署？", "generate_answer": "AWS Outposts可以部署在绝大部分数据中心、主机托管空间或本地设施。"}
{"origin_question": "\n什么是 AWS Outposts？\n", "origin_answer": "AWS Outposts 可将本地 AWS 服务、基础设施和运营模式引入绝大部分数据中心、主机托管空间或本地设施。使用 Outposts 上的 EMR，您可以像在云中一样在本地部署、管理和扩展 EMR 集群。\n", "generate_question": "AWS Outposts可以用来部署哪种服务？", "generate_answer": "AWS Outposts可以用来部署本地的AWS服务、基础设施和运营模式。"}
{"origin_question": "\n什么是 AWS Outposts？\n", "origin_answer": "AWS Outposts 可将本地 AWS 服务、基础设施和运营模式引入绝大部分数据中心、主机托管空间或本地设施。使用 Outposts 上的 EMR，您可以像在云中一样在本地部署、管理和扩展 EMR 集群。\n", "generate_question": "在AWS Outposts上可以使用哪个服务来部署、管理和扩展EMR集群？", "generate_answer": "在AWS Outposts上可以使用EMR来部署、管理和扩展EMR集群。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "什么是 Outposts 上的 EMR？", "generate_answer": "Outposts 上的 EMR 是指在亚马逊云科技的 Outposts 服务中运行的 Elastic MapReduce（EMR）服务。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 适用于哪些情况？", "generate_answer": "Outposts 上的 EMR 适用于那些有本地的 Apache Hadoop 部署，并且需要增强处理能力，同时不想将数据移至云中的情况。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 如何增强处理能力？", "generate_answer": "利用 Outposts 上的 EMR，您可以在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集，以满足高峰使用率期间的容量需求。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 是否符合 SLA 要求？", "generate_answer": "是的，使用 Outposts 上的 EMR 可以满足 SLA 要求。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 是否适用于保留在本地的数据处理？", "generate_answer": "是的，如果需要处理保留在本地的数据，可以使用 Outposts 上的 EMR 在本地部署并运行应用程序，如 Apache Hadoop 和 Apache Spark。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "使用 Outposts 上的 EMR 是否需要将大量本地数据移动到云中？", "generate_answer": "不需要，使用 Outposts 上的 EMR 可以减少将大量本地数据移动到云中的需求，从而减少处理这些数据所需的总体时间。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 是否适用于将数据和 Apache Hadoop 工作负载迁移到云中的情况？", "generate_answer": "是的，如果想在将数据和 Apache Hadoop 工作负载迁移到云中之前开始使用 EMR，可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "在迁移数据和 Apache Hadoop 工作负载到云中之前，可以逐渐将数据迁移到哪个亚马逊服务？", "generate_answer": "在迁移数据和 Apache Hadoop 工作负载到云中之前，可以逐渐将数据迁移到 Amazon S3。"}
{"origin_question": "\n何时应该使用 Outposts 上的 EMR？\n", "origin_answer": "如果您现在有本地的 Apache Hadoop 部署，并且仍在努力满足高峰使用率期间的容量需求，则可以在使用 Outposts 上的 EMR 来增强处理能力，而不必将数据移至云中。利用 Outposts 上的 EMR，您只需几分钟即可在本地启动新的 EMR 集群，并连接到本地 HDFS 存储中的现有数据集以满足此需求，同时仍符合 SLA 要求。\n\n对于因管理、合规性或其他原因而保留在本地的数据，如果需要处理，您可以使用 Outposts 上的 EMR 在本地部署并运行应用程序（如 Apache Hadoop 和 Apache Spark），与数据距离更近。这样便无需将大量本地数据移动到云中，减少了处理这些数据所需的总体时间。\n\n如果您正在将数据和 Apache Hadoop 工作负载迁移到云中，并且想在迁移完成前开始使用 EMR，您可以使用 AWS Outposts 来启动连接到现有本地 HDFS 存储的 EMR 集群。然后，您可以逐渐将数据迁移到 Amazon S3，作为云架构演变的一部分。\n", "generate_question": "Outposts 上的 EMR 是否可以作为云架构演变的一部分？", "generate_answer": "是的，使用 AWS Outposts 上的 EMR 可以作为云架构演变的一部分，逐步迁移数据和工作负载到云中。"}
{"origin_question": "\nOutposts 上的 EMR 支持哪些 EMR 版本？\n", "origin_answer": "支持的最低 Amazon EMR 版本为 5.28.0。\n", "generate_question": "亚马逊云科技的 Outposts 上是否支持除 EMR 之外的其他服务？", "generate_answer": "是的，亚马逊云科技的 Outposts 上支持除 EMR 之外的其他服务。"}
{"origin_question": "\nOutposts 上的 EMR 支持哪些 EMR 版本？\n", "origin_answer": "支持的最低 Amazon EMR 版本为 5.28.0。\n", "generate_question": "在 Outposts 上使用的 EMR 版本是否有限制？", "generate_answer": "是的，Outposts 上使用的 EMR 版本有限制，最低版本为 5.28.0。"}
{"origin_question": "\n使用 Outposts 时有哪些 EMR 应用程序可用？\n", "origin_answer": "EMR 5.28.0 及更高版本中的所有应用程序均支持。请参阅我们的发布说明，获取完整的 EMR 应用程序列表。\n", "generate_question": "Outposts 上的 EMR 5.28.0 及更高版本支持哪些应用程序？", "generate_answer": "EMR 5.28.0 及更高版本支持所有应用程序。您可以在发布说明中查看完整的 EMR 应用程序列表。"}
{"origin_question": "\n使用 Outposts 时有哪些 EMR 应用程序可用？\n", "origin_answer": "EMR 5.28.0 及更高版本中的所有应用程序均支持。请参阅我们的发布说明，获取完整的 EMR 应用程序列表。\n", "generate_question": "在使用 Outposts 时，如何确定 EMR 应用程序的版本？", "generate_answer": "您可以查看 EMR 的发布说明，其中包含了 EMR 5.28.0 及更高版本的应用程序列表。"}
{"origin_question": "\nOutposts 上的 EMR 不支持哪些 EMR 功能？\n", "origin_answer": "在 AWS Outposts 中不提供 EC2 Spot 实例。创建集群时，必须选择 EC2 按需实例。\nAWS Outposts 中提供一部分 EC2 实例类型。有关 EMR 和 Outposts 支持的实例类型的列表，请参阅我们的文档。\n将 Amazon EBS 卷添加到实例时，AWS Outposts 仅支持通用SSD (GP2) 存储类型。", "generate_question": "在 AWS Outposts 上，EMR 不支持哪些功能？", "generate_answer": "在 AWS Outposts 上，EMR 不支持 EC2 Spot 实例和添加 Amazon EBS 卷时的存储类型选择。"}
{"origin_question": "\nOutposts 上的 EMR 不支持哪些 EMR 功能？\n", "origin_answer": "在 AWS Outposts 中不提供 EC2 Spot 实例。创建集群时，必须选择 EC2 按需实例。\nAWS Outposts 中提供一部分 EC2 实例类型。有关 EMR 和 Outposts 支持的实例类型的列表，请参阅我们的文档。\n将 Amazon EBS 卷添加到实例时，AWS Outposts 仅支持通用SSD (GP2) 存储类型。", "generate_question": "在 AWS Outposts 上创建 EMR 集群时，必须选择哪种类型的 EC2 实例？", "generate_answer": "在 AWS Outposts 上创建 EMR 集群时，必须选择 EC2 按需实例。"}
{"origin_question": "\nOutposts 上的 EMR 不支持哪些 EMR 功能？\n", "origin_answer": "在 AWS Outposts 中不提供 EC2 Spot 实例。创建集群时，必须选择 EC2 按需实例。\nAWS Outposts 中提供一部分 EC2 实例类型。有关 EMR 和 Outposts 支持的实例类型的列表，请参阅我们的文档。\n将 Amazon EBS 卷添加到实例时，AWS Outposts 仅支持通用SSD (GP2) 存储类型。", "generate_question": "AWS Outposts 提供哪些类型的 EC2 实例？", "generate_answer": "AWS Outposts 提供一部分 EC2 实例类型，具体列表可以参考相关文档。"}
{"origin_question": "\nOutposts 上的 EMR 不支持哪些 EMR 功能？\n", "origin_answer": "在 AWS Outposts 中不提供 EC2 Spot 实例。创建集群时，必须选择 EC2 按需实例。\nAWS Outposts 中提供一部分 EC2 实例类型。有关 EMR 和 Outposts 支持的实例类型的列表，请参阅我们的文档。\n将 Amazon EBS 卷添加到实例时，AWS Outposts 仅支持通用SSD (GP2) 存储类型。", "generate_question": "在 AWS Outposts 上添加 Amazon EBS 卷时，支持哪种存储类型？", "generate_answer": "在 AWS Outposts 上添加 Amazon EBS 卷时，仅支持通用SSD (GP2) 存储类型。"}
{"origin_question": "\n可以使用 Outpost 中的 EMR 集群从我现有的本地 Apache Hadoop 集群中读取数据吗？\n", "origin_answer": "在 Outpost 的 EMR 上运行的工作负载可以在现有 HDFS 存储中读写数据，因而您可以与现有的本地 Apache Hadoop 部署轻松集成。这使您能够使用 EMR 更好地满足数据处理需求，而无需迁移数据。\n", "generate_question": "Outpost 中的 EMR 集群可以与现有的本地 Apache Hadoop 集群集成吗？", "generate_answer": "是的，您可以使用 Outpost 中的 EMR 集群与现有的本地 Apache Hadoop 集群轻松集成。"}
{"origin_question": "\n可以使用 Outpost 中的 EMR 集群从我现有的本地 Apache Hadoop 集群中读取数据吗？\n", "origin_answer": "在 Outpost 的 EMR 上运行的工作负载可以在现有 HDFS 存储中读写数据，因而您可以与现有的本地 Apache Hadoop 部署轻松集成。这使您能够使用 EMR 更好地满足数据处理需求，而无需迁移数据。\n", "generate_question": "Outpost 的 EMR 上运行的工作负载可以在现有的本地 HDFS 存储中读取和写入数据吗？", "generate_answer": "是的，Outpost 的 EMR 上运行的工作负载可以在现有的本地 HDFS 存储中读取和写入数据。"}
{"origin_question": "\n可以使用 Outpost 中的 EMR 集群从我现有的本地 Apache Hadoop 集群中读取数据吗？\n", "origin_answer": "在 Outpost 的 EMR 上运行的工作负载可以在现有 HDFS 存储中读写数据，因而您可以与现有的本地 Apache Hadoop 部署轻松集成。这使您能够使用 EMR 更好地满足数据处理需求，而无需迁移数据。\n", "generate_question": "使用 Outpost 的 EMR 集群可以满足数据处理需求，而无需迁移数据吗？", "generate_answer": "是的，使用 Outpost 的 EMR 集群可以满足数据处理需求，而无需迁移数据。"}
{"origin_question": "\n可以使用 Outpost 中的 EMR 集群从我现有的本地 Apache Hadoop 集群中读取数据吗？\n", "origin_answer": "在 Outpost 的 EMR 上运行的工作负载可以在现有 HDFS 存储中读写数据，因而您可以与现有的本地 Apache Hadoop 部署轻松集成。这使您能够使用 EMR 更好地满足数据处理需求，而无需迁移数据。\n", "generate_question": "Outpost 的 EMR 如何帮助更好地满足数据处理需求？", "generate_answer": "Outpost 的 EMR 可以与现有的本地 Apache Hadoop 部署集成，使您能够更好地满足数据处理需求，而无需迁移数据。"}
{"origin_question": "\n可以选择在哪里存储数据吗？\n", "origin_answer": "在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。\n", "generate_question": "在启动 EMR 集群时，数据可以存储在哪些位置？", "generate_answer": "在 Outpost 中启动 EMR 集群时，数据可以存储在本地的 Outpost 中的本地 EBS 卷上，或者存储在外部文件系统（如现有的 HDFS 安装）中，也可以存储在 Amazon S3 中。"}
{"origin_question": "\n可以选择在哪里存储数据吗？\n", "origin_answer": "在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。\n", "generate_question": "在 Outpost 上的 EMR 中，可以选择将数据存储在哪里？", "generate_answer": "在 Outpost 上的 EMR 中，可以选择将数据存储在 Amazon S3 中或者本地存储在 Outpost 中。"}
{"origin_question": "\n可以选择在哪里存储数据吗？\n", "origin_answer": "在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。\n", "generate_question": "可以使用哪些工具将数据写入 Outpost 上的 EMR？", "generate_answer": "可以使用 Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序等工具将数据写入 Outpost 上的 EMR。"}
{"origin_question": "\n可以选择在哪里存储数据吗？\n", "origin_answer": "在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。\n", "generate_question": "Outpost 上的 EMR 可以完全控制数据存储的位置吗？", "generate_answer": "是的，使用 Outpost 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。"}
{"origin_question": "\n可以选择在哪里存储数据吗？\n", "origin_answer": "在 Outpost 启动 EMR 集群时，所有计算和数据存储资源都将部署在 Outpost 中。本地写入 EMR 集群的数据存储在 Outpost 中的本地 EBS 卷上。Apache Hive、Apache Spark、Presto 和其他 EMR 应用程序之类的工具均可配置为在本地 Outpost 中、外部文件系统（例如现有的 HDFS 安装）中或 Amazon S3 中写入数据。使用 Outposts 上的 EMR，您可以完全控制将数据存储在 Amazon S3 中还是本地存储在 Outpost 中。\n", "generate_question": "在 Outpost 上启动的 EMR 集群中，计算和数据存储资源部署在哪里？", "generate_answer": "在 Outpost 上启动的 EMR 集群中，所有计算和数据存储资源都将部署在 Outpost 中。数据存储在 Outpost 中的本地 EBS 卷上。"}
{"origin_question": "\n是否有任何 EMR 功能需要将数据上传到 S3？\n", "origin_answer": "在 Outpost 中启动 EMR 集群时，您可以选择是否启用日志记录。启用日志记录后，集群日志将被上传到您指定的 S3 存储桶。这些日志用于简化集群终止后的调试。禁用后，日志不会上传到 S3。\n", "generate_question": "在亚马逊云科技的 EMR 中，如何启用日志记录功能？", "generate_answer": "在 Outpost 中启动 EMR 集群时，您可以选择是否启用日志记录。启用日志记录后，集群日志将被上传到您指定的 S3 存储桶。"}
{"origin_question": "\n是否有任何 EMR 功能需要将数据上传到 S3？\n", "origin_answer": "在 Outpost 中启动 EMR 集群时，您可以选择是否启用日志记录。启用日志记录后，集群日志将被上传到您指定的 S3 存储桶。这些日志用于简化集群终止后的调试。禁用后，日志不会上传到 S3。\n", "generate_question": "亚马逊云科技的 EMR 集群日志上传到 S3 有什么作用？", "generate_answer": "集群日志上传到 S3 后，可以用于简化集群终止后的调试。您可以通过查看这些日志来分析和解决问题。"}
{"origin_question": "\n是否有任何 EMR 功能需要将数据上传到 S3？\n", "origin_answer": "在 Outpost 中启动 EMR 集群时，您可以选择是否启用日志记录。启用日志记录后，集群日志将被上传到您指定的 S3 存储桶。这些日志用于简化集群终止后的调试。禁用后，日志不会上传到 S3。\n", "generate_question": "如果禁用了 EMR 集群的日志记录功能，会发生什么？", "generate_answer": "如果禁用了日志记录功能，集群日志将不会被上传到 S3 存储桶，无法用于集群终止后的调试。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "当 Outpost 容量不足时，EMR 会如何处理？", "generate_answer": "当 Outpost 上的容量不足时，EMR 将收到容量不足通知，并在一段时间内重试启动集群。如果在重试期间仍然没有可用容量，集群将无法启动。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "在调整集群大小时，如果 Outpost 上的容量不足会发生什么？", "generate_answer": "在调整集群大小时，如果所请求的实例类型在 Outpost 上的容量不足，EMR 将无法扩展集群。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "如何监视 Outpost 上的容量利用率？", "generate_answer": "您可以设置 Amazon CloudWatch 提醒来监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "Outpost 容量不足时，是否可以手动增加容量？", "generate_answer": "在 Outpost 上增加容量需要进行一系列的操作，包括购买和部署新的物理服务器。因此，无法手动增加 Outpost 的容量。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "Outpost 容量不足时，是否可以使用其他实例类型？", "generate_answer": "如果 Outpost 上的容量不足，EMR 无法启动或扩展集群，无法使用其他实例类型来解决容量不足的问题。"}
{"origin_question": "\nOutpost 容量不足时会怎样？\n", "origin_answer": "在 Outpost 中启动集群时，EMR 会尝试启动您请求的 EC2 按需实例的数量和类型。如果 Outpost 上的容量不足，则 EMR 将收到容量不足通知。EMR 将在一段时间内重试，如果没有可用容量，则集群将无法启动。在调整集群大小时，将应用相同的过程。如果对于所请求的实例类型，Outpost 上的容量不足，则 EMR 将无法扩展集群。您可以轻松设置 Amazon CloudWatch 提醒，以监视 Outpost 上的容量利用率，并在实例容量低于所需阈值时收到提醒。\n", "generate_question": "Outpost 容量不足时，是否可以迁移集群到其他地区？", "generate_answer": "Outpost 是部署在特定地区的基础设施，无法迁移集群到其他地区来解决容量不足的问题。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 和 AWS 之间的网络连接中断会导致哪些操作无法执行？", "generate_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则无法执行某些操作，包括创建新集群或对现有集群执行新操作。此外，向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件等操作也会延迟，直到连接恢复。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 中的集群会如何受到网络连接中断的影响？", "generate_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，Outpost 中的集群将继续运行，但在连接恢复之前，无法执行某些操作，并且无法自动替换故障实例。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "如何避免 Outpost 和 AWS 之间的网络连接中断？", "generate_answer": "为了避免 Outpost 和 AWS 区域之间的网络连接中断，建议提供可靠的高可用性网络连接。如果网络连接丢失超过数小时，已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。建议在网络连接受到影响时主动启用终止保护。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "在网络连接恢复之前，Outpost 中的集群是否能够正常运行？", "generate_answer": "是的，如果 Outpost 及其 AWS 区域之间的网络连接丢失，Outpost 中的集群将继续运行，但在连接恢复之前，无法执行某些操作。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 和 AWS 区域之间的网络连接中断会对集群的实例替换产生什么影响？", "generate_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，实例发生故障时将不会自动替换该实例。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 和 AWS 区域之间的网络连接中断会对向运行中的集群添加步骤产生什么影响？", "generate_answer": "在 Outpost 和 AWS 区域之间的网络连接恢复之前，向运行中的集群添加步骤的操作将发生延迟。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 和 AWS 区域之间的网络连接中断会对检查步骤执行状态产生什么影响？", "generate_answer": "在 Outpost 和 AWS 区域之间的网络连接恢复之前，检查步骤执行状态的操作将发生延迟。"}
{"origin_question": "\n如果 Outpost 和 AWS 之间的网络连接中断会怎样？\n", "origin_answer": "如果 Outpost 及其 AWS 区域之间的网络连接丢失，则 Outpost 中的集群将继续运行，但是在连接恢复之前，您将无法执行某些操作。在连接恢复之前，无法创建新集群或对现有集群执行新操作。如果实例发生故障，不会自动替换该实例。此外，诸如向运行中的集群添加步骤、检查步骤执行状态以及发送 CloudWatch 指标和事件之类的操作将发生延迟，直到连接恢复。\n\n我们建议在 Outpost 与 AWS 区域之间提供可靠的高可用性网络连接。如果 Outpost 与其 AWS 区域之间的网络连接丢失超过数小时，则已启用终止保护的集群将继续运行，而已禁用终止保护的集群可能会终止。如果网络连接因例行维护而受到影响，建议您主动启用终止保护。\n使用 EBS 卷", "generate_question": "Outpost 和 AWS 区域之间的网络连接中断会对发送 CloudWatch 指标和事件产生什么影响？", "generate_answer": "在 Outpost 和 AWS 区域之间的网络连接恢复之前，发送 CloudWatch 指标和事件的操作将发生延迟。"}
{"origin_question": "\n可以做到哪些之前我无法做到的事情？\n", "origin_answer": "大部分 EC2 实例都附带固定的存储容量，称为“实例存储”。现在，您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。利用此功能，您还可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。\n", "generate_question": "什么是实例存储？", "generate_answer": "实例存储是指大部分 EC2 实例附带的固定存储容量。"}
{"origin_question": "\n可以做到哪些之前我无法做到的事情？\n", "origin_answer": "大部分 EC2 实例都附带固定的存储容量，称为“实例存储”。现在，您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。利用此功能，您还可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。\n", "generate_question": "如何在 Amazon EMR 群集中添加 EBS 卷？", "generate_answer": "您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。"}
{"origin_question": "\n可以做到哪些之前我无法做到的事情？\n", "origin_answer": "大部分 EC2 实例都附带固定的存储容量，称为“实例存储”。现在，您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。利用此功能，您还可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。\n", "generate_question": "在什么实例系列上可以运行 Amazon EMR 群集？", "generate_answer": "您可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。"}
{"origin_question": "\n可以做到哪些之前我无法做到的事情？\n", "origin_answer": "大部分 EC2 实例都附带固定的存储容量，称为“实例存储”。现在，您可以向 Amazon EMR 群集中的实例添加 EBS 卷，以便在实例上自定义存储。利用此功能，您还可以在仅限 EBS 的实例系列（如 M4 和 C4）上运行 Amazon EMR 群集。\n", "generate_question": "通过向 Amazon EMR 群集中的实例添加 EBS 卷，可以实现什么功能？", "generate_answer": "通过向 Amazon EMR 群集中的实例添加 EBS 卷，您可以自定义存储，并在实例上运行 Amazon EMR 群集。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "什么是 Amazon EMR？", "generate_answer": "Amazon EMR 是亚马逊云科技提供的一种云计算服务，用于在亚马逊云上快速、轻松地处理和分析大规模数据集。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "为什么要向运行于 Amazon EMR 的实例添加 EBS 卷？", "generate_answer": "向实例添加 EBS 卷可以带来以下好处：1. 自定义实例上的存储容量，满足大量 HDFS（或本地）存储的需求；2. 解决新一代实例类型存储限制的问题；3. 使用或迁移到仅限 EBS 的新一代实例系列。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "如何通过向实例添加 EBS 卷来节约成本？", "generate_answer": "通过向实例添加 EBS 卷，您可以优化实例上的存储，从而节约成本。您可以根据实际需求自定义实例上的存储容量，避免不必要的资源浪费。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "为什么在迁移到新一代实例系列时需要添加 EBS 卷？", "generate_answer": "在迁移到新一代实例系列时，可能会受到新一代实例类型每个节点提供的存储的限制。通过添加 EBS 卷，您可以解决存储限制的问题，轻松使用任何新一代实例类型。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "Amazon EMR 团队建议运行应用程序以得出什么样的结论？", "generate_answer": "Amazon EMR 团队建议运行应用程序以得出正确的结论，以确定从较旧的实例系列（如 M1 或 M2）迁移到新一代实例系列（如 M4、C4 和 R3）是否能够实现成本节约并提升性能。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "什么是 HDFS 存储？", "generate_answer": "HDFS（Hadoop Distributed File System）是一种分布式文件系统，用于存储和处理大规模数据集。在 Amazon EMR 中，可以使用 HDFS 存储来满足处理大量数据的需求。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "除了存储容量自定义外，还有其他优化实例上存储的方法吗？", "generate_answer": "除了通过添加 EBS 卷来自定义存储容量外，还可以使用其他方法来优化实例上的存储，例如使用压缩算法减少存储空间占用或使用分区和分桶技术提高查询性能。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "什么是 EBS 卷？", "generate_answer": "EBS（Elastic Block Store）卷是一种持久性块存储设备，可以附加到 Amazon EC2 实例上。通过向运行于 Amazon EMR 的实例添加 EBS 卷，可以扩展实例的存储容量。"}
{"origin_question": "\n向运行于 Amazon EMR 的实例添加 EBS 卷有何好处？\n", "origin_answer": "在以下场景中，您可以通过向实例添加 EBS 卷来获得好处：\n\n您的处理要求如下：您需要当前某个实例提供的大量 HDFS（或本地）存储。借助 EBS 卷方面的支持，您将能够对与某个实例提供的计算容量相关的实例上的存储容量进行自定义。优化实例上的存储可帮助您节约成本。\n您正在运行较旧的实例系列（如 M1 和 M2 系列），希望迁移到最新一代的实例系列，但受到新一代实例类型的每个节点提供的存储的限制。现在，您可以轻松使用任何新一代实例类型，并添加 EBS 卷以优化存储。内部基准表明，您可以通过从较旧的实例系列（M1 或 M2）迁移到新一代实例系列（M4、C4 和 R3）来实现成本节约并提升性能。Amazon EMR 团队建议您运行应用程序以得出正确的结论。\n您希望使用或迁移到仅限 EBS 的新一代 M4 和 C4 系列。", "generate_question": "除了存储容量，还有其他因素需要考虑在添加 EBS 卷时？", "generate_answer": "在添加 EBS 卷时，除了存储容量外，还需要考虑其他因素，如成本、性能需求和数据可靠性。根据实际情况综合考虑这些因素，选择合适的 EBS 卷配置。"}
{"origin_question": "\n是否可以在群集终止后保留 EBS 卷上的数据？\n", "origin_answer": "目前，Amazon EMR 将在群集终止后删除卷。如果您希望在群集生命周期外保留数据，不妨考虑将 Amazon S3 作为数据存储使用。\n", "generate_question": "Amazon EMR 是否会自动删除群集终止后的卷？", "generate_answer": "是的，Amazon EMR 在群集终止后会自动删除卷。"}
{"origin_question": "\n是否可以在群集终止后保留 EBS 卷上的数据？\n", "origin_answer": "目前，Amazon EMR 将在群集终止后删除卷。如果您希望在群集生命周期外保留数据，不妨考虑将 Amazon S3 作为数据存储使用。\n", "generate_question": "如果我希望在群集终止后保留数据，应该如何处理？", "generate_answer": "如果您希望在群集终止后保留数据，可以考虑将数据存储在 Amazon S3 上。"}
{"origin_question": "\n是否可以在群集终止后保留 EBS 卷上的数据？\n", "origin_answer": "目前，Amazon EMR 将在群集终止后删除卷。如果您希望在群集生命周期外保留数据，不妨考虑将 Amazon S3 作为数据存储使用。\n", "generate_question": "除了 Amazon S3，还有其他可以用来保留数据的选项吗？", "generate_answer": "目前，Amazon EMR 只支持将数据存储在 Amazon S3 上来保留数据。"}
{"origin_question": "\n我可以向实例附加哪些类型的 EBS 卷？\n", "origin_answer": "Amazon EMR 允许您使用不同的 EBS 卷类型：通用型 SSD (GP2)、磁性和预置 IOPS (SSD)。\n", "generate_question": "Amazon EMR允许使用哪些类型的 EBS 卷？", "generate_answer": "Amazon EMR允许使用通用型 SSD (GP2)、磁性和预置 IOPS (SSD)这三种类型的 EBS 卷。"}
{"origin_question": "\n我可以向实例附加哪些类型的 EBS 卷？\n", "origin_answer": "Amazon EMR 允许您使用不同的 EBS 卷类型：通用型 SSD (GP2)、磁性和预置 IOPS (SSD)。\n", "generate_question": "亚马逊云科技的 EBS 卷有哪些类型？", "generate_answer": "亚马逊云科技的 EBS 卷有通用型 SSD (GP2)、磁性和预置 IOPS (SSD)这三种类型。"}
{"origin_question": "\n终止群集后，EBS 卷会发生什么？\n", "origin_answer": "Amazon EMR 将在 EMR 群集终止后删除卷。\n", "generate_question": "终止群集后，除了删除卷，Amazon EMR 还会执行哪些操作？", "generate_answer": "终止群集后，Amazon EMR 还会删除群集中的所有 EC2 实例，并释放相关的资源。"}
{"origin_question": "\n终止群集后，EBS 卷会发生什么？\n", "origin_answer": "Amazon EMR 将在 EMR 群集终止后删除卷。\n", "generate_question": "终止群集后，是否可以恢复已删除的卷？", "generate_answer": "终止群集后，已删除的卷无法恢复，因此在终止群集之前需要备份重要的数据。"}
{"origin_question": "\n是否可以将 EBS 与已经具有实例存储的实例结合使用？\n", "origin_answer": "可以，您可以向具有实例存储的实例添加 EBS 卷。\n", "generate_question": "什么是 EBS？", "generate_answer": "EBS 是亚马逊云科技提供的一种持久性块存储服务，可以与亚马逊云上的实例一起使用。"}
{"origin_question": "\n是否可以将 EBS 与已经具有实例存储的实例结合使用？\n", "origin_answer": "可以，您可以向具有实例存储的实例添加 EBS 卷。\n", "generate_question": "EBS 与实例存储有什么区别？", "generate_answer": "EBS 是一种持久性块存储服务，数据可以在实例之间移动，而实例存储是直接附加在实例上的临时存储，数据在实例终止时会丢失。"}
{"origin_question": "\n是否可以向正在运行的集群附加 EBS 卷？\n", "origin_answer": "不可以，当前您只能在启动群集时添加 EBS 卷。\n", "generate_question": "亚马逊云科技的集群是否支持在运行时添加EBS卷？", "generate_answer": "不支持，在启动集群时才能添加EBS卷。"}
{"origin_question": "\n是否可以向正在运行的集群附加 EBS 卷？\n", "origin_answer": "不可以，当前您只能在启动群集时添加 EBS 卷。\n", "generate_question": "亚马逊云科技的集群是否支持动态调整EBS卷的大小？", "generate_answer": "无法确定，反引号中的信息没有提到集群是否支持动态调整EBS卷的大小。"}
{"origin_question": "\n是否可以拍摄群集中的卷的快照？\n", "origin_answer": "EBS API 允许您拍摄群集的快照。但是，当前 Amazon EMR 不允许您从快照进行恢复。\n", "generate_question": "亚马逊云科技的EBS API是否允许拍摄群集中卷的快照？", "generate_answer": "是的，EBS API 允许您拍摄群集的快照。"}
{"origin_question": "\n是否可以拍摄群集中的卷的快照？\n", "origin_answer": "EBS API 允许您拍摄群集的快照。但是，当前 Amazon EMR 不允许您从快照进行恢复。\n", "generate_question": "亚马逊云科技的Amazon EMR是否允许从快照进行恢复？", "generate_answer": "不，当前 Amazon EMR 不允许您从快照进行恢复。"}
{"origin_question": "\n是否可以使用加密的 EBS 卷？\n", "origin_answer": "您可以使用 AWS KMS 作为密钥提供程序来加密 EBS 根设备和存储卷。有关更多信息，请参阅本地磁盘加密。", "generate_question": "如何使用加密的 EBS 卷？", "generate_answer": "您可以使用 AWS KMS 作为密钥提供程序来加密 EBS 根设备和存储卷。有关更多信息，请参阅本地磁盘加密。"}
{"origin_question": "\n是否可以使用加密的 EBS 卷？\n", "origin_answer": "您可以使用 AWS KMS 作为密钥提供程序来加密 EBS 根设备和存储卷。有关更多信息，请参阅本地磁盘加密。", "generate_question": "什么是 AWS KMS？", "generate_answer": "AWS KMS 是亚马逊云科技提供的一种密钥管理服务，可以用于加密和解密数据，以及生成和管理加密密钥。在使用加密的 EBS 卷时，可以使用 AWS KMS 作为密钥提供程序来加密和解密数据。"}
{"origin_question": "\n如果我从正在运行的集群删除附加卷，会发生什么？\n", "origin_answer": "如果从正在运行的群集删除附加卷，系统会将其作为节点故障进行处理。Amazon EMR 会将节点和 EBS 卷各替换为相同的节点和 EBS 卷。\n\nEMR 工作负载\nHive | Hudi | Impala | Pig | HBase\n", "generate_question": "从正在运行的集群删除附加卷会导致什么结果？", "generate_answer": "如果从正在运行的群集删除附加卷，系统会将其视为节点故障，并将节点和 EBS 卷替换为相同的节点和 EBS 卷。"}
{"origin_question": "\n如果我从正在运行的集群删除附加卷，会发生什么？\n", "origin_answer": "如果从正在运行的群集删除附加卷，系统会将其作为节点故障进行处理。Amazon EMR 会将节点和 EBS 卷各替换为相同的节点和 EBS 卷。\n\nEMR 工作负载\nHive | Hudi | Impala | Pig | HBase\n", "generate_question": "亚马逊云科技的EMR工作负载包括哪些组件？", "generate_answer": "亚马逊云科技的EMR工作负载包括Hive、Hudi、Impala、Pig和HBase。"}
{"origin_question": "\n如果我从正在运行的集群删除附加卷，会发生什么？\n", "origin_answer": "如果从正在运行的群集删除附加卷，系统会将其作为节点故障进行处理。Amazon EMR 会将节点和 EBS 卷各替换为相同的节点和 EBS 卷。\n\nEMR 工作负载\nHive | Hudi | Impala | Pig | HBase\n", "generate_question": "附加卷在亚马逊云科技的EMR集群中有什么作用？", "generate_answer": "附加卷在亚马逊云科技的EMR集群中用于存储数据和配置信息，可以在运行时动态地添加或删除。删除附加卷会被视为节点故障，并进行相应的替换。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "Apache Spark是用于什么样的工作负载的分布式处理系统？", "generate_answer": "Apache Spark是用于大数据工作负载的分布式处理系统。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "Apache Spark使用什么样的查询执行方式？", "generate_answer": "Apache Spark使用内存中缓存和优化的查询执行方式。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "Apache Spark可以针对什么样规模的数据进行快速分析查询？", "generate_answer": "Apache Spark可以针对任何规模的数据进行快速分析查询。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "为什么Amazon EMR是部署Apache Spark的最佳位置？", "generate_answer": "Amazon EMR是部署Apache Spark的最佳位置，因为它具备商用Spark分配的集成和测试严谨性，同时也具备云的规模、简单性和成本效益。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "在Amazon EMR上部署Apache Spark集群需要多长时间？", "generate_answer": "在Amazon EMR上部署Apache Spark集群只需要几分钟的时间。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "Amazon EMR具有适用于Apache Spark的什么运行时环境？", "generate_answer": "Amazon EMR具有适用于Apache Spark的Amazon EMR运行时环境，这是一种针对Apache Spark进行性能优化的运行时环境。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "使用适用于Apache Spark的Amazon EMR运行时相比没有EMR运行时的集群，速度快多少倍？", "generate_answer": "使用适用于Apache Spark的Amazon EMR运行时的集群速度比没有EMR运行时的集群快3倍以上。"}
{"origin_question": "\n什么是 Apache Spark？\n", "origin_answer": "Apache SparkTM 是一款用于大数据工作负载的分布式开源处理系统。它使用内存中缓存和优化的查询执行方式，可针对任何规模的数据进行快速分析查询。Amazon EMR 是在云中部署 Apache Spark 的最佳位置，因为它既具备商用 Spark 分配的集成和测试严谨性，又兼有云的规模、简单性和成本效益。它让您可以在几分钟内启动 Spark 集群，而无需执行节点预置、集群设置、Spark 配置或集群优化。EMR 具有适用于 Apache Spark 的 Amazon EMR 运行时，这是一种针对 Apache Spark 进行性能优化的运行时环境，默认情况下在 Amazon EMR 集群上处于活动状态。适用于 Apache Spark 的 Amazon EMR 运行时的速度可比没有 EMR 运行时的集群快 3 倍以上，并且与标准 Apache Spark 具有 100% 的 API 兼容性。详细了解 Spark 和 Amazon EMR 上的 Spark。\n", "generate_question": "适用于Apache Spark的Amazon EMR运行时与标准Apache Spark具有什么样的API兼容性？", "generate_answer": "适用于Apache Spark的Amazon EMR运行时与标准Apache Spark具有100%的API兼容性。"}
{"origin_question": "\n什么是 Presto？\n", "origin_answer": "Presto 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 Presto 和 Amazon EMR 上的 Presto。\n\n使用 Hive", "generate_question": "Presto 是用于什么目的的？", "generate_answer": "Presto 是用于针对任何规模的数据进行快速分析查询的开源分布式 SQL 查询引擎。"}
{"origin_question": "\n什么是 Presto？\n", "origin_answer": "Presto 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 Presto 和 Amazon EMR 上的 Presto。\n\n使用 Hive", "generate_question": "如何在 Amazon EMR 上启动 Presto 集群？", "generate_answer": "在 Amazon EMR 上，您可以在几分钟内启动 Presto 集群，无需执行节点预置、集群设置、Presto 配置或集群优化。"}
{"origin_question": "\n什么是 Presto？\n", "origin_answer": "Presto 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 Presto 和 Amazon EMR 上的 Presto。\n\n使用 Hive", "generate_question": "Presto 有哪两个社区项目？", "generate_answer": "Presto 拥有两个社区项目，分别是 PrestoDB 和 PrestoSQL。"}
{"origin_question": "\n什么是 Presto？\n", "origin_answer": "Presto 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 Presto 和 Amazon EMR 上的 Presto。\n\n使用 Hive", "generate_question": "Amazon EMR 是否支持 Presto 的两个社区项目？", "generate_answer": "是的，Amazon EMR 同时支持 Presto 的两个社区项目，即 PrestoDB 和 PrestoSQL。"}
{"origin_question": "\n什么是 Presto？\n", "origin_answer": "Presto 是一种开源的分布式 SQL 查询引擎，它从零开始设计，用于针对任何规模的数据进行快速分析查询。使用 Amazon EMR，您可以在几分钟内启动 Presto 集群，而无需执行节点预置、集群设置、Presto 配置或集群优化。EMR 让您可以在短短几分钟内预置一个、上百个或成千上万个计算实例。Presto 拥有两个社区项目 – PrestoDB 和 PrestoSQL。Amazon EMR 同时支持这两个项目。详细了解 Presto 和 Amazon EMR 上的 Presto。\n\n使用 Hive", "generate_question": "Amazon EMR 可以预置多少个计算实例？", "generate_answer": "Amazon EMR 可以预置一个、上百个或成千上万个计算实例，具体数量根据需求而定。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "Apache Hive是什么？", "generate_answer": "Apache Hive是一种在Hadoop顶部运行的开源数据仓库和分析软件包。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "Hive QL是什么？", "generate_answer": "Hive QL是Hive的基于SQL的查询语言，允许用户构建、汇总和查询存储在Amazon S3中的数据源。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "Hive QL相比标准SQL有什么特点？", "generate_answer": "Hive QL的功能超出标准SQL，支持一流的map/reduce函数和复杂的由用户定义的可扩展数据类型，如Json和Thrift。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "Hive可以处理哪些类型的数据源？", "generate_answer": "Hive可以处理复杂的甚至非结构化的数据源，如文本文档和日志文件。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "Hive允许用户执行哪些扩展操作？", "generate_answer": "Hive允许用户通过以Java编写和通过Amazon S3中的存储部署的用户自定义函数执行扩展操作。"}
{"origin_question": "\n什么是 Apache Hive？\n", "origin_answer": "Hive 是在 Hadoop 顶部运行的一种开源数据仓库和分析软件包。Hive 由基于 SQL 的语言 Hive QL 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。Hive QL 的功能超出标准 SQL，支持一流的 map/reduce 函数和 Json 与 Thrift 等复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Hive 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。您可以在此处了解有关 Apache Hive 的更多信息。\n", "generate_question": "如何获取更多关于Apache Hive的信息？", "generate_answer": "您可以在相关的资源中了解更多关于Apache Hive的信息。"}
{"origin_question": "\n我用 Amazon EMR 中运行的 Hive 可以做什么？\n", "origin_answer": "当 Pig 与 Amazon EMR 搭配使用时，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Hive 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "什么是 Amazon EMR？", "generate_answer": "Amazon EMR 是亚马逊云科技提供的一项云计算服务，用于在云中处理和分析大规模数据集。"}
{"origin_question": "\n我用 Amazon EMR 中运行的 Hive 可以做什么？\n", "origin_answer": "当 Pig 与 Amazon EMR 搭配使用时，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Hive 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "Amazon EMR 中的 Hive 是什么？", "generate_answer": "Hive 是 Amazon EMR 中的一种数据仓库工具，它允许用户使用 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。"}
{"origin_question": "\n我用 Amazon EMR 中运行的 Hive 可以做什么？\n", "origin_answer": "当 Pig 与 Amazon EMR 搭配使用时，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Hive 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "在 Amazon EMR 中使用 Hive 可以执行哪些任务？", "generate_answer": "在 Amazon EMR 中使用 Hive，可以执行各种任务，包括数据分析、监控和业务智能任务等。"}
{"origin_question": "\n我用 Amazon EMR 中运行的 Hive 可以做什么？\n", "origin_answer": "当 Pig 与 Amazon EMR 搭配使用时，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Hive 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "为什么要将 Hive 应用程序转换为可靠的数据仓库？", "generate_answer": "将 Hive 应用程序转换为可靠的数据仓库可以确保数据处理任务的可靠性和稳定性，同时方便进行数据分析、监控和业务智能任务等操作。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 与传统的 RDBMS 系统有何不同？", "generate_answer": "Hive 与传统的 RDBMS 系统在数据处理和查询方面有一些不同之处。传统 RDBMS 系统提供事务语义和 ACID 属性，支持检索和缓存表，可以快速更新少量数据，并强制执行参考完整性限制。而 Hive 则使用 MapReduce 执行查询，针对在机器群集中运行时执行全面的表扫描进行了优化，适用于处理超大量的数据。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 支持哪些查询语言？", "generate_answer": "Hive 支持类似于 SQL 的查询语言，称为 HiveQL。HiveQL 允许用户使用类似于 SQL 的语法来查询和操作数据。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 适用于哪些场景？", "generate_answer": "Hive 适用于脱机报告、转换和分析大型数据集的场景。例如，对大型网站或网站集合执行点击流分析时，可以使用 Hive 进行数据处理和查询。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 是否支持事务处理？", "generate_answer": "Hive 在较早的版本中不支持事务处理，但在较新的版本中引入了事务功能。用户可以使用 Hive 的事务功能来执行原子操作和保证数据的一致性。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 是否支持分区表？", "generate_answer": "是的，Hive 支持分区表。分区表允许用户将数据按照某个列的值进行分区，从而提高查询效率。当执行查询时，Hive 可以只扫描表的特定分区，而不需要扫描整个表。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 是否支持对复杂的用户定义数据类型执行操作？", "generate_answer": "传统的 RDBMS 系统不支持对复杂的用户定义数据类型执行操作，而 Hive 支持对复杂的用户定义数据类型执行操作。这使得 Hive 能够更灵活地处理不同类型的数据。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 是否支持在表中执行 map 和 reduce 函数？", "generate_answer": "传统的 RDBMS 系统不支持在表中执行 map 和 reduce 函数，而 Hive 支持在表中执行 map 和 reduce 函数。这使得 Hive 能够更好地处理大规模数据的计算和分析。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 如何与 Amazon S3 配合使用？", "generate_answer": "一种常见的做法是将数据从传统的 RDBMS 系统导出到 Amazon S3，然后使用运行 Hive 的 Amazon EMR 群集来执行脱机分析。Hive 可以直接从 Amazon S3 中读取数据，并进行查询和分析。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 在处理大型数据集时有哪些优势？", "generate_answer": "Hive 在处理大型数据集时具有优势。它使用 MapReduce 执行查询，针对在机器群集中运行时执行全面的表扫描进行了优化，能够处理超大量的数据。此外，Hive 还支持分区表和并行处理，提高了查询效率和处理能力。"}
{"origin_question": "\nHive 与传统的 RDBMS 系统有何不同？\n", "origin_answer": "传统 RDBMS 系统提供事务语义和 ACID 属性。它们还允许检索和缓存表，以便少量的数据也能很快被检索到。它们可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单一大型机器中运行，不支持在表中执行 map 和 reduce 函数，也不支持对复杂的由用户定义的数据类型执行操作。\n\n相比之下，Hive 可使用 MapReduce 执行 SQL 之类的查询。因此，它针对在机器群集中运行时执行全面的表扫描进行了优化，由此能够处理超大量的数据。Hive 提供分区表，如果执行的查询适合，它能够扫描表的分区，而不只是整个表。\n\n传统 RDMS 系统比较适合要求事务语义和参考完整性以及时常执行少量更新的情况。Hive 比较适合脱机报告、转换和分析大型数据集；例如，对大型网站或网站集合执行点击流分析。\n\n一种常见的做法是从 RDBMS 系统导出数据到 Amazon S3，从中可以使用运行 Hive 的 Amazon EMR 群集执行脱机分析。\n", "generate_question": "Hive 适用于哪些类型的数据分析？", "generate_answer": "Hive 适用于各种类型的数据分析，包括但不限于点击流分析、日志分析、数据挖掘和机器学习等。它的强大查询功能和对大规模数据的处理能力使得它成为处理和分析大型数据集的理想工具。"}
{"origin_question": "\n如何开始使用 Amazon EMR 中运行的 Hive？\n", "origin_answer": "要开始使用，您最好先查看此处的书面文档。\n", "generate_question": "如何开始使用 Amazon EMR 中运行的 Hive？", "generate_answer": "要开始使用 Amazon EMR 中运行的 Hive，您最好先查看此处的书面文档。这些文档将提供关于如何设置和配置 Amazon EMR 群集以及如何使用 Hive 进行数据分析的详细指导。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否支持高可用性的 Apache Hive 集群？", "generate_answer": "是的，Amazon EMR 支持高可用性的 Apache Hive 集群。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 如何实现 Apache Hive 集群的高可用性？", "generate_answer": "当主要主节点出现故障或关键进程崩溃时，Amazon EMR 会自动将故障转移到备用主节点，从而实现 Apache Hive 集群的高可用性。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否支持自动调整 Apache Hive 集群的大小？", "generate_answer": "是的，Amazon EMR 支持自动调整 Apache Hive 集群的大小。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 如何帮助优化 Apache Hive 集群的资源使用？", "generate_answer": "通过定义 EMR 托管扩展，您可以自动调整 Apache Hive 集群的大小，以实现最佳性能和资源利用率。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 托管扩展是如何工作的？", "generate_answer": "EMR 托管扩展会连续采样与集群上运行的工作负载相关的关键指标，并根据指定的最小和最大计算限制自动调整集群的大小，以实现最佳性能和资源利用率。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 6.0.0 增加了对什么的支持？", "generate_answer": "Amazon EMR 6.0.0 增加了对 Hive LLAP 的支持。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "相比于 EMR 5.29，EMR 6.0.0 对 Hive 的性能有多少提升？", "generate_answer": "EMR 6.0.0 相比于 EMR 5.29 提供平均 2 倍的性能提升。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如何在 Amazon EMR 上使用 Hive 结合 S3 Select 来提高性能？", "generate_answer": "可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用，S3 Select 允许应用程序仅从对象检索数据子集，从而减少了 Amazon EMR 与 Amazon S3 之间传输的数据量，提高了性能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 默认使用哪个引擎来支持复杂的 Apache Hive 查询？", "generate_answer": "Amazon EMR 默认使用 Apache Tez 引擎来支持复杂的 Apache Hive 查询。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Apache Tez 相比 Apache MapReduce 有什么优势？", "generate_answer": "Apache Tez 比 Apache MapReduce 更快，因为它将一个复杂的 Apache Hive 查询分解成一个作业，在同一作业中运行，从而提高了查询速度。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否支持将元存储保留在本地或外部化？", "generate_answer": "是的，Amazon EMR 支持将元存储保留在本地或外部化。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 与哪些服务进行了元存储的集成？", "generate_answer": "Amazon EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成，可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "在以前的版本中，导入分区的表需要进行什么操作？", "generate_answer": "在以前的版本中，导入分区的表需要单独更改表中每个独立分区的表语句。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否提供了简化导入分区表的功能？", "generate_answer": "是的，Amazon EMR 提供了适用于 Hive 语言的新语句类型：“alter table recover partitions”，可以轻松地将表并发导入多个群集，而不必保留共享的元数据存储。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "在向 Amazon S3 中的表写入数据时，Amazon EMR 如何提高性能？", "generate_answer": "当向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将直接写入 Amazon S3，而不使用临时文件，从而大大提高了性能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如果表位于 Amazon S3，是否可以在相同语句内对同一表进行读取和写入？", "generate_answer": "如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如果要更新 Amazon S3 中的表，Amazon EMR 会进行什么操作？", "generate_answer": "如果要更新 Amazon S3 中的表，Amazon EMR 会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 中安装的 Hive 版本是否允许访问 Amazon S3 中的资源？", "generate_answer": "是的，Amazon EMR 中安装的 Hive 版本允许直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如何在 Hive 脚本中引用 Amazon S3 中的其他库的脚本？", "generate_answer": "可以使用类似于 \"add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar\" 的语句来引用 Amazon S3 中其他库的脚本。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否支持在复杂的 Apache Hive 查询中实现快速性能？", "generate_answer": "是的，Amazon EMR 支持在复杂的 Apache Hive 查询中实现快速性能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 中默认使用的是哪个引擎来支持复杂的 Apache Hive 查询？", "generate_answer": "Amazon EMR 默认使用 Apache Tez 引擎来支持复杂的 Apache Hive 查询。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Apache Tez 相比 Apache MapReduce 有什么优势？", "generate_answer": "Apache Tez 比 Apache MapReduce 更快，因为它将一个复杂的 Apache Hive 查询分解成一个作业，在同一作业中运行，从而提高了查询速度。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否支持将元存储保留在本地或外部化？", "generate_answer": "是的，Amazon EMR 支持将元存储保留在本地或外部化。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 与哪些服务进行了元存储的集成？", "generate_answer": "Amazon EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成，可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "在以前的版本中，导入分区的表需要进行什么操作？", "generate_answer": "在以前的版本中，导入分区的表需要单独更改表中每个独立分区的表语句。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 是否提供了简化导入分区表的功能？", "generate_answer": "是的，Amazon EMR 提供了适用于 Hive 语言的新语句类型：“alter table recover partitions”，可以轻松地将表并发导入多个群集，而不必保留共享的元数据存储。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "在向 Amazon S3 中的表写入数据时，Amazon EMR 如何提高性能？", "generate_answer": "当向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将直接写入 Amazon S3，而不使用临时文件，从而大大提高了性能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如果表位于 Amazon S3，是否可以在相同语句内对同一表进行读取和写入？", "generate_answer": "如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "如果要更新 Amazon S3 中的表，Amazon EMR 会进行什么操作？", "generate_answer": "如果要更新 Amazon S3 中的表，Amazon EMR 会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。"}
{"origin_question": "\n特定于 Amazon EMR 的 Hive 是否有新功能？\n", "origin_answer": "可以。有关更多详情，请参阅我们的文档：\n\n您可以启动一个带有多个主节点的 EMR 集群，以支持 Apache Hive 的高可用性。如果主要主节点出现故障或者 Resource Manager 或 Name Node 等关键进程崩溃，Amazon EMR 会自动将故障转移到备用主节点。这意味着您可以在 EMR 集群上运行 Apache Hive 而不会中断。\nAmazon EMR 允许您为 Apache Hive 集群定义 EMR 托管扩展，以帮助您优化资源使用。借助 EMR 托管扩展，您可以自动调整集群大小，以尽可能低的成本获得最佳性能。通过 EMR 托管扩展，可以为集群指定最小和最大计算限制，Amazon EMR 会自动调整其大小，以实现最佳性能和资源利用率。EMR 托管扩展针对与集群上运行的工作负载相关的关键指标连续进行采样。\nAmazon EMR 6.0.0 增加了对 Hive LLAP 的支持，相比 EMR 5.29 提供平均 2 倍的性能提升。您可以单击此处了解更多信息。\n现在可以将 S3 Select 与 Amazon EMR 上的 Hive 结合使用来提高性能。S3 Select 允许应用程序仅从对象检索数据子集，这样可减少 Amazon EMR 与 Amazon S3 之间传输的数据量。\nAmazon EMR 还支持在复杂的 Apache Hive 查询中实现快速性能。EMR 默认使用 Apache Tez，它比 Apache MapReduce 快得多。Apache MapReduce 使用多个阶段，所以一个复杂的 Apache Hive 查询会被分解成四到五个作业。Apache Tez 专为更复杂的查询而设计，因此同一作业在 Apache Tez 上将在一个作业中运行，从而使其速度比 Apache MapReduce 快得多。\n使用 Amazon EMR，您可以选择将元存储保留在本地或将其外部化。EMR 提供与 AWS Glue Data Catalog、Amazon Aurora、Amazon RDS 和 AWS Lake Formation 的集成。Amazon EMR 可以直接从 Glue 或 Lake Formation 中提取信息来填充元存储。\n您可以自动从 Amazon S3 加载表分区。以前，要导入分区的表，您需要单独更改表中每个独立分区的表语句。现在，Amazon EMR 包含适用于 Hive 语言的新语句类型：“alter table recover partitions”。 该语句让您能够轻松地将表并发导入多个群集，而不必保留共享的元数据存储。使用此功能，可从外部进程保存数据的表（例如日志文件）进行读取。\n您可以直接向 Amazon S3 写入数据。向 Amazon S3 中的表写入数据时，Amazon EMR 中安装的 Hive 版本将不使用临时文件，而直接写入 Amazon S3。这样可大大提高性能，但从 Hive 角度意味着 HDFS 和 S3 的操作方式不同。如果表位于 Amazon S3，则无法在相同语句内对同一表进行读取和写入。如果要更新 S3 中的表，则会在集群的本地 HDFS 文件系统中创建一个临时表，将结果写入该表，然后将它们复制到 Amazon S3。\n您可以访问 Amazon S3 中的资源。Amazon EMR 中安装的 Hive 版本允许您直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本（例如，add jar s3://elasticmapreduce/samples/hive-ads/libs/jsonserde.jar）。\n", "generate_question": "Amazon EMR 中安装的 Hive 版本是否允许访问 Amazon S3 中的资源？", "generate_answer": "是的，Amazon EMR 中安装的 Hive 版本允许直接从 Hive 脚本内引用自定义 map 和 reduce 操作或 Amazon S3 中其他库的脚本。\n\nQuestion"}
{"origin_question": "\n支持哪些类型的 Hive 群集？\n", "origin_answer": "Hive 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Hive 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Hive 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "Hive 支持哪两类群集？", "generate_answer": "Hive 支持交互式和批处理两类群集。"}
{"origin_question": "\n支持哪些类型的 Hive 群集？\n", "origin_answer": "Hive 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Hive 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Hive 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "在交互式模式下，客户可以在哪里启动群集和运行 Hive 脚本？", "generate_answer": "在交互式模式下，客户可以直接在主节点上启动群集和运行 Hive 脚本。"}
{"origin_question": "\n支持哪些类型的 Hive 群集？\n", "origin_answer": "Hive 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Hive 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Hive 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "交互式模式通常用于执行什么样的任务？", "generate_answer": "交互式模式通常用于执行特别数据分析和应用程序开发任务。"}
{"origin_question": "\n支持哪些类型的 Hive 群集？\n", "origin_answer": "Hive 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Hive 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Hive 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "在批处理模式下，Hive 脚本存储在哪里？", "generate_answer": "在批处理模式下，Hive 脚本存储在 Amazon S3 中。"}
{"origin_question": "\n如何启动 Hive 群集？\n", "origin_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。请参阅发布指南中的 Hive 部分，了解有关启动 Hive 群集的更多详细信息。\n", "generate_question": "Hive 群集可以从哪些渠道启动？", "generate_answer": "批处理和交互式群集都可以从 AWS 管理控制台、EMR 命令行客户端或 API 启动。"}
{"origin_question": "\n如何启动 Hive 群集？\n", "origin_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。请参阅发布指南中的 Hive 部分，了解有关启动 Hive 群集的更多详细信息。\n", "generate_question": "有哪些方式可以启动 Hive 群集？", "generate_answer": "可以通过 AWS 管理控制台、EMR 命令行客户端或 API 来启动 Hive 群集。"}
{"origin_question": "\n如何启动 Hive 群集？\n", "origin_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。请参阅发布指南中的 Hive 部分，了解有关启动 Hive 群集的更多详细信息。\n", "generate_question": "如何获取有关启动 Hive 群集的更多详细信息？", "generate_answer": "可以参阅发布指南中的 Hive 部分，了解有关启动 Hive 群集的更多详细信息。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "Hive和PIG分别适用于哪些用户？", "generate_answer": "Hive适用于已熟悉SQL和关系数据库的用户，而PIG适用于熟悉脚本编程和数据流处理的用户。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "Hive和PIG都支持哪些复杂数据类型？", "generate_answer": "Hive和PIG都支持在大型数据集中操作的复杂数据类型。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "Hive和PIG都具备哪些查询计划优化功能？", "generate_answer": "Hive和PIG都具备查询计划优化功能，但PIG能在整个脚本范围内进行优化，而Hive查询仅在语句级别进行优化。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "Hive的分区表有什么作用？", "generate_answer": "Hive的分区表使得Amazon EMR群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "在选择使用Hive还是PIG时，应该考虑哪些因素？", "generate_answer": "在选择使用Hive还是PIG时，应该考虑应用程序域的精确要求以及执行人员和这些写入查询的首选项。"}
{"origin_question": "\n何时应使用 Hive与 PIG？\n", "origin_answer": "Hive 和 PIG 都提供高水平的数据处理语言，支持在大型数据集中操作的复杂数据类型。Hive 语言是 SQL 的变体，更适合供已熟悉 SQL 和关系数据库的用户访问。Hive 支持分区的表，它们使 Amazon EMR 群集只提取与执行的查询相关的表分区，而不会执行全面的表扫描。PIG 和 Hive 都有查询计划优化功能。PIG 能在整个脚本范围内进行优化，而 Hive 查询仅在语句级别进行优化。\n\n最终，使用 Hive 还是 PIG 则取决于应用程序域的精确要求及执行人员和这些写入查询的首选项。\n", "generate_question": "Hive和PIG分别是什么类型的数据处理语言？", "generate_answer": "Hive是SQL的变体，更适合供已熟悉SQL和关系数据库的用户访问；而PIG是一种脚本语言，适用于熟悉脚本编程和数据流处理的用户。"}
{"origin_question": "\nAmazon EMR 支持哪些版本的 Hive？\n", "origin_answer": "有关最新版本的 Amazon EMR 上的 Hive，请参阅文档。", "generate_question": "Amazon EMR 支持哪些版本的 Hive？", "generate_answer": "Amazon EMR支持最新版本的Hive，具体的版本信息可以在相关文档中查看。"}
{"origin_question": "\n是否可以从两个集群并发写入表？\n", "origin_answer": "Hive 不支持并发写入表。应避免并发写入同一个表，或在向表写入时从中进行读取。Hive 在同时读取和写入或同时写入时会出现不确定性的行为。\n", "generate_question": "Hive是否支持并发写入表？", "generate_answer": "不支持，并发写入同一个表或在向表写入时从中进行读取会导致不确定性的行为。"}
{"origin_question": "\n是否可以从两个集群并发写入表？\n", "origin_answer": "Hive 不支持并发写入表。应避免并发写入同一个表，或在向表写入时从中进行读取。Hive 在同时读取和写入或同时写入时会出现不确定性的行为。\n", "generate_question": "为什么要避免在Hive中同时读取和写入表？", "generate_answer": "在Hive中同时读取和写入表会导致不确定性的行为，可能会出现数据错误或丢失的情况，因此应该避免这种操作。"}
{"origin_question": "\n是否可以在不同的群集之间共享数据？\n", "origin_answer": "是的。您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。对于要访问的每个外部资源，您需要执行 create table 语句。\n", "generate_question": "如何在 Hive 脚本中读取 Amazon S3 中的数据？", "generate_answer": "您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。"}
{"origin_question": "\n是否可以在不同的群集之间共享数据？\n", "origin_answer": "是的。您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。对于要访问的每个外部资源，您需要执行 create table 语句。\n", "generate_question": "在访问外部资源时，需要执行哪些语句？", "generate_answer": "对于要访问的每个外部资源，您需要执行 create table 语句。"}
{"origin_question": "\n是否可以在不同的群集之间共享数据？\n", "origin_answer": "是的。您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。对于要访问的每个外部资源，您需要执行 create table 语句。\n", "generate_question": "是否可以在不同的群集之间共享数据？", "generate_answer": "是的，您可以在 Hive 脚本内，通过在脚本顶部写入“create external table”语句，读取 Amazon S3 中的数据。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。\n", "generate_question": "为什么在处理普通的批处理工作负载时，运行一个大型群集可能更为有效？", "generate_answer": "运行一个大型群集可以更有效地处理普通的批处理工作负载，因为大型群集可以同时处理更多的任务，提高处理效率。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。\n", "generate_question": "为什么在执行随时间变化的特别查询或工作负载时，可以选择创建若干独立的群集？", "generate_answer": "在执行随时间变化的特别查询或工作负载时，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务，从而提高查询或工作负载的执行效率。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。\n", "generate_question": "如何同时使用大型群集和许多较小的群集？", "generate_answer": "Amazon EMR 提供独特的功能，使您能够同时使用大型群集和许多较小的群集。大型群集适用于处理普通的批处理工作负载，而许多较小的群集适用于执行随时间变化的特别查询或工作负载。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。\n", "generate_question": "如何优化资源使用率？", "generate_answer": "您可以使用 EMR 托管扩展来优化资源使用率。通过使用托管扩展，您可以根据需要动态调整群集的大小，以适应不同的任务需求，从而最大程度地利用资源。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。 您可以使用 EMR 托管扩展来优化资源使用率。\n", "generate_question": "在共享 Amazon S3 中存储的数据源的特定任务中，为什么创建独立的群集更合适？", "generate_answer": "创建独立的群集更合适是因为可以根据特定任务的需求来调整群集的配置，从而提高任务的执行效率。这样可以避免不同任务之间的干扰，使每个任务都能够充分利用资源。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "亚马逊云科技的脚本或 Jar 资源是否可以直接访问本地文件系统？", "generate_answer": "不可以，必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "有哪些工具可以用来上传脚本或 Jar 到 Amazon S3？", "generate_answer": "可以使用 s3cmd、jets3t 或 S3Organizer 等工具来上传脚本或 Jar 到 Amazon S3。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "除了 Amazon S3，还有其他地方可以上传脚本或 Jar 吗？", "generate_answer": "除了 Amazon S3，也可以将脚本或 Jar 上传到群集的主节点上进行引用。"}
{"origin_question": "\n是否可运行执行多个 Hive 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Hive 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。\n", "generate_question": "在亚马逊云科技中，是否可以运行执行多个 Hive 查询的持续性群集？", "generate_answer": "是的，可以在亚马逊云科技中运行执行多个 Hive 查询的持续性群集。"}
{"origin_question": "\n是否可运行执行多个 Hive 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Hive 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。\n", "generate_question": "在手动终止模式下运行群集会发生什么？", "generate_answer": "在手动终止模式下运行群集时，它们不会在各个 Hive 步骤中终止。"}
{"origin_question": "\n是否可运行执行多个 Hive 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Hive 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。\n", "generate_question": "为了降低数据丢失的风险，亚马逊云科技建议采取什么措施？", "generate_answer": "亚马逊云科技建议定期在 Amazon S3 中保存所有重要的数据，以降低数据丢失的风险。"}
{"origin_question": "\n是否可运行执行多个 Hive 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Hive 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。\n", "generate_question": "为了测试从主节点故障中恢复的过程，亚马逊云科技建议定期将工作传输到哪里？", "generate_answer": "亚马逊云科技建议定期将工作传输到新的群集，以便测试从主节点故障中恢复的过程。"}
{"origin_question": "\n多个用户是否可基于同一源数据执行 Hive 步骤？\n", "origin_answer": "可以。多个用户在不同群集中执行的 Hive 脚本可能包括 create external table 语句，以并发导入 Amazon S3 中驻留的源数据。\n", "generate_question": "Hive 步骤是否可以基于 Amazon S3 中的源数据进行并发导入？", "generate_answer": "是的，多个用户可以在不同群集中执行 Hive 脚本，并且这些脚本可以包括 create external table 语句，以并发导入 Amazon S3 中的源数据。"}
{"origin_question": "\n多个用户是否可基于同一源数据执行 Hive 步骤？\n", "origin_answer": "可以。多个用户在不同群集中执行的 Hive 脚本可能包括 create external table 语句，以并发导入 Amazon S3 中驻留的源数据。\n", "generate_question": "在执行 Hive 步骤时，是否可以在不同群集中使用相同的源数据？", "generate_answer": "是的，多个用户可以在不同群集中执行 Hive 脚本，并且这些脚本可以使用相同的源数据，例如 Amazon S3 中的数据。"}
{"origin_question": "\n多个用户是否可在同一群集中运行查询？\n", "origin_answer": "可以。在批处理模式下，步骤呈序列化状态。多个用户可以将 Hive 步骤添加到同一集群；但将按顺序执行步骤。在交互式模式下，若干用户可以登录到同一集群，并发执行 Hive 语句。\n", "generate_question": "在亚马逊云科技中，多个用户是否可以同时在同一群集中运行查询？", "generate_answer": "是的，多个用户可以在同一群集中同时运行查询。在批处理模式下，用户可以将Hive步骤添加到同一集群，并按照顺序执行这些步骤。在交互式模式下，多个用户可以登录到同一集群，并发执行Hive语句。"}
{"origin_question": "\n是否可以在多个 AWS 用户之间共享数据？\n", "origin_answer": "可以。可以使用此处介绍的标准 Amazon S3 共享机制来共享数据。\n", "generate_question": "如何在多个 AWS 用户之间共享数据？", "generate_answer": "可以使用标准 Amazon S3 共享机制来共享数据。"}
{"origin_question": "\n是否可以在多个 AWS 用户之间共享数据？\n", "origin_answer": "可以。可以使用此处介绍的标准 Amazon S3 共享机制来共享数据。\n", "generate_question": "亚马逊云科技的哪个服务可以用于在多个 AWS 用户之间共享数据？", "generate_answer": "标准 Amazon S3 共享机制可以用于在多个 AWS 用户之间共享数据。"}
{"origin_question": "\nHive 是否支持从 JDBC 进行访问？\n", "origin_answer": "是的。Hive 提供 JDBC 驱动器，可用来以编程方式执行 Hive 语句。要在群集中启动 JDBC 服务，您需要在 Amazon EMR 命令行客户端中传递可选参数。此外，还需要建立一个 SSH 隧道，因为安全组不允许外部连接。\n", "generate_question": "Hive 是否支持以编程方式执行 Hive 语句？", "generate_answer": "是的，Hive 提供 JDBC 驱动器，可以用来以编程方式执行 Hive 语句。"}
{"origin_question": "\nHive 是否支持从 JDBC 进行访问？\n", "origin_answer": "是的。Hive 提供 JDBC 驱动器，可用来以编程方式执行 Hive 语句。要在群集中启动 JDBC 服务，您需要在 Amazon EMR 命令行客户端中传递可选参数。此外，还需要建立一个 SSH 隧道，因为安全组不允许外部连接。\n", "generate_question": "在 Amazon EMR 中如何启动 JDBC 服务？", "generate_answer": "要在 Amazon EMR 中启动 JDBC 服务，您需要在 Amazon EMR 命令行客户端中传递可选参数。"}
{"origin_question": "\nHive 是否支持从 JDBC 进行访问？\n", "origin_answer": "是的。Hive 提供 JDBC 驱动器，可用来以编程方式执行 Hive 语句。要在群集中启动 JDBC 服务，您需要在 Amazon EMR 命令行客户端中传递可选参数。此外，还需要建立一个 SSH 隧道，因为安全组不允许外部连接。\n", "generate_question": "在使用 Hive 进行 JDBC 访问时，为什么需要建立一个 SSH 隧道？", "generate_answer": "在使用 Hive 进行 JDBC 访问时，需要建立一个 SSH 隧道，因为安全组不允许外部连接。"}
{"origin_question": "\n在 EMR AMI 中更新软件包的流程是什么？\n", "origin_answer": "首次启动时，适用于 EMR 的 Amazon Linux AMI 会连接到 Amazon Linux AMI yum 存储库，以安装安全更新。使用自定义 AMI 时，您可以禁用此功能。但出于安全考虑，我们不建议这样做。\n", "generate_question": "什么是 EMR AMI？", "generate_answer": "EMR AMI 是适用于 Amazon Elastic MapReduce（EMR）的 Amazon Machine Image（AMI），它包含了预装的软件和配置，用于快速启动和配置 EMR 集群。"}
{"origin_question": "\n在 EMR AMI 中更新软件包的流程是什么？\n", "origin_answer": "首次启动时，适用于 EMR 的 Amazon Linux AMI 会连接到 Amazon Linux AMI yum 存储库，以安装安全更新。使用自定义 AMI 时，您可以禁用此功能。但出于安全考虑，我们不建议这样做。\n", "generate_question": "为什么不建议禁用 Amazon Linux AMI 的安全更新？", "generate_answer": "禁用 Amazon Linux AMI 的安全更新会降低系统的安全性，因为安全更新通常包含了修复已知漏洞和强化系统安全的补丁。建议保持系统更新以确保安全性。"}
{"origin_question": "\n在 EMR AMI 中更新软件包的流程是什么？\n", "origin_answer": "首次启动时，适用于 EMR 的 Amazon Linux AMI 会连接到 Amazon Linux AMI yum 存储库，以安装安全更新。使用自定义 AMI 时，您可以禁用此功能。但出于安全考虑，我们不建议这样做。\n", "generate_question": "如何禁用 Amazon Linux AMI 的安全更新？", "generate_answer": "使用自定义 AMI 时，可以禁用 Amazon Linux AMI 的安全更新。具体的操作方法可能因使用的工具和平台而有所不同，您可以参考相关文档或咨询亚马逊云科技的支持团队获取详细的步骤和建议。"}
{"origin_question": "\n我是否可以在 EMR 群集中更新自己的软件包？\n", "origin_answer": "可以。您可以使用引导操作向群集中的软件包安装更新。\n", "generate_question": "如何在 EMR 群集中安装更新软件包？", "generate_answer": "您可以使用引导操作来安装更新软件包。"}
{"origin_question": "\n我是否可以在 EMR 群集中更新自己的软件包？\n", "origin_answer": "可以。您可以使用引导操作向群集中的软件包安装更新。\n", "generate_question": "EMR 群集是否支持自定义软件包的更新？", "generate_answer": "是的，您可以在 EMR 群集中更新自己的软件包。"}
{"origin_question": "\n是否可以使用 Hive 处理 DynamoDB 数据？\n", "origin_answer": "可以。只需根据您的 DynamoDB 表定义一个外部 Hive 表。然后，即可使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。有关更多信息，请访问我们的开发人员指南。\n使用 Hudi", "generate_question": "如何使用 Hive 处理 DynamoDB 数据？", "generate_answer": "只需根据 DynamoDB 表定义一个外部 Hive 表，然后可以使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。"}
{"origin_question": "\n是否可以使用 Hive 处理 DynamoDB 数据？\n", "origin_answer": "可以。只需根据您的 DynamoDB 表定义一个外部 Hive 表。然后，即可使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。有关更多信息，请访问我们的开发人员指南。\n使用 Hudi", "generate_question": "DynamoDB 数据可以通过哪些方式进行分析？", "generate_answer": "可以使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。"}
{"origin_question": "\n是否可以使用 Hive 处理 DynamoDB 数据？\n", "origin_answer": "可以。只需根据您的 DynamoDB 表定义一个外部 Hive 表。然后，即可使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。有关更多信息，请访问我们的开发人员指南。\n使用 Hudi", "generate_question": "在使用 Hive 处理 DynamoDB 数据时，是否需要将数据加载回 DynamoDB 或 Amazon S3？", "generate_answer": "是的，可以使用 Hive 来分析 DynamoDB 中存储的数据，并将结果加载回 DynamoDB 或在 Amazon S3 中缓存它们。"}
{"origin_question": "\n什么是 Apache Hudi？\n", "origin_answer": "Apache Hudi 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。\n", "generate_question": "Apache Hudi是用于什么目的的？", "generate_answer": "Apache Hudi是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。"}
{"origin_question": "\n什么是 Apache Hudi？\n", "origin_answer": "Apache Hudi 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。\n", "generate_question": "Apache Hudi可以在哪里管理记录级别的数据？", "generate_answer": "Apache Hudi可以在Amazon S3中管理记录级别的数据。"}
{"origin_question": "\n什么是 Apache Hudi？\n", "origin_answer": "Apache Hudi 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。\n", "generate_question": "Apache Hudi如何简化变更数据捕获和流式数据摄入操作？", "generate_answer": "Apache Hudi通过在Amazon S3中管理记录级别的数据，简化了变更数据捕获和流式数据摄入操作。"}
{"origin_question": "\n什么是 Apache Hudi？\n", "origin_answer": "Apache Hudi 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。\n", "generate_question": "Apache Hudi的数据集如何存储？", "generate_answer": "Apache Hudi管理的数据集将使用开放存储格式存储在S3中。"}
{"origin_question": "\n什么是 Apache Hudi？\n", "origin_answer": "Apache Hudi 是一种开源数据管理框架，用于简化增量数据处理和数据管道开发工作。借助 Apache Hudi，您可以在 Amazon S3 中管理记录级别的数据，从而简化变更数据捕获 (CDC) 和流式数据摄入操作，为处理需要记录级别更新和删除的数据隐私使用案例提供了框架。Apache Hudi 管理的数据集将使用开放存储格式存储在 S3 中，并且通过与 Presto、Apache Hive、Apache Spark 和 AWS Glue 数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。\n", "generate_question": "Apache Hudi可以与哪些工具进行集成，以便访问更新的数据？", "generate_answer": "Apache Hudi可以与Presto、Apache Hive、Apache Spark和AWS Glue数据目录集成，让您可以使用熟悉的工具几乎实时访问更新的数据。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi适用于哪些使用案例？", "generate_answer": "Apache Hudi适用于以下五种常见使用案例：遵守数据隐私法律、使用实时数据流并应用企业系统中的变更数据捕获日志、恢复延迟到达或不正确的数据、追踪数据集的变更并提供回滚变更的能力、简化S3上的文件管理。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi如何帮助遵守数据隐私法律？", "generate_answer": "Apache Hudi可以使用开源数据格式（如Apache Parquet和Apache Avro）对存储在S3中的数据执行记录级别的插入、更新和删除操作，从而帮助组织遵守数据隐私法律。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi如何处理实时数据流并应用变更数据捕获日志？", "generate_answer": "Apache Hudi简化了变更日志的应用过程，使用户能够近乎实时地访问数据，并将企业数据仓库（EDW）和运营数据存储（ODS）数据存储在Amazon S3中，以便SQL引擎（如Apache Hive和Presto）可以对其进行数据处理和分析。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi如何处理延迟到达或不正确的数据？", "generate_answer": "Apache Hudi允许将记录“更新插入”到现有数据集中，从而依靠框架基于数据集中的情况来插入或更新记录，以处理延迟到达或不正确的数据，并更新现有数据集以合并新的或更新的记录。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi如何追踪数据集的变更并提供回滚变更的能力？", "generate_answer": "利用Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使用户能够查找数据集的特定变更和“撤销”变更。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi如何简化S3上的文件管理？", "generate_answer": "利用Apache Hudi，可以管理S3上的数据文件，用户只需配置最佳文件大小来存储数据，Hudi将合并文件来创建有效大小的文件，从而简化S3上的文件管理。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Hudi数据集可以以何种方式进行增量写入？", "generate_answer": "Hudi数据集可以以增量方式提取，这意味着可以获得自指定时刻以后的全部（及仅）已更新和新行。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi支持哪些开源数据格式？", "generate_answer": "Apache Hudi支持开源数据格式，如Apache Parquet和Apache Avro。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么需要记录级别的数据管理？", "generate_answer": "记录级别的数据管理可以帮助组织遵守数据隐私法律、处理实时数据流并应用变更数据捕获日志、恢复延迟到达或不正确的数据、追踪数据集的变更并提供回滚变更的能力，以及简化S3上的文件管理。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么需要处理实时数据流并应用变更数据捕获日志？", "generate_answer": "处理实时数据流并应用变更数据捕获日志可以使用户近乎实时地访问数据，并将企业数据仓库（EDW）和运营数据存储（ODS）数据存储在Amazon S3中，以便进行数据处理和分析。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么需要处理延迟到达或不正确的数据？", "generate_answer": "处理延迟到达或不正确的数据可以对数据进行恢复，并更新现有数据集以合并新的或更新的记录，确保数据的准确性和完整性。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么需要追踪数据集的变更并提供回滚变更的能力？", "generate_answer": "追踪数据集的变更并提供回滚变更的能力可以帮助用户查找数据集的特定变更和“撤销”变更，以满足数据管理和数据恢复的需求。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么需要简化S3上的文件管理？", "generate_answer": "简化S3上的文件管理可以帮助用户管理数据文件，只需配置最佳文件大小来存储数据，Hudi将合并文件来创建有效大小的文件，提高数据管理的效率。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "为什么Hudi数据集可以以增量方式进行提取？", "generate_answer": "Hudi数据集可以以增量方式提取，这意味着可以获得自指定时刻以后的全部（及仅）已更新和新行，方便用户进行增量数据处理。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "什么是Apache Hudi？", "generate_answer": "Apache Hudi是一个开源的数据湖工具，用于在S3上进行记录级别的数据管理，支持插入、更新和删除操作，并提供实时数据流处理、数据恢复、变更追踪和回滚等功能。"}
{"origin_question": "\n何时应使用 Apache Hudi？\n", "origin_answer": "Apache Hudi 有助于您处理需要在 S3 上进行记录级别数据管理的使用案例。有五种常见使用案例可以从这些能力中获益：\n遵守数据隐私法律，这类法律要求组织删除用户数据或在用户选择更改其对于数据使用方式的首选项时更新用户首选项。Apache Hudi 可使您使用 Apache Parquet 和 Apache Avro 等开源数据格式对存储在 S3 中的数据执行记录级别插入、更新和删除操作。\n使用实时数据流并应用企业系统中的变更数据捕获日志。很多组织要求在 Amazon S3 中提供企业数据仓库 (EDW) 和运营数据存储 (ODS) 数据，以便 Apache Hive 和 Presto 等 SQL 引擎可以访问它们进行数据处理和分析。Apache Hudi 简化了变更日志的应用过程，使用户能够近乎实时地访问数据。\n恢复延迟到达或不正确的数据。延迟到达或不正确的数据需要对数据进行恢复，并需要更新现有数据集以合并新的或更新的记录。Apache Hudi 允许您将记录“更新插入”到现有数据集中，从而依靠框架基于它们存在于数据集中的情况来插入或更新记录。\n追踪数据集的变更并提供回滚变更的能力。利用 Apache Hudi，可以将数据集的每次变更作为提交内容进行追踪，并且可以轻松回滚变更，从而使您能够查找数据集的特定变更和“撤销”变更。\n简化 S3 上的文件管理。为确保数据文件的有效大小，客户必须构建自定义解决方案来监控和将很多小文件重新写入较少的大文件中。利用 Apache Hudi，可以管理 S3 上的数据文件，且用户只需配置最佳文件大小来存储器数据，Hudi 将合并文件来创建有效大小的文件。\n将增量写入目标 Hudi 数据集。Hudi 数据集能够以增量方式提取，这意味着您可以获得自指定时刻以后的全部（及仅）已更新和新行。", "generate_question": "Apache Hudi适用于哪些存储系统？", "generate_answer": "Apache Hudi适用于存储在S3上的数据，可以与Amazon S3进行集成，实现记录级别的数据管理和处理。"}
{"origin_question": "\n如何创建 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 创建 Apache Hudi 数据集。创建数据集像编写 Apache Spark DataFrame 一样简单。可以选择将 Apache Hudi 数据集的元数据存储在 AWS Glue Data Catalog 或 Hive 元存储中，以简化数据发现过程以及与 Apache Hive 和 Presto 集成。\n", "generate_question": "如何创建 Apache Hudi 数据集？", "generate_answer": "使用 Apache Spark 创建 Apache Hudi 数据集。"}
{"origin_question": "\n如何创建 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 创建 Apache Hudi 数据集。创建数据集像编写 Apache Spark DataFrame 一样简单。可以选择将 Apache Hudi 数据集的元数据存储在 AWS Glue Data Catalog 或 Hive 元存储中，以简化数据发现过程以及与 Apache Hive 和 Presto 集成。\n", "generate_question": "创建 Apache Hudi 数据集与创建 Apache Spark DataFrame 有何相似之处？", "generate_answer": "创建数据集像编写 Apache Spark DataFrame 一样简单。"}
{"origin_question": "\n如何创建 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 创建 Apache Hudi 数据集。创建数据集像编写 Apache Spark DataFrame 一样简单。可以选择将 Apache Hudi 数据集的元数据存储在 AWS Glue Data Catalog 或 Hive 元存储中，以简化数据发现过程以及与 Apache Hive 和 Presto 集成。\n", "generate_question": "可以将 Apache Hudi 数据集的元数据存储在哪些地方？", "generate_answer": "可以选择将 Apache Hudi 数据集的元数据存储在 AWS Glue Data Catalog 或 Hive 元存储中。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "Apache Hudi 可以选择哪种数据管理策略来优化数据集的访问模式？", "generate_answer": "Apache Hudi 可以选择 \"写入时复制\" 或 \"读取时合并\" 数据管理策略来优化数据集的访问模式。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "什么是 \"写入时复制\" 数据管理策略？", "generate_answer": "\"写入时复制\" 数据管理策略是 Apache Hudi 中一种用于优化读取密集型使用案例的数据管理策略。它使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "什么是 \"读取时合并\" 数据管理策略？", "generate_answer": "\"读取时合并\" 数据管理策略是 Apache Hudi 中一种用于优化写入密集型工作负载的数据管理策略。它使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "\"写入时复制\" 数据管理策略使用哪种存储格式来组织数据？", "generate_answer": "\"写入时复制\" 数据管理策略使用分列存储格式来组织数据。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "\"读取时合并\" 数据管理策略使用哪种存储格式来组织数据？", "generate_answer": "\"读取时合并\" 数据管理策略使用分栏式和行存储格式的组合来组织数据。"}
{"origin_question": "\nApache Hudi 如何管理数据集？\n", "origin_answer": "使用 Apache Hudi 创建数据集时，您可以选择数据集应针对哪种类型的数据访问模式进行优化。对于读取密集型使用案例，您可以选择“写入时复制”数据管理策略来优化数据集的频繁读取。此策略使用分列存储格式组织数据，并在写入更新时合并现有的数据和新的更新。对于写入密集型工作负载，Apache Hudi 使用“读取时合并”数据管理策略，该策略使用分栏式和行存储格式的组合来组织数据，其中更新以基于行的存储格式附加到文件，而在读取时执行合并以提供更新的结果。\n", "generate_question": "Apache Hudi 的数据管理策略如何优化数据集的访问模式？", "generate_answer": "Apache Hudi 的数据管理策略根据不同的使用案例选择不同的策略来优化数据集的访问模式。对于读取密集型使用案例，可以选择 \"写入时复制\" 数据管理策略，而对于写入密集型工作负载，可以选择 \"读取时合并\" 数据管理策略。这些策略使用不同的存储格式和合并方式来提供最佳的数据访问性能。"}
{"origin_question": "\n如何写入到 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 对 Apache Hudi 数据集进行更改。使用 Apache Spark 时，Apache Hudi 数据集通过 Spark DataSource API 运行，从而使您能够写入和读取数据。可以使用相同的 DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。您也可以使用 Hudi DeltaStreamer 实用程序。\n", "generate_question": "如何使用 Apache Spark 对 Apache Hudi 数据集进行更改？", "generate_answer": "使用 Apache Spark 时，Apache Hudi 数据集可以通过 Spark DataSource API 进行更改。您可以使用 DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。此外，您还可以使用 Hudi DeltaStreamer 实用程序来更改数据集。"}
{"origin_question": "\n如何写入到 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 对 Apache Hudi 数据集进行更改。使用 Apache Spark 时，Apache Hudi 数据集通过 Spark DataSource API 运行，从而使您能够写入和读取数据。可以使用相同的 DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。您也可以使用 Hudi DeltaStreamer 实用程序。\n", "generate_question": "Apache Hudi 数据集可以通过哪些方式进行写入？", "generate_answer": "Apache Hudi 数据集可以通过使用 Apache Spark 对其进行更改来进行写入。您可以使用 Spark DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。此外，您还可以使用 Hudi DeltaStreamer 实用程序来写入数据集。"}
{"origin_question": "\n如何写入到 Apache Hudi 数据集？\n", "origin_answer": "使用 Apache Spark 对 Apache Hudi 数据集进行更改。使用 Apache Spark 时，Apache Hudi 数据集通过 Spark DataSource API 运行，从而使您能够写入和读取数据。可以使用相同的 DataSource API 编写包含新添加的数据或对现有数据进行更新的 DataFrame。您也可以使用 Hudi DeltaStreamer 实用程序。\n", "generate_question": "除了使用 Apache Spark，还有其他方式可以写入 Apache Hudi 数据集吗？", "generate_answer": "是的，除了使用 Apache Spark 对 Apache Hudi 数据集进行更改外，您还可以使用 Hudi DeltaStreamer 实用程序来写入数据集。Hudi DeltaStreamer 是一个用于将数据写入 Hudi 数据集的实用程序，它可以从多个源读取数据，并将其写入 Hudi 数据集。"}
{"origin_question": "\n如何从 Apache Hudi 数据集中进行读取？\n", "origin_answer": "您可以使用 Apache Spark、Apache Hive、Presto、Amazon Redshift Spectrum 或 Amazon Athena 读取数据。当您创建数据集时，您可以选择在 AWS Glue Data Catalog 或 Hive 元存储中发布该数据集的元数据。如果您选择在元存储中发布元数据，您的数据集看起来就像一个普通的表格，您可以使用 Apache Hive 和 Presto 查询该表格。\n", "generate_question": "有哪些工具可以用来从 Apache Hudi 数据集中进行读取？", "generate_answer": "可以使用 Apache Spark、Apache Hive、Presto、Amazon Redshift Spectrum 或 Amazon Athena 读取数据。"}
{"origin_question": "\n如何从 Apache Hudi 数据集中进行读取？\n", "origin_answer": "您可以使用 Apache Spark、Apache Hive、Presto、Amazon Redshift Spectrum 或 Amazon Athena 读取数据。当您创建数据集时，您可以选择在 AWS Glue Data Catalog 或 Hive 元存储中发布该数据集的元数据。如果您选择在元存储中发布元数据，您的数据集看起来就像一个普通的表格，您可以使用 Apache Hive 和 Presto 查询该表格。\n", "generate_question": "在创建数据集时，可以选择在哪些地方发布元数据？", "generate_answer": "可以选择在 AWS Glue Data Catalog 或 Hive 元存储中发布数据集的元数据。"}
{"origin_question": "\n如何从 Apache Hudi 数据集中进行读取？\n", "origin_answer": "您可以使用 Apache Spark、Apache Hive、Presto、Amazon Redshift Spectrum 或 Amazon Athena 读取数据。当您创建数据集时，您可以选择在 AWS Glue Data Catalog 或 Hive 元存储中发布该数据集的元数据。如果您选择在元存储中发布元数据，您的数据集看起来就像一个普通的表格，您可以使用 Apache Hive 和 Presto 查询该表格。\n", "generate_question": "如果选择在元存储中发布元数据，可以使用哪些工具来查询该数据集？", "generate_answer": "可以使用 Apache Hive 和 Presto 查询该数据集。"}
{"origin_question": "\n我在使用 Apache Hudi 时应注意哪些注意事项或限制？\n", "origin_answer": "有关使用 Amazon EMR 上的 Apache Hudi 时要注意的注意事项和限制的完整列表，请参阅我们的 Amazon EMR 文档。\n", "generate_question": "在使用 Apache Hudi 时，我应该在哪里查找 Amazon EMR 上的相关文档？", "generate_answer": "你可以在 Amazon EMR 文档中找到有关在 Amazon EMR 上使用 Apache Hudi 时的注意事项和限制的详细信息。"}
{"origin_question": "\n我在使用 Apache Hudi 时应注意哪些注意事项或限制？\n", "origin_answer": "有关使用 Amazon EMR 上的 Apache Hudi 时要注意的注意事项和限制的完整列表，请参阅我们的 Amazon EMR 文档。\n", "generate_question": "Amazon EMR 上的 Apache Hudi 有哪些注意事项和限制？", "generate_answer": "有关在 Amazon EMR 上使用 Apache Hudi 时的注意事项和限制的完整列表，请参阅 Amazon EMR 文档。"}
{"origin_question": "\n如何用 Apache Hudi 处理我的现有数据？\n", "origin_answer": "如果拥有想要现在使用 Apache Hudi 进行管理的数据，您可以使用 Amazon EMR 上的 Apache Hudi 提供的导入工具将您的 Apache Parquet 数据轻松转换为 Apache Hudi 数据集，或者使用 Hudi DeltaStreamer 实用程序或 Apache Spark 将您的现有数据重写为 Apache Hudi 数据集。\n使用 Impala", "generate_question": "如何将现有的 Apache Parquet 数据转换为 Apache Hudi 数据集？", "generate_answer": "您可以使用 Amazon EMR 上的 Apache Hudi 提供的导入工具将您的 Apache Parquet 数据轻松转换为 Apache Hudi 数据集。"}
{"origin_question": "\n如何用 Apache Hudi 处理我的现有数据？\n", "origin_answer": "如果拥有想要现在使用 Apache Hudi 进行管理的数据，您可以使用 Amazon EMR 上的 Apache Hudi 提供的导入工具将您的 Apache Parquet 数据轻松转换为 Apache Hudi 数据集，或者使用 Hudi DeltaStreamer 实用程序或 Apache Spark 将您的现有数据重写为 Apache Hudi 数据集。\n使用 Impala", "generate_question": "除了使用导入工具，还有其他方法可以将现有数据转换为 Apache Hudi 数据集吗？", "generate_answer": "是的，您还可以使用 Hudi DeltaStreamer 实用程序或 Apache Spark 将您的现有数据重写为 Apache Hudi 数据集。"}
{"origin_question": "\n如何用 Apache Hudi 处理我的现有数据？\n", "origin_answer": "如果拥有想要现在使用 Apache Hudi 进行管理的数据，您可以使用 Amazon EMR 上的 Apache Hudi 提供的导入工具将您的 Apache Parquet 数据轻松转换为 Apache Hudi 数据集，或者使用 Hudi DeltaStreamer 实用程序或 Apache Spark 将您的现有数据重写为 Apache Hudi 数据集。\n使用 Impala", "generate_question": "是否可以使用 Impala 来处理 Apache Hudi 数据集？", "generate_answer": "是的，您可以使用 Impala 来处理 Apache Hudi 数据集。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala是什么生态系统的开源工具？", "generate_answer": "Impala是Hadoop生态系统的开源工具。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala使用什么语法进行交互式即席查询？", "generate_answer": "Impala使用SQL语法进行交互式即席查询。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala与传统关系数据库管理系统 (RDBMS) 中的引擎有什么相似之处？", "generate_answer": "Impala利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala适用于哪种类型的查询？", "generate_answer": "Impala适用于进行交互式、低延迟分析的查询。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala使用什么来保留有关输入数据的信息？", "generate_answer": "Impala使用Hive元存储来保留有关输入数据的信息，包括分区名称和数据类型。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "在Amazon EMR上运行的Impala要求什么版本的Hadoop？", "generate_answer": "在Amazon EMR上运行的Impala要求AMI运行Hadoop 2.x或更高版本。"}
{"origin_question": "\n什么是 Impala？\n", "origin_answer": "Impala 是 Hadoop 生态系统的开源工具，方便使用 SQL 语法进行交互式即席查询。它不使用 MapReduce，而是利用与传统关系数据库管理系统 (RDBMS) 中的引擎类似的大规模并行处理 (MPP) 引擎。利用此架构，可以非常快速地查询 HDFS 或 HBase 表中的数据，并利用 Hadoop 的功能来处理不同数据类型并在运行时提供架构。这让 Impala 适合于进行交互式、低延迟分析。Impala 使用 Hive 元存储来保留有关输入数据的信息，包括分区名称和数据类型。另外，Amazon EMR 上的 Impala 要求 AMI 运行 Hadoop 2.x 或更高版本。单击此处可以了解有关 Impala 的更多信息。\n", "generate_question": "Impala适用于查询哪些类型的数据表？", "generate_answer": "Impala适用于查询HDFS或HBase表中的数据。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "什么是 Amazon EMR？", "generate_answer": "Amazon EMR 是亚马逊云科技提供的一项云计算服务，用于在云中处理和分析大规模数据集。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Amazon EMR 中的 Impala 是什么？", "generate_answer": "Impala 是 Amazon EMR 中的一种工具，用于执行复杂的数据处理应用程序，可以通过 SQL 语法进行操作。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中可以替代哪个工具？", "generate_answer": "Impala 可以替代 Hive，在 Amazon EMR 中执行临时查询和批处理 ETL 任务。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中的使用案例有哪些？", "generate_answer": "使用 Impala 可以在长期运行的群集中执行临时查询，也可以在临时群集上运行批处理 ETL 任务，还可以与第三方商业智能工具一起使用。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中与 Hive 和 Pig 一起使用有什么好处？", "generate_answer": "在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用可以提高查询性能，同时还可以方便地将查询从 Hive 修改为 Impala。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中与第三方商业智能工具一起使用的方法是什么？", "generate_answer": "可以使用客户端 ODBC 或 JDBC 驱动程序与群集连接，将 Impala 作为强大可视化工具和控制面板的引擎。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "在 Amazon EMR 中可以创建哪种类型的 Impala 群集？", "generate_answer": "可以创建批处理和交互式 Impala 群集。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "如何在 Amazon EMR 中使用 Impala 进行交互式查询？", "generate_answer": "可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中执行交互式查询的优势是什么？", "generate_answer": "Impala 可以将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中执行批处理 ETL 任务的优势是什么？", "generate_answer": "Impala 比 Hive 更快，可以为批处理 ETL 任务提供更好的性能。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Impala 在 Amazon EMR 中与 Hive 相比有什么不同？", "generate_answer": "Impala 使用 SQL 语法，与 Hive 类似，但在某些使用案例中，Impala 专用于提高执行速度。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "在 Amazon EMR 中使用 Impala 时需要注意什么？", "generate_answer": "需要根据具体的查询调整 Impala 群集，以获得最佳的性能。"}
{"origin_question": "\n使用 Amazon EMR 中运行的 Impala 可以执行哪些操作？\n", "origin_answer": "与将 Hive 和 Amazon EMR 一起使用类似，利用 Impala 和 Amazon EMR 可以通过 SQL 语法实施复杂的数据处理应用程序。但是，在某些使用案例中，Impala 专用于提高执行速度（参阅下文）。借助 Amazon EMR，您可以将 Impala 用作可靠的数据仓库来执行数据分析、监控和业务智能等任务。下面是三个使用案例：\n\n在长期运行的群集中使用 Impala 代替 Hive 来执行临时查询。Impala 将交互式查询时间缩短为数秒，是一种优秀的快速调查工具。可以在运行批处理 MapReduce 工作流的同一群集上运行 Impala，在长时间运行的分析群集上将 Impala 与 Hive 和 Pig 一起使用，也可以创建专门针对 Impala 查询调整的群集。\n使用 Impala 而非 Hive 在临时 Amazon EMR 群集上运行批处理 ETL 任务。对于许多查询而言，Impala 比 Hive 更快，可以这些工作负载提供更好的性能。与 Hive 一样，Impala 使用 SQL，因此可以方便地将查询从 Hive 修改为 Impala。\n将 Impala 与第三方商业智能工具一起使用。将客户端 ODBC 或 JDBC 驱动程序与群集连接，使用 Impala 作为强大可视化工具和控制面板的引擎。\n可以在 Amazon EMR 中创建批处理和交互式 Impala 群集。例如，您可以使长时间运行的 Amazon EMR 群集运行 Impala 来执行专门的交互式查询，或使用临时 Impala 群集执行快速的 ETL 工作流。\n", "generate_question": "Amazon EMR 中的 Impala 可以用作什么类型的数据仓库？", "generate_answer": "Impala 可以用作可靠的数据仓库，用于执行数据分析、监控和业务智能等任务。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 与传统的 RDBMS 有何区别？", "generate_answer": "Impala 与传统的关系数据库管理系统（RDBMS）在几个方面有所不同。传统的 RDBMS 具有事务语义和 ACID 属性，支持索引和缓存，但不支持用户定义的复杂数据类型操作。而 Impala 使用分布式查询系统，查询存储在 HDFS 中的数据，并使用 Hive 元存储来保存输入数据的信息。Impala 还支持查询各种复杂数据类型和执行用户定义函数。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 与传统的 RDBMS 在数据处理方式上有何不同？", "generate_answer": "Impala 在内存中处理数据，而传统的 RDBMS 在单个大型计算机上运行。这意味着 Impala 需要了解群集的硬件限制并优化查询以实现最佳性能。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 与 Hive 有何相似之处？", "generate_answer": "Impala 与 Hive 在查询的架构上相似，都可以在运行时提供查询的架构，并且都使用 Hive 元存储来保存有关输入数据的信息。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 与 Hive 在数据存储上有何不同？", "generate_answer": "Impala 查询存储在 HDFS 中的数据，而 Hive 使用 Hive 元存储来保存有关输入数据的信息。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 是否支持事务语义和 ACID 属性？", "generate_answer": "Impala 不支持事务语义和 ACID 属性，这是传统的关系数据库管理系统（RDBMS）所具有的特性。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 是否支持对表进行索引和缓存？", "generate_answer": "Impala 不支持对表进行索引和缓存，这是传统的关系数据库管理系统（RDBMS）所具有的特性。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 是否支持对用户定义的复杂数据类型进行操作？", "generate_answer": "是的，Impala 支持对用户定义的复杂数据类型进行操作，这是传统的关系数据库管理系统（RDBMS）所不具备的功能。"}
{"origin_question": "\nImpala 与传统的 RDBMS 有何区别？\n", "origin_answer": "传统关系数据库系统具有事务语义和数据库原子性、一致性、隔离性和持久性 (ACID) 属性。它们还允许对表进行索引和缓存，以便少量的数据也能很快被检索到，可快速更新少量数据，并可强制执行参考完整性限制。通常，它们在单个大型计算机上运行，不支持对用户定义的复杂数据类型进行操作。Impala 使用与 RDBMS 中类似的分布式查询系统，但查询 HDFS 中存储的数据，并使用 Hive 元存储来保存有关输入数据的信息。与 Hive 一样，在运行时提供查询的架构，可以更方便地更改架构。另外，Impala 可以查询各种复杂数据类型并执行用户定义函数。但是，因为 Impala 在内存中处理数据，所以了解群集的硬件限制并优化查询实现最佳性能非常重要。\n", "generate_question": "Impala 在查询性能方面有何要求？", "generate_answer": "Impala 在内存中处理数据，因此了解群集的硬件限制并优化查询是实现最佳性能的关键。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Impala 和 Hive 分别使用什么引擎执行 SQL 查询？", "generate_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Impala 和 Hive 在查询速度上有何区别？", "generate_answer": "Impala 的查询速度比 Hive 快数倍。这是因为 Impala 避免了 Hive 用于创建 MapReduce 任务的开销。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Impala 和 Hive 在内存资源的使用上有何区别？", "generate_answer": "Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。而 Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Impala 和 Hive 分别适用于哪种工作负载？", "generate_answer": "Impala 适用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Impala 适用于处理哪种类型的查询或数据集？", "generate_answer": "Impala 适用于执行耗费大量资源的查询或处理非常大的数据集。它旨在提高速度，非常适用于特殊调查。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "Hive 在处理大数据集方面有何优势？", "generate_answer": "Hive 在处理大数据集方面没有限制，使用相同的硬件可以成功地处理更大的数据集。"}
{"origin_question": "\nImpala 与 Hive 有何区别？\n", "origin_answer": "Impala 使用大规模并行处理 (MPP) 引擎执行 SQL 查询，而 Hive 使用 MapReduce 执行 SQL 查询。Impala 避免了 Hive 用于创建 MapReduce 任务的开销，其查询速度比 Hive 快数倍。但是，Impala 使用大量的内存资源，并且群集的可用内存为查询可以使用的内存量设定了限制。Hive 在这方面没有限制，使用相同的硬件可以成功地处理更大的数据集。通常，应将 Impala 用于快速、交互式查询，而 Hive 更适用于大数据集的 ETL 工作。Impala 旨在提高速度，非常适用于特殊调查，但需要大量内存来执行耗费大量资源的查询或处理非常大的数据集。因为存在这些限制，所以对于完成比速度更重要的工作负载，建议使用 Hive。单击此处查看 Impala 和 Hive 之间的性能基准。\n", "generate_question": "在完成比速度更重要的工作负载时，建议使用哪个工具？", "generate_answer": "在完成比速度更重要的工作负载时，建议使用 Hive。因为 Impala 使用大量的内存资源，并且对于完成比速度更重要的工作负载，Hive 更适合使用。"}
{"origin_question": "\n可以使用 Hadoop 1 吗？\n", "origin_answer": "不可以，Impala 需要 Hadoop 2，在使用运行 Hadoop 1.x 的 AMI 的群集上无法运行。\n", "generate_question": "Impala 需要运行在哪个版本的 Hadoop 上？", "generate_answer": "Impala 需要运行在 Hadoop 2 上。"}
{"origin_question": "\n可以使用 Hadoop 1 吗？\n", "origin_answer": "不可以，Impala 需要 Hadoop 2，在使用运行 Hadoop 1.x 的 AMI 的群集上无法运行。\n", "generate_question": "在使用运行 Hadoop 1.x 的 AMI 的群集上可以运行 Impala 吗？", "generate_answer": "不可以，在使用运行 Hadoop 1.x 的 AMI 的群集上无法运行 Impala。"}
{"origin_question": "\n应该对我的 Impala 群集使用什么实例类型？\n", "origin_answer": "为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。\n", "generate_question": "为什么推荐对 Impala 群集使用经过内存优化的实例？", "generate_answer": "推荐对 Impala 群集使用经过内存优化的实例是为了获得最佳的使用体验。"}
{"origin_question": "\n应该对我的 Impala 群集使用什么实例类型？\n", "origin_answer": "为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。\n", "generate_question": "在使用标准实例类型时，Impala 的性能如何？", "generate_answer": "在使用标准实例类型时，Impala 的性能要优于 Hive。"}
{"origin_question": "\n应该对我的 Impala 群集使用什么实例类型？\n", "origin_answer": "为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。\n", "generate_question": "如何更好地估计群集所需的内存资源？", "generate_answer": "可以阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。"}
{"origin_question": "\n应该对我的 Impala 群集使用什么实例类型？\n", "origin_answer": "为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。\n", "generate_question": "什么因素会影响 Impala 查询所需的内存和其他资源？", "generate_answer": "压缩类型、分区和实际查询（连接数、结果大小等）都会影响 Impala 查询所需的内存和其他资源。"}
{"origin_question": "\n应该对我的 Impala 群集使用什么实例类型？\n", "origin_answer": "为了获得 Impala 的最佳使用体验，我们推荐对您的群集使用经过内存优化的实例。但是，我们已经展示在使用标准实例类型时，获得的性能要优于 Hive。我们建议阅读“Amazon EMR 开发人员指南”的性能测试和查询优化部分，以更好地估计针对您的数据集和查询类型，群集所需的内存资源。压缩类型、分区和实际查询（连接数、结果大小等）都会影响所需内存。可以使用 EXPLAIN 语句估计 Impala 查询所需的内存和其他资源。\n", "generate_question": "如何估计 Impala 查询所需的内存和其他资源？", "generate_answer": "可以使用 EXPLAIN 语句来估计 Impala 查询所需的内存和其他资源。"}
{"origin_question": "\n如果查询时内存不足会发生什么？\n", "origin_answer": "如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。\n", "generate_question": "查询失败后，Amazon EMR 会如何处理内存不足的情况？", "generate_answer": "如果查询时内存不足，Amazon EMR 会关闭受影响节点上的 Impala 守护程序，并重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。关闭的是该节点上运行的守护程序，而非整个节点本身。"}
{"origin_question": "\n如果查询时内存不足会发生什么？\n", "origin_answer": "如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。\n", "generate_question": "在内存不足的情况下，HDFS 中的数据是否还可用？", "generate_answer": "是的，即使在内存不足的情况下，关闭的仅是受影响节点上的 Impala 守护程序，HDFS 中的数据仍然可用。"}
{"origin_question": "\n如果查询时内存不足会发生什么？\n", "origin_answer": "如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。\n", "generate_question": "Impala 的查询时间通常可以按秒计，这对于查询失败后的处理有什么好处？", "generate_answer": "Impala 的查询时间通常很短，可以按秒计。因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。"}
{"origin_question": "\n如果查询时内存不足会发生什么？\n", "origin_answer": "如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。\n", "generate_question": "为什么查询会失败？", "generate_answer": "查询会失败是因为内存不足，当内存不足时，Impala 无法继续执行查询操作。"}
{"origin_question": "\n如果查询时内存不足会发生什么？\n", "origin_answer": "如果内存不足，查询会失败，并且受影响节点上安装的 Impala 守护程序会关闭。然后，Amazon EMR 重新启动该节点上的守护程序，以便 Impala 准备好运行其他查询。此节点上 HDFS 中的数据仍然可用，因为关闭的仅是该节点上运行的守护程序，而非整个节点本身。对于使用 Impala 的专门分析，查询时间通常可以按秒计；因此，如果某个查询失败，您可以快速发现问题，并且可以迅速接着提交新查询。\n", "generate_question": "在查询失败后，可以立即提交新的查询吗？", "generate_answer": "是的，如果某个查询失败，您可以快速发现问题，并且可以立即提交新的查询。由于 Impala 的查询时间通常很短，您可以迅速进行下一次查询操作。"}
{"origin_question": "\nImpala 支持用户定义的函数吗？\n", "origin_answer": "是，Impala 支持用户定义的函数 (UDF)。可以用 Java 或 C++ 编写专用于 Impala 的 UDF。另外，可以修改为 Hive 创建的 UDF 或用户定义的聚合函数，以便在 Impala 中使用。有关 Hive UDF 的信息，请单击此处。\n", "generate_question": "Impala支持哪些编程语言编写用户定义的函数？", "generate_answer": "Impala支持用Java或C++编写用户定义的函数(UDF)。"}
{"origin_question": "\nImpala 支持用户定义的函数吗？\n", "origin_answer": "是，Impala 支持用户定义的函数 (UDF)。可以用 Java 或 C++ 编写专用于 Impala 的 UDF。另外，可以修改为 Hive 创建的 UDF 或用户定义的聚合函数，以便在 Impala 中使用。有关 Hive UDF 的信息，请单击此处。\n", "generate_question": "用户可以在Impala中使用哪些类型的函数？", "generate_answer": "用户可以在Impala中使用用户定义的函数(UDF)和用户定义的聚合函数。"}
{"origin_question": "\nImpala 支持用户定义的函数吗？\n", "origin_answer": "是，Impala 支持用户定义的函数 (UDF)。可以用 Java 或 C++ 编写专用于 Impala 的 UDF。另外，可以修改为 Hive 创建的 UDF 或用户定义的聚合函数，以便在 Impala 中使用。有关 Hive UDF 的信息，请单击此处。\n", "generate_question": "用户可以在Impala中使用哪些其他类型的函数？", "generate_answer": "用户可以在Impala中使用Hive创建的UDF或用户定义的聚合函数。"}
{"origin_question": "\n供 Impala 查询的数据存储在何处？\n", "origin_answer": "Impala 会查询 HDFS 或 HBase 表中的数据。\n", "generate_question": "Impala可以查询哪些数据存储位置？", "generate_answer": "Impala可以查询存储在HDFS或HBase表中的数据。"}
{"origin_question": "\n可以在群集上同时运行 Impala 和 MapReduce 吗？\n", "origin_answer": "是的，您可以设置具有 Impala 和 MapReduce 的多租户群集。但是，您应确保使用 Hadoop 2.x 上的 YARN 将资源（内存、磁盘和 CPU）分配给每个应用程序。分配的资源应取决于您计划在每个应用程序上所运行任务的需要。\n", "generate_question": "在亚马逊云科技的多租户群集中，可以同时运行哪些应用程序？", "generate_answer": "在亚马逊云科技的多租户群集中，可以同时运行 Impala 和 MapReduce 应用程序。"}
{"origin_question": "\n可以在群集上同时运行 Impala 和 MapReduce 吗？\n", "origin_answer": "是的，您可以设置具有 Impala 和 MapReduce 的多租户群集。但是，您应确保使用 Hadoop 2.x 上的 YARN 将资源（内存、磁盘和 CPU）分配给每个应用程序。分配的资源应取决于您计划在每个应用程序上所运行任务的需要。\n", "generate_question": "在设置具有 Impala 和 MapReduce 的多租户群集时，需要注意哪些方面？", "generate_answer": "在设置具有 Impala 和 MapReduce 的多租户群集时，需要注意使用 Hadoop 2.x 上的 YARN 将资源分配给每个应用程序，并根据每个应用程序所运行任务的需要来确定分配的资源（内存、磁盘和 CPU）。"}
{"origin_question": "\n可以在群集上同时运行 Impala 和 MapReduce 吗？\n", "origin_answer": "是的，您可以设置具有 Impala 和 MapReduce 的多租户群集。但是，您应确保使用 Hadoop 2.x 上的 YARN 将资源（内存、磁盘和 CPU）分配给每个应用程序。分配的资源应取决于您计划在每个应用程序上所运行任务的需要。\n", "generate_question": "在亚马逊云科技的多租户群集中，资源的分配应该基于什么因素？", "generate_answer": "在亚马逊云科技的多租户群集中，资源的分配应该基于每个应用程序所运行任务的需要来确定，包括内存、磁盘和 CPU 等资源。"}
{"origin_question": "\nImpala 支持 ODBC 和 JDBC 驱动程序吗？\n", "origin_answer": "虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅打开到主节点的 SSH 隧道。\n使用 Pig", "generate_question": "Impala支持哪些驱动程序？", "generate_answer": "Impala支持ODBC和JDBC驱动程序。"}
{"origin_question": "\nImpala 支持 ODBC 和 JDBC 驱动程序吗？\n", "origin_answer": "虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅打开到主节点的 SSH 隧道。\n使用 Pig", "generate_question": "如何下载和安装Impala客户端JDBC驱动程序？", "generate_answer": "您可以从以下位置下载和安装Impala客户端JDBC驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。"}
{"origin_question": "\nImpala 支持 ODBC 和 JDBC 驱动程序吗？\n", "origin_answer": "虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅打开到主节点的 SSH 隧道。\n使用 Pig", "generate_question": "如何通过JDBC连接第三方工具到Impala？", "generate_answer": "在安装了商业智能工具的客户端计算机中，使用SSH或VPN在端口21050上将JDBC驱动程序连接到Impala群集的主节点。"}
{"origin_question": "\nImpala 支持 ODBC 和 JDBC 驱动程序吗？\n", "origin_answer": "虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅打开到主节点的 SSH 隧道。\n使用 Pig", "generate_question": "如何打开到Impala主节点的SSH隧道？", "generate_answer": "要打开到Impala主节点的SSH隧道，请参阅相关文档获取更多信息。"}
{"origin_question": "\nImpala 支持 ODBC 和 JDBC 驱动程序吗？\n", "origin_answer": "虽然您可以使用 ODBC 驱动程序，但 Impala 也是一款优质引擎，适用于通过 JDBC 连接的第三方工具。可以从以下位置下载和安装 Impala 客户端 JDBC 驱动程序：http://elasticmapreduce.s3.amazonaws.com/libs/impala/1.2.1/impala-jdbc-1.2.1.zip。在安装了商业智能工具的客户端计算机中，使用 SSH 或 VPN 在端口 21050 上将 JDBC 驱动程序连接到 Impala 群集的主节点。有关更多信息，请参阅打开到主节点的 SSH 隧道。\n使用 Pig", "generate_question": "Impala适用于哪些连接方式？", "generate_answer": "Impala适用于通过JDBC连接的第三方工具，同时也支持使用ODBC驱动程序连接。"}
{"origin_question": "\n什么是 Apache Pig？\n", "origin_answer": "Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。\n", "generate_question": "Apache Pig是什么？", "generate_answer": "Apache Pig是一种在Hadoop上运行的开源分析软件包，它使用类似SQL的语言Pig Latin来操作数据。"}
{"origin_question": "\n什么是 Apache Pig？\n", "origin_answer": "Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。\n", "generate_question": "Pig Latin支持哪些操作？", "generate_answer": "Pig Latin支持构建、汇总和查询存储在Amazon S3中的数据源，并且还支持一流的map/reduce函数和用户定义的可扩展数据类型。"}
{"origin_question": "\n什么是 Apache Pig？\n", "origin_answer": "Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。\n", "generate_question": "Pig可以处理哪些类型的数据源？", "generate_answer": "Pig可以处理复杂的甚至非结构化的数据源，例如文本文档和日志文件。"}
{"origin_question": "\n什么是 Apache Pig？\n", "origin_answer": "Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。\n", "generate_question": "用户可以如何执行扩展操作？", "generate_answer": "用户可以通过编写Java代码和部署用户自定义函数到存储在Amazon S3中的位置来执行扩展操作。"}
{"origin_question": "\n什么是 Apache Pig？\n", "origin_answer": "Pig 是在 Hadoop 顶部运行的一种开源分析软件包。Pig 由类似 SQL 的语言 Pig Latin 操作，允许用户构建、汇总和查询 Amazon S3 中存储的数据源。与 SQL 操作类似，Pig Latin 也支持一流的 map/reduce 函数及复杂的由用户定义的可扩展数据类型。该功能能够处理复杂的甚至非结构化的数据源，如文本文档和日志文件。Pig 允许用户通过以 Java 编写和通过 Amazon S3 中的存储部署的用户自定义函数执行扩展。\n", "generate_question": "Pig与SQL操作有何相似之处？", "generate_answer": "Pig Latin与SQL操作类似，可以进行类似的数据处理和查询操作，但同时还支持更复杂的数据类型和函数。"}
{"origin_question": "\n我该如何使用 Amazon EMR 中运行的 Pig？\n", "origin_answer": "对于 Amazon EMR 使用 Pig，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Pig 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "如何在 Amazon EMR 中运行 Pig？", "generate_answer": "在 Amazon EMR 中运行 Pig，您可以使用熟悉的 SQL 语言和易用的工具执行复杂的数据处理应用程序。"}
{"origin_question": "\n我该如何使用 Amazon EMR 中运行的 Pig？\n", "origin_answer": "对于 Amazon EMR 使用 Pig，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Pig 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "Amazon EMR 中的 Pig 可以用于执行哪些任务？", "generate_answer": "Amazon EMR 中的 Pig 可以用于执行各种任务，包括数据分析、监控和业务智能任务。"}
{"origin_question": "\n我该如何使用 Amazon EMR 中运行的 Pig？\n", "origin_answer": "对于 Amazon EMR 使用 Pig，您可以通过 Amazon EMR 中熟悉的 SQL 之类的语言和易用的工具执行复杂的数据处理应用程序。借助 Amazon EMR，您可以将 Pig 应用程序转换为可靠的数据仓库来执行任务，如数据分析、监控和业务智能任务。\n", "generate_question": "Amazon EMR 如何将 Pig 应用程序转换为可靠的数据仓库？", "generate_answer": "Amazon EMR 可以将 Pig 应用程序转换为可靠的数据仓库，以执行各种任务，如数据分析、监控和业务智能任务。"}
{"origin_question": "\n如何开始使用 Amazon EMR 中运行的 Pig？\n", "origin_answer": "要开始使用，您最好先查看此处的书面文档。\n", "generate_question": "如何开始使用 Amazon EMR 中运行的 Pig？", "generate_answer": "要开始使用 Amazon EMR 中运行的 Pig，您最好先查看此处的书面文档。在文档中，您将找到关于如何设置和配置 Amazon EMR 群集以及如何编写和运行 Pig 脚本的详细说明。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "Amazon EMR 的 Pig 有哪些新功能？", "generate_answer": "可以访问多个文件系统、从 S3 加载资源和使用更多的 Piggybank 功能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "默认情况下，Amazon EMR 的 Pig 可以访问多少个远程文件系统？", "generate_answer": "默认情况下，Amazon EMR 的 Pig 只能访问一个远程文件系统。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "Amazon EMR 对 Pig 进行了怎样的扩展？", "generate_answer": "Amazon EMR 对 Pig 进行了扩展，使得任何任务都能根据需要访问任意数量的文件系统，并且可以从 S3 加载资源。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "Amazon EMR 的 Pig 扩展对性能有什么好处？", "generate_answer": "Amazon EMR 的 Pig 扩展使得任务内的临时数据始终存储在本地 HDFS 中，从而提高性能。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "如何从 S3 加载自定义的 JAR 和脚本？", "generate_answer": "可以使用类似于“REGISTER s3:///my-bucket/piggybank.jar”的语法从 S3 加载自定义的 JAR 和脚本。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "Amazon EMR 的 Piggybank 功能主要用于处理什么类型的数据？", "generate_answer": "Amazon EMR 的 Piggybank 功能主要用于处理字符串和日期时间数据。"}
{"origin_question": "\n特定于 Amazon EMR 的 Pig 是否有新功能？\n", "origin_answer": "可以。用于 Amazon EMR 时，有三项新功能可使得 Pig 更加强大，包括：\n\na/ 访问多个文件系统。默认情况下，无论是用于输入、输出和临时数据的 HDFS 存储还是 S3 存储段，Pig 任务只能访问一个远程文件系统。EMR 对 Pig 进行了扩展，使任何任务都能根据需要访问任意数量的文件系统。这样做的一个好处是，任务内的临时数据将始终存储在本地 HDFS 中，从而令性能提高。\n\nb/ 从 S3 加载资源。EMR 对 Pig 进行了扩展，使自定义的 JAR 和脚本可以来自 S3 文件系统，例如“REGISTER s3:///my-bucket/piggybank.jar”\n\nc/ 更多用于处理字符串和日期时间的 Piggybank 功能。\n", "generate_question": "Amazon EMR 的 Piggybank 功能有哪些？", "generate_answer": "没有具体提到，只是提到了有更多用于处理字符串和日期时间的 Piggybank 功能。"}
{"origin_question": "\n支持哪些类型的 Pig 群集？\n", "origin_answer": "Pig 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Pig 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Pig 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "Pig 支持哪两类群集？", "generate_answer": "Pig 支持交互式和批处理两类群集。"}
{"origin_question": "\n支持哪些类型的 Pig 群集？\n", "origin_answer": "Pig 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Pig 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Pig 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "在交互式模式下，客户可以在哪里启动群集和运行 Pig 脚本？", "generate_answer": "在交互式模式下，客户可以直接在主节点上启动群集和运行 Pig 脚本。"}
{"origin_question": "\n支持哪些类型的 Pig 群集？\n", "origin_answer": "Pig 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Pig 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Pig 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "在批处理模式下，Pig 脚本存储在哪里？", "generate_answer": "在批处理模式下，Pig 脚本存储在 Amazon S3 中。"}
{"origin_question": "\n支持哪些类型的 Pig 群集？\n", "origin_answer": "Pig 支持两类群集：交互式和批处理。在交互式模式下，客户可以直接在主节点上交互启动群集和运行 Pig 脚本。通常，该模式用来执行特别数据分析和应用程序开发。在批处理模式下，Pig 脚本存储在 Amazon S3 中，在启动群集时引用。通常，批处理模式用于报告生成等重复性运行。\n", "generate_question": "批处理模式通常用于什么样的任务？", "generate_answer": "批处理模式通常用于报告生成等重复性运行的任务。"}
{"origin_question": "\n如何启动 Pig 群集？\n", "origin_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。\n", "generate_question": "从哪些途径可以启动 Pig 群集？", "generate_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。"}
{"origin_question": "\n如何启动 Pig 群集？\n", "origin_answer": "批处理和交互式群集都可从 AWS 管理控制台、EMR 命令行客户端或 API 启动。\n", "generate_question": "有哪些方式可以启动 Pig 群集？", "generate_answer": "可以通过 AWS 管理控制台、EMR 命令行客户端或 API 来启动 Pig 群集。"}
{"origin_question": "\nAmazon EMR 支持哪些版本的 Pig？\n", "origin_answer": "Amazon EMR 支持多个版本的 Pig。\n", "generate_question": "Amazon EMR支持哪些版本的Hadoop？", "generate_answer": "Amazon EMR支持多个版本的Hadoop。"}
{"origin_question": "\n是否可以从两个群集并发写入 S3 存储段？\n", "origin_answer": "是的，可以从两个并发群集写入同一个存储段。\n", "generate_question": "亚马逊云科技的 S3 存储段是否支持并发写入？", "generate_answer": "是的，亚马逊云科技的 S3 存储段支持并发写入。"}
{"origin_question": "\n是否可以从两个群集并发写入 S3 存储段？\n", "origin_answer": "是的，可以从两个并发群集写入同一个存储段。\n", "generate_question": "除了两个群集，还可以从多少个并发群集写入同一个 S3 存储段？", "generate_answer": "除了两个群集，亚马逊云科技的 S3 存储段还可以支持多个并发群集写入。"}
{"origin_question": "\n是否可以在不同的群集之间共享 S3 中的输入数据？\n", "origin_answer": "是的，可以从两个并发群集读取 S3 中的相同数据。\n", "generate_question": "亚马逊云科技的 S3 是否支持多个并发群集同时读取相同的数据？", "generate_answer": "是的，可以从两个并发群集读取 S3 中的相同数据。"}
{"origin_question": "\n是否可以在不同的群集之间共享 S3 中的输入数据？\n", "origin_answer": "是的，可以从两个并发群集读取 S3 中的相同数据。\n", "generate_question": "亚马逊云科技的 S3 是否支持在不同的群集之间共享输入数据？", "generate_answer": "是的，可以在不同的群集之间共享 S3 中的输入数据。"}
{"origin_question": "\n是否可以在多个 AWS 用户之间共享数据？\n", "origin_answer": "可以。可以使用此处 http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html 描述的标准 Amazon S3 共享机制共享数据\n", "generate_question": "如何在多个 AWS 用户之间共享数据？", "generate_answer": "可以使用标准 Amazon S3 共享机制来共享数据，具体的操作可以参考此处的文档：http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html"}
{"origin_question": "\n是否可以在多个 AWS 用户之间共享数据？\n", "origin_answer": "可以。可以使用此处 http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html 描述的标准 Amazon S3 共享机制共享数据\n", "generate_question": "在 AWS 中，有哪些方法可以实现数据共享？", "generate_answer": "在 AWS 中，可以使用标准 Amazon S3 共享机制来实现数据共享，具体的操作可以参考此处的文档：http://docs.amazonwebservices.com/AmazonS3/latest/index.html?S3_ACLs.html"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。\n", "generate_question": "Amazon EMR提供了哪些功能来支持在多个用户之间共享大型群集？", "generate_answer": "Amazon EMR提供了独特的功能，使您能够同时使用大型群集和独立的群集来满足不同的需求。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。\n", "generate_question": "为什么大型群集对于处理普通的批处理工作负载更有效？", "generate_answer": "大型群集可以更好地处理大量的数据和复杂的计算任务，从而提高处理效率和性能。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。\n", "generate_question": "为什么创建独立的群集可以适应共享Amazon S3中存储的数据源的特定任务？", "generate_answer": "创建独立的群集可以根据特定的查询或工作负载进行调整，以满足共享Amazon S3中存储的数据源的需求。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。\n", "generate_question": "在什么情况下应该选择运行许多较小的群集？", "generate_answer": "当需要执行随时间变化的特别查询或工作负载时，可以选择创建许多较小的群集，以便于调整和优化处理任务。"}
{"origin_question": "\n我应该运行一个大型群集在多个用户之间共享，还是运行许多较小的群集？\n", "origin_answer": "Amazon EMR 提供独特的功能，使您能够同时使用两种方法。一方面，大型群集对于处理普通的批处理工作负载可能更为有效。另一方面，如果您需要执行随时间变化的特别查询或工作负载，可以选择创建若干独立的群集，以便于调整使其适合共享 Amazon S3 中所存储数据源的特定任务。\n", "generate_question": "Amazon EMR如何帮助用户在多个用户之间共享群集？", "generate_answer": "Amazon EMR提供了独特的功能，使用户可以选择同时使用大型群集和独立的群集，以满足不同用户的需求和任务。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "亚马逊云科技的脚本或 Jar 资源是否可以直接访问本地文件系统？", "generate_answer": "不可以，必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "有哪些工具可以用来上传脚本或 Jar 到 Amazon S3？", "generate_answer": "可以使用 s3cmd、jets3t 或 S3Organizer 等工具来上传脚本或 Jar 到 Amazon S3。"}
{"origin_question": "\n是否可以访问本地文件系统中的脚本或 Jar 资源？\n", "origin_answer": "必须将脚本或 Jar 上传到 Amazon S3 或群集的主节点，才能对其引用。要上传到 Amazon S3，您可以使用 s3cmd、jets3t 或 S3Organizer 等工具。\n", "generate_question": "除了 Amazon S3，还有其他地方可以上传脚本或 Jar 吗？", "generate_answer": "除了 Amazon S3，也可以将脚本或 Jar 上传到群集的主节点上进行引用。"}
{"origin_question": "\n是否可运行执行多个 Pig 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Pig 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。\n", "generate_question": "在亚马逊云科技的持续性群集中，是否可以运行执行多个 Pig 查询？", "generate_answer": "是的，可以在亚马逊云科技的持续性群集中运行执行多个 Pig 查询。"}
{"origin_question": "\n是否可运行执行多个 Pig 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Pig 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。\n", "generate_question": "在手动终止模式下运行群集时，会发生什么情况？", "generate_answer": "在手动终止模式下运行群集时，群集不会在各个 Pig 步骤中终止。"}
{"origin_question": "\n是否可运行执行多个 Pig 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Pig 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。\n", "generate_question": "为了降低数据丢失的风险，亚马逊云科技建议采取什么措施？", "generate_answer": "亚马逊云科技建议定期在 Amazon S3 中保存所有重要的数据，以降低数据丢失的风险。"}
{"origin_question": "\n是否可运行执行多个 Pig 查询的持续性群集？\n", "origin_answer": "可以。在手动终止模式下运行群集，它们则不会在各个 Pig 步骤中终止。要降低数据丢失的风险，我们建议您定期在 Amazon S3 中保存所有重要的数据。最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。\n", "generate_question": "为了测试从主节点故障进行恢复的进程，亚马逊云科技建议采取什么措施？", "generate_answer": "亚马逊云科技建议最好定期将工作传输到新的群集，以测试从主节点故障进行恢复的进程。"}
{"origin_question": "\nPig 是否支持从 JDBC 进行访问？\n", "origin_answer": "Pig 不支持通过 JDBC 进行访问。 ", "generate_question": "亚马逊云科技的 Pig 是否支持通过 JDBC 进行访问？", "generate_answer": "Pig 不支持通过 JDBC 进行访问。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "Apache HBase是什么？", "generate_answer": "Apache HBase是一种开源的、非关系型的分布式数据库，它模仿了Google BigTable的设计思想。作为Apache软件基金会Hadoop项目的一部分，HBase在Hadoop分布式文件系统（HDFS）上运行，为Hadoop生态系统提供了非关系型数据库的功能。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase是如何存储数据的？", "generate_answer": "HBase使用列式压缩和存储方式来高效地存储大量稀疏数据。数据存储在内存中而非磁盘上，因此可以快速查找数据。此外，HBase还对连续写入操作进行了优化，批量插入、更新和删除等操作的效率很高。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase与Hadoop如何配合工作？", "generate_answer": "HBase与Hadoop无缝配合，可以共享Hadoop的文件系统，并作为Hadoop工作的直接输入和输出。这意味着HBase可以与Hadoop一起使用，以处理大规模数据集，并利用Hadoop的分布式计算能力。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase与Apache Hive有何关联？", "generate_answer": "HBase与Apache Hive集成，支持对HBase表进行类似SQL的查询。通过与基于Hive的表结合，可以在HBase上执行更复杂的查询操作。此外，HBase还支持Java数据库连接（JDBC），使得可以通过JDBC与HBase进行交互。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase适用于哪些场景？", "generate_answer": "HBase适用于需要存储大量稀疏数据的场景，特别是需要快速查找数据和进行连续写入操作的场景。由于HBase可以与Hadoop无缝配合，因此适用于需要与Hadoop一起处理大规模数据集的场景。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase的优势是什么？", "generate_answer": "HBase的优势包括高效存储大量稀疏数据、快速查找数据、优化的连续写入操作、与Hadoop无缝配合、与Apache Hive集成以支持类似SQL的查询、支持Java数据库连接（JDBC）等。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "HBase是哪个项目的一部分？", "generate_answer": "HBase是Apache软件基金会Hadoop项目的一部分。"}
{"origin_question": "\n什么是 Apache HBase？\n", "origin_answer": "HBase 是一种仿效 Google BigTable 的开源、非关系型分布式数据库。它是 Apache 软件基金会 Hadoop 项目的一部分，基于 Hadoop 分布式文件系统 (HDFS) 运行，为 Hadoop 生态系统提供非关系数据库功能。HBase 为您提供了一种用列式压缩和存储方式来存储大量稀疏数据的高效容错方法。此外，因为数据存储在内存中而非磁盘上，所以还可以通过 HBase 快速查找数据。在连续写入操作方面对 HBase 进行了优化，批量插入、更新和删除等操作的效率很高。HBase 可与 Hadoop 无缝配合，从而共享其文件系统并用作 Hadoop 工作的直接输入和输出。HBase 还与 Apache Hive 集成，支持对 HBase 表进行类似 SQL 的查询、与基于 Hive 的表结合并支持 Java 数据库连接 (JDBC)。您可以在此处了解有关 Apache HBase 的更多信息。", "generate_question": "如何获取更多关于Apache HBase的信息？", "generate_answer": "您可以在Apache HBase的官方网站上获取更多关于HBase的信息。"}
{"origin_question": "\n特定于 Amazon EMR 的 HBase 是否有新功能？\n", "origin_answer": "借助 Amazon EMR，您可以在 Amazon S3 上使用 HBase 将集群的 HBase 根目录和元数据直接存储到 Amazon S3，并创建只读副本和快照。要了解更多信息，请参阅我们的文档。\n", "generate_question": "如何在 Amazon EMR 上使用 HBase 存储集群的 HBase 根目录和元数据？", "generate_answer": "借助 Amazon EMR，您可以在 Amazon S3 上使用 HBase 将集群的 HBase 根目录和元数据直接存储到 Amazon S3。"}
{"origin_question": "\n特定于 Amazon EMR 的 HBase 是否有新功能？\n", "origin_answer": "借助 Amazon EMR，您可以在 Amazon S3 上使用 HBase 将集群的 HBase 根目录和元数据直接存储到 Amazon S3，并创建只读副本和快照。要了解更多信息，请参阅我们的文档。\n", "generate_question": "Amazon EMR 是否支持创建 HBase 的只读副本和快照？", "generate_answer": "是的，您可以使用 Amazon EMR 在 Amazon S3 上创建 HBase 的只读副本和快照。"}
{"origin_question": "\n特定于 Amazon EMR 的 HBase 是否有新功能？\n", "origin_answer": "借助 Amazon EMR，您可以在 Amazon S3 上使用 HBase 将集群的 HBase 根目录和元数据直接存储到 Amazon S3，并创建只读副本和快照。要了解更多信息，请参阅我们的文档。\n", "generate_question": "如何了解更多关于 Amazon EMR 中特定于 HBase 的新功能的信息？", "generate_answer": "您可以参阅 Amazon EMR 的文档，以了解更多关于特定于 HBase 的新功能的信息。"}
{"origin_question": "\nAmazon EMR 支持哪些版本的 HBase？\n", "origin_answer": "您可以在此处查看 Amazon EMR 支持的最新 HBase 版本。", "generate_question": "Amazon EMR支持的最新HBase版本是什么？", "generate_answer": "您可以在此处查看 Amazon EMR 支持的最新 HBase 版本。"}
{"origin_question": "\nAmazon EMR 支持哪些版本的 HBase？\n", "origin_answer": "您可以在此处查看 Amazon EMR 支持的最新 HBase 版本。", "generate_question": "在哪里可以找到Amazon EMR支持的最新HBase版本？", "generate_answer": "您可以在此处找到 Amazon EMR 支持的最新 HBase 版本。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器支持什么功能？\n", "origin_answer": "该连接器支持 EMR 直接从 Kinesis 串流读取和查询数据。现在，您可以使用现有的 Hadoop 生态系统工具，如 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading，来执行 Kinesis 串流的批处理。\n", "generate_question": "Kinesis 上的 EMR 连接器支持哪些工具来执行批处理？", "generate_answer": "该连接器支持使用 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading 这些现有的 Hadoop 生态系统工具来执行 Kinesis 串流的批处理。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器支持什么功能？\n", "origin_answer": "该连接器支持 EMR 直接从 Kinesis 串流读取和查询数据。现在，您可以使用现有的 Hadoop 生态系统工具，如 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading，来执行 Kinesis 串流的批处理。\n", "generate_question": "EMR 连接器可以直接从 Kinesis 串流中读取和查询数据吗？", "generate_answer": "是的，EMR 连接器支持 EMR 直接从 Kinesis 串流读取和查询数据。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器支持什么功能？\n", "origin_answer": "该连接器支持 EMR 直接从 Kinesis 串流读取和查询数据。现在，您可以使用现有的 Hadoop 生态系统工具，如 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading，来执行 Kinesis 串流的批处理。\n", "generate_question": "通过 EMR 连接器，可以在 Kinesis 上执行哪些操作？", "generate_answer": "通过 EMR 连接器，可以在 Kinesis 上执行批处理操作，使用 Hive、Pig、MapReduce、Hadoop Streaming 和 Cascading 等工具进行数据处理。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？\n", "origin_answer": "读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。\n", "generate_question": "为什么使用 EMR 连接器可以简化读取和处理来自 Kinesis 串流的数据的过程？", "generate_answer": "使用 EMR 连接器，您只需要编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流，而无需开发或维护一组新的处理应用程序。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？\n", "origin_answer": "读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。\n", "generate_question": "使用 EMR 连接器可以使用哪些工具来分析 Kinesis 串流？", "generate_answer": "使用 EMR 连接器，您可以使用 SQL 或其他 Hadoop 生态系统工具来分析 Kinesis 串流。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？\n", "origin_answer": "读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。\n", "generate_question": "使用 EMR 连接器需要耗费多少时间和精力？", "generate_answer": "使用 EMR 连接器可以节省大量的时间和精力，因为您不需要编写、部署和维护独立的流式处理应用程序。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？\n", "origin_answer": "读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。\n", "generate_question": "使用 EMR 连接器可以实现对 Kinesis 串流的哪些操作？", "generate_answer": "使用 EMR 连接器，您可以读取和处理来自 Kinesis 串流的数据，并进行分析和查询。"}
{"origin_question": "\n添加到 Kinesis 上去的 EMR 连接器能支持我完成哪些之前无法完成的任务？\n", "origin_answer": "读取和处理来自 Kinesis 串流的数据要求您编写、部署和维持独立的流式处理应用程序。这些需要耗费大量的时间和精力。但是，使用此连接器，您编写一个简单的 Hive 或 Pig 脚本就可以开始读取和分析 Kinesis 串流。这意味着，您可以使用 SQL 来分析 Kinesis 串流。 当然，也可以使用其他 Hadoop 生态系统工具。您不必开发或维护一组新的处理应用程序。\n", "generate_question": "使用 EMR 连接器需要具备哪些编程技能？", "generate_answer": "使用 EMR 连接器，您需要具备编写简单的 Hive 或 Pig 脚本的技能，以便读取和分析 Kinesis 串流的数据。"}
{"origin_question": "\n此功能对哪些人有用？\n", "origin_answer": "此功能对以下各类用户有用：\n\n对使用此广泛的 Hadoop 生态系统工具来分析 Kinesis 串流有兴趣的 Hadoop 用户。\n正在寻求简单地方法来增强性能和正在运行 Kinesis 数据的流处理和 ETL（提取、转换和加载）的 Kinesis 用户。\n希望使用熟悉的工具，如 SQL（通过 Hive）或脚本撰写语言，如 Pig，对 Kinesis 串流中的数据执行临时分析的商业分析师和 IT 专业人员。", "generate_question": "对于哪些用户来说，此功能是有用的？", "generate_answer": "此功能对以下几类用户是有用的：使用 Hadoop 生态系统工具来分析 Kinesis 串流的用户、正在寻求提升性能并处理 Kinesis 数据流的用户、希望使用 SQL 或脚本语言对 Kinesis 串流数据进行临时分析的商业分析师和 IT 专业人员。"}
{"origin_question": "\n此功能对哪些人有用？\n", "origin_answer": "此功能对以下各类用户有用：\n\n对使用此广泛的 Hadoop 生态系统工具来分析 Kinesis 串流有兴趣的 Hadoop 用户。\n正在寻求简单地方法来增强性能和正在运行 Kinesis 数据的流处理和 ETL（提取、转换和加载）的 Kinesis 用户。\n希望使用熟悉的工具，如 SQL（通过 Hive）或脚本撰写语言，如 Pig，对 Kinesis 串流中的数据执行临时分析的商业分析师和 IT 专业人员。", "generate_question": "为什么 Hadoop 用户会对此功能感兴趣？", "generate_answer": "Hadoop 用户对此功能感兴趣是因为他们可以使用广泛的 Hadoop 生态系统工具来分析 Kinesis 串流数据，从而提升数据分析的效率和准确性。"}
{"origin_question": "\n此功能对哪些人有用？\n", "origin_answer": "此功能对以下各类用户有用：\n\n对使用此广泛的 Hadoop 生态系统工具来分析 Kinesis 串流有兴趣的 Hadoop 用户。\n正在寻求简单地方法来增强性能和正在运行 Kinesis 数据的流处理和 ETL（提取、转换和加载）的 Kinesis 用户。\n希望使用熟悉的工具，如 SQL（通过 Hive）或脚本撰写语言，如 Pig，对 Kinesis 串流中的数据执行临时分析的商业分析师和 IT 专业人员。", "generate_question": "为什么 Kinesis 用户会对此功能感兴趣？", "generate_answer": "Kinesis 用户对此功能感兴趣是因为他们可以通过此功能简化流处理和 ETL（提取、转换和加载）过程，提升数据处理的性能和效率。"}
{"origin_question": "\n此功能对哪些人有用？\n", "origin_answer": "此功能对以下各类用户有用：\n\n对使用此广泛的 Hadoop 生态系统工具来分析 Kinesis 串流有兴趣的 Hadoop 用户。\n正在寻求简单地方法来增强性能和正在运行 Kinesis 数据的流处理和 ETL（提取、转换和加载）的 Kinesis 用户。\n希望使用熟悉的工具，如 SQL（通过 Hive）或脚本撰写语言，如 Pig，对 Kinesis 串流中的数据执行临时分析的商业分析师和 IT 专业人员。", "generate_question": "商业分析师和 IT 专业人员为什么会对此功能感兴趣？", "generate_answer": "商业分析师和 IT 专业人员对此功能感兴趣是因为他们可以使用熟悉的工具（如 SQL 或脚本语言）对 Kinesis 串流中的数据进行临时分析，从而更好地理解和利用数据。"}
{"origin_question": "\n此功能对哪些人有用？\n", "origin_answer": "此功能对以下各类用户有用：\n\n对使用此广泛的 Hadoop 生态系统工具来分析 Kinesis 串流有兴趣的 Hadoop 用户。\n正在寻求简单地方法来增强性能和正在运行 Kinesis 数据的流处理和 ETL（提取、转换和加载）的 Kinesis 用户。\n希望使用熟悉的工具，如 SQL（通过 Hive）或脚本撰写语言，如 Pig，对 Kinesis 串流中的数据执行临时分析的商业分析师和 IT 专业人员。", "generate_question": "除了使用 SQL 和脚本语言，还有其他工具可以对 Kinesis 串流数据进行分析吗？", "generate_answer": "除了使用 SQL（通过 Hive）和脚本语言（如 Pig），商业分析师和 IT 专业人员还可以使用其他工具来对 Kinesis 串流数据进行分析，具体取决于他们的需求和技术偏好。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "亚马逊云科技的集成支持哪些使用案例？", "generate_answer": "亚马逊云科技的集成支持以下代表性使用案例：流处理日志分析、复杂数据处理工作流和临时查询。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "如何使用亚马逊云科技的集成进行流处理日志分析？", "generate_answer": "使用亚马逊云科技的集成，您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "亚马逊云科技的集成如何处理复杂数据处理工作流？", "generate_answer": "亚马逊云科技的集成可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "如何使用亚马逊云科技的集成进行临时查询？", "generate_answer": "使用亚马逊云科技的集成，您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "亚马逊云科技的集成还支持其他使用案例吗？", "generate_answer": "亚马逊云科技的集成还支持其他使用案例，但以上提到的流处理日志分析、复杂数据处理工作流和临时查询是其中的代表性案例。"}
{"origin_question": "\n这种集成有哪些使用案例？\n", "origin_answer": "以下为此集成支持的代表性使用案例：\n\n流处理日志分析：您可以按地区、浏览器和访问域分析流处理网页日志，以便每隔几分钟生成一个 10 大类错误列表。\n复杂数据处理工作流：您可以将存储在 S3、Dynamo DB 表和 HDFS 中的数据加入到 Kinesis 串流中。您可以编写加入了来自 Kinesis 的点击流数据并将广告活动信息存储在 DynamoDB 表中的查询，以识别各特定网站上显示的最有效的广告类别。\n临时查询：您可以定期将来自 Kinesis 的数据加载到 HDFS 中并作为本地 Impala 表推出，用于快速交互式分析查询。", "generate_question": "亚马逊云科技的集成可以处理哪些类型的数据？", "generate_answer": "亚马逊云科技的集成可以处理存储在 S3、Dynamo DB 表和 HDFS 中的数据，并将其加入到 Kinesis 串流中进行处理。"}
{"origin_question": "\n要使用此连接器，我需要使用什么 EMR AMI 版本？\n", "origin_answer": "您需要使用 EMR AMI 的版本 3.0.4 和更新的版本。\n", "generate_question": "亚马逊云科技的 EMR AMI 版本有哪些？", "generate_answer": "亚马逊云科技的 EMR AMI 版本包括 3.0.4 和更新的版本。"}
{"origin_question": "\n要使用此连接器，我需要使用什么 EMR AMI 版本？\n", "origin_answer": "您需要使用 EMR AMI 的版本 3.0.4 和更新的版本。\n", "generate_question": "亚马逊云科技的 EMR AMI 版本更新了哪些内容？", "generate_answer": "亚马逊云科技的 EMR AMI 版本更新了一些功能和修复了一些问题，具体更新内容请参考版本更新说明。"}
{"origin_question": "\n此连接器是独立的工具吗？\n", "origin_answer": "不是，它是 Amazon Hadoop 分配的内置组件，EMR AMI 的版本 3.0.4 及更新版本上提供此组件。客户只需使用版本 3.0.4 或更新版本的 AMI 快速构建一个群集就可以开始使用此功能。\n", "generate_question": "亚马逊云科技的此连接器是什么工具？", "generate_answer": "此连接器是 Amazon Hadoop 分配的内置组件。"}
{"origin_question": "\n此连接器是独立的工具吗？\n", "origin_answer": "不是，它是 Amazon Hadoop 分配的内置组件，EMR AMI 的版本 3.0.4 及更新版本上提供此组件。客户只需使用版本 3.0.4 或更新版本的 AMI 快速构建一个群集就可以开始使用此功能。\n", "generate_question": "在哪个版本的 AMI 上提供了此连接器？", "generate_answer": "此连接器在版本 3.0.4 及更新版本的 AMI 上提供。"}
{"origin_question": "\n此连接器是独立的工具吗？\n", "origin_answer": "不是，它是 Amazon Hadoop 分配的内置组件，EMR AMI 的版本 3.0.4 及更新版本上提供此组件。客户只需使用版本 3.0.4 或更新版本的 AMI 快速构建一个群集就可以开始使用此功能。\n", "generate_question": "如何开始使用此连接器？", "generate_answer": "客户只需使用版本 3.0.4 或更新版本的 AMI 快速构建一个群集就可以开始使用此功能。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成支持读取哪种数据格式？", "generate_answer": "EMR Kinesis 集成不指定数据格式，可以读取任何格式的数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成如何处理 Kinesis 记录？", "generate_answer": "EMR Kinesis 集成将 Kinesis 记录作为标准记录呈递给 Hadoop，可以使用任何 Hadoop MapReduce 框架进行读取。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成内置了哪些框架来帮助序列化和还原序列化数据？", "generate_answer": "EMR Kinesis 集成内置了 Hive、Pig 和 Cascading 等框架来帮助序列化和还原序列化数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成中的 Hive 如何读取不同格式的数据？", "generate_answer": "Hive 用户可以通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成中的 Pig 有哪些组件用于读取不同格式的数据？", "generate_answer": "Pig 拥有 Loadfunc/Evalfunc 组件，可以用于读取不同格式的数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成中的 Cascading 有哪些组件用于读取不同格式的数据？", "generate_answer": "Cascading 拥有 Tap 组件，可以用于读取不同格式的数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成是否需要编写格式专用代码来读取数据？", "generate_answer": "不需要，EMR Kinesis 集成提供了广泛的 Hadoop 适配器生态系统，可以无需编写格式专用代码来读取数据。"}
{"origin_question": "\n支持 EMR 从 Kinesis 串流读取数据需要哪种数据格式？\n", "origin_answer": "EMR Kinesis 集成不指定数据格式。您可以读取任何格式的数据。个别 Kinesis 记录作为标准记录呈递给 Hadoop，该记录可使用任何 Hadoop MapReduce 框架进行读取。Hive、Pig 和 Cascading 等个别框架已内置在帮助序列化和还原序列化的组件中，从而使开发人员能够轻松查询多种格式的数据，而无需实施自定义代码。例如，Hive 用户可通过在定义表时指定适当的 Hive SerDe 来从 JSON 文件、XML 文件和 SEQ 文件读取数据。Pig 拥有的类似组件称为 Loadfunc/Evalfunc，而 Cascading 的类似组件称为 Tap。Hadoop 用户可以利用这种广泛的 Hadoop 适配器生态系统，无需编写格式专用代码。您还可以实施自定义还原序列化格式来读取其中任何一个工具的域专用数据。\n", "generate_question": "亚马逊云科技的 EMR Kinesis 集成是否支持实施自定义还原序列化格式来读取数据？", "generate_answer": "是的，可以实施自定义还原序列化格式来读取数据。"}
{"origin_question": "\n在 EMR 中，如何使用 Hive 来分析 Kinesis 串流？\n", "origin_answer": "创建一个引用 Kinesis 串流的表。然后，您可以像分析 Hive 中的其他任何表一样分析此表。请参阅我们的教程页面了解更多详情。\n", "generate_question": "在亚马逊云科技的 EMR 中，如何创建一个引用 Kinesis 串流的表？", "generate_answer": "在 EMR 中，您可以通过创建一个引用 Kinesis 串流的表来使用 Hive 来分析该串流。具体操作方法可以参考亚马逊云科技的教程页面。"}
{"origin_question": "\n在 EMR 中，如何使用 Hive 来分析 Kinesis 串流？\n", "origin_answer": "创建一个引用 Kinesis 串流的表。然后，您可以像分析 Hive 中的其他任何表一样分析此表。请参阅我们的教程页面了解更多详情。\n", "generate_question": "除了 Kinesis 串流，还可以在 EMR 中使用 Hive 分析哪些数据源？", "generate_answer": "在 EMR 中，除了 Kinesis 串流，您还可以使用 Hive 分析其他任何表。EMR 提供了丰富的功能和工具，使您能够对各种数据源进行分析和处理。具体的数据源可以参考亚马逊云科技的文档和教程。"}
{"origin_question": "\n使用 Hive 时，如何创建结合了 Kinesis 串流数据和其他数据源的查询？\n", "origin_answer": "首先，创建一个引用 Kinesis 串流的表。Hive 表创建好后，您可以将它与映射到其他数据源（如 Amazon S3、Amazon Dynamo DB 和 HDFS）的表结合起来。这会有效地将来自 Kinesis 串流的数据加入到其他数据源中。\n", "generate_question": "在使用 Hive 时，如何创建一个引用 Kinesis 串流的表？", "generate_answer": "在使用 Hive 时，可以通过创建一个表来引用 Kinesis 串流。首先，需要使用 Hive 的 CREATE TABLE 语句来创建一个表，然后在表的定义中指定 Kinesis 串流的相关信息，如数据源和数据格式等。"}
{"origin_question": "\n使用 Hive 时，如何创建结合了 Kinesis 串流数据和其他数据源的查询？\n", "origin_answer": "首先，创建一个引用 Kinesis 串流的表。Hive 表创建好后，您可以将它与映射到其他数据源（如 Amazon S3、Amazon Dynamo DB 和 HDFS）的表结合起来。这会有效地将来自 Kinesis 串流的数据加入到其他数据源中。\n", "generate_question": "在 Hive 中如何将 Kinesis 串流数据与其他数据源结合起来进行查询？", "generate_answer": "在 Hive 中，可以将 Kinesis 串流数据与其他数据源结合起来进行查询。首先，需要创建一个引用 Kinesis 串流的表，然后可以将该表与映射到其他数据源的表进行结合。这样可以将来自 Kinesis 串流的数据有效地加入到其他数据源中，从而进行更全面的查询分析。"}
{"origin_question": "\n使用 Hive 时，如何创建结合了 Kinesis 串流数据和其他数据源的查询？\n", "origin_answer": "首先，创建一个引用 Kinesis 串流的表。Hive 表创建好后，您可以将它与映射到其他数据源（如 Amazon S3、Amazon Dynamo DB 和 HDFS）的表结合起来。这会有效地将来自 Kinesis 串流的数据加入到其他数据源中。\n", "generate_question": "Hive 中如何将来自 Kinesis 串流的数据加入到其他数据源中？", "generate_answer": "在 Hive 中，可以通过创建一个引用 Kinesis 串流的表，并将其与其他数据源的表结合起来，来将来自 Kinesis 串流的数据加入到其他数据源中。首先，需要使用 Hive 的 CREATE TABLE 语句创建一个表，然后在表的定义中指定 Kinesis 串流的相关信息。接下来，可以使用 Hive 的 INSERT INTO 语句将 Kinesis 串流数据插入到其他数据源的表中，从而实现数据的整合和加入。"}
{"origin_question": "\n此集成仅用于 Hive 吗？\n", "origin_answer": "不是，您可以使用 Hive、Pig、MapReduce、Hadoop 流以及 Cascading。\n", "generate_question": "亚马逊云科技的集成可以支持哪些数据处理工具？", "generate_answer": "亚马逊云科技的集成不仅仅支持Hive，还可以使用Pig、MapReduce、Hadoop流以及Cascading。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "什么是 EMR Kinesis 输入连接器？", "generate_answer": "EMR Kinesis 输入连接器是一个工具，用于配置和管理在 Kinesis 串流上运行的既定周期性任务。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "如何设置一个每 N 分钟运行一次的 Hive 脚本？", "generate_answer": "在任务的配置参数中，您可以为任务指定一个逻辑名称，并在每次运行任务后增加一个迭代，从而实现每 N 分钟运行一次的 Hive 脚本。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "什么是逻辑名称？", "generate_answer": "逻辑名称是一个标签，用于通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "为什么要将连续的 Kinesis 串流分割成数批？", "generate_answer": "因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，需要将连续的串流分割成数批。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "什么是迭代？", "generate_answer": "每个批次称为一个迭代，每个迭代分配一个以 0 开头的号码，并由起始序列号和结尾序列号定义。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "如果一次尝试发生故障，EMR Kinesis 输入连接器会怎么处理？", "generate_answer": "如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代，从该迭代的已知起始序列号开始，确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "为什么重试功能可以确保 Kinesis 串流的幂等处理？", "generate_answer": "重试功能可以确保 Kinesis 串流的幂等处理，因为同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "如何在 Hadoop 工具中指定逻辑名称和迭代？", "generate_answer": "您可以在相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "EMR Kinesis 输入连接器如何按顺序处理迭代？", "generate_answer": "EMR Kinesis 输入连接器会按顺序处理迭代，从起始序列号到结尾序列号。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "EMR Kinesis 输入连接器提供了哪些功能？", "generate_answer": "EMR Kinesis 输入连接器提供了配置和管理传统调度引擎中的既定周期性任务的功能。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "什么是幂等处理？", "generate_answer": "幂等处理是指对同一操作的多次执行具有相同的结果，不会产生额外的影响。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "什么是 MapReduce？", "generate_answer": "MapReduce 是一种用于处理大规模数据集的编程模型和软件框架。"}
{"origin_question": "\n如何设置要在 Kinesis 串流上运行的既定任务？\n", "origin_answer": "EMR Kinesis 输入连接器提供各种功能，帮助您配置和管理传统调度引擎（如 Cron）中的既定周期性任务。例如，您可以开发一个每 N 分钟运行一次的 Hive 脚本。在任务的配置参数中，您可以为任务指定一个逻辑名称。逻辑名称是一个标签，会通知 EMR Kinesis 输入连接器该任务的单个实例是同一周期性调度的成员。逻辑名称允许该过程利用迭代，我们接下来将对其予以解释。\n\n因为 MapReduce 是批处理框架，所以要使用 EMR 来分析 Kinesis 串流，连续的串流就需分割成数批。每个批次称为一个迭代。每个迭代分配一个以 0 开头的号码。每个迭代的边界由起始序列号和结尾序列号定义。然后 EMR 会按顺序处理迭代。\n\n如果一次尝试发生故障，EMR Kinesis 输入连接器将在逻辑名称内重试该迭代（从该迭代的已知起始序列号开始）。此功能确保同一迭代的连续尝试与之前的尝试具有准确相同的 Kinesis 串流输入记录。这就确保了 Kinesis 串流的幂等（一致性）处理。\n\n您可以在您相应的 Hadoop 工具中将逻辑名称和迭代指定为运行时参数。例如，在教程的“使用检查点运行查询”部分中，代码示例显示了一个预定的 Hive 查询，后者为查询指定逻辑名称，并且在每次运行任务后增加一个迭代。\n\n此外，该教程中还提供了一个示例 Cron 调度脚本。\n", "generate_question": "EMR Kinesis 输入连接器适用于哪种类型的任务？", "generate_answer": "EMR Kinesis 输入连接器适用于需要在 Kinesis 串流上运行的既定周期性任务。"}
{"origin_question": "\n逻辑名称的元数据和迭代存储在何处？\n", "origin_answer": "允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据存储在 Amazon DynamoDB 中。您必须预配置一个 Amazon Dynamo DB 表并指定其作为 Hadoop 任务的输入参数。注意：您要为该表配置合适的 IOPS 来支持此集成。请参阅入门教程，了解有关设置 Amazon Dynamo DB 表的更多信息。\n", "generate_question": "在哪里存储了允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据？", "generate_answer": "元数据存储在 Amazon DynamoDB 中。"}
{"origin_question": "\n逻辑名称的元数据和迭代存储在何处？\n", "origin_answer": "允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据存储在 Amazon DynamoDB 中。您必须预配置一个 Amazon Dynamo DB 表并指定其作为 Hadoop 任务的输入参数。注意：您要为该表配置合适的 IOPS 来支持此集成。请参阅入门教程，了解有关设置 Amazon Dynamo DB 表的更多信息。\n", "generate_question": "为了使用 EMR Kinesis 输入连接器在既定的周期性工作流中使用元数据，需要预配置哪个服务？", "generate_answer": "需要预配置 Amazon DynamoDB。"}
{"origin_question": "\n逻辑名称的元数据和迭代存储在何处？\n", "origin_answer": "允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据存储在 Amazon DynamoDB 中。您必须预配置一个 Amazon Dynamo DB 表并指定其作为 Hadoop 任务的输入参数。注意：您要为该表配置合适的 IOPS 来支持此集成。请参阅入门教程，了解有关设置 Amazon Dynamo DB 表的更多信息。\n", "generate_question": "在使用 EMR Kinesis 输入连接器时，需要为哪个表配置合适的 IOPS？", "generate_answer": "需要为 Amazon DynamoDB 表配置合适的 IOPS。"}
{"origin_question": "\n逻辑名称的元数据和迭代存储在何处？\n", "origin_answer": "允许 EMR Kinesis 输入连接器在既定的周期性工作流中使用的元数据存储在 Amazon DynamoDB 中。您必须预配置一个 Amazon Dynamo DB 表并指定其作为 Hadoop 任务的输入参数。注意：您要为该表配置合适的 IOPS 来支持此集成。请参阅入门教程，了解有关设置 Amazon Dynamo DB 表的更多信息。\n", "generate_question": "如何了解有关设置 Amazon DynamoDB 表的更多信息？", "generate_answer": "可以参阅入门教程，了解有关设置 Amazon DynamoDB 表的更多信息。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "在 Kinesis 串流中，迭代处理失败会导致什么结果？", "generate_answer": "当迭代处理失败时，Kinesis 串流会自动运行 MapReduce 任务的映射相位（默认情况下运行三次）。如果重试失败，您可以选择从最后一次成功或通过的数据边界开始重试处理过程。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "如何控制处理期间迭代处理失败的行为？", "generate_answer": "您可以通过提供 kinesis.checkpoint.iteration.no 参数来控制处理期间迭代处理失败的行为。具体配置方法可以参考入门教程中关于如何为 Hadoop 生态系统中的不同工具配置该值的信息。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "迭代标识符在 Kinesis 串流中的作用是什么？", "generate_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "Kinesis 串流中的迭代处理是如何工作的？", "generate_answer": "Kinesis 串流中的迭代处理是通过自动运行 MapReduce 任务的映射相位来实现的。如果任务发生故障，它将自动运行三次。如果重试失败，您可以选择从最后一次成功或通过的数据边界开始重试处理过程。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "什么是数据边界？", "generate_answer": "数据边界是指在 Kinesis 串流中的指定边界，对应着 MapReduce 任务的映射相位中的数据。当迭代处理失败时，您可以选择从最后一次成功或通过的数据边界开始重试处理过程。"}
{"origin_question": "\n当迭代处理失败时，会出现什么情况？\n", "origin_answer": "在 Kinesis 串流中，迭代标识符是用户提供的映射到指定边界（开头和结尾序列号）的值。这些边界对应的数据位于 MapReduce 任务的映射相位。此相位由框架管理，如果任务发生故障，它将自动运行（默认情况下运行三次）。如果重试失败，您仍可以选择从最后一次成功或通过的数据边界开始重试处理过程。处理期间，此行为通过提供 kinesis.checkpoint.iteration.no 参数来控制。请参考入门教程了解更多有关如何为 Hadoop 生态系统中的不同工具配置该值的信息。\n", "generate_question": "如何配置 kinesis.checkpoint.iteration.no 参数？", "generate_answer": "具体配置 kinesis.checkpoint.iteration.no 参数的方法可以参考入门教程中关于如何为 Hadoop 生态系统中的不同工具配置该值的信息。"}
{"origin_question": "\n是否能在同一迭代中运行多个查询？\n", "origin_answer": "可以，您可以通过在连续处理过程中设定 kinesis.checkpoint.iteration.no 参数来指定之前运行的迭代。该实施确保同一迭代的连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。\n", "generate_question": "如何在同一迭代中运行多个查询？", "generate_answer": "您可以通过在连续处理过程中设定 kinesis.checkpoint.iteration.no 参数来指定之前运行的迭代。这样做可以确保同一迭代的连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。"}
{"origin_question": "\n是否能在同一迭代中运行多个查询？\n", "origin_answer": "可以，您可以通过在连续处理过程中设定 kinesis.checkpoint.iteration.no 参数来指定之前运行的迭代。该实施确保同一迭代的连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。\n", "generate_question": "在连续处理过程中，如何保证同一迭代的运行与之前的运行具有相同的 Kinesis 串流输入记录？", "generate_answer": "您可以通过设定 kinesis.checkpoint.iteration.no 参数来实现，在同一迭代中运行多个查询，并确保连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。"}
{"origin_question": "\n是否能在同一迭代中运行多个查询？\n", "origin_answer": "可以，您可以通过在连续处理过程中设定 kinesis.checkpoint.iteration.no 参数来指定之前运行的迭代。该实施确保同一迭代的连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。\n", "generate_question": "有没有办法在同一迭代中运行多个查询，同时保持与之前运行的迭代相同的 Kinesis 串流输入记录？", "generate_answer": "是的，您可以通过设置 kinesis.checkpoint.iteration.no 参数来实现在同一迭代中运行多个查询，并确保连续运行与之前的运行具有准确相同的 Kinesis 串流输入记录。"}
{"origin_question": "\n如果迭代中的记录在 Kinesis 串流中到期失效，会出现什么情况？\n", "origin_answer": "如果迭代的开始序列号和/或结尾序列号属于已在 Kinesis 串流中到期失效的记录，则 Hadoop 任务会失败。您将需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。\n", "generate_question": "如果迭代中的记录在 Kinesis 串流中到期失效，会导致什么结果？", "generate_answer": "如果迭代中的记录在 Kinesis 串流中到期失效，那么在处理 Kinesis 串流的 Hadoop 任务时会失败。"}
{"origin_question": "\n如果迭代中的记录在 Kinesis 串流中到期失效，会出现什么情况？\n", "origin_answer": "如果迭代的开始序列号和/或结尾序列号属于已在 Kinesis 串流中到期失效的记录，则 Hadoop 任务会失败。您将需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。\n", "generate_question": "如果迭代的开始序列号和结尾序列号都属于已在 Kinesis 串流中到期失效的记录，应该如何处理 Kinesis 串流的开始数据？", "generate_answer": "如果迭代的开始序列号和结尾序列号都属于已在 Kinesis 串流中到期失效的记录，您需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。"}
{"origin_question": "\n如果迭代中的记录在 Kinesis 串流中到期失效，会出现什么情况？\n", "origin_answer": "如果迭代的开始序列号和/或结尾序列号属于已在 Kinesis 串流中到期失效的记录，则 Hadoop 任务会失败。您将需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。\n", "generate_question": "在处理 Kinesis 串流的 Hadoop 任务时，如果迭代的开始序列号或结尾序列号属于已在 Kinesis 串流中到期失效的记录，会发生什么？", "generate_answer": "如果迭代的开始序列号和/或结尾序列号属于已在 Kinesis 串流中到期失效的记录，那么处理 Kinesis 串流的 Hadoop 任务会失败。您将需要使用其他逻辑名称来处理 Kinesis 串流的开始数据。"}
{"origin_question": "\n能否将数据从 EMR 推送到 Kinesis 串流中？\n", "origin_answer": "目前，EMR Kinesis 连接器不支持将数据回写到 Kinesis 串流中。\n", "generate_question": "EMR Kinesis 连接器支持哪些数据推送功能？", "generate_answer": "EMR Kinesis 连接器支持将数据从 Kinesis 串流读取到 EMR 中进行处理和分析。"}
{"origin_question": "\n能否将数据从 EMR 推送到 Kinesis 串流中？\n", "origin_answer": "目前，EMR Kinesis 连接器不支持将数据回写到 Kinesis 串流中。\n", "generate_question": "除了 EMR Kinesis 连接器，还有其他方式可以将数据从 EMR 推送到 Kinesis 串流中吗？", "generate_answer": "目前，EMR Kinesis 连接器是亚马逊云科技提供的官方工具，用于将数据从 Kinesis 串流读取到 EMR 中。其他方式可能需要自行开发或使用第三方工具。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "Kinesis 的 EMR Hadoop 输入连接器支持哪些框架？", "generate_answer": "Kinesis 的 EMR Hadoop 输入连接器支持 Hadoop 生态系统框架，如 Twitter Storm 和 Spark 流。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "Kinesis 的 EMR Hadoop 输入连接器是否支持连续流处理？", "generate_answer": "不支持。Hadoop MapReduce 框架是一个批处理系统，不支持连续查询。但是，可以使用其他框架如 Twitter Storm 和 Spark 流来支持连续流处理。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "如何获取 Kinesis 的 Storm 连接器？", "generate_answer": "您可以在 GitHub 上获取 Kinesis 的 Storm 连接器。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "如何在 EMR 上设置 Spark 流和运行连续查询？", "generate_answer": "您可以在 GitHub 上找到有关如何在 EMR 上设置 Spark 流和运行连续查询的教程。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "除了使用 EMR Hadoop 输入连接器，还有其他方法可以开发实时流处理应用程序吗？", "generate_answer": "是的，开发人员可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在 Kinesis 文档中找到更多有关开发自定义 Kinesis 应用程序的信息。"}
{"origin_question": "\nKinesis 的 EMR Hadoop 输入连接器支持连续流处理吗？\n", "origin_answer": "Hadoop MapReduce 框架是一个批处理系统。因此，不支持连续查询。然而，有一组新兴的 Hadoop 生态系统框架，例如 Twitter Storm 和 Spark 流，可支持开发人员构建适用于连续流处理的应用程序。Kinesis 的 Storm 连接器可在此处的 GitHub 上获取，您还可以在此处找到解释如何在 EMR 上设置 Spark 流和运行连续查询的教程。\n\n此外，开发人员还可以利用 Kinesis 客户端库来开发实时流处理应用程序。您可以在此处的 Kinesis 文档中查找更多有关开发自定义 Kinesis 应用程序的信息。\n", "generate_question": "在哪里可以找到有关开发自定义 Kinesis 应用程序的更多信息？", "generate_answer": "您可以在 Kinesis 文档中找到更多有关开发自定义 Kinesis 应用程序的信息。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "如何指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？", "generate_answer": "可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "Kinesis 连接器使用的是哪些访问凭证？", "generate_answer": "Kinesis 连接器默认使用用户在创建群集时指定的访问凭证。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "如何在 Hive 中设置 kinesis.accessKey 和 kinesis.secretKey 参数？", "generate_answer": "在 Hive 中，可以通过在 TBLPROPERTIES 中设置 \"kinesis.accessKey\" 和 \"kinesis.secretKey\" 参数来指定 kinesis 的访问凭证。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "如何在 Pig 中设置 kinesis.accessKey 和 kinesis.secretKey 参数？", "generate_answer": "在 Pig 中，可以通过在 com.amazon.emr.kinesis.pig.KinesisStreamLoader 中使用 kinesis.accessKey 和 kinesis.secretKey 参数来设置 kinesis 的访问凭证。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "kinesis.accessKey 和 kinesis.secretKey 参数的作用是什么？", "generate_answer": "kinesis.accessKey 和 kinesis.secretKey 参数用于指定访问凭证，以便从其他 AWS 账户访问 Kinesis 串流的流数据。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "是否可以从其他 AWS 账户读取流数据？", "generate_answer": "是的，可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "是否可以覆盖默认的访问凭证？", "generate_answer": "是的，可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖默认的访问凭证。"}
{"origin_question": "\n是否能指定访问凭证来读取由其他 AWS 账户管理的 Kinesis 串流？\n", "origin_answer": "可以。您可以通过为拥有该 Kinesis 串流的账户指定适当访问凭证来从其他 AWS 账户读取流数据。默认情况下，Kinesis 连接器使用的是用户在创建群集时指定的访问凭证。您可以通过设置 kinesis.accessKey 和 kinesis.secretKey 参数来覆盖这些凭证，以便从其他 AWS 账户访问流数据。以下示例显示了在 Hive 和 Pig 中如何设置 kinesis.accessKey 和 kinesis.secretKey 参数。\n\nHive 代码示例：\n...\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n\nPig 代码示例：\n…\nraw_logs = LOAD 'AccessLogStream' USING com.amazon.emr.kinesis.pig.Kin\nesisStreamLoader('kinesis.accessKey=AwsAccessKey', 'kinesis.secretKey=AwsSecretKey'\n) AS (line:chararray);\n", "generate_question": "请举例说明如何在 Hive 中设置 kinesis.accessKey 和 kinesis.secretKey 参数。", "generate_answer": "在 Hive 中，可以在 TBLPROPERTIES 中设置 \"kinesis.accessKey\" 和 \"kinesis.secretKey\" 参数，例如：\n```\nSTORED BY\n'com.amazon.emr.kinesis.hive.KinesisStorageHandler'\nTBLPROPERTIES(\n\"kinesis.accessKey\"=\"AwsAccessKey\",\n\"kinesis.secretKey\"=\"AwsSecretKey\",\n);\n```"}
{"origin_question": "\n能否在 EMR 中加入并分析多个 Kinesis 串流？\n", "origin_answer": "可以，例如在 Hive 中，您可以创建两个映射到不同 Kinesis 串流的表并在两个表之间创建连接。\n", "generate_question": "在 EMR 中可以加入和分析多少个 Kinesis 串流？", "generate_answer": "在 EMR 中可以加入和分析多个 Kinesis 串流。"}
{"origin_question": "\n能否在 EMR 中加入并分析多个 Kinesis 串流？\n", "origin_answer": "可以，例如在 Hive 中，您可以创建两个映射到不同 Kinesis 串流的表并在两个表之间创建连接。\n", "generate_question": "在 EMR 中如何在两个表之间创建连接以分析不同的 Kinesis 串流？", "generate_answer": "在 Hive 中，您可以创建两个映射到不同 Kinesis 串流的表，并在两个表之间创建连接。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "EMR Kinesis 连接器能够处理哪些 Kinesis 扩展活动？", "generate_answer": "EMR Kinesis 连接器能够处理 Kinesis 的拆分和合并活动。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "Kinesis 连接器是如何处理 Kinesis 扩展活动的？", "generate_answer": "Kinesis 连接器将单个 Kinesis 碎片与 Hadoop MapReduce 映射任务相联系，并在迭代的逻辑周期内为每个唯一碎片生成一个映射任务。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "如果发生碎片拆分或合并活动，Kinesis 连接器会有什么反应？", "generate_answer": "如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID，并且 MapReduce 框架将预配置更多映射任务以从 Kinesis 读取内容。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "用户能否感知到 Kinesis 连接器处理拆分和合并活动的过程？", "generate_answer": "对用户来说，Kinesis 连接器处理拆分和合并活动的过程是透明的，用户无需感知。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "Kinesis 连接器如何处理 Kinesis 流内的扩展逻辑单元？", "generate_answer": "Kinesis 连接器将单个 Kinesis 碎片与 Hadoop MapReduce 映射任务相联系，每个唯一碎片都将生成一个确切的映射任务。"}
{"origin_question": "\nEMR Kinesis 连接器是否处理 Kinesis 扩展活动，如合并和拆分活动？\n", "origin_answer": "是的。该实施处理拆分和合并活动。Kinesis 连接器将单个 Kinesis 碎片（Kinesis 流内的扩展逻辑单元）与 Hadoop MapReduce 映射任务相联系。在迭代的逻辑周期内，流内的每个唯一碎片都将生成一个确切的映射任务。如果发生碎片拆分或合并活动，Kinesis 将配置新的唯一碎片 ID。结果，MapReduce 框架将预配置更多映射任务，以便从 Kinesis 读取内容。所有这些对用户都是透明的。\n", "generate_question": "Kinesis 连接器是否能够处理其他类型的活动，除了拆分和合并活动？", "generate_answer": "根据提供的信息，没有提到 Kinesis 连接器能够处理除拆分和合并活动之外的其他类型活动。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "如何配置亚马逊云科技的 Kinesis 连接器中的 kinesis.nodata.timeout 参数？", "generate_answer": "您可以通过设置 kinesis.nodata.timeout 参数来配置亚马逊云科技的 Kinesis 连接器。具体的配置方法请参考相关教程。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "如果我希望每隔一段时间运行一次 Hive 查询，该怎么做？", "generate_answer": "您可以通过设置 kinesis.nodata.timeout 参数和 kinesis.iteration.timeout 参数来实现每隔一段时间运行一次 Hive 查询。具体的配置方法请参考相关教程。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "在 Kinesis 连接器中，当没有新记录达到时会发生什么？", "generate_answer": "当没有新记录达到时，Kinesis 连接器会根据 kinesis.nodata.timeout 参数的设置来决定是否停止轮询并仅处理流的当前批次已读取的记录。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "如果在 kinesis.nodata.timeout 时间间隔用完之前有新记录达到，会发生什么？", "generate_answer": "如果在 kinesis.nodata.timeout 时间间隔用完之前有新记录达到，Kinesis 连接器会等待 kinesis.iteration.timeout 对应的额外时间间隔。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "如何定义 kinesis.nodata.timeout 参数和 kinesis.iteration.timeout 参数？", "generate_answer": "您可以在相关教程中找到如何定义 kinesis.nodata.timeout 参数和 kinesis.iteration.timeout 参数的详细信息。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "Kinesis 连接器会如何处理静默时段中已读取的记录？", "generate_answer": "在静默时段中，Kinesis 连接器会停止轮询并仅处理流的当前批次已读取的记录。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "是否可以自定义 kinesis.nodata.timeout 参数的值？", "generate_answer": "是的，您可以根据需要自定义 kinesis.nodata.timeout 参数的值。"}
{"origin_question": "\n如果我的流中存在一些“静默”时段，会怎么样？\n", "origin_answer": "该实施允许您配置名为 kinesis.nodata.timeout 的参数。例如，考虑这样一个情况，其中 kinesis.nodata.timeout 设为 2 分钟，同时您希望每隔 10 分钟运行一次 Hive 查询。此外，考虑自上次迭代后（10 分钟之前），一些数据已写入串流中。然而，目前没有新的记录达到，也就是说，串流内是静默的。在这种情况下，当查询的当前迭代启动时，Kinesis 连接器将发现没有即将达到的新记录。连接器将使该串流保持轮询 2 分钟，如果该时间内记录没有达到，则停止轮询并仅处理流的当前批次已读取的记录。但是，如果新记录在 kinesis.nodata.timeout 时间间隔用完之前达到，那么，连接器将等待参数 kinesis.iteration.timeout 对应的额外时间间隔。请查阅教程了解如何定义这些参数。\n", "generate_question": "是否可以自定义 kinesis.iteration.timeout 参数的值？", "generate_answer": "是的，您可以根据需要自定义 kinesis.iteration.timeout 参数的值。"}
{"origin_question": "\n如何调试在每次迭代中持续失败的查询？\n", "origin_answer": "如果处理发生故障，您在调试 Hadoop 任务时可以利用他们当前所用的工具。包括帮助识别和访问错误日志的 Amazon EMR Web 控制台。可在此处找到更多有关调试 EMR 任务的详细信息。\n", "generate_question": "在调试 Hadoop 任务时，如何利用 Amazon EMR Web 控制台帮助识别和访问错误日志？", "generate_answer": "您可以利用 Amazon EMR Web 控制台来帮助识别和访问错误日志，以调试 Hadoop 任务。具体的操作步骤可以在 Amazon EMR Web 控制台中找到，该控制台提供了更多关于调试 EMR 任务的详细信息。"}
{"origin_question": "\n如何调试在每次迭代中持续失败的查询？\n", "origin_answer": "如果处理发生故障，您在调试 Hadoop 任务时可以利用他们当前所用的工具。包括帮助识别和访问错误日志的 Amazon EMR Web 控制台。可在此处找到更多有关调试 EMR 任务的详细信息。\n", "generate_question": "为什么在每次迭代中的查询持续失败时，可以使用 Amazon EMR Web 控制台进行调试？", "generate_answer": "Amazon EMR Web 控制台提供了一些工具，可以帮助您调试 Hadoop 任务。当处理发生故障时，您可以利用这些工具来识别和访问错误日志，以解决查询持续失败的问题。"}
{"origin_question": "\n如何调试在每次迭代中持续失败的查询？\n", "origin_answer": "如果处理发生故障，您在调试 Hadoop 任务时可以利用他们当前所用的工具。包括帮助识别和访问错误日志的 Amazon EMR Web 控制台。可在此处找到更多有关调试 EMR 任务的详细信息。\n", "generate_question": "在调试 Hadoop 任务时，除了 Amazon EMR Web 控制台，还有其他工具可以使用吗？", "generate_answer": "除了 Amazon EMR Web 控制台，您还可以使用其他工具来调试 Hadoop 任务。具体的工具取决于您当前所用的环境和工具集，可以根据需要选择适合的工具来帮助您调试任务。"}
{"origin_question": "\n如果指定了没有访问权限的 DynamoDB 表，会出现什么情况？\n", "origin_answer": "任务会失败，此异常情况会显示任务的错误日志中。\n", "generate_question": "DynamoDB 表没有访问权限会导致任务失败的原因是什么？", "generate_answer": "DynamoDB 表没有访问权限会导致任务失败，因为没有权限访问表中的数据和执行相关操作。"}
{"origin_question": "\n如果指定了没有访问权限的 DynamoDB 表，会出现什么情况？\n", "origin_answer": "任务会失败，此异常情况会显示任务的错误日志中。\n", "generate_question": "如何解决指定了没有访问权限的 DynamoDB 表导致任务失败的问题？", "generate_answer": "要解决指定了没有访问权限的 DynamoDB 表导致任务失败的问题，需要为相应的用户或角色授予访问该表的权限，以确保任务能够成功执行。"}
{"origin_question": "\n如果任务没有失败，但是 DynamoDB 的检查点出现故障，会出现什么情况？\n", "origin_answer": "任务会失败，此异常情况会显示任务的错误日志中。\n", "generate_question": "如果任务没有失败，但是 DynamoDB 的检查点出现故障，会出现什么情况？", "generate_answer": "任务会失败，此异常情况会显示任务的错误日志中。"}
{"origin_question": "\n如果任务没有失败，但是 DynamoDB 的检查点出现故障，会出现什么情况？\n", "origin_answer": "任务会失败，此异常情况会显示任务的错误日志中。\n", "generate_question": "DynamoDB 的检查点故障会对任务的执行产生什么影响？", "generate_answer": "如果 DynamoDB 的检查点出现故障，任务会失败，并且错误日志中会显示该异常情况。"}
{"origin_question": "\n如何将从 Kinesis 串流到 EMR 的读取吞吐量最大化？\n", "origin_answer": "Kinesis 串流的吞吐量的增长随所用实例的大小以及 Kinesis 流中的记录大小而定。我们建议您使用 m1.xlarge 以及更大的实例，以确保将主要节点和核心节点用于此功能。 ", "generate_question": "如何将从 Kinesis 串流到 EMR 的读取吞吐量最大化？", "generate_answer": "Kinesis 串流的吞吐量的增长随所用实例的大小以及 Kinesis 流中的记录大小而定。我们建议您使用 m1.xlarge 以及更大的实例，以确保将主要节点和核心节点用于此功能。"}
{"origin_question": "\n如何将从 Kinesis 串流到 EMR 的读取吞吐量最大化？\n", "origin_answer": "Kinesis 串流的吞吐量的增长随所用实例的大小以及 Kinesis 流中的记录大小而定。我们建议您使用 m1.xlarge 以及更大的实例，以确保将主要节点和核心节点用于此功能。 ", "generate_question": "为什么使用 m1.xlarge 以及更大的实例可以最大化 Kinesis 串流到 EMR 的读取吞吐量？", "generate_answer": "使用 m1.xlarge 以及更大的实例可以最大化 Kinesis 串流到 EMR 的读取吞吐量，是因为这些实例具有更高的计算和存储能力，能够更有效地处理大量的数据记录。"}
{"origin_question": "\n如何将从 Kinesis 串流到 EMR 的读取吞吐量最大化？\n", "origin_answer": "Kinesis 串流的吞吐量的增长随所用实例的大小以及 Kinesis 流中的记录大小而定。我们建议您使用 m1.xlarge 以及更大的实例，以确保将主要节点和核心节点用于此功能。 ", "generate_question": "除了实例的大小，还有哪些因素会影响 Kinesis 串流到 EMR 的读取吞吐量？", "generate_answer": "除了实例的大小，Kinesis 串流到 EMR 的读取吞吐量还受到 Kinesis 流中的记录大小的影响。较大的记录大小可能会导致更长的处理时间，从而降低读取吞吐量。"}
{"origin_question": "\n什么是 Amazon EMR 服务等级协议？\n", "origin_answer": "请参阅我们的服务等级协议。\n", "generate_question": "Amazon EMR 服务等级协议的目的是什么？", "generate_answer": "Amazon EMR 服务等级协议的目的是确保亚马逊云科技提供的 EMR 服务能够满足客户的需求，并保证服务的可靠性和稳定性。"}
{"origin_question": "\n什么是 Amazon EMR 服务等级协议？\n", "origin_answer": "请参阅我们的服务等级协议。\n", "generate_question": "服务等级协议对于客户有什么作用？", "generate_answer": "服务等级协议为客户提供了一种保障，确保他们在使用 Amazon EMR 服务时能够获得一定的服务质量和可用性。"}
{"origin_question": "\n什么是 Amazon EMR 服务等级协议？\n", "origin_answer": "请参阅我们的服务等级协议。\n", "generate_question": "如何查看 Amazon EMR 服务等级协议的详细内容？", "generate_answer": "您可以参阅亚马逊云科技提供的服务等级协议，其中包含了关于 Amazon EMR 服务等级协议的详细信息。"}
{"origin_question": "\nAmazon EMR 服务等级协议提供了什么？\n", "origin_answer": "AWS 将采取商业上合理的措施，以确保在每种情况下，每个 AWS 区域，每项 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%（“服务承诺”）。", "generate_question": "Amazon EMR 服务等级协议保证了什么？", "generate_answer": "Amazon EMR 服务等级协议保证了每个 AWS 区域中 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%。"}
{"origin_question": "\nAmazon EMR 服务等级协议提供了什么？\n", "origin_answer": "AWS 将采取商业上合理的措施，以确保在每种情况下，每个 AWS 区域，每项 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%（“服务承诺”）。", "generate_question": "亚马逊云科技的服务承诺是多少？", "generate_answer": "亚马逊云科技的服务承诺是每个 AWS 区域中 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%。"}
{"origin_question": "\nAmazon EMR 服务等级协议提供了什么？\n", "origin_answer": "AWS 将采取商业上合理的措施，以确保在每种情况下，每个 AWS 区域，每项 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%（“服务承诺”）。", "generate_question": "亚马逊云科技如何确保 Amazon EMR 服务的正常运行时间？", "generate_answer": "亚马逊云科技将采取商业上合理的措施，以确保在每种情况下，每个 AWS 区域，每项 Amazon EMR 服务在任何月度结算周期的月度正常运行时间百分比至少达到 99.9%。"}
{"origin_question": "\n如果您没有满足服务承诺会出现什么情况？\n", "origin_answer": "如有任何 Amazon EMR 服务没有满足服务承诺，您将有资格获得服务抵扣。", "generate_question": "什么是 Amazon EMR 服务承诺？", "generate_answer": "Amazon EMR 服务承诺是指亚马逊云科技对于其提供的 Amazon EMR 服务的一种保证，即如果服务没有满足承诺，用户将有资格获得服务抵扣。"}
{"origin_question": "\n如果您没有满足服务承诺会出现什么情况？\n", "origin_answer": "如有任何 Amazon EMR 服务没有满足服务承诺，您将有资格获得服务抵扣。", "generate_question": "如何获得服务抵扣？", "generate_answer": "如果任何 Amazon EMR 服务没有满足服务承诺，用户将有资格获得服务抵扣。具体的获得方式可能需要与亚马逊云科技的客户支持团队联系以了解详细信息。"}
{"origin_question": "\n怎样确定我是否有资格获得服务抵扣？ 如何申请？\n", "origin_answer": "要获得服务积分，您需要 在 AWS Support Center 创建一个案例，以提交申请。要了解资格和申请格式，请参阅 https://aws.amazon.com/emr/sla/", "generate_question": "如何确定是否有资格获得服务抵扣？", "generate_answer": "要确定是否有资格获得服务抵扣，您需要在 AWS Support Center 创建一个案例，以提交申请。"}
{"origin_question": "\n怎样确定我是否有资格获得服务抵扣？ 如何申请？\n", "origin_answer": "要获得服务积分，您需要 在 AWS Support Center 创建一个案例，以提交申请。要了解资格和申请格式，请参阅 https://aws.amazon.com/emr/sla/", "generate_question": "在哪里可以了解到资格和申请格式？", "generate_answer": "您可以在 https://aws.amazon.com/emr/sla/ 上了解到资格和申请格式。"}
{"origin_question": "\n怎样确定我是否有资格获得服务抵扣？ 如何申请？\n", "origin_answer": "要获得服务积分，您需要 在 AWS Support Center 创建一个案例，以提交申请。要了解资格和申请格式，请参阅 https://aws.amazon.com/emr/sla/", "generate_question": "如何申请服务积分？", "generate_answer": "要申请服务积分，您需要在 AWS Support Center 创建一个案例，并按照要求提交申请。"}
