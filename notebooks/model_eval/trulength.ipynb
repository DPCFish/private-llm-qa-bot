{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2522a33-cdcc-49aa-89a3-108ec7ae79da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 前提条件\n",
    "- 本地安装jupyter notebook <br>\n",
    "执行`pip3 install notebook` <br>\n",
    "\n",
    "- 运行notebook （不能到SageMaker中运行，因为无法打开后续的评估页面）<br>\n",
    "cd 到当前repo所在的目录 <br>\n",
    "执行 `jupyter notebook`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f7b3a0",
   "metadata": {},
   "source": [
    "## 安装trulens-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4b78b-1de1-4eaf-8b80-910c2c7bbc41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install trulens-eval==0.18.3 llama_index==0.8.69 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2e787-6ad6-4cf2-9fc1-7ee5f0de7057",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a841f92-6b8e-49a5-a64b-aacd7b604284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import json\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "# Tru().reset_database()\n",
    "tru = Tru()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f55d2d-eadf-4011-8ba3-b4d44d1d9393",
   "metadata": {},
   "source": [
    "## 定义RAG App\n",
    "- 需要实现retrieve，和query接口， trulens会记录这2个接口的输入和结果\n",
    "- Api gateway有时候会超时，所以直接使用lambda\n",
    "- 执行该脚本时需要对main func lambda 有invoke权限"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9f529",
   "metadata": {},
   "source": [
    "### 更换成对应的main func arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e3cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = '<account_id_placeholder>'\n",
    "region='us-west-2'\n",
    "main_func = f'arn:aws:lambda:{region}:{account_id}:function:Ask_Assistant'\n",
    "main_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c433570-9bc2-477e-95b6-c30e2a618a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "lambda_client = boto3.client('lambda',regin_name=region)\n",
    "# MODEL_NAME = \"claude-instant\"\n",
    "MODEL_NAME = \"claude-v2\"\n",
    "\n",
    "class RAG_from_scratch:\n",
    "    @instrument\n",
    "    def retrieve(self, query: str) -> list:\n",
    "        results = self.call_remote_service(query, retrieve_only=True)\n",
    "        ret = [result['doc'] for result in results]\n",
    "        return ret\n",
    "        \n",
    "    def call_remote_service(self,query:str,retrieve_only:bool = False, max_token :int =1024):\n",
    "        ## 构建pay load\n",
    "        payload={\n",
    "            \"msgid\":str(uuid.uuid4()),\n",
    "            \"chat_name\":\"OnlyForDEBUG\",\n",
    "            \"prompt\":query,\n",
    "            \"use_qa\":True,\n",
    "            \"multi_rounds\":False,\n",
    "            \"hide_ref\":True,\n",
    "            \"use_stream\":False,\n",
    "            \"max_tokens\":max_token,\n",
    "            \"retrieve_only\":retrieve_only,\n",
    "            \"temperature\": 0.01,\n",
    "            \"use_trace\": False,\n",
    "            \"system_role\": \"\",\n",
    "            \"system_role_prompt\": \"\",\n",
    "            \"model_name\": MODEL_NAME,\n",
    "            \"template_id\": \"1702434088941-4073e3\",\n",
    "            \"username\": \"test\"\n",
    "        }\n",
    "        start = time.time()\n",
    "        response = lambda_client.invoke(\n",
    "                FunctionName = main_func,\n",
    "                InvocationType='RequestResponse',\n",
    "                Payload=json.dumps(payload)\n",
    "            )\n",
    "        print(f'time cost:{time.time()-start}')\n",
    "        payload_json = json.loads(response.get('Payload').read())     \n",
    "        body = payload_json['body']\n",
    "        # print(body)\n",
    "        if retrieve_only:\n",
    "            extra_info =  body[0]['extra_info']\n",
    "            return extra_info['recall_knowledge']\n",
    "        else:\n",
    "            answer = body[0]['choices'][0]['text']\n",
    "            return answer\n",
    "        \n",
    "\n",
    "    @instrument\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve(query)\n",
    "        completion = self.call_remote_service(query)\n",
    "        return completion\n",
    "\n",
    "rag = RAG_from_scratch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5cd66-2b2a-44b2-ba72-323f44a5b880",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 测试下是否能跑通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f614bbe-1e67-47b6-b0ac-df3ea36d765e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag.query('怎么提交FOOB？')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fe66a-b269-423c-8c23-f9c1ba6cf036",
   "metadata": {},
   "source": [
    "## 使用Claude 作为评估器的基础模型\n",
    "- 当前trulens-eval-0.18.3版本不支持claude，因此需要对provider进行重载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556fc1c-6444-45b2-8728-2473dd090caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trulens_eval.feedback.provider.bedrock import Bedrock as fBedrock\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "class NewBedrock(fBedrock):\n",
    "    model_id :str = \"anthropic.claude-v2:1\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        model_id: str = \"anthropic.claude-v2:1\",\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "             *args,\n",
    "            model_id=model_id,\n",
    "            **kwargs\n",
    "        )  \n",
    "        \n",
    "    def convert_messages(self,messages:list) ->str: \n",
    "        prompt = ''\n",
    "        for msg in messages:\n",
    "            if msg['role'] == 'system':\n",
    "                prompt += msg['content'] + '\\\\n'\n",
    "            elif msg['role'] == 'user':\n",
    "                prompt += msg['content'] + '\\\\n'\n",
    "        return prompt\n",
    "\n",
    "    # LLMProvider requirement\n",
    "    def _create_chat_completion(\n",
    "        self,\n",
    "        prompt: Optional[str] = None,\n",
    "        messages: Optional[Sequence[Dict]] = None,\n",
    "        **kwargs\n",
    "    ) -> str:\n",
    "        assert self.endpoint is not None\n",
    "        \n",
    "        if not prompt and messages:\n",
    "            prompt = self.convert_messages(messages)\n",
    "            \n",
    "        print('*********** prompt to claude:***********\\n',prompt)\n",
    "        import json\n",
    "    \n",
    "        body = json.dumps({\n",
    "            \"prompt\": f\"\\n\\nHuman: {prompt}\\n\\nAssistant:\",\n",
    "            \"max_tokens_to_sample\": 2000,\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.9,\n",
    "        })\n",
    "        \n",
    "        modelId = self.model_id\n",
    "\n",
    "        response = self.endpoint.client.invoke_model(body=body, modelId=modelId)\n",
    "        \n",
    "        response_body = json.loads(response.get('body').read()).get('completion')\n",
    "        \n",
    "        print('*********** claude response:***********\\n',response_body)\n",
    "\n",
    "        return response_body\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd776d5-ddec-4fe2-81cb-9546119eae3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_provider = NewBedrock(model_id='anthropic.claude-v2:1',region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0248822-68ad-40fd-baca-c3eb7dcc4262",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 如果使用openai\n",
    "- 则填入api key\n",
    "- 使用llm_provider = fOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7eb0a2-1319-4585-9f3b-ce4b20b06ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY_PLACEHOLDER\"\n",
    "llm_provider = fOpenAI(model_engine='gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22f076-18ec-4915-88d7-88e5e3c052bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 导入golden set文件\n",
    "- golden set文件需要自己准备，是一个excel文件，有两列，分别是问题和答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4eecc9-c3c1-4cfb-acdf-2a41c703b589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51021c79-05a0-41d1-98c3-4d857e26cd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('golden_set.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e990f06-c2bc-43cc-8c77-45d8e64f63fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "golden_set = [{'query':q,'response':a} for q,a in df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9ff28-ef08-4c95-851f-7494b438bd59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback import GroundTruthAgreement\n",
    "from trulens_eval.feedback.provider.openai import OpenAI as fOpenAI\n",
    "from trulens_eval.feedback.provider.bedrock import Bedrock as fBedrock\n",
    "from trulens_eval.feedback.provider.endpoint.bedrock import BedrockEndpoint as BedrockEndpoint\n",
    "import numpy as np\n",
    "\n",
    "# Initialize provider class\n",
    "# llm_provider = fOpenAI()\n",
    "\n",
    "# Define a groundtruth feedback function\n",
    "f_groundtruth = (\n",
    "    Feedback(GroundTruthAgreement(golden_set,provider=llm_provider).agreement_measure, name = \"Ground Truth\").on_input_output()\n",
    ")\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=llm_provider)\n",
    "# Define a groundedness feedback function\n",
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons, name = \"Groundedness\")\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = (\n",
    "    Feedback(llm_provider.relevance_with_cot_reasons, name = \"Answer Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on_output()\n",
    ")\n",
    "\n",
    "# Question/statement relevance between question and each context chunk.\n",
    "f_context_relevance = (\n",
    "    Feedback(llm_provider.qs_relevance_with_cot_reasons, name = \"Context Relevance\")\n",
    "    .on(Select.RecordCalls.retrieve.args.query)\n",
    "    .on(Select.RecordCalls.retrieve.rets.collect())\n",
    "    .aggregate(np.mean)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35589569-2fc4-4e7e-b74d-4b9f3b9acac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruCustomApp\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now()\n",
    "timestamp_str = timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "app_id = f'RAG_{timestamp_str}_{MODEL_NAME}'\n",
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = app_id,\n",
    "    feedbacks = [f_groundtruth,f_groundedness,f_qa_relevance,f_context_relevance]\n",
    "    ) #f_groundtruth,f_groundedness,f_qa_relevance,f_context_relevance\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9e6a57",
   "metadata": {},
   "source": [
    "### 先用一个query简单测试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b18241",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    rag.query('aws cleanrooms是什么？')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6484453",
   "metadata": {},
   "source": [
    "### 使用golden set测试集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c94955e-e6cd-4ac7-b10c-d5084e27b931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time \n",
    "with tru_rag as recording:\n",
    "    for i,item in enumerate(golden_set):\n",
    "        print(f\"run query[{i}] [{item['query']}]\")\n",
    "        rag.query(item['query'])\n",
    "        time.sleep(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1313a3ef",
   "metadata": {},
   "source": [
    "## 查看得分结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf4899-9db5-41e4-bfc4-17e69d8497dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd680cc3",
   "metadata": {},
   "source": [
    "# 启动仪表板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d57dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add13e98",
   "metadata": {},
   "source": [
    "# 关闭仪表盘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14b7d3-5d83-45ef-944d-dd87335c823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.stop_dashboard()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
