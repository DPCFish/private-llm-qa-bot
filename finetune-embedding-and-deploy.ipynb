{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be69f0e-bc9c-41c1-ba7b-c5b9a42c2e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
      "  Using cached safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, regex, nltk, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.16.4 nltk-3.8.1 regex-2023.6.3 safetensors-0.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.31.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "736dc101-5863-44ff-b086-a25a69f0b51d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.19.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.19.0\n",
      "    Uninstalling accelerate-0.19.0:\n",
      "      Successfully uninstalled accelerate-0.19.0\n",
      "Successfully installed accelerate-0.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install  accelerate -U "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59b9525-038f-4820-9d22-1de0d83bfbf7",
   "metadata": {},
   "source": [
    "# finetune 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c2ae124-2a55-4713-afe0-c40be9b3bb5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "import torch\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bc65f6-c9a2-47bc-a2da-094b8924ca15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s', datefmt = '%Y-%m-%d %H:%M:S', level=logging.INFO, handlers =[LoggingHandler()] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e9e75-5fdf-4e85-967f-e4d86f85902a",
   "metadata": {},
   "source": [
    "## 从hf加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66eade76-c737-4abc-8a2d-625347306f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 09:31:S - Load pretrained SentenceTransformer: sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "2023-07-31 09:31:S - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "modelB = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5cf155-2608-4cad-934f-c7281e3c8fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_id = \"embedding-data/sentence-compression\"\n",
    "# dataset = load_dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfa89a5-e6af-45fa-9b76-7b05900aabbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3_faq.faq', '.ipynb_checkpoints', '1_faq.faq', '4_faq.faq', '2_faq.faq']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,datasets\n",
    "filenames = os.listdir('topwar_faq')\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5808a2dd-569a-4513-9ded-3c25b35a64c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:126\n"
     ]
    }
   ],
   "source": [
    "def parse_faq(file_content,QA_SEP='====='):\n",
    "    arr = file_content.split(QA_SEP)\n",
    "    list_arr = []\n",
    "    for item in arr:\n",
    "        question, answer = item.strip().split(\"\\n\", 1)\n",
    "        question = question.replace(\"Question: \", \"\")\n",
    "        answer = answer.replace(\"Answer: \", \"\")\n",
    "        list_arr.append((answer,question))\n",
    "    return list_arr\n",
    "\n",
    "all_datas = []\n",
    "for fn in filenames:\n",
    "    if fn == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    with open(f\"topwar_faq/{fn}\") as f:\n",
    "        data = f.read()\n",
    "        all_datas += parse_faq(data)\n",
    "print(f\"data size:{len(all_datas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "734c79a3-92b1-4740-909e-e7e195099bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "\n",
    "for i in range(len(all_datas)):\n",
    "    example = all_datas[i]\n",
    "    train_examples.append(InputExample(texts=[example[0], example[1]],label = [0.85]*len(all_datas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c874f8-1f0c-40d9-b9b3-6d4a219646fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=64)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=modelB)\n",
    "num_epochs = 10\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7353170e-a8af-494b-8981-40f586446955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:03<00:03,  3.73s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]\u001b[A\n",
      "Epoch:  10%|█         | 1/10 [00:05<00:46,  5.15s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.44s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\u001b[A\n",
      "Epoch:  20%|██        | 2/10 [00:08<00:30,  3.80s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.44s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]\u001b[A\n",
      "Epoch:  30%|███       | 3/10 [00:10<00:23,  3.36s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.44s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\u001b[A\n",
      "Epoch:  40%|████      | 4/10 [00:13<00:18,  3.15s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.45s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\u001b[A\n",
      "Epoch:  50%|█████     | 5/10 [00:16<00:15,  3.04s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.43s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]\u001b[A\n",
      "Epoch:  60%|██████    | 6/10 [00:19<00:11,  2.98s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.42s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\u001b[A\n",
      "Epoch:  70%|███████   | 7/10 [00:22<00:08,  2.94s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.47s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]\u001b[A\n",
      "Epoch:  80%|████████  | 8/10 [00:25<00:05,  2.92s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.45s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\u001b[A\n",
      "Epoch:  90%|█████████ | 9/10 [00:27<00:02,  2.91s/it]\n",
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Iteration:  50%|█████     | 1/2 [00:01<00:01,  1.47s/it]\u001b[A\n",
      "Iteration: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 10/10 [00:30<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-31 02:55:S - Save model to ./finetuned-sentence-embedding\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "modelB.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "           # evaluator=evaluator,\n",
    "            evaluation_steps=5,\n",
    "           output_path='./finetuned-sentence-embedding',\n",
    "          warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc41acd2-7471-4cc1-889b-1a70eb6d21c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelB.evaluate(evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4597bff-501a-47e0-83df-a4a672823f18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 从本地加载finetuned的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "18fd2552-4321-4c94-8452-2177b731554b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-01 08:35:S - Load pretrained SentenceTransformer: ./finetuned-sentence-embedding\n",
      "2023-08-01 08:35:S - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "modelB = SentenceTransformer('./finetuned-sentence-embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "82f99adb-d475-41bc-827b-9fe1dbdd96d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.37it/s]\n"
     ]
    }
   ],
   "source": [
    "input_sentences_a = ['专属技能碎片可以通过多种途径获得，例如礼包商城-特惠礼包界面可以购买专属技能碎片礼包', \n",
    "                  '中国首都在北京',\n",
    "                  '美国首都在华盛顿']\n",
    "input_sentences_q = ['专属技能碎片在哪里？',\n",
    "                   '中国首都在哪里？',\n",
    "                   '美国首都在哪里？']\n",
    "\n",
    "embeddings = modelB.encode(input_sentences_a+input_sentences_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb77deba-a613-4177-bf04-7f02692614d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7496, -0.0593, -0.0969],\n",
       "        [-0.0216,  0.8824,  0.5007],\n",
       "        [-0.0075,  0.5930,  0.8479]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import evaluation,util\n",
    "\n",
    "util.cos_sim(embeddings[:3],embeddings[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "807f79e8-002a-4f86-9294-27b11158cbb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_answer  = []\n",
    "input_question  = []\n",
    "for i, (a,b) in enumerate (all_datas):\n",
    "        input_answer.append(a)\n",
    "        input_question.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a9bbeb9d-7d2d-4e47-aa4c-3cacb31db498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:00<00:00, 10.10it/s]\n",
      "Batches: 100%|██████████| 4/4 [00:00<00:00, 31.72it/s]\n"
     ]
    }
   ],
   "source": [
    "emb_answer = modelB.encode(input_answer)\n",
    "emb_question = modelB.encode(input_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "90bb0891-fd80-4a90-bdf1-097c43c80e55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 126)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_question),len(input_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8715caf-e85a-4690-beb2-0d732a8b244d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 将question和answer进行cross 对比，生成126*126个结果，再查看这个分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e529a082-e4d0-4f0e-85bd-f38160a09cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_simsvalues = util.cos_sim(emb_answer,emb_question).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "23cfc0f1-4468-48bb-8349-1011605d5870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_sims_s = pd.Series(cross_simsvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cdd17e5a-01cc-481b-9f36-e56944f2cd86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = len(input_question)\n",
    "pos_indices = [ i*N+i for i in range(N)] ##正例的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "92f376bf-da76-4f80-bf93-ca0165f2dbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    126.000000\n",
       "mean       0.655297\n",
       "std        0.099786\n",
       "min        0.439509\n",
       "25%        0.583280\n",
       "50%        0.661202\n",
       "75%        0.720619\n",
       "max        0.912604\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正样本的得分\n",
    "pos_cross_sims_s = cross_sims_s[pos_indices]\n",
    "pos_cross_sims_s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1b58af3-47be-423a-8999-da07609eaa9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15750.000000\n",
       "mean         0.099584\n",
       "std          0.123988\n",
       "min         -0.246504\n",
       "25%          0.015882\n",
       "50%          0.086160\n",
       "75%          0.162934\n",
       "max          0.813635\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#负样本得分\n",
    "neg_cross_sims_s = cross_sims_s.drop(pos_indices)\n",
    "neg_cross_sims_s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "98bfbea3-1274-4ea0-91d9-69af1784600c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(pos_cross_sims_s, color='green',kde=True)\n",
    " ##负样本较多，只采样一部分进行plot\n",
    "sns.histplot(neg_cross_sims_s.sample(N), color='red',kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b8002-1cb8-4899-a903-c43fabf37ddc",
   "metadata": {},
   "source": [
    "## 输出具体的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7f5224be-74af-410b-b165-e211399bc26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def similarity(v1,v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "\n",
    "    return dot_product / (magnitude_v1 * magnitude_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ee658-32b0-49ab-b6eb-2c9b258e1762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_question)):\n",
    "    sims = similarity(emb_answer[i],emb_question[i])\n",
    "    print(f\"Question:{input_question[i]}\\nAnswer:{input_answer[i]}\\n{sims}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63deec-e324-470e-aad4-ff13cabcbaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "348b3ab6-f42d-4c54-a9b7-3a6223387168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 89.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'corpus_id': 117, 'score': 0.36897891759872437},\n",
       "  {'corpus_id': 35, 'score': 0.36897891759872437},\n",
       "  {'corpus_id': 120, 'score': 0.35904332995414734}]]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_queries = ['雷电将军好不好使？']\n",
    "q_embedding = modelB.encode(input_queries)\n",
    "results = util.semantic_search(query_embeddings = q_embedding,corpus_embeddings= emb_answer,top_k=3)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37fbf424-9b29-44ba-8300-65aab4b56a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4407898"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(q_embedding[0],emb_answer[93])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6b7015ab-0ab1-4b5a-bb70-1f1eff19c8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('全力交锋--战斗阶段开始后，跨服到其它战区后，除了攻打首府和两个2个王者遗迹-守卫外（其他遗迹和发射塔为和平状态，不可攻击），还可以攻打该服玩家的城堡，采集田和强化弱化塔。', '战斗阶段是否可以攻击其他战区指挥官？') score:0.4162951409816742\n",
      "('玩家拥有建筑的占领权后，拥有【先锋】权限的玩家，可以开启对决。开启对决后，该玩家在此建筑中的所有部队都将会进入对决状态中，其他势力的拥有【先锋】权限的玩家，可以发起对决；当击败玩家所有进入对决状态的部队后，视为攻击成功。对决连续守住一定的攻击次数，或守住规定的时间，则对决成功，否则对决失败。对决获胜，可获得一定时间的无敌时间，并立即摧毁一定的城防值；对决失败，则击败对决的玩家获得建筑的控制权。', '先锋对决怎么玩，胜负规则是什么？') score:0.33781808614730835\n",
      "('您好，破浪突袭者BW-3的控制技能主要体现在 技能中有一项是潮汐震荡，如果被击目标处在攻击力降低状态，50%概率对其附加[眩晕]（无法普攻和释放主动技能）。从技能定位来看，其更偏向攻击，但防守效果也不错。', '小蓝是拥有控制技能的重装机兵，这个控制技能怎么理解？它更适合攻击还是防守？') score:0.29779693484306335\n"
     ]
    }
   ],
   "source": [
    "for ret in results[0]:\n",
    "    print(f\"{all_datas[ret['corpus_id']]} score:{ret['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80db02-8714-4132-8457-2acf024b1a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d47bd28-2482-47cb-b058-9f2f8bce9944",
   "metadata": {},
   "source": [
    "# 使用pre trained 模型对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "da83ef84-16fd-4366-9a0e-3be21e731fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "66d5dff5-b3eb-44d6-b871-926cda9de11a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ccf9a3e4-15c9-4233-aad4-c65c68c6e7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0].to(device) #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float().to(device)\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def load_model(model_location):    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "   \n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_location, \n",
    "        # device_map=\"balanced_low_0\", \n",
    "        #load_in_8bit=True\n",
    "    )\n",
    "    # load the model on GPU\n",
    "    model.to(device) \n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fedb25cf-5c33-41fd-8131-0c0c36cdebd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_location = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
    "modelA,tokenizer  = load_model(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1f875dd8-c54c-4eb3-9516-9c9a7a16ae8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(input_question, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1d2ee9b2-e277-4e8e-90bd-6759665b091d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model_output = modelA(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings_q = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "116a097b-ab2d-41d6-a2e8-309e5c27bf51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(input_answer, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    model_output = modelA(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings_a = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15726d48-4201-4edf-82ed-c0222afd82a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(input_question)):\n",
    "    sims = similarity(sentence_embeddings_a[i],sentence_embeddings_q[i])\n",
    "    print(f\"Question:{input_question[i]}\\nAnswer:{input_answer[i]}\\n{sims}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f29850ba-cfa6-476b-9a2b-8262aa55f22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_queries = ['怎么攻击别人?']\n",
    "encoded_input = tokenizer(input_queries, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    model_output = modelA(**encoded_input)\n",
    "\n",
    "q_embedding = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fa12cf2d-097c-4a0d-8725-d83b7df885fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('您好，[援护]效果不分担燃烧伤害（除燃烧伤害外，都可以分担）。拥有点燃技能的英雄目前有寂，914，马克西莫，异化娜迪亚等。', '尤里卡突袭者的[援护]效果是否能分担各种英雄技能打出的伤害？') score:0.44886574149131775\n",
      "('玩家拥有建筑的占领权后，拥有【先锋】权限的玩家，可以开启对决。开启对决后，该玩家在此建筑中的所有部队都将会进入对决状态中，其他势力的拥有【先锋】权限的玩家，可以发起对决；当击败玩家所有进入对决状态的部队后，视为攻击成功。对决连续守住一定的攻击次数，或守住规定的时间，则对决成功，否则对决失败。对决获胜，可获得一定时间的无敌时间，并立即摧毁一定的城防值；对决失败，则击败对决的玩家获得建筑的控制权。', '先锋对决怎么玩，胜负规则是什么？') score:0.4420698285102844\n",
      "('您好，破浪突袭者BW-3的控制技能主要体现在 技能中有一项是潮汐震荡，如果被击目标处在攻击力降低状态，50%概率对其附加[眩晕]（无法普攻和释放主动技能）。从技能定位来看，其更偏向攻击，但防守效果也不错。', '小蓝是拥有控制技能的重装机兵，这个控制技能怎么理解？它更适合攻击还是防守？') score:0.43532323837280273\n"
     ]
    }
   ],
   "source": [
    "results = util.semantic_search(query_embeddings = q_embedding,corpus_embeddings= sentence_embeddings_a,top_k=3)\n",
    "results\n",
    "for ret in results[0]:\n",
    "    print(f\"{all_datas[ret['corpus_id']]} score:{ret['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9fa8a3c-ce82-406c-b274-e1157838689c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_queries \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m中国的首都在哪里？\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m中国的首都在北京\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(input_queries, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m modelA(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "input_queries = ['中国的首都在哪里？','中国的首都在北京']\n",
    "encoded_input = tokenizer(input_queries, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    model_output = modelA(**encoded_input)\n",
    "\n",
    "embedding = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc99a0-ee6a-4902-b8af-b7c6cc9da18a",
   "metadata": {},
   "source": [
    "# 部署模型到sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57dc4832-b17a-47b0-8662-4ced85f29952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.154.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.169.0.tar.gz (851 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.8/851.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting attrs<24,>=23.1.0 (from sagemaker)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.132)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Collecting PyYAML==6.0 (from sagemaker)\n",
      "  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.132 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.132)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.132->boto3<2.0,>=1.26.131->sagemaker) (1.26.15)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.169.0-py2.py3-none-any.whl size=1158252 sha256=0ec721d00f4427b64ea6d9d4e052bb5989328fde366bb4acd16933fb90d67f82\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/17/69/c2089332a0db669b4a27888e1d76e825168014112d5eb44231\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: PyYAML, attrs, sagemaker\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 5.4.1\n",
      "    Uninstalling PyYAML-5.4.1:\n",
      "      Successfully uninstalled PyYAML-5.4.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 22.2.0\n",
      "    Uninstalling attrs-22.2.0:\n",
      "      Successfully uninstalled attrs-22.2.0\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.154.0\n",
      "    Uninstalling sagemaker-2.154.0:\n",
      "      Successfully uninstalled sagemaker-2.154.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.132 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0 attrs-23.1.0 sagemaker-2.169.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0490240-edff-4fff-8eec-bd295bf43f99",
   "metadata": {},
   "source": [
    "## 2. 把模型拷贝到S3为后续部署做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df4a6f16-63af-4c84-9dda-0af0dfa7b487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fb24429-b2e5-4259-bd2d-70aa006c8cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_code_prefix: LLM-RAG/workshop/finetuned-sentence2emb_deploy_code\n",
      "model_snapshot_path: ./finetuned-sentence-embedding\n"
     ]
    }
   ],
   "source": [
    "s3_model_prefix = \"LLM-RAG/workshop/finetuned-sentence2emb-model\"  # folder where model checkpoint will go\n",
    "model_snapshot_path = \"./finetuned-sentence-embedding\"\n",
    "s3_code_prefix = \"LLM-RAG/workshop/finetuned-sentence2emb_deploy_code\"\n",
    "print(f\"s3_code_prefix: {s3_code_prefix}\")\n",
    "print(f\"model_snapshot_path: {model_snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e53e83fd-305a-42f8-83cf-e0a17779eaac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "upload: finetuned-sentence-embedding/config_sentence_transformers.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/config_sentence_transformers.json\n",
      "upload: finetuned-sentence-embedding/config.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/config.json\n",
      "upload: finetuned-sentence-embedding/1_Pooling/config.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/1_Pooling/config.json\n",
      "upload: finetuned-sentence-embedding/modules.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/modules.json\n",
      "upload: finetuned-sentence-embedding/README.md to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/README.md\n",
      "upload: finetuned-sentence-embedding/eval/.ipynb_checkpoints/similarity_evaluation_results-checkpoint.csv to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/eval/.ipynb_checkpoints/similarity_evaluation_results-checkpoint.csv\n",
      "upload: finetuned-sentence-embedding/special_tokens_map.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/special_tokens_map.json\n",
      "upload: finetuned-sentence-embedding/eval/similarity_evaluation_results.csv to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/eval/similarity_evaluation_results.csv\n",
      "upload: finetuned-sentence-embedding/sentence_bert_config.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/sentence_bert_config.json\n",
      "upload: finetuned-sentence-embedding/tokenizer_config.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/tokenizer_config.json\n",
      "upload: finetuned-sentence-embedding/tokenizer.json to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/tokenizer.json\n",
      "upload: finetuned-sentence-embedding/sentencepiece.bpe.model to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/sentencepiece.bpe.model\n",
      "upload: finetuned-sentence-embedding/pytorch_model.bin to s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive {model_snapshot_path} s3://{bucket}/{s3_model_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4c4651-d731-4e8d-8deb-350918d8d721",
   "metadata": {},
   "source": [
    "### 3. 模型部署准备（entrypoint脚本，容器镜像，服务配置）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8a07ff35-d547-4df3-b511-4be2862dcb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-2.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = (\n",
    "    f\"763104351884.dkr.ecr.{region}.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    ")\n",
    "\n",
    "#中国区需要替换为下面的image_uri\n",
    "# inference_image_uri = (\n",
    "#     f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.21.0-deepspeed0.8.3-cu117\"\n",
    "# )\n",
    "\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4858bfe1-0392-41fd-8c46-d4a04a520397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p sentence2emb_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5fe26158-4b50-4659-a869-6d64f3d152e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentence2emb_deploy_code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentence2emb_deploy_code/model.py\n",
    "from djl_python import Input, Output\n",
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'--device={device}')\n",
    "\n",
    "\n",
    "def load_model(properties):\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    model_location = properties['model_dir']\n",
    "    if \"model_id\" in properties:\n",
    "        model_location = properties['model_id']\n",
    "    logging.info(f\"Loading model in {model_location}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_location)\n",
    "   \n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_location, \n",
    "        # device_map=\"balanced_low_0\", \n",
    "        #load_in_8bit=True\n",
    "    )\n",
    "    # load the model on GPU\n",
    "    model.to(device) \n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "model = None\n",
    "tokenizer = None\n",
    "generator = None\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0].to(device) #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float().to(device)\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "def handle(inputs: Input):\n",
    "    global model, tokenizer\n",
    "    if not model:\n",
    "        model, tokenizer = load_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        return None\n",
    "    data = inputs.get_as_json()\n",
    "    \n",
    "    input_sentences = data[\"inputs\"]\n",
    "    params = data[\"parameters\"]\n",
    "    logging.info(f\"inputs: {input_sentences}\")\n",
    "    logging.info(f\"parameters: {params}\")\n",
    "    \n",
    "    encoded_input = tokenizer(input_sentences, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask']).to(device).cpu().numpy()\n",
    "\n",
    "#     # preprocess\n",
    "#     input_ids = tokenizer(input_sentences, return_tensors=\"pt\").input_ids\n",
    "#     # pass inputs with all kwargs in data\n",
    "#     if params is not None:\n",
    "#         outputs = model.generate(input_ids, **params)\n",
    "#     else:\n",
    "#         outputs = model.generate(input_ids)\n",
    "\n",
    "#     # postprocess the prediction\n",
    "#     prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    result = {\"sentence_embeddings\": sentence_embeddings}\n",
    "    return Output().add_as_json(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c02fa9-d046-42a7-88fc-fc81fe890313",
   "metadata": {},
   "source": [
    "#### Note: option.s3url 需要按照自己的账号进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64254ec0-69ab-4c2f-a9bb-05f259ab5218",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sentence2emb_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile sentence2emb_deploy_code/serving.properties\n",
    "engine=Python\n",
    "option.tensor_parallel_degree=1\n",
    "option.s3url = s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d76dad38-02f0-46f9-9121-9cb5155d7a76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "sentence2emb_deploy_code/\n",
      "sentence2emb_deploy_code/model.py\n",
      "sentence2emb_deploy_code/serving.properties\n"
     ]
    }
   ],
   "source": [
    "!rm s2e_model.tar.gz\n",
    "!cd sentence2emb_deploy_code && rm -rf \".ipynb_checkpoints\"\n",
    "!tar czvf s2e_model.tar.gz sentence2emb_deploy_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76d3d300-4d4d-4ea3-a7d8-2667619cd727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-east-2-946277762357/LLM-RAG/workshop/finetuned-sentence2emb_deploy_code/s2e_model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_artifact = sess.upload_data(\"s2e_model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a07e1-0955-497f-ba2d-9991a6deb833",
   "metadata": {},
   "source": [
    "### 4. 创建模型 & 创建endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9318f47-36c1-4f16-962b-bdfe84c77c16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned-paraphrase-2023-07-05-03-14-23-508\n",
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-east-2.amazonaws.com/djl-inference:0.21.0-deepspeed0.8.3-cu117\n",
      "Created Model: arn:aws:sagemaker:us-east-2:946277762357:model/finetuned-paraphrase-2023-07-05-03-14-23-508\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "import boto3\n",
    "\n",
    "model_name = name_from_base(\"finetuned-paraphrase\") #Note: Need to specify model_name\n",
    "print(model_name)\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\n",
    "        \"Image\": inference_image_uri,\n",
    "        \"ModelDataUrl\": s3_code_artifact\n",
    "    },\n",
    "    \n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a2371-de79-4240-b029-80c15a674a7f",
   "metadata": {},
   "source": [
    "###  如果批量创建索引量较多，建议改成\"InstanceType\": \"ml.g4dn.xlarge\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e337d531-3324-4ae4-ac76-66c3418fd548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointConfigArn': 'arn:aws:sagemaker:us-east-2:946277762357:endpoint-config/finetuned-paraphrase-2023-07-05-03-14-23-508-config',\n",
       " 'ResponseMetadata': {'RequestId': '0b754ef3-6cb2-4243-bd14-518fbf35d080',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '0b754ef3-6cb2-4243-bd14-518fbf35d080',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '132',\n",
       "   'date': 'Wed, 05 Jul 2023 03:14:30 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": \"ml.m5.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            # \"VolumeSizeInGB\" : 400,\n",
    "            # \"ModelDataDownloadTimeoutInSeconds\": 2400,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 10*60,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "endpoint_config_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "75f6a4b6-c36a-4ec5-8dd9-35b237ba55ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_1225/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">4188345917.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_1225/4188345917.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">530</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_api_call</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>py_operation_name<span style=\"color: #808000; text-decoration-color: #808000\">}() only accepts keyword arguments.\"</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 │   │   │   # The \"self\" in this scope is referring to the BaseClient.</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 530 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._make_api_call(operation_name, kwargs)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 531 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 │   │   </span>_api_call.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(py_operation_name)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">960</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_make_api_call</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 957 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> http.status_code &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">300</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 958 │   │   │   </span>error_code = parsed_response.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Error\"</span>, {}).get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Code\"</span>)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 959 │   │   │   </span>error_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.exceptions.from_code(error_code)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 960 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> error_class(parsed_response, operation_name)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 961 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 962 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parsed_response                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 963 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ClientError: </span>An error occurred <span style=\"font-weight: bold\">(</span>ValidationException<span style=\"font-weight: bold\">)</span> when calling the CreateEndpoint operation: Cannot create \n",
       "already existing endpoint \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"arn:aws:sagemaker:us-east-2:946277762357:endpoint/finetuned-paraphrase-2023-07-05-03-14-23-508-endpoint\"</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_1225/\u001b[0m\u001b[1;33m4188345917.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_1225/4188345917.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m530\u001b[0m in \u001b[92m_api_call\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpy_operation_name\u001b[33m}\u001b[0m\u001b[33m() only accepts keyword arguments.\u001b[0m\u001b[33m\"\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 530 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._make_api_call(operation_name, kwargs)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 531 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   \u001b[0m_api_call.\u001b[91m__name__\u001b[0m = \u001b[96mstr\u001b[0m(py_operation_name)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m960\u001b[0m in \u001b[92m_make_api_call\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 957 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http.status_code >= \u001b[94m300\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 958 \u001b[0m\u001b[2m│   │   │   \u001b[0merror_code = parsed_response.get(\u001b[33m\"\u001b[0m\u001b[33mError\u001b[0m\u001b[33m\"\u001b[0m, {}).get(\u001b[33m\"\u001b[0m\u001b[33mCode\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 959 \u001b[0m\u001b[2m│   │   │   \u001b[0merror_class = \u001b[96mself\u001b[0m.exceptions.from_code(error_code)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 960 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m error_class(parsed_response, operation_name)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 961 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 962 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m parsed_response                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 963 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mClientError: \u001b[0mAn error occurred \u001b[1m(\u001b[0mValidationException\u001b[1m)\u001b[0m when calling the CreateEndpoint operation: Cannot create \n",
       "already existing endpoint \n",
       "\u001b[32m\"arn:aws:sagemaker:us-east-2:946277762357:endpoint/finetuned-paraphrase-2023-07-05-03-14-23-508-endpoint\"\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "277cc50a-d67e-4d01-ae58-18af86bf6259",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:us-east-2:946277762357:endpoint/finetuned-paraphrase-2023-07-04-16-08-10-303-endpoint\n",
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9ac01c-e8d9-4887-be4e-baded6d36abc",
   "metadata": {},
   "source": [
    "## 5. 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bef7a45-2484-4c77-8b14-1f6d5fea6b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vector_by_sm_endpoint(questions, sm_client, endpoint_name):\n",
    "    parameters = {\n",
    "        \"max_new_tokens\": 50,\n",
    "        \"temperature\": 0,\n",
    "        \"min_length\": 10,\n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "    }\n",
    "\n",
    "    response_model = sm_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": questions,\n",
    "                \"parameters\": parameters\n",
    "            }\n",
    "        ),\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    json_str = response_model['Body'].read().decode('utf8')\n",
    "    json_obj = json.loads(json_str)\n",
    "    embeddings = json_obj['sentence_embeddings']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61b0cb25-1e16-4a70-a77c-f5e644d1166e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts1 = \"\"\"专属技能碎片在哪里获得？\"\"\"\n",
    "prompts1 = \"\"\"中国首都在哪里？\"\"\"\n",
    "\n",
    "emb1 = get_vector_by_sm_endpoint(prompts1, smr_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f37256a-7fa3-4e4c-b0c5-f17e0e8f858a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts2 = \"\"\"专属技能碎片可以通过多种途径获得，例如礼包商城-特惠礼包界面可以购买专属技能碎片礼包\"\"\"\n",
    "emb2 = get_vector_by_sm_endpoint(prompts2, smr_client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9377d20d-31c8-493e-9247-135052e35cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0653]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.cos_sim(emb1,emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3a2f25-e206-439e-b8ee-b5f4216f09a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
